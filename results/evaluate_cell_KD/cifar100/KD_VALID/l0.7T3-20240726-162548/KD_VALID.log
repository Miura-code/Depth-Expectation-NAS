07/26 04:25:48PM parser.py:28 [INFO] 
07/26 04:25:48PM parser.py:29 [INFO] Parameters:
07/26 04:25:48PM parser.py:31 [INFO] T=5.0
07/26 04:25:48PM parser.py:31 [INFO] ADVANCED=True
07/26 04:25:48PM parser.py:31 [INFO] AUX_WEIGHT=0.4
07/26 04:25:48PM parser.py:31 [INFO] BATCH_SIZE=64
07/26 04:25:48PM parser.py:31 [INFO] CUTOUT_LENGTH=16
07/26 04:25:48PM parser.py:31 [INFO] DATA_PATH=../data/
07/26 04:25:48PM parser.py:31 [INFO] DATASET=cifar100
07/26 04:25:48PM parser.py:31 [INFO] DESCRIPTION=validate_kd_setting_T-3_lambda-0.7
07/26 04:25:48PM parser.py:31 [INFO] DROP_PATH_PROB=0.2
07/26 04:25:48PM parser.py:31 [INFO] EPOCHS=100
07/26 04:25:48PM parser.py:31 [INFO] EXP_NAME=l0.7T3-20240726-162548
07/26 04:25:48PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('dil_conv_3x3', 2)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 3)]], normal1_concat=range(2, 6), reduce1=[[('skip_connect', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 2), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 0), ('sep_conv_3x3', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 2)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 0), ('skip_connect', 1)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_5x5', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)]], normal3_concat=range(2, 6))
07/26 04:25:48PM parser.py:31 [INFO] GPUS=[0]
07/26 04:25:48PM parser.py:31 [INFO] GRAD_CLIP=5.0
07/26 04:25:48PM parser.py:31 [INFO] INIT_CHANNELS=32
07/26 04:25:48PM parser.py:31 [INFO] L=0.6
07/26 04:25:48PM parser.py:31 [INFO] LAYERS=20
07/26 04:25:48PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
07/26 04:25:48PM parser.py:31 [INFO] LR=0.025
07/26 04:25:48PM parser.py:31 [INFO] LR_MIN=0.001
07/26 04:25:48PM parser.py:31 [INFO] MOMENTUM=0.9
07/26 04:25:48PM parser.py:31 [INFO] NAME=KD_VALID
07/26 04:25:48PM parser.py:31 [INFO] NONKD=False
07/26 04:25:48PM parser.py:31 [INFO] PATH=results/evaluate_cell_KD/cifar100/KD_VALID/l0.7T3-20240726-162548
07/26 04:25:48PM parser.py:31 [INFO] PRINT_FREQ=50
07/26 04:25:48PM parser.py:31 [INFO] RESUME_PATH=None
07/26 04:25:48PM parser.py:31 [INFO] SAVE=l0.7T3
07/26 04:25:48PM parser.py:31 [INFO] SEED=0
07/26 04:25:48PM parser.py:31 [INFO] TEACHER_NAME=efficientnet_v2_s
07/26 04:25:48PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/teacher/cifar100/efficientnet_v2_s/FINETUNE2/pretrained-20240716-002108/best.pth.tar
07/26 04:25:48PM parser.py:31 [INFO] TRAIN_PORTION=0.9
07/26 04:25:48PM parser.py:31 [INFO] WEIGHT_DECAY=0.0003
07/26 04:25:48PM parser.py:31 [INFO] WORKERS=4
07/26 04:25:48PM parser.py:32 [INFO] 
07/26 04:25:50PM evaluateCell_KD_trainer.py:113 [INFO] --> Loaded teacher model 'efficientnet_v2_s' from '/home/miura/lab/KD-hdas/results/teacher/cifar100/efficientnet_v2_s/FINETUNE2/pretrained-20240716-002108/best.pth.tar' and Freezed parameters)
07/26 04:25:52PM eval_util.py:125 [INFO] Test: Step 000/078 Prec@(1,5) (81.2%, 98.4%)
07/26 04:25:58PM eval_util.py:125 [INFO] Test: Step 078/078 Prec@(1,5) (85.9%, 98.2%)
07/26 04:25:58PM eval_util.py:130 [INFO] Teacher=(efficientnet_v2_s <- (/home/miura/lab/KD-hdas/results/teacher/cifar100/efficientnet_v2_s/FINETUNE2/pretrained-20240716-002108/best.pth.tar)) achives Test Prec(@1, @5) = (85.9400%, 98.1600%)
07/26 04:26:01PM evaluateCell_KD_trainer.py:120 [INFO] --> No loaded checkpoint!
07/26 04:26:11PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][50/703]	Step 50	lr 0.025	Loss 68.7335 (70.8065)	Hard Loss 4.4584 (4.5975)	Soft Loss 0.0042 (0.0039)	Prec@(1,5) (1.4%, 7.3%)	
07/26 04:26:20PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][100/703]	Step 100	lr 0.025	Loss 68.2963 (70.0004)	Hard Loss 4.4294 (4.5438)	Soft Loss 0.0039 (0.0039)	Prec@(1,5) (2.3%, 9.9%)	
07/26 04:26:29PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][150/703]	Step 150	lr 0.025	Loss 67.2752 (69.0987)	Hard Loss 4.3625 (4.4837)	Soft Loss 0.0038 (0.0038)	Prec@(1,5) (2.8%, 12.3%)	
07/26 04:26:37PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][200/703]	Step 200	lr 0.025	Loss 67.8562 (68.4233)	Hard Loss 4.4038 (4.4390)	Soft Loss 0.0036 (0.0038)	Prec@(1,5) (3.3%, 13.6%)	
07/26 04:26:46PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][250/703]	Step 250	lr 0.025	Loss 66.7928 (67.5305)	Hard Loss 4.3344 (4.3802)	Soft Loss 0.0036 (0.0038)	Prec@(1,5) (3.8%, 15.2%)	
07/26 04:26:55PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][300/703]	Step 300	lr 0.025	Loss 66.5131 (66.7251)	Hard Loss 4.3140 (4.3274)	Soft Loss 0.0035 (0.0037)	Prec@(1,5) (4.3%, 16.8%)	
07/26 04:27:04PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][350/703]	Step 350	lr 0.025	Loss 62.9426 (65.9950)	Hard Loss 4.0809 (4.2796)	Soft Loss 0.0040 (0.0037)	Prec@(1,5) (4.7%, 18.1%)	
07/26 04:27:13PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][400/703]	Step 400	lr 0.025	Loss 57.8568 (65.1643)	Hard Loss 3.7459 (4.2252)	Soft Loss 0.0034 (0.0037)	Prec@(1,5) (5.4%, 19.8%)	
07/26 04:27:21PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][450/703]	Step 450	lr 0.025	Loss 53.9992 (64.4509)	Hard Loss 3.4926 (4.1785)	Soft Loss 0.0034 (0.0037)	Prec@(1,5) (6.2%, 21.4%)	
07/26 04:27:30PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][500/703]	Step 500	lr 0.025	Loss 61.3778 (63.6920)	Hard Loss 3.9793 (4.1288)	Soft Loss 0.0040 (0.0037)	Prec@(1,5) (7.0%, 22.9%)	
07/26 04:27:39PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][550/703]	Step 550	lr 0.025	Loss 55.5146 (63.0038)	Hard Loss 3.5958 (4.0839)	Soft Loss 0.0033 (0.0036)	Prec@(1,5) (7.6%, 24.3%)	
07/26 04:27:48PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][600/703]	Step 600	lr 0.025	Loss 53.7276 (62.3277)	Hard Loss 3.4780 (4.0397)	Soft Loss 0.0035 (0.0036)	Prec@(1,5) (8.2%, 25.6%)	
07/26 04:27:57PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][650/703]	Step 650	lr 0.025	Loss 59.0581 (61.7884)	Hard Loss 3.8242 (4.0045)	Soft Loss 0.0029 (0.0036)	Prec@(1,5) (8.7%, 26.7%)	
07/26 04:28:06PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][700/703]	Step 700	lr 0.025	Loss 56.6630 (61.2970)	Hard Loss 3.6720 (3.9725)	Soft Loss 0.0030 (0.0036)	Prec@(1,5) (9.1%, 27.6%)	
07/26 04:28:06PM evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [0][703/703]	Step 703	lr 0.025	Loss 52.6879 (61.2602)	Hard Loss 3.4089 (3.9701)	Soft Loss 0.0032 (0.0036)	Prec@(1,5) (9.1%, 27.7%)	
07/26 04:28:07PM evaluateCell_KD_trainer.py:194 [INFO] Train: [  0/99] Final Prec@1 9.1378%
07/26 04:28:10PM evaluateCell_KD_trainer.py:229 [INFO] Valid: [  0/99] Final Prec@1 13.1200%
07/26 04:28:10午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 13.1200%
07/26 04:28:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][50/703]	Step 754	lr 0.02499	Loss 49.4058 (53.3570)	Hard Loss 3.1915 (3.4544)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (16.8%, 43.1%)	
07/26 04:28:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][100/703]	Step 804	lr 0.02499	Loss 54.2273 (53.0327)	Hard Loss 3.5153 (3.4335)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (17.1%, 43.9%)	
07/26 04:28:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][150/703]	Step 854	lr 0.02499	Loss 51.9351 (52.9099)	Hard Loss 3.3595 (3.4256)	Soft Loss 0.0035 (0.0033)	Prec@(1,5) (17.4%, 44.1%)	
07/26 04:28:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][200/703]	Step 904	lr 0.02499	Loss 53.5527 (52.7073)	Hard Loss 3.4714 (3.4124)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (17.9%, 44.4%)	
07/26 04:28:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][250/703]	Step 954	lr 0.02499	Loss 55.6850 (52.3979)	Hard Loss 3.6122 (3.3923)	Soft Loss 0.0038 (0.0033)	Prec@(1,5) (18.0%, 44.9%)	
07/26 04:29:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][300/703]	Step 1004	lr 0.02499	Loss 55.8055 (52.0573)	Hard Loss 3.6194 (3.3699)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (18.3%, 45.5%)	
07/26 04:29:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][350/703]	Step 1054	lr 0.02499	Loss 52.1312 (51.8341)	Hard Loss 3.3746 (3.3552)	Soft Loss 0.0037 (0.0033)	Prec@(1,5) (18.4%, 46.0%)	
07/26 04:29:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][400/703]	Step 1104	lr 0.02499	Loss 45.4894 (51.4967)	Hard Loss 2.9360 (3.3331)	Soft Loss 0.0029 (0.0033)	Prec@(1,5) (18.8%, 46.6%)	
07/26 04:29:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][450/703]	Step 1154	lr 0.02499	Loss 46.8281 (51.2595)	Hard Loss 3.0277 (3.3176)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (19.1%, 47.1%)	
07/26 04:29:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][500/703]	Step 1204	lr 0.02499	Loss 49.6075 (50.9724)	Hard Loss 3.2067 (3.2987)	Soft Loss 0.0030 (0.0033)	Prec@(1,5) (19.4%, 47.6%)	
07/26 04:29:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][550/703]	Step 1254	lr 0.02499	Loss 46.8844 (50.7395)	Hard Loss 3.0333 (3.2836)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (19.6%, 47.9%)	
07/26 04:30:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][600/703]	Step 1304	lr 0.02499	Loss 43.9417 (50.5137)	Hard Loss 2.8405 (3.2687)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (19.9%, 48.4%)	
07/26 04:30:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][650/703]	Step 1354	lr 0.02499	Loss 43.2582 (50.2535)	Hard Loss 2.7944 (3.2517)	Soft Loss 0.0028 (0.0033)	Prec@(1,5) (20.1%, 48.8%)	
07/26 04:30:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][700/703]	Step 1404	lr 0.02499	Loss 45.4227 (49.9972)	Hard Loss 2.9331 (3.2349)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (20.5%, 49.2%)	
07/26 04:30:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [1][703/703]	Step 1407	lr 0.02499	Loss 47.7141 (49.9958)	Hard Loss 3.0820 (3.2348)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (20.5%, 49.2%)	
07/26 04:30:21午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  1/99] Final Prec@1 20.4733%
07/26 04:30:25午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  1/99] Final Prec@1 23.1800%
07/26 04:30:25午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 23.1800%
07/26 04:30:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][50/703]	Step 1458	lr 0.02498	Loss 47.1705 (45.7891)	Hard Loss 3.0520 (2.9585)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (25.9%, 55.8%)	
07/26 04:30:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][100/703]	Step 1508	lr 0.02498	Loss 49.1712 (45.5991)	Hard Loss 3.1803 (2.9463)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (25.9%, 56.9%)	
07/26 04:30:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][150/703]	Step 1558	lr 0.02498	Loss 48.5968 (45.5894)	Hard Loss 3.1427 (2.9455)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (25.8%, 56.9%)	
07/26 04:31:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][200/703]	Step 1608	lr 0.02498	Loss 48.3427 (45.5464)	Hard Loss 3.1245 (2.9428)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (26.1%, 56.8%)	
07/26 04:31:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][250/703]	Step 1658	lr 0.02498	Loss 53.1513 (45.1240)	Hard Loss 3.4398 (2.9152)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (26.6%, 57.5%)	
07/26 04:31:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][300/703]	Step 1708	lr 0.02498	Loss 40.2338 (44.9447)	Hard Loss 2.5912 (2.9036)	Soft Loss 0.0028 (0.0031)	Prec@(1,5) (26.8%, 57.8%)	
07/26 04:31:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][350/703]	Step 1758	lr 0.02498	Loss 44.6464 (44.6657)	Hard Loss 2.8841 (2.8853)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (27.2%, 58.3%)	
07/26 04:31:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][400/703]	Step 1808	lr 0.02498	Loss 38.5349 (44.4807)	Hard Loss 2.4865 (2.8732)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (27.5%, 58.6%)	
07/26 04:31:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][450/703]	Step 1858	lr 0.02498	Loss 31.9832 (44.3744)	Hard Loss 2.0526 (2.8663)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (27.7%, 58.7%)	
07/26 04:31:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][500/703]	Step 1908	lr 0.02498	Loss 45.0913 (44.2556)	Hard Loss 2.9132 (2.8585)	Soft Loss 0.0036 (0.0031)	Prec@(1,5) (27.9%, 59.0%)	
07/26 04:32:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][550/703]	Step 1958	lr 0.02498	Loss 39.7243 (44.1372)	Hard Loss 2.5624 (2.8508)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (28.1%, 59.2%)	
07/26 04:32:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][600/703]	Step 2008	lr 0.02498	Loss 39.5461 (44.0216)	Hard Loss 2.5508 (2.8433)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (28.3%, 59.4%)	
07/26 04:32:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][650/703]	Step 2058	lr 0.02498	Loss 40.2724 (43.8921)	Hard Loss 2.5974 (2.8348)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (28.5%, 59.6%)	
07/26 04:32:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][700/703]	Step 2108	lr 0.02498	Loss 40.9057 (43.7656)	Hard Loss 2.6414 (2.8266)	Soft Loss 0.0028 (0.0031)	Prec@(1,5) (28.6%, 59.9%)	
07/26 04:32:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [2][703/703]	Step 2111	lr 0.02498	Loss 37.4020 (43.7547)	Hard Loss 2.4084 (2.8259)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (28.6%, 59.9%)	
07/26 04:32:37午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  2/99] Final Prec@1 28.6178%
07/26 04:32:40午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  2/99] Final Prec@1 29.5800%
07/26 04:32:40午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 29.5800%
07/26 04:32:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][50/703]	Step 2162	lr 0.02495	Loss 42.9545 (41.0259)	Hard Loss 2.7703 (2.6470)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (31.6%, 64.0%)	
07/26 04:32:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][100/703]	Step 2212	lr 0.02495	Loss 39.3447 (40.9936)	Hard Loss 2.5363 (2.6454)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (31.7%, 64.0%)	
07/26 04:33:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][150/703]	Step 2262	lr 0.02495	Loss 39.1178 (40.3983)	Hard Loss 2.5182 (2.6064)	Soft Loss 0.0027 (0.0030)	Prec@(1,5) (32.6%, 64.9%)	
07/26 04:33:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][200/703]	Step 2312	lr 0.02495	Loss 42.7973 (40.4466)	Hard Loss 2.7658 (2.6097)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (32.5%, 64.8%)	
07/26 04:33:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][250/703]	Step 2362	lr 0.02495	Loss 40.0098 (40.3711)	Hard Loss 2.5720 (2.6047)	Soft Loss 0.0026 (0.0030)	Prec@(1,5) (32.8%, 64.9%)	
07/26 04:33:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][300/703]	Step 2412	lr 0.02495	Loss 40.0393 (40.2893)	Hard Loss 2.5799 (2.5993)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (32.8%, 65.1%)	
07/26 04:34:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][350/703]	Step 2462	lr 0.02495	Loss 32.5233 (40.1130)	Hard Loss 2.0872 (2.5877)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (33.1%, 65.4%)	
07/26 04:34:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][400/703]	Step 2512	lr 0.02495	Loss 38.5044 (40.0068)	Hard Loss 2.4830 (2.5808)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (33.2%, 65.5%)	
07/26 04:34:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][450/703]	Step 2562	lr 0.02495	Loss 33.3984 (39.9113)	Hard Loss 2.1513 (2.5746)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (33.3%, 65.6%)	
07/26 04:34:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][500/703]	Step 2612	lr 0.02495	Loss 38.3806 (39.8944)	Hard Loss 2.4712 (2.5736)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (33.3%, 65.7%)	
07/26 04:34:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][550/703]	Step 2662	lr 0.02495	Loss 38.8119 (39.7686)	Hard Loss 2.5043 (2.5654)	Soft Loss 0.0027 (0.0030)	Prec@(1,5) (33.5%, 65.8%)	
07/26 04:34:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][600/703]	Step 2712	lr 0.02495	Loss 33.7226 (39.7062)	Hard Loss 2.1714 (2.5613)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (33.5%, 65.9%)	
07/26 04:35:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][650/703]	Step 2762	lr 0.02495	Loss 35.6710 (39.6319)	Hard Loss 2.3000 (2.5565)	Soft Loss 0.0034 (0.0030)	Prec@(1,5) (33.7%, 66.0%)	
07/26 04:35:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][700/703]	Step 2812	lr 0.02495	Loss 39.6521 (39.4138)	Hard Loss 2.5580 (2.5422)	Soft Loss 0.0027 (0.0029)	Prec@(1,5) (34.1%, 66.2%)	
07/26 04:35:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [3][703/703]	Step 2815	lr 0.02495	Loss 39.2396 (39.4064)	Hard Loss 2.5350 (2.5417)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (34.1%, 66.2%)	
07/26 04:35:12午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  3/99] Final Prec@1 34.1000%
07/26 04:35:16午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  3/99] Final Prec@1 33.7400%
07/26 04:35:16午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 33.7400%
07/26 04:35:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][50/703]	Step 2866	lr 0.02491	Loss 41.8907 (36.3388)	Hard Loss 2.7051 (2.3397)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (38.0%, 70.2%)	
07/26 04:35:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][100/703]	Step 2916	lr 0.02491	Loss 43.5015 (36.6129)	Hard Loss 2.8098 (2.3586)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (37.6%, 69.9%)	
07/26 04:35:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][150/703]	Step 2966	lr 0.02491	Loss 34.5837 (36.4879)	Hard Loss 2.2235 (2.3504)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (37.9%, 70.1%)	
07/26 04:35:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][200/703]	Step 3016	lr 0.02491	Loss 33.9110 (36.4287)	Hard Loss 2.1847 (2.3468)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (38.1%, 70.2%)	
07/26 04:36:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][250/703]	Step 3066	lr 0.02491	Loss 36.2168 (36.4756)	Hard Loss 2.3300 (2.3498)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (37.9%, 70.2%)	
07/26 04:36:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][300/703]	Step 3116	lr 0.02491	Loss 34.9154 (36.4776)	Hard Loss 2.2490 (2.3501)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (38.0%, 70.3%)	
07/26 04:36:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][350/703]	Step 3166	lr 0.02491	Loss 33.9660 (36.4286)	Hard Loss 2.1852 (2.3468)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (38.0%, 70.4%)	
07/26 04:36:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][400/703]	Step 3216	lr 0.02491	Loss 41.8197 (36.3768)	Hard Loss 2.6988 (2.3434)	Soft Loss 0.0027 (0.0029)	Prec@(1,5) (38.2%, 70.5%)	
07/26 04:36:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][450/703]	Step 3266	lr 0.02491	Loss 36.3866 (36.4076)	Hard Loss 2.3439 (2.3456)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (38.1%, 70.4%)	
07/26 04:36:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][500/703]	Step 3316	lr 0.02491	Loss 34.4493 (36.4397)	Hard Loss 2.2159 (2.3477)	Soft Loss 0.0024 (0.0029)	Prec@(1,5) (38.1%, 70.4%)	
07/26 04:37:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][550/703]	Step 3366	lr 0.02491	Loss 36.6797 (36.4026)	Hard Loss 2.3647 (2.3453)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (38.2%, 70.4%)	
07/26 04:37:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][600/703]	Step 3416	lr 0.02491	Loss 34.9082 (36.3441)	Hard Loss 2.2448 (2.3416)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (38.3%, 70.5%)	
07/26 04:37:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][650/703]	Step 3466	lr 0.02491	Loss 30.3109 (36.2299)	Hard Loss 1.9454 (2.3342)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (38.5%, 70.7%)	
07/26 04:37:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][700/703]	Step 3516	lr 0.02491	Loss 40.6686 (36.1800)	Hard Loss 2.6296 (2.3309)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (38.6%, 70.7%)	
07/26 04:37:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [4][703/703]	Step 3519	lr 0.02491	Loss 35.7811 (36.1795)	Hard Loss 2.3065 (2.3309)	Soft Loss 0.0025 (0.0029)	Prec@(1,5) (38.6%, 70.7%)	
07/26 04:37:29午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  4/99] Final Prec@1 38.6333%
07/26 04:37:32午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  4/99] Final Prec@1 38.2200%
07/26 04:37:32午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 38.2200%
07/26 04:37:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][50/703]	Step 3570	lr 0.02485	Loss 41.5283 (33.8869)	Hard Loss 2.6782 (2.1805)	Soft Loss 0.0034 (0.0029)	Prec@(1,5) (41.3%, 74.4%)	
07/26 04:37:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][100/703]	Step 3620	lr 0.02485	Loss 38.9021 (34.4620)	Hard Loss 2.5058 (2.2182)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (40.9%, 73.2%)	
07/26 04:38:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][150/703]	Step 3670	lr 0.02485	Loss 34.4885 (34.2764)	Hard Loss 2.2194 (2.2063)	Soft Loss 0.0034 (0.0028)	Prec@(1,5) (41.5%, 73.1%)	
07/26 04:38:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][200/703]	Step 3720	lr 0.02485	Loss 36.4525 (34.3159)	Hard Loss 2.3495 (2.2090)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (41.3%, 73.3%)	
07/26 04:38:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][250/703]	Step 3770	lr 0.02485	Loss 35.8562 (34.2828)	Hard Loss 2.3090 (2.2069)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (41.1%, 73.4%)	
07/26 04:38:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][300/703]	Step 3820	lr 0.02485	Loss 32.7711 (34.1684)	Hard Loss 2.1033 (2.1995)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (41.1%, 73.7%)	
07/26 04:38:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][350/703]	Step 3870	lr 0.02485	Loss 35.6538 (34.0801)	Hard Loss 2.2984 (2.1938)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (41.3%, 73.7%)	
07/26 04:38:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][400/703]	Step 3920	lr 0.02485	Loss 30.0617 (34.1365)	Hard Loss 1.9272 (2.1975)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (41.3%, 73.8%)	
07/26 04:38:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][450/703]	Step 3970	lr 0.02485	Loss 26.9788 (34.0074)	Hard Loss 1.7277 (2.1890)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (41.6%, 74.0%)	
07/26 04:39:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][500/703]	Step 4020	lr 0.02485	Loss 31.3230 (33.9471)	Hard Loss 2.0087 (2.1851)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (41.6%, 74.1%)	
07/26 04:39:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][550/703]	Step 4070	lr 0.02485	Loss 29.6488 (33.9357)	Hard Loss 1.9081 (2.1845)	Soft Loss 0.0023 (0.0028)	Prec@(1,5) (41.6%, 74.1%)	
07/26 04:39:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][600/703]	Step 4120	lr 0.02485	Loss 39.1139 (33.8542)	Hard Loss 2.5258 (2.1791)	Soft Loss 0.0025 (0.0028)	Prec@(1,5) (41.7%, 74.2%)	
07/26 04:39:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][650/703]	Step 4170	lr 0.02485	Loss 35.5669 (33.7739)	Hard Loss 2.2912 (2.1739)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (41.7%, 74.3%)	
07/26 04:39:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][700/703]	Step 4220	lr 0.02485	Loss 32.4220 (33.7256)	Hard Loss 2.0866 (2.1708)	Soft Loss 0.0032 (0.0028)	Prec@(1,5) (41.8%, 74.3%)	
07/26 04:39:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [5][703/703]	Step 4223	lr 0.02485	Loss 32.3308 (33.7342)	Hard Loss 2.0834 (2.1714)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (41.8%, 74.3%)	
07/26 04:39:45午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  5/99] Final Prec@1 41.8200%
07/26 04:39:48午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  5/99] Final Prec@1 40.6800%
07/26 04:39:48午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 40.6800%
07/26 04:39:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][50/703]	Step 4274	lr 0.02479	Loss 30.9485 (31.0735)	Hard Loss 1.9894 (1.9966)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (46.2%, 77.6%)	
07/26 04:40:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][100/703]	Step 4324	lr 0.02479	Loss 34.6567 (31.4332)	Hard Loss 2.2365 (2.0205)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (45.6%, 76.7%)	
07/26 04:40:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][150/703]	Step 4374	lr 0.02479	Loss 35.2148 (31.5602)	Hard Loss 2.2705 (2.0290)	Soft Loss 0.0024 (0.0028)	Prec@(1,5) (45.5%, 76.5%)	
07/26 04:40:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][200/703]	Step 4424	lr 0.02479	Loss 30.7141 (31.7274)	Hard Loss 1.9702 (2.0400)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (45.2%, 76.6%)	
07/26 04:40:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][250/703]	Step 4474	lr 0.02479	Loss 27.3384 (31.7188)	Hard Loss 1.7517 (2.0395)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (45.1%, 76.7%)	
07/26 04:40:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][300/703]	Step 4524	lr 0.02479	Loss 28.0373 (31.7721)	Hard Loss 1.8017 (2.0431)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (45.1%, 76.6%)	
07/26 04:40:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][350/703]	Step 4574	lr 0.02479	Loss 32.4527 (31.9329)	Hard Loss 2.0885 (2.0537)	Soft Loss 0.0031 (0.0027)	Prec@(1,5) (44.9%, 76.4%)	
07/26 04:41:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][400/703]	Step 4624	lr 0.02479	Loss 33.3738 (31.9332)	Hard Loss 2.1433 (2.0537)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (44.9%, 76.4%)	
07/26 04:41:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][450/703]	Step 4674	lr 0.02479	Loss 27.2924 (31.8787)	Hard Loss 1.7505 (2.0502)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (44.9%, 76.5%)	
07/26 04:41:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][500/703]	Step 4724	lr 0.02479	Loss 36.2656 (31.9236)	Hard Loss 2.3328 (2.0532)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (44.8%, 76.4%)	
07/26 04:41:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][550/703]	Step 4774	lr 0.02479	Loss 29.9333 (31.8674)	Hard Loss 1.9223 (2.0495)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (44.9%, 76.5%)	
07/26 04:41:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][600/703]	Step 4824	lr 0.02479	Loss 28.6576 (31.7673)	Hard Loss 1.8430 (2.0431)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (44.9%, 76.6%)	
07/26 04:41:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][650/703]	Step 4874	lr 0.02479	Loss 31.9638 (31.7451)	Hard Loss 2.0557 (2.0417)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (45.0%, 76.6%)	
07/26 04:42:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][700/703]	Step 4924	lr 0.02479	Loss 29.6940 (31.7197)	Hard Loss 1.9091 (2.0401)	Soft Loss 0.0031 (0.0027)	Prec@(1,5) (45.1%, 76.7%)	
07/26 04:42:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [6][703/703]	Step 4927	lr 0.02479	Loss 32.0741 (31.7273)	Hard Loss 2.0697 (2.0406)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (45.1%, 76.7%)	
07/26 04:42:01午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  6/99] Final Prec@1 45.0778%
07/26 04:42:05午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  6/99] Final Prec@1 43.0400%
07/26 04:42:05午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 43.0400%
07/26 04:42:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][50/703]	Step 4978	lr 0.02471	Loss 27.8655 (30.3094)	Hard Loss 1.7902 (1.9486)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (46.8%, 78.2%)	
07/26 04:42:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][100/703]	Step 5028	lr 0.02471	Loss 28.8749 (29.8127)	Hard Loss 1.8538 (1.9154)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (47.8%, 79.0%)	
07/26 04:42:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][150/703]	Step 5078	lr 0.02471	Loss 32.5375 (29.9580)	Hard Loss 2.0928 (1.9248)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (47.4%, 78.6%)	
07/26 04:42:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][200/703]	Step 5128	lr 0.02471	Loss 28.8407 (29.9725)	Hard Loss 1.8508 (1.9258)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (47.4%, 78.7%)	
07/26 04:42:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][250/703]	Step 5178	lr 0.02471	Loss 29.2598 (29.8731)	Hard Loss 1.8808 (1.9193)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (47.6%, 78.8%)	
07/26 04:43:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][300/703]	Step 5228	lr 0.02471	Loss 29.7714 (29.9423)	Hard Loss 1.9109 (1.9238)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (47.6%, 78.7%)	
07/26 04:43:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][350/703]	Step 5278	lr 0.02471	Loss 33.2618 (29.8994)	Hard Loss 2.1438 (1.9211)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (47.7%, 78.9%)	
07/26 04:43:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][400/703]	Step 5328	lr 0.02471	Loss 30.1084 (29.9506)	Hard Loss 1.9317 (1.9245)	Soft Loss 0.0024 (0.0027)	Prec@(1,5) (47.5%, 78.9%)	
07/26 04:43:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][450/703]	Step 5378	lr 0.02471	Loss 34.6130 (29.9813)	Hard Loss 2.2381 (1.9266)	Soft Loss 0.0031 (0.0027)	Prec@(1,5) (47.6%, 78.8%)	
07/26 04:43:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][500/703]	Step 5428	lr 0.02471	Loss 28.6004 (29.9590)	Hard Loss 1.8407 (1.9251)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (47.6%, 78.8%)	
07/26 04:43:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][550/703]	Step 5478	lr 0.02471	Loss 29.2381 (30.0038)	Hard Loss 1.8778 (1.9281)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (47.5%, 78.7%)	
07/26 04:43:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][600/703]	Step 5528	lr 0.02471	Loss 25.3708 (29.9937)	Hard Loss 1.6171 (1.9275)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (47.5%, 78.8%)	
07/26 04:44:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][650/703]	Step 5578	lr 0.02471	Loss 26.3061 (30.0441)	Hard Loss 1.6868 (1.9308)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (47.4%, 78.7%)	
07/26 04:44:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][700/703]	Step 5628	lr 0.02471	Loss 32.7886 (30.0444)	Hard Loss 2.1189 (1.9309)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (47.4%, 78.7%)	
07/26 04:44:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [7][703/703]	Step 5631	lr 0.02471	Loss 25.1879 (30.0292)	Hard Loss 1.6129 (1.9299)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (47.4%, 78.7%)	
07/26 04:44:17午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  7/99] Final Prec@1 47.4222%
07/26 04:44:21午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  7/99] Final Prec@1 44.4400%
07/26 04:44:21午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 44.4400%
07/26 04:44:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][50/703]	Step 5682	lr 0.02462	Loss 27.0396 (28.8741)	Hard Loss 1.7331 (1.8532)	Soft Loss 0.0024 (0.0027)	Prec@(1,5) (49.1%, 80.8%)	
07/26 04:44:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][100/703]	Step 5732	lr 0.02462	Loss 28.9041 (28.3154)	Hard Loss 1.8570 (1.8164)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (50.0%, 81.1%)	
07/26 04:44:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][150/703]	Step 5782	lr 0.02462	Loss 28.1161 (28.5375)	Hard Loss 1.8077 (1.8319)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (49.7%, 80.6%)	
07/26 04:44:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][200/703]	Step 5832	lr 0.02462	Loss 32.5089 (28.5080)	Hard Loss 2.0971 (1.8301)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (49.9%, 80.8%)	
07/26 04:45:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][250/703]	Step 5882	lr 0.02462	Loss 25.1256 (28.4749)	Hard Loss 1.6081 (1.8279)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (49.9%, 80.7%)	
07/26 04:45:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][300/703]	Step 5932	lr 0.02462	Loss 29.9805 (28.5380)	Hard Loss 1.9343 (1.8321)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (49.9%, 80.4%)	
07/26 04:45:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][350/703]	Step 5982	lr 0.02462	Loss 30.1790 (28.6815)	Hard Loss 1.9415 (1.8415)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (49.8%, 80.2%)	
07/26 04:45:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][400/703]	Step 6032	lr 0.02462	Loss 23.8816 (28.6137)	Hard Loss 1.5254 (1.8372)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (49.8%, 80.3%)	
07/26 04:45:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][450/703]	Step 6082	lr 0.02462	Loss 29.5128 (28.6624)	Hard Loss 1.8963 (1.8405)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (49.7%, 80.2%)	
07/26 04:45:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][500/703]	Step 6132	lr 0.02462	Loss 29.8510 (28.5570)	Hard Loss 1.9174 (1.8336)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (49.8%, 80.3%)	
07/26 04:46:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][550/703]	Step 6182	lr 0.02462	Loss 31.8753 (28.6049)	Hard Loss 2.0549 (1.8369)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (49.8%, 80.3%)	
07/26 04:46:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][600/703]	Step 6232	lr 0.02462	Loss 30.3279 (28.6329)	Hard Loss 1.9464 (1.8388)	Soft Loss 0.0031 (0.0027)	Prec@(1,5) (49.7%, 80.3%)	
07/26 04:46:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][650/703]	Step 6282	lr 0.02462	Loss 28.8798 (28.6555)	Hard Loss 1.8591 (1.8404)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (49.7%, 80.3%)	
07/26 04:46:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][700/703]	Step 6332	lr 0.02462	Loss 27.7279 (28.6944)	Hard Loss 1.7823 (1.8430)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (49.6%, 80.2%)	
07/26 04:46:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [8][703/703]	Step 6335	lr 0.02462	Loss 28.3070 (28.6912)	Hard Loss 1.8159 (1.8427)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (49.6%, 80.2%)	
07/26 04:46:34午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  8/99] Final Prec@1 49.6311%
07/26 04:46:37午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  8/99] Final Prec@1 44.6200%
07/26 04:46:37午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 44.6200%
07/26 04:46:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][50/703]	Step 6386	lr 0.02452	Loss 22.4179 (26.6243)	Hard Loss 1.4258 (1.7061)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (53.4%, 82.8%)	
07/26 04:46:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][100/703]	Step 6436	lr 0.02452	Loss 28.2174 (27.0007)	Hard Loss 1.8097 (1.7313)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (52.4%, 82.9%)	
07/26 04:47:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][150/703]	Step 6486	lr 0.02452	Loss 20.9532 (26.8651)	Hard Loss 1.3292 (1.7227)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (52.3%, 82.8%)	
07/26 04:47:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][200/703]	Step 6536	lr 0.02452	Loss 27.3892 (26.9700)	Hard Loss 1.7581 (1.7296)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (52.2%, 82.7%)	
07/26 04:47:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][250/703]	Step 6586	lr 0.02452	Loss 29.0215 (27.1831)	Hard Loss 1.8669 (1.7436)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (51.7%, 82.3%)	
07/26 04:47:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][300/703]	Step 6636	lr 0.02452	Loss 31.3352 (27.2158)	Hard Loss 2.0159 (1.7458)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (51.7%, 82.3%)	
07/26 04:47:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][350/703]	Step 6686	lr 0.02452	Loss 24.8263 (27.3080)	Hard Loss 1.5897 (1.7519)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (51.6%, 82.2%)	
07/26 04:47:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][400/703]	Step 6736	lr 0.02452	Loss 24.7347 (27.4405)	Hard Loss 1.5880 (1.7607)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (51.4%, 81.9%)	
07/26 04:48:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][450/703]	Step 6786	lr 0.02452	Loss 24.9665 (27.4159)	Hard Loss 1.5972 (1.7590)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (51.5%, 81.9%)	
07/26 04:48:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][500/703]	Step 6836	lr 0.02452	Loss 24.3139 (27.3232)	Hard Loss 1.5604 (1.7530)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (51.7%, 82.1%)	
07/26 04:48:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][550/703]	Step 6886	lr 0.02452	Loss 32.1164 (27.3122)	Hard Loss 2.0665 (1.7524)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (51.8%, 82.0%)	
07/26 04:48:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][600/703]	Step 6936	lr 0.02452	Loss 30.8350 (27.3937)	Hard Loss 1.9866 (1.7578)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (51.7%, 81.9%)	
07/26 04:48:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][650/703]	Step 6986	lr 0.02452	Loss 22.6923 (27.4086)	Hard Loss 1.4484 (1.7588)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (51.6%, 81.8%)	
07/26 04:48:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][700/703]	Step 7036	lr 0.02452	Loss 28.5006 (27.4168)	Hard Loss 1.8302 (1.7594)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (51.6%, 81.9%)	
07/26 04:48:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [9][703/703]	Step 7039	lr 0.02452	Loss 30.3387 (27.4225)	Hard Loss 1.9533 (1.7598)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (51.6%, 81.8%)	
07/26 04:48:50午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [  9/99] Final Prec@1 51.5778%
07/26 04:48:53午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [  9/99] Final Prec@1 47.0600%
07/26 04:48:53午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 47.0600%
07/26 04:49:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][50/703]	Step 7090	lr 0.02441	Loss 26.8561 (25.2579)	Hard Loss 1.7194 (1.6174)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (55.2%, 83.8%)	
07/26 04:49:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][100/703]	Step 7140	lr 0.02441	Loss 27.0020 (25.4226)	Hard Loss 1.7281 (1.6284)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (54.8%, 83.8%)	
07/26 04:49:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][150/703]	Step 7190	lr 0.02441	Loss 25.9752 (25.7058)	Hard Loss 1.6649 (1.6470)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (54.0%, 83.6%)	
07/26 04:49:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][200/703]	Step 7240	lr 0.02441	Loss 24.6679 (25.8580)	Hard Loss 1.5777 (1.6572)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (53.9%, 83.3%)	
07/26 04:49:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][250/703]	Step 7290	lr 0.02441	Loss 25.9036 (26.1326)	Hard Loss 1.6582 (1.6754)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (53.5%, 82.8%)	
07/26 04:49:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][300/703]	Step 7340	lr 0.02441	Loss 25.8360 (26.1530)	Hard Loss 1.6537 (1.6767)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (53.6%, 82.9%)	
07/26 04:50:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][350/703]	Step 7390	lr 0.02441	Loss 22.6764 (26.1974)	Hard Loss 1.4499 (1.6796)	Soft Loss 0.0030 (0.0026)	Prec@(1,5) (53.6%, 82.8%)	
07/26 04:50:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][400/703]	Step 7440	lr 0.02441	Loss 32.9462 (26.2990)	Hard Loss 2.1233 (1.6864)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (53.3%, 82.8%)	
07/26 04:50:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][450/703]	Step 7490	lr 0.02441	Loss 24.5515 (26.2421)	Hard Loss 1.5730 (1.6826)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (53.5%, 82.8%)	
07/26 04:50:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][500/703]	Step 7540	lr 0.02441	Loss 33.5075 (26.2412)	Hard Loss 2.1633 (1.6826)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (53.6%, 82.8%)	
07/26 04:50:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][550/703]	Step 7590	lr 0.02441	Loss 27.1488 (26.3057)	Hard Loss 1.7409 (1.6868)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (53.5%, 82.8%)	
07/26 04:50:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][600/703]	Step 7640	lr 0.02441	Loss 25.3947 (26.4094)	Hard Loss 1.6218 (1.6936)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (53.3%, 82.7%)	
07/26 04:50:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][650/703]	Step 7690	lr 0.02441	Loss 27.4954 (26.4880)	Hard Loss 1.7642 (1.6988)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (53.1%, 82.6%)	
07/26 04:51:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][700/703]	Step 7740	lr 0.02441	Loss 30.6533 (26.4959)	Hard Loss 1.9713 (1.6994)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (53.1%, 82.6%)	
07/26 04:51:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [10][703/703]	Step 7743	lr 0.02441	Loss 29.9397 (26.5033)	Hard Loss 1.9248 (1.6999)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (53.1%, 82.6%)	
07/26 04:51:06午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 10/99] Final Prec@1 53.0778%
07/26 04:51:09午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 10/99] Final Prec@1 47.4000%
07/26 04:51:10午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 47.4000%
07/26 04:51:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][50/703]	Step 7794	lr 0.02429	Loss 28.5183 (24.9356)	Hard Loss 1.8315 (1.5970)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (55.0%, 84.2%)	
07/26 04:51:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][100/703]	Step 7844	lr 0.02429	Loss 21.4191 (25.0680)	Hard Loss 1.3657 (1.6052)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (55.1%, 84.6%)	
07/26 04:51:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][150/703]	Step 7894	lr 0.02429	Loss 21.2507 (25.2429)	Hard Loss 1.3525 (1.6165)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (54.8%, 84.7%)	
07/26 04:51:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][200/703]	Step 7944	lr 0.02429	Loss 26.2467 (25.2518)	Hard Loss 1.6726 (1.6171)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (54.9%, 84.5%)	
07/26 04:51:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][250/703]	Step 7994	lr 0.02429	Loss 25.0818 (25.2170)	Hard Loss 1.6029 (1.6149)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (54.8%, 84.5%)	
07/26 04:52:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][300/703]	Step 8044	lr 0.02429	Loss 23.8785 (25.1460)	Hard Loss 1.5279 (1.6105)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (54.9%, 84.6%)	
07/26 04:52:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][350/703]	Step 8094	lr 0.02429	Loss 24.9145 (25.1593)	Hard Loss 1.5959 (1.6114)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (55.0%, 84.4%)	
07/26 04:52:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][400/703]	Step 8144	lr 0.02429	Loss 29.7509 (25.1473)	Hard Loss 1.9121 (1.6107)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (55.1%, 84.4%)	
07/26 04:52:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][450/703]	Step 8194	lr 0.02429	Loss 26.0039 (25.2404)	Hard Loss 1.6696 (1.6168)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (54.8%, 84.3%)	
07/26 04:52:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][500/703]	Step 8244	lr 0.02429	Loss 26.4817 (25.2584)	Hard Loss 1.6969 (1.6181)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (54.7%, 84.2%)	
07/26 04:52:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][550/703]	Step 8294	lr 0.02429	Loss 26.6007 (25.3142)	Hard Loss 1.7085 (1.6218)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (54.7%, 84.1%)	
07/26 04:53:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][600/703]	Step 8344	lr 0.02429	Loss 29.9397 (25.3647)	Hard Loss 1.9218 (1.6252)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (54.7%, 84.0%)	
07/26 04:53:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][650/703]	Step 8394	lr 0.02429	Loss 25.4835 (25.4268)	Hard Loss 1.6274 (1.6293)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (54.7%, 84.0%)	
07/26 04:53:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][700/703]	Step 8444	lr 0.02429	Loss 22.4382 (25.4563)	Hard Loss 1.4305 (1.6313)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (54.6%, 83.9%)	
07/26 04:53:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [11][703/703]	Step 8447	lr 0.02429	Loss 27.4910 (25.4612)	Hard Loss 1.7734 (1.6316)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (54.5%, 83.9%)	
07/26 04:53:22午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 11/99] Final Prec@1 54.5333%
07/26 04:53:26午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 11/99] Final Prec@1 49.4800%
07/26 04:53:26午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 49.4800%
07/26 04:53:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][50/703]	Step 8498	lr 0.02416	Loss 21.5298 (24.1613)	Hard Loss 1.3721 (1.5451)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (56.8%, 85.5%)	
07/26 04:53:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][100/703]	Step 8548	lr 0.02416	Loss 24.3059 (24.4324)	Hard Loss 1.5527 (1.5635)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (56.1%, 85.0%)	
07/26 04:53:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][150/703]	Step 8598	lr 0.02416	Loss 23.0838 (24.3716)	Hard Loss 1.4751 (1.5595)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (56.2%, 85.0%)	
07/26 04:54:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][200/703]	Step 8648	lr 0.02416	Loss 25.9079 (24.3835)	Hard Loss 1.6566 (1.5605)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (56.4%, 84.9%)	
07/26 04:54:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][250/703]	Step 8698	lr 0.02416	Loss 22.3007 (24.4295)	Hard Loss 1.4288 (1.5638)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (56.4%, 85.1%)	
07/26 04:54:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][300/703]	Step 8748	lr 0.02416	Loss 24.7202 (24.4500)	Hard Loss 1.5829 (1.5652)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (56.2%, 84.9%)	
07/26 04:54:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][350/703]	Step 8798	lr 0.02416	Loss 25.0012 (24.5216)	Hard Loss 1.5991 (1.5699)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (56.0%, 85.0%)	
07/26 04:54:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][400/703]	Step 8848	lr 0.02416	Loss 24.8689 (24.6052)	Hard Loss 1.5893 (1.5756)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (55.8%, 84.9%)	
07/26 04:54:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][450/703]	Step 8898	lr 0.02416	Loss 26.1720 (24.6782)	Hard Loss 1.6796 (1.5804)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (55.8%, 84.8%)	
07/26 04:55:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][500/703]	Step 8948	lr 0.02416	Loss 23.0759 (24.7051)	Hard Loss 1.4745 (1.5822)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (55.8%, 84.8%)	
07/26 04:55:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][550/703]	Step 8998	lr 0.02416	Loss 21.4364 (24.6941)	Hard Loss 1.3692 (1.5815)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (55.8%, 84.8%)	
07/26 04:55:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][600/703]	Step 9048	lr 0.02416	Loss 20.9095 (24.6651)	Hard Loss 1.3391 (1.5797)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (55.8%, 84.9%)	
07/26 04:55:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][650/703]	Step 9098	lr 0.02416	Loss 17.5637 (24.7086)	Hard Loss 1.1159 (1.5825)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (55.7%, 84.9%)	
07/26 04:55:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][700/703]	Step 9148	lr 0.02416	Loss 26.1179 (24.7423)	Hard Loss 1.6766 (1.5848)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (55.7%, 84.8%)	
07/26 04:55:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [12][703/703]	Step 9151	lr 0.02416	Loss 21.8551 (24.7357)	Hard Loss 1.3978 (1.5844)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (55.7%, 84.8%)	
07/26 04:55:38午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 12/99] Final Prec@1 55.7489%
07/26 04:55:42午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 12/99] Final Prec@1 47.8000%
07/26 04:55:42午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 49.4800%
07/26 04:55:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][50/703]	Step 9202	lr 0.02401	Loss 19.7193 (23.3598)	Hard Loss 1.2592 (1.4923)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (57.1%, 86.3%)	
07/26 04:56:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][100/703]	Step 9252	lr 0.02401	Loss 29.9598 (23.2869)	Hard Loss 1.9243 (1.4881)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (57.0%, 86.2%)	
07/26 04:56:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][150/703]	Step 9302	lr 0.02401	Loss 18.2577 (23.1821)	Hard Loss 1.1660 (1.4815)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (57.3%, 86.5%)	
07/26 04:56:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][200/703]	Step 9352	lr 0.02401	Loss 20.8682 (23.5075)	Hard Loss 1.3316 (1.5031)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (57.1%, 86.1%)	
07/26 04:56:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][250/703]	Step 9402	lr 0.02401	Loss 24.6336 (23.5357)	Hard Loss 1.5773 (1.5051)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (57.2%, 86.1%)	
07/26 04:56:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][300/703]	Step 9452	lr 0.02401	Loss 24.7042 (23.6722)	Hard Loss 1.5854 (1.5142)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (57.0%, 85.9%)	
07/26 04:56:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][350/703]	Step 9502	lr 0.02401	Loss 25.7988 (23.7778)	Hard Loss 1.6592 (1.5211)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (56.7%, 85.8%)	
07/26 04:56:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][400/703]	Step 9552	lr 0.02401	Loss 22.7028 (23.8049)	Hard Loss 1.4473 (1.5230)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (56.7%, 85.8%)	
07/26 04:57:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][450/703]	Step 9602	lr 0.02401	Loss 24.3535 (23.9404)	Hard Loss 1.5604 (1.5319)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (56.6%, 85.5%)	
07/26 04:57:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][500/703]	Step 9652	lr 0.02401	Loss 26.7799 (23.9836)	Hard Loss 1.7120 (1.5347)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (56.5%, 85.5%)	
07/26 04:57:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][550/703]	Step 9702	lr 0.02401	Loss 23.9445 (24.0039)	Hard Loss 1.5326 (1.5361)	Soft Loss 0.0030 (0.0026)	Prec@(1,5) (56.5%, 85.5%)	
07/26 04:57:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][600/703]	Step 9752	lr 0.02401	Loss 27.0402 (24.0305)	Hard Loss 1.7320 (1.5379)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (56.5%, 85.5%)	
07/26 04:57:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][650/703]	Step 9802	lr 0.02401	Loss 32.7782 (24.0811)	Hard Loss 2.1106 (1.5413)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (56.3%, 85.4%)	
07/26 04:57:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][700/703]	Step 9852	lr 0.02401	Loss 16.9377 (24.1204)	Hard Loss 1.0704 (1.5439)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (56.3%, 85.5%)	
07/26 04:57:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [13][703/703]	Step 9855	lr 0.02401	Loss 23.9590 (24.1278)	Hard Loss 1.5335 (1.5444)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (56.3%, 85.5%)	
07/26 04:57:54午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 13/99] Final Prec@1 56.3133%
07/26 04:57:58午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 13/99] Final Prec@1 50.9800%
07/26 04:57:58午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 50.9800%
07/26 04:58:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][50/703]	Step 9906	lr 0.02386	Loss 22.7084 (22.5732)	Hard Loss 1.4510 (1.4409)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (59.4%, 87.0%)	
07/26 04:58:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][100/703]	Step 9956	lr 0.02386	Loss 23.4032 (22.9431)	Hard Loss 1.4967 (1.4656)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (58.4%, 86.6%)	
07/26 04:58:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][150/703]	Step 10006	lr 0.02386	Loss 22.7398 (22.9251)	Hard Loss 1.4531 (1.4649)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (58.4%, 86.9%)	
07/26 04:58:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][200/703]	Step 10056	lr 0.02386	Loss 20.2842 (23.0544)	Hard Loss 1.2940 (1.4733)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (58.3%, 86.6%)	
07/26 04:58:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][250/703]	Step 10106	lr 0.02386	Loss 21.0341 (22.9525)	Hard Loss 1.3462 (1.4669)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (58.4%, 86.6%)	
07/26 04:58:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][300/703]	Step 10156	lr 0.02386	Loss 18.0133 (22.9348)	Hard Loss 1.1418 (1.4658)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (58.6%, 86.7%)	
07/26 04:59:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][350/703]	Step 10206	lr 0.02386	Loss 24.0218 (23.0035)	Hard Loss 1.5377 (1.4705)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (58.3%, 86.7%)	
07/26 04:59:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][400/703]	Step 10256	lr 0.02386	Loss 24.8086 (23.0793)	Hard Loss 1.5935 (1.4755)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (58.4%, 86.6%)	
07/26 04:59:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][450/703]	Step 10306	lr 0.02386	Loss 15.7824 (23.1087)	Hard Loss 0.9981 (1.4773)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (58.5%, 86.5%)	
07/26 04:59:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][500/703]	Step 10356	lr 0.02386	Loss 19.2111 (23.1815)	Hard Loss 1.2247 (1.4821)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (58.4%, 86.4%)	
07/26 04:59:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][550/703]	Step 10406	lr 0.02386	Loss 24.2686 (23.2289)	Hard Loss 1.5540 (1.4852)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (58.4%, 86.3%)	
07/26 04:59:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][600/703]	Step 10456	lr 0.02386	Loss 22.0064 (23.2268)	Hard Loss 1.4128 (1.4851)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (58.4%, 86.3%)	
07/26 05:00:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][650/703]	Step 10506	lr 0.02386	Loss 19.0156 (23.1786)	Hard Loss 1.2078 (1.4820)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (58.4%, 86.4%)	
07/26 05:00:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][700/703]	Step 10556	lr 0.02386	Loss 21.8432 (23.2443)	Hard Loss 1.3953 (1.4863)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (58.3%, 86.4%)	
07/26 05:00:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [14][703/703]	Step 10559	lr 0.02386	Loss 23.9783 (23.2480)	Hard Loss 1.5360 (1.4866)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (58.3%, 86.4%)	
07/26 05:00:11午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 14/99] Final Prec@1 58.2689%
07/26 05:00:14午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 14/99] Final Prec@1 51.2400%
07/26 05:00:14午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 51.2400%
07/26 05:00:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][50/703]	Step 10610	lr 0.02369	Loss 24.3689 (21.8009)	Hard Loss 1.5563 (1.3914)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (60.2%, 87.8%)	
07/26 05:00:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][100/703]	Step 10660	lr 0.02369	Loss 20.1913 (22.0077)	Hard Loss 1.2777 (1.4047)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (60.2%, 87.6%)	
07/26 05:00:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][150/703]	Step 10710	lr 0.02369	Loss 23.8600 (21.8855)	Hard Loss 1.5257 (1.3966)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (60.1%, 87.7%)	
07/26 05:00:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][200/703]	Step 10760	lr 0.02369	Loss 21.0024 (22.0193)	Hard Loss 1.3398 (1.4056)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (59.7%, 87.7%)	
07/26 05:01:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][250/703]	Step 10810	lr 0.02369	Loss 21.8420 (22.2744)	Hard Loss 1.3986 (1.4223)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (59.3%, 87.4%)	
07/26 05:01:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][300/703]	Step 10860	lr 0.02369	Loss 21.5170 (22.3368)	Hard Loss 1.3761 (1.4265)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (59.3%, 87.2%)	
07/26 05:01:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][350/703]	Step 10910	lr 0.02369	Loss 23.1587 (22.2747)	Hard Loss 1.4847 (1.4226)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (59.4%, 87.3%)	
07/26 05:01:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][400/703]	Step 10960	lr 0.02369	Loss 23.1290 (22.3515)	Hard Loss 1.4824 (1.4278)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (59.3%, 87.3%)	
07/26 05:01:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][450/703]	Step 11010	lr 0.02369	Loss 18.0059 (22.3502)	Hard Loss 1.1384 (1.4276)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (59.3%, 87.3%)	
07/26 05:01:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][500/703]	Step 11060	lr 0.02369	Loss 21.9720 (22.4474)	Hard Loss 1.4023 (1.4341)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (59.2%, 87.2%)	
07/26 05:01:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][550/703]	Step 11110	lr 0.02369	Loss 25.8308 (22.5184)	Hard Loss 1.6597 (1.4388)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (59.1%, 87.1%)	
07/26 05:02:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][600/703]	Step 11160	lr 0.02369	Loss 22.0349 (22.5428)	Hard Loss 1.4148 (1.4406)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (59.1%, 87.1%)	
07/26 05:03:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][650/703]	Step 11210	lr 0.02369	Loss 17.4945 (22.5740)	Hard Loss 1.1122 (1.4427)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (59.0%, 87.1%)	
07/26 05:03:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][700/703]	Step 11260	lr 0.02369	Loss 26.6336 (22.6336)	Hard Loss 1.7069 (1.4466)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (59.0%, 87.0%)	
07/26 05:03:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [15][703/703]	Step 11263	lr 0.02369	Loss 20.1092 (22.6306)	Hard Loss 1.2810 (1.4464)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (59.0%, 87.0%)	
07/26 05:03:30午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 15/99] Final Prec@1 58.9911%
07/26 05:03:33午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 15/99] Final Prec@1 52.5600%
07/26 05:03:34午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 52.5600%
07/26 05:03:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][50/703]	Step 11314	lr 0.02352	Loss 24.7107 (21.0090)	Hard Loss 1.5831 (1.3393)	Soft Loss 0.0030 (0.0025)	Prec@(1,5) (61.5%, 88.8%)	
07/26 05:03:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][100/703]	Step 11364	lr 0.02352	Loss 22.5119 (21.4547)	Hard Loss 1.4367 (1.3683)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (60.8%, 88.4%)	
07/26 05:04:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][150/703]	Step 11414	lr 0.02352	Loss 23.7776 (21.4180)	Hard Loss 1.5254 (1.3660)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (60.8%, 88.4%)	
07/26 05:04:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][200/703]	Step 11464	lr 0.02352	Loss 24.5847 (21.6522)	Hard Loss 1.5765 (1.3816)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (60.4%, 88.2%)	
07/26 05:04:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][250/703]	Step 11514	lr 0.02352	Loss 20.9186 (21.6492)	Hard Loss 1.3401 (1.3814)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (60.6%, 88.2%)	
07/26 05:04:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][300/703]	Step 11564	lr 0.02352	Loss 22.2600 (21.7652)	Hard Loss 1.4247 (1.3891)	Soft Loss 0.0030 (0.0025)	Prec@(1,5) (60.4%, 88.0%)	
07/26 05:04:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][350/703]	Step 11614	lr 0.02352	Loss 17.8166 (21.6799)	Hard Loss 1.1300 (1.3836)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (60.5%, 88.2%)	
07/26 05:04:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][400/703]	Step 11664	lr 0.02352	Loss 27.2171 (21.6708)	Hard Loss 1.7500 (1.3830)	Soft Loss 0.0030 (0.0026)	Prec@(1,5) (60.6%, 88.2%)	
07/26 05:04:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][450/703]	Step 11714	lr 0.02352	Loss 29.1210 (21.7182)	Hard Loss 1.8732 (1.3862)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (60.5%, 88.1%)	
07/26 05:05:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][500/703]	Step 11764	lr 0.02352	Loss 17.6325 (21.7981)	Hard Loss 1.1182 (1.3915)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (60.5%, 88.0%)	
07/26 05:05:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][550/703]	Step 11814	lr 0.02352	Loss 23.3713 (21.9208)	Hard Loss 1.4889 (1.3996)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (60.2%, 87.8%)	
07/26 05:05:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][600/703]	Step 11864	lr 0.02352	Loss 19.6339 (21.9900)	Hard Loss 1.2492 (1.4042)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (60.1%, 87.8%)	
07/26 05:05:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][650/703]	Step 11914	lr 0.02352	Loss 16.6013 (21.9839)	Hard Loss 1.0462 (1.4038)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (60.2%, 87.8%)	
07/26 05:05:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][700/703]	Step 11964	lr 0.02352	Loss 27.4819 (22.0618)	Hard Loss 1.7638 (1.4089)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (60.0%, 87.7%)	
07/26 05:05:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [16][703/703]	Step 11967	lr 0.02352	Loss 20.3237 (22.0533)	Hard Loss 1.2961 (1.4084)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (60.0%, 87.7%)	
07/26 05:05:47午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 16/99] Final Prec@1 60.0289%
07/26 05:05:50午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 16/99] Final Prec@1 51.1200%
07/26 05:05:51午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 52.5600%
07/26 05:06:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][50/703]	Step 12018	lr 0.02333	Loss 18.4971 (20.3635)	Hard Loss 1.1771 (1.2961)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.2%, 88.8%)	
07/26 05:06:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][100/703]	Step 12068	lr 0.02333	Loss 25.7958 (20.2811)	Hard Loss 1.6532 (1.2909)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.0%, 89.2%)	
07/26 05:06:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][150/703]	Step 12118	lr 0.02333	Loss 26.2834 (20.9114)	Hard Loss 1.6859 (1.3325)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (62.1%, 88.7%)	
07/26 05:06:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][200/703]	Step 12168	lr 0.02333	Loss 21.2543 (21.0388)	Hard Loss 1.3515 (1.3409)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (62.0%, 88.5%)	
07/26 05:06:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][250/703]	Step 12218	lr 0.02333	Loss 19.8599 (21.1147)	Hard Loss 1.2700 (1.3458)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (61.9%, 88.5%)	
07/26 05:06:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][300/703]	Step 12268	lr 0.02333	Loss 23.2238 (21.2021)	Hard Loss 1.4837 (1.3517)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (61.7%, 88.5%)	
07/26 05:06:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][350/703]	Step 12318	lr 0.02333	Loss 18.2645 (21.2386)	Hard Loss 1.1579 (1.3542)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (61.4%, 88.4%)	
07/26 05:07:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][400/703]	Step 12368	lr 0.02333	Loss 23.4012 (21.3201)	Hard Loss 1.4926 (1.3597)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (61.2%, 88.3%)	
07/26 05:07:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][450/703]	Step 12418	lr 0.02333	Loss 25.7022 (21.3811)	Hard Loss 1.6402 (1.3638)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (61.1%, 88.2%)	
07/26 05:07:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][500/703]	Step 12468	lr 0.02333	Loss 26.7685 (21.4022)	Hard Loss 1.7215 (1.3652)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (61.1%, 88.2%)	
07/26 05:07:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][550/703]	Step 12518	lr 0.02333	Loss 28.8127 (21.4706)	Hard Loss 1.8559 (1.3698)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (61.0%, 88.2%)	
07/26 05:07:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][600/703]	Step 12568	lr 0.02333	Loss 20.7795 (21.5037)	Hard Loss 1.3259 (1.3721)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (60.9%, 88.1%)	
07/26 05:07:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][650/703]	Step 12618	lr 0.02333	Loss 18.2842 (21.5711)	Hard Loss 1.1645 (1.3766)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (60.8%, 88.1%)	
07/26 05:08:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][700/703]	Step 12668	lr 0.02333	Loss 21.3318 (21.6047)	Hard Loss 1.3567 (1.3789)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (60.8%, 88.0%)	
07/26 05:08:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [17][703/703]	Step 12671	lr 0.02333	Loss 20.1709 (21.6074)	Hard Loss 1.2869 (1.3790)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (60.8%, 88.0%)	
07/26 05:08:03午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 17/99] Final Prec@1 60.7844%
07/26 05:08:06午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 17/99] Final Prec@1 54.1200%
07/26 05:08:07午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 54.1200%
07/26 05:08:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][50/703]	Step 12722	lr 0.02313	Loss 22.5536 (19.8824)	Hard Loss 1.4425 (1.2657)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (63.8%, 90.0%)	
07/26 05:08:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][100/703]	Step 12772	lr 0.02313	Loss 21.5941 (20.3935)	Hard Loss 1.3799 (1.2989)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (62.9%, 89.6%)	
07/26 05:08:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][150/703]	Step 12822	lr 0.02313	Loss 22.7181 (20.5322)	Hard Loss 1.4493 (1.3080)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (62.6%, 89.4%)	
07/26 05:08:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][200/703]	Step 12872	lr 0.02313	Loss 17.7540 (20.5606)	Hard Loss 1.1329 (1.3100)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (62.4%, 89.3%)	
07/26 05:08:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][250/703]	Step 12922	lr 0.02313	Loss 22.3374 (20.7854)	Hard Loss 1.4197 (1.3249)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (61.9%, 89.1%)	
07/26 05:09:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][300/703]	Step 12972	lr 0.02313	Loss 26.4957 (20.8487)	Hard Loss 1.7010 (1.3289)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (61.7%, 89.2%)	
07/26 05:09:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][350/703]	Step 13022	lr 0.02313	Loss 24.6748 (20.8120)	Hard Loss 1.5825 (1.3266)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (61.7%, 89.2%)	
07/26 05:09:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][400/703]	Step 13072	lr 0.02313	Loss 23.8701 (20.9186)	Hard Loss 1.5236 (1.3336)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (61.5%, 89.0%)	
07/26 05:09:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][450/703]	Step 13122	lr 0.02313	Loss 19.3910 (20.9700)	Hard Loss 1.2393 (1.3370)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (61.4%, 89.0%)	
07/26 05:09:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][500/703]	Step 13172	lr 0.02313	Loss 19.9871 (21.0117)	Hard Loss 1.2784 (1.3399)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (61.4%, 88.9%)	
07/26 05:09:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][550/703]	Step 13222	lr 0.02313	Loss 19.8221 (21.0156)	Hard Loss 1.2589 (1.3402)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (61.5%, 88.9%)	
07/26 05:10:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][600/703]	Step 13272	lr 0.02313	Loss 23.1296 (21.0671)	Hard Loss 1.4772 (1.3436)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (61.5%, 88.8%)	
07/26 05:10:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][650/703]	Step 13322	lr 0.02313	Loss 23.3580 (21.1484)	Hard Loss 1.4968 (1.3490)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (61.3%, 88.7%)	
07/26 05:10:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][700/703]	Step 13372	lr 0.02313	Loss 18.3709 (21.1236)	Hard Loss 1.1738 (1.3474)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (61.4%, 88.7%)	
07/26 05:10:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [18][703/703]	Step 13375	lr 0.02313	Loss 22.0227 (21.1272)	Hard Loss 1.4084 (1.3476)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (61.3%, 88.7%)	
07/26 05:10:19午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 18/99] Final Prec@1 61.3356%
07/26 05:10:22午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 18/99] Final Prec@1 51.1400%
07/26 05:10:22午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 54.1200%
07/26 05:10:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][50/703]	Step 13426	lr 0.02292	Loss 23.7385 (19.0811)	Hard Loss 1.5190 (1.2115)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (64.7%, 90.6%)	
07/26 05:10:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][100/703]	Step 13476	lr 0.02292	Loss 18.7319 (19.3536)	Hard Loss 1.1859 (1.2299)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (64.0%, 90.1%)	
07/26 05:10:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][150/703]	Step 13526	lr 0.02292	Loss 20.3705 (19.7133)	Hard Loss 1.2991 (1.2539)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.6%, 90.1%)	
07/26 05:11:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][200/703]	Step 13576	lr 0.02292	Loss 14.8623 (19.7631)	Hard Loss 0.9369 (1.2573)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.8%, 90.0%)	
07/26 05:11:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][250/703]	Step 13626	lr 0.02292	Loss 20.6917 (19.8955)	Hard Loss 1.3195 (1.2661)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (63.4%, 90.0%)	
07/26 05:11:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][300/703]	Step 13676	lr 0.02292	Loss 26.1350 (20.0289)	Hard Loss 1.6779 (1.2748)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (63.2%, 89.8%)	
07/26 05:11:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][350/703]	Step 13726	lr 0.02292	Loss 21.9675 (20.1128)	Hard Loss 1.4026 (1.2804)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (63.0%, 89.7%)	
07/26 05:11:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][400/703]	Step 13776	lr 0.02292	Loss 18.2712 (20.1428)	Hard Loss 1.1639 (1.2826)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (62.9%, 89.6%)	
07/26 05:11:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][450/703]	Step 13826	lr 0.02292	Loss 24.2562 (20.2959)	Hard Loss 1.5512 (1.2927)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (62.7%, 89.5%)	
07/26 05:11:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][500/703]	Step 13876	lr 0.02292	Loss 23.1074 (20.3748)	Hard Loss 1.4755 (1.2979)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (62.6%, 89.4%)	
07/26 05:12:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][550/703]	Step 13926	lr 0.02292	Loss 23.2103 (20.5046)	Hard Loss 1.4844 (1.3065)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (62.4%, 89.3%)	
07/26 05:12:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][600/703]	Step 13976	lr 0.02292	Loss 22.5305 (20.6157)	Hard Loss 1.4385 (1.3138)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (62.2%, 89.2%)	
07/26 05:12:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][650/703]	Step 14026	lr 0.02292	Loss 21.5748 (20.6215)	Hard Loss 1.3717 (1.3142)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (62.2%, 89.2%)	
07/26 05:12:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][700/703]	Step 14076	lr 0.02292	Loss 20.2351 (20.6533)	Hard Loss 1.2905 (1.3163)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (62.1%, 89.1%)	
07/26 05:12:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [19][703/703]	Step 14079	lr 0.02292	Loss 22.6236 (20.6611)	Hard Loss 1.4445 (1.3169)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (62.1%, 89.1%)	
07/26 05:12:35午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 19/99] Final Prec@1 62.1178%
07/26 05:12:38午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 19/99] Final Prec@1 54.6600%
07/26 05:12:38午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 54.6600%
07/26 05:12:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][50/703]	Step 14130	lr 0.02271	Loss 23.0110 (19.0195)	Hard Loss 1.4606 (1.2081)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (64.1%, 90.7%)	
07/26 05:12:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][100/703]	Step 14180	lr 0.02271	Loss 16.5145 (19.1933)	Hard Loss 1.0404 (1.2190)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (64.5%, 90.3%)	
07/26 05:13:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][150/703]	Step 14230	lr 0.02271	Loss 22.0840 (19.1412)	Hard Loss 1.4129 (1.2160)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (64.5%, 90.2%)	
07/26 05:13:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][200/703]	Step 14280	lr 0.02271	Loss 22.6414 (19.5745)	Hard Loss 1.4431 (1.2445)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (63.9%, 89.8%)	
07/26 05:13:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][250/703]	Step 14330	lr 0.02271	Loss 21.1614 (19.5970)	Hard Loss 1.3488 (1.2462)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (64.0%, 89.6%)	
07/26 05:13:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][300/703]	Step 14380	lr 0.02271	Loss 21.7239 (19.6412)	Hard Loss 1.3868 (1.2495)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (64.0%, 89.7%)	
07/26 05:13:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][350/703]	Step 14430	lr 0.02271	Loss 19.4519 (19.7806)	Hard Loss 1.2353 (1.2587)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.8%, 89.6%)	
07/26 05:13:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][400/703]	Step 14480	lr 0.02271	Loss 21.1894 (19.8922)	Hard Loss 1.3543 (1.2662)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.6%, 89.5%)	
07/26 05:14:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][450/703]	Step 14530	lr 0.02271	Loss 23.7401 (20.0202)	Hard Loss 1.5248 (1.2746)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (63.4%, 89.4%)	
07/26 05:14:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][500/703]	Step 14580	lr 0.02271	Loss 21.8827 (20.0739)	Hard Loss 1.3978 (1.2782)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (63.3%, 89.4%)	
07/26 05:14:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][550/703]	Step 14630	lr 0.02271	Loss 17.1217 (20.1481)	Hard Loss 1.0871 (1.2831)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.1%, 89.3%)	
07/26 05:14:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][600/703]	Step 14680	lr 0.02271	Loss 18.0152 (20.2142)	Hard Loss 1.1489 (1.2875)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.0%, 89.2%)	
07/26 05:14:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][650/703]	Step 14730	lr 0.02271	Loss 18.2968 (20.2372)	Hard Loss 1.1633 (1.2890)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.0%, 89.3%)	
07/26 05:14:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][700/703]	Step 14780	lr 0.02271	Loss 21.1900 (20.2302)	Hard Loss 1.3536 (1.2887)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (63.1%, 89.3%)	
07/26 05:14:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [20][703/703]	Step 14783	lr 0.02271	Loss 20.4706 (20.2334)	Hard Loss 1.3070 (1.2889)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.0%, 89.2%)	
07/26 05:14:51午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 20/99] Final Prec@1 63.0333%
07/26 05:14:54午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 20/99] Final Prec@1 55.0200%
07/26 05:14:54午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 55.0200%
07/26 05:15:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][50/703]	Step 14834	lr 0.02248	Loss 14.4560 (18.7197)	Hard Loss 0.9094 (1.1892)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (65.6%, 90.5%)	
07/26 05:15:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][100/703]	Step 14884	lr 0.02248	Loss 19.9037 (19.1061)	Hard Loss 1.2666 (1.2141)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (64.9%, 90.2%)	
07/26 05:15:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][150/703]	Step 14934	lr 0.02248	Loss 20.5317 (19.2779)	Hard Loss 1.3088 (1.2253)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (64.5%, 90.2%)	
07/26 05:15:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][200/703]	Step 14984	lr 0.02248	Loss 24.8626 (19.3798)	Hard Loss 1.5895 (1.2321)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (64.2%, 90.3%)	
07/26 05:15:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][250/703]	Step 15034	lr 0.02248	Loss 18.5715 (19.4840)	Hard Loss 1.1811 (1.2392)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (64.0%, 90.2%)	
07/26 05:15:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][300/703]	Step 15084	lr 0.02248	Loss 21.3118 (19.5972)	Hard Loss 1.3575 (1.2467)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (64.0%, 89.9%)	
07/26 05:16:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][350/703]	Step 15134	lr 0.02248	Loss 20.1329 (19.6541)	Hard Loss 1.2824 (1.2504)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (64.0%, 89.8%)	
07/26 05:16:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][400/703]	Step 15184	lr 0.02248	Loss 24.7283 (19.7142)	Hard Loss 1.5814 (1.2544)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (64.0%, 89.7%)	
07/26 05:16:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][450/703]	Step 15234	lr 0.02248	Loss 23.8473 (19.6559)	Hard Loss 1.5288 (1.2507)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (64.1%, 89.7%)	
07/26 05:16:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][500/703]	Step 15284	lr 0.02248	Loss 19.8808 (19.6854)	Hard Loss 1.2669 (1.2526)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (64.0%, 89.8%)	
07/26 05:16:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][550/703]	Step 15334	lr 0.02248	Loss 21.3798 (19.7335)	Hard Loss 1.3660 (1.2558)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.9%, 89.7%)	
07/26 05:16:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][600/703]	Step 15384	lr 0.02248	Loss 15.2438 (19.7659)	Hard Loss 0.9562 (1.2579)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.8%, 89.7%)	
07/26 05:16:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][650/703]	Step 15434	lr 0.02248	Loss 18.9236 (19.8504)	Hard Loss 1.1967 (1.2635)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (63.7%, 89.6%)	
07/26 05:17:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][700/703]	Step 15484	lr 0.02248	Loss 20.5599 (19.8941)	Hard Loss 1.3100 (1.2665)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.6%, 89.6%)	
07/26 05:17:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [21][703/703]	Step 15487	lr 0.02248	Loss 20.8392 (19.8946)	Hard Loss 1.3286 (1.2665)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (63.6%, 89.6%)	
07/26 05:17:07午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 21/99] Final Prec@1 63.6133%
07/26 05:17:10午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 21/99] Final Prec@1 55.3400%
07/26 05:17:11午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 55.3400%
07/26 05:17:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][50/703]	Step 15538	lr 0.02225	Loss 16.6637 (19.0562)	Hard Loss 1.0513 (1.2097)	Soft Loss 0.0022 (0.0024)	Prec@(1,5) (65.5%, 90.7%)	
07/26 05:17:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][100/703]	Step 15588	lr 0.02225	Loss 23.4029 (18.4880)	Hard Loss 1.4952 (1.1728)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (66.1%, 91.1%)	
07/26 05:17:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][150/703]	Step 15638	lr 0.02225	Loss 16.6320 (18.5202)	Hard Loss 1.0445 (1.1752)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (66.0%, 91.0%)	
07/26 05:17:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][200/703]	Step 15688	lr 0.02225	Loss 15.3066 (18.5838)	Hard Loss 0.9680 (1.1797)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (65.7%, 90.9%)	
07/26 05:17:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][250/703]	Step 15738	lr 0.02225	Loss 18.7095 (18.7115)	Hard Loss 1.1880 (1.1882)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.7%, 90.8%)	
07/26 05:18:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][300/703]	Step 15788	lr 0.02225	Loss 20.5032 (18.6758)	Hard Loss 1.3082 (1.1860)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.7%, 90.8%)	
07/26 05:18:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][350/703]	Step 15838	lr 0.02225	Loss 19.3706 (18.8476)	Hard Loss 1.2262 (1.1972)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (65.4%, 90.7%)	
07/26 05:18:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][400/703]	Step 15888	lr 0.02225	Loss 18.6591 (19.0109)	Hard Loss 1.1856 (1.2081)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (65.1%, 90.5%)	
07/26 05:18:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][450/703]	Step 15938	lr 0.02225	Loss 17.4302 (19.0655)	Hard Loss 1.0998 (1.2118)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (64.9%, 90.4%)	
07/26 05:18:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][500/703]	Step 15988	lr 0.02225	Loss 21.0576 (19.1464)	Hard Loss 1.3409 (1.2171)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (64.6%, 90.4%)	
07/26 05:18:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][550/703]	Step 16038	lr 0.02225	Loss 20.5421 (19.2537)	Hard Loss 1.3115 (1.2242)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (64.5%, 90.3%)	
07/26 05:19:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][600/703]	Step 16088	lr 0.02225	Loss 19.9346 (19.2657)	Hard Loss 1.2704 (1.2250)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (64.5%, 90.3%)	
07/26 05:19:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][650/703]	Step 16138	lr 0.02225	Loss 25.0737 (19.3330)	Hard Loss 1.6046 (1.2294)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (64.4%, 90.2%)	
07/26 05:19:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][700/703]	Step 16188	lr 0.02225	Loss 19.5361 (19.3566)	Hard Loss 1.2460 (1.2310)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (64.4%, 90.2%)	
07/26 05:19:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [22][703/703]	Step 16191	lr 0.02225	Loss 17.1255 (19.3467)	Hard Loss 1.0847 (1.2304)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (64.4%, 90.2%)	
07/26 05:19:26午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 22/99] Final Prec@1 64.3756%
07/26 05:19:30午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 22/99] Final Prec@1 55.3600%
07/26 05:19:30午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 55.3600%
07/26 05:19:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][50/703]	Step 16242	lr 0.022	Loss 17.2363 (17.4490)	Hard Loss 1.0949 (1.1044)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.4%, 91.9%)	
07/26 05:19:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][100/703]	Step 16292	lr 0.022	Loss 18.8137 (17.8102)	Hard Loss 1.1963 (1.1289)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (67.5%, 91.5%)	
07/26 05:20:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][150/703]	Step 16342	lr 0.022	Loss 16.4299 (18.0151)	Hard Loss 1.0393 (1.1425)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (67.0%, 91.7%)	
07/26 05:20:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][200/703]	Step 16392	lr 0.022	Loss 15.7406 (18.2139)	Hard Loss 0.9990 (1.1557)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (66.5%, 91.4%)	
07/26 05:20:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][250/703]	Step 16442	lr 0.022	Loss 17.2844 (18.2126)	Hard Loss 1.0945 (1.1556)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (66.4%, 91.3%)	
07/26 05:20:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][300/703]	Step 16492	lr 0.022	Loss 14.1422 (18.3243)	Hard Loss 0.8856 (1.1629)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (66.2%, 91.2%)	
07/26 05:20:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][350/703]	Step 16542	lr 0.022	Loss 12.1719 (18.4615)	Hard Loss 0.7587 (1.1720)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (65.9%, 91.0%)	
07/26 05:20:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][400/703]	Step 16592	lr 0.022	Loss 14.3356 (18.4861)	Hard Loss 0.9019 (1.1737)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (65.9%, 91.1%)	
07/26 05:21:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][450/703]	Step 16642	lr 0.022	Loss 21.0088 (18.6063)	Hard Loss 1.3389 (1.1816)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (65.8%, 90.9%)	
07/26 05:21:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][500/703]	Step 16692	lr 0.022	Loss 18.2871 (18.7365)	Hard Loss 1.1587 (1.1902)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (65.6%, 90.7%)	
07/26 05:21:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][550/703]	Step 16742	lr 0.022	Loss 25.2708 (18.7815)	Hard Loss 1.6305 (1.1932)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (65.5%, 90.7%)	
07/26 05:21:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][600/703]	Step 16792	lr 0.022	Loss 18.1922 (18.8875)	Hard Loss 1.1561 (1.2002)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.4%, 90.6%)	
07/26 05:21:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][650/703]	Step 16842	lr 0.022	Loss 22.3198 (18.9878)	Hard Loss 1.4205 (1.2068)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (65.1%, 90.5%)	
07/26 05:21:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][700/703]	Step 16892	lr 0.022	Loss 17.2195 (19.0289)	Hard Loss 1.0914 (1.2095)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.0%, 90.5%)	
07/26 05:21:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [23][703/703]	Step 16895	lr 0.022	Loss 22.1435 (19.0522)	Hard Loss 1.4114 (1.2110)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (65.0%, 90.5%)	
07/26 05:21:47午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 23/99] Final Prec@1 64.9933%
07/26 05:21:51午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 23/99] Final Prec@1 53.4800%
07/26 05:21:51午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 55.3600%
07/26 05:22:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][50/703]	Step 16946	lr 0.02175	Loss 21.6831 (17.2323)	Hard Loss 1.3822 (1.0899)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (68.3%, 92.2%)	
07/26 05:22:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][100/703]	Step 16996	lr 0.02175	Loss 19.2529 (17.3906)	Hard Loss 1.2297 (1.1009)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (68.1%, 91.9%)	
07/26 05:22:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][150/703]	Step 17046	lr 0.02175	Loss 22.4875 (17.7495)	Hard Loss 1.4385 (1.1245)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (67.8%, 91.4%)	
07/26 05:22:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][200/703]	Step 17096	lr 0.02175	Loss 19.5621 (17.8126)	Hard Loss 1.2461 (1.1289)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (67.7%, 91.4%)	
07/26 05:22:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][250/703]	Step 17146	lr 0.02175	Loss 17.4386 (17.8920)	Hard Loss 1.1069 (1.1342)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.3%, 91.3%)	
07/26 05:22:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][300/703]	Step 17196	lr 0.02175	Loss 16.1856 (17.9967)	Hard Loss 1.0261 (1.1412)	Soft Loss 0.0029 (0.0025)	Prec@(1,5) (66.9%, 91.4%)	
07/26 05:22:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][350/703]	Step 17246	lr 0.02175	Loss 14.6927 (18.0877)	Hard Loss 0.9228 (1.1473)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.6%, 91.3%)	
07/26 05:23:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][400/703]	Step 17296	lr 0.02175	Loss 14.2594 (18.1273)	Hard Loss 0.8940 (1.1500)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.5%, 91.2%)	
07/26 05:23:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][450/703]	Step 17346	lr 0.02175	Loss 17.2392 (18.2571)	Hard Loss 1.0854 (1.1585)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (66.2%, 91.1%)	
07/26 05:23:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][500/703]	Step 17396	lr 0.02175	Loss 15.7461 (18.3507)	Hard Loss 0.9941 (1.1648)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (66.1%, 91.0%)	
07/26 05:23:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][550/703]	Step 17446	lr 0.02175	Loss 18.5158 (18.4194)	Hard Loss 1.1811 (1.1693)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (66.0%, 90.9%)	
07/26 05:23:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][600/703]	Step 17496	lr 0.02175	Loss 20.9195 (18.4856)	Hard Loss 1.3359 (1.1737)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (65.9%, 90.9%)	
07/26 05:23:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][650/703]	Step 17546	lr 0.02175	Loss 18.9103 (18.5562)	Hard Loss 1.1999 (1.1784)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (65.8%, 90.8%)	
07/26 05:24:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][700/703]	Step 17596	lr 0.02175	Loss 22.6644 (18.5996)	Hard Loss 1.4539 (1.1814)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.7%, 90.7%)	
07/26 05:24:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [24][703/703]	Step 17599	lr 0.02175	Loss 16.1456 (18.6087)	Hard Loss 1.0199 (1.1820)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.6%, 90.7%)	
07/26 05:24:03午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 24/99] Final Prec@1 65.6378%
07/26 05:24:06午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 24/99] Final Prec@1 55.2600%
07/26 05:24:07午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 55.3600%
07/26 05:24:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][50/703]	Step 17650	lr 0.02149	Loss 13.9457 (17.4786)	Hard Loss 0.8802 (1.1066)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (66.7%, 92.4%)	
07/26 05:24:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][100/703]	Step 17700	lr 0.02149	Loss 20.3466 (17.3676)	Hard Loss 1.2900 (1.0997)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (66.9%, 92.2%)	
07/26 05:24:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][150/703]	Step 17750	lr 0.02149	Loss 17.1054 (17.2802)	Hard Loss 1.0858 (1.0942)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (67.0%, 92.3%)	
07/26 05:24:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][200/703]	Step 17800	lr 0.02149	Loss 22.7594 (17.4710)	Hard Loss 1.4543 (1.1066)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.0%, 92.1%)	
07/26 05:24:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][250/703]	Step 17850	lr 0.02149	Loss 15.8121 (17.6121)	Hard Loss 1.0052 (1.1159)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.8%, 91.9%)	
07/26 05:25:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][300/703]	Step 17900	lr 0.02149	Loss 13.9814 (17.6940)	Hard Loss 0.8751 (1.1214)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (66.8%, 91.7%)	
07/26 05:25:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][350/703]	Step 17950	lr 0.02149	Loss 18.2037 (17.7376)	Hard Loss 1.1510 (1.1244)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.8%, 91.7%)	
07/26 05:25:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][400/703]	Step 18000	lr 0.02149	Loss 14.9767 (17.8516)	Hard Loss 0.9413 (1.1318)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (66.7%, 91.6%)	
07/26 05:25:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][450/703]	Step 18050	lr 0.02149	Loss 21.2134 (17.9090)	Hard Loss 1.3552 (1.1357)	Soft Loss 0.0030 (0.0025)	Prec@(1,5) (66.6%, 91.5%)	
07/26 05:25:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][500/703]	Step 18100	lr 0.02149	Loss 18.7971 (18.0187)	Hard Loss 1.1908 (1.1430)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.5%, 91.4%)	
07/26 05:25:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][550/703]	Step 18150	lr 0.02149	Loss 19.6402 (18.0794)	Hard Loss 1.2524 (1.1470)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (66.4%, 91.3%)	
07/26 05:26:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][600/703]	Step 18200	lr 0.02149	Loss 17.0366 (18.1433)	Hard Loss 1.0840 (1.1513)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.2%, 91.3%)	
07/26 05:26:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][650/703]	Step 18250	lr 0.02149	Loss 23.6074 (18.2940)	Hard Loss 1.5059 (1.1612)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (66.0%, 91.2%)	
07/26 05:26:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][700/703]	Step 18300	lr 0.02149	Loss 19.1921 (18.3524)	Hard Loss 1.2166 (1.1650)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (65.9%, 91.1%)	
07/26 05:26:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [25][703/703]	Step 18303	lr 0.02149	Loss 16.5405 (18.3608)	Hard Loss 1.0502 (1.1656)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (65.9%, 91.1%)	
07/26 05:26:19午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 25/99] Final Prec@1 65.8978%
07/26 05:26:22午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 25/99] Final Prec@1 56.1000%
07/26 05:26:22午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 56.1000%
07/26 05:26:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][50/703]	Step 18354	lr 0.02121	Loss 19.0794 (17.5584)	Hard Loss 1.2121 (1.1105)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (68.3%, 93.0%)	
07/26 05:26:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][100/703]	Step 18404	lr 0.02121	Loss 20.9603 (17.1086)	Hard Loss 1.3388 (1.0821)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (68.8%, 92.8%)	
07/26 05:26:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][150/703]	Step 18454	lr 0.02121	Loss 17.6590 (17.0787)	Hard Loss 1.1201 (1.0805)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.4%, 92.5%)	
07/26 05:27:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][200/703]	Step 18504	lr 0.02121	Loss 18.9846 (17.2064)	Hard Loss 1.2099 (1.0890)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.3%, 92.3%)	
07/26 05:27:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][250/703]	Step 18554	lr 0.02121	Loss 11.1347 (17.1801)	Hard Loss 0.6884 (1.0872)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.2%, 92.5%)	
07/26 05:27:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][300/703]	Step 18604	lr 0.02121	Loss 16.0077 (17.2582)	Hard Loss 1.0121 (1.0925)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (67.9%, 92.3%)	
07/26 05:27:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][350/703]	Step 18654	lr 0.02121	Loss 22.5234 (17.4340)	Hard Loss 1.4371 (1.1041)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (67.6%, 92.1%)	
07/26 05:27:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][400/703]	Step 18704	lr 0.02121	Loss 17.0396 (17.5257)	Hard Loss 1.0808 (1.1102)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (67.4%, 92.1%)	
07/26 05:27:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][450/703]	Step 18754	lr 0.02121	Loss 16.2131 (17.6163)	Hard Loss 1.0243 (1.1162)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (67.2%, 92.0%)	
07/26 05:27:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][500/703]	Step 18804	lr 0.02121	Loss 17.7491 (17.7041)	Hard Loss 1.1215 (1.1220)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.0%, 91.9%)	
07/26 05:28:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][550/703]	Step 18854	lr 0.02121	Loss 18.7046 (17.8357)	Hard Loss 1.1762 (1.1307)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (66.9%, 91.8%)	
07/26 05:28:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][600/703]	Step 18904	lr 0.02121	Loss 15.0510 (17.8872)	Hard Loss 0.9497 (1.1341)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (66.8%, 91.7%)	
07/26 05:28:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][650/703]	Step 18954	lr 0.02121	Loss 17.4704 (17.9513)	Hard Loss 1.1089 (1.1384)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (66.7%, 91.7%)	
07/26 05:28:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][700/703]	Step 19004	lr 0.02121	Loss 17.4133 (18.0159)	Hard Loss 1.0990 (1.1427)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (66.7%, 91.6%)	
07/26 05:28:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [26][703/703]	Step 19007	lr 0.02121	Loss 19.9105 (18.0235)	Hard Loss 1.2640 (1.1432)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (66.6%, 91.6%)	
07/26 05:28:35午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 26/99] Final Prec@1 66.6422%
07/26 05:28:38午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 26/99] Final Prec@1 57.3400%
07/26 05:28:38午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 57.3400%
07/26 05:28:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][50/703]	Step 19058	lr 0.02094	Loss 19.3289 (16.2982)	Hard Loss 1.2264 (1.0285)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.5%, 92.8%)	
07/26 05:28:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][100/703]	Step 19108	lr 0.02094	Loss 14.5906 (16.3612)	Hard Loss 0.9180 (1.0325)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.2%, 93.0%)	
07/26 05:29:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][150/703]	Step 19158	lr 0.02094	Loss 14.1482 (16.6118)	Hard Loss 0.8859 (1.0492)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (68.8%, 92.8%)	
07/26 05:29:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][200/703]	Step 19208	lr 0.02094	Loss 16.8667 (16.7626)	Hard Loss 1.0688 (1.0593)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (68.8%, 92.6%)	
07/26 05:29:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][250/703]	Step 19258	lr 0.02094	Loss 19.8049 (16.8932)	Hard Loss 1.2592 (1.0681)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.5%, 92.6%)	
07/26 05:29:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][300/703]	Step 19308	lr 0.02094	Loss 21.1801 (17.0470)	Hard Loss 1.3447 (1.0783)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (68.4%, 92.4%)	
07/26 05:29:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][350/703]	Step 19358	lr 0.02094	Loss 17.7136 (17.1086)	Hard Loss 1.1266 (1.0825)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (68.2%, 92.3%)	
07/26 05:29:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][400/703]	Step 19408	lr 0.02094	Loss 17.9531 (17.1540)	Hard Loss 1.1390 (1.0855)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (68.3%, 92.3%)	
07/26 05:30:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][450/703]	Step 19458	lr 0.02094	Loss 18.1817 (17.2367)	Hard Loss 1.1584 (1.0911)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.0%, 92.2%)	
07/26 05:30:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][500/703]	Step 19508	lr 0.02094	Loss 15.3741 (17.3150)	Hard Loss 0.9675 (1.0963)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (67.9%, 92.1%)	
07/26 05:30:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][550/703]	Step 19558	lr 0.02094	Loss 14.9921 (17.3623)	Hard Loss 0.9452 (1.0995)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (67.8%, 92.0%)	
07/26 05:30:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][600/703]	Step 19608	lr 0.02094	Loss 20.5523 (17.4891)	Hard Loss 1.3094 (1.1079)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (67.6%, 91.9%)	
07/26 05:30:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][650/703]	Step 19658	lr 0.02094	Loss 13.9268 (17.5765)	Hard Loss 0.8767 (1.1137)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.3%, 91.8%)	
07/26 05:30:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][700/703]	Step 19708	lr 0.02094	Loss 18.5342 (17.6131)	Hard Loss 1.1729 (1.1162)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (67.3%, 91.8%)	
07/26 05:30:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [27][703/703]	Step 19711	lr 0.02094	Loss 16.2901 (17.6229)	Hard Loss 1.0292 (1.1168)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.3%, 91.8%)	
07/26 05:30:51午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 27/99] Final Prec@1 67.2578%
07/26 05:30:54午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 27/99] Final Prec@1 56.8400%
07/26 05:30:54午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 57.3400%
07/26 05:31:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][50/703]	Step 19762	lr 0.02065	Loss 16.4313 (16.2637)	Hard Loss 1.0412 (1.0256)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (70.2%, 93.0%)	
07/26 05:31:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][100/703]	Step 19812	lr 0.02065	Loss 19.3918 (16.3536)	Hard Loss 1.2320 (1.0323)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.7%, 92.5%)	
07/26 05:31:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][150/703]	Step 19862	lr 0.02065	Loss 13.2130 (16.5320)	Hard Loss 0.8325 (1.0445)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (69.3%, 92.3%)	
07/26 05:31:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][200/703]	Step 19912	lr 0.02065	Loss 16.5509 (16.8012)	Hard Loss 1.0457 (1.0623)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.7%, 92.3%)	
07/26 05:31:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][250/703]	Step 19962	lr 0.02065	Loss 12.6257 (16.8663)	Hard Loss 0.7858 (1.0666)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.7%, 92.2%)	
07/26 05:31:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][300/703]	Step 20012	lr 0.02065	Loss 26.8670 (16.9258)	Hard Loss 1.7246 (1.0705)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (68.7%, 92.3%)	
07/26 05:32:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][350/703]	Step 20062	lr 0.02065	Loss 14.5787 (16.9663)	Hard Loss 0.9194 (1.0732)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.6%, 92.3%)	
07/26 05:32:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][400/703]	Step 20112	lr 0.02065	Loss 18.5511 (17.0802)	Hard Loss 1.1757 (1.0808)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.4%, 92.2%)	
07/26 05:32:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][450/703]	Step 20162	lr 0.02065	Loss 22.7933 (17.1767)	Hard Loss 1.4539 (1.0869)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.3%, 92.1%)	
07/26 05:32:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][500/703]	Step 20212	lr 0.02065	Loss 18.6319 (17.2164)	Hard Loss 1.1825 (1.0896)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.2%, 92.1%)	
07/26 05:32:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][550/703]	Step 20262	lr 0.02065	Loss 22.4247 (17.2271)	Hard Loss 1.4328 (1.0903)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (68.2%, 92.1%)	
07/26 05:32:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][600/703]	Step 20312	lr 0.02065	Loss 19.0210 (17.2782)	Hard Loss 1.2092 (1.0937)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.1%, 92.0%)	
07/26 05:32:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][650/703]	Step 20362	lr 0.02065	Loss 24.6643 (17.3121)	Hard Loss 1.5794 (1.0960)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.0%, 92.0%)	
07/26 05:33:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][700/703]	Step 20412	lr 0.02065	Loss 16.7912 (17.3374)	Hard Loss 1.0617 (1.0977)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (67.9%, 91.9%)	
07/26 05:33:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [28][703/703]	Step 20415	lr 0.02065	Loss 15.9870 (17.3403)	Hard Loss 1.0120 (1.0979)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (67.9%, 91.9%)	
07/26 05:33:06午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 28/99] Final Prec@1 67.9000%
07/26 05:33:10午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 28/99] Final Prec@1 55.6000%
07/26 05:33:10午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 57.3400%
07/26 05:33:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][50/703]	Step 20466	lr 0.02035	Loss 15.8464 (15.7881)	Hard Loss 1.0046 (0.9961)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (70.1%, 93.1%)	
07/26 05:33:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][100/703]	Step 20516	lr 0.02035	Loss 19.4087 (16.0217)	Hard Loss 1.2301 (1.0114)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (69.7%, 92.9%)	
07/26 05:33:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][150/703]	Step 20566	lr 0.02035	Loss 18.4330 (16.0511)	Hard Loss 1.1663 (1.0127)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.9%, 92.9%)	
07/26 05:33:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][200/703]	Step 20616	lr 0.02035	Loss 14.5807 (16.0424)	Hard Loss 0.9173 (1.0123)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (70.1%, 93.0%)	
07/26 05:33:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][250/703]	Step 20666	lr 0.02035	Loss 16.6504 (16.2012)	Hard Loss 1.0515 (1.0228)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (69.9%, 92.9%)	
07/26 05:34:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][300/703]	Step 20716	lr 0.02035	Loss 19.6433 (16.4336)	Hard Loss 1.2460 (1.0382)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.6%, 92.8%)	
07/26 05:34:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][350/703]	Step 20766	lr 0.02035	Loss 18.9000 (16.5196)	Hard Loss 1.2029 (1.0438)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (69.4%, 92.7%)	
07/26 05:34:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][400/703]	Step 20816	lr 0.02035	Loss 16.6081 (16.5661)	Hard Loss 1.0422 (1.0468)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (69.3%, 92.7%)	
07/26 05:34:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][450/703]	Step 20866	lr 0.02035	Loss 9.3544 (16.6318)	Hard Loss 0.5795 (1.0512)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.1%, 92.6%)	
07/26 05:34:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][500/703]	Step 20916	lr 0.02035	Loss 19.3294 (16.7570)	Hard Loss 1.2273 (1.0594)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (68.9%, 92.5%)	
07/26 05:34:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][550/703]	Step 20966	lr 0.02035	Loss 15.3310 (16.8325)	Hard Loss 0.9639 (1.0645)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (68.8%, 92.4%)	
07/26 05:35:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][600/703]	Step 21016	lr 0.02035	Loss 18.7957 (16.9242)	Hard Loss 1.1902 (1.0706)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (68.6%, 92.3%)	
07/26 05:35:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][650/703]	Step 21066	lr 0.02035	Loss 15.6165 (17.0108)	Hard Loss 0.9912 (1.0763)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (68.5%, 92.3%)	
07/26 05:35:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][700/703]	Step 21116	lr 0.02035	Loss 21.2703 (17.0506)	Hard Loss 1.3546 (1.0789)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.4%, 92.3%)	
07/26 05:35:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [29][703/703]	Step 21119	lr 0.02035	Loss 15.8786 (17.0522)	Hard Loss 0.9983 (1.0790)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.4%, 92.3%)	
07/26 05:35:23午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 29/99] Final Prec@1 68.3889%
07/26 05:35:26午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 29/99] Final Prec@1 57.7400%
07/26 05:35:26午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 57.7400%
07/26 05:35:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][50/703]	Step 21170	lr 0.02005	Loss 16.5769 (15.7249)	Hard Loss 1.0507 (0.9903)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (70.9%, 93.3%)	
07/26 05:35:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][100/703]	Step 21220	lr 0.02005	Loss 13.7576 (15.6304)	Hard Loss 0.8560 (0.9842)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (71.1%, 93.7%)	
07/26 05:35:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][150/703]	Step 21270	lr 0.02005	Loss 19.3380 (15.9145)	Hard Loss 1.2291 (1.0031)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (70.8%, 93.4%)	
07/26 05:36:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][200/703]	Step 21320	lr 0.02005	Loss 17.0329 (15.9881)	Hard Loss 1.0808 (1.0081)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (70.6%, 93.2%)	
07/26 05:36:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][250/703]	Step 21370	lr 0.02005	Loss 16.6579 (16.0895)	Hard Loss 1.0497 (1.0150)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (70.3%, 93.0%)	
07/26 05:36:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][300/703]	Step 21420	lr 0.02005	Loss 14.6053 (16.1770)	Hard Loss 0.9161 (1.0206)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (70.0%, 93.0%)	
07/26 05:36:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][350/703]	Step 21470	lr 0.02005	Loss 21.3553 (16.1848)	Hard Loss 1.3604 (1.0213)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (70.0%, 93.0%)	
07/26 05:36:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][400/703]	Step 21520	lr 0.02005	Loss 14.8784 (16.2829)	Hard Loss 0.9408 (1.0278)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (69.8%, 92.8%)	
07/26 05:36:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][450/703]	Step 21570	lr 0.02005	Loss 20.9533 (16.3922)	Hard Loss 1.3338 (1.0351)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.5%, 92.8%)	
07/26 05:37:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][500/703]	Step 21620	lr 0.02005	Loss 17.7017 (16.4979)	Hard Loss 1.1179 (1.0421)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.4%, 92.7%)	
07/26 05:37:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][550/703]	Step 21670	lr 0.02005	Loss 20.9486 (16.5513)	Hard Loss 1.3353 (1.0458)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.2%, 92.6%)	
07/26 05:37:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][600/703]	Step 21720	lr 0.02005	Loss 17.9008 (16.5976)	Hard Loss 1.1356 (1.0489)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.2%, 92.6%)	
07/26 05:37:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][650/703]	Step 21770	lr 0.02005	Loss 17.3525 (16.6704)	Hard Loss 1.0993 (1.0537)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.0%, 92.5%)	
07/26 05:37:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][700/703]	Step 21820	lr 0.02005	Loss 18.8258 (16.7488)	Hard Loss 1.1962 (1.0589)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.9%, 92.5%)	
07/26 05:37:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [30][703/703]	Step 21823	lr 0.02005	Loss 15.7674 (16.7626)	Hard Loss 0.9948 (1.0598)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (68.9%, 92.4%)	
07/26 05:37:39午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 30/99] Final Prec@1 68.8911%
07/26 05:37:42午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 30/99] Final Prec@1 55.7600%
07/26 05:37:42午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 57.7400%
07/26 05:37:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][50/703]	Step 21874	lr 0.01975	Loss 14.5484 (15.6027)	Hard Loss 0.9162 (0.9825)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.8%, 93.7%)	
07/26 05:38:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][100/703]	Step 21924	lr 0.01975	Loss 16.7044 (15.6103)	Hard Loss 1.0524 (0.9834)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (69.5%, 93.5%)	
07/26 05:38:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][150/703]	Step 21974	lr 0.01975	Loss 17.9626 (15.7323)	Hard Loss 1.1350 (0.9913)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (69.8%, 93.2%)	
07/26 05:38:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][200/703]	Step 22024	lr 0.01975	Loss 15.7293 (15.8385)	Hard Loss 0.9925 (0.9985)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (69.9%, 93.2%)	
07/26 05:38:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][250/703]	Step 22074	lr 0.01975	Loss 16.4650 (15.9257)	Hard Loss 1.0419 (1.0045)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.9%, 93.0%)	
07/26 05:38:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][300/703]	Step 22124	lr 0.01975	Loss 14.0420 (15.9460)	Hard Loss 0.8833 (1.0058)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (69.8%, 93.0%)	
07/26 05:38:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][350/703]	Step 22174	lr 0.01975	Loss 15.7258 (15.9910)	Hard Loss 0.9958 (1.0088)	Soft Loss 0.0029 (0.0025)	Prec@(1,5) (69.6%, 93.0%)	
07/26 05:38:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][400/703]	Step 22224	lr 0.01975	Loss 20.2887 (16.1251)	Hard Loss 1.2917 (1.0176)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (69.5%, 93.0%)	
07/26 05:39:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][450/703]	Step 22274	lr 0.01975	Loss 18.2373 (16.1574)	Hard Loss 1.1571 (1.0197)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.6%, 92.9%)	
07/26 05:39:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][500/703]	Step 22324	lr 0.01975	Loss 15.4794 (16.2017)	Hard Loss 0.9776 (1.0226)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (69.4%, 92.9%)	
07/26 05:39:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][550/703]	Step 22374	lr 0.01975	Loss 16.9795 (16.2732)	Hard Loss 1.0795 (1.0273)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.3%, 92.9%)	
07/26 05:39:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][600/703]	Step 22424	lr 0.01975	Loss 16.5260 (16.3252)	Hard Loss 1.0483 (1.0309)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (69.3%, 92.8%)	
07/26 05:39:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][650/703]	Step 22474	lr 0.01975	Loss 17.2943 (16.3824)	Hard Loss 1.0933 (1.0346)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (69.2%, 92.8%)	
07/26 05:39:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][700/703]	Step 22524	lr 0.01975	Loss 12.3531 (16.3827)	Hard Loss 0.7727 (1.0347)	Soft Loss 0.0029 (0.0025)	Prec@(1,5) (69.2%, 92.8%)	
07/26 05:39:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [31][703/703]	Step 22527	lr 0.01975	Loss 21.3873 (16.3869)	Hard Loss 1.3572 (1.0350)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (69.2%, 92.8%)	
07/26 05:39:54午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 31/99] Final Prec@1 69.1933%
07/26 05:39:57午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 31/99] Final Prec@1 57.2000%
07/26 05:39:58午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 57.7400%
07/26 05:40:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][50/703]	Step 22578	lr 0.01943	Loss 16.5257 (14.5124)	Hard Loss 1.0408 (0.9107)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (72.4%, 94.7%)	
07/26 05:40:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][100/703]	Step 22628	lr 0.01943	Loss 16.9652 (14.7364)	Hard Loss 1.0758 (0.9252)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (72.2%, 94.0%)	
07/26 05:40:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][150/703]	Step 22678	lr 0.01943	Loss 14.6492 (14.9100)	Hard Loss 0.9205 (0.9368)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (72.0%, 93.8%)	
07/26 05:40:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][200/703]	Step 22728	lr 0.01943	Loss 20.6160 (15.2559)	Hard Loss 1.3180 (0.9598)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (71.3%, 93.6%)	
07/26 05:40:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][250/703]	Step 22778	lr 0.01943	Loss 14.3709 (15.3093)	Hard Loss 0.8998 (0.9635)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (71.3%, 93.6%)	
07/26 05:40:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][300/703]	Step 22828	lr 0.01943	Loss 17.4966 (15.3703)	Hard Loss 1.1058 (0.9676)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (71.1%, 93.6%)	
07/26 05:41:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][350/703]	Step 22878	lr 0.01943	Loss 20.5040 (15.5109)	Hard Loss 1.3033 (0.9769)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (70.9%, 93.5%)	
07/26 05:41:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][400/703]	Step 22928	lr 0.01943	Loss 17.7581 (15.6675)	Hard Loss 1.1235 (0.9872)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (70.6%, 93.4%)	
07/26 05:41:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][450/703]	Step 22978	lr 0.01943	Loss 18.6116 (15.7530)	Hard Loss 1.1810 (0.9929)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (70.5%, 93.3%)	
07/26 05:41:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][500/703]	Step 23028	lr 0.01943	Loss 17.1713 (15.8104)	Hard Loss 1.0914 (0.9967)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (70.3%, 93.3%)	
07/26 05:41:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][550/703]	Step 23078	lr 0.01943	Loss 15.9667 (15.8848)	Hard Loss 1.0086 (1.0017)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (70.2%, 93.2%)	
07/26 05:41:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][600/703]	Step 23128	lr 0.01943	Loss 20.3215 (15.9635)	Hard Loss 1.2933 (1.0069)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (70.1%, 93.1%)	
07/26 05:42:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][650/703]	Step 23178	lr 0.01943	Loss 12.7016 (16.0172)	Hard Loss 0.7958 (1.0106)	Soft Loss 0.0022 (0.0026)	Prec@(1,5) (70.0%, 93.0%)	
07/26 05:42:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][700/703]	Step 23228	lr 0.01943	Loss 13.8155 (16.0802)	Hard Loss 0.8702 (1.0147)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (69.8%, 93.0%)	
07/26 05:42:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [32][703/703]	Step 23231	lr 0.01943	Loss 17.6378 (16.0909)	Hard Loss 1.1205 (1.0154)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (69.8%, 93.0%)	
07/26 05:42:10午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 32/99] Final Prec@1 69.8378%
07/26 05:42:13午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 32/99] Final Prec@1 58.8600%
07/26 05:42:13午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 58.8600%
07/26 05:42:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][50/703]	Step 23282	lr 0.01911	Loss 18.5711 (14.8390)	Hard Loss 1.1770 (0.9321)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (71.7%, 94.3%)	
07/26 05:42:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][100/703]	Step 23332	lr 0.01911	Loss 18.1951 (15.1116)	Hard Loss 1.1524 (0.9500)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (71.2%, 93.9%)	
07/26 05:42:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][150/703]	Step 23382	lr 0.01911	Loss 13.0801 (14.9534)	Hard Loss 0.8147 (0.9397)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (71.5%, 93.9%)	
07/26 05:42:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][200/703]	Step 23432	lr 0.01911	Loss 14.0630 (15.0846)	Hard Loss 0.8754 (0.9484)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (71.3%, 93.9%)	
07/26 05:43:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][250/703]	Step 23482	lr 0.01911	Loss 16.5107 (15.2776)	Hard Loss 1.0348 (0.9613)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (71.0%, 93.6%)	
07/26 05:43:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][300/703]	Step 23532	lr 0.01911	Loss 14.8807 (15.2988)	Hard Loss 0.9379 (0.9628)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (71.1%, 93.7%)	
07/26 05:43:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][350/703]	Step 23582	lr 0.01911	Loss 17.0675 (15.4765)	Hard Loss 1.0810 (0.9745)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.0%, 93.5%)	
07/26 05:43:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][400/703]	Step 23632	lr 0.01911	Loss 15.1747 (15.4906)	Hard Loss 0.9616 (0.9755)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.0%, 93.5%)	
07/26 05:43:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][450/703]	Step 23682	lr 0.01911	Loss 17.3939 (15.5376)	Hard Loss 1.1126 (0.9786)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (71.0%, 93.5%)	
07/26 05:43:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][500/703]	Step 23732	lr 0.01911	Loss 18.8311 (15.6353)	Hard Loss 1.1930 (0.9851)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (70.8%, 93.4%)	
07/26 05:43:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][550/703]	Step 23782	lr 0.01911	Loss 13.4814 (15.6722)	Hard Loss 0.8398 (0.9877)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (70.8%, 93.4%)	
07/26 05:44:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][600/703]	Step 23832	lr 0.01911	Loss 15.0198 (15.7668)	Hard Loss 0.9413 (0.9939)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (70.6%, 93.3%)	
07/26 05:44:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][650/703]	Step 23882	lr 0.01911	Loss 18.1408 (15.7804)	Hard Loss 1.1495 (0.9948)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (70.6%, 93.3%)	
07/26 05:44:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][700/703]	Step 23932	lr 0.01911	Loss 21.4670 (15.8916)	Hard Loss 1.3686 (1.0022)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (70.4%, 93.2%)	
07/26 05:44:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [33][703/703]	Step 23935	lr 0.01911	Loss 19.0016 (15.9038)	Hard Loss 1.2022 (1.0030)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (70.4%, 93.2%)	
07/26 05:44:26午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 33/99] Final Prec@1 70.4133%
07/26 05:44:29午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 33/99] Final Prec@1 58.4200%
07/26 05:44:29午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 58.8600%
07/26 05:44:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][50/703]	Step 23986	lr 0.01878	Loss 13.2009 (14.6968)	Hard Loss 0.8175 (0.9225)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (72.7%, 93.9%)	
07/26 05:44:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][100/703]	Step 24036	lr 0.01878	Loss 12.5995 (14.4386)	Hard Loss 0.7867 (0.9060)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (72.9%, 94.2%)	
07/26 05:44:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][150/703]	Step 24086	lr 0.01878	Loss 11.2565 (14.5189)	Hard Loss 0.7015 (0.9115)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (72.9%, 94.2%)	
07/26 05:45:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][200/703]	Step 24136	lr 0.01878	Loss 15.8008 (14.5955)	Hard Loss 0.9958 (0.9165)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (72.9%, 94.0%)	
07/26 05:45:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][250/703]	Step 24186	lr 0.01878	Loss 14.2757 (14.7412)	Hard Loss 0.8975 (0.9260)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (72.6%, 94.0%)	
07/26 05:45:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][300/703]	Step 24236	lr 0.01878	Loss 15.8740 (14.9467)	Hard Loss 1.0042 (0.9395)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (72.4%, 93.9%)	
07/26 05:45:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][350/703]	Step 24286	lr 0.01878	Loss 10.2441 (14.9735)	Hard Loss 0.6326 (0.9413)	Soft Loss 0.0030 (0.0025)	Prec@(1,5) (72.3%, 93.8%)	
07/26 05:45:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][400/703]	Step 24336	lr 0.01878	Loss 14.4444 (15.0551)	Hard Loss 0.9086 (0.9467)	Soft Loss 0.0028 (0.0025)	Prec@(1,5) (72.2%, 93.8%)	
07/26 05:45:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][450/703]	Step 24386	lr 0.01878	Loss 17.7118 (15.0993)	Hard Loss 1.1185 (0.9496)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (72.0%, 93.7%)	
07/26 05:46:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][500/703]	Step 24436	lr 0.01878	Loss 15.4450 (15.1592)	Hard Loss 0.9749 (0.9537)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (71.8%, 93.7%)	
07/26 05:46:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][550/703]	Step 24486	lr 0.01878	Loss 18.9712 (15.2760)	Hard Loss 1.2079 (0.9614)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (71.7%, 93.6%)	
07/26 05:46:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][600/703]	Step 24536	lr 0.01878	Loss 17.7384 (15.3680)	Hard Loss 1.1310 (0.9675)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (71.5%, 93.5%)	
07/26 05:46:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][650/703]	Step 24586	lr 0.01878	Loss 14.6784 (15.4345)	Hard Loss 0.9207 (0.9719)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (71.4%, 93.5%)	
07/26 05:46:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][700/703]	Step 24636	lr 0.01878	Loss 16.6640 (15.4944)	Hard Loss 1.0504 (0.9759)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (71.3%, 93.4%)	
07/26 05:46:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [34][703/703]	Step 24639	lr 0.01878	Loss 13.4224 (15.4943)	Hard Loss 0.8368 (0.9759)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (71.3%, 93.4%)	
07/26 05:46:41午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 34/99] Final Prec@1 71.3156%
07/26 05:46:44午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 34/99] Final Prec@1 57.3400%
07/26 05:46:45午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 58.8600%
07/26 05:46:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][50/703]	Step 24690	lr 0.01845	Loss 15.7729 (13.7269)	Hard Loss 0.9856 (0.8593)	Soft Loss 0.0029 (0.0025)	Prec@(1,5) (73.7%, 95.4%)	
07/26 05:47:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][100/703]	Step 24740	lr 0.01845	Loss 13.6313 (13.8618)	Hard Loss 0.8484 (0.8684)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (73.4%, 95.2%)	
07/26 05:47:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][150/703]	Step 24790	lr 0.01845	Loss 15.7175 (14.0209)	Hard Loss 0.9919 (0.8787)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (73.3%, 94.9%)	
07/26 05:47:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][200/703]	Step 24840	lr 0.01845	Loss 16.4586 (14.2406)	Hard Loss 1.0449 (0.8930)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (73.0%, 94.7%)	
07/26 05:47:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][250/703]	Step 24890	lr 0.01845	Loss 18.4736 (14.5120)	Hard Loss 1.1767 (0.9109)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (72.7%, 94.4%)	
07/26 05:47:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][300/703]	Step 24940	lr 0.01845	Loss 18.1563 (14.6950)	Hard Loss 1.1523 (0.9230)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (72.4%, 94.2%)	
07/26 05:47:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][350/703]	Step 24990	lr 0.01845	Loss 18.0862 (14.7953)	Hard Loss 1.1532 (0.9296)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (72.0%, 94.2%)	
07/26 05:48:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][400/703]	Step 25040	lr 0.01845	Loss 16.4732 (14.8980)	Hard Loss 1.0374 (0.9364)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (71.7%, 94.1%)	
07/26 05:48:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][450/703]	Step 25090	lr 0.01845	Loss 13.9928 (14.9986)	Hard Loss 0.8732 (0.9430)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.5%, 94.0%)	
07/26 05:48:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][500/703]	Step 25140	lr 0.01845	Loss 16.9246 (15.0775)	Hard Loss 1.0643 (0.9483)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.4%, 94.0%)	
07/26 05:48:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][550/703]	Step 25190	lr 0.01845	Loss 17.6556 (15.0873)	Hard Loss 1.1217 (0.9490)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.4%, 94.0%)	
07/26 05:48:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][600/703]	Step 25240	lr 0.01845	Loss 23.5795 (15.2111)	Hard Loss 1.5082 (0.9572)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (71.1%, 94.0%)	
07/26 05:48:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][650/703]	Step 25290	lr 0.01845	Loss 16.2573 (15.2657)	Hard Loss 1.0213 (0.9608)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (71.1%, 93.9%)	
07/26 05:48:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][700/703]	Step 25340	lr 0.01845	Loss 16.2483 (15.2784)	Hard Loss 1.0248 (0.9617)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.1%, 93.9%)	
07/26 05:48:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [35][703/703]	Step 25343	lr 0.01845	Loss 13.1315 (15.2733)	Hard Loss 0.8159 (0.9614)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.1%, 93.9%)	
07/26 05:48:57午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 35/99] Final Prec@1 71.1111%
07/26 05:49:01午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 35/99] Final Prec@1 58.3800%
07/26 05:49:01午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 58.8600%
07/26 05:49:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][50/703]	Step 25394	lr 0.01811	Loss 13.7164 (14.2079)	Hard Loss 0.8572 (0.8906)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (72.8%, 94.8%)	
07/26 05:49:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][100/703]	Step 25444	lr 0.01811	Loss 12.5382 (14.1455)	Hard Loss 0.7725 (0.8867)	Soft Loss 0.0023 (0.0025)	Prec@(1,5) (73.0%, 94.9%)	
07/26 05:49:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][150/703]	Step 25494	lr 0.01811	Loss 15.3620 (14.1902)	Hard Loss 0.9681 (0.8895)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (72.9%, 95.0%)	
07/26 05:49:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][200/703]	Step 25544	lr 0.01811	Loss 18.7902 (14.2218)	Hard Loss 1.1989 (0.8916)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (72.9%, 94.8%)	
07/26 05:49:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][250/703]	Step 25594	lr 0.01811	Loss 17.1405 (14.4194)	Hard Loss 1.0804 (0.9046)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (72.6%, 94.6%)	
07/26 05:49:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][300/703]	Step 25644	lr 0.01811	Loss 15.8490 (14.4442)	Hard Loss 1.0031 (0.9064)	Soft Loss 0.0027 (0.0025)	Prec@(1,5) (72.7%, 94.5%)	
07/26 05:50:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][350/703]	Step 25694	lr 0.01811	Loss 14.4956 (14.4929)	Hard Loss 0.9042 (0.9097)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (72.6%, 94.5%)	
07/26 05:50:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][400/703]	Step 25744	lr 0.01811	Loss 17.1661 (14.5677)	Hard Loss 1.0772 (0.9147)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (72.5%, 94.3%)	
07/26 05:50:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][450/703]	Step 25794	lr 0.01811	Loss 13.7691 (14.6944)	Hard Loss 0.8653 (0.9230)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (72.2%, 94.2%)	
07/26 05:50:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][500/703]	Step 25844	lr 0.01811	Loss 16.1140 (14.7321)	Hard Loss 1.0157 (0.9256)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (72.1%, 94.2%)	
07/26 05:50:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][550/703]	Step 25894	lr 0.01811	Loss 17.2689 (14.8076)	Hard Loss 1.0907 (0.9306)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (71.9%, 94.2%)	
07/26 05:50:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][600/703]	Step 25944	lr 0.01811	Loss 16.7040 (14.9191)	Hard Loss 1.0647 (0.9380)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (71.8%, 94.1%)	
07/26 05:51:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][650/703]	Step 25994	lr 0.01811	Loss 15.8232 (14.9693)	Hard Loss 0.9962 (0.9413)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (71.7%, 94.1%)	
07/26 05:51:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][700/703]	Step 26044	lr 0.01811	Loss 14.2024 (15.0527)	Hard Loss 0.8908 (0.9468)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (71.6%, 94.0%)	
07/26 05:51:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [36][703/703]	Step 26047	lr 0.01811	Loss 19.5601 (15.0584)	Hard Loss 1.2425 (0.9472)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (71.6%, 94.0%)	
07/26 05:51:13午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 36/99] Final Prec@1 71.5489%
07/26 05:51:16午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 36/99] Final Prec@1 58.2600%
07/26 05:51:16午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 58.8600%
07/26 05:51:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][50/703]	Step 26098	lr 0.01777	Loss 9.5911 (13.0638)	Hard Loss 0.5821 (0.8145)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (75.0%, 95.4%)	
07/26 05:51:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][100/703]	Step 26148	lr 0.01777	Loss 18.7408 (13.4885)	Hard Loss 1.1882 (0.8428)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (74.1%, 95.3%)	
07/26 05:51:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][150/703]	Step 26198	lr 0.01777	Loss 17.3139 (13.6790)	Hard Loss 1.0967 (0.8555)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (73.9%, 95.1%)	
07/26 05:51:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][200/703]	Step 26248	lr 0.01777	Loss 14.4731 (13.6440)	Hard Loss 0.9032 (0.8533)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (74.2%, 95.1%)	
07/26 05:52:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][250/703]	Step 26298	lr 0.01777	Loss 14.7884 (13.8554)	Hard Loss 0.9247 (0.8675)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (73.9%, 94.9%)	
07/26 05:52:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][300/703]	Step 26348	lr 0.01777	Loss 14.5155 (13.8866)	Hard Loss 0.9093 (0.8696)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (73.7%, 94.9%)	
07/26 05:52:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][350/703]	Step 26398	lr 0.01777	Loss 20.6637 (13.9481)	Hard Loss 1.3062 (0.8737)	Soft Loss 0.0025 (0.0025)	Prec@(1,5) (73.5%, 94.9%)	
07/26 05:52:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][400/703]	Step 26448	lr 0.01777	Loss 15.5841 (14.0626)	Hard Loss 0.9812 (0.8812)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.4%, 94.8%)	
07/26 05:52:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][450/703]	Step 26498	lr 0.01777	Loss 20.3830 (14.2030)	Hard Loss 1.2928 (0.8905)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.1%, 94.7%)	
07/26 05:52:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][500/703]	Step 26548	lr 0.01777	Loss 16.1115 (14.2822)	Hard Loss 1.0127 (0.8957)	Soft Loss 0.0022 (0.0026)	Prec@(1,5) (72.9%, 94.6%)	
07/26 05:53:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][550/703]	Step 26598	lr 0.01777	Loss 15.1622 (14.3614)	Hard Loss 0.9583 (0.9009)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (72.9%, 94.6%)	
07/26 05:53:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][600/703]	Step 26648	lr 0.01777	Loss 9.2705 (14.4515)	Hard Loss 0.5710 (0.9070)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (72.7%, 94.5%)	
07/26 05:53:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][650/703]	Step 26698	lr 0.01777	Loss 19.3880 (14.5872)	Hard Loss 1.2267 (0.9159)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (72.5%, 94.4%)	
07/26 05:53:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][700/703]	Step 26748	lr 0.01777	Loss 16.6024 (14.6661)	Hard Loss 1.0475 (0.9211)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (72.4%, 94.3%)	
07/26 05:53:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [37][703/703]	Step 26751	lr 0.01777	Loss 16.9534 (14.6586)	Hard Loss 1.0691 (0.9206)	Soft Loss 0.0022 (0.0026)	Prec@(1,5) (72.4%, 94.3%)	
07/26 05:53:28午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 37/99] Final Prec@1 72.3511%
07/26 05:53:32午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 37/99] Final Prec@1 58.6800%
07/26 05:53:32午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 58.8600%
07/26 05:53:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][50/703]	Step 26802	lr 0.01742	Loss 14.3076 (13.2251)	Hard Loss 0.8937 (0.8257)	Soft Loss 0.0022 (0.0025)	Prec@(1,5) (74.7%, 95.3%)	
07/26 05:53:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][100/703]	Step 26852	lr 0.01742	Loss 18.4942 (13.2960)	Hard Loss 1.1723 (0.8306)	Soft Loss 0.0024 (0.0025)	Prec@(1,5) (75.0%, 95.4%)	
07/26 05:54:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][150/703]	Step 26902	lr 0.01742	Loss 8.7394 (13.5226)	Hard Loss 0.5382 (0.8455)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.4%, 95.1%)	
07/26 05:54:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][200/703]	Step 26952	lr 0.01742	Loss 10.9682 (13.6759)	Hard Loss 0.6847 (0.8556)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (74.3%, 94.9%)	
07/26 05:54:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][250/703]	Step 27002	lr 0.01742	Loss 11.9811 (13.7525)	Hard Loss 0.7437 (0.8607)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (74.1%, 94.9%)	
07/26 05:54:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][300/703]	Step 27052	lr 0.01742	Loss 12.1982 (13.9079)	Hard Loss 0.7612 (0.8711)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (73.8%, 94.8%)	
07/26 05:54:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][350/703]	Step 27102	lr 0.01742	Loss 14.6593 (14.0505)	Hard Loss 0.9181 (0.8806)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.4%, 94.6%)	
07/26 05:54:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][400/703]	Step 27152	lr 0.01742	Loss 17.5468 (14.0931)	Hard Loss 1.1126 (0.8833)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (73.4%, 94.6%)	
07/26 05:54:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][450/703]	Step 27202	lr 0.01742	Loss 9.9738 (14.1051)	Hard Loss 0.6145 (0.8841)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.5%, 94.6%)	
07/26 05:55:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][500/703]	Step 27252	lr 0.01742	Loss 17.7307 (14.2254)	Hard Loss 1.1207 (0.8921)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.3%, 94.4%)	
07/26 05:55:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][550/703]	Step 27302	lr 0.01742	Loss 18.5696 (14.2789)	Hard Loss 1.1713 (0.8956)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.2%, 94.4%)	
07/26 05:55:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][600/703]	Step 27352	lr 0.01742	Loss 14.7267 (14.3104)	Hard Loss 0.9269 (0.8977)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (73.2%, 94.4%)	
07/26 05:55:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][650/703]	Step 27402	lr 0.01742	Loss 13.9190 (14.3516)	Hard Loss 0.8756 (0.9004)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.1%, 94.3%)	
07/26 05:55:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][700/703]	Step 27452	lr 0.01742	Loss 15.5129 (14.4022)	Hard Loss 0.9768 (0.9037)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (73.0%, 94.3%)	
07/26 05:55:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [38][703/703]	Step 27455	lr 0.01742	Loss 15.2505 (14.4038)	Hard Loss 0.9560 (0.9038)	Soft Loss 0.0021 (0.0026)	Prec@(1,5) (73.0%, 94.3%)	
07/26 05:55:44午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 38/99] Final Prec@1 72.9844%
07/26 05:55:47午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 38/99] Final Prec@1 59.4600%
07/26 05:55:48午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 59.4600%
07/26 05:55:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][50/703]	Step 27506	lr 0.01706	Loss 13.5023 (13.5540)	Hard Loss 0.8464 (0.8465)	Soft Loss 0.0026 (0.0025)	Prec@(1,5) (74.3%, 95.2%)	
07/26 05:56:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][100/703]	Step 27556	lr 0.01706	Loss 14.5234 (13.2183)	Hard Loss 0.9075 (0.8248)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (75.3%, 95.4%)	
07/26 05:56:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][150/703]	Step 27606	lr 0.01706	Loss 14.0078 (13.2944)	Hard Loss 0.8737 (0.8299)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (75.2%, 95.4%)	
07/26 05:56:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][200/703]	Step 27656	lr 0.01706	Loss 15.1272 (13.4588)	Hard Loss 0.9487 (0.8408)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (74.9%, 95.2%)	
07/26 05:56:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][250/703]	Step 27706	lr 0.01706	Loss 13.4523 (13.4863)	Hard Loss 0.8366 (0.8427)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (74.7%, 95.2%)	
07/26 05:56:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][300/703]	Step 27756	lr 0.01706	Loss 9.0869 (13.5379)	Hard Loss 0.5523 (0.8463)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (74.6%, 95.2%)	
07/26 05:56:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][350/703]	Step 27806	lr 0.01706	Loss 11.9681 (13.6386)	Hard Loss 0.7454 (0.8529)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.3%, 95.0%)	
07/26 05:57:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][400/703]	Step 27856	lr 0.01706	Loss 19.4952 (13.7735)	Hard Loss 1.2390 (0.8617)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (74.1%, 95.0%)	
07/26 05:57:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][450/703]	Step 27906	lr 0.01706	Loss 13.5296 (13.8021)	Hard Loss 0.8441 (0.8637)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (74.0%, 94.9%)	
07/26 05:57:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][500/703]	Step 27956	lr 0.01706	Loss 14.9091 (13.9070)	Hard Loss 0.9426 (0.8706)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (73.8%, 94.8%)	
07/26 05:57:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][550/703]	Step 28006	lr 0.01706	Loss 15.1096 (13.9889)	Hard Loss 0.9476 (0.8760)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (73.6%, 94.7%)	
07/26 05:57:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][600/703]	Step 28056	lr 0.01706	Loss 9.9629 (13.9774)	Hard Loss 0.6174 (0.8754)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (73.6%, 94.8%)	
07/26 05:57:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][650/703]	Step 28106	lr 0.01706	Loss 14.6136 (13.9771)	Hard Loss 0.9119 (0.8754)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (73.6%, 94.8%)	
07/26 05:57:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][700/703]	Step 28156	lr 0.01706	Loss 15.2919 (14.0588)	Hard Loss 0.9555 (0.8808)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (73.4%, 94.7%)	
07/26 05:58:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [39][703/703]	Step 28159	lr 0.01706	Loss 16.2798 (14.0650)	Hard Loss 1.0278 (0.8812)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (73.4%, 94.7%)	
07/26 05:58:00午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 39/99] Final Prec@1 73.3800%
07/26 05:58:03午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 39/99] Final Prec@1 57.7600%
07/26 05:58:03午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 59.4600%
07/26 05:58:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][50/703]	Step 28210	lr 0.01671	Loss 11.7902 (13.1024)	Hard Loss 0.7328 (0.8179)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.6%, 95.2%)	
07/26 05:58:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][100/703]	Step 28260	lr 0.01671	Loss 16.2715 (12.8496)	Hard Loss 1.0265 (0.8009)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (75.5%, 95.2%)	
07/26 05:58:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][150/703]	Step 28310	lr 0.01671	Loss 14.0417 (12.8479)	Hard Loss 0.8799 (0.8007)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (75.6%, 95.4%)	
07/26 05:58:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][200/703]	Step 28360	lr 0.01671	Loss 18.9331 (12.9645)	Hard Loss 1.1929 (0.8086)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (75.3%, 95.4%)	
07/26 05:58:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][250/703]	Step 28410	lr 0.01671	Loss 13.1689 (13.0212)	Hard Loss 0.8195 (0.8124)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (75.4%, 95.4%)	
07/26 05:59:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][300/703]	Step 28460	lr 0.01671	Loss 14.7357 (13.2037)	Hard Loss 0.9245 (0.8244)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.2%, 95.3%)	
07/26 05:59:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][350/703]	Step 28510	lr 0.01671	Loss 12.5079 (13.1909)	Hard Loss 0.7794 (0.8236)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (75.1%, 95.4%)	
07/26 05:59:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][400/703]	Step 28560	lr 0.01671	Loss 21.3288 (13.2788)	Hard Loss 1.3621 (0.8293)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.0%, 95.3%)	
07/26 05:59:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][450/703]	Step 28610	lr 0.01671	Loss 14.6012 (13.4432)	Hard Loss 0.9160 (0.8401)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (74.7%, 95.1%)	
07/26 05:59:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][500/703]	Step 28660	lr 0.01671	Loss 20.0027 (13.5211)	Hard Loss 1.2730 (0.8452)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.5%, 95.2%)	
07/26 05:59:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][550/703]	Step 28710	lr 0.01671	Loss 13.2192 (13.6490)	Hard Loss 0.8286 (0.8535)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (74.4%, 95.0%)	
07/26 05:59:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][600/703]	Step 28760	lr 0.01671	Loss 15.2840 (13.7396)	Hard Loss 0.9611 (0.8596)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (74.2%, 95.0%)	
07/26 06:00:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][650/703]	Step 28810	lr 0.01671	Loss 13.1312 (13.7913)	Hard Loss 0.8179 (0.8630)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (74.1%, 94.9%)	
07/26 06:00:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][700/703]	Step 28860	lr 0.01671	Loss 13.8318 (13.8550)	Hard Loss 0.8675 (0.8673)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.9%, 94.9%)	
07/26 06:00:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [40][703/703]	Step 28863	lr 0.01671	Loss 15.1610 (13.8729)	Hard Loss 0.9532 (0.8684)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (73.9%, 94.9%)	
07/26 06:00:15午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 40/99] Final Prec@1 73.8711%
07/26 06:00:19午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 40/99] Final Prec@1 59.1400%
07/26 06:00:19午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 59.4600%
07/26 06:00:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][50/703]	Step 28914	lr 0.01635	Loss 10.0520 (12.7767)	Hard Loss 0.6091 (0.7961)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (75.8%, 95.9%)	
07/26 06:00:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][100/703]	Step 28964	lr 0.01635	Loss 10.3795 (12.7449)	Hard Loss 0.6362 (0.7940)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (76.0%, 95.7%)	
07/26 06:00:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][150/703]	Step 29014	lr 0.01635	Loss 14.6576 (12.6449)	Hard Loss 0.9222 (0.7877)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.8%, 95.6%)	
07/26 06:00:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][200/703]	Step 29064	lr 0.01635	Loss 14.8231 (12.7601)	Hard Loss 0.9279 (0.7953)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (75.6%, 95.5%)	
07/26 06:01:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][250/703]	Step 29114	lr 0.01635	Loss 10.1470 (12.7797)	Hard Loss 0.6286 (0.7965)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.7%, 95.4%)	
07/26 06:01:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][300/703]	Step 29164	lr 0.01635	Loss 12.9820 (12.8242)	Hard Loss 0.8124 (0.7995)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (75.5%, 95.4%)	
07/26 06:01:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][350/703]	Step 29214	lr 0.01635	Loss 14.8958 (12.9110)	Hard Loss 0.9322 (0.8051)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.4%, 95.4%)	
07/26 06:01:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][400/703]	Step 29264	lr 0.01635	Loss 13.6992 (13.0503)	Hard Loss 0.8531 (0.8142)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (75.1%, 95.3%)	
07/26 06:01:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][450/703]	Step 29314	lr 0.01635	Loss 14.4977 (13.1658)	Hard Loss 0.9109 (0.8218)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (74.9%, 95.3%)	
07/26 06:01:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][500/703]	Step 29364	lr 0.01635	Loss 12.6240 (13.3272)	Hard Loss 0.7911 (0.8324)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (74.7%, 95.1%)	
07/26 06:02:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][550/703]	Step 29414	lr 0.01635	Loss 20.4985 (13.4012)	Hard Loss 1.3024 (0.8373)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (74.6%, 95.1%)	
07/26 06:02:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][600/703]	Step 29464	lr 0.01635	Loss 14.7025 (13.4325)	Hard Loss 0.9261 (0.8394)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.6%, 95.1%)	
07/26 06:02:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][650/703]	Step 29514	lr 0.01635	Loss 13.4383 (13.4652)	Hard Loss 0.8467 (0.8416)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (74.5%, 95.1%)	
07/26 06:02:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][700/703]	Step 29564	lr 0.01635	Loss 15.4575 (13.4937)	Hard Loss 0.9799 (0.8435)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (74.4%, 95.0%)	
07/26 06:02:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [41][703/703]	Step 29567	lr 0.01635	Loss 14.4815 (13.5011)	Hard Loss 0.9128 (0.8440)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.4%, 95.0%)	
07/26 06:02:31午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 41/99] Final Prec@1 74.4467%
07/26 06:02:34午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 41/99] Final Prec@1 59.0400%
07/26 06:02:34午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 59.4600%
07/26 06:02:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][50/703]	Step 29618	lr 0.01598	Loss 10.9504 (12.0645)	Hard Loss 0.6742 (0.7481)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (77.5%, 95.8%)	
07/26 06:02:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][100/703]	Step 29668	lr 0.01598	Loss 12.7017 (11.9170)	Hard Loss 0.7882 (0.7385)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (77.6%, 96.2%)	
07/26 06:03:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][150/703]	Step 29718	lr 0.01598	Loss 16.5240 (12.2602)	Hard Loss 1.0388 (0.7611)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (77.0%, 95.8%)	
07/26 06:03:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][200/703]	Step 29768	lr 0.01598	Loss 14.0941 (12.4400)	Hard Loss 0.8812 (0.7729)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (76.7%, 95.7%)	
07/26 06:03:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][250/703]	Step 29818	lr 0.01598	Loss 14.1125 (12.6302)	Hard Loss 0.8856 (0.7855)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (76.3%, 95.5%)	
07/26 06:03:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][300/703]	Step 29868	lr 0.01598	Loss 13.8558 (12.6690)	Hard Loss 0.8726 (0.7882)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (76.1%, 95.6%)	
07/26 06:03:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][350/703]	Step 29918	lr 0.01598	Loss 20.7021 (12.8082)	Hard Loss 1.3175 (0.7976)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (75.8%, 95.5%)	
07/26 06:03:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][400/703]	Step 29968	lr 0.01598	Loss 13.1398 (12.8458)	Hard Loss 0.8191 (0.8003)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.7%, 95.6%)	
07/26 06:03:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][450/703]	Step 30018	lr 0.01598	Loss 11.6791 (12.9908)	Hard Loss 0.7261 (0.8099)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (75.4%, 95.5%)	
07/26 06:04:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][500/703]	Step 30068	lr 0.01598	Loss 12.6093 (13.0519)	Hard Loss 0.7852 (0.8140)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (75.3%, 95.4%)	
07/26 06:04:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][550/703]	Step 30118	lr 0.01598	Loss 15.2532 (13.1098)	Hard Loss 0.9626 (0.8179)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (75.2%, 95.4%)	
07/26 06:04:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][600/703]	Step 30168	lr 0.01598	Loss 16.8551 (13.1598)	Hard Loss 1.0642 (0.8213)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (75.1%, 95.4%)	
07/26 06:04:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][650/703]	Step 30218	lr 0.01598	Loss 16.3914 (13.2244)	Hard Loss 1.0337 (0.8256)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.0%, 95.4%)	
07/26 06:04:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][700/703]	Step 30268	lr 0.01598	Loss 13.1534 (13.3085)	Hard Loss 0.8222 (0.8312)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (74.8%, 95.3%)	
07/26 06:04:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [42][703/703]	Step 30271	lr 0.01598	Loss 12.5354 (13.3158)	Hard Loss 0.7788 (0.8317)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (74.8%, 95.3%)	
07/26 06:04:47午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 42/99] Final Prec@1 74.8178%
07/26 06:04:50午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 42/99] Final Prec@1 58.1000%
07/26 06:04:50午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 59.4600%
07/26 06:05:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][50/703]	Step 30322	lr 0.01562	Loss 12.7423 (12.6997)	Hard Loss 0.7861 (0.7897)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (75.5%, 95.9%)	
07/26 06:05:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][100/703]	Step 30372	lr 0.01562	Loss 13.4740 (12.3577)	Hard Loss 0.8415 (0.7677)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (76.4%, 95.8%)	
07/26 06:05:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][150/703]	Step 30422	lr 0.01562	Loss 13.5567 (12.5147)	Hard Loss 0.8496 (0.7781)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (76.1%, 95.6%)	
07/26 06:05:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][200/703]	Step 30472	lr 0.01562	Loss 14.8568 (12.5092)	Hard Loss 0.9306 (0.7779)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (76.3%, 95.6%)	
07/26 06:05:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][250/703]	Step 30522	lr 0.01562	Loss 13.9742 (12.5029)	Hard Loss 0.8750 (0.7774)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (76.4%, 95.7%)	
07/26 06:05:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][300/703]	Step 30572	lr 0.01562	Loss 11.7192 (12.6852)	Hard Loss 0.7282 (0.7895)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (76.1%, 95.6%)	
07/26 06:05:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][350/703]	Step 30622	lr 0.01562	Loss 6.5661 (12.7130)	Hard Loss 0.3834 (0.7914)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (76.0%, 95.6%)	
07/26 06:06:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][400/703]	Step 30672	lr 0.01562	Loss 13.5980 (12.7726)	Hard Loss 0.8440 (0.7953)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (75.9%, 95.6%)	
07/26 06:06:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][450/703]	Step 30722	lr 0.01562	Loss 16.5637 (12.8430)	Hard Loss 1.0463 (0.7999)	Soft Loss 0.0030 (0.0026)	Prec@(1,5) (75.7%, 95.6%)	
07/26 06:06:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][500/703]	Step 30772	lr 0.01562	Loss 12.6775 (12.8989)	Hard Loss 0.7935 (0.8036)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (75.7%, 95.5%)	
07/26 06:06:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][550/703]	Step 30822	lr 0.01562	Loss 12.2616 (12.9004)	Hard Loss 0.7675 (0.8038)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (75.6%, 95.5%)	
07/26 06:06:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][600/703]	Step 30872	lr 0.01562	Loss 13.5862 (12.9576)	Hard Loss 0.8454 (0.8076)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (75.5%, 95.5%)	
07/26 06:06:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][650/703]	Step 30922	lr 0.01562	Loss 10.8669 (12.9817)	Hard Loss 0.6658 (0.8093)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (75.5%, 95.4%)	
07/26 06:07:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][700/703]	Step 30972	lr 0.01562	Loss 13.8302 (13.0180)	Hard Loss 0.8669 (0.8118)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (75.4%, 95.4%)	
07/26 06:07:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [43][703/703]	Step 30975	lr 0.01562	Loss 14.9255 (13.0249)	Hard Loss 0.9360 (0.8122)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (75.4%, 95.4%)	
07/26 06:07:02午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 43/99] Final Prec@1 75.4378%
07/26 06:07:06午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 43/99] Final Prec@1 60.8000%
07/26 06:07:06午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 60.8000%
07/26 06:07:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][50/703]	Step 31026	lr 0.01525	Loss 10.8562 (12.0061)	Hard Loss 0.6584 (0.7449)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (77.1%, 96.6%)	
07/26 06:07:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][100/703]	Step 31076	lr 0.01525	Loss 14.7343 (12.1631)	Hard Loss 0.9242 (0.7548)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (77.2%, 96.4%)	
07/26 06:07:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][150/703]	Step 31126	lr 0.01525	Loss 11.3788 (12.0663)	Hard Loss 0.7030 (0.7481)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (77.4%, 96.3%)	
07/26 06:07:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][200/703]	Step 31176	lr 0.01525	Loss 13.7744 (12.1047)	Hard Loss 0.8659 (0.7508)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (77.2%, 96.3%)	
07/26 06:07:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][250/703]	Step 31226	lr 0.01525	Loss 7.7879 (12.1867)	Hard Loss 0.4667 (0.7563)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (77.2%, 96.2%)	
07/26 06:08:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][300/703]	Step 31276	lr 0.01525	Loss 17.7036 (12.3277)	Hard Loss 1.1229 (0.7656)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (76.8%, 96.1%)	
07/26 06:08:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][350/703]	Step 31326	lr 0.01525	Loss 15.8094 (12.3760)	Hard Loss 1.0003 (0.7689)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (76.8%, 96.0%)	
07/26 06:08:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][400/703]	Step 31376	lr 0.01525	Loss 16.5013 (12.5108)	Hard Loss 1.0337 (0.7778)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (76.5%, 95.9%)	
07/26 06:08:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][450/703]	Step 31426	lr 0.01525	Loss 16.0722 (12.5544)	Hard Loss 1.0138 (0.7808)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (76.4%, 95.9%)	
07/26 06:08:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][500/703]	Step 31476	lr 0.01525	Loss 12.1459 (12.6659)	Hard Loss 0.7548 (0.7883)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (76.1%, 95.8%)	
07/26 06:08:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][550/703]	Step 31526	lr 0.01525	Loss 11.2352 (12.7104)	Hard Loss 0.7004 (0.7913)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (76.0%, 95.8%)	
07/26 06:08:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][600/703]	Step 31576	lr 0.01525	Loss 14.1834 (12.7409)	Hard Loss 0.8891 (0.7933)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (75.9%, 95.8%)	
07/26 06:09:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][650/703]	Step 31626	lr 0.01525	Loss 15.1792 (12.7764)	Hard Loss 0.9512 (0.7958)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.8%, 95.7%)	
07/26 06:09:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][700/703]	Step 31676	lr 0.01525	Loss 14.7116 (12.8339)	Hard Loss 0.9283 (0.7996)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (75.7%, 95.7%)	
07/26 06:09:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [44][703/703]	Step 31679	lr 0.01525	Loss 11.3070 (12.8341)	Hard Loss 0.7041 (0.7996)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (75.7%, 95.7%)	
07/26 06:09:18午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 44/99] Final Prec@1 75.7356%
07/26 06:09:21午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 44/99] Final Prec@1 59.5600%
07/26 06:09:22午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 60.8000%
07/26 06:09:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][50/703]	Step 31730	lr 0.01488	Loss 6.6821 (11.3641)	Hard Loss 0.4010 (0.7026)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (78.0%, 96.5%)	
07/26 06:09:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][100/703]	Step 31780	lr 0.01488	Loss 13.8026 (11.3685)	Hard Loss 0.8606 (0.7034)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (78.1%, 96.7%)	
07/26 06:09:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][150/703]	Step 31830	lr 0.01488	Loss 9.8648 (11.5463)	Hard Loss 0.6070 (0.7146)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (77.9%, 96.7%)	
07/26 06:09:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][200/703]	Step 31880	lr 0.01488	Loss 10.7555 (11.7843)	Hard Loss 0.6574 (0.7301)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (77.5%, 96.5%)	
07/26 06:10:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][250/703]	Step 31930	lr 0.01488	Loss 12.3217 (11.9533)	Hard Loss 0.7616 (0.7412)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (77.4%, 96.4%)	
07/26 06:10:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][300/703]	Step 31980	lr 0.01488	Loss 16.2193 (12.0775)	Hard Loss 1.0244 (0.7493)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (77.1%, 96.3%)	
07/26 06:10:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][350/703]	Step 32030	lr 0.01488	Loss 15.3743 (12.1995)	Hard Loss 0.9678 (0.7572)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (77.0%, 96.2%)	
07/26 06:10:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][400/703]	Step 32080	lr 0.01488	Loss 11.3145 (12.2608)	Hard Loss 0.7035 (0.7614)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (77.0%, 96.1%)	
07/26 06:10:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][450/703]	Step 32130	lr 0.01488	Loss 13.0739 (12.2978)	Hard Loss 0.8121 (0.7638)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (76.9%, 96.1%)	
07/26 06:10:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][500/703]	Step 32180	lr 0.01488	Loss 11.2463 (12.3329)	Hard Loss 0.6974 (0.7661)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (76.9%, 96.0%)	
07/26 06:11:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][550/703]	Step 32230	lr 0.01488	Loss 14.0306 (12.3406)	Hard Loss 0.8785 (0.7667)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (76.9%, 96.0%)	
07/26 06:11:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][600/703]	Step 32280	lr 0.01488	Loss 8.4875 (12.4081)	Hard Loss 0.5203 (0.7712)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (76.7%, 96.0%)	
07/26 06:11:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][650/703]	Step 32330	lr 0.01488	Loss 11.7933 (12.4216)	Hard Loss 0.7319 (0.7722)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (76.6%, 96.0%)	
07/26 06:11:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][700/703]	Step 32380	lr 0.01488	Loss 20.4759 (12.5111)	Hard Loss 1.2989 (0.7782)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (76.4%, 95.9%)	
07/26 06:11:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [45][703/703]	Step 32383	lr 0.01488	Loss 16.6761 (12.5201)	Hard Loss 1.0435 (0.7787)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (76.4%, 95.9%)	
07/26 06:11:34午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 45/99] Final Prec@1 76.3800%
07/26 06:11:37午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 45/99] Final Prec@1 60.7600%
07/26 06:11:37午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 60.8000%
07/26 06:11:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][50/703]	Step 32434	lr 0.0145	Loss 12.8446 (11.1790)	Hard Loss 0.7982 (0.6905)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (78.6%, 96.7%)	
07/26 06:11:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][100/703]	Step 32484	lr 0.0145	Loss 8.9565 (11.2957)	Hard Loss 0.5409 (0.6976)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (78.1%, 96.6%)	
07/26 06:12:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][150/703]	Step 32534	lr 0.0145	Loss 13.9382 (11.4102)	Hard Loss 0.8689 (0.7049)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (78.0%, 96.6%)	
07/26 06:12:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][200/703]	Step 32584	lr 0.0145	Loss 13.2180 (11.5973)	Hard Loss 0.8205 (0.7175)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (77.7%, 96.4%)	
07/26 06:12:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][250/703]	Step 32634	lr 0.0145	Loss 13.2103 (11.5436)	Hard Loss 0.8206 (0.7141)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (77.9%, 96.4%)	
07/26 06:12:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][300/703]	Step 32684	lr 0.0145	Loss 10.2975 (11.6420)	Hard Loss 0.6362 (0.7206)	Soft Loss 0.0024 (0.0026)	Prec@(1,5) (77.7%, 96.4%)	
07/26 06:12:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][350/703]	Step 32734	lr 0.0145	Loss 13.0130 (11.7530)	Hard Loss 0.8043 (0.7280)	Soft Loss 0.0027 (0.0026)	Prec@(1,5) (77.5%, 96.3%)	
07/26 06:12:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][400/703]	Step 32784	lr 0.0145	Loss 12.7813 (11.7761)	Hard Loss 0.7964 (0.7294)	Soft Loss 0.0028 (0.0026)	Prec@(1,5) (77.4%, 96.3%)	
07/26 06:13:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][450/703]	Step 32834	lr 0.0145	Loss 15.2880 (11.8982)	Hard Loss 0.9622 (0.7375)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (77.1%, 96.2%)	
07/26 06:13:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][500/703]	Step 32884	lr 0.0145	Loss 14.2767 (11.9780)	Hard Loss 0.8897 (0.7428)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (77.0%, 96.2%)	
07/26 06:13:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][550/703]	Step 32934	lr 0.0145	Loss 14.9965 (12.0562)	Hard Loss 0.9408 (0.7480)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (76.9%, 96.2%)	
07/26 06:13:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][600/703]	Step 32984	lr 0.0145	Loss 9.3605 (12.0896)	Hard Loss 0.5721 (0.7502)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (76.8%, 96.2%)	
07/26 06:13:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][650/703]	Step 33034	lr 0.0145	Loss 11.9041 (12.1195)	Hard Loss 0.7313 (0.7523)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (76.7%, 96.2%)	
07/26 06:13:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][700/703]	Step 33084	lr 0.0145	Loss 13.3815 (12.2120)	Hard Loss 0.8345 (0.7584)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (76.6%, 96.1%)	
07/26 06:13:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [46][703/703]	Step 33087	lr 0.0145	Loss 9.9692 (12.2198)	Hard Loss 0.6083 (0.7589)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (76.6%, 96.1%)	
07/26 06:13:50午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 46/99] Final Prec@1 76.5844%
07/26 06:13:53午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 46/99] Final Prec@1 60.2800%
07/26 06:13:53午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 60.8000%
07/26 06:14:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][50/703]	Step 33138	lr 0.01413	Loss 11.3519 (11.4004)	Hard Loss 0.7082 (0.7048)	Soft Loss 0.0026 (0.0026)	Prec@(1,5) (77.2%, 97.1%)	
07/26 06:14:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][100/703]	Step 33188	lr 0.01413	Loss 12.8904 (11.2650)	Hard Loss 0.7963 (0.6958)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (78.2%, 96.8%)	
07/26 06:14:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][150/703]	Step 33238	lr 0.01413	Loss 9.8833 (11.2094)	Hard Loss 0.6053 (0.6921)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (78.5%, 96.7%)	
07/26 06:14:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][200/703]	Step 33288	lr 0.01413	Loss 9.4435 (11.2806)	Hard Loss 0.5772 (0.6968)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (78.3%, 96.6%)	
07/26 06:14:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][250/703]	Step 33338	lr 0.01413	Loss 11.2984 (11.3527)	Hard Loss 0.6943 (0.7015)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (78.2%, 96.6%)	
07/26 06:14:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][300/703]	Step 33388	lr 0.01413	Loss 8.8519 (11.5060)	Hard Loss 0.5365 (0.7114)	Soft Loss 0.0024 (0.0027)	Prec@(1,5) (77.9%, 96.4%)	
07/26 06:14:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][350/703]	Step 33438	lr 0.01413	Loss 13.3685 (11.5180)	Hard Loss 0.8344 (0.7123)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (77.7%, 96.5%)	
07/26 06:15:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][400/703]	Step 33488	lr 0.01413	Loss 10.0550 (11.5482)	Hard Loss 0.6091 (0.7144)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (77.8%, 96.6%)	
07/26 06:15:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][450/703]	Step 33538	lr 0.01413	Loss 15.2862 (11.6504)	Hard Loss 0.9633 (0.7211)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (77.7%, 96.5%)	
07/26 06:15:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][500/703]	Step 33588	lr 0.01413	Loss 13.4189 (11.6362)	Hard Loss 0.8345 (0.7202)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (77.8%, 96.5%)	
07/26 06:15:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][550/703]	Step 33638	lr 0.01413	Loss 15.4751 (11.6716)	Hard Loss 0.9756 (0.7227)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (77.7%, 96.4%)	
07/26 06:15:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][600/703]	Step 33688	lr 0.01413	Loss 13.9527 (11.7294)	Hard Loss 0.8768 (0.7264)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (77.6%, 96.3%)	
07/26 06:15:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][650/703]	Step 33738	lr 0.01413	Loss 10.4005 (11.8502)	Hard Loss 0.6433 (0.7343)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (77.4%, 96.3%)	
07/26 06:16:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][700/703]	Step 33788	lr 0.01413	Loss 11.8457 (11.8795)	Hard Loss 0.7352 (0.7362)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (77.3%, 96.3%)	
07/26 06:16:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [47][703/703]	Step 33791	lr 0.01413	Loss 16.7563 (11.8877)	Hard Loss 1.0527 (0.7368)	Soft Loss 0.0031 (0.0027)	Prec@(1,5) (77.3%, 96.3%)	
07/26 06:16:05午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 47/99] Final Prec@1 77.2978%
07/26 06:16:09午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 47/99] Final Prec@1 60.0800%
07/26 06:16:09午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 60.8000%
07/26 06:16:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][50/703]	Step 33842	lr 0.01375	Loss 11.1652 (10.5925)	Hard Loss 0.6868 (0.6507)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.9%, 96.8%)	
07/26 06:16:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][100/703]	Step 33892	lr 0.01375	Loss 11.9649 (10.6817)	Hard Loss 0.7382 (0.6564)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (80.0%, 96.9%)	
07/26 06:16:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][150/703]	Step 33942	lr 0.01375	Loss 16.1362 (10.7707)	Hard Loss 1.0124 (0.6624)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (80.0%, 96.9%)	
07/26 06:16:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][200/703]	Step 33992	lr 0.01375	Loss 12.1937 (11.0027)	Hard Loss 0.7567 (0.6777)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (79.2%, 96.9%)	
07/26 06:16:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][250/703]	Step 34042	lr 0.01375	Loss 10.1745 (11.0512)	Hard Loss 0.6236 (0.6811)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.1%, 96.7%)	
07/26 06:17:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][300/703]	Step 34092	lr 0.01375	Loss 12.6399 (11.1036)	Hard Loss 0.7824 (0.6848)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (79.0%, 96.8%)	
07/26 06:17:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][350/703]	Step 34142	lr 0.01375	Loss 11.1457 (11.2114)	Hard Loss 0.6899 (0.6918)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (78.8%, 96.7%)	
07/26 06:17:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][400/703]	Step 34192	lr 0.01375	Loss 12.2960 (11.3354)	Hard Loss 0.7695 (0.7001)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (78.5%, 96.7%)	
07/26 06:17:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][450/703]	Step 34242	lr 0.01375	Loss 8.2910 (11.4388)	Hard Loss 0.5009 (0.7068)	Soft Loss 0.0024 (0.0027)	Prec@(1,5) (78.2%, 96.5%)	
07/26 06:17:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][500/703]	Step 34292	lr 0.01375	Loss 10.6668 (11.5200)	Hard Loss 0.6620 (0.7122)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (78.0%, 96.5%)	
07/26 06:17:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][550/703]	Step 34342	lr 0.01375	Loss 11.3167 (11.6113)	Hard Loss 0.7011 (0.7183)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (77.8%, 96.5%)	
07/26 06:18:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][600/703]	Step 34392	lr 0.01375	Loss 10.5947 (11.6563)	Hard Loss 0.6505 (0.7213)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (77.7%, 96.5%)	
07/26 06:18:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][650/703]	Step 34442	lr 0.01375	Loss 9.0391 (11.7053)	Hard Loss 0.5446 (0.7246)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (77.7%, 96.4%)	
07/26 06:18:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][700/703]	Step 34492	lr 0.01375	Loss 13.6613 (11.7381)	Hard Loss 0.8555 (0.7268)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (77.6%, 96.4%)	
07/26 06:18:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [48][703/703]	Step 34495	lr 0.01375	Loss 14.0320 (11.7431)	Hard Loss 0.8826 (0.7272)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (77.6%, 96.4%)	
07/26 06:18:21午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 48/99] Final Prec@1 77.5978%
07/26 06:18:24午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 48/99] Final Prec@1 61.0600%
07/26 06:18:25午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 61.0600%
07/26 06:18:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][50/703]	Step 34546	lr 0.01338	Loss 11.1654 (10.6917)	Hard Loss 0.6930 (0.6580)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (80.2%, 97.1%)	
07/26 06:18:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][100/703]	Step 34596	lr 0.01338	Loss 6.9139 (10.5968)	Hard Loss 0.4150 (0.6516)	Soft Loss 0.0033 (0.0027)	Prec@(1,5) (79.8%, 97.2%)	
07/26 06:18:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][150/703]	Step 34646	lr 0.01338	Loss 8.0760 (10.5446)	Hard Loss 0.4827 (0.6480)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.9%, 97.3%)	
07/26 06:19:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][200/703]	Step 34696	lr 0.01338	Loss 13.6052 (10.7726)	Hard Loss 0.8487 (0.6630)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.6%, 97.2%)	
07/26 06:19:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][250/703]	Step 34746	lr 0.01338	Loss 11.5070 (10.9241)	Hard Loss 0.7088 (0.6729)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (79.2%, 97.1%)	
07/26 06:19:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][300/703]	Step 34796	lr 0.01338	Loss 11.1639 (10.9238)	Hard Loss 0.6886 (0.6730)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.2%, 97.0%)	
07/26 06:19:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][350/703]	Step 34846	lr 0.01338	Loss 12.3104 (11.0913)	Hard Loss 0.7588 (0.6840)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (78.9%, 97.0%)	
07/26 06:19:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][400/703]	Step 34896	lr 0.01338	Loss 8.1881 (11.1161)	Hard Loss 0.4956 (0.6857)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (78.9%, 96.9%)	
07/26 06:19:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][450/703]	Step 34946	lr 0.01338	Loss 12.5363 (11.1218)	Hard Loss 0.7872 (0.6861)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (78.9%, 96.9%)	
07/26 06:19:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][500/703]	Step 34996	lr 0.01338	Loss 13.9171 (11.1334)	Hard Loss 0.8662 (0.6868)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (78.9%, 96.9%)	
07/26 06:20:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][550/703]	Step 35046	lr 0.01338	Loss 18.1040 (11.1904)	Hard Loss 1.1419 (0.6907)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (78.8%, 96.9%)	
07/26 06:20:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][600/703]	Step 35096	lr 0.01338	Loss 13.6086 (11.2713)	Hard Loss 0.8530 (0.6960)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (78.7%, 96.8%)	
07/26 06:20:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][650/703]	Step 35146	lr 0.01338	Loss 11.9185 (11.3515)	Hard Loss 0.7368 (0.7013)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (78.5%, 96.7%)	
07/26 06:20:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][700/703]	Step 35196	lr 0.01338	Loss 16.8854 (11.4595)	Hard Loss 1.0628 (0.7084)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (78.3%, 96.6%)	
07/26 06:20:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [49][703/703]	Step 35199	lr 0.01338	Loss 11.1665 (11.4562)	Hard Loss 0.6858 (0.7082)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (78.3%, 96.6%)	
07/26 06:20:37午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 49/99] Final Prec@1 78.2956%
07/26 06:20:40午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 49/99] Final Prec@1 62.9000%
07/26 06:20:41午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 62.9000%
07/26 06:20:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][50/703]	Step 35250	lr 0.013	Loss 9.5351 (10.3857)	Hard Loss 0.5809 (0.6363)	Soft Loss 0.0029 (0.0026)	Prec@(1,5) (80.2%, 97.2%)	
07/26 06:21:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][100/703]	Step 35300	lr 0.013	Loss 14.4925 (10.5268)	Hard Loss 0.9063 (0.6464)	Soft Loss 0.0025 (0.0026)	Prec@(1,5) (79.8%, 97.0%)	
07/26 06:21:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][150/703]	Step 35350	lr 0.013	Loss 9.4674 (10.7321)	Hard Loss 0.5838 (0.6600)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (79.3%, 97.1%)	
07/26 06:21:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][200/703]	Step 35400	lr 0.013	Loss 7.4649 (10.6693)	Hard Loss 0.4407 (0.6558)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (79.5%, 97.2%)	
07/26 06:21:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][250/703]	Step 35450	lr 0.013	Loss 9.6708 (10.5771)	Hard Loss 0.5893 (0.6499)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.8%, 97.2%)	
07/26 06:21:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][300/703]	Step 35500	lr 0.013	Loss 9.6278 (10.6575)	Hard Loss 0.5832 (0.6552)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (79.6%, 97.2%)	
07/26 06:21:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][350/703]	Step 35550	lr 0.013	Loss 11.0360 (10.7647)	Hard Loss 0.6835 (0.6623)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.5%, 97.1%)	
07/26 06:21:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][400/703]	Step 35600	lr 0.013	Loss 7.0017 (10.7702)	Hard Loss 0.4209 (0.6627)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (79.4%, 97.1%)	
07/26 06:22:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][450/703]	Step 35650	lr 0.013	Loss 10.1424 (10.7253)	Hard Loss 0.6250 (0.6599)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (79.5%, 97.1%)	
07/26 06:22:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][500/703]	Step 35700	lr 0.013	Loss 12.3220 (10.8442)	Hard Loss 0.7608 (0.6677)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.2%, 97.1%)	
07/26 06:22:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][550/703]	Step 35750	lr 0.013	Loss 11.1014 (10.8970)	Hard Loss 0.6901 (0.6713)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (79.2%, 97.0%)	
07/26 06:22:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][600/703]	Step 35800	lr 0.013	Loss 10.0481 (10.9504)	Hard Loss 0.6225 (0.6748)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (79.1%, 97.0%)	
07/26 06:22:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][650/703]	Step 35850	lr 0.013	Loss 13.3787 (10.9833)	Hard Loss 0.8291 (0.6769)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (79.0%, 97.0%)	
07/26 06:22:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][700/703]	Step 35900	lr 0.013	Loss 11.1034 (10.9842)	Hard Loss 0.6868 (0.6770)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (79.0%, 96.9%)	
07/26 06:22:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [50][703/703]	Step 35903	lr 0.013	Loss 11.7193 (10.9813)	Hard Loss 0.7332 (0.6768)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (79.0%, 97.0%)	
07/26 06:22:53午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 50/99] Final Prec@1 79.0444%
07/26 06:22:56午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 50/99] Final Prec@1 60.9600%
07/26 06:22:56午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 62.9000%
07/26 06:23:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][50/703]	Step 35954	lr 0.01262	Loss 13.4515 (10.2666)	Hard Loss 0.8348 (0.6289)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (81.2%, 97.5%)	
07/26 06:23:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][100/703]	Step 36004	lr 0.01262	Loss 6.7755 (10.0189)	Hard Loss 0.4015 (0.6131)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.2%, 97.5%)	
07/26 06:23:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][150/703]	Step 36054	lr 0.01262	Loss 8.6426 (10.1492)	Hard Loss 0.5197 (0.6215)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (80.9%, 97.4%)	
07/26 06:23:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][200/703]	Step 36104	lr 0.01262	Loss 11.2829 (10.2913)	Hard Loss 0.7002 (0.6309)	Soft Loss 0.0031 (0.0027)	Prec@(1,5) (80.5%, 97.2%)	
07/26 06:23:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][250/703]	Step 36154	lr 0.01262	Loss 10.3235 (10.2978)	Hard Loss 0.6417 (0.6314)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (80.5%, 97.4%)	
07/26 06:23:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][300/703]	Step 36204	lr 0.01262	Loss 7.5970 (10.3153)	Hard Loss 0.4578 (0.6325)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (80.3%, 97.4%)	
07/26 06:24:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][350/703]	Step 36254	lr 0.01262	Loss 9.3655 (10.3757)	Hard Loss 0.5721 (0.6365)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (80.2%, 97.3%)	
07/26 06:24:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][400/703]	Step 36304	lr 0.01262	Loss 9.9779 (10.5272)	Hard Loss 0.6173 (0.6466)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (79.8%, 97.3%)	
07/26 06:24:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][450/703]	Step 36354	lr 0.01262	Loss 9.7767 (10.5582)	Hard Loss 0.5970 (0.6487)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (79.8%, 97.2%)	
07/26 06:24:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][500/703]	Step 36404	lr 0.01262	Loss 8.5927 (10.6863)	Hard Loss 0.5132 (0.6571)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (79.6%, 97.1%)	
07/26 06:24:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][550/703]	Step 36454	lr 0.01262	Loss 14.0891 (10.7398)	Hard Loss 0.8793 (0.6606)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (79.5%, 97.1%)	
07/26 06:24:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][600/703]	Step 36504	lr 0.01262	Loss 7.4295 (10.7640)	Hard Loss 0.4416 (0.6623)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (79.5%, 97.1%)	
07/26 06:24:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][650/703]	Step 36554	lr 0.01262	Loss 12.5873 (10.7638)	Hard Loss 0.7833 (0.6623)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (79.4%, 97.1%)	
07/26 06:25:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][700/703]	Step 36604	lr 0.01262	Loss 11.2547 (10.7779)	Hard Loss 0.7013 (0.6633)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (79.4%, 97.1%)	
07/26 06:25:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [51][703/703]	Step 36607	lr 0.01262	Loss 10.2657 (10.7860)	Hard Loss 0.6291 (0.6638)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (79.4%, 97.1%)	
07/26 06:25:08午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 51/99] Final Prec@1 79.3800%
07/26 06:25:12午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 51/99] Final Prec@1 62.0000%
07/26 06:25:12午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 62.9000%
07/26 06:25:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][50/703]	Step 36658	lr 0.01225	Loss 11.4172 (9.2223)	Hard Loss 0.7009 (0.5604)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (82.5%, 97.6%)	
07/26 06:25:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][100/703]	Step 36708	lr 0.01225	Loss 13.0877 (9.5807)	Hard Loss 0.8141 (0.5837)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (82.1%, 97.6%)	
07/26 06:25:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][150/703]	Step 36758	lr 0.01225	Loss 8.4997 (9.4963)	Hard Loss 0.5194 (0.5787)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (82.4%, 97.6%)	
07/26 06:25:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][200/703]	Step 36808	lr 0.01225	Loss 8.2780 (9.6795)	Hard Loss 0.5013 (0.5907)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.0%, 97.3%)	
07/26 06:25:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][250/703]	Step 36858	lr 0.01225	Loss 11.7549 (9.8967)	Hard Loss 0.7249 (0.6048)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (81.6%, 97.3%)	
07/26 06:26:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][300/703]	Step 36908	lr 0.01225	Loss 10.0857 (9.9065)	Hard Loss 0.6171 (0.6056)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (81.5%, 97.3%)	
07/26 06:26:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][350/703]	Step 36958	lr 0.01225	Loss 10.8335 (10.0251)	Hard Loss 0.6649 (0.6133)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.2%, 97.2%)	
07/26 06:26:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][400/703]	Step 37008	lr 0.01225	Loss 15.1886 (10.1624)	Hard Loss 0.9559 (0.6223)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (80.8%, 97.2%)	
07/26 06:26:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][450/703]	Step 37058	lr 0.01225	Loss 8.0759 (10.2090)	Hard Loss 0.4922 (0.6255)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (80.6%, 97.2%)	
07/26 06:26:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][500/703]	Step 37108	lr 0.01225	Loss 10.2404 (10.2735)	Hard Loss 0.6247 (0.6298)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (80.5%, 97.2%)	
07/26 06:26:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][550/703]	Step 37158	lr 0.01225	Loss 12.1619 (10.3100)	Hard Loss 0.7551 (0.6323)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (80.4%, 97.1%)	
07/26 06:27:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][600/703]	Step 37208	lr 0.01225	Loss 11.1204 (10.3615)	Hard Loss 0.6832 (0.6357)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (80.3%, 97.1%)	
07/26 06:27:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][650/703]	Step 37258	lr 0.01225	Loss 9.2161 (10.4422)	Hard Loss 0.5689 (0.6410)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (80.2%, 97.1%)	
07/26 06:27:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][700/703]	Step 37308	lr 0.01225	Loss 8.4511 (10.5095)	Hard Loss 0.5102 (0.6455)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (80.0%, 97.1%)	
07/26 06:27:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [52][703/703]	Step 37311	lr 0.01225	Loss 10.9165 (10.5126)	Hard Loss 0.6777 (0.6457)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (80.0%, 97.1%)	
07/26 06:27:24午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 52/99] Final Prec@1 80.0378%
07/26 06:27:28午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 52/99] Final Prec@1 62.4200%
07/26 06:27:28午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 62.9000%
07/26 06:27:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][50/703]	Step 37362	lr 0.01187	Loss 9.0852 (9.4046)	Hard Loss 0.5501 (0.5728)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (82.6%, 97.3%)	
07/26 06:27:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][100/703]	Step 37412	lr 0.01187	Loss 9.1943 (9.5117)	Hard Loss 0.5603 (0.5795)	Soft Loss 0.0023 (0.0026)	Prec@(1,5) (82.4%, 97.5%)	
07/26 06:27:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][150/703]	Step 37462	lr 0.01187	Loss 10.6504 (9.6079)	Hard Loss 0.6539 (0.5857)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (82.0%, 97.6%)	
07/26 06:28:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][200/703]	Step 37512	lr 0.01187	Loss 9.4568 (9.7551)	Hard Loss 0.5758 (0.5955)	Soft Loss 0.0029 (0.0027)	Prec@(1,5) (81.7%, 97.5%)	
07/26 06:28:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][250/703]	Step 37562	lr 0.01187	Loss 8.8388 (9.7870)	Hard Loss 0.5359 (0.5977)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (81.8%, 97.5%)	
07/26 06:28:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][300/703]	Step 37612	lr 0.01187	Loss 9.4100 (9.9050)	Hard Loss 0.5705 (0.6053)	Soft Loss 0.0025 (0.0027)	Prec@(1,5) (81.3%, 97.5%)	
07/26 06:28:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][350/703]	Step 37662	lr 0.01187	Loss 13.1592 (9.9996)	Hard Loss 0.8266 (0.6116)	Soft Loss 0.0033 (0.0027)	Prec@(1,5) (81.1%, 97.4%)	
07/26 06:28:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][400/703]	Step 37712	lr 0.01187	Loss 10.4837 (10.0757)	Hard Loss 0.6396 (0.6166)	Soft Loss 0.0026 (0.0027)	Prec@(1,5) (81.0%, 97.3%)	
07/26 06:28:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][450/703]	Step 37762	lr 0.01187	Loss 11.8783 (10.0875)	Hard Loss 0.7349 (0.6174)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (81.0%, 97.3%)	
07/26 06:29:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][500/703]	Step 37812	lr 0.01187	Loss 12.2612 (10.1218)	Hard Loss 0.7649 (0.6198)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (80.8%, 97.3%)	
07/26 06:29:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][550/703]	Step 37862	lr 0.01187	Loss 7.0436 (10.2247)	Hard Loss 0.4169 (0.6265)	Soft Loss 0.0028 (0.0027)	Prec@(1,5) (80.6%, 97.3%)	
07/26 06:29:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][600/703]	Step 37912	lr 0.01187	Loss 8.6195 (10.2791)	Hard Loss 0.5199 (0.6301)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (80.4%, 97.2%)	
07/26 06:29:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][650/703]	Step 37962	lr 0.01187	Loss 8.8330 (10.2976)	Hard Loss 0.5396 (0.6314)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (80.4%, 97.2%)	
07/26 06:29:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][700/703]	Step 38012	lr 0.01187	Loss 13.3025 (10.3012)	Hard Loss 0.8273 (0.6317)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (80.4%, 97.2%)	
07/26 06:29:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [53][703/703]	Step 38015	lr 0.01187	Loss 16.8403 (10.3107)	Hard Loss 1.0613 (0.6323)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (80.4%, 97.2%)	
07/26 06:29:40午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 53/99] Final Prec@1 80.3933%
07/26 06:29:44午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 53/99] Final Prec@1 61.9600%
07/26 06:29:44午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 62.9000%
07/26 06:29:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][50/703]	Step 38066	lr 0.0115	Loss 11.4803 (9.3675)	Hard Loss 0.7115 (0.5694)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.8%, 97.7%)	
07/26 06:30:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][100/703]	Step 38116	lr 0.0115	Loss 9.8147 (9.1004)	Hard Loss 0.6083 (0.5520)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (82.7%, 97.7%)	
07/26 06:30:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][150/703]	Step 38166	lr 0.0115	Loss 9.8655 (9.1086)	Hard Loss 0.6066 (0.5524)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.6%, 97.8%)	
07/26 06:30:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][200/703]	Step 38216	lr 0.0115	Loss 6.8223 (9.1991)	Hard Loss 0.4023 (0.5588)	Soft Loss 0.0031 (0.0028)	Prec@(1,5) (82.3%, 97.9%)	
07/26 06:30:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][250/703]	Step 38266	lr 0.0115	Loss 8.3696 (9.4109)	Hard Loss 0.5054 (0.5726)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (81.9%, 97.7%)	
07/26 06:30:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][300/703]	Step 38316	lr 0.0115	Loss 11.3715 (9.4307)	Hard Loss 0.7021 (0.5741)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (81.9%, 97.7%)	
07/26 06:30:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][350/703]	Step 38366	lr 0.0115	Loss 7.7758 (9.5104)	Hard Loss 0.4662 (0.5795)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.8%, 97.6%)	
07/26 06:31:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][400/703]	Step 38416	lr 0.0115	Loss 10.4958 (9.5720)	Hard Loss 0.6409 (0.5835)	Soft Loss 0.0025 (0.0028)	Prec@(1,5) (81.7%, 97.6%)	
07/26 06:31:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][450/703]	Step 38466	lr 0.0115	Loss 10.6325 (9.6867)	Hard Loss 0.6541 (0.5910)	Soft Loss 0.0024 (0.0028)	Prec@(1,5) (81.4%, 97.5%)	
07/26 06:31:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][500/703]	Step 38516	lr 0.0115	Loss 9.9162 (9.7348)	Hard Loss 0.6054 (0.5943)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (81.3%, 97.5%)	
07/26 06:31:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][550/703]	Step 38566	lr 0.0115	Loss 9.9237 (9.7652)	Hard Loss 0.6021 (0.5963)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (81.3%, 97.5%)	
07/26 06:31:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][600/703]	Step 38616	lr 0.0115	Loss 11.4261 (9.8521)	Hard Loss 0.7081 (0.6021)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.2%, 97.4%)	
07/26 06:31:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][650/703]	Step 38666	lr 0.0115	Loss 11.8231 (9.8986)	Hard Loss 0.7320 (0.6052)	Soft Loss 0.0024 (0.0028)	Prec@(1,5) (81.1%, 97.4%)	
07/26 06:31:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][700/703]	Step 38716	lr 0.0115	Loss 7.5816 (9.9309)	Hard Loss 0.4593 (0.6073)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (81.1%, 97.4%)	
07/26 06:31:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [54][703/703]	Step 38719	lr 0.0115	Loss 10.9045 (9.9445)	Hard Loss 0.6686 (0.6081)	Soft Loss 0.0025 (0.0028)	Prec@(1,5) (81.1%, 97.4%)	
07/26 06:31:59午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 54/99] Final Prec@1 81.1222%
07/26 06:32:02午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 54/99] Final Prec@1 63.0000%
07/26 06:32:03午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 63.0000%
07/26 06:32:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][50/703]	Step 38770	lr 0.01112	Loss 9.9418 (9.1031)	Hard Loss 0.6101 (0.5523)	Soft Loss 0.0030 (0.0027)	Prec@(1,5) (82.9%, 97.8%)	
07/26 06:32:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][100/703]	Step 38820	lr 0.01112	Loss 9.9464 (9.1502)	Hard Loss 0.6066 (0.5556)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (82.7%, 97.8%)	
07/26 06:32:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][150/703]	Step 38870	lr 0.01112	Loss 7.5152 (9.0726)	Hard Loss 0.4475 (0.5504)	Soft Loss 0.0032 (0.0028)	Prec@(1,5) (82.9%, 97.9%)	
07/26 06:32:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][200/703]	Step 38920	lr 0.01112	Loss 7.0684 (9.1376)	Hard Loss 0.4210 (0.5547)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (82.6%, 97.8%)	
07/26 06:32:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][250/703]	Step 38970	lr 0.01112	Loss 10.0892 (9.3072)	Hard Loss 0.6135 (0.5660)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (82.4%, 97.7%)	
07/26 06:32:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][300/703]	Step 39020	lr 0.01112	Loss 9.5014 (9.3868)	Hard Loss 0.5797 (0.5712)	Soft Loss 0.0032 (0.0028)	Prec@(1,5) (82.2%, 97.7%)	
07/26 06:33:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][350/703]	Step 39070	lr 0.01112	Loss 11.3937 (9.4248)	Hard Loss 0.7021 (0.5738)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (82.3%, 97.7%)	
07/26 06:33:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][400/703]	Step 39120	lr 0.01112	Loss 10.9452 (9.5359)	Hard Loss 0.6752 (0.5811)	Soft Loss 0.0033 (0.0028)	Prec@(1,5) (82.1%, 97.6%)	
07/26 06:33:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][450/703]	Step 39170	lr 0.01112	Loss 9.0593 (9.6061)	Hard Loss 0.5469 (0.5856)	Soft Loss 0.0025 (0.0028)	Prec@(1,5) (81.9%, 97.6%)	
07/26 06:33:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][500/703]	Step 39220	lr 0.01112	Loss 11.4185 (9.6383)	Hard Loss 0.7061 (0.5878)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.7%, 97.6%)	
07/26 06:33:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][550/703]	Step 39270	lr 0.01112	Loss 10.5063 (9.6735)	Hard Loss 0.6451 (0.5902)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (81.7%, 97.6%)	
07/26 06:33:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][600/703]	Step 39320	lr 0.01112	Loss 9.0000 (9.6955)	Hard Loss 0.5390 (0.5916)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (81.6%, 97.6%)	
07/26 06:34:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][650/703]	Step 39370	lr 0.01112	Loss 13.6227 (9.7294)	Hard Loss 0.8449 (0.5938)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (81.4%, 97.6%)	
07/26 06:34:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][700/703]	Step 39420	lr 0.01112	Loss 6.7365 (9.7639)	Hard Loss 0.4037 (0.5962)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (81.4%, 97.6%)	
07/26 06:34:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [55][703/703]	Step 39423	lr 0.01112	Loss 12.0100 (9.7717)	Hard Loss 0.7410 (0.5967)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (81.4%, 97.6%)	
07/26 06:34:28午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 55/99] Final Prec@1 81.3667%
07/26 06:34:31午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 55/99] Final Prec@1 61.3800%
07/26 06:34:31午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 63.0000%
07/26 06:34:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][50/703]	Step 39474	lr 0.01075	Loss 8.0269 (8.7080)	Hard Loss 0.4822 (0.5256)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (83.4%, 98.2%)	
07/26 06:34:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][100/703]	Step 39524	lr 0.01075	Loss 6.4595 (8.9111)	Hard Loss 0.3819 (0.5394)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.7%, 98.2%)	
07/26 06:34:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][150/703]	Step 39574	lr 0.01075	Loss 8.5138 (8.9393)	Hard Loss 0.5179 (0.5412)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (82.9%, 98.1%)	
07/26 06:35:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][200/703]	Step 39624	lr 0.01075	Loss 10.7868 (8.9504)	Hard Loss 0.6651 (0.5423)	Soft Loss 0.0031 (0.0028)	Prec@(1,5) (82.9%, 98.0%)	
07/26 06:35:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][250/703]	Step 39674	lr 0.01075	Loss 10.7143 (8.9838)	Hard Loss 0.6591 (0.5447)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (82.9%, 98.0%)	
07/26 06:35:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][300/703]	Step 39724	lr 0.01075	Loss 9.2539 (9.1185)	Hard Loss 0.5559 (0.5536)	Soft Loss 0.0025 (0.0028)	Prec@(1,5) (82.6%, 97.9%)	
07/26 06:35:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][350/703]	Step 39774	lr 0.01075	Loss 11.0306 (9.2357)	Hard Loss 0.6780 (0.5613)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (82.4%, 97.8%)	
07/26 06:35:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][400/703]	Step 39824	lr 0.01075	Loss 11.7925 (9.2592)	Hard Loss 0.7316 (0.5627)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (82.3%, 97.8%)	
07/26 06:35:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][450/703]	Step 39874	lr 0.01075	Loss 8.3122 (9.2956)	Hard Loss 0.4976 (0.5651)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (82.3%, 97.8%)	
07/26 06:36:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][500/703]	Step 39924	lr 0.01075	Loss 7.5072 (9.3633)	Hard Loss 0.4466 (0.5696)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.2%, 97.8%)	
07/26 06:36:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][550/703]	Step 39974	lr 0.01075	Loss 9.6275 (9.4195)	Hard Loss 0.5865 (0.5732)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.0%, 97.8%)	
07/26 06:36:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][600/703]	Step 40024	lr 0.01075	Loss 9.6271 (9.4406)	Hard Loss 0.5876 (0.5746)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.0%, 97.8%)	
07/26 06:36:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][650/703]	Step 40074	lr 0.01075	Loss 15.1428 (9.4686)	Hard Loss 0.9493 (0.5764)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (81.9%, 97.8%)	
07/26 06:36:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][700/703]	Step 40124	lr 0.01075	Loss 9.4999 (9.5456)	Hard Loss 0.5825 (0.5816)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (81.8%, 97.7%)	
07/26 06:36:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [56][703/703]	Step 40127	lr 0.01075	Loss 8.6182 (9.5515)	Hard Loss 0.5231 (0.5820)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (81.7%, 97.7%)	
07/26 06:36:43午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 56/99] Final Prec@1 81.7378%
07/26 06:36:47午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 56/99] Final Prec@1 62.7000%
07/26 06:36:47午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 63.0000%
07/26 06:36:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][50/703]	Step 40178	lr 0.01038	Loss 8.7954 (8.6023)	Hard Loss 0.5289 (0.5195)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (83.3%, 98.0%)	
07/26 06:37:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][100/703]	Step 40228	lr 0.01038	Loss 6.7794 (8.5216)	Hard Loss 0.3981 (0.5142)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (83.7%, 98.1%)	
07/26 06:37:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][150/703]	Step 40278	lr 0.01038	Loss 9.3578 (8.7642)	Hard Loss 0.5634 (0.5298)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (83.1%, 98.0%)	
07/26 06:37:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][200/703]	Step 40328	lr 0.01038	Loss 6.2906 (8.8024)	Hard Loss 0.3668 (0.5325)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (83.2%, 98.0%)	
07/26 06:37:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][250/703]	Step 40378	lr 0.01038	Loss 8.0555 (8.9509)	Hard Loss 0.4795 (0.5424)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (82.9%, 98.0%)	
07/26 06:37:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][300/703]	Step 40428	lr 0.01038	Loss 9.9163 (8.9678)	Hard Loss 0.6086 (0.5436)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (82.8%, 98.0%)	
07/26 06:37:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][350/703]	Step 40478	lr 0.01038	Loss 11.2344 (9.0209)	Hard Loss 0.6973 (0.5472)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.7%, 97.9%)	
07/26 06:38:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][400/703]	Step 40528	lr 0.01038	Loss 9.7885 (9.0776)	Hard Loss 0.5963 (0.5508)	Soft Loss 0.0035 (0.0028)	Prec@(1,5) (82.7%, 97.9%)	
07/26 06:38:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][450/703]	Step 40578	lr 0.01038	Loss 8.6086 (9.1239)	Hard Loss 0.5270 (0.5538)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (82.6%, 97.9%)	
07/26 06:38:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][500/703]	Step 40628	lr 0.01038	Loss 9.9016 (9.1541)	Hard Loss 0.6060 (0.5558)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (82.5%, 97.9%)	
07/26 06:38:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][550/703]	Step 40678	lr 0.01038	Loss 11.0802 (9.1675)	Hard Loss 0.6803 (0.5568)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (82.5%, 97.9%)	
07/26 06:38:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][600/703]	Step 40728	lr 0.01038	Loss 9.9245 (9.2070)	Hard Loss 0.6134 (0.5594)	Soft Loss 0.0033 (0.0028)	Prec@(1,5) (82.5%, 97.9%)	
07/26 06:38:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][650/703]	Step 40778	lr 0.01038	Loss 9.3507 (9.2535)	Hard Loss 0.5715 (0.5625)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (82.4%, 97.8%)	
07/26 06:38:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][700/703]	Step 40828	lr 0.01038	Loss 9.1479 (9.2919)	Hard Loss 0.5625 (0.5651)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (82.3%, 97.8%)	
07/26 06:38:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [57][703/703]	Step 40831	lr 0.01038	Loss 7.7804 (9.2895)	Hard Loss 0.4605 (0.5649)	Soft Loss 0.0030 (0.0028)	Prec@(1,5) (82.3%, 97.8%)	
07/26 06:38:59午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 57/99] Final Prec@1 82.2844%
07/26 06:39:02午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 57/99] Final Prec@1 62.5400%
07/26 06:39:02午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 63.0000%
07/26 06:39:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][50/703]	Step 40882	lr 0.01002	Loss 11.7490 (8.2160)	Hard Loss 0.7226 (0.4922)	Soft Loss 0.0027 (0.0027)	Prec@(1,5) (84.7%, 98.6%)	
07/26 06:39:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][100/703]	Step 40932	lr 0.01002	Loss 8.9120 (8.3974)	Hard Loss 0.5389 (0.5047)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (84.3%, 98.5%)	
07/26 06:39:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][150/703]	Step 40982	lr 0.01002	Loss 8.4553 (8.5605)	Hard Loss 0.5115 (0.5156)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (84.4%, 98.3%)	
07/26 06:39:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][200/703]	Step 41032	lr 0.01002	Loss 10.1610 (8.5788)	Hard Loss 0.6227 (0.5172)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (84.2%, 98.3%)	
07/26 06:39:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][250/703]	Step 41082	lr 0.01002	Loss 7.3333 (8.5023)	Hard Loss 0.4330 (0.5125)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (84.1%, 98.3%)	
07/26 06:39:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][300/703]	Step 41132	lr 0.01002	Loss 9.7903 (8.6214)	Hard Loss 0.5952 (0.5202)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (83.9%, 98.3%)	
07/26 06:40:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][350/703]	Step 41182	lr 0.01002	Loss 8.4541 (8.6272)	Hard Loss 0.5107 (0.5207)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (83.9%, 98.2%)	
07/26 06:40:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][400/703]	Step 41232	lr 0.01002	Loss 9.6521 (8.7331)	Hard Loss 0.5845 (0.5278)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (83.7%, 98.1%)	
07/26 06:40:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][450/703]	Step 41282	lr 0.01002	Loss 9.6027 (8.7840)	Hard Loss 0.5843 (0.5312)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (83.6%, 98.1%)	
07/26 06:40:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][500/703]	Step 41332	lr 0.01002	Loss 9.9401 (8.8402)	Hard Loss 0.6071 (0.5349)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (83.5%, 98.0%)	
07/26 06:40:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][550/703]	Step 41382	lr 0.01002	Loss 7.3620 (8.8787)	Hard Loss 0.4329 (0.5376)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (83.4%, 98.0%)	
07/26 06:40:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][600/703]	Step 41432	lr 0.01002	Loss 8.6324 (8.9120)	Hard Loss 0.5285 (0.5398)	Soft Loss 0.0031 (0.0028)	Prec@(1,5) (83.4%, 98.0%)	
07/26 06:41:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][650/703]	Step 41482	lr 0.01002	Loss 7.2376 (8.9730)	Hard Loss 0.4280 (0.5438)	Soft Loss 0.0032 (0.0028)	Prec@(1,5) (83.2%, 98.0%)	
07/26 06:41:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][700/703]	Step 41532	lr 0.01002	Loss 9.0045 (8.9996)	Hard Loss 0.5494 (0.5456)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (83.1%, 98.0%)	
07/26 06:41:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [58][703/703]	Step 41535	lr 0.01002	Loss 7.9928 (9.0026)	Hard Loss 0.4819 (0.5458)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (83.1%, 98.0%)	
07/26 06:41:15午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 58/99] Final Prec@1 83.1244%
07/26 06:41:18午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 58/99] Final Prec@1 63.8800%
07/26 06:41:18午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 63.8800%
07/26 06:41:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][50/703]	Step 41586	lr 0.00965	Loss 9.8103 (7.7374)	Hard Loss 0.5947 (0.4625)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (85.7%, 98.7%)	
07/26 06:41:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][100/703]	Step 41636	lr 0.00965	Loss 6.4502 (7.9901)	Hard Loss 0.3782 (0.4792)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (85.2%, 98.4%)	
07/26 06:41:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][150/703]	Step 41686	lr 0.00965	Loss 10.0924 (8.2124)	Hard Loss 0.6125 (0.4934)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (84.5%, 98.3%)	
07/26 06:41:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][200/703]	Step 41736	lr 0.00965	Loss 9.2818 (8.2209)	Hard Loss 0.5676 (0.4941)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (84.5%, 98.2%)	
07/26 06:42:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][250/703]	Step 41786	lr 0.00965	Loss 9.6941 (8.2958)	Hard Loss 0.5887 (0.4989)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (84.3%, 98.2%)	
07/26 06:42:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][300/703]	Step 41836	lr 0.00965	Loss 7.0630 (8.3483)	Hard Loss 0.4192 (0.5022)	Soft Loss 0.0031 (0.0028)	Prec@(1,5) (84.2%, 98.2%)	
07/26 06:42:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][350/703]	Step 41886	lr 0.00965	Loss 11.6939 (8.3935)	Hard Loss 0.7128 (0.5053)	Soft Loss 0.0034 (0.0028)	Prec@(1,5) (84.2%, 98.2%)	
07/26 06:42:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][400/703]	Step 41936	lr 0.00965	Loss 9.2890 (8.4364)	Hard Loss 0.5644 (0.5082)	Soft Loss 0.0026 (0.0028)	Prec@(1,5) (84.1%, 98.2%)	
07/26 06:42:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][450/703]	Step 41986	lr 0.00965	Loss 11.9313 (8.5164)	Hard Loss 0.7420 (0.5134)	Soft Loss 0.0031 (0.0028)	Prec@(1,5) (84.0%, 98.2%)	
07/26 06:42:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][500/703]	Step 42036	lr 0.00965	Loss 10.5927 (8.5700)	Hard Loss 0.6459 (0.5170)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (83.8%, 98.1%)	
07/26 06:43:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][550/703]	Step 42086	lr 0.00965	Loss 9.0952 (8.6261)	Hard Loss 0.5544 (0.5207)	Soft Loss 0.0032 (0.0029)	Prec@(1,5) (83.8%, 98.1%)	
07/26 06:43:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][600/703]	Step 42136	lr 0.00965	Loss 7.9854 (8.7025)	Hard Loss 0.4786 (0.5258)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (83.6%, 98.1%)	
07/26 06:43:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][650/703]	Step 42186	lr 0.00965	Loss 10.5094 (8.7675)	Hard Loss 0.6445 (0.5301)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (83.5%, 98.0%)	
07/26 06:43:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][700/703]	Step 42236	lr 0.00965	Loss 9.4051 (8.7697)	Hard Loss 0.5718 (0.5303)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (83.5%, 98.0%)	
07/26 06:43:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [59][703/703]	Step 42239	lr 0.00965	Loss 8.9588 (8.7764)	Hard Loss 0.5444 (0.5307)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (83.5%, 98.0%)	
07/26 06:43:31午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 59/99] Final Prec@1 83.5044%
07/26 06:43:34午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 59/99] Final Prec@1 63.6400%
07/26 06:43:34午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 63.8800%
07/26 06:43:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][50/703]	Step 42290	lr 0.00929	Loss 9.6500 (7.3991)	Hard Loss 0.5900 (0.4401)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (86.2%, 98.5%)	
07/26 06:43:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][100/703]	Step 42340	lr 0.00929	Loss 8.8935 (7.8291)	Hard Loss 0.5438 (0.4680)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (85.3%, 98.3%)	
07/26 06:44:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][150/703]	Step 42390	lr 0.00929	Loss 10.8669 (7.9647)	Hard Loss 0.6624 (0.4770)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.1%, 98.3%)	
07/26 06:44:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][200/703]	Step 42440	lr 0.00929	Loss 8.4588 (8.0984)	Hard Loss 0.5032 (0.4858)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (84.8%, 98.3%)	
07/26 06:44:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][250/703]	Step 42490	lr 0.00929	Loss 6.1716 (8.1391)	Hard Loss 0.3603 (0.4886)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (84.8%, 98.3%)	
07/26 06:44:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][300/703]	Step 42540	lr 0.00929	Loss 8.9692 (8.2209)	Hard Loss 0.5457 (0.4938)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (84.6%, 98.3%)	
07/26 06:44:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][350/703]	Step 42590	lr 0.00929	Loss 7.2373 (8.2649)	Hard Loss 0.4305 (0.4968)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (84.5%, 98.3%)	
07/26 06:44:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][400/703]	Step 42640	lr 0.00929	Loss 9.4255 (8.2722)	Hard Loss 0.5800 (0.4973)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (84.5%, 98.3%)	
07/26 06:44:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][450/703]	Step 42690	lr 0.00929	Loss 8.7232 (8.3361)	Hard Loss 0.5293 (0.5016)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (84.3%, 98.3%)	
07/26 06:45:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][500/703]	Step 42740	lr 0.00929	Loss 7.5701 (8.3943)	Hard Loss 0.4552 (0.5054)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (84.2%, 98.2%)	
07/26 06:45:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][550/703]	Step 42790	lr 0.00929	Loss 9.8463 (8.4225)	Hard Loss 0.5981 (0.5073)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (84.2%, 98.2%)	
07/26 06:45:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][600/703]	Step 42840	lr 0.00929	Loss 8.4511 (8.4607)	Hard Loss 0.5116 (0.5098)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (84.1%, 98.2%)	
07/26 06:45:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][650/703]	Step 42890	lr 0.00929	Loss 6.3561 (8.4966)	Hard Loss 0.3689 (0.5122)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (84.0%, 98.2%)	
07/26 06:45:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][700/703]	Step 42940	lr 0.00929	Loss 8.0159 (8.4989)	Hard Loss 0.4834 (0.5124)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (83.9%, 98.2%)	
07/26 06:45:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [60][703/703]	Step 42943	lr 0.00929	Loss 9.7274 (8.5035)	Hard Loss 0.5948 (0.5127)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (83.9%, 98.2%)	
07/26 06:45:46午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 60/99] Final Prec@1 83.9333%
07/26 06:45:50午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 60/99] Final Prec@1 64.1200%
07/26 06:45:50午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.1200%
07/26 06:46:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][50/703]	Step 42994	lr 0.00894	Loss 8.2106 (7.8576)	Hard Loss 0.4899 (0.4704)	Soft Loss 0.0028 (0.0028)	Prec@(1,5) (84.7%, 98.4%)	
07/26 06:46:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][100/703]	Step 43044	lr 0.00894	Loss 7.6481 (7.7195)	Hard Loss 0.4519 (0.4610)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (85.1%, 98.5%)	
07/26 06:46:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][150/703]	Step 43094	lr 0.00894	Loss 10.9890 (7.7571)	Hard Loss 0.6795 (0.4633)	Soft Loss 0.0033 (0.0028)	Prec@(1,5) (85.1%, 98.5%)	
07/26 06:46:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][200/703]	Step 43144	lr 0.00894	Loss 6.4109 (7.7007)	Hard Loss 0.3754 (0.4592)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.3%, 98.6%)	
07/26 06:46:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][250/703]	Step 43194	lr 0.00894	Loss 6.4260 (7.8109)	Hard Loss 0.3783 (0.4665)	Soft Loss 0.0032 (0.0028)	Prec@(1,5) (85.2%, 98.5%)	
07/26 06:46:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][300/703]	Step 43244	lr 0.00894	Loss 9.3408 (7.8234)	Hard Loss 0.5648 (0.4672)	Soft Loss 0.0029 (0.0028)	Prec@(1,5) (85.2%, 98.5%)	
07/26 06:46:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][350/703]	Step 43294	lr 0.00894	Loss 8.7492 (7.8160)	Hard Loss 0.5273 (0.4669)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.3%, 98.5%)	
07/26 06:47:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][400/703]	Step 43344	lr 0.00894	Loss 7.9319 (7.8862)	Hard Loss 0.4790 (0.4716)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (85.2%, 98.4%)	
07/26 06:47:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][450/703]	Step 43394	lr 0.00894	Loss 5.3105 (7.9565)	Hard Loss 0.3089 (0.4764)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (85.0%, 98.4%)	
07/26 06:47:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][500/703]	Step 43444	lr 0.00894	Loss 9.0367 (7.9797)	Hard Loss 0.5509 (0.4780)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (85.0%, 98.4%)	
07/26 06:47:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][550/703]	Step 43494	lr 0.00894	Loss 12.7124 (8.0732)	Hard Loss 0.7867 (0.4841)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (84.7%, 98.4%)	
07/26 06:47:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][600/703]	Step 43544	lr 0.00894	Loss 8.5639 (8.1171)	Hard Loss 0.5194 (0.4870)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (84.6%, 98.4%)	
07/26 06:47:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][650/703]	Step 43594	lr 0.00894	Loss 11.5203 (8.1934)	Hard Loss 0.7123 (0.4921)	Soft Loss 0.0032 (0.0029)	Prec@(1,5) (84.5%, 98.3%)	
07/26 06:48:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][700/703]	Step 43644	lr 0.00894	Loss 8.3190 (8.2327)	Hard Loss 0.5017 (0.4947)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (84.4%, 98.3%)	
07/26 06:48:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [61][703/703]	Step 43647	lr 0.00894	Loss 5.8302 (8.2343)	Hard Loss 0.3290 (0.4948)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (84.4%, 98.3%)	
07/26 06:48:02午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 61/99] Final Prec@1 84.4178%
07/26 06:48:05午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 61/99] Final Prec@1 63.3800%
07/26 06:48:06午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.1200%
07/26 06:48:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][50/703]	Step 43698	lr 0.00858	Loss 7.9471 (7.2778)	Hard Loss 0.4773 (0.4315)	Soft Loss 0.0027 (0.0028)	Prec@(1,5) (86.3%, 99.0%)	
07/26 06:48:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][100/703]	Step 43748	lr 0.00858	Loss 10.6739 (7.5317)	Hard Loss 0.6536 (0.4479)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.6%, 98.8%)	
07/26 06:48:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][150/703]	Step 43798	lr 0.00858	Loss 8.2175 (7.5549)	Hard Loss 0.4953 (0.4493)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.6%, 98.7%)	
07/26 06:48:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][200/703]	Step 43848	lr 0.00858	Loss 6.5402 (7.5281)	Hard Loss 0.3768 (0.4477)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (85.7%, 98.8%)	
07/26 06:48:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][250/703]	Step 43898	lr 0.00858	Loss 5.3360 (7.5971)	Hard Loss 0.3132 (0.4524)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.7%, 98.7%)	
07/26 06:49:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][300/703]	Step 43948	lr 0.00858	Loss 7.6881 (7.6630)	Hard Loss 0.4655 (0.4568)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (85.6%, 98.6%)	
07/26 06:49:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][350/703]	Step 43998	lr 0.00858	Loss 7.2820 (7.7078)	Hard Loss 0.4267 (0.4599)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (85.5%, 98.6%)	
07/26 06:49:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][400/703]	Step 44048	lr 0.00858	Loss 6.9330 (7.7616)	Hard Loss 0.4087 (0.4634)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (85.2%, 98.6%)	
07/26 06:49:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][450/703]	Step 44098	lr 0.00858	Loss 9.3493 (7.8411)	Hard Loss 0.5741 (0.4687)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (85.1%, 98.5%)	
07/26 06:49:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][500/703]	Step 44148	lr 0.00858	Loss 9.7728 (7.8688)	Hard Loss 0.5969 (0.4705)	Soft Loss 0.0033 (0.0029)	Prec@(1,5) (85.0%, 98.6%)	
07/26 06:49:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][550/703]	Step 44198	lr 0.00858	Loss 9.2610 (7.9330)	Hard Loss 0.5625 (0.4748)	Soft Loss 0.0027 (0.0029)	Prec@(1,5) (84.9%, 98.5%)	
07/26 06:49:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][600/703]	Step 44248	lr 0.00858	Loss 6.8179 (7.9366)	Hard Loss 0.4032 (0.4751)	Soft Loss 0.0027 (0.0029)	Prec@(1,5) (84.9%, 98.5%)	
07/26 06:50:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][650/703]	Step 44298	lr 0.00858	Loss 13.9268 (7.9913)	Hard Loss 0.8654 (0.4788)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (84.8%, 98.4%)	
07/26 06:50:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][700/703]	Step 44348	lr 0.00858	Loss 9.4604 (8.0252)	Hard Loss 0.5761 (0.4810)	Soft Loss 0.0033 (0.0029)	Prec@(1,5) (84.8%, 98.4%)	
07/26 06:50:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [62][703/703]	Step 44351	lr 0.00858	Loss 8.0659 (8.0302)	Hard Loss 0.4853 (0.4814)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (84.8%, 98.4%)	
07/26 06:50:18午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 62/99] Final Prec@1 84.7733%
07/26 06:50:21午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 62/99] Final Prec@1 63.1600%
07/26 06:50:21午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.1200%
07/26 06:50:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][50/703]	Step 44402	lr 0.00823	Loss 7.8450 (7.7545)	Hard Loss 0.4720 (0.4626)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (85.3%, 98.3%)	
07/26 06:50:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][100/703]	Step 44452	lr 0.00823	Loss 6.8013 (7.5350)	Hard Loss 0.4030 (0.4483)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.7%, 98.6%)	
07/26 06:50:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][150/703]	Step 44502	lr 0.00823	Loss 6.8231 (7.5472)	Hard Loss 0.4042 (0.4493)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.7%, 98.6%)	
07/26 06:50:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][200/703]	Step 44552	lr 0.00823	Loss 7.2632 (7.4409)	Hard Loss 0.4275 (0.4420)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (86.0%, 98.7%)	
07/26 06:51:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][250/703]	Step 44602	lr 0.00823	Loss 10.2025 (7.4598)	Hard Loss 0.6209 (0.4434)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (86.0%, 98.7%)	
07/26 06:51:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][300/703]	Step 44652	lr 0.00823	Loss 8.8090 (7.5082)	Hard Loss 0.5366 (0.4467)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (86.1%, 98.6%)	
07/26 06:51:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][350/703]	Step 44702	lr 0.00823	Loss 8.5143 (7.5820)	Hard Loss 0.5131 (0.4517)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (86.0%, 98.6%)	
07/26 06:51:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][400/703]	Step 44752	lr 0.00823	Loss 8.5490 (7.6315)	Hard Loss 0.5224 (0.4548)	Soft Loss 0.0032 (0.0029)	Prec@(1,5) (85.8%, 98.6%)	
07/26 06:51:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][450/703]	Step 44802	lr 0.00823	Loss 5.5355 (7.7219)	Hard Loss 0.3196 (0.4607)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (85.6%, 98.5%)	
07/26 06:51:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][500/703]	Step 44852	lr 0.00823	Loss 7.4938 (7.7464)	Hard Loss 0.4454 (0.4624)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (85.5%, 98.5%)	
07/26 06:52:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][550/703]	Step 44902	lr 0.00823	Loss 7.4138 (7.7671)	Hard Loss 0.4388 (0.4638)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (85.5%, 98.5%)	
07/26 06:52:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][600/703]	Step 44952	lr 0.00823	Loss 13.9249 (7.8195)	Hard Loss 0.8716 (0.4673)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (85.4%, 98.5%)	
07/26 06:52:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][650/703]	Step 45002	lr 0.00823	Loss 8.9579 (7.8098)	Hard Loss 0.5482 (0.4667)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (85.3%, 98.5%)	
07/26 06:52:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][700/703]	Step 45052	lr 0.00823	Loss 8.1676 (7.8040)	Hard Loss 0.4852 (0.4664)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (85.4%, 98.5%)	
07/26 06:52:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [63][703/703]	Step 45055	lr 0.00823	Loss 9.8874 (7.8103)	Hard Loss 0.5984 (0.4668)	Soft Loss 0.0033 (0.0029)	Prec@(1,5) (85.3%, 98.5%)	
07/26 06:52:34午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 63/99] Final Prec@1 85.3489%
07/26 06:52:37午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 63/99] Final Prec@1 63.5800%
07/26 06:52:37午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.1200%
07/26 06:52:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][50/703]	Step 45106	lr 0.00789	Loss 8.0950 (7.0562)	Hard Loss 0.4825 (0.4166)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (86.7%, 99.0%)	
07/26 06:52:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][100/703]	Step 45156	lr 0.00789	Loss 4.7255 (7.1853)	Hard Loss 0.2561 (0.4248)	Soft Loss 0.0029 (0.0029)	Prec@(1,5) (86.9%, 98.7%)	
07/26 06:53:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][150/703]	Step 45206	lr 0.00789	Loss 5.7570 (7.1621)	Hard Loss 0.3317 (0.4235)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (87.1%, 98.7%)	
07/26 06:53:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][200/703]	Step 45256	lr 0.00789	Loss 7.4754 (7.2198)	Hard Loss 0.4441 (0.4275)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (86.7%, 98.7%)	
07/26 06:53:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][250/703]	Step 45306	lr 0.00789	Loss 6.6577 (7.3105)	Hard Loss 0.3911 (0.4335)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (86.6%, 98.6%)	
07/26 06:53:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][300/703]	Step 45356	lr 0.00789	Loss 5.5246 (7.3111)	Hard Loss 0.3130 (0.4338)	Soft Loss 0.0026 (0.0029)	Prec@(1,5) (86.5%, 98.7%)	
07/26 06:53:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][350/703]	Step 45406	lr 0.00789	Loss 6.1367 (7.3493)	Hard Loss 0.3448 (0.4362)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (86.4%, 98.6%)	
07/26 06:53:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][400/703]	Step 45456	lr 0.00789	Loss 10.1466 (7.3286)	Hard Loss 0.6176 (0.4349)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (86.5%, 98.6%)	
07/26 06:54:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][450/703]	Step 45506	lr 0.00789	Loss 8.1616 (7.3654)	Hard Loss 0.4935 (0.4373)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (86.4%, 98.6%)	
07/26 06:54:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][500/703]	Step 45556	lr 0.00789	Loss 6.3155 (7.4156)	Hard Loss 0.3696 (0.4406)	Soft Loss 0.0027 (0.0029)	Prec@(1,5) (86.3%, 98.6%)	
07/26 06:54:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][550/703]	Step 45606	lr 0.00789	Loss 7.0573 (7.4254)	Hard Loss 0.4195 (0.4413)	Soft Loss 0.0033 (0.0029)	Prec@(1,5) (86.2%, 98.6%)	
07/26 06:54:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][600/703]	Step 45656	lr 0.00789	Loss 8.4901 (7.4593)	Hard Loss 0.5132 (0.4435)	Soft Loss 0.0031 (0.0029)	Prec@(1,5) (86.2%, 98.6%)	
07/26 06:54:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][650/703]	Step 45706	lr 0.00789	Loss 7.2614 (7.4645)	Hard Loss 0.4253 (0.4439)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (86.2%, 98.6%)	
07/26 06:54:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][700/703]	Step 45756	lr 0.00789	Loss 4.6059 (7.4968)	Hard Loss 0.2656 (0.4461)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (86.1%, 98.6%)	
07/26 06:54:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [64][703/703]	Step 45759	lr 0.00789	Loss 7.8970 (7.4954)	Hard Loss 0.4736 (0.4460)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (86.1%, 98.6%)	
07/26 06:54:49午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 64/99] Final Prec@1 86.0533%
07/26 06:54:53午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 64/99] Final Prec@1 64.5200%
07/26 06:54:53午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.5200%
07/26 06:55:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][50/703]	Step 45810	lr 0.00755	Loss 6.4784 (7.0139)	Hard Loss 0.3785 (0.4145)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (86.9%, 98.9%)	
07/26 06:55:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][100/703]	Step 45860	lr 0.00755	Loss 8.1900 (6.9283)	Hard Loss 0.4882 (0.4083)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (87.5%, 98.7%)	
07/26 06:55:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][150/703]	Step 45910	lr 0.00755	Loss 8.0186 (7.0229)	Hard Loss 0.4797 (0.4147)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.2%, 98.8%)	
07/26 06:55:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][200/703]	Step 45960	lr 0.00755	Loss 6.3853 (7.0046)	Hard Loss 0.3689 (0.4135)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (87.3%, 98.7%)	
07/26 06:55:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][250/703]	Step 46010	lr 0.00755	Loss 4.7233 (6.9674)	Hard Loss 0.2670 (0.4111)	Soft Loss 0.0028 (0.0029)	Prec@(1,5) (87.4%, 98.7%)	
07/26 06:55:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][300/703]	Step 46060	lr 0.00755	Loss 7.4307 (6.9176)	Hard Loss 0.4413 (0.4077)	Soft Loss 0.0030 (0.0029)	Prec@(1,5) (87.4%, 98.8%)	
07/26 06:55:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][350/703]	Step 46110	lr 0.00755	Loss 6.7796 (6.9645)	Hard Loss 0.3949 (0.4108)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (87.2%, 98.8%)	
07/26 06:56:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][400/703]	Step 46160	lr 0.00755	Loss 7.2864 (7.0027)	Hard Loss 0.4328 (0.4133)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (87.2%, 98.8%)	
07/26 06:56:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][450/703]	Step 46210	lr 0.00755	Loss 7.5850 (7.0544)	Hard Loss 0.4465 (0.4167)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.0%, 98.8%)	
07/26 06:56:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][500/703]	Step 46260	lr 0.00755	Loss 8.1035 (7.0944)	Hard Loss 0.4851 (0.4194)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (86.9%, 98.7%)	
07/26 06:56:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][550/703]	Step 46310	lr 0.00755	Loss 7.4980 (7.1401)	Hard Loss 0.4519 (0.4224)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (86.9%, 98.7%)	
07/26 06:56:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][600/703]	Step 46360	lr 0.00755	Loss 7.7151 (7.1709)	Hard Loss 0.4541 (0.4245)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (86.8%, 98.7%)	
07/26 06:56:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][650/703]	Step 46410	lr 0.00755	Loss 6.4304 (7.2179)	Hard Loss 0.3811 (0.4276)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (86.7%, 98.7%)	
07/26 06:57:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][700/703]	Step 46460	lr 0.00755	Loss 8.9902 (7.2488)	Hard Loss 0.5490 (0.4297)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (86.6%, 98.7%)	
07/26 06:57:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [65][703/703]	Step 46463	lr 0.00755	Loss 6.5892 (7.2499)	Hard Loss 0.3874 (0.4298)	Soft Loss 0.0027 (0.0030)	Prec@(1,5) (86.6%, 98.7%)	
07/26 06:57:05午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 65/99] Final Prec@1 86.6511%
07/26 06:57:08午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 65/99] Final Prec@1 64.2800%
07/26 06:57:08午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.5200%
07/26 06:57:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][50/703]	Step 46514	lr 0.00722	Loss 6.9885 (6.4560)	Hard Loss 0.4090 (0.3772)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.9%, 99.1%)	
07/26 06:57:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][100/703]	Step 46564	lr 0.00722	Loss 6.6001 (6.4224)	Hard Loss 0.3849 (0.3750)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (88.3%, 99.1%)	
07/26 06:57:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][150/703]	Step 46614	lr 0.00722	Loss 5.5925 (6.5071)	Hard Loss 0.3212 (0.3810)	Soft Loss 0.0027 (0.0030)	Prec@(1,5) (88.0%, 99.1%)	
07/26 06:57:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][200/703]	Step 46664	lr 0.00722	Loss 8.0302 (6.6649)	Hard Loss 0.4809 (0.3913)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (87.7%, 99.0%)	
07/26 06:57:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][250/703]	Step 46714	lr 0.00722	Loss 6.1346 (6.6906)	Hard Loss 0.3589 (0.3929)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (87.7%, 99.0%)	
07/26 06:58:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][300/703]	Step 46764	lr 0.00722	Loss 7.0072 (6.7175)	Hard Loss 0.4225 (0.3947)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (87.6%, 99.0%)	
07/26 06:58:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][350/703]	Step 46814	lr 0.00722	Loss 9.3280 (6.7448)	Hard Loss 0.5563 (0.3965)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 06:58:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][400/703]	Step 46864	lr 0.00722	Loss 4.9993 (6.7605)	Hard Loss 0.2819 (0.3974)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (87.4%, 99.0%)	
07/26 06:58:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][450/703]	Step 46914	lr 0.00722	Loss 6.6257 (6.8134)	Hard Loss 0.3895 (0.4009)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (87.3%, 98.9%)	
07/26 06:58:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][500/703]	Step 46964	lr 0.00722	Loss 4.8854 (6.8781)	Hard Loss 0.2691 (0.4051)	Soft Loss 0.0027 (0.0030)	Prec@(1,5) (87.2%, 98.9%)	
07/26 06:58:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][550/703]	Step 47014	lr 0.00722	Loss 8.8217 (6.9137)	Hard Loss 0.5274 (0.4075)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (87.1%, 98.8%)	
07/26 06:59:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][600/703]	Step 47064	lr 0.00722	Loss 6.7541 (6.9479)	Hard Loss 0.3932 (0.4097)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.1%, 98.8%)	
07/26 06:59:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][650/703]	Step 47114	lr 0.00722	Loss 5.0217 (6.9939)	Hard Loss 0.2765 (0.4128)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.0%, 98.8%)	
07/26 06:59:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][700/703]	Step 47164	lr 0.00722	Loss 8.2903 (7.0226)	Hard Loss 0.4949 (0.4146)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.0%, 98.8%)	
07/26 06:59:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [66][703/703]	Step 47167	lr 0.00722	Loss 5.4149 (7.0233)	Hard Loss 0.3088 (0.4147)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (87.0%, 98.8%)	
07/26 06:59:21午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 66/99] Final Prec@1 86.9533%
07/26 06:59:24午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 66/99] Final Prec@1 63.9600%
07/26 06:59:24午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 64.5200%
07/26 06:59:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][50/703]	Step 47218	lr 0.00689	Loss 7.6505 (6.5064)	Hard Loss 0.4560 (0.3811)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (88.4%, 98.7%)	
07/26 06:59:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][100/703]	Step 47268	lr 0.00689	Loss 6.5865 (6.6785)	Hard Loss 0.3835 (0.3921)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (88.0%, 98.9%)	
07/26 06:59:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][150/703]	Step 47318	lr 0.00689	Loss 5.7043 (6.5840)	Hard Loss 0.3228 (0.3858)	Soft Loss 0.0033 (0.0030)	Prec@(1,5) (88.1%, 99.0%)	
07/26 07:00:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][200/703]	Step 47368	lr 0.00689	Loss 7.1442 (6.6197)	Hard Loss 0.4190 (0.3881)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (88.0%, 99.0%)	
07/26 07:00:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][250/703]	Step 47418	lr 0.00689	Loss 5.3455 (6.5974)	Hard Loss 0.3025 (0.3869)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.9%, 99.1%)	
07/26 07:00:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][300/703]	Step 47468	lr 0.00689	Loss 4.8554 (6.6277)	Hard Loss 0.2728 (0.3887)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.8%, 99.1%)	
07/26 07:00:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][350/703]	Step 47518	lr 0.00689	Loss 8.6451 (6.6920)	Hard Loss 0.5185 (0.3930)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (87.7%, 99.0%)	
07/26 07:00:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][400/703]	Step 47568	lr 0.00689	Loss 8.9056 (6.6920)	Hard Loss 0.5390 (0.3930)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (87.7%, 99.0%)	
07/26 07:00:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][450/703]	Step 47618	lr 0.00689	Loss 7.3359 (6.7475)	Hard Loss 0.4371 (0.3965)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 07:00:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][500/703]	Step 47668	lr 0.00689	Loss 4.9928 (6.7709)	Hard Loss 0.2828 (0.3981)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.6%, 99.0%)	
07/26 07:01:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][550/703]	Step 47718	lr 0.00689	Loss 8.3810 (6.8008)	Hard Loss 0.4979 (0.4001)	Soft Loss 0.0033 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 07:01:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][600/703]	Step 47768	lr 0.00689	Loss 6.6027 (6.7965)	Hard Loss 0.3863 (0.3997)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 07:01:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][650/703]	Step 47818	lr 0.00689	Loss 8.0091 (6.8174)	Hard Loss 0.4784 (0.4011)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 07:01:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][700/703]	Step 47868	lr 0.00689	Loss 4.9073 (6.8268)	Hard Loss 0.2790 (0.4017)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 07:01:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [67][703/703]	Step 47871	lr 0.00689	Loss 3.5755 (6.8244)	Hard Loss 0.1943 (0.4016)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (87.5%, 99.0%)	
07/26 07:01:36午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 67/99] Final Prec@1 87.4622%
07/26 07:01:40午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 67/99] Final Prec@1 65.0400%
07/26 07:01:40午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.0400%
07/26 07:01:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][50/703]	Step 47922	lr 0.00657	Loss 6.0289 (6.2444)	Hard Loss 0.3498 (0.3632)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.9%, 98.8%)	
07/26 07:01:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][100/703]	Step 47972	lr 0.00657	Loss 3.1046 (6.2379)	Hard Loss 0.1587 (0.3627)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (88.9%, 99.0%)	
07/26 07:02:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][150/703]	Step 48022	lr 0.00657	Loss 6.2186 (6.3353)	Hard Loss 0.3635 (0.3694)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (88.9%, 99.0%)	
07/26 07:02:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][200/703]	Step 48072	lr 0.00657	Loss 8.2009 (6.2329)	Hard Loss 0.4853 (0.3625)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (89.1%, 99.1%)	
07/26 07:02:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][250/703]	Step 48122	lr 0.00657	Loss 6.1268 (6.3209)	Hard Loss 0.3626 (0.3686)	Soft Loss 0.0034 (0.0030)	Prec@(1,5) (88.8%, 98.9%)	
07/26 07:02:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][300/703]	Step 48172	lr 0.00657	Loss 9.1734 (6.3212)	Hard Loss 0.5524 (0.3685)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (88.8%, 99.0%)	
07/26 07:02:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][350/703]	Step 48222	lr 0.00657	Loss 6.9991 (6.3523)	Hard Loss 0.4168 (0.3707)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (88.7%, 99.0%)	
07/26 07:02:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][400/703]	Step 48272	lr 0.00657	Loss 5.9788 (6.3656)	Hard Loss 0.3479 (0.3716)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (88.6%, 99.0%)	
07/26 07:03:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][450/703]	Step 48322	lr 0.00657	Loss 6.3376 (6.4277)	Hard Loss 0.3665 (0.3756)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (88.5%, 99.0%)	
07/26 07:03:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][500/703]	Step 48372	lr 0.00657	Loss 8.5818 (6.4594)	Hard Loss 0.5098 (0.3776)	Soft Loss 0.0034 (0.0031)	Prec@(1,5) (88.4%, 99.0%)	
07/26 07:03:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][550/703]	Step 48422	lr 0.00657	Loss 7.9140 (6.5233)	Hard Loss 0.4710 (0.3818)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (88.2%, 99.0%)	
07/26 07:03:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][600/703]	Step 48472	lr 0.00657	Loss 7.2211 (6.5620)	Hard Loss 0.4352 (0.3842)	Soft Loss 0.0027 (0.0031)	Prec@(1,5) (88.2%, 99.0%)	
07/26 07:03:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][650/703]	Step 48522	lr 0.00657	Loss 9.4318 (6.6013)	Hard Loss 0.5761 (0.3869)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (88.1%, 99.0%)	
07/26 07:03:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][700/703]	Step 48572	lr 0.00657	Loss 8.3472 (6.6255)	Hard Loss 0.4984 (0.3885)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (88.0%, 98.9%)	
07/26 07:03:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [68][703/703]	Step 48575	lr 0.00657	Loss 8.4743 (6.6284)	Hard Loss 0.5140 (0.3887)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (88.0%, 98.9%)	
07/26 07:03:52午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 68/99] Final Prec@1 87.9933%
07/26 07:03:55午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 68/99] Final Prec@1 65.2600%
07/26 07:03:56午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.2600%
07/26 07:04:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][50/703]	Step 48626	lr 0.00625	Loss 6.0234 (5.9516)	Hard Loss 0.3503 (0.3441)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (89.3%, 99.2%)	
07/26 07:04:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][100/703]	Step 48676	lr 0.00625	Loss 6.5977 (6.0860)	Hard Loss 0.3902 (0.3533)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (89.2%, 99.0%)	
07/26 07:04:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][150/703]	Step 48726	lr 0.00625	Loss 4.8800 (6.1264)	Hard Loss 0.2738 (0.3558)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (89.1%, 99.0%)	
07/26 07:04:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][200/703]	Step 48776	lr 0.00625	Loss 5.4536 (6.2086)	Hard Loss 0.3114 (0.3614)	Soft Loss 0.0027 (0.0030)	Prec@(1,5) (88.9%, 99.0%)	
07/26 07:04:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][250/703]	Step 48826	lr 0.00625	Loss 5.1173 (6.2098)	Hard Loss 0.2925 (0.3615)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (88.8%, 99.0%)	
07/26 07:04:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][300/703]	Step 48876	lr 0.00625	Loss 7.1964 (6.2521)	Hard Loss 0.4233 (0.3642)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.7%, 99.0%)	
07/26 07:05:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][350/703]	Step 48926	lr 0.00625	Loss 6.4411 (6.2340)	Hard Loss 0.3812 (0.3629)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.8%, 99.0%)	
07/26 07:05:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][400/703]	Step 48976	lr 0.00625	Loss 7.2492 (6.3002)	Hard Loss 0.4276 (0.3672)	Soft Loss 0.0033 (0.0030)	Prec@(1,5) (88.7%, 99.0%)	
07/26 07:05:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][450/703]	Step 49026	lr 0.00625	Loss 4.9528 (6.3144)	Hard Loss 0.2788 (0.3681)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.7%, 99.0%)	
07/26 07:05:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][500/703]	Step 49076	lr 0.00625	Loss 9.2652 (6.3735)	Hard Loss 0.5659 (0.3720)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.5%, 99.0%)	
07/26 07:05:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][550/703]	Step 49126	lr 0.00625	Loss 7.1462 (6.3769)	Hard Loss 0.4233 (0.3722)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.5%, 99.0%)	
07/26 07:05:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][600/703]	Step 49176	lr 0.00625	Loss 5.9760 (6.3708)	Hard Loss 0.3480 (0.3718)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (88.5%, 99.0%)	
07/26 07:05:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][650/703]	Step 49226	lr 0.00625	Loss 7.2899 (6.4089)	Hard Loss 0.4339 (0.3744)	Soft Loss 0.0030 (0.0030)	Prec@(1,5) (88.4%, 99.0%)	
07/26 07:06:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][700/703]	Step 49276	lr 0.00625	Loss 7.6914 (6.4431)	Hard Loss 0.4567 (0.3766)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (88.4%, 98.9%)	
07/26 07:06:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [69][703/703]	Step 49279	lr 0.00625	Loss 5.5492 (6.4400)	Hard Loss 0.3133 (0.3764)	Soft Loss 0.0029 (0.0030)	Prec@(1,5) (88.4%, 98.9%)	
07/26 07:06:08午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 69/99] Final Prec@1 88.3511%
07/26 07:06:11午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 69/99] Final Prec@1 64.3600%
07/26 07:06:11午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.2600%
07/26 07:06:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][50/703]	Step 49330	lr 0.00595	Loss 4.1678 (5.9746)	Hard Loss 0.2292 (0.3457)	Soft Loss 0.0028 (0.0030)	Prec@(1,5) (89.2%, 99.2%)	
07/26 07:06:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][100/703]	Step 49380	lr 0.00595	Loss 11.0562 (6.1169)	Hard Loss 0.6839 (0.3548)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (89.0%, 99.1%)	
07/26 07:06:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][150/703]	Step 49430	lr 0.00595	Loss 3.8533 (6.0751)	Hard Loss 0.2131 (0.3523)	Soft Loss 0.0035 (0.0031)	Prec@(1,5) (89.2%, 99.1%)	
07/26 07:06:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][200/703]	Step 49480	lr 0.00595	Loss 7.8267 (5.9534)	Hard Loss 0.4668 (0.3445)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (89.4%, 99.1%)	
07/26 07:06:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][250/703]	Step 49530	lr 0.00595	Loss 8.4068 (5.9797)	Hard Loss 0.5055 (0.3461)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.3%, 99.1%)	
07/26 07:07:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][300/703]	Step 49580	lr 0.00595	Loss 6.8616 (5.9827)	Hard Loss 0.4009 (0.3463)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.3%, 99.2%)	
07/26 07:07:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][350/703]	Step 49630	lr 0.00595	Loss 7.1156 (6.0407)	Hard Loss 0.4239 (0.3501)	Soft Loss 0.0036 (0.0031)	Prec@(1,5) (89.2%, 99.1%)	
07/26 07:07:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][400/703]	Step 49680	lr 0.00595	Loss 8.4188 (6.0555)	Hard Loss 0.5120 (0.3510)	Soft Loss 0.0027 (0.0031)	Prec@(1,5) (89.2%, 99.1%)	
07/26 07:07:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][450/703]	Step 49730	lr 0.00595	Loss 6.1758 (6.0677)	Hard Loss 0.3565 (0.3518)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.1%, 99.1%)	
07/26 07:07:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][500/703]	Step 49780	lr 0.00595	Loss 6.6190 (6.0850)	Hard Loss 0.3895 (0.3530)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (89.1%, 99.1%)	
07/26 07:07:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][550/703]	Step 49830	lr 0.00595	Loss 6.7964 (6.1028)	Hard Loss 0.3997 (0.3542)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.0%, 99.1%)	
07/26 07:08:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][600/703]	Step 49880	lr 0.00595	Loss 5.0681 (6.1322)	Hard Loss 0.2849 (0.3561)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (88.9%, 99.1%)	
07/26 07:08:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][650/703]	Step 49930	lr 0.00595	Loss 7.0304 (6.1755)	Hard Loss 0.4057 (0.3589)	Soft Loss 0.0028 (0.0031)	Prec@(1,5) (88.8%, 99.1%)	
07/26 07:08:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][700/703]	Step 49980	lr 0.00595	Loss 7.2473 (6.2216)	Hard Loss 0.4291 (0.3620)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (88.7%, 99.1%)	
07/26 07:08:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [70][703/703]	Step 49983	lr 0.00595	Loss 8.3029 (6.2265)	Hard Loss 0.4970 (0.3623)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (88.7%, 99.1%)	
07/26 07:08:24午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 70/99] Final Prec@1 88.7111%
07/26 07:08:27午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 70/99] Final Prec@1 65.8400%
07/26 07:08:27午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.8400%
07/26 07:08:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][50/703]	Step 50034	lr 0.00565	Loss 5.5667 (5.7467)	Hard Loss 0.3185 (0.3300)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.9%, 99.3%)	
07/26 07:08:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][100/703]	Step 50084	lr 0.00565	Loss 4.6019 (5.6575)	Hard Loss 0.2553 (0.3239)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.2%, 99.2%)	
07/26 07:08:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][150/703]	Step 50134	lr 0.00565	Loss 5.1629 (5.7269)	Hard Loss 0.2937 (0.3289)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.0%, 99.2%)	
07/26 07:09:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][200/703]	Step 50184	lr 0.00565	Loss 10.0067 (5.7347)	Hard Loss 0.6029 (0.3296)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.0%, 99.2%)	
07/26 07:09:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][250/703]	Step 50234	lr 0.00565	Loss 5.8136 (5.7648)	Hard Loss 0.3333 (0.3315)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.9%, 99.2%)	
07/26 07:09:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][300/703]	Step 50284	lr 0.00565	Loss 3.7648 (5.8283)	Hard Loss 0.2079 (0.3357)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (89.8%, 99.2%)	
07/26 07:09:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][350/703]	Step 50334	lr 0.00565	Loss 4.5712 (5.8538)	Hard Loss 0.2598 (0.3376)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.7%, 99.2%)	
07/26 07:09:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][400/703]	Step 50384	lr 0.00565	Loss 6.7994 (5.8512)	Hard Loss 0.3984 (0.3373)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (89.7%, 99.2%)	
07/26 07:09:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][450/703]	Step 50434	lr 0.00565	Loss 8.0669 (5.9021)	Hard Loss 0.4810 (0.3407)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (89.6%, 99.1%)	
07/26 07:10:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][500/703]	Step 50484	lr 0.00565	Loss 5.2523 (5.9260)	Hard Loss 0.3042 (0.3423)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.5%, 99.1%)	
07/26 07:10:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][550/703]	Step 50534	lr 0.00565	Loss 9.5088 (5.9481)	Hard Loss 0.5787 (0.3438)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (89.4%, 99.2%)	
07/26 07:10:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][600/703]	Step 50584	lr 0.00565	Loss 7.0723 (5.9509)	Hard Loss 0.4160 (0.3440)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.4%, 99.1%)	
07/26 07:10:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][650/703]	Step 50634	lr 0.00565	Loss 6.3370 (5.9803)	Hard Loss 0.3717 (0.3460)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (89.3%, 99.1%)	
07/26 07:10:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][700/703]	Step 50684	lr 0.00565	Loss 7.9930 (6.0088)	Hard Loss 0.4804 (0.3480)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.2%, 99.1%)	
07/26 07:10:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [71][703/703]	Step 50687	lr 0.00565	Loss 7.6377 (6.0143)	Hard Loss 0.4497 (0.3483)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.2%, 99.1%)	
07/26 07:10:39午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 71/99] Final Prec@1 89.1644%
07/26 07:10:43午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 71/99] Final Prec@1 64.7600%
07/26 07:10:43午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.8400%
07/26 07:10:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][50/703]	Step 50738	lr 0.00535	Loss 6.6681 (5.8787)	Hard Loss 0.3913 (0.3386)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.4%, 99.1%)	
07/26 07:11:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][100/703]	Step 50788	lr 0.00535	Loss 6.3978 (5.8015)	Hard Loss 0.3730 (0.3335)	Soft Loss 0.0031 (0.0030)	Prec@(1,5) (90.0%, 99.1%)	
07/26 07:11:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][150/703]	Step 50838	lr 0.00535	Loss 5.3791 (5.8090)	Hard Loss 0.3113 (0.3343)	Soft Loss 0.0032 (0.0030)	Prec@(1,5) (89.9%, 99.1%)	
07/26 07:11:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][200/703]	Step 50888	lr 0.00535	Loss 7.1753 (5.8161)	Hard Loss 0.4285 (0.3347)	Soft Loss 0.0035 (0.0030)	Prec@(1,5) (89.8%, 99.1%)	
07/26 07:11:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][250/703]	Step 50938	lr 0.00535	Loss 5.8083 (5.8324)	Hard Loss 0.3314 (0.3360)	Soft Loss 0.0035 (0.0031)	Prec@(1,5) (89.7%, 99.1%)	
07/26 07:11:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][300/703]	Step 50988	lr 0.00535	Loss 5.3519 (5.7787)	Hard Loss 0.3090 (0.3324)	Soft Loss 0.0035 (0.0031)	Prec@(1,5) (89.8%, 99.2%)	
07/26 07:11:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][350/703]	Step 51038	lr 0.00535	Loss 6.2254 (5.7574)	Hard Loss 0.3604 (0.3312)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (89.9%, 99.2%)	
07/26 07:11:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][400/703]	Step 51088	lr 0.00535	Loss 6.9687 (5.7883)	Hard Loss 0.4096 (0.3334)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.8%, 99.2%)	
07/26 07:12:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][450/703]	Step 51138	lr 0.00535	Loss 5.9643 (5.7604)	Hard Loss 0.3484 (0.3316)	Soft Loss 0.0034 (0.0031)	Prec@(1,5) (89.9%, 99.2%)	
07/26 07:12:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][500/703]	Step 51188	lr 0.00535	Loss 3.4920 (5.7560)	Hard Loss 0.1820 (0.3312)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (89.9%, 99.2%)	
07/26 07:12:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][550/703]	Step 51238	lr 0.00535	Loss 5.3882 (5.7940)	Hard Loss 0.3121 (0.3337)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (89.8%, 99.2%)	
07/26 07:12:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][600/703]	Step 51288	lr 0.00535	Loss 3.3828 (5.7944)	Hard Loss 0.1755 (0.3337)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (89.8%, 99.2%)	
07/26 07:12:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][650/703]	Step 51338	lr 0.00535	Loss 4.8124 (5.8010)	Hard Loss 0.2652 (0.3342)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (89.8%, 99.2%)	
07/26 07:12:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][700/703]	Step 51388	lr 0.00535	Loss 4.6726 (5.8200)	Hard Loss 0.2663 (0.3355)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (89.7%, 99.2%)	
07/26 07:12:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [72][703/703]	Step 51391	lr 0.00535	Loss 4.2947 (5.8160)	Hard Loss 0.2386 (0.3352)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (89.7%, 99.2%)	
07/26 07:12:55午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 72/99] Final Prec@1 89.7289%
07/26 07:12:58午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 72/99] Final Prec@1 65.2400%
07/26 07:12:59午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.8400%
07/26 07:13:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][50/703]	Step 51442	lr 0.00506	Loss 5.1445 (5.1879)	Hard Loss 0.2877 (0.2941)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (91.0%, 99.3%)	
07/26 07:13:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][100/703]	Step 51492	lr 0.00506	Loss 3.9665 (5.1756)	Hard Loss 0.2159 (0.2932)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (90.9%, 99.4%)	
07/26 07:13:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][150/703]	Step 51542	lr 0.00506	Loss 5.3521 (5.2437)	Hard Loss 0.3053 (0.2975)	Soft Loss 0.0034 (0.0031)	Prec@(1,5) (90.8%, 99.4%)	
07/26 07:13:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][200/703]	Step 51592	lr 0.00506	Loss 5.8336 (5.2861)	Hard Loss 0.3425 (0.3003)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (90.7%, 99.4%)	
07/26 07:13:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][250/703]	Step 51642	lr 0.00506	Loss 5.8844 (5.2787)	Hard Loss 0.3395 (0.3000)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.9%, 99.4%)	
07/26 07:13:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][300/703]	Step 51692	lr 0.00506	Loss 3.5103 (5.3345)	Hard Loss 0.1799 (0.3036)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (90.8%, 99.4%)	
07/26 07:14:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][350/703]	Step 51742	lr 0.00506	Loss 5.2009 (5.3867)	Hard Loss 0.2966 (0.3071)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (90.7%, 99.3%)	
07/26 07:14:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][400/703]	Step 51792	lr 0.00506	Loss 6.3915 (5.4417)	Hard Loss 0.3718 (0.3107)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (90.5%, 99.3%)	
07/26 07:14:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][450/703]	Step 51842	lr 0.00506	Loss 2.3626 (5.5084)	Hard Loss 0.1136 (0.3151)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.4%, 99.3%)	
07/26 07:14:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][500/703]	Step 51892	lr 0.00506	Loss 6.6886 (5.5371)	Hard Loss 0.3874 (0.3169)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.3%, 99.3%)	
07/26 07:14:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][550/703]	Step 51942	lr 0.00506	Loss 6.5360 (5.5689)	Hard Loss 0.3776 (0.3189)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (90.3%, 99.3%)	
07/26 07:14:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][600/703]	Step 51992	lr 0.00506	Loss 4.7466 (5.6023)	Hard Loss 0.2607 (0.3211)	Soft Loss 0.0033 (0.0031)	Prec@(1,5) (90.2%, 99.3%)	
07/26 07:15:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][650/703]	Step 52042	lr 0.00506	Loss 4.9001 (5.6243)	Hard Loss 0.2751 (0.3225)	Soft Loss 0.0028 (0.0031)	Prec@(1,5) (90.2%, 99.3%)	
07/26 07:15:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][700/703]	Step 52092	lr 0.00506	Loss 4.6070 (5.6143)	Hard Loss 0.2538 (0.3218)	Soft Loss 0.0028 (0.0031)	Prec@(1,5) (90.2%, 99.3%)	
07/26 07:15:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [73][703/703]	Step 52095	lr 0.00506	Loss 6.8941 (5.6178)	Hard Loss 0.4108 (0.3220)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (90.2%, 99.3%)	
07/26 07:15:11午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 73/99] Final Prec@1 90.1844%
07/26 07:15:14午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 73/99] Final Prec@1 65.6400%
07/26 07:15:15午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.8400%
07/26 07:15:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][50/703]	Step 52146	lr 0.00479	Loss 4.3911 (4.9082)	Hard Loss 0.2421 (0.2752)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (91.8%, 99.6%)	
07/26 07:15:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][100/703]	Step 52196	lr 0.00479	Loss 3.7134 (5.0025)	Hard Loss 0.1994 (0.2821)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (91.6%, 99.5%)	
07/26 07:15:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][150/703]	Step 52246	lr 0.00479	Loss 7.8539 (5.0692)	Hard Loss 0.4689 (0.2865)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.2%, 99.4%)	
07/26 07:15:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][200/703]	Step 52296	lr 0.00479	Loss 5.4597 (5.0962)	Hard Loss 0.3115 (0.2881)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (91.2%, 99.4%)	
07/26 07:16:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][250/703]	Step 52346	lr 0.00479	Loss 7.4096 (5.1676)	Hard Loss 0.4322 (0.2927)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (91.0%, 99.4%)	
07/26 07:16:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][300/703]	Step 52396	lr 0.00479	Loss 3.5461 (5.1476)	Hard Loss 0.1880 (0.2914)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (91.1%, 99.4%)	
07/26 07:16:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][350/703]	Step 52446	lr 0.00479	Loss 5.7578 (5.1687)	Hard Loss 0.3343 (0.2926)	Soft Loss 0.0027 (0.0031)	Prec@(1,5) (91.0%, 99.4%)	
07/26 07:16:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][400/703]	Step 52496	lr 0.00479	Loss 6.7392 (5.2088)	Hard Loss 0.3893 (0.2952)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.9%, 99.4%)	
07/26 07:16:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][450/703]	Step 52546	lr 0.00479	Loss 5.0071 (5.2389)	Hard Loss 0.2794 (0.2973)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (90.9%, 99.4%)	
07/26 07:16:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][500/703]	Step 52596	lr 0.00479	Loss 6.8028 (5.2601)	Hard Loss 0.3980 (0.2987)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (90.8%, 99.3%)	
07/26 07:16:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][550/703]	Step 52646	lr 0.00479	Loss 5.2734 (5.2786)	Hard Loss 0.2978 (0.2999)	Soft Loss 0.0032 (0.0031)	Prec@(1,5) (90.8%, 99.3%)	
07/26 07:17:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][600/703]	Step 52696	lr 0.00479	Loss 7.7626 (5.3056)	Hard Loss 0.4600 (0.3016)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (90.7%, 99.3%)	
07/26 07:17:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][650/703]	Step 52746	lr 0.00479	Loss 6.3738 (5.3369)	Hard Loss 0.3660 (0.3036)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (90.7%, 99.3%)	
07/26 07:17:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][700/703]	Step 52796	lr 0.00479	Loss 7.9419 (5.3701)	Hard Loss 0.4678 (0.3057)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (90.6%, 99.3%)	
07/26 07:17:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [74][703/703]	Step 52799	lr 0.00479	Loss 6.9065 (5.3747)	Hard Loss 0.4038 (0.3060)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (90.6%, 99.3%)	
07/26 07:17:27午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 74/99] Final Prec@1 90.6000%
07/26 07:17:30午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 74/99] Final Prec@1 65.7600%
07/26 07:17:30午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.8400%
07/26 07:17:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][50/703]	Step 52850	lr 0.00451	Loss 5.2549 (5.1355)	Hard Loss 0.3016 (0.2907)	Soft Loss 0.0034 (0.0031)	Prec@(1,5) (90.9%, 99.6%)	
07/26 07:17:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][100/703]	Step 52900	lr 0.00451	Loss 3.7458 (5.1054)	Hard Loss 0.1938 (0.2881)	Soft Loss 0.0031 (0.0031)	Prec@(1,5) (91.3%, 99.5%)	
07/26 07:17:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][150/703]	Step 52950	lr 0.00451	Loss 4.2466 (5.1155)	Hard Loss 0.2344 (0.2890)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (91.2%, 99.5%)	
07/26 07:18:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][200/703]	Step 53000	lr 0.00451	Loss 6.3934 (5.0924)	Hard Loss 0.3657 (0.2875)	Soft Loss 0.0029 (0.0031)	Prec@(1,5) (91.3%, 99.5%)	
07/26 07:18:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][250/703]	Step 53050	lr 0.00451	Loss 5.3857 (5.1339)	Hard Loss 0.3084 (0.2903)	Soft Loss 0.0034 (0.0031)	Prec@(1,5) (91.1%, 99.5%)	
07/26 07:18:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][300/703]	Step 53100	lr 0.00451	Loss 3.9531 (5.0716)	Hard Loss 0.2158 (0.2861)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (91.2%, 99.5%)	
07/26 07:18:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][350/703]	Step 53150	lr 0.00451	Loss 4.6900 (5.1162)	Hard Loss 0.2544 (0.2891)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (91.1%, 99.5%)	
07/26 07:18:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][400/703]	Step 53200	lr 0.00451	Loss 4.5815 (5.1383)	Hard Loss 0.2557 (0.2904)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.1%, 99.4%)	
07/26 07:18:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][450/703]	Step 53250	lr 0.00451	Loss 3.8712 (5.1138)	Hard Loss 0.2173 (0.2889)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (91.2%, 99.4%)	
07/26 07:19:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][500/703]	Step 53300	lr 0.00451	Loss 5.3733 (5.1225)	Hard Loss 0.3042 (0.2895)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.1%, 99.4%)	
07/26 07:19:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][550/703]	Step 53350	lr 0.00451	Loss 4.9137 (5.1341)	Hard Loss 0.2770 (0.2902)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.1%, 99.4%)	
07/26 07:19:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][600/703]	Step 53400	lr 0.00451	Loss 4.8499 (5.1597)	Hard Loss 0.2722 (0.2918)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (91.0%, 99.4%)	
07/26 07:19:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][650/703]	Step 53450	lr 0.00451	Loss 4.0704 (5.1795)	Hard Loss 0.2249 (0.2932)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.0%, 99.4%)	
07/26 07:19:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][700/703]	Step 53500	lr 0.00451	Loss 7.0399 (5.1957)	Hard Loss 0.4159 (0.2943)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.0%, 99.4%)	
07/26 07:19:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [75][703/703]	Step 53503	lr 0.00451	Loss 5.8939 (5.2006)	Hard Loss 0.3368 (0.2946)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.0%, 99.4%)	
07/26 07:19:43午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 75/99] Final Prec@1 90.9489%
07/26 07:19:46午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 75/99] Final Prec@1 65.9400%
07/26 07:19:46午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.9400%
07/26 07:19:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][50/703]	Step 53554	lr 0.00425	Loss 8.2314 (4.8461)	Hard Loss 0.4891 (0.2719)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.1%, 99.5%)	
07/26 07:20:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][100/703]	Step 53604	lr 0.00425	Loss 5.5334 (5.0875)	Hard Loss 0.3090 (0.2871)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.0%, 99.5%)	
07/26 07:20:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][150/703]	Step 53654	lr 0.00425	Loss 5.6116 (4.9373)	Hard Loss 0.3221 (0.2772)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.4%, 99.5%)	
07/26 07:20:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][200/703]	Step 53704	lr 0.00425	Loss 4.4441 (4.8971)	Hard Loss 0.2409 (0.2745)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (91.6%, 99.5%)	
07/26 07:20:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][250/703]	Step 53754	lr 0.00425	Loss 3.3652 (4.8347)	Hard Loss 0.1794 (0.2705)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.8%, 99.5%)	
07/26 07:20:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][300/703]	Step 53804	lr 0.00425	Loss 4.5735 (4.8969)	Hard Loss 0.2533 (0.2747)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:20:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][350/703]	Step 53854	lr 0.00425	Loss 4.2180 (4.9658)	Hard Loss 0.2314 (0.2792)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (91.6%, 99.4%)	
07/26 07:21:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][400/703]	Step 53904	lr 0.00425	Loss 4.4848 (5.0617)	Hard Loss 0.2420 (0.2854)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.4%, 99.4%)	
07/26 07:21:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][450/703]	Step 53954	lr 0.00425	Loss 5.8309 (5.0350)	Hard Loss 0.3329 (0.2837)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (91.5%, 99.4%)	
07/26 07:21:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][500/703]	Step 54004	lr 0.00425	Loss 6.9935 (5.0592)	Hard Loss 0.4087 (0.2854)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.4%, 99.4%)	
07/26 07:21:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][550/703]	Step 54054	lr 0.00425	Loss 6.4337 (5.0762)	Hard Loss 0.3743 (0.2865)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.3%, 99.4%)	
07/26 07:21:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][600/703]	Step 54104	lr 0.00425	Loss 3.7550 (5.1002)	Hard Loss 0.1918 (0.2880)	Soft Loss 0.0028 (0.0032)	Prec@(1,5) (91.2%, 99.5%)	
07/26 07:21:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][650/703]	Step 54154	lr 0.00425	Loss 3.5356 (5.0927)	Hard Loss 0.1873 (0.2875)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (91.2%, 99.5%)	
07/26 07:21:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][700/703]	Step 54204	lr 0.00425	Loss 6.5314 (5.1085)	Hard Loss 0.3785 (0.2885)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.1%, 99.5%)	
07/26 07:21:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [76][703/703]	Step 54207	lr 0.00425	Loss 6.4144 (5.1149)	Hard Loss 0.3754 (0.2890)	Soft Loss 0.0029 (0.0032)	Prec@(1,5) (91.1%, 99.5%)	
07/26 07:21:59午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 76/99] Final Prec@1 91.1111%
07/26 07:22:02午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 76/99] Final Prec@1 65.9200%
07/26 07:22:02午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 65.9400%
07/26 07:22:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][50/703]	Step 54258	lr 0.004	Loss 5.7737 (4.5774)	Hard Loss 0.3261 (0.2542)	Soft Loss 0.0030 (0.0031)	Prec@(1,5) (92.4%, 99.6%)	
07/26 07:22:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][100/703]	Step 54308	lr 0.004	Loss 4.1650 (4.6873)	Hard Loss 0.2303 (0.2613)	Soft Loss 0.0034 (0.0031)	Prec@(1,5) (92.1%, 99.6%)	
07/26 07:22:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][150/703]	Step 54358	lr 0.004	Loss 5.0371 (4.7589)	Hard Loss 0.2780 (0.2660)	Soft Loss 0.0028 (0.0032)	Prec@(1,5) (92.0%, 99.6%)	
07/26 07:22:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][200/703]	Step 54408	lr 0.004	Loss 3.7201 (4.7847)	Hard Loss 0.1965 (0.2676)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.0%, 99.6%)	
07/26 07:22:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][250/703]	Step 54458	lr 0.004	Loss 6.4351 (4.7957)	Hard Loss 0.3738 (0.2680)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.9%, 99.6%)	
07/26 07:22:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][300/703]	Step 54508	lr 0.004	Loss 4.3438 (4.8102)	Hard Loss 0.2342 (0.2689)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (91.8%, 99.6%)	
07/26 07:23:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][350/703]	Step 54558	lr 0.004	Loss 5.9816 (4.8383)	Hard Loss 0.3476 (0.2707)	Soft Loss 0.0027 (0.0032)	Prec@(1,5) (91.7%, 99.6%)	
07/26 07:23:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][400/703]	Step 54608	lr 0.004	Loss 4.4202 (4.8501)	Hard Loss 0.2488 (0.2715)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.7%, 99.6%)	
07/26 07:23:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][450/703]	Step 54658	lr 0.004	Loss 3.9702 (4.8837)	Hard Loss 0.2119 (0.2736)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:23:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][500/703]	Step 54708	lr 0.004	Loss 3.0953 (4.8790)	Hard Loss 0.1578 (0.2734)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:23:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][550/703]	Step 54758	lr 0.004	Loss 4.8467 (4.8968)	Hard Loss 0.2676 (0.2746)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:23:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][600/703]	Step 54808	lr 0.004	Loss 6.0637 (4.9019)	Hard Loss 0.3479 (0.2749)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.6%, 99.5%)	
07/26 07:24:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][650/703]	Step 54858	lr 0.004	Loss 2.7396 (4.8821)	Hard Loss 0.1356 (0.2736)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:24:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][700/703]	Step 54908	lr 0.004	Loss 4.9858 (4.8943)	Hard Loss 0.2821 (0.2745)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:24:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [77][703/703]	Step 54911	lr 0.004	Loss 4.8578 (4.8979)	Hard Loss 0.2639 (0.2747)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (91.7%, 99.5%)	
07/26 07:24:14午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 77/99] Final Prec@1 91.6533%
07/26 07:24:17午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 77/99] Final Prec@1 67.2200%
07/26 07:24:18午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 67.2200%
07/26 07:24:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][50/703]	Step 54962	lr 0.00375	Loss 4.3143 (4.3718)	Hard Loss 0.2375 (0.2408)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (92.9%, 99.8%)	
07/26 07:24:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][100/703]	Step 55012	lr 0.00375	Loss 4.6092 (4.5313)	Hard Loss 0.2534 (0.2507)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (92.4%, 99.6%)	
07/26 07:24:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][150/703]	Step 55062	lr 0.00375	Loss 3.7409 (4.5431)	Hard Loss 0.1881 (0.2513)	Soft Loss 0.0030 (0.0033)	Prec@(1,5) (92.3%, 99.6%)	
07/26 07:24:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][200/703]	Step 55112	lr 0.00375	Loss 5.3032 (4.5934)	Hard Loss 0.3015 (0.2547)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (92.2%, 99.6%)	
07/26 07:25:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][250/703]	Step 55162	lr 0.00375	Loss 5.4549 (4.6183)	Hard Loss 0.3092 (0.2562)	Soft Loss 0.0028 (0.0033)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:25:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][300/703]	Step 55212	lr 0.00375	Loss 3.3836 (4.6378)	Hard Loss 0.1673 (0.2574)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (92.1%, 99.6%)	
07/26 07:25:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][350/703]	Step 55262	lr 0.00375	Loss 5.6255 (4.6406)	Hard Loss 0.3194 (0.2578)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:25:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][400/703]	Step 55312	lr 0.00375	Loss 5.5664 (4.6371)	Hard Loss 0.3140 (0.2576)	Soft Loss 0.0029 (0.0033)	Prec@(1,5) (92.1%, 99.6%)	
07/26 07:25:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][450/703]	Step 55362	lr 0.00375	Loss 4.9354 (4.6463)	Hard Loss 0.2741 (0.2582)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (92.2%, 99.5%)	
07/26 07:25:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][500/703]	Step 55412	lr 0.00375	Loss 7.0199 (4.6942)	Hard Loss 0.4172 (0.2613)	Soft Loss 0.0037 (0.0032)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:26:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][550/703]	Step 55462	lr 0.00375	Loss 6.0141 (4.6809)	Hard Loss 0.3497 (0.2604)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (92.1%, 99.6%)	
07/26 07:26:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][600/703]	Step 55512	lr 0.00375	Loss 3.8757 (4.6960)	Hard Loss 0.2102 (0.2614)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:26:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][650/703]	Step 55562	lr 0.00375	Loss 8.7106 (4.6971)	Hard Loss 0.5307 (0.2614)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:26:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][700/703]	Step 55612	lr 0.00375	Loss 3.9626 (4.6917)	Hard Loss 0.2139 (0.2611)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:26:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [78][703/703]	Step 55615	lr 0.00375	Loss 5.9015 (4.6997)	Hard Loss 0.3371 (0.2616)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (92.1%, 99.5%)	
07/26 07:26:30午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 78/99] Final Prec@1 92.0556%
07/26 07:26:33午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 78/99] Final Prec@1 66.1600%
07/26 07:26:33午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 67.2200%
07/26 07:26:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][50/703]	Step 55666	lr 0.00352	Loss 5.4169 (4.2100)	Hard Loss 0.3093 (0.2291)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (93.7%, 99.7%)	
07/26 07:26:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][100/703]	Step 55716	lr 0.00352	Loss 4.6067 (4.3480)	Hard Loss 0.2499 (0.2382)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:27:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][150/703]	Step 55766	lr 0.00352	Loss 3.8512 (4.4292)	Hard Loss 0.2037 (0.2435)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.9%, 99.6%)	
07/26 07:27:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][200/703]	Step 55816	lr 0.00352	Loss 5.4341 (4.4369)	Hard Loss 0.3115 (0.2440)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (92.8%, 99.6%)	
07/26 07:27:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][250/703]	Step 55866	lr 0.00352	Loss 9.3664 (4.4588)	Hard Loss 0.5666 (0.2453)	Soft Loss 0.0033 (0.0032)	Prec@(1,5) (92.8%, 99.6%)	
07/26 07:27:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][300/703]	Step 55916	lr 0.00352	Loss 4.3345 (4.4404)	Hard Loss 0.2390 (0.2443)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.8%, 99.6%)	
07/26 07:27:39午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][350/703]	Step 55966	lr 0.00352	Loss 3.8316 (4.4513)	Hard Loss 0.2062 (0.2450)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.8%, 99.6%)	
07/26 07:27:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][400/703]	Step 56016	lr 0.00352	Loss 6.0408 (4.4887)	Hard Loss 0.3487 (0.2475)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (92.7%, 99.6%)	
07/26 07:27:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][450/703]	Step 56066	lr 0.00352	Loss 2.6855 (4.4629)	Hard Loss 0.1280 (0.2459)	Soft Loss 0.0035 (0.0032)	Prec@(1,5) (92.7%, 99.6%)	
07/26 07:28:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][500/703]	Step 56116	lr 0.00352	Loss 5.2437 (4.4729)	Hard Loss 0.3014 (0.2464)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.7%, 99.6%)	
07/26 07:28:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][550/703]	Step 56166	lr 0.00352	Loss 4.2989 (4.5018)	Hard Loss 0.2362 (0.2483)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (92.6%, 99.6%)	
07/26 07:28:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][600/703]	Step 56216	lr 0.00352	Loss 3.4756 (4.5282)	Hard Loss 0.1882 (0.2500)	Soft Loss 0.0034 (0.0032)	Prec@(1,5) (92.5%, 99.6%)	
07/26 07:28:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][650/703]	Step 56266	lr 0.00352	Loss 4.7645 (4.5524)	Hard Loss 0.2674 (0.2517)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (92.5%, 99.6%)	
07/26 07:28:45午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][700/703]	Step 56316	lr 0.00352	Loss 2.1353 (4.5676)	Hard Loss 0.0956 (0.2528)	Soft Loss 0.0032 (0.0032)	Prec@(1,5) (92.4%, 99.6%)	
07/26 07:28:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [79][703/703]	Step 56319	lr 0.00352	Loss 4.6545 (4.5695)	Hard Loss 0.2520 (0.2529)	Soft Loss 0.0028 (0.0032)	Prec@(1,5) (92.4%, 99.6%)	
07/26 07:28:46午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 79/99] Final Prec@1 92.4089%
07/26 07:28:49午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 79/99] Final Prec@1 67.3200%
07/26 07:28:49午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 67.3200%
07/26 07:28:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][50/703]	Step 56370	lr 0.00329	Loss 3.6220 (4.1299)	Hard Loss 0.1866 (0.2234)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (93.4%, 99.5%)	
07/26 07:29:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][100/703]	Step 56420	lr 0.00329	Loss 2.7471 (4.0767)	Hard Loss 0.1308 (0.2203)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (93.6%, 99.6%)	
07/26 07:29:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][150/703]	Step 56470	lr 0.00329	Loss 6.2702 (4.1632)	Hard Loss 0.3614 (0.2260)	Soft Loss 0.0031 (0.0032)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:29:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][200/703]	Step 56520	lr 0.00329	Loss 2.0194 (4.2115)	Hard Loss 0.0812 (0.2292)	Soft Loss 0.0030 (0.0032)	Prec@(1,5) (93.4%, 99.6%)	
07/26 07:29:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][250/703]	Step 56570	lr 0.00329	Loss 3.9959 (4.2459)	Hard Loss 0.2209 (0.2314)	Soft Loss 0.0036 (0.0032)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:29:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][300/703]	Step 56620	lr 0.00329	Loss 3.2937 (4.2492)	Hard Loss 0.1729 (0.2318)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:29:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][350/703]	Step 56670	lr 0.00329	Loss 5.8824 (4.2311)	Hard Loss 0.3412 (0.2308)	Soft Loss 0.0029 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:30:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][400/703]	Step 56720	lr 0.00329	Loss 3.9807 (4.2664)	Hard Loss 0.2015 (0.2331)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:30:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][450/703]	Step 56770	lr 0.00329	Loss 3.8095 (4.3020)	Hard Loss 0.2052 (0.2354)	Soft Loss 0.0035 (0.0033)	Prec@(1,5) (93.0%, 99.6%)	
07/26 07:30:23午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][500/703]	Step 56820	lr 0.00329	Loss 4.8298 (4.3644)	Hard Loss 0.2687 (0.2394)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (92.9%, 99.6%)	
07/26 07:30:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][550/703]	Step 56870	lr 0.00329	Loss 5.1924 (4.3685)	Hard Loss 0.2917 (0.2397)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (92.9%, 99.6%)	
07/26 07:30:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][600/703]	Step 56920	lr 0.00329	Loss 4.4753 (4.3744)	Hard Loss 0.2496 (0.2400)	Soft Loss 0.0039 (0.0033)	Prec@(1,5) (92.9%, 99.6%)	
07/26 07:30:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][650/703]	Step 56970	lr 0.00329	Loss 6.0561 (4.3903)	Hard Loss 0.3474 (0.2411)	Soft Loss 0.0035 (0.0033)	Prec@(1,5) (92.8%, 99.6%)	
07/26 07:31:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][700/703]	Step 57020	lr 0.00329	Loss 5.0672 (4.4226)	Hard Loss 0.2856 (0.2433)	Soft Loss 0.0037 (0.0033)	Prec@(1,5) (92.7%, 99.6%)	
07/26 07:31:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [80][703/703]	Step 57023	lr 0.00329	Loss 4.3001 (4.4270)	Hard Loss 0.2353 (0.2436)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (92.7%, 99.6%)	
07/26 07:31:03午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 80/99] Final Prec@1 92.7244%
07/26 07:31:06午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 80/99] Final Prec@1 66.9200%
07/26 07:31:07午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 67.3200%
07/26 07:31:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][50/703]	Step 57074	lr 0.00308	Loss 2.6844 (4.0962)	Hard Loss 0.1280 (0.2217)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.4%, 99.7%)	
07/26 07:31:26午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][100/703]	Step 57124	lr 0.00308	Loss 3.1007 (4.1699)	Hard Loss 0.1560 (0.2267)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (93.3%, 99.7%)	
07/26 07:31:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][150/703]	Step 57174	lr 0.00308	Loss 3.2149 (4.1860)	Hard Loss 0.1660 (0.2280)	Soft Loss 0.0036 (0.0033)	Prec@(1,5) (93.2%, 99.7%)	
07/26 07:31:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][200/703]	Step 57224	lr 0.00308	Loss 3.8222 (4.1791)	Hard Loss 0.2055 (0.2275)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.3%, 99.7%)	
07/26 07:31:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][250/703]	Step 57274	lr 0.00308	Loss 4.4695 (4.1666)	Hard Loss 0.2470 (0.2267)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:32:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][300/703]	Step 57324	lr 0.00308	Loss 4.8759 (4.1575)	Hard Loss 0.2701 (0.2262)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:32:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][350/703]	Step 57374	lr 0.00308	Loss 4.0902 (4.2106)	Hard Loss 0.2222 (0.2297)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:32:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][400/703]	Step 57424	lr 0.00308	Loss 4.2938 (4.1893)	Hard Loss 0.2371 (0.2283)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:32:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][450/703]	Step 57474	lr 0.00308	Loss 2.6941 (4.2067)	Hard Loss 0.1294 (0.2294)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:32:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][500/703]	Step 57524	lr 0.00308	Loss 2.9423 (4.2086)	Hard Loss 0.1504 (0.2295)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:32:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][550/703]	Step 57574	lr 0.00308	Loss 3.6774 (4.2153)	Hard Loss 0.1944 (0.2300)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:32:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][600/703]	Step 57624	lr 0.00308	Loss 4.5790 (4.2155)	Hard Loss 0.2527 (0.2299)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:33:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][650/703]	Step 57674	lr 0.00308	Loss 4.9257 (4.2403)	Hard Loss 0.2816 (0.2315)	Soft Loss 0.0041 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:33:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][700/703]	Step 57724	lr 0.00308	Loss 3.8289 (4.2593)	Hard Loss 0.2060 (0.2328)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:33:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [81][703/703]	Step 57727	lr 0.00308	Loss 4.4906 (4.2608)	Hard Loss 0.2533 (0.2330)	Soft Loss 0.0039 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:33:19午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 81/99] Final Prec@1 93.0667%
07/26 07:33:22午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 81/99] Final Prec@1 66.5200%
07/26 07:33:22午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 67.3200%
07/26 07:33:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][50/703]	Step 57778	lr 0.00287	Loss 3.5958 (3.9221)	Hard Loss 0.1884 (0.2103)	Soft Loss 0.0029 (0.0033)	Prec@(1,5) (93.9%, 99.7%)	
07/26 07:33:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][100/703]	Step 57828	lr 0.00287	Loss 7.4659 (3.9737)	Hard Loss 0.4370 (0.2137)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.6%, 99.7%)	
07/26 07:33:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][150/703]	Step 57878	lr 0.00287	Loss 4.8171 (3.9853)	Hard Loss 0.2622 (0.2143)	Soft Loss 0.0035 (0.0033)	Prec@(1,5) (93.6%, 99.7%)	
07/26 07:34:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][200/703]	Step 57928	lr 0.00287	Loss 2.8145 (3.9806)	Hard Loss 0.1345 (0.2139)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.7%, 99.7%)	
07/26 07:34:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][250/703]	Step 57978	lr 0.00287	Loss 4.4321 (4.0523)	Hard Loss 0.2480 (0.2188)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.5%, 99.7%)	
07/26 07:34:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][300/703]	Step 58028	lr 0.00287	Loss 2.5322 (4.0957)	Hard Loss 0.1224 (0.2217)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.4%, 99.7%)	
07/26 07:34:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][350/703]	Step 58078	lr 0.00287	Loss 4.8935 (4.1445)	Hard Loss 0.2727 (0.2250)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:34:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][400/703]	Step 58128	lr 0.00287	Loss 4.0207 (4.1608)	Hard Loss 0.2144 (0.2260)	Soft Loss 0.0029 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:34:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][450/703]	Step 58178	lr 0.00287	Loss 5.0398 (4.1636)	Hard Loss 0.2765 (0.2263)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:34:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][500/703]	Step 58228	lr 0.00287	Loss 4.4469 (4.1566)	Hard Loss 0.2540 (0.2258)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (93.4%, 99.6%)	
07/26 07:35:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][550/703]	Step 58278	lr 0.00287	Loss 5.1024 (4.1879)	Hard Loss 0.2910 (0.2278)	Soft Loss 0.0037 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:35:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][600/703]	Step 58328	lr 0.00287	Loss 2.6865 (4.1949)	Hard Loss 0.1286 (0.2283)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.3%, 99.6%)	
07/26 07:35:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][650/703]	Step 58378	lr 0.00287	Loss 5.2634 (4.2052)	Hard Loss 0.2954 (0.2291)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:35:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][700/703]	Step 58428	lr 0.00287	Loss 4.1041 (4.2164)	Hard Loss 0.2263 (0.2299)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.2%, 99.6%)	
07/26 07:35:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [82][703/703]	Step 58431	lr 0.00287	Loss 4.8156 (4.2201)	Hard Loss 0.2666 (0.2301)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (93.1%, 99.6%)	
07/26 07:35:35午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 82/99] Final Prec@1 93.1422%
07/26 07:35:38午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 82/99] Final Prec@1 68.1000%
07/26 07:35:38午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:35:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][50/703]	Step 58482	lr 0.00267	Loss 3.9118 (4.1151)	Hard Loss 0.2080 (0.2226)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (93.6%, 99.4%)	
07/26 07:35:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][100/703]	Step 58532	lr 0.00267	Loss 4.5110 (4.0285)	Hard Loss 0.2474 (0.2172)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (93.6%, 99.5%)	
07/26 07:36:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][150/703]	Step 58582	lr 0.00267	Loss 4.2691 (3.9611)	Hard Loss 0.2342 (0.2127)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (93.7%, 99.6%)	
07/26 07:36:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][200/703]	Step 58632	lr 0.00267	Loss 3.6365 (4.0185)	Hard Loss 0.1866 (0.2167)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (93.6%, 99.5%)	
07/26 07:36:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][250/703]	Step 58682	lr 0.00267	Loss 4.7527 (4.0364)	Hard Loss 0.2633 (0.2179)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (93.5%, 99.5%)	
07/26 07:36:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][300/703]	Step 58732	lr 0.00267	Loss 5.4705 (4.0235)	Hard Loss 0.3181 (0.2171)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (93.6%, 99.6%)	
07/26 07:36:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][350/703]	Step 58782	lr 0.00267	Loss 6.4696 (4.0615)	Hard Loss 0.3685 (0.2197)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (93.5%, 99.5%)	
07/26 07:36:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][400/703]	Step 58832	lr 0.00267	Loss 6.0808 (4.0717)	Hard Loss 0.3543 (0.2203)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (93.4%, 99.5%)	
07/26 07:37:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][450/703]	Step 58882	lr 0.00267	Loss 4.3969 (4.0552)	Hard Loss 0.2409 (0.2193)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (93.5%, 99.5%)	
07/26 07:37:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][500/703]	Step 58932	lr 0.00267	Loss 3.2859 (4.0465)	Hard Loss 0.1632 (0.2188)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:37:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][550/703]	Step 58982	lr 0.00267	Loss 5.0322 (4.0734)	Hard Loss 0.2814 (0.2204)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:37:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][600/703]	Step 59032	lr 0.00267	Loss 3.6655 (4.0623)	Hard Loss 0.1958 (0.2198)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:37:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][650/703]	Step 59082	lr 0.00267	Loss 4.3733 (4.0625)	Hard Loss 0.2417 (0.2199)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:37:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][700/703]	Step 59132	lr 0.00267	Loss 4.7212 (4.0634)	Hard Loss 0.2563 (0.2200)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:37:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [83][703/703]	Step 59135	lr 0.00267	Loss 3.0525 (4.0619)	Hard Loss 0.1557 (0.2199)	Soft Loss 0.0028 (0.0034)	Prec@(1,5) (93.5%, 99.6%)	
07/26 07:37:50午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 83/99] Final Prec@1 93.4778%
07/26 07:37:54午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 83/99] Final Prec@1 66.6800%
07/26 07:37:54午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:38:04午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][50/703]	Step 59186	lr 0.00248	Loss 3.3578 (3.9247)	Hard Loss 0.1703 (0.2097)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:38:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][100/703]	Step 59236	lr 0.00248	Loss 4.5571 (3.8635)	Hard Loss 0.2497 (0.2065)	Soft Loss 0.0035 (0.0033)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:38:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][150/703]	Step 59286	lr 0.00248	Loss 3.9552 (3.8492)	Hard Loss 0.2175 (0.2055)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:38:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][200/703]	Step 59336	lr 0.00248	Loss 4.8760 (3.8461)	Hard Loss 0.2691 (0.2056)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:38:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][250/703]	Step 59386	lr 0.00248	Loss 5.3934 (3.8922)	Hard Loss 0.3036 (0.2087)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.0%, 99.7%)	
07/26 07:38:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][300/703]	Step 59436	lr 0.00248	Loss 2.7745 (3.9087)	Hard Loss 0.1256 (0.2097)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (93.8%, 99.7%)	
07/26 07:39:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][350/703]	Step 59486	lr 0.00248	Loss 2.9425 (3.9579)	Hard Loss 0.1477 (0.2127)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (93.7%, 99.7%)	
07/26 07:39:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][400/703]	Step 59536	lr 0.00248	Loss 2.7855 (3.9826)	Hard Loss 0.1363 (0.2144)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (93.6%, 99.7%)	
07/26 07:39:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][450/703]	Step 59586	lr 0.00248	Loss 4.5715 (4.0069)	Hard Loss 0.2547 (0.2162)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (93.5%, 99.7%)	
07/26 07:39:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][500/703]	Step 59636	lr 0.00248	Loss 5.4106 (4.0209)	Hard Loss 0.3040 (0.2171)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (93.4%, 99.7%)	
07/26 07:39:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][550/703]	Step 59686	lr 0.00248	Loss 5.8486 (4.0043)	Hard Loss 0.3337 (0.2160)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (93.5%, 99.7%)	
07/26 07:39:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][600/703]	Step 59736	lr 0.00248	Loss 2.8464 (3.9968)	Hard Loss 0.1403 (0.2155)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (93.5%, 99.7%)	
07/26 07:39:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][650/703]	Step 59786	lr 0.00248	Loss 4.0226 (3.9937)	Hard Loss 0.2244 (0.2154)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (93.5%, 99.7%)	
07/26 07:40:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][700/703]	Step 59836	lr 0.00248	Loss 2.1510 (3.9997)	Hard Loss 0.0938 (0.2157)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (93.6%, 99.7%)	
07/26 07:40:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [84][703/703]	Step 59839	lr 0.00248	Loss 3.4293 (3.9979)	Hard Loss 0.1841 (0.2156)	Soft Loss 0.0033 (0.0033)	Prec@(1,5) (93.6%, 99.7%)	
07/26 07:40:06午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 84/99] Final Prec@1 93.5622%
07/26 07:40:10午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 84/99] Final Prec@1 66.9000%
07/26 07:40:10午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:40:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][50/703]	Step 59890	lr 0.00231	Loss 3.8916 (3.7864)	Hard Loss 0.2045 (0.2013)	Soft Loss 0.0030 (0.0033)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:40:29午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][100/703]	Step 59940	lr 0.00231	Loss 2.2566 (3.7709)	Hard Loss 0.0993 (0.2008)	Soft Loss 0.0034 (0.0033)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:40:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][150/703]	Step 59990	lr 0.00231	Loss 3.8454 (3.7087)	Hard Loss 0.2025 (0.1966)	Soft Loss 0.0040 (0.0033)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:40:48午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][200/703]	Step 60040	lr 0.00231	Loss 3.1851 (3.7197)	Hard Loss 0.1553 (0.1972)	Soft Loss 0.0031 (0.0033)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:40:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][250/703]	Step 60090	lr 0.00231	Loss 4.3856 (3.6833)	Hard Loss 0.2421 (0.1948)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (94.5%, 99.7%)	
07/26 07:41:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][300/703]	Step 60140	lr 0.00231	Loss 4.6639 (3.7553)	Hard Loss 0.2630 (0.1996)	Soft Loss 0.0030 (0.0033)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:41:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][350/703]	Step 60190	lr 0.00231	Loss 3.9864 (3.7654)	Hard Loss 0.2160 (0.2003)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:41:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][400/703]	Step 60240	lr 0.00231	Loss 4.0708 (3.7758)	Hard Loss 0.2196 (0.2010)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:41:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][450/703]	Step 60290	lr 0.00231	Loss 3.2457 (3.7936)	Hard Loss 0.1621 (0.2020)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:41:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][500/703]	Step 60340	lr 0.00231	Loss 5.1701 (3.7683)	Hard Loss 0.2950 (0.2005)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:41:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][550/703]	Step 60390	lr 0.00231	Loss 3.8092 (3.7871)	Hard Loss 0.2074 (0.2017)	Soft Loss 0.0038 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:42:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][600/703]	Step 60440	lr 0.00231	Loss 5.3359 (3.7903)	Hard Loss 0.3013 (0.2019)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:42:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][650/703]	Step 60490	lr 0.00231	Loss 3.4204 (3.8056)	Hard Loss 0.1817 (0.2029)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:42:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][700/703]	Step 60540	lr 0.00231	Loss 4.1760 (3.8086)	Hard Loss 0.2200 (0.2031)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:42:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [85][703/703]	Step 60543	lr 0.00231	Loss 2.4508 (3.8103)	Hard Loss 0.1106 (0.2032)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:42:22午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 85/99] Final Prec@1 94.1378%
07/26 07:42:25午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 85/99] Final Prec@1 67.0200%
07/26 07:42:25午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:42:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][50/703]	Step 60594	lr 0.00214	Loss 4.2611 (3.5632)	Hard Loss 0.2353 (0.1875)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.7%, 99.7%)	
07/26 07:42:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][100/703]	Step 60644	lr 0.00214	Loss 4.5403 (3.5688)	Hard Loss 0.2464 (0.1871)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.7%, 99.8%)	
07/26 07:42:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][150/703]	Step 60694	lr 0.00214	Loss 3.7992 (3.6764)	Hard Loss 0.2036 (0.1943)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:43:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][200/703]	Step 60744	lr 0.00214	Loss 4.1375 (3.6740)	Hard Loss 0.2189 (0.1939)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:43:13午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][250/703]	Step 60794	lr 0.00214	Loss 3.6941 (3.6895)	Hard Loss 0.1953 (0.1951)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:43:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][300/703]	Step 60844	lr 0.00214	Loss 2.5958 (3.6897)	Hard Loss 0.1235 (0.1952)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:43:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][350/703]	Step 60894	lr 0.00214	Loss 3.1130 (3.7086)	Hard Loss 0.1557 (0.1964)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:43:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][400/703]	Step 60944	lr 0.00214	Loss 2.5787 (3.7028)	Hard Loss 0.1292 (0.1961)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:43:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][450/703]	Step 60994	lr 0.00214	Loss 2.3918 (3.7110)	Hard Loss 0.1076 (0.1967)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:43:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][500/703]	Step 61044	lr 0.00214	Loss 2.1915 (3.7206)	Hard Loss 0.1030 (0.1972)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:44:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][550/703]	Step 61094	lr 0.00214	Loss 3.6729 (3.7216)	Hard Loss 0.1962 (0.1973)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:44:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][600/703]	Step 61144	lr 0.00214	Loss 4.6705 (3.7372)	Hard Loss 0.2658 (0.1983)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:44:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][650/703]	Step 61194	lr 0.00214	Loss 3.0760 (3.7585)	Hard Loss 0.1645 (0.1997)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:44:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][700/703]	Step 61244	lr 0.00214	Loss 7.5208 (3.7844)	Hard Loss 0.4459 (0.2015)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.1%, 99.6%)	
07/26 07:44:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [86][703/703]	Step 61247	lr 0.00214	Loss 4.6642 (3.7880)	Hard Loss 0.2581 (0.2017)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.1%, 99.6%)	
07/26 07:44:38午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 86/99] Final Prec@1 94.1200%
07/26 07:44:41午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 86/99] Final Prec@1 67.4200%
07/26 07:44:41午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:44:51午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][50/703]	Step 61298	lr 0.00199	Loss 3.4643 (3.8023)	Hard Loss 0.1744 (0.2029)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:45:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][100/703]	Step 61348	lr 0.00199	Loss 4.8730 (3.7568)	Hard Loss 0.2707 (0.2003)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:45:10午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][150/703]	Step 61398	lr 0.00199	Loss 3.9129 (3.7540)	Hard Loss 0.2100 (0.1997)	Soft Loss 0.0032 (0.0033)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:45:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][200/703]	Step 61448	lr 0.00199	Loss 2.9727 (3.7126)	Hard Loss 0.1427 (0.1970)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.5%, 99.7%)	
07/26 07:45:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][250/703]	Step 61498	lr 0.00199	Loss 3.2546 (3.7348)	Hard Loss 0.1722 (0.1983)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:45:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][300/703]	Step 61548	lr 0.00199	Loss 5.0785 (3.7090)	Hard Loss 0.2913 (0.1967)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:45:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][350/703]	Step 61598	lr 0.00199	Loss 4.0201 (3.7380)	Hard Loss 0.2130 (0.1985)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:45:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][400/703]	Step 61648	lr 0.00199	Loss 4.3151 (3.7575)	Hard Loss 0.2367 (0.1999)	Soft Loss 0.0038 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:46:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][450/703]	Step 61698	lr 0.00199	Loss 4.1252 (3.7412)	Hard Loss 0.2239 (0.1988)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][500/703]	Step 61748	lr 0.00199	Loss 4.6355 (3.7480)	Hard Loss 0.2573 (0.1992)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][550/703]	Step 61798	lr 0.00199	Loss 4.4155 (3.7403)	Hard Loss 0.2425 (0.1988)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][600/703]	Step 61848	lr 0.00199	Loss 3.7591 (3.7526)	Hard Loss 0.2010 (0.1997)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][650/703]	Step 61898	lr 0.00199	Loss 4.0457 (3.7507)	Hard Loss 0.2204 (0.1995)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][700/703]	Step 61948	lr 0.00199	Loss 3.5385 (3.7493)	Hard Loss 0.1820 (0.1994)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [87][703/703]	Step 61951	lr 0.00199	Loss 3.0036 (3.7497)	Hard Loss 0.1483 (0.1994)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.1%, 99.7%)	
07/26 07:46:54午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 87/99] Final Prec@1 94.0911%
07/26 07:46:57午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 87/99] Final Prec@1 67.5200%
07/26 07:46:57午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:47:07午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][50/703]	Step 62002	lr 0.00184	Loss 4.2740 (3.7457)	Hard Loss 0.2336 (0.1994)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:47:16午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][100/703]	Step 62052	lr 0.00184	Loss 2.7045 (3.6299)	Hard Loss 0.1303 (0.1919)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:47:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][150/703]	Step 62102	lr 0.00184	Loss 2.3087 (3.5664)	Hard Loss 0.1009 (0.1876)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:47:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][200/703]	Step 62152	lr 0.00184	Loss 3.0956 (3.5740)	Hard Loss 0.1567 (0.1879)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:47:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][250/703]	Step 62202	lr 0.00184	Loss 4.3561 (3.5999)	Hard Loss 0.2403 (0.1897)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:47:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][300/703]	Step 62252	lr 0.00184	Loss 3.1665 (3.6385)	Hard Loss 0.1617 (0.1921)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.2%, 99.7%)	
07/26 07:48:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][350/703]	Step 62302	lr 0.00184	Loss 2.9795 (3.6032)	Hard Loss 0.1453 (0.1899)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:48:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][400/703]	Step 62352	lr 0.00184	Loss 2.6792 (3.6289)	Hard Loss 0.1312 (0.1913)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.4%, 99.7%)	
07/26 07:48:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][450/703]	Step 62402	lr 0.00184	Loss 3.3135 (3.6427)	Hard Loss 0.1743 (0.1923)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:48:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][500/703]	Step 62452	lr 0.00184	Loss 3.6768 (3.6293)	Hard Loss 0.2011 (0.1915)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:48:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][550/703]	Step 62502	lr 0.00184	Loss 4.0624 (3.6399)	Hard Loss 0.2197 (0.1922)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:48:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][600/703]	Step 62552	lr 0.00184	Loss 4.0458 (3.6400)	Hard Loss 0.2174 (0.1922)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:48:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][650/703]	Step 62602	lr 0.00184	Loss 4.6067 (3.6352)	Hard Loss 0.2587 (0.1919)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:49:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][700/703]	Step 62652	lr 0.00184	Loss 5.2264 (3.6411)	Hard Loss 0.3038 (0.1922)	Soft Loss 0.0039 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:49:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [88][703/703]	Step 62655	lr 0.00184	Loss 3.8360 (3.6404)	Hard Loss 0.2092 (0.1922)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.3%, 99.7%)	
07/26 07:49:09午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 88/99] Final Prec@1 94.3333%
07/26 07:49:12午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 88/99] Final Prec@1 67.3400%
07/26 07:49:13午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:49:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][50/703]	Step 62706	lr 0.00171	Loss 4.3371 (3.4627)	Hard Loss 0.2399 (0.1804)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.8%, 99.6%)	
07/26 07:49:32午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][100/703]	Step 62756	lr 0.00171	Loss 4.2708 (3.5479)	Hard Loss 0.2277 (0.1859)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.5%, 99.7%)	
07/26 07:49:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][150/703]	Step 62806	lr 0.00171	Loss 3.7664 (3.4450)	Hard Loss 0.2006 (0.1795)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.8%, 99.7%)	
07/26 07:49:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][200/703]	Step 62856	lr 0.00171	Loss 2.4702 (3.4706)	Hard Loss 0.1107 (0.1814)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:50:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][250/703]	Step 62906	lr 0.00171	Loss 2.1545 (3.4802)	Hard Loss 0.0947 (0.1818)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:50:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][300/703]	Step 62956	lr 0.00171	Loss 2.3889 (3.4632)	Hard Loss 0.1136 (0.1807)	Soft Loss 0.0038 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:50:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][350/703]	Step 63006	lr 0.00171	Loss 3.5730 (3.4680)	Hard Loss 0.1861 (0.1811)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:50:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][400/703]	Step 63056	lr 0.00171	Loss 4.0692 (3.5118)	Hard Loss 0.2135 (0.1839)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.8%, 99.7%)	
07/26 07:50:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][450/703]	Step 63106	lr 0.00171	Loss 2.4277 (3.5357)	Hard Loss 0.1171 (0.1856)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (94.7%, 99.7%)	
07/26 07:50:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][500/703]	Step 63156	lr 0.00171	Loss 3.5512 (3.5783)	Hard Loss 0.1873 (0.1882)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:50:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][550/703]	Step 63206	lr 0.00171	Loss 4.0906 (3.5979)	Hard Loss 0.2237 (0.1895)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:51:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][600/703]	Step 63256	lr 0.00171	Loss 3.7452 (3.6235)	Hard Loss 0.1950 (0.1911)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.5%, 99.7%)	
07/26 07:51:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][650/703]	Step 63306	lr 0.00171	Loss 3.3529 (3.6223)	Hard Loss 0.1767 (0.1911)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.5%, 99.7%)	
07/26 07:51:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][700/703]	Step 63356	lr 0.00171	Loss 4.3347 (3.6071)	Hard Loss 0.2404 (0.1901)	Soft Loss 0.0038 (0.0034)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:51:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [89][703/703]	Step 63359	lr 0.00171	Loss 4.2368 (3.6051)	Hard Loss 0.2262 (0.1899)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:51:25午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 89/99] Final Prec@1 94.5711%
07/26 07:51:28午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 89/99] Final Prec@1 66.5400%
07/26 07:51:28午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:51:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][50/703]	Step 63410	lr 0.00159	Loss 4.1243 (3.4351)	Hard Loss 0.2241 (0.1784)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.7%, 99.7%)	
07/26 07:51:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][100/703]	Step 63460	lr 0.00159	Loss 4.4913 (3.4616)	Hard Loss 0.2430 (0.1801)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (94.7%, 99.7%)	
07/26 07:51:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][150/703]	Step 63510	lr 0.00159	Loss 2.8283 (3.4835)	Hard Loss 0.1364 (0.1815)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.6%, 99.8%)	
07/26 07:52:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][200/703]	Step 63560	lr 0.00159	Loss 2.9706 (3.4744)	Hard Loss 0.1434 (0.1812)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.6%, 99.8%)	
07/26 07:52:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][250/703]	Step 63610	lr 0.00159	Loss 2.8727 (3.5212)	Hard Loss 0.1408 (0.1844)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.5%, 99.8%)	
07/26 07:52:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][300/703]	Step 63660	lr 0.00159	Loss 3.4574 (3.5280)	Hard Loss 0.1799 (0.1848)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.5%, 99.8%)	
07/26 07:52:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][350/703]	Step 63710	lr 0.00159	Loss 3.5964 (3.5454)	Hard Loss 0.1886 (0.1859)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.5%, 99.8%)	
07/26 07:52:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][400/703]	Step 63760	lr 0.00159	Loss 2.1587 (3.4969)	Hard Loss 0.0954 (0.1827)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.7%, 99.8%)	
07/26 07:52:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][450/703]	Step 63810	lr 0.00159	Loss 2.1529 (3.4979)	Hard Loss 0.0948 (0.1828)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.6%, 99.8%)	
07/26 07:53:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][500/703]	Step 63860	lr 0.00159	Loss 4.5359 (3.4793)	Hard Loss 0.2498 (0.1815)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.7%, 99.8%)	
07/26 07:53:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][550/703]	Step 63910	lr 0.00159	Loss 3.0959 (3.4720)	Hard Loss 0.1497 (0.1811)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.7%, 99.8%)	
07/26 07:53:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][600/703]	Step 63960	lr 0.00159	Loss 5.4375 (3.4772)	Hard Loss 0.3081 (0.1815)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.6%, 99.8%)	
07/26 07:53:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][650/703]	Step 64010	lr 0.00159	Loss 7.9688 (3.4923)	Hard Loss 0.4755 (0.1824)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.6%, 99.8%)	
07/26 07:53:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][700/703]	Step 64060	lr 0.00159	Loss 6.9354 (3.5072)	Hard Loss 0.4110 (0.1834)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:53:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [90][703/703]	Step 64063	lr 0.00159	Loss 1.5951 (3.5054)	Hard Loss 0.0603 (0.1833)	Soft Loss 0.0030 (0.0034)	Prec@(1,5) (94.6%, 99.7%)	
07/26 07:53:41午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 90/99] Final Prec@1 94.5778%
07/26 07:53:44午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 90/99] Final Prec@1 67.4800%
07/26 07:53:44午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:53:54午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][50/703]	Step 64114	lr 0.00148	Loss 4.2906 (3.4629)	Hard Loss 0.2276 (0.1798)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:54:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][100/703]	Step 64164	lr 0.00148	Loss 2.6539 (3.4441)	Hard Loss 0.1302 (0.1780)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:54:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][150/703]	Step 64214	lr 0.00148	Loss 4.0034 (3.4344)	Hard Loss 0.2189 (0.1780)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (95.0%, 99.7%)	
07/26 07:54:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][200/703]	Step 64264	lr 0.00148	Loss 3.2367 (3.4372)	Hard Loss 0.1599 (0.1782)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (95.0%, 99.7%)	
07/26 07:54:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][250/703]	Step 64314	lr 0.00148	Loss 3.7833 (3.4502)	Hard Loss 0.2041 (0.1790)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (95.1%, 99.7%)	
07/26 07:54:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][300/703]	Step 64364	lr 0.00148	Loss 3.9644 (3.4280)	Hard Loss 0.2187 (0.1777)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (95.1%, 99.7%)	
07/26 07:54:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][350/703]	Step 64414	lr 0.00148	Loss 4.4231 (3.4299)	Hard Loss 0.2455 (0.1779)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (95.1%, 99.7%)	
07/26 07:54:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][400/703]	Step 64464	lr 0.00148	Loss 4.3996 (3.3969)	Hard Loss 0.2463 (0.1759)	Soft Loss 0.0038 (0.0034)	Prec@(1,5) (95.2%, 99.7%)	
07/26 07:55:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][450/703]	Step 64514	lr 0.00148	Loss 5.1309 (3.4297)	Hard Loss 0.2868 (0.1781)	Soft Loss 0.0040 (0.0034)	Prec@(1,5) (95.1%, 99.7%)	
07/26 07:55:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][500/703]	Step 64564	lr 0.00148	Loss 4.5599 (3.4560)	Hard Loss 0.2506 (0.1799)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (95.0%, 99.7%)	
07/26 07:55:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][550/703]	Step 64614	lr 0.00148	Loss 3.3597 (3.4554)	Hard Loss 0.1788 (0.1799)	Soft Loss 0.0038 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:55:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][600/703]	Step 64664	lr 0.00148	Loss 3.7515 (3.4546)	Hard Loss 0.2044 (0.1799)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:55:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][650/703]	Step 64714	lr 0.00148	Loss 4.1903 (3.4737)	Hard Loss 0.2283 (0.1812)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:55:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][700/703]	Step 64764	lr 0.00148	Loss 2.1714 (3.4701)	Hard Loss 0.0969 (0.1810)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:55:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [91][703/703]	Step 64767	lr 0.00148	Loss 3.0060 (3.4724)	Hard Loss 0.1454 (0.1811)	Soft Loss 0.0028 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:55:56午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 91/99] Final Prec@1 94.8733%
07/26 07:56:00午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 91/99] Final Prec@1 67.7400%
07/26 07:56:00午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:56:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][50/703]	Step 64818	lr 0.00138	Loss 2.4601 (3.4053)	Hard Loss 0.1150 (0.1761)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.9%, 99.8%)	
07/26 07:56:19午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][100/703]	Step 64868	lr 0.00138	Loss 2.2646 (3.3025)	Hard Loss 0.0999 (0.1696)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (95.4%, 99.8%)	
07/26 07:56:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][150/703]	Step 64918	lr 0.00138	Loss 2.3055 (3.3726)	Hard Loss 0.1085 (0.1744)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (95.1%, 99.8%)	
07/26 07:56:38午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][200/703]	Step 64968	lr 0.00138	Loss 3.0678 (3.3793)	Hard Loss 0.1531 (0.1749)	Soft Loss 0.0040 (0.0034)	Prec@(1,5) (94.9%, 99.8%)	
07/26 07:56:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][250/703]	Step 65018	lr 0.00138	Loss 3.6191 (3.3558)	Hard Loss 0.1865 (0.1733)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (95.0%, 99.8%)	
07/26 07:56:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][300/703]	Step 65068	lr 0.00138	Loss 4.0255 (3.3057)	Hard Loss 0.2104 (0.1702)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (95.2%, 99.8%)	
07/26 07:57:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][350/703]	Step 65118	lr 0.00138	Loss 4.3002 (3.3332)	Hard Loss 0.2437 (0.1721)	Soft Loss 0.0045 (0.0034)	Prec@(1,5) (95.1%, 99.8%)	
07/26 07:57:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][400/703]	Step 65168	lr 0.00138	Loss 2.1698 (3.3528)	Hard Loss 0.0935 (0.1733)	Soft Loss 0.0039 (0.0034)	Prec@(1,5) (95.1%, 99.8%)	
07/26 07:57:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][450/703]	Step 65218	lr 0.00138	Loss 3.2433 (3.3574)	Hard Loss 0.1633 (0.1735)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (95.1%, 99.8%)	
07/26 07:57:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][500/703]	Step 65268	lr 0.00138	Loss 3.9072 (3.3617)	Hard Loss 0.2182 (0.1738)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (95.0%, 99.8%)	
07/26 07:57:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][550/703]	Step 65318	lr 0.00138	Loss 5.1617 (3.3661)	Hard Loss 0.2893 (0.1741)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (95.0%, 99.8%)	
07/26 07:57:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][600/703]	Step 65368	lr 0.00138	Loss 4.6103 (3.3754)	Hard Loss 0.2579 (0.1747)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (95.0%, 99.8%)	
07/26 07:58:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][650/703]	Step 65418	lr 0.00138	Loss 2.4679 (3.3779)	Hard Loss 0.1139 (0.1749)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (95.0%, 99.8%)	
07/26 07:58:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][700/703]	Step 65468	lr 0.00138	Loss 4.4311 (3.3885)	Hard Loss 0.2502 (0.1756)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.9%, 99.8%)	
07/26 07:58:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [92][703/703]	Step 65471	lr 0.00138	Loss 3.6888 (3.3923)	Hard Loss 0.1925 (0.1759)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (94.9%, 99.8%)	
07/26 07:58:12午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 92/99] Final Prec@1 94.9311%
07/26 07:58:15午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 92/99] Final Prec@1 68.1000%
07/26 07:58:15午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 07:58:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][50/703]	Step 65522	lr 0.00129	Loss 2.7812 (3.3003)	Hard Loss 0.1305 (0.1699)	Soft Loss 0.0035 (0.0034)	Prec@(1,5) (95.2%, 99.7%)	
07/26 07:58:35午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][100/703]	Step 65572	lr 0.00129	Loss 3.4891 (3.3626)	Hard Loss 0.1861 (0.1750)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (95.1%, 99.7%)	
07/26 07:58:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][150/703]	Step 65622	lr 0.00129	Loss 4.1410 (3.3806)	Hard Loss 0.2274 (0.1760)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (95.1%, 99.7%)	
07/26 07:58:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][200/703]	Step 65672	lr 0.00129	Loss 4.2674 (3.4105)	Hard Loss 0.2352 (0.1777)	Soft Loss 0.0040 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:59:03午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][250/703]	Step 65722	lr 0.00129	Loss 2.3067 (3.3573)	Hard Loss 0.1060 (0.1741)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (95.0%, 99.7%)	
07/26 07:59:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][300/703]	Step 65772	lr 0.00129	Loss 4.4947 (3.3651)	Hard Loss 0.2352 (0.1744)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (95.0%, 99.7%)	
07/26 07:59:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][350/703]	Step 65822	lr 0.00129	Loss 1.7796 (3.3831)	Hard Loss 0.0661 (0.1755)	Soft Loss 0.0034 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:59:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][400/703]	Step 65872	lr 0.00129	Loss 3.4696 (3.3777)	Hard Loss 0.1836 (0.1752)	Soft Loss 0.0031 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:59:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][450/703]	Step 65922	lr 0.00129	Loss 4.6400 (3.3956)	Hard Loss 0.2623 (0.1763)	Soft Loss 0.0036 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:59:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][500/703]	Step 65972	lr 0.00129	Loss 4.7896 (3.4060)	Hard Loss 0.2637 (0.1769)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 07:59:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][550/703]	Step 66022	lr 0.00129	Loss 3.9761 (3.3987)	Hard Loss 0.2139 (0.1765)	Soft Loss 0.0033 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 08:00:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][600/703]	Step 66072	lr 0.00129	Loss 3.0632 (3.4040)	Hard Loss 0.1557 (0.1768)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 08:00:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][650/703]	Step 66122	lr 0.00129	Loss 2.7257 (3.4028)	Hard Loss 0.1271 (0.1767)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 08:00:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][700/703]	Step 66172	lr 0.00129	Loss 2.0612 (3.3987)	Hard Loss 0.0930 (0.1765)	Soft Loss 0.0032 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 08:00:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [93][703/703]	Step 66175	lr 0.00129	Loss 3.3021 (3.3999)	Hard Loss 0.1750 (0.1765)	Soft Loss 0.0039 (0.0034)	Prec@(1,5) (94.9%, 99.7%)	
07/26 08:00:28午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 93/99] Final Prec@1 94.9356%
07/26 08:00:31午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 93/99] Final Prec@1 67.3800%
07/26 08:00:31午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 08:00:41午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][50/703]	Step 66226	lr 0.00121	Loss 2.4866 (3.4078)	Hard Loss 0.1111 (0.1768)	Soft Loss 0.0037 (0.0034)	Prec@(1,5) (94.7%, 99.7%)	
07/26 08:00:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][100/703]	Step 66276	lr 0.00121	Loss 4.1647 (3.3551)	Hard Loss 0.2309 (0.1737)	Soft Loss 0.0039 (0.0035)	Prec@(1,5) (94.9%, 99.8%)	
07/26 08:01:00午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][150/703]	Step 66326	lr 0.00121	Loss 3.6233 (3.3401)	Hard Loss 0.1848 (0.1731)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.0%, 99.8%)	
07/26 08:01:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][200/703]	Step 66376	lr 0.00121	Loss 2.7218 (3.3007)	Hard Loss 0.1362 (0.1704)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.0%, 99.8%)	
07/26 08:01:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][250/703]	Step 66426	lr 0.00121	Loss 5.1527 (3.3272)	Hard Loss 0.2889 (0.1718)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.0%, 99.8%)	
07/26 08:01:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][300/703]	Step 66476	lr 0.00121	Loss 3.6614 (3.2936)	Hard Loss 0.1904 (0.1698)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:01:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][350/703]	Step 66526	lr 0.00121	Loss 3.2022 (3.3170)	Hard Loss 0.1685 (0.1711)	Soft Loss 0.0042 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:01:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][400/703]	Step 66576	lr 0.00121	Loss 5.0610 (3.3044)	Hard Loss 0.2829 (0.1702)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:01:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][450/703]	Step 66626	lr 0.00121	Loss 2.7284 (3.3411)	Hard Loss 0.1384 (0.1726)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:02:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][500/703]	Step 66676	lr 0.00121	Loss 3.4990 (3.3540)	Hard Loss 0.1868 (0.1733)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:02:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][550/703]	Step 66726	lr 0.00121	Loss 2.3950 (3.3438)	Hard Loss 0.1101 (0.1727)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:02:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][600/703]	Step 66776	lr 0.00121	Loss 2.6969 (3.3439)	Hard Loss 0.1337 (0.1728)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:02:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][650/703]	Step 66826	lr 0.00121	Loss 5.4892 (3.3528)	Hard Loss 0.3084 (0.1734)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:02:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][700/703]	Step 66876	lr 0.00121	Loss 2.5609 (3.3411)	Hard Loss 0.1244 (0.1726)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:02:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [94][703/703]	Step 66879	lr 0.00121	Loss 4.0272 (3.3429)	Hard Loss 0.2204 (0.1727)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:02:43午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 94/99] Final Prec@1 95.1933%
07/26 08:02:47午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 94/99] Final Prec@1 67.4000%
07/26 08:02:47午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 08:02:57午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][50/703]	Step 66930	lr 0.00115	Loss 1.7703 (3.2451)	Hard Loss 0.0721 (0.1657)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.0%, 99.8%)	
07/26 08:03:06午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][100/703]	Step 66980	lr 0.00115	Loss 2.9648 (3.1905)	Hard Loss 0.1493 (0.1626)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.3%, 99.7%)	
07/26 08:03:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][150/703]	Step 67030	lr 0.00115	Loss 5.0550 (3.2622)	Hard Loss 0.2866 (0.1674)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:03:25午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][200/703]	Step 67080	lr 0.00115	Loss 2.9046 (3.2474)	Hard Loss 0.1431 (0.1667)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:03:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][250/703]	Step 67130	lr 0.00115	Loss 3.2144 (3.2692)	Hard Loss 0.1690 (0.1679)	Soft Loss 0.0039 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:03:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][300/703]	Step 67180	lr 0.00115	Loss 4.4113 (3.2542)	Hard Loss 0.2395 (0.1669)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:03:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][350/703]	Step 67230	lr 0.00115	Loss 2.6261 (3.2728)	Hard Loss 0.1251 (0.1682)	Soft Loss 0.0040 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:04:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][400/703]	Step 67280	lr 0.00115	Loss 5.1406 (3.2823)	Hard Loss 0.2870 (0.1689)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:04:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][450/703]	Step 67330	lr 0.00115	Loss 2.7806 (3.3006)	Hard Loss 0.1389 (0.1701)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:04:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][500/703]	Step 67380	lr 0.00115	Loss 5.5912 (3.3448)	Hard Loss 0.3269 (0.1731)	Soft Loss 0.0047 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:04:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][550/703]	Step 67430	lr 0.00115	Loss 4.4071 (3.3364)	Hard Loss 0.2446 (0.1725)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:04:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][600/703]	Step 67480	lr 0.00115	Loss 2.3192 (3.3481)	Hard Loss 0.1053 (0.1732)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:04:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][650/703]	Step 67530	lr 0.00115	Loss 2.0555 (3.3310)	Hard Loss 0.0969 (0.1721)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:04:58午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][700/703]	Step 67580	lr 0.00115	Loss 2.6814 (3.3411)	Hard Loss 0.1278 (0.1727)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:04:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [95][703/703]	Step 67583	lr 0.00115	Loss 2.8640 (3.3409)	Hard Loss 0.1391 (0.1727)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.1%, 99.8%)	
07/26 08:04:59午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 95/99] Final Prec@1 95.1267%
07/26 08:05:02午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 95/99] Final Prec@1 67.7600%
07/26 08:05:02午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.1000%
07/26 08:05:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][50/703]	Step 67634	lr 0.00109	Loss 3.6428 (3.5394)	Hard Loss 0.1940 (0.1852)	Soft Loss 0.0042 (0.0035)	Prec@(1,5) (94.8%, 99.6%)	
07/26 08:05:22午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][100/703]	Step 67684	lr 0.00109	Loss 4.4727 (3.3983)	Hard Loss 0.2383 (0.1759)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.0%, 99.7%)	
07/26 08:05:31午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][150/703]	Step 67734	lr 0.00109	Loss 2.2825 (3.3665)	Hard Loss 0.0964 (0.1737)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:05:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][200/703]	Step 67784	lr 0.00109	Loss 4.5126 (3.3336)	Hard Loss 0.2558 (0.1718)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:05:50午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][250/703]	Step 67834	lr 0.00109	Loss 3.4011 (3.3320)	Hard Loss 0.1729 (0.1720)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:05:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][300/703]	Step 67884	lr 0.00109	Loss 3.1337 (3.3195)	Hard Loss 0.1596 (0.1713)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:06:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][350/703]	Step 67934	lr 0.00109	Loss 2.8939 (3.2898)	Hard Loss 0.1445 (0.1695)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:06:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][400/703]	Step 67984	lr 0.00109	Loss 2.7523 (3.2901)	Hard Loss 0.1324 (0.1695)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:06:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][450/703]	Step 68034	lr 0.00109	Loss 1.4065 (3.3086)	Hard Loss 0.0559 (0.1706)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:06:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][500/703]	Step 68084	lr 0.00109	Loss 4.1344 (3.3170)	Hard Loss 0.2263 (0.1712)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:06:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][550/703]	Step 68134	lr 0.00109	Loss 3.4695 (3.3260)	Hard Loss 0.1775 (0.1718)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.1%, 99.7%)	
07/26 08:06:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][600/703]	Step 68184	lr 0.00109	Loss 3.9690 (3.3179)	Hard Loss 0.2091 (0.1712)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:07:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][650/703]	Step 68234	lr 0.00109	Loss 4.2480 (3.3075)	Hard Loss 0.2309 (0.1705)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:07:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][700/703]	Step 68284	lr 0.00109	Loss 3.1880 (3.3042)	Hard Loss 0.1631 (0.1703)	Soft Loss 0.0038 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:07:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [96][703/703]	Step 68287	lr 0.00109	Loss 4.7128 (3.3050)	Hard Loss 0.2688 (0.1703)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (95.2%, 99.7%)	
07/26 08:07:15午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 96/99] Final Prec@1 95.2000%
07/26 08:07:18午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 96/99] Final Prec@1 68.2600%
07/26 08:07:18午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.2600%
07/26 08:07:28午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][50/703]	Step 68338	lr 0.00105	Loss 1.9818 (3.1396)	Hard Loss 0.0869 (0.1596)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (96.0%, 99.7%)	
07/26 08:07:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][100/703]	Step 68388	lr 0.00105	Loss 3.1397 (3.0974)	Hard Loss 0.1558 (0.1564)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (96.0%, 99.8%)	
07/26 08:07:47午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][150/703]	Step 68438	lr 0.00105	Loss 3.2049 (3.0995)	Hard Loss 0.1655 (0.1565)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.9%, 99.7%)	
07/26 08:07:56午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][200/703]	Step 68488	lr 0.00105	Loss 2.9209 (3.1268)	Hard Loss 0.1432 (0.1584)	Soft Loss 0.0042 (0.0035)	Prec@(1,5) (95.9%, 99.7%)	
07/26 08:08:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][250/703]	Step 68538	lr 0.00105	Loss 2.7488 (3.1939)	Hard Loss 0.1330 (0.1627)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.6%, 99.8%)	
07/26 08:08:15午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][300/703]	Step 68588	lr 0.00105	Loss 4.0836 (3.2073)	Hard Loss 0.2178 (0.1635)	Soft Loss 0.0031 (0.0035)	Prec@(1,5) (95.6%, 99.8%)	
07/26 08:08:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][350/703]	Step 68638	lr 0.00105	Loss 2.2891 (3.2190)	Hard Loss 0.1049 (0.1644)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.6%, 99.8%)	
07/26 08:08:34午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][400/703]	Step 68688	lr 0.00105	Loss 2.2307 (3.2329)	Hard Loss 0.0985 (0.1654)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.5%, 99.8%)	
07/26 08:08:43午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][450/703]	Step 68738	lr 0.00105	Loss 2.5277 (3.2145)	Hard Loss 0.1277 (0.1643)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (95.5%, 99.8%)	
07/26 08:08:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][500/703]	Step 68788	lr 0.00105	Loss 2.9278 (3.2178)	Hard Loss 0.1466 (0.1645)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.5%, 99.8%)	
07/26 08:09:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][550/703]	Step 68838	lr 0.00105	Loss 2.9149 (3.2276)	Hard Loss 0.1537 (0.1652)	Soft Loss 0.0039 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:09:11午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][600/703]	Step 68888	lr 0.00105	Loss 1.9388 (3.2412)	Hard Loss 0.0854 (0.1660)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:09:20午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][650/703]	Step 68938	lr 0.00105	Loss 6.0644 (3.2264)	Hard Loss 0.3528 (0.1651)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:09:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][700/703]	Step 68988	lr 0.00105	Loss 4.0734 (3.2268)	Hard Loss 0.2224 (0.1651)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:09:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [97][703/703]	Step 68991	lr 0.00105	Loss 4.0869 (3.2307)	Hard Loss 0.2174 (0.1654)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:09:31午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 97/99] Final Prec@1 95.4044%
07/26 08:09:34午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 97/99] Final Prec@1 67.6000%
07/26 08:09:34午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.2600%
07/26 08:09:44午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][50/703]	Step 69042	lr 0.00102	Loss 2.5656 (3.1067)	Hard Loss 0.1208 (0.1578)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.6%, 99.7%)	
07/26 08:09:53午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][100/703]	Step 69092	lr 0.00102	Loss 3.8139 (3.2132)	Hard Loss 0.2038 (0.1644)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.4%, 99.7%)	
07/26 08:10:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][150/703]	Step 69142	lr 0.00102	Loss 4.3446 (3.2215)	Hard Loss 0.2356 (0.1648)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.4%, 99.7%)	
07/26 08:10:12午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][200/703]	Step 69192	lr 0.00102	Loss 3.6322 (3.2069)	Hard Loss 0.1914 (0.1638)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.5%, 99.7%)	
07/26 08:10:21午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][250/703]	Step 69242	lr 0.00102	Loss 2.8929 (3.1876)	Hard Loss 0.1488 (0.1625)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.5%, 99.7%)	
07/26 08:10:30午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][300/703]	Step 69292	lr 0.00102	Loss 2.4257 (3.2096)	Hard Loss 0.1054 (0.1640)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:10:40午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][350/703]	Step 69342	lr 0.00102	Loss 3.5977 (3.2535)	Hard Loss 0.1915 (0.1669)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:10:49午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][400/703]	Step 69392	lr 0.00102	Loss 3.3099 (3.2510)	Hard Loss 0.1730 (0.1667)	Soft Loss 0.0038 (0.0035)	Prec@(1,5) (95.3%, 99.7%)	
07/26 08:10:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][450/703]	Step 69442	lr 0.00102	Loss 3.2607 (3.2467)	Hard Loss 0.1685 (0.1664)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:11:08午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][500/703]	Step 69492	lr 0.00102	Loss 3.7108 (3.2458)	Hard Loss 0.1974 (0.1663)	Soft Loss 0.0039 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:11:17午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][550/703]	Step 69542	lr 0.00102	Loss 3.4471 (3.2418)	Hard Loss 0.1775 (0.1661)	Soft Loss 0.0030 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:11:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][600/703]	Step 69592	lr 0.00102	Loss 3.7159 (3.2493)	Hard Loss 0.1922 (0.1666)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:11:36午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][650/703]	Step 69642	lr 0.00102	Loss 3.3690 (3.2603)	Hard Loss 0.1820 (0.1673)	Soft Loss 0.0037 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:11:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][700/703]	Step 69692	lr 0.00102	Loss 3.0201 (3.2689)	Hard Loss 0.1507 (0.1679)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:11:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [98][703/703]	Step 69695	lr 0.00102	Loss 2.6804 (3.2669)	Hard Loss 0.1313 (0.1677)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:11:46午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 98/99] Final Prec@1 95.2733%
07/26 08:11:49午後 evaluateCell_KD_trainer.py:229 [INFO] Valid: [ 98/99] Final Prec@1 67.7600%
07/26 08:11:50午後 evaluateCell_main.py:75 [INFO] Until now, best Prec@1 = 68.2600%
07/26 08:11:59午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][50/703]	Step 69746	lr 0.00101	Loss 4.0012 (3.1032)	Hard Loss 0.2157 (0.1561)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.8%, 99.8%)	
07/26 08:12:09午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][100/703]	Step 69796	lr 0.00101	Loss 2.2136 (3.1545)	Hard Loss 0.1015 (0.1596)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.7%, 99.9%)	
07/26 08:12:18午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][150/703]	Step 69846	lr 0.00101	Loss 3.7155 (3.1840)	Hard Loss 0.1988 (0.1620)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.6%, 99.8%)	
07/26 08:12:27午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][200/703]	Step 69896	lr 0.00101	Loss 2.7817 (3.2423)	Hard Loss 0.1409 (0.1660)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.5%, 99.8%)	
07/26 08:12:37午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][250/703]	Step 69946	lr 0.00101	Loss 2.1058 (3.2471)	Hard Loss 0.0900 (0.1663)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:12:46午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][300/703]	Step 69996	lr 0.00101	Loss 4.8236 (3.2846)	Hard Loss 0.2677 (0.1687)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:12:55午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][350/703]	Step 70046	lr 0.00101	Loss 2.9159 (3.2792)	Hard Loss 0.1491 (0.1683)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:13:05午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][400/703]	Step 70096	lr 0.00101	Loss 3.4909 (3.2543)	Hard Loss 0.1831 (0.1668)	Soft Loss 0.0041 (0.0035)	Prec@(1,5) (95.4%, 99.8%)	
07/26 08:13:14午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][450/703]	Step 70146	lr 0.00101	Loss 4.1488 (3.2879)	Hard Loss 0.2225 (0.1691)	Soft Loss 0.0032 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:13:24午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][500/703]	Step 70196	lr 0.00101	Loss 2.7396 (3.2784)	Hard Loss 0.1306 (0.1685)	Soft Loss 0.0036 (0.0035)	Prec@(1,5) (95.3%, 99.8%)	
07/26 08:13:33午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][550/703]	Step 70246	lr 0.00101	Loss 3.3098 (3.2956)	Hard Loss 0.1749 (0.1696)	Soft Loss 0.0034 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:13:42午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][600/703]	Step 70296	lr 0.00101	Loss 3.5624 (3.2892)	Hard Loss 0.1861 (0.1692)	Soft Loss 0.0039 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:13:52午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][650/703]	Step 70346	lr 0.00101	Loss 3.9466 (3.2934)	Hard Loss 0.2146 (0.1695)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:14:01午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][700/703]	Step 70396	lr 0.00101	Loss 4.4435 (3.2971)	Hard Loss 0.2435 (0.1698)	Soft Loss 0.0033 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:14:02午後 evaluateCell_KD_trainer.py:185 [INFO] Train: Epoch: [99][703/703]	Step 70399	lr 0.00101	Loss 3.9703 (3.3004)	Hard Loss 0.2224 (0.1700)	Soft Loss 0.0035 (0.0035)	Prec@(1,5) (95.2%, 99.8%)	
07/26 08:14:02午後 evaluateCell_KD_trainer.py:194 [INFO] Train: [ 99/99] Final Prec@1 95.1933%
