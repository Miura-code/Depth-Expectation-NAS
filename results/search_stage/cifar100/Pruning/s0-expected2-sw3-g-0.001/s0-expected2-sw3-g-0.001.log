12/04 03:55:36AM parser.py:28 [INFO] 
12/04 03:55:36AM parser.py:29 [INFO] Parameters:
12/04 03:55:36AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g-0.001/DAG
12/04 03:55:36AM parser.py:31 [INFO] T=10.0
12/04 03:55:36AM parser.py:31 [INFO] ADVANCED=1
12/04 03:55:36AM parser.py:31 [INFO] ALPHA_LR=0.0003
12/04 03:55:36AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/04 03:55:36AM parser.py:31 [INFO] ARCH_CRITERION=expected
12/04 03:55:36AM parser.py:31 [INFO] BATCH_SIZE=64
12/04 03:55:36AM parser.py:31 [INFO] CASCADE=0
12/04 03:55:36AM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/04 03:55:36AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 20]
12/04 03:55:36AM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/04 03:55:36AM parser.py:31 [INFO] DATA_PATH=../data/
12/04 03:55:36AM parser.py:31 [INFO] DATASET=cifar100
12/04 03:55:36AM parser.py:31 [INFO] DEPTH_COEF=0.0
12/04 03:55:36AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/04 03:55:36AM parser.py:31 [INFO] DISCRETE=1
12/04 03:55:36AM parser.py:31 [INFO] EPOCHS=50
12/04 03:55:36AM parser.py:31 [INFO] EVAL_EPOCHS=100
12/04 03:55:36AM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g-0.001
12/04 03:55:36AM parser.py:31 [INFO] FINAL_L=0.0
12/04 03:55:36AM parser.py:31 [INFO] G=-0.001
12/04 03:55:36AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/04 03:55:36AM parser.py:31 [INFO] GPUS=[0]
12/04 03:55:36AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/04 03:55:36AM parser.py:31 [INFO] INIT_CHANNELS=16
12/04 03:55:36AM parser.py:31 [INFO] L=0.0
12/04 03:55:36AM parser.py:31 [INFO] LAYERS=32
12/04 03:55:36AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/04 03:55:36AM parser.py:31 [INFO] NAME=Pruning
12/04 03:55:36AM parser.py:31 [INFO] NONKD=1
12/04 03:55:36AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g-0.001
12/04 03:55:36AM parser.py:31 [INFO] PCDARTS=0
12/04 03:55:36AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g-0.001/plots
12/04 03:55:36AM parser.py:31 [INFO] PRINT_FREQ=100
12/04 03:55:36AM parser.py:31 [INFO] RESET=0
12/04 03:55:36AM parser.py:31 [INFO] RESUME_PATH=None
12/04 03:55:36AM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g-0.001
12/04 03:55:36AM parser.py:31 [INFO] SEED=0
12/04 03:55:36AM parser.py:31 [INFO] SHARE_STAGE=0
12/04 03:55:36AM parser.py:31 [INFO] SLIDE_WINDOW=3
12/04 03:55:36AM parser.py:31 [INFO] SPEC_CELL=1
12/04 03:55:36AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/04 03:55:36AM parser.py:31 [INFO] TEACHER_NAME=none
12/04 03:55:36AM parser.py:31 [INFO] TEACHER_PATH=none
12/04 03:55:36AM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/04 03:55:36AM parser.py:31 [INFO] TYPE=Pruning
12/04 03:55:36AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/04 03:55:36AM parser.py:31 [INFO] W_LR=0.025
12/04 03:55:36AM parser.py:31 [INFO] W_LR_MIN=0.001
12/04 03:55:36AM parser.py:31 [INFO] W_MOMENTUM=0.9
12/04 03:55:36AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/04 03:55:36AM parser.py:31 [INFO] WORKERS=4
12/04 03:55:36AM parser.py:32 [INFO] 
12/04 03:55:38AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/04 03:56:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3844 (4.5416)	Arch Loss 4.4198 (4.5383)	Arch Hard Loss 4.4260 (4.5445)	Arch Beta Loss 6.1928 (6.1943)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.1%, 9.7%)	
12/04 03:57:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1209 (4.4219)	Arch Loss 4.2989 (4.4047)	Arch Hard Loss 4.3051 (4.4109)	Arch Beta Loss 6.1881 (6.1920)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.1%, 13.0%)	
12/04 03:58:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0906 (4.3119)	Arch Loss 4.0393 (4.3041)	Arch Hard Loss 4.0455 (4.3103)	Arch Beta Loss 6.1850 (6.1903)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.2%, 16.5%)	
12/04 03:58:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9052 (4.2445)	Arch Loss 3.8753 (4.2299)	Arch Hard Loss 3.8815 (4.2361)	Arch Beta Loss 6.1820 (6.1888)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.0%, 18.7%)	
12/04 03:58:49AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  0/49] Final Prec@1 4.9520%
12/04 03:58:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9036	Prec@(1,5) (8.9%, 29.3%)
12/04 03:59:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.8931	Prec@(1,5) (9.2%, 29.3%)
12/04 03:59:09AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.8938	Prec@(1,5) (9.2%, 29.3%)
12/04 03:59:15AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.8927	Prec@(1,5) (9.1%, 29.2%)
12/04 03:59:15AM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 9.1400%
12/04 03:59:15AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 4])
12/04 03:59:16AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.1400%
12/04 04:00:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8641 (3.9149)	Arch Loss 4.0460 (3.8920)	Arch Hard Loss 4.0522 (3.8981)	Arch Beta Loss 6.1773 (6.1789)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.2%, 28.7%)	
12/04 04:00:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.7488 (3.8731)	Arch Loss 3.8567 (3.8428)	Arch Hard Loss 3.8629 (3.8490)	Arch Beta Loss 6.1720 (6.1771)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.3%, 30.4%)	
12/04 04:01:43AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.6115 (3.8332)	Arch Loss 3.6342 (3.8008)	Arch Hard Loss 3.6404 (3.8069)	Arch Beta Loss 6.1683 (6.1747)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.0%, 31.5%)	
12/04 04:02:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.6935 (3.7876)	Arch Loss 3.9131 (3.7683)	Arch Hard Loss 3.9193 (3.7745)	Arch Beta Loss 6.1636 (6.1724)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.6%, 33.0%)	
12/04 04:02:27AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  1/49] Final Prec@1 10.6440%
12/04 04:02:34AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6797	Prec@(1,5) (12.0%, 36.4%)
12/04 04:02:41AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6664	Prec@(1,5) (12.5%, 36.6%)
12/04 04:02:47AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6731	Prec@(1,5) (12.5%, 36.5%)
12/04 04:02:53AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6688	Prec@(1,5) (12.5%, 36.6%)
12/04 04:02:53AM searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 12.5440%
12/04 04:02:53AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[3, 7])
12/04 04:02:54AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.5440%
12/04 04:03:43AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.7029 (3.5814)	Arch Loss 3.4169 (3.5764)	Arch Hard Loss 3.4231 (3.5825)	Arch Beta Loss 6.1573 (6.1623)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.0%, 39.1%)	
12/04 04:04:31AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4205 (3.5599)	Arch Loss 3.4901 (3.5660)	Arch Hard Loss 3.4963 (3.5721)	Arch Beta Loss 6.1544 (6.1599)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.5%, 40.1%)	
12/04 04:05:19AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.3006 (3.5267)	Arch Loss 3.5005 (3.5331)	Arch Hard Loss 3.5067 (3.5392)	Arch Beta Loss 6.1444 (6.1560)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.1%, 40.8%)	
12/04 04:06:02AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4163 (3.5040)	Arch Loss 3.3128 (3.5074)	Arch Hard Loss 3.3190 (3.5136)	Arch Beta Loss 6.1406 (6.1529)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.5%, 41.4%)	
12/04 04:06:03AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  2/49] Final Prec@1 15.5360%
12/04 04:06:10AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3793	Prec@(1,5) (17.9%, 45.3%)
12/04 04:06:16AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3885	Prec@(1,5) (17.6%, 45.0%)
12/04 04:06:23AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3943	Prec@(1,5) (17.5%, 44.9%)
12/04 04:06:28AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3957	Prec@(1,5) (17.6%, 45.0%)
12/04 04:06:28AM searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 17.5680%
12/04 04:06:28AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[3, 7])
12/04 04:06:29AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.5680%
12/04 04:07:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5952 (3.3632)	Arch Loss 3.2339 (3.3370)	Arch Hard Loss 3.2400 (3.3431)	Arch Beta Loss 6.1396 (6.1394)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 45.0%)	
12/04 04:08:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1449 (3.3214)	Arch Loss 3.4567 (3.3189)	Arch Hard Loss 3.4628 (3.3251)	Arch Beta Loss 6.1391 (6.1395)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.4%, 46.8%)	
12/04 04:08:55AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.2133 (3.2928)	Arch Loss 3.3918 (3.2994)	Arch Hard Loss 3.3979 (3.3055)	Arch Beta Loss 6.1313 (6.1376)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 47.5%)	
12/04 04:09:38AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.0740 (3.2687)	Arch Loss 3.1852 (3.2780)	Arch Hard Loss 3.1913 (3.2841)	Arch Beta Loss 6.1273 (6.1352)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 48.1%)	
12/04 04:09:39AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  3/49] Final Prec@1 19.5320%
12/04 04:09:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2490	Prec@(1,5) (20.3%, 48.5%)
12/04 04:09:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2424	Prec@(1,5) (20.4%, 48.9%)
12/04 04:09:58AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2506	Prec@(1,5) (20.3%, 48.7%)
12/04 04:10:04AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2552	Prec@(1,5) (20.1%, 48.6%)
12/04 04:10:04AM searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 20.1360%
12/04 04:10:04AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:10:05AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.1360%
12/04 04:10:55AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.0792 (3.1090)	Arch Loss 2.9455 (3.1970)	Arch Hard Loss 2.9516 (3.2031)	Arch Beta Loss 6.1180 (6.1235)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.1%, 52.4%)	
12/04 04:11:43AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.0835 (3.0805)	Arch Loss 2.8847 (3.1500)	Arch Hard Loss 2.8908 (3.1561)	Arch Beta Loss 6.1145 (6.1201)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 53.2%)	
12/04 04:12:31AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.8322 (3.0727)	Arch Loss 3.0244 (3.1292)	Arch Hard Loss 3.0305 (3.1353)	Arch Beta Loss 6.1030 (6.1159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 53.4%)	
12/04 04:13:14AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.9989 (3.0619)	Arch Loss 2.8442 (3.1014)	Arch Hard Loss 2.8503 (3.1075)	Arch Beta Loss 6.0977 (6.1122)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.2%, 53.6%)	
12/04 04:13:15AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  4/49] Final Prec@1 23.2400%
12/04 04:13:22AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0391	Prec@(1,5) (24.3%, 55.3%)
12/04 04:13:29AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0120	Prec@(1,5) (24.7%, 55.7%)
12/04 04:13:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0111	Prec@(1,5) (24.8%, 55.7%)
12/04 04:13:42AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0129	Prec@(1,5) (24.9%, 55.8%)
12/04 04:13:42AM searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 24.9040%
12/04 04:13:42AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:13:43AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.9040%
12/04 04:14:33AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.1460 (2.9084)	Arch Loss 3.0860 (2.9660)	Arch Hard Loss 3.0921 (2.9721)	Arch Beta Loss 6.0879 (6.0943)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.8%, 57.1%)	
12/04 04:15:21AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.1248 (2.9029)	Arch Loss 3.2597 (2.9845)	Arch Hard Loss 3.2658 (2.9906)	Arch Beta Loss 6.0772 (6.0875)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.6%, 57.2%)	
12/04 04:16:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8051 (2.8937)	Arch Loss 2.6143 (2.9570)	Arch Hard Loss 2.6204 (2.9631)	Arch Beta Loss 6.0753 (6.0837)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.4%)	
12/04 04:16:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.4984 (2.8835)	Arch Loss 2.7794 (2.9370)	Arch Hard Loss 2.7855 (2.9430)	Arch Beta Loss 6.0716 (6.0814)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.0%, 57.9%)	
12/04 04:16:54AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  5/49] Final Prec@1 26.9760%
12/04 04:17:01AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8469	Prec@(1,5) (27.5%, 59.5%)
12/04 04:17:07AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8581	Prec@(1,5) (27.7%, 59.1%)
12/04 04:17:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8627	Prec@(1,5) (27.5%, 59.2%)
12/04 04:17:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8573	Prec@(1,5) (27.6%, 59.3%)
12/04 04:17:19AM searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 27.6480%
12/04 04:17:19AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:17:20AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.6480%
12/04 04:18:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8875 (2.7246)	Arch Loss 2.8009 (2.8505)	Arch Hard Loss 2.8070 (2.8566)	Arch Beta Loss 6.0635 (6.0671)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.2%, 62.2%)	
12/04 04:18:59AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.7957 (2.7375)	Arch Loss 2.9811 (2.8320)	Arch Hard Loss 2.9872 (2.8381)	Arch Beta Loss 6.0572 (6.0641)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.4%, 61.6%)	
12/04 04:19:46AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.9546 (2.7337)	Arch Loss 2.6536 (2.8041)	Arch Hard Loss 2.6596 (2.8101)	Arch Beta Loss 6.0485 (6.0610)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 61.9%)	
12/04 04:20:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7755 (2.7310)	Arch Loss 2.6885 (2.8045)	Arch Hard Loss 2.6946 (2.8106)	Arch Beta Loss 6.0459 (6.0578)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.4%, 62.1%)	
12/04 04:20:30AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  6/49] Final Prec@1 29.3960%
12/04 04:20:37AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6863	Prec@(1,5) (31.5%, 62.7%)
12/04 04:20:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6747	Prec@(1,5) (31.7%, 63.2%)
12/04 04:20:50AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6813	Prec@(1,5) (31.5%, 62.9%)
12/04 04:20:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6894	Prec@(1,5) (31.3%, 62.9%)
12/04 04:20:56AM searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 31.3160%
12/04 04:20:56AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:20:56AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.3160%
12/04 04:21:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.9014 (2.5863)	Arch Loss 2.6837 (2.7475)	Arch Hard Loss 2.6898 (2.7535)	Arch Beta Loss 6.0369 (6.0414)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.5%, 65.7%)	
12/04 04:22:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.5667 (2.5926)	Arch Loss 2.6640 (2.7348)	Arch Hard Loss 2.6700 (2.7409)	Arch Beta Loss 6.0246 (6.0360)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.8%, 65.4%)	
12/04 04:23:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.0684 (2.5928)	Arch Loss 3.1943 (2.7193)	Arch Hard Loss 3.2003 (2.7254)	Arch Beta Loss 6.0179 (6.0311)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 65.5%)	
12/04 04:24:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.5974 (2.5844)	Arch Loss 2.7510 (2.6936)	Arch Hard Loss 2.7570 (2.6996)	Arch Beta Loss 6.0143 (6.0275)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 65.6%)	
12/04 04:24:07AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  7/49] Final Prec@1 32.9840%
12/04 04:24:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6648	Prec@(1,5) (31.6%, 64.1%)
12/04 04:24:21AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6350	Prec@(1,5) (31.9%, 64.6%)
12/04 04:24:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6329	Prec@(1,5) (32.0%, 64.6%)
12/04 04:24:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6431	Prec@(1,5) (31.8%, 64.3%)
12/04 04:24:33AM searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 31.8320%
12/04 04:24:33AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:24:34AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.8320%
12/04 04:25:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4221 (2.4714)	Arch Loss 2.7701 (2.5970)	Arch Hard Loss 2.7761 (2.6030)	Arch Beta Loss 6.0068 (6.0086)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 68.4%)	
12/04 04:26:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.0875 (2.4729)	Arch Loss 2.9029 (2.6026)	Arch Hard Loss 2.9089 (2.6086)	Arch Beta Loss 6.0008 (6.0064)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 68.1%)	
12/04 04:27:01AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.4883 (2.4723)	Arch Loss 2.7281 (2.6004)	Arch Hard Loss 2.7340 (2.6064)	Arch Beta Loss 5.9925 (6.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.0%, 67.9%)	
12/04 04:27:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.0658 (2.4664)	Arch Loss 2.6351 (2.5892)	Arch Hard Loss 2.6411 (2.5952)	Arch Beta Loss 5.9893 (5.9998)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 68.1%)	
12/04 04:27:45AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  8/49] Final Prec@1 35.2080%
12/04 04:27:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4814	Prec@(1,5) (35.5%, 67.9%)
12/04 04:27:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5055	Prec@(1,5) (34.9%, 67.1%)
12/04 04:28:05AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5186	Prec@(1,5) (34.6%, 66.7%)
12/04 04:28:11AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5167	Prec@(1,5) (34.5%, 66.8%)
12/04 04:28:11AM searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 34.5040%
12/04 04:28:11AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:28:11AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5040%
12/04 04:29:01AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.4492 (2.3598)	Arch Loss 2.7944 (2.5250)	Arch Hard Loss 2.8003 (2.5310)	Arch Beta Loss 5.9789 (5.9829)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 70.7%)	
12/04 04:29:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.4214 (2.3690)	Arch Loss 2.5667 (2.5159)	Arch Hard Loss 2.5726 (2.5219)	Arch Beta Loss 5.9732 (5.9798)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 70.1%)	
12/04 04:30:39AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.3447 (2.3594)	Arch Loss 2.2874 (2.5036)	Arch Hard Loss 2.2934 (2.5096)	Arch Beta Loss 5.9662 (5.9766)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.2%)	
12/04 04:31:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.2900 (2.3565)	Arch Loss 2.5943 (2.4974)	Arch Hard Loss 2.6003 (2.5034)	Arch Beta Loss 5.9633 (5.9737)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.3%)	
12/04 04:31:23AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  9/49] Final Prec@1 37.5280%
12/04 04:31:30AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.5193	Prec@(1,5) (34.0%, 67.4%)
12/04 04:31:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4964	Prec@(1,5) (34.6%, 67.6%)
12/04 04:31:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.5116	Prec@(1,5) (34.5%, 67.4%)
12/04 04:31:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.5113	Prec@(1,5) (34.5%, 67.4%)
12/04 04:31:49AM searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 34.5240%
12/04 04:31:49AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[3, 7])
12/04 04:31:49AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5240%
12/04 04:32:39AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.4256 (2.2145)	Arch Loss 2.5922 (2.4607)	Arch Hard Loss 2.5982 (2.4666)	Arch Beta Loss 5.9589 (5.9604)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.3%)	
12/04 04:33:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4821 (2.2432)	Arch Loss 2.2547 (2.4346)	Arch Hard Loss 2.2607 (2.4406)	Arch Beta Loss 5.9504 (5.9580)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.8%, 73.0%)	
12/04 04:34:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.4961 (2.2569)	Arch Loss 2.1177 (2.4276)	Arch Hard Loss 2.1237 (2.4336)	Arch Beta Loss 5.9439 (5.9543)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.4%, 72.8%)	
12/04 04:34:59AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.4313 (2.2529)	Arch Loss 2.2503 (2.4167)	Arch Hard Loss 2.2563 (2.4226)	Arch Beta Loss 5.9377 (5.9511)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.7%)	
12/04 04:34:59AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 10/49] Final Prec@1 39.6800%
12/04 04:35:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3941	Prec@(1,5) (36.8%, 69.9%)
12/04 04:35:13AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3739	Prec@(1,5) (37.1%, 70.5%)
12/04 04:35:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3950	Prec@(1,5) (37.1%, 70.0%)
12/04 04:35:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3902	Prec@(1,5) (37.1%, 70.0%)
12/04 04:35:25AM searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 37.0920%
12/04 04:35:25AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
12/04 04:35:26AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.0920%
12/04 04:36:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2145 (2.1678)	Arch Loss 2.7646 (2.3802)	Arch Hard Loss 2.7705 (2.3861)	Arch Beta Loss 5.9330 (5.9351)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.8%, 74.4%)	
12/04 04:37:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4395 (2.1597)	Arch Loss 2.5420 (2.3582)	Arch Hard Loss 2.5479 (2.3641)	Arch Beta Loss 5.9274 (5.9326)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.8%, 74.5%)	
12/04 04:37:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.1925 (2.1516)	Arch Loss 2.1608 (2.3500)	Arch Hard Loss 2.1668 (2.3559)	Arch Beta Loss 5.9171 (5.9292)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 74.7%)	
12/04 04:38:38AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.0241 (2.1609)	Arch Loss 2.3331 (2.3517)	Arch Hard Loss 2.3390 (2.3576)	Arch Beta Loss 5.9153 (5.9260)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.5%)	
12/04 04:38:38AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 11/49] Final Prec@1 41.5800%
12/04 04:38:45AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3163	Prec@(1,5) (38.7%, 71.7%)
12/04 04:38:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3093	Prec@(1,5) (38.9%, 71.8%)
12/04 04:38:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3049	Prec@(1,5) (39.2%, 71.8%)
12/04 04:39:05AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3037	Prec@(1,5) (39.2%, 71.7%)
12/04 04:39:05AM searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 39.1960%
12/04 04:39:05AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[3, 7])
12/04 04:39:05AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.1960%
12/04 04:39:56AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.8033 (2.0470)	Arch Loss 2.0675 (2.3074)	Arch Hard Loss 2.0734 (2.3133)	Arch Beta Loss 5.9128 (5.9144)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 76.6%)	
12/04 04:40:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.1670 (2.0687)	Arch Loss 2.2394 (2.3158)	Arch Hard Loss 2.2453 (2.3217)	Arch Beta Loss 5.9081 (5.9120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.3%)	
12/04 04:41:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.0099 (2.0731)	Arch Loss 2.4735 (2.3019)	Arch Hard Loss 2.4794 (2.3078)	Arch Beta Loss 5.8970 (5.9091)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.2%)	
12/04 04:42:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.6542 (2.0740)	Arch Loss 2.2175 (2.2872)	Arch Hard Loss 2.2234 (2.2931)	Arch Beta Loss 5.8950 (5.9060)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.2%)	
12/04 04:42:19AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 12/49] Final Prec@1 43.8800%
12/04 04:42:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2913	Prec@(1,5) (39.2%, 72.1%)
12/04 04:42:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2791	Prec@(1,5) (39.5%, 72.5%)
12/04 04:42:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2771	Prec@(1,5) (39.5%, 72.4%)
12/04 04:42:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2869	Prec@(1,5) (39.4%, 72.2%)
12/04 04:42:46AM searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 39.3480%
12/04 04:42:46AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[3, 7])
12/04 04:42:47AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.3480%
12/04 04:43:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.0769 (1.9459)	Arch Loss 2.2471 (2.2381)	Arch Hard Loss 2.2530 (2.2440)	Arch Beta Loss 5.8849 (5.8888)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 78.8%)	
12/04 04:44:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.6111 (2.0016)	Arch Loss 2.2392 (2.2340)	Arch Hard Loss 2.2451 (2.2399)	Arch Beta Loss 5.8808 (5.8866)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.7%)	
12/04 04:45:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.9368 (1.9978)	Arch Loss 2.1029 (2.2340)	Arch Hard Loss 2.1088 (2.2398)	Arch Beta Loss 5.8772 (5.8840)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 77.7%)	
12/04 04:46:00AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.7758 (2.0037)	Arch Loss 1.9979 (2.2283)	Arch Hard Loss 2.0037 (2.2342)	Arch Beta Loss 5.8774 (5.8824)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 77.5%)	
12/04 04:46:00AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 13/49] Final Prec@1 45.1240%
12/04 04:46:08AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1757	Prec@(1,5) (41.9%, 74.3%)
12/04 04:46:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1937	Prec@(1,5) (41.6%, 73.9%)
12/04 04:46:21AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1752	Prec@(1,5) (42.2%, 74.2%)
12/04 04:46:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1786	Prec@(1,5) (42.0%, 74.1%)
12/04 04:46:27AM searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 41.9640%
12/04 04:46:27AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 5])
12/04 04:46:28AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.9640%
12/04 04:47:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8787 (1.8758)	Arch Loss 2.4343 (2.2233)	Arch Hard Loss 2.4402 (2.2292)	Arch Beta Loss 5.8695 (5.8734)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 80.4%)	
12/04 04:48:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.9523 (1.9233)	Arch Loss 2.2118 (2.2191)	Arch Hard Loss 2.2177 (2.2249)	Arch Beta Loss 5.8640 (5.8707)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.3%)	
12/04 04:48:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.1012 (1.9263)	Arch Loss 2.1992 (2.2053)	Arch Hard Loss 2.2051 (2.2111)	Arch Beta Loss 5.8607 (5.8677)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.2%)	
12/04 04:49:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.8008 (1.9305)	Arch Loss 2.1924 (2.1907)	Arch Hard Loss 2.1983 (2.1966)	Arch Beta Loss 5.8599 (5.8662)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 79.1%)	
12/04 04:49:37AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 14/49] Final Prec@1 46.7440%
12/04 04:49:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1614	Prec@(1,5) (43.3%, 74.7%)
12/04 04:49:51AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1760	Prec@(1,5) (42.5%, 74.6%)
12/04 04:49:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1792	Prec@(1,5) (42.2%, 74.5%)
12/04 04:50:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1797	Prec@(1,5) (42.1%, 74.5%)
12/04 04:50:03AM searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 42.1320%
12/04 04:50:03AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 5])
12/04 04:50:04AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.1320%
12/04 04:50:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.2724 (1.8219)	Arch Loss 2.1867 (2.1641)	Arch Hard Loss 2.1925 (2.1699)	Arch Beta Loss 5.8537 (5.8570)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.8%)	
12/04 04:51:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.4737 (1.8334)	Arch Loss 2.1126 (2.1610)	Arch Hard Loss 2.1185 (2.1668)	Arch Beta Loss 5.8513 (5.8535)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.7%)	
12/04 04:52:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9400 (1.8373)	Arch Loss 1.9993 (2.1527)	Arch Hard Loss 2.0051 (2.1585)	Arch Beta Loss 5.8473 (5.8521)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.9%)	
12/04 04:53:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.6590 (1.8475)	Arch Loss 1.8674 (2.1461)	Arch Hard Loss 1.8732 (2.1520)	Arch Beta Loss 5.8439 (5.8504)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.7%)	
12/04 04:53:12AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 15/49] Final Prec@1 48.8160%
12/04 04:53:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1251	Prec@(1,5) (43.7%, 75.8%)
12/04 04:53:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1191	Prec@(1,5) (43.5%, 75.6%)
12/04 04:53:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1291	Prec@(1,5) (43.2%, 75.2%)
12/04 04:53:39AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1201	Prec@(1,5) (43.4%, 75.4%)
12/04 04:53:39AM searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 43.3520%
12/04 04:53:39AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 04:53:40AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3520%
12/04 04:54:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.5809 (1.7586)	Arch Loss 1.7455 (2.1248)	Arch Hard Loss 1.7513 (2.1307)	Arch Beta Loss 5.8359 (5.8391)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.8%)	
12/04 04:55:19AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.8661 (1.7841)	Arch Loss 2.1124 (2.1097)	Arch Hard Loss 2.1182 (2.1155)	Arch Beta Loss 5.8336 (5.8374)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.0%, 81.6%)	
12/04 04:56:08AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.7033 (1.7918)	Arch Loss 2.3075 (2.1194)	Arch Hard Loss 2.3133 (2.1253)	Arch Beta Loss 5.8364 (5.8367)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.4%)	
12/04 04:56:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.8986 (1.7982)	Arch Loss 2.0050 (2.1060)	Arch Hard Loss 2.0109 (2.1118)	Arch Beta Loss 5.8350 (5.8361)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.4%)	
12/04 04:56:53AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 16/49] Final Prec@1 49.6800%
12/04 04:57:00AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1030	Prec@(1,5) (43.8%, 76.2%)
12/04 04:57:07AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0819	Prec@(1,5) (44.1%, 76.2%)
12/04 04:57:13AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0803	Prec@(1,5) (44.3%, 76.2%)
12/04 04:57:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0758	Prec@(1,5) (44.4%, 76.3%)
12/04 04:57:19AM searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 44.4320%
12/04 04:57:19AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 04:57:19AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.4320%
12/04 04:58:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.5181 (1.6777)	Arch Loss 2.0168 (2.0922)	Arch Hard Loss 2.0227 (2.0980)	Arch Beta Loss 5.8301 (5.8327)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.6%)	
12/04 04:58:58AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.7616 (1.7065)	Arch Loss 1.8826 (2.0747)	Arch Hard Loss 1.8884 (2.0805)	Arch Beta Loss 5.8264 (5.8299)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.0%, 83.2%)	
12/04 04:59:47AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8751 (1.7237)	Arch Loss 1.8444 (2.0826)	Arch Hard Loss 1.8503 (2.0885)	Arch Beta Loss 5.8199 (5.8278)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.8%)	
12/04 05:00:31AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.2770 (1.7365)	Arch Loss 1.9753 (2.0753)	Arch Hard Loss 1.9811 (2.0811)	Arch Beta Loss 5.8167 (5.8256)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.8%)	
12/04 05:00:32AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 17/49] Final Prec@1 51.2520%
12/04 05:00:38AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0655	Prec@(1,5) (45.0%, 76.3%)
12/04 05:00:45AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0456	Prec@(1,5) (45.6%, 76.9%)
12/04 05:00:51AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0452	Prec@(1,5) (45.6%, 77.0%)
12/04 05:00:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0477	Prec@(1,5) (45.4%, 76.9%)
12/04 05:00:57AM searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 45.4400%
12/04 05:00:57AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 05:00:58AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.4400%
12/04 05:01:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4038 (1.6239)	Arch Loss 2.3689 (2.0342)	Arch Hard Loss 2.3747 (2.0400)	Arch Beta Loss 5.8151 (5.8163)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.5%)	
12/04 05:02:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4932 (1.6648)	Arch Loss 1.8288 (2.0444)	Arch Hard Loss 1.8346 (2.0502)	Arch Beta Loss 5.8066 (5.8136)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.4%, 83.7%)	
12/04 05:03:21AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.7056 (1.6636)	Arch Loss 2.1261 (2.0482)	Arch Hard Loss 2.1319 (2.0540)	Arch Beta Loss 5.8043 (5.8110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.8%)	
12/04 05:04:04AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.6616 (1.6747)	Arch Loss 1.3954 (2.0380)	Arch Hard Loss 1.4012 (2.0438)	Arch Beta Loss 5.8012 (5.8090)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.6%)	
12/04 05:04:05AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 18/49] Final Prec@1 52.9680%
12/04 05:04:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0355	Prec@(1,5) (45.4%, 76.7%)
12/04 05:04:18AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0278	Prec@(1,5) (46.0%, 77.3%)
12/04 05:04:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0258	Prec@(1,5) (46.1%, 77.4%)
12/04 05:04:31AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0276	Prec@(1,5) (45.9%, 77.5%)
12/04 05:04:31AM searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 45.8800%
12/04 05:04:31AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 05:04:31AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.8800%
12/04 05:05:20AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.2395 (1.5694)	Arch Loss 2.3070 (2.0204)	Arch Hard Loss 2.3128 (2.0262)	Arch Beta Loss 5.7972 (5.7982)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.6%)	
12/04 05:06:08AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.7866 (1.5941)	Arch Loss 2.4885 (2.0210)	Arch Hard Loss 2.4942 (2.0268)	Arch Beta Loss 5.7940 (5.7963)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 85.3%)	
12/04 05:06:56AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.0525 (1.6071)	Arch Loss 1.6272 (2.0089)	Arch Hard Loss 1.6330 (2.0147)	Arch Beta Loss 5.7862 (5.7945)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.1%, 85.1%)	
12/04 05:07:40AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.4914 (1.6231)	Arch Loss 2.1336 (2.0068)	Arch Hard Loss 2.1394 (2.0126)	Arch Beta Loss 5.7845 (5.7923)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.8%, 84.7%)	
12/04 05:07:41AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 19/49] Final Prec@1 53.8120%
12/04 05:07:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0201	Prec@(1,5) (47.0%, 77.2%)
12/04 05:07:54AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0262	Prec@(1,5) (46.5%, 77.0%)
12/04 05:08:01AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0257	Prec@(1,5) (46.5%, 77.1%)
12/04 05:08:07AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0252	Prec@(1,5) (46.2%, 77.2%)
12/04 05:08:07AM searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 46.1640%
12/04 05:08:07AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 05:08:08AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.1640%
12/04 05:08:58AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6326 (1.5221)	Arch Loss 1.9883 (2.0149)	Arch Hard Loss 1.9940 (2.0206)	Arch Beta Loss 5.7817 (5.7837)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.5%)	
12/04 05:09:46AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.8277 (1.5407)	Arch Loss 2.7792 (2.0118)	Arch Hard Loss 2.7850 (2.0175)	Arch Beta Loss 5.7836 (5.7829)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.0%)	
12/04 05:10:35AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.2000 (1.5564)	Arch Loss 1.9178 (2.0039)	Arch Hard Loss 1.9236 (2.0097)	Arch Beta Loss 5.7808 (5.7826)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.7%)	
12/04 05:11:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.7145 (1.5750)	Arch Loss 1.7140 (1.9966)	Arch Hard Loss 1.7198 (2.0024)	Arch Beta Loss 5.7769 (5.7817)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.4%, 85.3%)	
12/04 05:11:18AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 20/49] Final Prec@1 55.4120%
12/04 05:11:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9575	Prec@(1,5) (47.9%, 78.7%)
12/04 05:11:32AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9448	Prec@(1,5) (48.1%, 79.1%)
12/04 05:11:39AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9478	Prec@(1,5) (47.9%, 79.0%)
12/04 05:11:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9531	Prec@(1,5) (47.7%, 78.9%)
12/04 05:11:44AM searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 47.7280%
12/04 05:11:44AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 05:11:45AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.7280%
12/04 05:12:36AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5595 (1.4396)	Arch Loss 2.2044 (1.9571)	Arch Hard Loss 2.2102 (1.9629)	Arch Beta Loss 5.7708 (5.7739)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.7%, 88.0%)	
12/04 05:13:25AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4948 (1.4834)	Arch Loss 2.0544 (1.9648)	Arch Hard Loss 2.0602 (1.9705)	Arch Beta Loss 5.7671 (5.7714)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.8%)	
12/04 05:14:13AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.6058 (1.5054)	Arch Loss 1.8008 (1.9608)	Arch Hard Loss 1.8066 (1.9665)	Arch Beta Loss 5.7633 (5.7697)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.5%)	
12/04 05:14:56AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.5773 (1.5150)	Arch Loss 1.7990 (1.9596)	Arch Hard Loss 1.8048 (1.9653)	Arch Beta Loss 5.7592 (5.7679)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.8%, 86.4%)	
12/04 05:14:57AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 21/49] Final Prec@1 56.8120%
12/04 05:15:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9417	Prec@(1,5) (49.2%, 78.8%)
12/04 05:15:10AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9473	Prec@(1,5) (48.2%, 78.9%)
12/04 05:15:16AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9361	Prec@(1,5) (48.1%, 79.2%)
12/04 05:15:22AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9358	Prec@(1,5) (47.9%, 79.1%)
12/04 05:15:22AM searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 47.8920%
12/04 05:15:22AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 4])
12/04 05:15:23AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8920%
12/04 05:16:13AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.8082 (1.3996)	Arch Loss 2.2714 (1.9716)	Arch Hard Loss 2.2772 (1.9774)	Arch Beta Loss 5.7545 (5.7563)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 88.6%)	
12/04 05:17:02AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.5880 (1.4342)	Arch Loss 1.8851 (1.9505)	Arch Hard Loss 1.8909 (1.9563)	Arch Beta Loss 5.7514 (5.7548)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.7%)	
12/04 05:17:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4310 (1.4524)	Arch Loss 2.2550 (1.9471)	Arch Hard Loss 2.2608 (1.9529)	Arch Beta Loss 5.7464 (5.7522)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.0%, 87.3%)	
12/04 05:18:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.4655 (1.4650)	Arch Loss 2.0853 (1.9412)	Arch Hard Loss 2.0910 (1.9470)	Arch Beta Loss 5.7464 (5.7509)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.7%, 87.3%)	
12/04 05:18:35AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 22/49] Final Prec@1 57.7120%
12/04 05:18:41AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9122	Prec@(1,5) (48.7%, 79.0%)
12/04 05:18:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9126	Prec@(1,5) (48.3%, 79.2%)
12/04 05:18:54AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9117	Prec@(1,5) (48.4%, 79.4%)
12/04 05:19:00AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9150	Prec@(1,5) (48.4%, 79.3%)
12/04 05:19:00AM searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 48.3680%
12/04 05:19:00AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[3, 4])
12/04 05:19:01AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3680%
12/04 05:19:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.3697 (1.3206)	Arch Loss 1.6485 (1.9235)	Arch Hard Loss 1.6543 (1.9292)	Arch Beta Loss 5.7435 (5.7448)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.4%, 89.4%)	
12/04 05:20:39AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3546 (1.3768)	Arch Loss 1.9806 (1.9311)	Arch Hard Loss 1.9863 (1.9369)	Arch Beta Loss 5.7368 (5.7424)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.4%)	
12/04 05:21:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.4012 (1.3880)	Arch Loss 1.7237 (1.9358)	Arch Hard Loss 1.7294 (1.9415)	Arch Beta Loss 5.7306 (5.7396)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.5%)	
12/04 05:22:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4927 (1.4056)	Arch Loss 2.0823 (1.9289)	Arch Hard Loss 2.0881 (1.9346)	Arch Beta Loss 5.7259 (5.7367)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 88.3%)	
12/04 05:22:12AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 23/49] Final Prec@1 59.2280%
12/04 05:22:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9000	Prec@(1,5) (49.8%, 78.6%)
12/04 05:22:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9082	Prec@(1,5) (49.1%, 79.2%)
12/04 05:22:32AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9217	Prec@(1,5) (48.9%, 79.1%)
12/04 05:22:38AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9229	Prec@(1,5) (48.9%, 79.3%)
12/04 05:22:38AM searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 48.9080%
12/04 05:22:38AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 4])
12/04 05:22:39AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.9080%
12/04 05:23:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 0.9004 (1.3315)	Arch Loss 2.0601 (1.8879)	Arch Hard Loss 2.0658 (1.8936)	Arch Beta Loss 5.7245 (5.7244)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 89.1%)	
12/04 05:24:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2801 (1.3553)	Arch Loss 2.2092 (1.9067)	Arch Hard Loss 2.2149 (1.9124)	Arch Beta Loss 5.7214 (5.7243)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.7%)	
12/04 05:25:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.7085 (1.3578)	Arch Loss 1.6450 (1.9045)	Arch Hard Loss 1.6507 (1.9102)	Arch Beta Loss 5.7159 (5.7224)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.7%)	
12/04 05:25:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2340 (1.3701)	Arch Loss 1.8558 (1.9107)	Arch Hard Loss 1.8616 (1.9165)	Arch Beta Loss 5.7097 (5.7200)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.6%)	
12/04 05:25:50AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 24/49] Final Prec@1 59.9600%
12/04 05:25:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9248	Prec@(1,5) (49.0%, 79.9%)
12/04 05:26:04AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9203	Prec@(1,5) (49.3%, 79.8%)
12/04 05:26:10AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9267	Prec@(1,5) (48.9%, 79.5%)
12/04 05:26:16AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9164	Prec@(1,5) (49.0%, 79.7%)
12/04 05:26:16AM searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 49.0280%
12/04 05:26:16AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 4])
12/04 05:26:17AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.0280%
12/04 05:27:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.2967 (1.2849)	Arch Loss 1.8867 (1.8727)	Arch Hard Loss 1.8924 (1.8784)	Arch Beta Loss 5.7022 (5.7054)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.7%)	
12/04 05:27:56AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.2039 (1.2952)	Arch Loss 2.3647 (1.8723)	Arch Hard Loss 2.3704 (1.8781)	Arch Beta Loss 5.7010 (5.7036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.7%)	
12/04 05:28:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.1389 (1.3104)	Arch Loss 1.3570 (1.8811)	Arch Hard Loss 1.3627 (1.8868)	Arch Beta Loss 5.6993 (5.7022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.5%)	
12/04 05:29:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 0.9785 (1.3161)	Arch Loss 1.5474 (1.8771)	Arch Hard Loss 1.5531 (1.8828)	Arch Beta Loss 5.6955 (5.7013)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.3%)	
12/04 05:29:29AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 25/49] Final Prec@1 61.9560%
12/04 05:29:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8442	Prec@(1,5) (50.7%, 81.1%)
12/04 05:29:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8560	Prec@(1,5) (50.5%, 80.9%)
12/04 05:29:49AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8393	Prec@(1,5) (50.6%, 81.1%)
12/04 05:29:55AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8423	Prec@(1,5) (50.5%, 80.9%)
12/04 05:29:55AM searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 50.5440%
12/04 05:29:55AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 05:29:55AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.5440%
12/04 05:30:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.6189 (1.2400)	Arch Loss 1.6702 (1.8289)	Arch Hard Loss 1.6759 (1.8346)	Arch Beta Loss 5.6911 (5.6930)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.4%)	
12/04 05:31:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.9694 (1.2618)	Arch Loss 2.1393 (1.8533)	Arch Hard Loss 2.1450 (1.8589)	Arch Beta Loss 5.6829 (5.6904)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.2%)	
12/04 05:32:24AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2538 (1.2637)	Arch Loss 1.6508 (1.8569)	Arch Hard Loss 1.6564 (1.8626)	Arch Beta Loss 5.6819 (5.6875)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.3%)	
12/04 05:33:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0964 (1.2815)	Arch Loss 2.1396 (1.8684)	Arch Hard Loss 2.1453 (1.8741)	Arch Beta Loss 5.6757 (5.6853)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 90.0%)	
12/04 05:33:07AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 26/49] Final Prec@1 62.5800%
12/04 05:33:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8356	Prec@(1,5) (50.6%, 81.2%)
12/04 05:33:21AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8197	Prec@(1,5) (51.2%, 81.2%)
12/04 05:33:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8264	Prec@(1,5) (50.9%, 81.1%)
12/04 05:33:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8300	Prec@(1,5) (50.6%, 81.0%)
12/04 05:33:33AM searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 50.6360%
12/04 05:33:33AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 05:33:34AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.6360%
12/04 05:34:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0906 (1.1561)	Arch Loss 2.4950 (1.8790)	Arch Hard Loss 2.5007 (1.8847)	Arch Beta Loss 5.6709 (5.6737)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.9%)	
12/04 05:35:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.5958 (1.1905)	Arch Loss 1.4971 (1.8539)	Arch Hard Loss 1.5028 (1.8596)	Arch Beta Loss 5.6657 (5.6711)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.4%)	
12/04 05:35:57AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.0322 (1.2089)	Arch Loss 2.1435 (1.8604)	Arch Hard Loss 2.1491 (1.8661)	Arch Beta Loss 5.6592 (5.6683)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.1%)	
12/04 05:36:40AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.1434 (1.2277)	Arch Loss 1.6879 (1.8565)	Arch Hard Loss 1.6935 (1.8621)	Arch Beta Loss 5.6550 (5.6655)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.8%)	
12/04 05:36:40AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 27/49] Final Prec@1 64.6520%
12/04 05:36:47AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8227	Prec@(1,5) (50.4%, 81.2%)
12/04 05:36:54AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8097	Prec@(1,5) (51.1%, 81.4%)
12/04 05:37:00AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8153	Prec@(1,5) (51.2%, 81.3%)
12/04 05:37:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8119	Prec@(1,5) (51.3%, 81.3%)
12/04 05:37:06AM searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 51.3120%
12/04 05:37:06AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 05:37:07AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.3120%
12/04 05:37:56AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.4663 (1.1333)	Arch Loss 1.8343 (1.8158)	Arch Hard Loss 1.8399 (1.8214)	Arch Beta Loss 5.6457 (5.6512)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.6%)	
12/04 05:38:44AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.0403 (1.1613)	Arch Loss 1.5116 (1.8213)	Arch Hard Loss 1.5172 (1.8269)	Arch Beta Loss 5.6426 (5.6480)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.6%)	
12/04 05:39:33AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.2246 (1.1695)	Arch Loss 1.8118 (1.8288)	Arch Hard Loss 1.8175 (1.8345)	Arch Beta Loss 5.6372 (5.6450)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.4%)	
12/04 05:40:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.0748 (1.1906)	Arch Loss 1.4374 (1.8394)	Arch Hard Loss 1.4430 (1.8450)	Arch Beta Loss 5.6355 (5.6429)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.2%)	
12/04 05:40:18AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 28/49] Final Prec@1 65.3200%
12/04 05:40:24AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8477	Prec@(1,5) (50.3%, 81.0%)
12/04 05:40:31AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8577	Prec@(1,5) (50.0%, 80.7%)
12/04 05:40:37AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8334	Prec@(1,5) (50.6%, 81.1%)
12/04 05:40:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8253	Prec@(1,5) (50.8%, 81.3%)
12/04 05:40:43AM searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 50.8160%
12/04 05:40:43AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 05:40:43AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.3120%
12/04 05:41:33AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.3236 (1.0937)	Arch Loss 1.6404 (1.8360)	Arch Hard Loss 1.6461 (1.8416)	Arch Beta Loss 5.6352 (5.6352)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.7%)	
12/04 05:42:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9951 (1.1058)	Arch Loss 1.6100 (1.8359)	Arch Hard Loss 1.6156 (1.8415)	Arch Beta Loss 5.6309 (5.6343)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.5%)	
12/04 05:43:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.0295 (1.1226)	Arch Loss 1.9553 (1.8330)	Arch Hard Loss 1.9609 (1.8387)	Arch Beta Loss 5.6276 (5.6329)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 92.2%)	
12/04 05:43:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.2009 (1.1356)	Arch Loss 1.9152 (1.8273)	Arch Hard Loss 1.9208 (1.8329)	Arch Beta Loss 5.6217 (5.6310)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 92.0%)	
12/04 05:43:55AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 29/49] Final Prec@1 66.6120%
12/04 05:44:02AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7965	Prec@(1,5) (51.4%, 81.8%)
12/04 05:44:08AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7701	Prec@(1,5) (52.5%, 82.2%)
12/04 05:44:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7842	Prec@(1,5) (52.2%, 81.9%)
12/04 05:44:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7777	Prec@(1,5) (52.2%, 82.2%)
12/04 05:44:20AM searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 52.2200%
12/04 05:44:20AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 05:44:21AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.2200%
12/04 05:45:11AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.1781 (1.0587)	Arch Loss 1.3803 (1.7776)	Arch Hard Loss 1.3859 (1.7832)	Arch Beta Loss 5.6212 (5.6211)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.3%)	
12/04 05:45:59AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.1426 (1.0593)	Arch Loss 1.9966 (1.8132)	Arch Hard Loss 2.0022 (1.8189)	Arch Beta Loss 5.6128 (5.6194)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.1%)	
12/04 05:46:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.2355 (1.0783)	Arch Loss 1.4422 (1.8035)	Arch Hard Loss 1.4478 (1.8091)	Arch Beta Loss 5.6109 (5.6169)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.7%)	
12/04 05:47:32AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.3197 (1.1003)	Arch Loss 2.1143 (1.8094)	Arch Hard Loss 2.1199 (1.8150)	Arch Beta Loss 5.6077 (5.6151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.5%)	
12/04 05:47:33AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 30/49] Final Prec@1 67.9600%
12/04 05:47:39AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7841	Prec@(1,5) (52.9%, 81.8%)
12/04 05:47:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7782	Prec@(1,5) (52.8%, 81.9%)
12/04 05:47:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7920	Prec@(1,5) (52.4%, 81.8%)
12/04 05:47:58AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7901	Prec@(1,5) (52.4%, 81.8%)
12/04 05:47:58AM searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 52.4120%
12/04 05:47:58AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 05:47:59AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.4120%
12/04 05:48:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.0724 (1.0231)	Arch Loss 2.0029 (1.7746)	Arch Hard Loss 2.0085 (1.7802)	Arch Beta Loss 5.6045 (5.6053)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.7%)	
12/04 05:49:36AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9178 (1.0243)	Arch Loss 1.6208 (1.7917)	Arch Hard Loss 1.6264 (1.7973)	Arch Beta Loss 5.5993 (5.6031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
12/04 05:50:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1571 (1.0477)	Arch Loss 2.0281 (1.7943)	Arch Hard Loss 2.0337 (1.7999)	Arch Beta Loss 5.5943 (5.6012)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.1%)	
12/04 05:51:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.2220 (1.0647)	Arch Loss 1.7046 (1.7907)	Arch Hard Loss 1.7101 (1.7963)	Arch Beta Loss 5.5948 (5.5996)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.8%)	
12/04 05:51:06AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 31/49] Final Prec@1 68.8880%
12/04 05:51:13AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7088	Prec@(1,5) (53.5%, 83.1%)
12/04 05:51:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7245	Prec@(1,5) (53.3%, 83.0%)
12/04 05:51:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7431	Prec@(1,5) (53.2%, 82.5%)
12/04 05:51:31AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7552	Prec@(1,5) (53.0%, 82.2%)
12/04 05:51:31AM searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 52.9600%
12/04 05:51:31AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 05:51:32AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.9600%
12/04 05:52:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.2599 (1.0038)	Arch Loss 1.6208 (1.7823)	Arch Hard Loss 1.6264 (1.7879)	Arch Beta Loss 5.5929 (5.5938)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.6%, 94.0%)	
12/04 05:53:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9628 (1.0120)	Arch Loss 1.8591 (1.7887)	Arch Hard Loss 1.8647 (1.7943)	Arch Beta Loss 5.5879 (5.5921)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.8%)	
12/04 05:53:59AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8033 (1.0132)	Arch Loss 1.9622 (1.7946)	Arch Hard Loss 1.9678 (1.8002)	Arch Beta Loss 5.5847 (5.5899)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.6%)	
12/04 05:54:43AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.0043 (1.0218)	Arch Loss 1.6820 (1.7882)	Arch Hard Loss 1.6876 (1.7938)	Arch Beta Loss 5.5805 (5.5880)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.4%)	
12/04 05:54:44AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 32/49] Final Prec@1 69.7000%
12/04 05:54:50AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7693	Prec@(1,5) (52.5%, 82.5%)
12/04 05:54:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7616	Prec@(1,5) (52.8%, 82.7%)
12/04 05:55:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7562	Prec@(1,5) (53.1%, 82.6%)
12/04 05:55:09AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7535	Prec@(1,5) (53.2%, 82.7%)
12/04 05:55:09AM searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 53.2000%
12/04 05:55:09AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 05:55:10AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2000%
12/04 05:56:00AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8847 (0.9217)	Arch Loss 1.8827 (1.7829)	Arch Hard Loss 1.8883 (1.7885)	Arch Beta Loss 5.5761 (5.5778)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.5%, 95.0%)	
12/04 05:56:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.6779 (0.9485)	Arch Loss 1.5651 (1.7565)	Arch Hard Loss 1.5707 (1.7621)	Arch Beta Loss 5.5734 (5.5761)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.5%)	
12/04 05:57:38AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2245 (0.9651)	Arch Loss 2.1151 (1.7855)	Arch Hard Loss 2.1207 (1.7911)	Arch Beta Loss 5.5675 (5.5742)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.3%)	
12/04 05:58:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1009 (0.9759)	Arch Loss 1.6589 (1.7794)	Arch Hard Loss 1.6645 (1.7850)	Arch Beta Loss 5.5642 (5.5723)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.2%)	
12/04 05:58:23AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 33/49] Final Prec@1 71.5120%
12/04 05:58:30AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7466	Prec@(1,5) (53.2%, 82.8%)
12/04 05:58:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7424	Prec@(1,5) (53.5%, 82.9%)
12/04 05:58:42AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7495	Prec@(1,5) (53.3%, 82.7%)
12/04 05:58:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7583	Prec@(1,5) (53.3%, 82.5%)
12/04 05:58:48AM searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 53.2560%
12/04 05:58:48AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 05:58:49AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2560%
12/04 05:59:39AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7249 (0.8860)	Arch Loss 1.8296 (1.7242)	Arch Hard Loss 1.8352 (1.7298)	Arch Beta Loss 5.5588 (5.5613)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.1%)	
12/04 06:00:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.7359 (0.9231)	Arch Loss 2.1301 (1.7615)	Arch Hard Loss 2.1357 (1.7671)	Arch Beta Loss 5.5554 (5.5593)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.7%)	
12/04 06:01:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.9686 (0.9356)	Arch Loss 2.1006 (1.7684)	Arch Hard Loss 2.1061 (1.7740)	Arch Beta Loss 5.5495 (5.5572)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.4%)	
12/04 06:02:00AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.2037 (0.9539)	Arch Loss 1.7328 (1.7709)	Arch Hard Loss 1.7383 (1.7765)	Arch Beta Loss 5.5461 (5.5551)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.2%)	
12/04 06:02:00AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 34/49] Final Prec@1 71.7840%
12/04 06:02:07AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7462	Prec@(1,5) (53.6%, 83.0%)
12/04 06:02:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7568	Prec@(1,5) (53.2%, 82.6%)
12/04 06:02:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7478	Prec@(1,5) (53.4%, 82.7%)
12/04 06:02:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7425	Prec@(1,5) (53.5%, 82.8%)
12/04 06:02:26AM searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 53.4760%
12/04 06:02:26AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:02:27AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4760%
12/04 06:03:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.9807 (0.8909)	Arch Loss 1.6933 (1.7639)	Arch Hard Loss 1.6988 (1.7695)	Arch Beta Loss 5.5416 (5.5440)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.2%)	
12/04 06:04:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9972 (0.9103)	Arch Loss 1.5832 (1.7700)	Arch Hard Loss 1.5888 (1.7755)	Arch Beta Loss 5.5384 (5.5419)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 95.0%)	
12/04 06:04:55AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.8696 (0.9188)	Arch Loss 1.8892 (1.7582)	Arch Hard Loss 1.8948 (1.7638)	Arch Beta Loss 5.5354 (5.5402)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.9%)	
12/04 06:05:38AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.9735 (0.9194)	Arch Loss 1.4389 (1.7639)	Arch Hard Loss 1.4445 (1.7694)	Arch Beta Loss 5.5313 (5.5385)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.9%)	
12/04 06:05:39AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 35/49] Final Prec@1 73.0280%
12/04 06:05:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.6855	Prec@(1,5) (54.9%, 83.4%)
12/04 06:05:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7054	Prec@(1,5) (54.7%, 83.3%)
12/04 06:05:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7068	Prec@(1,5) (54.9%, 83.2%)
12/04 06:06:05AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7056	Prec@(1,5) (54.8%, 83.2%)
12/04 06:06:05AM searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 54.7760%
12/04 06:06:05AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:06:06AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7760%
12/04 06:06:55AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8248 (0.8404)	Arch Loss 2.0347 (1.7709)	Arch Hard Loss 2.0403 (1.7764)	Arch Beta Loss 5.5293 (5.5307)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 96.0%)	
12/04 06:07:43AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.7138 (0.8684)	Arch Loss 1.4520 (1.7502)	Arch Hard Loss 1.4576 (1.7558)	Arch Beta Loss 5.5269 (5.5294)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.6%)	
12/04 06:08:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8144 (0.8762)	Arch Loss 1.9311 (1.7475)	Arch Hard Loss 1.9366 (1.7530)	Arch Beta Loss 5.5225 (5.5278)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.4%)	
12/04 06:09:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8021 (0.8790)	Arch Loss 1.7385 (1.7495)	Arch Hard Loss 1.7440 (1.7551)	Arch Beta Loss 5.5228 (5.5266)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.4%)	
12/04 06:09:13AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 36/49] Final Prec@1 73.9720%
12/04 06:09:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7220	Prec@(1,5) (54.7%, 83.4%)
12/04 06:09:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7113	Prec@(1,5) (54.9%, 83.4%)
12/04 06:09:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7239	Prec@(1,5) (54.5%, 83.1%)
12/04 06:09:39AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7227	Prec@(1,5) (54.2%, 83.2%)
12/04 06:09:39AM searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 54.2560%
12/04 06:09:39AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:09:39AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7760%
12/04 06:10:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.7256 (0.8154)	Arch Loss 2.0109 (1.7540)	Arch Hard Loss 2.0164 (1.7596)	Arch Beta Loss 5.5204 (5.5221)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.8%)	
12/04 06:11:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.7863 (0.8254)	Arch Loss 2.1272 (1.7345)	Arch Hard Loss 2.1327 (1.7400)	Arch Beta Loss 5.5147 (5.5195)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.7%)	
12/04 06:12:04AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8388 (0.8356)	Arch Loss 1.6376 (1.7410)	Arch Hard Loss 1.6431 (1.7465)	Arch Beta Loss 5.5101 (5.5171)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.5%)	
12/04 06:12:47AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.6748 (0.8376)	Arch Loss 1.8463 (1.7436)	Arch Hard Loss 1.8518 (1.7491)	Arch Beta Loss 5.5078 (5.5152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.7%)	
12/04 06:12:48AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 37/49] Final Prec@1 75.4960%
12/04 06:12:55AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7256	Prec@(1,5) (54.2%, 83.1%)
12/04 06:13:02AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7201	Prec@(1,5) (54.4%, 83.2%)
12/04 06:13:08AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7132	Prec@(1,5) (54.6%, 83.3%)
12/04 06:13:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7157	Prec@(1,5) (54.3%, 83.2%)
12/04 06:13:14AM searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 54.3000%
12/04 06:13:14AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:13:15AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7760%
12/04 06:14:04AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6045 (0.8004)	Arch Loss 1.6076 (1.7329)	Arch Hard Loss 1.6131 (1.7385)	Arch Beta Loss 5.5068 (5.5070)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.8%)	
12/04 06:14:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6978 (0.8100)	Arch Loss 1.8460 (1.7132)	Arch Hard Loss 1.8515 (1.7187)	Arch Beta Loss 5.5028 (5.5058)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.8%)	
12/04 06:15:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.9114 (0.8133)	Arch Loss 1.8529 (1.7219)	Arch Hard Loss 1.8584 (1.7274)	Arch Beta Loss 5.4980 (5.5037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.8%)	
12/04 06:16:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6273 (0.8159)	Arch Loss 2.0460 (1.7435)	Arch Hard Loss 2.0515 (1.7490)	Arch Beta Loss 5.4936 (5.5018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.8%)	
12/04 06:16:27AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 38/49] Final Prec@1 76.1200%
12/04 06:16:34AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7159	Prec@(1,5) (55.3%, 82.6%)
12/04 06:16:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.6992	Prec@(1,5) (55.4%, 83.0%)
12/04 06:16:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.6940	Prec@(1,5) (55.2%, 83.3%)
12/04 06:16:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.6922	Prec@(1,5) (55.1%, 83.3%)
12/04 06:16:52AM searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 55.0800%
12/04 06:16:52AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:16:53AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0800%
12/04 06:17:43AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.6926 (0.7681)	Arch Loss 1.5093 (1.7188)	Arch Hard Loss 1.5148 (1.7243)	Arch Beta Loss 5.4888 (5.4911)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.2%)	
12/04 06:18:32AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6990 (0.7736)	Arch Loss 1.7941 (1.7182)	Arch Hard Loss 1.7996 (1.7237)	Arch Beta Loss 5.4863 (5.4893)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.3%)	
12/04 06:19:20AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.6824 (0.7823)	Arch Loss 1.5741 (1.7263)	Arch Hard Loss 1.5796 (1.7318)	Arch Beta Loss 5.4811 (5.4876)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.1%)	
12/04 06:20:04AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8292 (0.7876)	Arch Loss 1.6558 (1.7336)	Arch Hard Loss 1.6612 (1.7390)	Arch Beta Loss 5.4802 (5.4860)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
12/04 06:20:05AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 39/49] Final Prec@1 77.1840%
12/04 06:20:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.6939	Prec@(1,5) (54.8%, 83.7%)
12/04 06:20:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.6933	Prec@(1,5) (55.1%, 83.6%)
12/04 06:20:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.6934	Prec@(1,5) (55.0%, 83.5%)
12/04 06:20:32AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.6963	Prec@(1,5) (55.1%, 83.4%)
12/04 06:20:32AM searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 55.1160%
12/04 06:20:32AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:20:32AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.1160%
12/04 06:21:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6376 (0.7313)	Arch Loss 1.9535 (1.7853)	Arch Hard Loss 1.9590 (1.7908)	Arch Beta Loss 5.4799 (5.4804)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
12/04 06:22:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.7598 (0.7364)	Arch Loss 2.0307 (1.7627)	Arch Hard Loss 2.0362 (1.7682)	Arch Beta Loss 5.4749 (5.4788)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.7%)	
12/04 06:23:01AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.5431 (0.7531)	Arch Loss 1.6415 (1.7522)	Arch Hard Loss 1.6470 (1.7577)	Arch Beta Loss 5.4719 (5.4770)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
12/04 06:23:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.9400 (0.7542)	Arch Loss 1.6871 (1.7390)	Arch Hard Loss 1.6926 (1.7444)	Arch Beta Loss 5.4689 (5.4753)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.6%)	
12/04 06:23:46AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 40/49] Final Prec@1 78.4800%
12/04 06:23:53AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.6491	Prec@(1,5) (56.2%, 84.4%)
12/04 06:23:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.6672	Prec@(1,5) (55.8%, 83.9%)
12/04 06:24:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.6737	Prec@(1,5) (55.5%, 83.8%)
12/04 06:24:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.6797	Prec@(1,5) (55.3%, 83.8%)
12/04 06:24:12AM searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 55.2720%
12/04 06:24:12AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:24:13AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2720%
12/04 06:25:03AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.6643 (0.7166)	Arch Loss 1.8518 (1.7482)	Arch Hard Loss 1.8573 (1.7537)	Arch Beta Loss 5.4661 (5.4673)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
12/04 06:25:52AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5945 (0.7208)	Arch Loss 1.9393 (1.7439)	Arch Hard Loss 1.9448 (1.7494)	Arch Beta Loss 5.4619 (5.4655)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
12/04 06:26:40AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6207 (0.7208)	Arch Loss 1.3459 (1.7425)	Arch Hard Loss 1.3513 (1.7479)	Arch Beta Loss 5.4557 (5.4634)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.9%)	
12/04 06:27:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.8009 (0.7322)	Arch Loss 1.5746 (1.7359)	Arch Hard Loss 1.5801 (1.7414)	Arch Beta Loss 5.4532 (5.4613)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.9%)	
12/04 06:27:23AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 41/49] Final Prec@1 79.2480%
12/04 06:27:30AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.6921	Prec@(1,5) (55.2%, 83.7%)
12/04 06:27:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.6902	Prec@(1,5) (55.1%, 83.9%)
12/04 06:27:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.6858	Prec@(1,5) (55.4%, 83.9%)
12/04 06:27:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.6878	Prec@(1,5) (55.3%, 83.8%)
12/04 06:27:49AM searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 55.2680%
12/04 06:27:49AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:27:49AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2720%
12/04 06:28:38AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6151 (0.6872)	Arch Loss 1.5230 (1.7292)	Arch Hard Loss 1.5284 (1.7346)	Arch Beta Loss 5.4532 (5.4530)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.2%)	
12/04 06:29:27AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6468 (0.7021)	Arch Loss 1.6512 (1.7085)	Arch Hard Loss 1.6566 (1.7139)	Arch Beta Loss 5.4503 (5.4522)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
12/04 06:30:15AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6391 (0.7107)	Arch Loss 2.2110 (1.7199)	Arch Hard Loss 2.2164 (1.7253)	Arch Beta Loss 5.4454 (5.4509)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.0%)	
12/04 06:30:59AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.7029 (0.7123)	Arch Loss 1.8034 (1.7170)	Arch Hard Loss 1.8088 (1.7224)	Arch Beta Loss 5.4413 (5.4489)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
12/04 06:31:00AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 42/49] Final Prec@1 79.9880%
12/04 06:31:07AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6624	Prec@(1,5) (55.6%, 84.0%)
12/04 06:31:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.6819	Prec@(1,5) (55.4%, 83.7%)
12/04 06:31:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.6809	Prec@(1,5) (55.3%, 83.6%)
12/04 06:31:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.6844	Prec@(1,5) (55.2%, 83.7%)
12/04 06:31:26AM searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 55.2240%
12/04 06:31:26AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:31:26AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2720%
12/04 06:32:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7518 (0.6847)	Arch Loss 1.7922 (1.6987)	Arch Hard Loss 1.7977 (1.7041)	Arch Beta Loss 5.4401 (5.4405)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.4%)	
12/04 06:33:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.7463 (0.6913)	Arch Loss 1.7519 (1.7079)	Arch Hard Loss 1.7574 (1.7134)	Arch Beta Loss 5.4363 (5.4392)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
12/04 06:33:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7972 (0.6898)	Arch Loss 2.0989 (1.7145)	Arch Hard Loss 2.1043 (1.7199)	Arch Beta Loss 5.4325 (5.4374)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
12/04 06:34:36AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.5684 (0.6955)	Arch Loss 1.6561 (1.7186)	Arch Hard Loss 1.6615 (1.7240)	Arch Beta Loss 5.4308 (5.4362)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.2%)	
12/04 06:34:37AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 43/49] Final Prec@1 80.4040%
12/04 06:34:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6558	Prec@(1,5) (56.0%, 84.3%)
12/04 06:34:50AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6505	Prec@(1,5) (56.0%, 84.3%)
12/04 06:34:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6535	Prec@(1,5) (56.0%, 84.1%)
12/04 06:35:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.6655	Prec@(1,5) (56.0%, 83.9%)
12/04 06:35:03AM searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 55.9800%
12/04 06:35:03AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
12/04 06:35:03AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.9800%
12/04 06:35:52AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.6697 (0.6660)	Arch Loss 1.8324 (1.7290)	Arch Hard Loss 1.8378 (1.7344)	Arch Beta Loss 5.4274 (5.4295)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.5%)	
12/04 06:36:39AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8387 (0.6672)	Arch Loss 2.4446 (1.7273)	Arch Hard Loss 2.4500 (1.7327)	Arch Beta Loss 5.4218 (5.4271)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
12/04 06:37:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6934 (0.6784)	Arch Loss 1.9642 (1.7309)	Arch Hard Loss 1.9697 (1.7363)	Arch Beta Loss 5.4189 (5.4249)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.3%)	
12/04 06:38:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5394 (0.6791)	Arch Loss 2.0102 (1.7240)	Arch Hard Loss 2.0156 (1.7294)	Arch Beta Loss 5.4165 (5.4233)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.3%)	
12/04 06:38:13AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 44/49] Final Prec@1 80.9880%
12/04 06:38:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6589	Prec@(1,5) (55.6%, 84.4%)
12/04 06:38:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6743	Prec@(1,5) (55.6%, 84.2%)
12/04 06:38:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6729	Prec@(1,5) (55.7%, 84.1%)
12/04 06:38:38AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.6768	Prec@(1,5) (55.6%, 84.0%)
12/04 06:38:39AM searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 55.6360%
12/04 06:38:39AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 06:38:39AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.9800%
12/04 06:39:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5504 (0.6719)	Arch Loss 1.3510 (1.7016)	Arch Hard Loss 1.3564 (1.7070)	Arch Beta Loss 5.4150 (5.4150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
12/04 06:40:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.8672 (0.6670)	Arch Loss 2.0827 (1.7136)	Arch Hard Loss 2.0881 (1.7190)	Arch Beta Loss 5.4100 (5.4139)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.3%)	
12/04 06:41:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6804 (0.6675)	Arch Loss 2.0069 (1.7125)	Arch Hard Loss 2.0123 (1.7179)	Arch Beta Loss 5.4077 (5.4122)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.3%)	
12/04 06:41:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4999 (0.6682)	Arch Loss 1.6356 (1.7190)	Arch Hard Loss 1.6411 (1.7244)	Arch Beta Loss 5.4057 (5.4110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.3%)	
12/04 06:41:51AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 45/49] Final Prec@1 81.4720%
12/04 06:41:58AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6239	Prec@(1,5) (57.0%, 84.3%)
12/04 06:42:04AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.6522	Prec@(1,5) (56.4%, 83.9%)
12/04 06:42:11AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.6675	Prec@(1,5) (56.1%, 83.8%)
12/04 06:42:17AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.6683	Prec@(1,5) (55.9%, 83.8%)
12/04 06:42:17AM searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 55.8640%
12/04 06:42:17AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/04 06:42:17AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.9800%
12/04 06:43:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.8279 (0.6215)	Arch Loss 1.7626 (1.7078)	Arch Hard Loss 1.7680 (1.7132)	Arch Beta Loss 5.4035 (5.4050)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.5%)	
12/04 06:43:57AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5483 (0.6414)	Arch Loss 1.7155 (1.7120)	Arch Hard Loss 1.7209 (1.7174)	Arch Beta Loss 5.3998 (5.4036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.5%)	
12/04 06:44:46AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5385 (0.6428)	Arch Loss 1.7392 (1.7121)	Arch Hard Loss 1.7446 (1.7175)	Arch Beta Loss 5.3935 (5.4015)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.6%)	
12/04 06:45:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.5520 (0.6526)	Arch Loss 1.8523 (1.7147)	Arch Hard Loss 1.8577 (1.7201)	Arch Beta Loss 5.3911 (5.3994)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.4%)	
12/04 06:45:30AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 46/49] Final Prec@1 82.0200%
12/04 06:45:37AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.6684	Prec@(1,5) (56.5%, 83.7%)
12/04 06:45:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6690	Prec@(1,5) (56.2%, 83.7%)
12/04 06:45:50AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6682	Prec@(1,5) (56.1%, 83.8%)
12/04 06:45:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.6666	Prec@(1,5) (56.0%, 83.9%)
12/04 06:45:56AM searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 56.0160%
12/04 06:45:56AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 06:45:57AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0160%
12/04 06:46:47AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.7073 (0.6395)	Arch Loss 1.3624 (1.6873)	Arch Hard Loss 1.3678 (1.6927)	Arch Beta Loss 5.3879 (5.3895)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 98.0%)	
12/04 06:47:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.4494 (0.6347)	Arch Loss 1.5597 (1.7111)	Arch Hard Loss 1.5650 (1.7165)	Arch Beta Loss 5.3834 (5.3876)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.9%)	
12/04 06:48:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.4979 (0.6432)	Arch Loss 1.7563 (1.7110)	Arch Hard Loss 1.7617 (1.7163)	Arch Beta Loss 5.3799 (5.3857)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.8%)	
12/04 06:49:09AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.6952 (0.6447)	Arch Loss 1.9537 (1.7123)	Arch Hard Loss 1.9591 (1.7176)	Arch Beta Loss 5.3780 (5.3839)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.7%)	
12/04 06:49:10AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 47/49] Final Prec@1 82.2520%
12/04 06:49:17AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6658	Prec@(1,5) (54.8%, 84.2%)
12/04 06:49:24AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6649	Prec@(1,5) (55.6%, 83.9%)
12/04 06:49:31AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6672	Prec@(1,5) (55.7%, 83.9%)
12/04 06:49:37AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6706	Prec@(1,5) (55.6%, 83.9%)
12/04 06:49:37AM searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 55.6080%
12/04 06:49:37AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 06:49:37AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0160%
12/04 06:50:27AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6485 (0.6231)	Arch Loss 1.6226 (1.6857)	Arch Hard Loss 1.6280 (1.6910)	Arch Beta Loss 5.3767 (5.3769)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
12/04 06:51:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6356 (0.6306)	Arch Loss 1.9447 (1.7191)	Arch Hard Loss 1.9501 (1.7244)	Arch Beta Loss 5.3749 (5.3759)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
12/04 06:52:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.6981 (0.6420)	Arch Loss 1.6362 (1.7145)	Arch Hard Loss 1.6416 (1.7198)	Arch Beta Loss 5.3710 (5.3748)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
12/04 06:52:49AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6921 (0.6472)	Arch Loss 1.6844 (1.7175)	Arch Hard Loss 1.6898 (1.7229)	Arch Beta Loss 5.3693 (5.3737)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.7%)	
12/04 06:52:49AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 48/49] Final Prec@1 81.9800%
12/04 06:52:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.6793	Prec@(1,5) (55.3%, 84.0%)
12/04 06:53:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6697	Prec@(1,5) (55.5%, 84.1%)
12/04 06:53:09AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6579	Prec@(1,5) (55.6%, 84.3%)
12/04 06:53:15AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6610	Prec@(1,5) (55.7%, 84.3%)
12/04 06:53:15AM searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 55.6960%
12/04 06:53:15AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 06:53:15AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0160%
12/04 06:54:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.6647 (0.6260)	Arch Loss 1.8752 (1.7119)	Arch Hard Loss 1.8806 (1.7172)	Arch Beta Loss 5.3667 (5.3684)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
12/04 06:54:55AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5915 (0.6271)	Arch Loss 1.9271 (1.7161)	Arch Hard Loss 1.9325 (1.7215)	Arch Beta Loss 5.3678 (5.3677)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
12/04 06:55:44AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5439 (0.6305)	Arch Loss 1.9021 (1.7157)	Arch Hard Loss 1.9075 (1.7211)	Arch Beta Loss 5.3641 (5.3670)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.7%)	
12/04 06:56:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6695 (0.6374)	Arch Loss 1.3956 (1.7208)	Arch Hard Loss 1.4010 (1.7262)	Arch Beta Loss 5.3637 (5.3663)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
12/04 06:56:29AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 49/49] Final Prec@1 82.4800%
12/04 06:56:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6469	Prec@(1,5) (55.3%, 84.7%)
12/04 06:56:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6666	Prec@(1,5) (55.5%, 84.3%)
12/04 06:56:49AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6790	Prec@(1,5) (55.5%, 83.9%)
12/04 06:56:55AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6656	Prec@(1,5) (55.8%, 84.1%)
12/04 06:56:55AM searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 55.7840%
12/04 06:56:55AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
12/04 06:56:55AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0160%
12/04 06:56:55AM trainer_runner.py:110 [INFO] Final best Prec@1 = 56.0160%
12/04 06:56:55AM trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
