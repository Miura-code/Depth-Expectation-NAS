11/27 03:23:59AM parser.py:28 [INFO] 
11/27 03:23:59AM parser.py:29 [INFO] Parameters:
11/27 03:23:59AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s4-expected-sw3-g_0-50/DAG
11/27 03:23:59AM parser.py:31 [INFO] T=10.0
11/27 03:23:59AM parser.py:31 [INFO] ADVANCED=1
11/27 03:23:59AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/27 03:23:59AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/27 03:23:59AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/27 03:23:59AM parser.py:31 [INFO] BATCH_SIZE=128
11/27 03:23:59AM parser.py:31 [INFO] CASCADE=0
11/27 03:23:59AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/27 03:23:59AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[0, 50]
11/27 03:23:59AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/27 03:23:59AM parser.py:31 [INFO] DATA_PATH=../data/
11/27 03:23:59AM parser.py:31 [INFO] DATASET=cifar100
11/27 03:23:59AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/27 03:23:59AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3_
11/27 03:23:59AM parser.py:31 [INFO] DISCRETE=1
11/27 03:23:59AM parser.py:31 [INFO] EPOCHS=50
11/27 03:23:59AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/27 03:23:59AM parser.py:31 [INFO] EXP_NAME=s4-expected-sw3-g_0-50
11/27 03:23:59AM parser.py:31 [INFO] FINAL_L=0.0
11/27 03:23:59AM parser.py:31 [INFO] G=0.001
11/27 03:23:59AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/27 03:23:59AM parser.py:31 [INFO] GPUS=[0]
11/27 03:23:59AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/27 03:23:59AM parser.py:31 [INFO] INIT_CHANNELS=16
11/27 03:23:59AM parser.py:31 [INFO] L=0.0
11/27 03:23:59AM parser.py:31 [INFO] LAYERS=32
11/27 03:23:59AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/27 03:23:59AM parser.py:31 [INFO] NAME=Curriculum
11/27 03:23:59AM parser.py:31 [INFO] NONKD=1
11/27 03:23:59AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s4-expected-sw3-g_0-50
11/27 03:23:59AM parser.py:31 [INFO] PCDARTS=0
11/27 03:23:59AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s4-expected-sw3-g_0-50/plots
11/27 03:23:59AM parser.py:31 [INFO] PRINT_FREQ=100
11/27 03:23:59AM parser.py:31 [INFO] RESET=0
11/27 03:23:59AM parser.py:31 [INFO] RESUME_PATH=None
11/27 03:23:59AM parser.py:31 [INFO] SAVE=s4-expected-sw3-g_0-50
11/27 03:23:59AM parser.py:31 [INFO] SEED=4
11/27 03:23:59AM parser.py:31 [INFO] SHARE_STAGE=0
11/27 03:23:59AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/27 03:23:59AM parser.py:31 [INFO] SPEC_CELL=1
11/27 03:23:59AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/27 03:23:59AM parser.py:31 [INFO] TEACHER_NAME=none
11/27 03:23:59AM parser.py:31 [INFO] TEACHER_PATH=none
11/27 03:23:59AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/27 03:23:59AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
11/27 03:23:59AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/27 03:23:59AM parser.py:31 [INFO] W_LR=0.025
11/27 03:23:59AM parser.py:31 [INFO] W_LR_MIN=0.001
11/27 03:23:59AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/27 03:23:59AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/27 03:23:59AM parser.py:31 [INFO] WORKERS=4
11/27 03:23:59AM parser.py:32 [INFO] 
11/27 03:24:01AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/27 03:24:01AM searchEvalStage_curriculum_trainer.py:146 [INFO] --> Curriculum part A finished. Part B begins!
11/27 03:25:41AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][100/195]	Step 100	lr 0.025	Loss 4.3374 (4.4545)	Arch Loss 4.5380 (4.8165)	Arch Hard Loss 4.1846 (4.4596)	Arch Beta Loss 353.3437 (356.8203)	Arch depth Loss -0.0024 (-0.0015)	Prec@(1,5) (2.7%, 11.4%)	
11/27 03:27:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][195/195]	Step 195	lr 0.025	Loss 4.0714 (4.2902)	Arch Loss 4.2889 (4.6431)	Arch Hard Loss 3.9422 (4.2896)	Arch Beta Loss 346.7345 (353.4875)	Arch depth Loss -0.0035 (-0.0022)	Prec@(1,5) (4.5%, 16.8%)	
11/27 03:27:16AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  0/149] Final Prec@1 4.4560%
11/27 03:27:32AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/196]	Step 196	Loss 3.9830	Prec@(1,5) (7.4%, 26.8%)
11/27 03:27:47AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][195/196]	Step 196	Loss 3.9867	Prec@(1,5) (7.5%, 26.6%)
11/27 03:27:47AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 7.4840%
11/27 03:27:47AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 6])
11/27 03:27:47AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 7.4840%
11/27 03:29:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][100/195]	Step 296	lr 0.025	Loss 3.9991 (3.9237)	Arch Loss 4.3195 (4.2597)	Arch Hard Loss 3.9797 (3.9165)	Arch Beta Loss 339.7928 (343.1914)	Arch depth Loss -0.0030 (-0.0031)	Prec@(1,5) (9.1%, 28.5%)	
11/27 03:30:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][195/195]	Step 391	lr 0.025	Loss 3.7813 (3.8455)	Arch Loss 3.9339 (4.1875)	Arch Hard Loss 3.6001 (3.8475)	Arch Beta Loss 333.7772 (340.0266)	Arch depth Loss -0.0014 (-0.0026)	Prec@(1,5) (10.0%, 31.2%)	
11/27 03:31:00午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  1/149] Final Prec@1 10.0280%
11/27 03:31:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/196]	Step 392	Loss 3.7077	Prec@(1,5) (11.8%, 36.1%)
11/27 03:31:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][195/196]	Step 392	Loss 3.7085	Prec@(1,5) (11.7%, 35.9%)
11/27 03:31:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 11.7160%
11/27 03:31:30午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[2, 3])
11/27 03:31:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 11.7160%
11/27 03:33:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][100/195]	Step 492	lr 0.02499	Loss 3.4124 (3.6396)	Arch Loss 3.8902 (3.9943)	Arch Hard Loss 3.5631 (3.6640)	Arch Beta Loss 327.1242 (330.3443)	Arch depth Loss -0.0053 (-0.0032)	Prec@(1,5) (13.2%, 37.8%)	
11/27 03:34:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][195/195]	Step 587	lr 0.02499	Loss 3.3968 (3.5730)	Arch Loss 3.8874 (3.9092)	Arch Hard Loss 3.5660 (3.5818)	Arch Beta Loss 321.4343 (327.3861)	Arch depth Loss -0.0027 (-0.0038)	Prec@(1,5) (14.3%, 39.8%)	
11/27 03:34:44午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  2/149] Final Prec@1 14.3040%
11/27 03:34:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/196]	Step 588	Loss 3.6136	Prec@(1,5) (14.1%, 39.2%)
11/27 03:35:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][195/196]	Step 588	Loss 3.6109	Prec@(1,5) (14.4%, 39.5%)
11/27 03:35:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 14.4280%
11/27 03:35:14午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 3])
11/27 03:35:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 14.4280%
11/27 03:36:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][100/195]	Step 688	lr 0.02498	Loss 3.3288 (3.3778)	Arch Loss 3.6271 (3.7223)	Arch Hard Loss 3.3116 (3.4039)	Arch Beta Loss 315.4984 (318.3721)	Arch depth Loss -0.0058 (-0.0057)	Prec@(1,5) (17.4%, 45.6%)	
11/27 03:38:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][195/195]	Step 783	lr 0.02498	Loss 3.1442 (3.3319)	Arch Loss 3.4045 (3.6733)	Arch Hard Loss 3.0944 (3.3576)	Arch Beta Loss 310.1381 (315.6439)	Arch depth Loss -0.0048 (-0.0056)	Prec@(1,5) (18.4%, 46.9%)	
11/27 03:38:27午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  3/149] Final Prec@1 18.3880%
11/27 03:38:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/196]	Step 784	Loss 3.3152	Prec@(1,5) (18.7%, 47.2%)
11/27 03:38:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][195/196]	Step 784	Loss 3.3205	Prec@(1,5) (18.6%, 47.0%)
11/27 03:38:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 18.6040%
11/27 03:38:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 3])
11/27 03:38:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 18.6040%
11/27 03:40:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][100/195]	Step 884	lr 0.02496	Loss 3.1260 (3.1738)	Arch Loss 3.7553 (3.5192)	Arch Hard Loss 3.4503 (3.2117)	Arch Beta Loss 304.9700 (307.4678)	Arch depth Loss -0.0042 (-0.0044)	Prec@(1,5) (21.4%, 51.1%)	
11/27 03:42:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][195/195]	Step 979	lr 0.02496	Loss 3.1105 (3.1393)	Arch Loss 3.3759 (3.4826)	Arch Hard Loss 3.0759 (3.1776)	Arch Beta Loss 299.9717 (305.0198)	Arch depth Loss -0.0031 (-0.0043)	Prec@(1,5) (21.8%, 52.0%)	
11/27 03:42:11午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  4/149] Final Prec@1 21.7720%
11/27 03:42:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/196]	Step 980	Loss 3.1718	Prec@(1,5) (22.4%, 51.0%)
11/27 03:42:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][195/196]	Step 980	Loss 3.1758	Prec@(1,5) (22.0%, 51.2%)
11/27 03:42:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 21.9960%
11/27 03:42:41午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 3])
11/27 03:42:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 21.9960%
11/27 03:44:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][100/195]	Step 1080	lr 0.02493	Loss 3.2693 (3.0026)	Arch Loss 3.2044 (3.3618)	Arch Hard Loss 2.9096 (3.0644)	Arch Beta Loss 294.8831 (297.4152)	Arch depth Loss -0.0042 (-0.0025)	Prec@(1,5) (24.2%, 55.8%)	
11/27 03:45:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][195/195]	Step 1175	lr 0.02493	Loss 2.9198 (2.9754)	Arch Loss 3.3207 (3.3251)	Arch Hard Loss 3.0303 (3.0301)	Arch Beta Loss 290.4029 (295.0807)	Arch depth Loss -0.0032 (-0.0027)	Prec@(1,5) (24.7%, 56.3%)	
11/27 03:45:54午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  5/149] Final Prec@1 24.7040%
11/27 03:46:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/196]	Step 1176	Loss 2.9900	Prec@(1,5) (25.3%, 56.5%)
11/27 03:46:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][195/196]	Step 1176	Loss 2.9740	Prec@(1,5) (25.3%, 56.7%)
11/27 03:46:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 25.3040%
11/27 03:46:25午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 3])
11/27 03:46:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 25.3040%
11/27 03:48:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][100/195]	Step 1276	lr 0.02491	Loss 2.8600 (2.8191)	Arch Loss 3.0613 (3.1999)	Arch Hard Loss 2.7754 (2.9119)	Arch Beta Loss 285.9116 (288.0631)	Arch depth Loss -0.0039 (-0.0034)	Prec@(1,5) (27.9%, 60.0%)	
11/27 03:49:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][195/195]	Step 1371	lr 0.02491	Loss 2.8399 (2.8051)	Arch Loss 3.2075 (3.1725)	Arch Hard Loss 2.9260 (2.8865)	Arch Beta Loss 281.5340 (285.9283)	Arch depth Loss -0.0051 (-0.0039)	Prec@(1,5) (28.4%, 60.3%)	
11/27 03:49:38午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  6/149] Final Prec@1 28.4160%
11/27 03:49:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/196]	Step 1372	Loss 2.8790	Prec@(1,5) (27.3%, 59.2%)
11/27 03:50:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][195/196]	Step 1372	Loss 2.8968	Prec@(1,5) (27.1%, 58.8%)
11/27 03:50:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 27.0400%
11/27 03:50:08午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 3])
11/27 03:50:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 27.0400%
11/27 03:51:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][100/195]	Step 1472	lr 0.02487	Loss 2.6056 (2.6644)	Arch Loss 3.1701 (3.0821)	Arch Hard Loss 2.8932 (2.8029)	Arch Beta Loss 276.9007 (279.1535)	Arch depth Loss -0.0109 (-0.0079)	Prec@(1,5) (30.8%, 63.2%)	
11/27 03:53:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][195/195]	Step 1567	lr 0.02487	Loss 2.5859 (2.6528)	Arch Loss 2.7640 (3.0428)	Arch Hard Loss 2.4910 (2.7657)	Arch Beta Loss 273.0071 (277.0771)	Arch depth Loss -0.0131 (-0.0097)	Prec@(1,5) (31.3%, 63.4%)	
11/27 03:53:22午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  7/149] Final Prec@1 31.2720%
11/27 03:53:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/196]	Step 1568	Loss 2.7296	Prec@(1,5) (31.1%, 62.5%)
11/27 03:53:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][195/196]	Step 1568	Loss 2.7430	Prec@(1,5) (30.5%, 62.2%)
11/27 03:53:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 30.5280%
11/27 03:53:52午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 03:53:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 30.5280%
11/27 03:55:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][100/195]	Step 1668	lr 0.02483	Loss 2.3687 (2.5449)	Arch Loss 3.0121 (2.9812)	Arch Hard Loss 2.7433 (2.7103)	Arch Beta Loss 268.7783 (270.8683)	Arch depth Loss -0.0178 (-0.0151)	Prec@(1,5) (33.7%, 66.3%)	
11/27 03:57:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][195/195]	Step 1763	lr 0.02483	Loss 2.5540 (2.5443)	Arch Loss 3.0975 (2.9421)	Arch Hard Loss 2.8324 (2.6731)	Arch Beta Loss 265.1288 (268.9562)	Arch depth Loss -0.0178 (-0.0166)	Prec@(1,5) (33.5%, 66.3%)	
11/27 03:57:06午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  8/149] Final Prec@1 33.5160%
11/27 03:57:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/196]	Step 1764	Loss 2.6869	Prec@(1,5) (31.5%, 63.1%)
11/27 03:57:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][195/196]	Step 1764	Loss 2.6935	Prec@(1,5) (31.0%, 62.9%)
11/27 03:57:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 31.0280%
11/27 03:57:36午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 03:57:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.0280%
11/27 03:59:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][100/195]	Step 1864	lr 0.02479	Loss 2.4782 (2.4197)	Arch Loss 2.8935 (2.8794)	Arch Hard Loss 2.6323 (2.6163)	Arch Beta Loss 261.1516 (263.1254)	Arch depth Loss -0.0229 (-0.0197)	Prec@(1,5) (35.8%, 69.5%)	
11/27 04:00:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][195/195]	Step 1959	lr 0.02479	Loss 2.2813 (2.4240)	Arch Loss 2.6522 (2.8447)	Arch Hard Loss 2.3945 (2.5834)	Arch Beta Loss 257.7399 (261.3167)	Arch depth Loss -0.0229 (-0.0213)	Prec@(1,5) (35.8%, 69.1%)	
11/27 04:00:50午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  9/149] Final Prec@1 35.7680%
11/27 04:01:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/196]	Step 1960	Loss 2.6941	Prec@(1,5) (30.8%, 63.3%)
11/27 04:01:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][195/196]	Step 1960	Loss 2.6839	Prec@(1,5) (31.1%, 63.6%)
11/27 04:01:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 31.0320%
11/27 04:01:21午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 04:01:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.0320%
11/27 04:03:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][100/195]	Step 2060	lr 0.02474	Loss 2.3884 (2.3027)	Arch Loss 2.7273 (2.8090)	Arch Hard Loss 2.4733 (2.5532)	Arch Beta Loss 254.0674 (255.8352)	Arch depth Loss -0.0266 (-0.0248)	Prec@(1,5) (38.7%, 71.5%)	
11/27 04:04:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][195/195]	Step 2155	lr 0.02474	Loss 2.4679 (2.3325)	Arch Loss 2.5177 (2.7748)	Arch Hard Loss 2.2670 (2.5206)	Arch Beta Loss 250.6724 (254.1517)	Arch depth Loss -0.0288 (-0.0264)	Prec@(1,5) (38.2%, 70.8%)	
11/27 04:04:34午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 10/149] Final Prec@1 38.2200%
11/27 04:04:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/196]	Step 2156	Loss 2.4774	Prec@(1,5) (36.0%, 68.2%)
11/27 04:05:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][195/196]	Step 2156	Loss 2.4993	Prec@(1,5) (35.6%, 67.7%)
11/27 04:05:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 35.5600%
11/27 04:05:05午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 04:05:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 35.5600%
11/27 04:06:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][100/195]	Step 2256	lr 0.02468	Loss 2.2765 (2.2226)	Arch Loss 2.7450 (2.6941)	Arch Hard Loss 2.4979 (2.4452)	Arch Beta Loss 247.0190 (248.8503)	Arch depth Loss -0.0323 (-0.0302)	Prec@(1,5) (40.5%, 73.6%)	
11/27 04:08:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][195/195]	Step 2351	lr 0.02468	Loss 2.2208 (2.2286)	Arch Loss 2.7739 (2.6888)	Arch Hard Loss 2.5301 (2.4416)	Arch Beta Loss 243.8730 (247.1675)	Arch depth Loss -0.0335 (-0.0316)	Prec@(1,5) (40.3%, 73.3%)	
11/27 04:08:18午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 11/149] Final Prec@1 40.3040%
11/27 04:08:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/196]	Step 2352	Loss 2.4579	Prec@(1,5) (36.5%, 68.6%)
11/27 04:08:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][195/196]	Step 2352	Loss 2.4607	Prec@(1,5) (36.1%, 68.2%)
11/27 04:08:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 36.1160%
11/27 04:08:49午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 04:08:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.1160%
11/27 04:10:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][100/195]	Step 2452	lr 0.02462	Loss 2.1799 (2.1222)	Arch Loss 2.9209 (2.6539)	Arch Hard Loss 2.6804 (2.4117)	Arch Beta Loss 240.5698 (242.2184)	Arch depth Loss -0.0374 (-0.0352)	Prec@(1,5) (42.5%, 75.1%)	
11/27 04:12:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][195/195]	Step 2547	lr 0.02462	Loss 2.0501 (2.1407)	Arch Loss 2.6088 (2.6232)	Arch Hard Loss 2.3713 (2.3825)	Arch Beta Loss 237.4911 (240.6620)	Arch depth Loss -0.0399 (-0.0367)	Prec@(1,5) (42.0%, 74.9%)	
11/27 04:12:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 12/149] Final Prec@1 42.0360%
11/27 04:12:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/196]	Step 2548	Loss 2.3985	Prec@(1,5) (37.7%, 69.8%)
11/27 04:12:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][195/196]	Step 2548	Loss 2.3861	Prec@(1,5) (37.8%, 70.2%)
11/27 04:12:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 37.8280%
11/27 04:12:33午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 04:12:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.8280%
11/27 04:14:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][100/195]	Step 2648	lr 0.02456	Loss 2.2425 (2.0503)	Arch Loss 2.6833 (2.5952)	Arch Hard Loss 2.4491 (2.3594)	Arch Beta Loss 234.2205 (235.7919)	Arch depth Loss -0.0436 (-0.0416)	Prec@(1,5) (43.9%, 76.7%)	
11/27 04:15:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][195/195]	Step 2743	lr 0.02456	Loss 2.1033 (2.0771)	Arch Loss 2.4382 (2.5673)	Arch Hard Loss 2.2069 (2.3330)	Arch Beta Loss 231.2812 (234.2918)	Arch depth Loss -0.0436 (-0.0427)	Prec@(1,5) (43.6%, 76.3%)	
11/27 04:15:47午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 13/149] Final Prec@1 43.5760%
11/27 04:16:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/196]	Step 2744	Loss 2.3882	Prec@(1,5) (37.9%, 69.7%)
11/27 04:16:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][195/196]	Step 2744	Loss 2.3929	Prec@(1,5) (38.1%, 69.8%)
11/27 04:16:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 38.1520%
11/27 04:16:17午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/27 04:16:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 38.1520%
11/27 04:17:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][100/195]	Step 2844	lr 0.02449	Loss 1.9780 (1.9906)	Arch Loss 2.7553 (2.5348)	Arch Hard Loss 2.5272 (2.3051)	Arch Beta Loss 228.1647 (229.7234)	Arch depth Loss -0.0459 (-0.0451)	Prec@(1,5) (45.8%, 78.0%)	
11/27 04:19:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][195/195]	Step 2939	lr 0.02449	Loss 2.2415 (2.0013)	Arch Loss 2.4981 (2.5209)	Arch Hard Loss 2.2726 (2.2926)	Arch Beta Loss 225.4225 (228.2667)	Arch depth Loss -0.0474 (-0.0460)	Prec@(1,5) (45.3%, 77.5%)	
11/27 04:19:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 14/149] Final Prec@1 45.2600%
11/27 04:19:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/196]	Step 2940	Loss 2.3310	Prec@(1,5) (39.4%, 71.2%)
11/27 04:20:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][195/196]	Step 2940	Loss 2.3242	Prec@(1,5) (39.5%, 71.2%)
11/27 04:20:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 39.4880%
11/27 04:20:01午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:20:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.4880%
11/27 04:21:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][100/195]	Step 3040	lr 0.02441	Loss 2.0428 (1.9174)	Arch Loss 2.6553 (2.4820)	Arch Hard Loss 2.4327 (2.2579)	Arch Beta Loss 222.6130 (224.0755)	Arch depth Loss -0.0491 (-0.0478)	Prec@(1,5) (46.8%, 79.5%)	
11/27 04:23:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][195/195]	Step 3135	lr 0.02441	Loss 1.8827 (1.9321)	Arch Loss 2.4493 (2.4726)	Arch Hard Loss 2.2294 (2.2500)	Arch Beta Loss 219.8897 (222.6774)	Arch depth Loss -0.0500 (-0.0484)	Prec@(1,5) (46.4%, 79.2%)	
11/27 04:23:15午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 15/149] Final Prec@1 46.3920%
11/27 04:23:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/196]	Step 3136	Loss 2.2367	Prec@(1,5) (41.2%, 73.6%)
11/27 04:23:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][195/196]	Step 3136	Loss 2.2507	Prec@(1,5) (41.0%, 73.1%)
11/27 04:23:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 40.9720%
11/27 04:23:46午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:23:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.9720%
11/27 04:25:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][100/195]	Step 3236	lr 0.02433	Loss 1.9095 (1.8734)	Arch Loss 2.4313 (2.4082)	Arch Hard Loss 2.2143 (2.1897)	Arch Beta Loss 216.9974 (218.4397)	Arch depth Loss -0.0497 (-0.0491)	Prec@(1,5) (47.4%, 80.7%)	
11/27 04:26:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][195/195]	Step 3331	lr 0.02433	Loss 1.8770 (1.8739)	Arch Loss 2.1790 (2.4089)	Arch Hard Loss 1.9645 (2.1917)	Arch Beta Loss 214.5308 (217.1276)	Arch depth Loss -0.0476 (-0.0491)	Prec@(1,5) (48.2%, 80.5%)	
11/27 04:26:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 16/149] Final Prec@1 48.1560%
11/27 04:27:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/196]	Step 3332	Loss 2.2497	Prec@(1,5) (41.0%, 73.2%)
11/27 04:27:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][195/196]	Step 3332	Loss 2.2327	Prec@(1,5) (41.4%, 73.2%)
11/27 04:27:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 41.4320%
11/27 04:27:29午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:27:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.4320%
11/27 04:29:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][100/195]	Step 3432	lr 0.02425	Loss 1.8777 (1.7742)	Arch Loss 2.5450 (2.3953)	Arch Hard Loss 2.3332 (2.1821)	Arch Beta Loss 211.8229 (213.1715)	Arch depth Loss -0.0488 (-0.0479)	Prec@(1,5) (50.8%, 81.9%)	
11/27 04:30:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][195/195]	Step 3527	lr 0.02425	Loss 1.7325 (1.8026)	Arch Loss 2.6508 (2.3810)	Arch Hard Loss 2.4415 (2.1691)	Arch Beta Loss 209.2768 (211.8409)	Arch depth Loss -0.0462 (-0.0480)	Prec@(1,5) (49.9%, 81.4%)	
11/27 04:30:44午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 17/149] Final Prec@1 49.8840%
11/27 04:30:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/196]	Step 3528	Loss 2.1611	Prec@(1,5) (42.9%, 74.2%)
11/27 04:31:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][195/196]	Step 3528	Loss 2.1780	Prec@(1,5) (42.4%, 74.0%)
11/27 04:31:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 42.3920%
11/27 04:31:14午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:31:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.3920%
11/27 04:32:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][100/195]	Step 3628	lr 0.02416	Loss 1.5075 (1.7313)	Arch Loss 2.3601 (2.3460)	Arch Hard Loss 2.1535 (2.1381)	Arch Beta Loss 206.6840 (207.9666)	Arch depth Loss -0.0455 (-0.0450)	Prec@(1,5) (51.5%, 82.8%)	
11/27 04:34:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][195/195]	Step 3723	lr 0.02416	Loss 1.6474 (1.7521)	Arch Loss 2.0609 (2.3370)	Arch Hard Loss 1.8566 (2.1303)	Arch Beta Loss 204.3197 (206.7570)	Arch depth Loss -0.0441 (-0.0450)	Prec@(1,5) (51.2%, 82.3%)	
11/27 04:34:27午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 18/149] Final Prec@1 51.2160%
11/27 04:34:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/196]	Step 3724	Loss 2.1571	Prec@(1,5) (43.3%, 75.0%)
11/27 04:34:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][195/196]	Step 3724	Loss 2.1482	Prec@(1,5) (43.2%, 74.9%)
11/27 04:34:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 43.2280%
11/27 04:34:58午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:34:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.2280%
11/27 04:36:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][100/195]	Step 3824	lr 0.02406	Loss 1.7570 (1.6774)	Arch Loss 2.1153 (2.3327)	Arch Hard Loss 1.9135 (2.1297)	Arch Beta Loss 201.8402 (202.9554)	Arch depth Loss -0.0414 (-0.0428)	Prec@(1,5) (52.7%, 83.6%)	
11/27 04:38:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][195/195]	Step 3919	lr 0.02406	Loss 1.9380 (1.7089)	Arch Loss 2.2527 (2.3233)	Arch Hard Loss 2.0531 (2.1214)	Arch Beta Loss 199.6046 (201.8586)	Arch depth Loss -0.0392 (-0.0417)	Prec@(1,5) (52.2%, 83.1%)	
11/27 04:38:12午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 19/149] Final Prec@1 52.1680%
11/27 04:38:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/196]	Step 3920	Loss 2.1434	Prec@(1,5) (43.0%, 75.1%)
11/27 04:38:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][195/196]	Step 3920	Loss 2.1529	Prec@(1,5) (43.0%, 75.0%)
11/27 04:38:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 42.9920%
11/27 04:38:42午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:38:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.2280%
11/27 04:40:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][100/195]	Step 4020	lr 0.02396	Loss 1.5636 (1.6493)	Arch Loss 2.1352 (2.2778)	Arch Hard Loss 1.9379 (2.0794)	Arch Beta Loss 197.2873 (198.4497)	Arch depth Loss -0.0355 (-0.0372)	Prec@(1,5) (53.4%, 84.2%)	
11/27 04:41:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][195/195]	Step 4115	lr 0.02396	Loss 1.6636 (1.6577)	Arch Loss 2.3528 (2.2743)	Arch Hard Loss 2.1578 (2.0770)	Arch Beta Loss 195.0286 (197.3162)	Arch depth Loss -0.0344 (-0.0363)	Prec@(1,5) (53.3%, 84.0%)	
11/27 04:41:56午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 20/149] Final Prec@1 53.3440%
11/27 04:42:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/196]	Step 4116	Loss 2.1143	Prec@(1,5) (44.4%, 75.8%)
11/27 04:42:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][195/196]	Step 4116	Loss 2.1389	Prec@(1,5) (44.0%, 75.5%)
11/27 04:42:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 44.0040%
11/27 04:42:27午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:42:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.0040%
11/27 04:44:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][100/195]	Step 4216	lr 0.02386	Loss 1.3899 (1.5720)	Arch Loss 2.5337 (2.2478)	Arch Hard Loss 2.3411 (2.0540)	Arch Beta Loss 192.5428 (193.8081)	Arch depth Loss -0.0322 (-0.0329)	Prec@(1,5) (55.6%, 85.6%)	
11/27 04:45:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][195/195]	Step 4311	lr 0.02386	Loss 1.6344 (1.6008)	Arch Loss 1.9919 (2.2471)	Arch Hard Loss 1.8015 (2.0545)	Arch Beta Loss 190.4491 (192.6501)	Arch depth Loss -0.0269 (-0.0315)	Prec@(1,5) (54.5%, 85.0%)	
11/27 04:45:41午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 21/149] Final Prec@1 54.5000%
11/27 04:45:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/196]	Step 4312	Loss 2.1350	Prec@(1,5) (44.3%, 75.4%)
11/27 04:46:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][195/196]	Step 4312	Loss 2.1358	Prec@(1,5) (44.2%, 75.5%)
11/27 04:46:11午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 44.2360%
11/27 04:46:11午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:46:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.2360%
11/27 04:47:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][100/195]	Step 4412	lr 0.02375	Loss 1.3900 (1.5223)	Arch Loss 2.3601 (2.2447)	Arch Hard Loss 2.1718 (2.0553)	Arch Beta Loss 188.3561 (189.3786)	Arch depth Loss -0.0217 (-0.0243)	Prec@(1,5) (56.8%, 86.3%)	
11/27 04:49:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][195/195]	Step 4507	lr 0.02375	Loss 1.5591 (1.5687)	Arch Loss 1.8999 (2.2321)	Arch Hard Loss 1.7137 (2.0438)	Arch Beta Loss 186.2689 (188.3447)	Arch depth Loss -0.0195 (-0.0223)	Prec@(1,5) (55.4%, 85.5%)	
11/27 04:49:25午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 22/149] Final Prec@1 55.4400%
11/27 04:49:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/196]	Step 4508	Loss 2.0713	Prec@(1,5) (45.4%, 76.5%)
11/27 04:49:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][195/196]	Step 4508	Loss 2.0526	Prec@(1,5) (45.9%, 76.9%)
11/27 04:49:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 45.8840%
11/27 04:49:55午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:49:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8840%
11/27 04:51:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][100/195]	Step 4608	lr 0.02363	Loss 1.8129 (1.4981)	Arch Loss 2.4280 (2.2026)	Arch Hard Loss 2.2441 (2.0175)	Arch Beta Loss 183.9584 (185.0919)	Arch depth Loss -0.0168 (-0.0181)	Prec@(1,5) (56.8%, 87.0%)	
11/27 04:53:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][195/195]	Step 4703	lr 0.02363	Loss 1.4242 (1.5174)	Arch Loss 2.5351 (2.1937)	Arch Hard Loss 2.3529 (2.0096)	Arch Beta Loss 182.1477 (184.0979)	Arch depth Loss -0.0134 (-0.0167)	Prec@(1,5) (56.5%, 86.5%)	
11/27 04:53:09午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 23/149] Final Prec@1 56.4880%
11/27 04:53:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/196]	Step 4704	Loss 2.0361	Prec@(1,5) (46.2%, 77.5%)
11/27 04:53:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][195/196]	Step 4704	Loss 2.0261	Prec@(1,5) (46.4%, 77.7%)
11/27 04:53:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 46.3680%
11/27 04:53:39午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/27 04:53:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.3680%
11/27 04:55:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][100/195]	Step 4804	lr 0.02352	Loss 1.4514 (1.4786)	Arch Loss 2.3990 (2.2248)	Arch Hard Loss 2.2188 (2.0437)	Arch Beta Loss 180.2039 (181.1271)	Arch depth Loss -0.0071 (-0.0101)	Prec@(1,5) (57.6%, 86.7%)	
11/27 04:56:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][195/195]	Step 4899	lr 0.02352	Loss 1.5685 (1.4948)	Arch Loss 1.5767 (2.1844)	Arch Hard Loss 1.3985 (2.0042)	Arch Beta Loss 178.2105 (180.1742)	Arch depth Loss -0.0026 (-0.0074)	Prec@(1,5) (57.2%, 86.6%)	
11/27 04:56:53午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 24/149] Final Prec@1 57.2480%
11/27 04:57:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/196]	Step 4900	Loss 2.0754	Prec@(1,5) (46.6%, 77.0%)
11/27 04:57:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][195/196]	Step 4900	Loss 2.0635	Prec@(1,5) (46.6%, 77.1%)
11/27 04:57:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 46.6120%
11/27 04:57:24午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 04:57:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.6120%
11/27 04:59:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][100/195]	Step 5000	lr 0.02339	Loss 1.4689 (1.3809)	Arch Loss 2.4195 (2.1764)	Arch Hard Loss 2.2431 (1.9991)	Arch Beta Loss 176.3142 (177.2510)	Arch depth Loss 0.0041 (0.0012)	Prec@(1,5) (60.2%, 88.6%)	
11/27 05:00:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][195/195]	Step 5095	lr 0.02339	Loss 1.4969 (1.4377)	Arch Loss 1.8961 (2.1684)	Arch Hard Loss 1.7218 (1.9921)	Arch Beta Loss 174.3302 (176.3251)	Arch depth Loss 0.0082 (0.0037)	Prec@(1,5) (58.7%, 87.6%)	
11/27 05:00:38午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 25/149] Final Prec@1 58.7320%
11/27 05:00:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/196]	Step 5096	Loss 2.0688	Prec@(1,5) (45.5%, 77.1%)
11/27 05:01:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][195/196]	Step 5096	Loss 2.0657	Prec@(1,5) (45.8%, 77.1%)
11/27 05:01:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 45.8400%
11/27 05:01:09午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:01:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.6120%
11/27 05:02:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][100/195]	Step 5196	lr 0.02326	Loss 1.1963 (1.3703)	Arch Loss 2.3653 (2.1470)	Arch Hard Loss 2.1928 (1.9735)	Arch Beta Loss 172.5021 (173.4560)	Arch depth Loss 0.0141 (0.0113)	Prec@(1,5) (60.6%, 88.8%)	
11/27 05:04:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][195/195]	Step 5291	lr 0.02326	Loss 1.4180 (1.4003)	Arch Loss 2.0779 (2.1369)	Arch Hard Loss 1.9071 (1.9643)	Arch Beta Loss 170.7911 (172.5687)	Arch depth Loss 0.0227 (0.0144)	Prec@(1,5) (59.7%, 88.3%)	
11/27 05:04:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 26/149] Final Prec@1 59.7320%
11/27 05:04:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/196]	Step 5292	Loss 2.0089	Prec@(1,5) (47.3%, 78.3%)
11/27 05:04:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][195/196]	Step 5292	Loss 2.0094	Prec@(1,5) (46.8%, 78.0%)
11/27 05:04:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 46.7880%
11/27 05:04:53午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:04:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.7880%
11/27 05:06:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][100/195]	Step 5392	lr 0.02313	Loss 1.2584 (1.3409)	Arch Loss 2.3390 (2.1581)	Arch Hard Loss 2.1703 (1.9884)	Arch Beta Loss 168.7154 (169.7590)	Arch depth Loss 0.0300 (0.0271)	Prec@(1,5) (61.1%, 89.3%)	
11/27 05:08:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][195/195]	Step 5487	lr 0.02313	Loss 1.5606 (1.3727)	Arch Loss 2.3250 (2.1296)	Arch Hard Loss 2.1577 (1.9607)	Arch Beta Loss 167.2460 (168.8953)	Arch depth Loss 0.0344 (0.0293)	Prec@(1,5) (60.4%, 88.6%)	
11/27 05:08:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 27/149] Final Prec@1 60.3520%
11/27 05:08:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/196]	Step 5488	Loss 2.0282	Prec@(1,5) (46.8%, 77.5%)
11/27 05:08:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][195/196]	Step 5488	Loss 2.0286	Prec@(1,5) (46.8%, 77.6%)
11/27 05:08:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 46.7640%
11/27 05:08:38午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:08:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.7880%
11/27 05:10:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][100/195]	Step 5588	lr 0.023	Loss 1.3992 (1.3018)	Arch Loss 2.3341 (2.1569)	Arch Hard Loss 2.1686 (1.9906)	Arch Beta Loss 165.4278 (166.2980)	Arch depth Loss 0.0408 (0.0375)	Prec@(1,5) (62.1%, 89.6%)	
11/27 05:11:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][195/195]	Step 5683	lr 0.023	Loss 1.4874 (1.3402)	Arch Loss 2.1703 (2.1168)	Arch Hard Loss 2.0064 (1.9512)	Arch Beta Loss 163.9226 (165.5234)	Arch depth Loss 0.0480 (0.0411)	Prec@(1,5) (61.2%, 89.1%)	
11/27 05:11:51午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 28/149] Final Prec@1 61.2400%
11/27 05:12:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/196]	Step 5684	Loss 1.9947	Prec@(1,5) (47.5%, 78.0%)
11/27 05:12:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][195/196]	Step 5684	Loss 1.9776	Prec@(1,5) (47.9%, 78.4%)
11/27 05:12:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 47.9280%
11/27 05:12:22午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:12:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.9280%
11/27 05:14:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][100/195]	Step 5784	lr 0.02285	Loss 1.3337 (1.2875)	Arch Loss 2.1661 (2.1024)	Arch Hard Loss 2.0037 (1.9393)	Arch Beta Loss 162.3289 (163.1134)	Arch depth Loss 0.0588 (0.0535)	Prec@(1,5) (62.5%, 90.0%)	
11/27 05:15:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][195/195]	Step 5879	lr 0.02285	Loss 1.3442 (1.3075)	Arch Loss 2.1983 (2.0896)	Arch Hard Loss 2.0376 (1.9273)	Arch Beta Loss 160.7585 (162.3505)	Arch depth Loss 0.0632 (0.0569)	Prec@(1,5) (62.0%, 89.6%)	
11/27 05:15:36午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 29/149] Final Prec@1 62.0360%
11/27 05:15:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/196]	Step 5880	Loss 1.9113	Prec@(1,5) (49.7%, 79.8%)
11/27 05:16:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][195/196]	Step 5880	Loss 1.9371	Prec@(1,5) (48.9%, 79.2%)
11/27 05:16:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 48.9160%
11/27 05:16:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:16:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.9160%
11/27 05:17:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][100/195]	Step 5980	lr 0.02271	Loss 1.2414 (1.2405)	Arch Loss 2.1217 (2.0966)	Arch Hard Loss 1.9625 (1.9366)	Arch Beta Loss 159.2020 (159.9076)	Arch depth Loss 0.0756 (0.0700)	Prec@(1,5) (63.9%, 90.8%)	
11/27 05:19:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][195/195]	Step 6075	lr 0.02271	Loss 1.3524 (1.2651)	Arch Loss 2.1245 (2.0892)	Arch Hard Loss 1.9669 (1.9300)	Arch Beta Loss 157.6291 (159.1957)	Arch depth Loss 0.0819 (0.0745)	Prec@(1,5) (63.4%, 90.2%)	
11/27 05:19:19午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 30/149] Final Prec@1 63.4320%
11/27 05:19:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/196]	Step 6076	Loss 1.9394	Prec@(1,5) (48.6%, 79.5%)
11/27 05:19:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][195/196]	Step 6076	Loss 1.9536	Prec@(1,5) (48.6%, 79.1%)
11/27 05:19:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 48.5960%
11/27 05:19:50午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:19:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.9160%
11/27 05:21:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][100/195]	Step 6176	lr 0.02256	Loss 1.1265 (1.2112)	Arch Loss 1.9579 (2.0825)	Arch Hard Loss 1.8019 (1.9257)	Arch Beta Loss 155.9498 (156.7880)	Arch depth Loss 0.0885 (0.0851)	Prec@(1,5) (64.7%, 91.2%)	
11/27 05:23:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][195/195]	Step 6271	lr 0.02256	Loss 1.2683 (1.2416)	Arch Loss 1.9822 (2.0815)	Arch Hard Loss 1.8277 (1.9256)	Arch Beta Loss 154.4757 (155.9847)	Arch depth Loss 0.0963 (0.0882)	Prec@(1,5) (63.5%, 90.7%)	
11/27 05:23:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 31/149] Final Prec@1 63.5280%
11/27 05:23:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/196]	Step 6272	Loss 2.0133	Prec@(1,5) (47.3%, 77.9%)
11/27 05:23:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][195/196]	Step 6272	Loss 2.0121	Prec@(1,5) (47.7%, 77.8%)
11/27 05:23:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 47.7440%
11/27 05:23:34午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 05:23:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.9160%
11/27 05:25:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][100/195]	Step 6372	lr 0.0224	Loss 1.3935 (1.1805)	Arch Loss 2.1018 (2.0663)	Arch Hard Loss 1.9488 (1.9125)	Arch Beta Loss 153.0340 (153.7694)	Arch depth Loss 0.1048 (0.1005)	Prec@(1,5) (65.7%, 91.4%)	
11/27 05:26:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][195/195]	Step 6467	lr 0.0224	Loss 1.4069 (1.2124)	Arch Loss 2.1828 (2.0512)	Arch Hard Loss 2.0311 (1.8981)	Arch Beta Loss 151.6455 (153.0616)	Arch depth Loss 0.1110 (0.1043)	Prec@(1,5) (64.7%, 90.8%)	
11/27 05:26:48午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 32/149] Final Prec@1 64.7120%
11/27 05:27:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/196]	Step 6468	Loss 1.9424	Prec@(1,5) (48.8%, 79.6%)
11/27 05:27:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][195/196]	Step 6468	Loss 1.9450	Prec@(1,5) (48.8%, 79.3%)
11/27 05:27:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 48.7680%
11/27 05:27:18午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:27:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.9160%
11/27 05:28:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][100/195]	Step 6568	lr 0.02225	Loss 1.0982 (1.1513)	Arch Loss 2.2584 (2.0502)	Arch Hard Loss 2.1081 (1.8993)	Arch Beta Loss 150.2338 (150.8692)	Arch depth Loss 0.1210 (0.1164)	Prec@(1,5) (66.1%, 92.0%)	
11/27 05:30:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][195/195]	Step 6663	lr 0.02225	Loss 1.1447 (1.1800)	Arch Loss 2.0947 (2.0575)	Arch Hard Loss 1.9459 (1.9073)	Arch Beta Loss 148.7965 (150.2128)	Arch depth Loss 0.1285 (0.1205)	Prec@(1,5) (65.4%, 91.5%)	
11/27 05:30:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 33/149] Final Prec@1 65.3520%
11/27 05:30:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/196]	Step 6664	Loss 1.9392	Prec@(1,5) (49.1%, 79.6%)
11/27 05:31:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][195/196]	Step 6664	Loss 1.9234	Prec@(1,5) (49.5%, 80.1%)
11/27 05:31:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 49.5000%
11/27 05:31:02午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:31:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.5000%
11/27 05:32:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][100/195]	Step 6764	lr 0.02208	Loss 1.1755 (1.1028)	Arch Loss 2.0146 (2.0395)	Arch Hard Loss 1.8671 (1.8913)	Arch Beta Loss 147.5405 (148.1329)	Arch depth Loss 0.1408 (0.1352)	Prec@(1,5) (67.3%, 92.3%)	
11/27 05:34:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][195/195]	Step 6859	lr 0.02208	Loss 1.1987 (1.1498)	Arch Loss 2.2709 (2.0412)	Arch Hard Loss 2.1245 (1.8936)	Arch Beta Loss 146.3731 (147.5648)	Arch depth Loss 0.1505 (0.1408)	Prec@(1,5) (66.0%, 91.9%)	
11/27 05:34:15午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 34/149] Final Prec@1 66.0440%
11/27 05:34:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/196]	Step 6860	Loss 2.0355	Prec@(1,5) (47.7%, 78.2%)
11/27 05:34:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][195/196]	Step 6860	Loss 2.0407	Prec@(1,5) (47.7%, 78.1%)
11/27 05:34:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 47.7160%
11/27 05:34:46午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:34:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.5000%
11/27 05:36:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][100/195]	Step 6960	lr 0.02192	Loss 1.1914 (1.0983)	Arch Loss 1.7698 (2.0352)	Arch Hard Loss 1.6248 (1.8895)	Arch Beta Loss 145.0127 (145.6666)	Arch depth Loss 0.1629 (0.1558)	Prec@(1,5) (67.2%, 92.5%)	
11/27 05:37:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][195/195]	Step 7055	lr 0.02192	Loss 1.1718 (1.1390)	Arch Loss 2.2694 (2.0379)	Arch Hard Loss 2.1256 (1.8928)	Arch Beta Loss 143.8063 (145.0478)	Arch depth Loss 0.1704 (0.1611)	Prec@(1,5) (66.3%, 92.0%)	
11/27 05:37:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 35/149] Final Prec@1 66.3120%
11/27 05:38:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/196]	Step 7056	Loss 1.9230	Prec@(1,5) (49.7%, 80.2%)
11/27 05:38:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][195/196]	Step 7056	Loss 1.9055	Prec@(1,5) (50.1%, 80.3%)
11/27 05:38:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 50.0760%
11/27 05:38:30午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:38:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.0760%
11/27 05:40:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][100/195]	Step 7156	lr 0.02175	Loss 1.1437 (1.0727)	Arch Loss 2.0718 (2.0426)	Arch Hard Loss 1.9292 (1.8994)	Arch Beta Loss 142.6671 (143.2351)	Arch depth Loss 0.1824 (0.1762)	Prec@(1,5) (68.4%, 92.5%)	
11/27 05:41:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][195/195]	Step 7251	lr 0.02175	Loss 1.3140 (1.0955)	Arch Loss 1.8968 (2.0310)	Arch Hard Loss 1.7554 (1.8884)	Arch Beta Loss 141.3353 (142.6298)	Arch depth Loss 0.1922 (0.1819)	Prec@(1,5) (67.9%, 92.4%)	
11/27 05:41:43午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 36/149] Final Prec@1 67.8560%
11/27 05:41:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/196]	Step 7252	Loss 1.9490	Prec@(1,5) (49.1%, 79.5%)
11/27 05:42:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][195/196]	Step 7252	Loss 1.9287	Prec@(1,5) (49.5%, 79.7%)
11/27 05:42:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 49.4720%
11/27 05:42:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:42:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.0760%
11/27 05:43:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][100/195]	Step 7352	lr 0.02157	Loss 1.0656 (1.0575)	Arch Loss 1.9988 (1.9926)	Arch Hard Loss 1.8587 (1.8519)	Arch Beta Loss 140.0985 (140.7124)	Arch depth Loss 0.2020 (0.1975)	Prec@(1,5) (68.7%, 93.2%)	
11/27 05:45:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][195/195]	Step 7447	lr 0.02157	Loss 1.3448 (1.0885)	Arch Loss 2.1865 (2.0198)	Arch Hard Loss 2.0473 (1.8796)	Arch Beta Loss 139.1395 (140.1772)	Arch depth Loss 0.2136 (0.2030)	Prec@(1,5) (68.0%, 92.5%)	
11/27 05:45:26午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 37/149] Final Prec@1 67.9760%
11/27 05:45:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/196]	Step 7448	Loss 1.9237	Prec@(1,5) (49.9%, 79.6%)
11/27 05:45:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][195/196]	Step 7448	Loss 1.9386	Prec@(1,5) (49.5%, 79.4%)
11/27 05:45:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 49.5320%
11/27 05:45:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:45:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.0760%
11/27 05:47:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][100/195]	Step 7548	lr 0.0214	Loss 1.1537 (1.0251)	Arch Loss 2.0664 (2.0061)	Arch Hard Loss 1.9285 (1.8676)	Arch Beta Loss 137.9080 (138.5156)	Arch depth Loss 0.2243 (0.2177)	Prec@(1,5) (69.6%, 93.5%)	
11/27 05:49:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][195/195]	Step 7643	lr 0.0214	Loss 1.0844 (1.0665)	Arch Loss 2.0031 (2.0023)	Arch Hard Loss 1.8662 (1.8643)	Arch Beta Loss 136.8356 (137.9393)	Arch depth Loss 0.2351 (0.2239)	Prec@(1,5) (68.5%, 92.9%)	
11/27 05:49:10午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 38/149] Final Prec@1 68.5160%
11/27 05:49:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/196]	Step 7644	Loss 1.9669	Prec@(1,5) (48.9%, 78.9%)
11/27 05:49:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][195/196]	Step 7644	Loss 1.9591	Prec@(1,5) (48.9%, 79.0%)
11/27 05:49:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 48.9040%
11/27 05:49:40午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:49:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.0760%
11/27 05:51:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][100/195]	Step 7744	lr 0.02121	Loss 1.0474 (1.0186)	Arch Loss 1.7377 (1.9709)	Arch Hard Loss 1.6021 (1.8347)	Arch Beta Loss 135.6304 (136.1986)	Arch depth Loss 0.2433 (0.2409)	Prec@(1,5) (69.9%, 93.5%)	
11/27 05:52:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][195/195]	Step 7839	lr 0.02121	Loss 0.9824 (1.0515)	Arch Loss 2.2309 (1.9980)	Arch Hard Loss 2.0963 (1.8623)	Arch Beta Loss 134.6762 (135.6835)	Arch depth Loss 0.2535 (0.2448)	Prec@(1,5) (68.9%, 93.2%)	
11/27 05:52:54午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 39/149] Final Prec@1 68.8480%
11/27 05:53:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/196]	Step 7840	Loss 1.8773	Prec@(1,5) (50.4%, 80.8%)
11/27 05:53:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][195/196]	Step 7840	Loss 1.8965	Prec@(1,5) (50.4%, 80.3%)
11/27 05:53:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 50.3840%
11/27 05:53:24午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:53:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.3840%
11/27 05:55:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][100/195]	Step 7940	lr 0.02103	Loss 1.1183 (0.9961)	Arch Loss 2.1949 (2.0045)	Arch Hard Loss 2.0614 (1.8705)	Arch Beta Loss 133.4886 (134.0349)	Arch depth Loss 0.2648 (0.2584)	Prec@(1,5) (70.5%, 93.9%)	
11/27 05:56:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][195/195]	Step 8035	lr 0.02103	Loss 0.9578 (1.0248)	Arch Loss 1.8072 (1.9946)	Arch Hard Loss 1.6746 (1.8611)	Arch Beta Loss 132.6583 (133.5601)	Arch depth Loss 0.2753 (0.2642)	Prec@(1,5) (69.8%, 93.4%)	
11/27 05:56:38午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 40/149] Final Prec@1 69.7920%
11/27 05:56:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/196]	Step 8036	Loss 1.9252	Prec@(1,5) (50.2%, 79.8%)
11/27 05:57:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][195/196]	Step 8036	Loss 1.9091	Prec@(1,5) (50.5%, 80.1%)
11/27 05:57:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 50.4840%
11/27 05:57:08午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 05:57:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4840%
11/27 05:58:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][100/195]	Step 8136	lr 0.02084	Loss 1.1219 (0.9683)	Arch Loss 2.2868 (1.9987)	Arch Hard Loss 2.1551 (1.8666)	Arch Beta Loss 131.7243 (132.1666)	Arch depth Loss 0.2844 (0.2799)	Prec@(1,5) (71.6%, 94.1%)	
11/27 06:00:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][195/195]	Step 8231	lr 0.02084	Loss 1.0659 (1.0041)	Arch Loss 1.9988 (1.9979)	Arch Hard Loss 1.8680 (1.8662)	Arch Beta Loss 130.7689 (131.7199)	Arch depth Loss 0.2953 (0.2849)	Prec@(1,5) (70.3%, 93.7%)	
11/27 06:00:22午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 41/149] Final Prec@1 70.2640%
11/27 06:00:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/196]	Step 8232	Loss 1.9476	Prec@(1,5) (49.4%, 79.5%)
11/27 06:00:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][195/196]	Step 8232	Loss 1.9531	Prec@(1,5) (49.3%, 79.5%)
11/27 06:00:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 49.2520%
11/27 06:00:52午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 06:00:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4840%
11/27 06:02:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][100/195]	Step 8332	lr 0.02065	Loss 1.0731 (0.9759)	Arch Loss 1.9856 (1.9853)	Arch Hard Loss 1.8558 (1.8551)	Arch Beta Loss 129.7740 (130.2541)	Arch depth Loss 0.3037 (0.2992)	Prec@(1,5) (71.4%, 94.1%)	
11/27 06:04:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][195/195]	Step 8427	lr 0.02065	Loss 0.8213 (0.9965)	Arch Loss 2.1186 (1.9835)	Arch Hard Loss 1.9897 (1.8537)	Arch Beta Loss 128.9716 (129.8141)	Arch depth Loss 0.3112 (0.3029)	Prec@(1,5) (70.7%, 93.9%)	
11/27 06:04:05午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 42/149] Final Prec@1 70.6640%
11/27 06:04:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/196]	Step 8428	Loss 1.9017	Prec@(1,5) (50.5%, 80.5%)
11/27 06:04:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][195/196]	Step 8428	Loss 1.8861	Prec@(1,5) (50.9%, 80.5%)
11/27 06:04:35午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 50.8960%
11/27 06:04:35午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 06:04:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8960%
11/27 06:06:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][100/195]	Step 8528	lr 0.02045	Loss 1.1594 (0.9484)	Arch Loss 2.1319 (1.9857)	Arch Hard Loss 2.0038 (1.8572)	Arch Beta Loss 128.0827 (128.4900)	Arch depth Loss 0.3218 (0.3172)	Prec@(1,5) (72.4%, 94.4%)	
11/27 06:07:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][195/195]	Step 8623	lr 0.02045	Loss 0.8084 (0.9666)	Arch Loss 2.0791 (1.9859)	Arch Hard Loss 1.9518 (1.8578)	Arch Beta Loss 127.2836 (128.0909)	Arch depth Loss 0.3282 (0.3213)	Prec@(1,5) (71.7%, 94.2%)	
11/27 06:07:48午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 43/149] Final Prec@1 71.6760%
11/27 06:08:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/196]	Step 8624	Loss 1.8774	Prec@(1,5) (51.2%, 80.8%)
11/27 06:08:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][195/196]	Step 8624	Loss 1.8748	Prec@(1,5) (51.2%, 80.8%)
11/27 06:08:19午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 51.1640%
11/27 06:08:19午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/27 06:08:19午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1640%
11/27 06:09:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][100/195]	Step 8724	lr 0.02026	Loss 0.8327 (0.9069)	Arch Loss 1.8346 (1.9929)	Arch Hard Loss 1.7081 (1.8660)	Arch Beta Loss 126.5111 (126.8875)	Arch depth Loss 0.3397 (0.3344)	Prec@(1,5) (73.0%, 95.1%)	
11/27 06:11:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][195/195]	Step 8819	lr 0.02026	Loss 1.1702 (0.9395)	Arch Loss 2.2945 (1.9868)	Arch Hard Loss 2.1689 (1.8604)	Arch Beta Loss 125.5248 (126.4551)	Arch depth Loss 0.3476 (0.3388)	Prec@(1,5) (72.1%, 94.6%)	
11/27 06:11:32午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 44/149] Final Prec@1 72.0720%
11/27 06:11:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/196]	Step 8820	Loss 1.9232	Prec@(1,5) (50.6%, 80.0%)
11/27 06:12:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][195/196]	Step 8820	Loss 1.9137	Prec@(1,5) (50.8%, 80.2%)
11/27 06:12:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 50.8520%
11/27 06:12:03午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 06:12:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1640%
11/27 06:13:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][100/195]	Step 8920	lr 0.02005	Loss 0.8828 (0.9038)	Arch Loss 1.5731 (1.9665)	Arch Hard Loss 1.4483 (1.8414)	Arch Beta Loss 124.7854 (125.1371)	Arch depth Loss 0.3600 (0.3526)	Prec@(1,5) (73.2%, 95.2%)	
11/27 06:15:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][195/195]	Step 9015	lr 0.02005	Loss 1.0338 (0.9355)	Arch Loss 2.2457 (1.9720)	Arch Hard Loss 2.1216 (1.8472)	Arch Beta Loss 124.0988 (124.7856)	Arch depth Loss 0.3683 (0.3587)	Prec@(1,5) (72.4%, 94.6%)	
11/27 06:15:16午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 45/149] Final Prec@1 72.3520%
11/27 06:15:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/196]	Step 9016	Loss 1.9228	Prec@(1,5) (50.5%, 80.4%)
11/27 06:15:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][195/196]	Step 9016	Loss 1.9209	Prec@(1,5) (50.6%, 80.3%)
11/27 06:15:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 50.5880%
11/27 06:15:46午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 06:15:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1640%
11/27 06:17:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][100/195]	Step 9116	lr 0.01985	Loss 1.0684 (0.8767)	Arch Loss 1.9306 (1.9549)	Arch Hard Loss 1.8073 (1.8312)	Arch Beta Loss 123.3226 (123.7637)	Arch depth Loss 0.3789 (0.3733)	Prec@(1,5) (73.7%, 95.3%)	
11/27 06:18:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][195/195]	Step 9211	lr 0.01985	Loss 1.0077 (0.9183)	Arch Loss 2.0132 (1.9817)	Arch Hard Loss 1.8906 (1.8583)	Arch Beta Loss 122.6257 (123.3800)	Arch depth Loss 0.3880 (0.3783)	Prec@(1,5) (72.8%, 94.8%)	
11/27 06:18:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 46/149] Final Prec@1 72.7640%
11/27 06:19:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/196]	Step 9212	Loss 1.9310	Prec@(1,5) (50.1%, 80.6%)
11/27 06:19:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][195/196]	Step 9212	Loss 1.9139	Prec@(1,5) (50.6%, 80.7%)
11/27 06:19:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 50.5880%
11/27 06:19:30午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 06:19:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1640%
11/27 06:21:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][100/195]	Step 9312	lr 0.01964	Loss 0.8463 (0.8645)	Arch Loss 1.7099 (1.9594)	Arch Hard Loss 1.5879 (1.8371)	Arch Beta Loss 121.9787 (122.2965)	Arch depth Loss 0.3972 (0.3924)	Prec@(1,5) (74.6%, 95.3%)	
11/27 06:22:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][195/195]	Step 9407	lr 0.01964	Loss 0.9849 (0.8895)	Arch Loss 2.0066 (1.9616)	Arch Hard Loss 1.8853 (1.8396)	Arch Beta Loss 121.3287 (121.9886)	Arch depth Loss 0.4059 (0.3970)	Prec@(1,5) (73.8%, 95.0%)	
11/27 06:22:43午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 47/149] Final Prec@1 73.7480%
11/27 06:22:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/196]	Step 9408	Loss 1.8903	Prec@(1,5) (50.9%, 81.3%)
11/27 06:23:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][195/196]	Step 9408	Loss 1.8814	Prec@(1,5) (51.6%, 81.1%)
11/27 06:23:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 51.5840%
11/27 06:23:14午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 06:23:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5840%
11/27 06:24:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][100/195]	Step 9508	lr 0.01943	Loss 0.9251 (0.8572)	Arch Loss 2.0329 (1.9670)	Arch Hard Loss 1.9125 (1.8461)	Arch Beta Loss 120.4622 (120.8280)	Arch depth Loss 0.4164 (0.4111)	Prec@(1,5) (74.4%, 95.5%)	
11/27 06:26:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][195/195]	Step 9603	lr 0.01943	Loss 1.1703 (0.8942)	Arch Loss 1.9174 (1.9845)	Arch Hard Loss 1.7977 (1.8640)	Arch Beta Loss 119.7309 (120.4605)	Arch depth Loss 0.4244 (0.4160)	Prec@(1,5) (73.2%, 95.1%)	
11/27 06:26:28午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 48/149] Final Prec@1 73.2480%
11/27 06:26:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/196]	Step 9604	Loss 1.8438	Prec@(1,5) (52.4%, 81.7%)
11/27 06:26:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][195/196]	Step 9604	Loss 1.8399	Prec@(1,5) (52.6%, 81.6%)
11/27 06:26:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 52.6080%
11/27 06:26:58午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 06:26:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:28:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][100/195]	Step 9704	lr 0.01922	Loss 0.7718 (0.8402)	Arch Loss 2.2449 (1.9396)	Arch Hard Loss 2.1258 (1.8203)	Arch Beta Loss 119.1520 (119.3818)	Arch depth Loss 0.4329 (0.4284)	Prec@(1,5) (75.0%, 95.7%)	
11/27 06:30:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][195/195]	Step 9799	lr 0.01922	Loss 1.0178 (0.8720)	Arch Loss 1.8912 (1.9593)	Arch Hard Loss 1.7728 (1.8402)	Arch Beta Loss 118.4020 (119.0846)	Arch depth Loss 0.4431 (0.4331)	Prec@(1,5) (74.1%, 95.4%)	
11/27 06:30:12午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 49/149] Final Prec@1 74.0520%
11/27 06:30:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/196]	Step 9800	Loss 1.8617	Prec@(1,5) (52.0%, 81.1%)
11/27 06:30:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][195/196]	Step 9800	Loss 1.8570	Prec@(1,5) (52.2%, 81.4%)
11/27 06:30:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 52.2200%
11/27 06:30:42午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/27 06:30:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:30:43午前 searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
11/27 06:30:43午前 searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
11/27 06:31:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][100/351]	Step 9900	lr 0.025	Loss 1.8679 (2.7322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.4%)	
11/27 06:32:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][200/351]	Step 10000	lr 0.025	Loss 2.3441 (2.4644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.0%, 68.7%)	
11/27 06:32:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][300/351]	Step 10100	lr 0.025	Loss 2.1109 (2.3378)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.3%)	
11/27 06:33:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][351/351]	Step 10151	lr 0.025	Loss 2.0963 (2.2930)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 72.2%)	
11/27 06:33:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 50/149] Final Prec@1 39.5800%
11/27 06:33:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][39/40]	Step 10152	Loss 2.4713	Prec@(1,5) (36.8%, 69.4%)
11/27 06:33:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 36.7800%
11/27 06:33:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:33:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][100/351]	Step 10252	lr 0.02499	Loss 1.9373 (1.9176)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.2%)	
11/27 06:34:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][200/351]	Step 10352	lr 0.02499	Loss 1.8432 (1.9123)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.5%)	
11/27 06:35:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][300/351]	Step 10452	lr 0.02499	Loss 1.8968 (1.9022)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.5%)	
11/27 06:35:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][351/351]	Step 10503	lr 0.02499	Loss 2.1855 (1.8994)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 79.6%)	
11/27 06:35:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 51/149] Final Prec@1 48.2089%
11/27 06:35:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][39/40]	Step 10504	Loss 2.2063	Prec@(1,5) (42.4%, 73.9%)
11/27 06:35:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 42.4200%
11/27 06:35:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:36:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][100/351]	Step 10604	lr 0.02498	Loss 1.6085 (1.7795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.0%)	
11/27 06:37:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][200/351]	Step 10704	lr 0.02498	Loss 1.7588 (1.7813)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.0%)	
11/27 06:37:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][300/351]	Step 10804	lr 0.02498	Loss 1.8277 (1.7765)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.9%)	
11/27 06:38:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][351/351]	Step 10855	lr 0.02498	Loss 1.8852 (1.7726)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.0%)	
11/27 06:38:04午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 52/149] Final Prec@1 51.0800%
11/27 06:38:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][39/40]	Step 10856	Loss 2.0071	Prec@(1,5) (45.9%, 77.7%)
11/27 06:38:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 45.8800%
11/27 06:38:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:38:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][100/351]	Step 10956	lr 0.02495	Loss 1.7244 (1.6640)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 83.7%)	
11/27 06:39:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][200/351]	Step 11056	lr 0.02495	Loss 1.4392 (1.6651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.7%)	
11/27 06:40:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][300/351]	Step 11156	lr 0.02495	Loss 1.9961 (1.6846)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.4%)	
11/27 06:40:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][351/351]	Step 11207	lr 0.02495	Loss 1.9252 (1.6855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.4%)	
11/27 06:40:32午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 53/149] Final Prec@1 53.1333%
11/27 06:40:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][39/40]	Step 11208	Loss 1.9498	Prec@(1,5) (47.6%, 79.3%)
11/27 06:40:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 47.5800%
11/27 06:40:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:41:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][100/351]	Step 11308	lr 0.02491	Loss 1.6265 (1.6182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.9%, 84.4%)	
11/27 06:41:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][200/351]	Step 11408	lr 0.02491	Loss 1.5505 (1.6278)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.3%)	
11/27 06:42:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][300/351]	Step 11508	lr 0.02491	Loss 1.5572 (1.6346)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.2%)	
11/27 06:43:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][351/351]	Step 11559	lr 0.02491	Loss 1.8919 (1.6294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.3%)	
11/27 06:43:00午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 54/149] Final Prec@1 54.6911%
11/27 06:43:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][39/40]	Step 11560	Loss 2.0215	Prec@(1,5) (46.7%, 77.7%)
11/27 06:43:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 46.6600%
11/27 06:43:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:43:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][100/351]	Step 11660	lr 0.02485	Loss 1.4908 (1.5814)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.0%)	
11/27 06:44:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][200/351]	Step 11760	lr 0.02485	Loss 1.4679 (1.5747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.2%, 85.0%)	
11/27 06:45:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][300/351]	Step 11860	lr 0.02485	Loss 1.6045 (1.5733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.0%)	
11/27 06:45:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][351/351]	Step 11911	lr 0.02485	Loss 1.6733 (1.5799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.8%, 84.9%)	
11/27 06:45:28午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 55/149] Final Prec@1 55.8556%
11/27 06:45:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][39/40]	Step 11912	Loss 1.9659	Prec@(1,5) (47.2%, 78.6%)
11/27 06:45:35午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 47.2400%
11/27 06:45:35午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:46:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][100/351]	Step 12012	lr 0.02479	Loss 1.7174 (1.5042)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.2%)	
11/27 06:46:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][200/351]	Step 12112	lr 0.02479	Loss 1.5235 (1.5190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.0%)	
11/27 06:47:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][300/351]	Step 12212	lr 0.02479	Loss 1.6517 (1.5327)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.8%)	
11/27 06:47:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][351/351]	Step 12263	lr 0.02479	Loss 1.3543 (1.5388)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.6%)	
11/27 06:47:57午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 56/149] Final Prec@1 56.9000%
11/27 06:48:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][39/40]	Step 12264	Loss 1.7870	Prec@(1,5) (51.5%, 81.5%)
11/27 06:48:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 51.4800%
11/27 06:48:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:48:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][100/351]	Step 12364	lr 0.02471	Loss 1.4622 (1.4713)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.1%)	
11/27 06:49:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][200/351]	Step 12464	lr 0.02471	Loss 1.3702 (1.4710)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.1%)	
11/27 06:50:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][300/351]	Step 12564	lr 0.02471	Loss 1.6172 (1.4878)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.7%)	
11/27 06:50:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][351/351]	Step 12615	lr 0.02471	Loss 1.4810 (1.4930)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.6%)	
11/27 06:50:25午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 57/149] Final Prec@1 57.9511%
11/27 06:50:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][39/40]	Step 12616	Loss 1.9947	Prec@(1,5) (47.9%, 78.0%)
11/27 06:50:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 47.9400%
11/27 06:50:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:51:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][100/351]	Step 12716	lr 0.02462	Loss 1.6343 (1.4189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.4%)	
11/27 06:51:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][200/351]	Step 12816	lr 0.02462	Loss 1.6232 (1.4581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 86.7%)	
11/27 06:52:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][300/351]	Step 12916	lr 0.02462	Loss 1.5462 (1.4628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 86.8%)	
11/27 06:52:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][351/351]	Step 12967	lr 0.02462	Loss 1.5140 (1.4621)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 86.9%)	
11/27 06:52:53午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 58/149] Final Prec@1 58.5311%
11/27 06:53:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][39/40]	Step 12968	Loss 1.8636	Prec@(1,5) (50.3%, 81.4%)
11/27 06:53:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 50.3400%
11/27 06:53:00午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:53:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][100/351]	Step 13068	lr 0.02452	Loss 1.3076 (1.4292)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.5%)	
11/27 06:54:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][200/351]	Step 13168	lr 0.02452	Loss 1.4897 (1.4263)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.5%)	
11/27 06:55:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][300/351]	Step 13268	lr 0.02452	Loss 1.5495 (1.4326)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.4%)	
11/27 06:55:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][351/351]	Step 13319	lr 0.02452	Loss 1.5089 (1.4362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.3%)	
11/27 06:55:21午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 59/149] Final Prec@1 59.3289%
11/27 06:55:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][39/40]	Step 13320	Loss 1.8202	Prec@(1,5) (50.9%, 81.2%)
11/27 06:55:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 50.8400%
11/27 06:55:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:56:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][100/351]	Step 13420	lr 0.02441	Loss 1.3108 (1.3805)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.2%)	
11/27 06:56:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][200/351]	Step 13520	lr 0.02441	Loss 1.2505 (1.3870)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.2%)	
11/27 06:57:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][300/351]	Step 13620	lr 0.02441	Loss 1.5639 (1.3999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.9%)	
11/27 06:57:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][351/351]	Step 13671	lr 0.02441	Loss 1.6301 (1.4064)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.7%)	
11/27 06:57:50午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 60/149] Final Prec@1 60.1178%
11/27 06:57:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][39/40]	Step 13672	Loss 1.9198	Prec@(1,5) (49.2%, 80.4%)
11/27 06:57:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 49.1600%
11/27 06:57:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 06:58:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][100/351]	Step 13772	lr 0.02429	Loss 1.2968 (1.3490)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.6%)	
11/27 06:59:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][200/351]	Step 13872	lr 0.02429	Loss 1.2885 (1.3706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.0%)	
11/27 06:59:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][300/351]	Step 13972	lr 0.02429	Loss 1.5175 (1.3768)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.0%)	
11/27 07:00:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][351/351]	Step 14023	lr 0.02429	Loss 1.4997 (1.3799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.1%)	
11/27 07:00:18午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 61/149] Final Prec@1 60.6867%
11/27 07:00:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][39/40]	Step 14024	Loss 1.7676	Prec@(1,5) (51.7%, 82.6%)
11/27 07:00:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 51.7000%
11/27 07:00:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6080%
11/27 07:01:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][100/351]	Step 14124	lr 0.02416	Loss 1.2348 (1.3318)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.1%)	
11/27 07:01:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][200/351]	Step 14224	lr 0.02416	Loss 1.5368 (1.3431)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.1%)	
11/27 07:02:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][300/351]	Step 14324	lr 0.02416	Loss 1.2844 (1.3513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.7%)	
11/27 07:02:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][351/351]	Step 14375	lr 0.02416	Loss 1.4420 (1.3513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.8%)	
11/27 07:02:46午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 62/149] Final Prec@1 61.5311%
11/27 07:02:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][39/40]	Step 14376	Loss 1.6803	Prec@(1,5) (54.0%, 83.9%)
11/27 07:02:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 53.9600%
11/27 07:02:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9600%
11/27 07:03:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][100/351]	Step 14476	lr 0.02401	Loss 1.1529 (1.2997)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.5%)	
11/27 07:04:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][200/351]	Step 14576	lr 0.02401	Loss 1.3011 (1.3108)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.3%)	
11/27 07:04:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][300/351]	Step 14676	lr 0.02401	Loss 1.2852 (1.3244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.1%)	
11/27 07:05:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][351/351]	Step 14727	lr 0.02401	Loss 1.4617 (1.3276)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.0%)	
11/27 07:05:15午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 63/149] Final Prec@1 61.9756%
11/27 07:05:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][39/40]	Step 14728	Loss 1.7415	Prec@(1,5) (52.2%, 82.7%)
11/27 07:05:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 52.2200%
11/27 07:05:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9600%
11/27 07:06:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][100/351]	Step 14828	lr 0.02386	Loss 1.1895 (1.2702)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.9%)	
11/27 07:06:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][200/351]	Step 14928	lr 0.02386	Loss 1.4416 (1.2947)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.5%)	
11/27 07:07:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][300/351]	Step 15028	lr 0.02386	Loss 1.3167 (1.3048)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.3%)	
11/27 07:07:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][351/351]	Step 15079	lr 0.02386	Loss 1.2924 (1.3074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.2%)	
11/27 07:07:43午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 64/149] Final Prec@1 62.5800%
11/27 07:07:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][39/40]	Step 15080	Loss 1.6791	Prec@(1,5) (54.6%, 83.8%)
11/27 07:07:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 54.6000%
11/27 07:07:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6000%
11/27 07:08:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][100/351]	Step 15180	lr 0.02369	Loss 1.1897 (1.2427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.3%)	
11/27 07:09:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][200/351]	Step 15280	lr 0.02369	Loss 1.3540 (1.2711)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.7%)	
11/27 07:09:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][300/351]	Step 15380	lr 0.02369	Loss 1.3353 (1.2775)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.6%)	
11/27 07:10:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][351/351]	Step 15431	lr 0.02369	Loss 1.2970 (1.2862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.4%)	
11/27 07:10:12午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 65/149] Final Prec@1 63.1133%
11/27 07:10:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][39/40]	Step 15432	Loss 1.7620	Prec@(1,5) (52.4%, 82.4%)
11/27 07:10:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 52.4400%
11/27 07:10:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6000%
11/27 07:10:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][100/351]	Step 15532	lr 0.02352	Loss 1.3926 (1.2356)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.0%)	
11/27 07:11:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][200/351]	Step 15632	lr 0.02352	Loss 1.1949 (1.2460)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.0%)	
11/27 07:12:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][300/351]	Step 15732	lr 0.02352	Loss 1.4293 (1.2662)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 89.7%)	
11/27 07:12:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][351/351]	Step 15783	lr 0.02352	Loss 1.3794 (1.2772)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.6%)	
11/27 07:12:40午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 66/149] Final Prec@1 63.2800%
11/27 07:12:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][39/40]	Step 15784	Loss 1.7015	Prec@(1,5) (54.0%, 83.9%)
11/27 07:12:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 53.9600%
11/27 07:12:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6000%
11/27 07:13:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][100/351]	Step 15884	lr 0.02333	Loss 1.2918 (1.2196)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.3%)	
11/27 07:14:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][200/351]	Step 15984	lr 0.02333	Loss 1.3730 (1.2335)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.3%)	
11/27 07:14:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][300/351]	Step 16084	lr 0.02333	Loss 1.1826 (1.2525)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.0%)	
11/27 07:15:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][351/351]	Step 16135	lr 0.02333	Loss 1.2800 (1.2523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.0%)	
11/27 07:15:08午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 67/149] Final Prec@1 63.8022%
11/27 07:15:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][39/40]	Step 16136	Loss 1.6208	Prec@(1,5) (55.8%, 84.5%)
11/27 07:15:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 55.8000%
11/27 07:15:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:15:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][100/351]	Step 16236	lr 0.02313	Loss 1.0266 (1.1908)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.1%)	
11/27 07:16:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][200/351]	Step 16336	lr 0.02313	Loss 1.2003 (1.2097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.5%)	
11/27 07:17:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][300/351]	Step 16436	lr 0.02313	Loss 1.2263 (1.2213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
11/27 07:17:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][351/351]	Step 16487	lr 0.02313	Loss 1.2228 (1.2276)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.3%)	
11/27 07:17:37午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 68/149] Final Prec@1 64.4444%
11/27 07:17:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][39/40]	Step 16488	Loss 1.8450	Prec@(1,5) (51.8%, 81.6%)
11/27 07:17:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 51.7800%
11/27 07:17:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:18:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][100/351]	Step 16588	lr 0.02292	Loss 1.0903 (1.1573)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.1%)	
11/27 07:19:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][200/351]	Step 16688	lr 0.02292	Loss 1.2232 (1.1867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 90.7%)	
11/27 07:19:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][300/351]	Step 16788	lr 0.02292	Loss 1.3192 (1.2065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.5%)	
11/27 07:20:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][351/351]	Step 16839	lr 0.02292	Loss 1.5069 (1.2112)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.4%)	
11/27 07:20:05午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 69/149] Final Prec@1 65.0511%
11/27 07:20:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][39/40]	Step 16840	Loss 1.7142	Prec@(1,5) (53.1%, 83.6%)
11/27 07:20:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 53.1600%
11/27 07:20:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:20:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][100/351]	Step 16940	lr 0.02271	Loss 1.2277 (1.1401)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.5%)	
11/27 07:21:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][200/351]	Step 17040	lr 0.02271	Loss 1.2023 (1.1642)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.2%)	
11/27 07:22:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][300/351]	Step 17140	lr 0.02271	Loss 1.2438 (1.1835)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 90.9%)	
11/27 07:22:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][351/351]	Step 17191	lr 0.02271	Loss 1.3248 (1.1909)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.8%)	
11/27 07:22:33午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 70/149] Final Prec@1 65.4422%
11/27 07:22:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][39/40]	Step 17192	Loss 1.7351	Prec@(1,5) (53.8%, 84.1%)
11/27 07:22:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 53.7800%
11/27 07:22:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:23:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][100/351]	Step 17292	lr 0.02248	Loss 1.2185 (1.1453)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.4%)	
11/27 07:24:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][200/351]	Step 17392	lr 0.02248	Loss 0.9686 (1.1640)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.1%)	
11/27 07:24:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][300/351]	Step 17492	lr 0.02248	Loss 1.1613 (1.1743)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.0%)	
11/27 07:25:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][351/351]	Step 17543	lr 0.02248	Loss 1.1393 (1.1731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.0%)	
11/27 07:25:02午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 71/149] Final Prec@1 65.8689%
11/27 07:25:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][39/40]	Step 17544	Loss 1.7067	Prec@(1,5) (53.5%, 83.5%)
11/27 07:25:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 53.4200%
11/27 07:25:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:25:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][100/351]	Step 17644	lr 0.02225	Loss 1.2638 (1.1252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.5%)	
11/27 07:26:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][200/351]	Step 17744	lr 0.02225	Loss 1.2452 (1.1465)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.4%)	
11/27 07:27:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][300/351]	Step 17844	lr 0.02225	Loss 1.3234 (1.1607)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.2%)	
11/27 07:27:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][351/351]	Step 17895	lr 0.02225	Loss 0.9964 (1.1609)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.2%)	
11/27 07:27:30午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 72/149] Final Prec@1 66.3533%
11/27 07:27:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][39/40]	Step 17896	Loss 1.6649	Prec@(1,5) (55.1%, 84.1%)
11/27 07:27:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 55.1000%
11/27 07:27:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:28:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][100/351]	Step 17996	lr 0.022	Loss 1.1390 (1.1057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 92.0%)	
11/27 07:28:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][200/351]	Step 18096	lr 0.022	Loss 1.2622 (1.1296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.7%)	
11/27 07:29:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][300/351]	Step 18196	lr 0.022	Loss 1.0954 (1.1449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.5%)	
11/27 07:29:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][351/351]	Step 18247	lr 0.022	Loss 1.1106 (1.1455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.5%)	
11/27 07:29:58午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 73/149] Final Prec@1 66.5133%
11/27 07:30:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][39/40]	Step 18248	Loss 1.7101	Prec@(1,5) (53.6%, 83.7%)
11/27 07:30:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 53.6600%
11/27 07:30:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:30:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][100/351]	Step 18348	lr 0.02175	Loss 1.1846 (1.0900)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 91.8%)	
11/27 07:31:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][200/351]	Step 18448	lr 0.02175	Loss 0.9108 (1.1149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.7%)	
11/27 07:32:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][300/351]	Step 18548	lr 0.02175	Loss 0.8952 (1.1209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.6%)	
11/27 07:32:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][351/351]	Step 18599	lr 0.02175	Loss 1.0657 (1.1290)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.6%)	
11/27 07:32:26午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 74/149] Final Prec@1 67.1400%
11/27 07:32:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][39/40]	Step 18600	Loss 1.6871	Prec@(1,5) (55.2%, 84.0%)
11/27 07:32:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 55.2600%
11/27 07:32:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:33:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][100/351]	Step 18700	lr 0.02149	Loss 1.1897 (1.0794)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.4%)	
11/27 07:33:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][200/351]	Step 18800	lr 0.02149	Loss 1.1076 (1.0928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.3%)	
11/27 07:34:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][300/351]	Step 18900	lr 0.02149	Loss 1.2424 (1.1138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.9%)	
11/27 07:34:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][351/351]	Step 18951	lr 0.02149	Loss 1.2669 (1.1197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
11/27 07:34:55午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 75/149] Final Prec@1 67.1356%
11/27 07:35:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][39/40]	Step 18952	Loss 1.6561	Prec@(1,5) (55.6%, 84.9%)
11/27 07:35:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 55.6200%
11/27 07:35:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:35:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][100/351]	Step 19052	lr 0.02121	Loss 0.9700 (1.0574)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.4%)	
11/27 07:36:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][200/351]	Step 19152	lr 0.02121	Loss 1.3477 (1.0820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.2%)	
11/27 07:37:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][300/351]	Step 19252	lr 0.02121	Loss 1.1372 (1.0938)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.1%)	
11/27 07:37:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][351/351]	Step 19303	lr 0.02121	Loss 1.2595 (1.1034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.0%)	
11/27 07:37:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 76/149] Final Prec@1 67.6756%
11/27 07:37:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][39/40]	Step 19304	Loss 1.7943	Prec@(1,5) (53.1%, 82.8%)
11/27 07:37:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 53.1400%
11/27 07:37:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8000%
11/27 07:38:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][100/351]	Step 19404	lr 0.02094	Loss 1.0869 (1.0406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.6%)	
11/27 07:38:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][200/351]	Step 19504	lr 0.02094	Loss 1.0472 (1.0649)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.1%)	
11/27 07:39:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][300/351]	Step 19604	lr 0.02094	Loss 1.3569 (1.0763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.1%)	
11/27 07:39:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][351/351]	Step 19655	lr 0.02094	Loss 1.2338 (1.0807)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.1%)	
11/27 07:39:51午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 77/149] Final Prec@1 68.2889%
11/27 07:39:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][39/40]	Step 19656	Loss 1.6406	Prec@(1,5) (55.8%, 84.9%)
11/27 07:39:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 55.8200%
11/27 07:39:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.8200%
11/27 07:40:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][100/351]	Step 19756	lr 0.02065	Loss 1.2097 (1.0156)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.1%)	
11/27 07:41:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][200/351]	Step 19856	lr 0.02065	Loss 1.0776 (1.0507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.6%)	
11/27 07:41:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][300/351]	Step 19956	lr 0.02065	Loss 1.3063 (1.0661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.4%)	
11/27 07:42:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][351/351]	Step 20007	lr 0.02065	Loss 1.1737 (1.0721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.3%)	
11/27 07:42:20午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 78/149] Final Prec@1 68.4711%
11/27 07:42:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][39/40]	Step 20008	Loss 1.5721	Prec@(1,5) (58.1%, 85.5%)
11/27 07:42:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 58.1600%
11/27 07:42:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:43:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][100/351]	Step 20108	lr 0.02035	Loss 0.9063 (1.0150)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.3%)	
11/27 07:43:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][200/351]	Step 20208	lr 0.02035	Loss 1.0619 (1.0397)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.9%)	
11/27 07:44:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][300/351]	Step 20308	lr 0.02035	Loss 0.8703 (1.0421)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.8%)	
11/27 07:44:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][351/351]	Step 20359	lr 0.02035	Loss 0.9189 (1.0539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.6%)	
11/27 07:44:48午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 79/149] Final Prec@1 69.0022%
11/27 07:44:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][39/40]	Step 20360	Loss 1.6949	Prec@(1,5) (55.5%, 84.4%)
11/27 07:44:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 55.4800%
11/27 07:44:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:45:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][100/351]	Step 20460	lr 0.02005	Loss 1.0032 (0.9825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.4%)	
11/27 07:46:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][200/351]	Step 20560	lr 0.02005	Loss 1.1305 (1.0172)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.0%)	
11/27 07:46:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][300/351]	Step 20660	lr 0.02005	Loss 1.0928 (1.0307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 92.8%)	
11/27 07:47:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][351/351]	Step 20711	lr 0.02005	Loss 1.3532 (1.0427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.7%)	
11/27 07:47:17午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 80/149] Final Prec@1 69.2044%
11/27 07:47:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][39/40]	Step 20712	Loss 1.6545	Prec@(1,5) (56.6%, 84.8%)
11/27 07:47:23午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 56.6600%
11/27 07:47:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:48:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][100/351]	Step 20812	lr 0.01975	Loss 0.9721 (0.9873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.5%)	
11/27 07:48:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][200/351]	Step 20912	lr 0.01975	Loss 0.8766 (1.0034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
11/27 07:49:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][300/351]	Step 21012	lr 0.01975	Loss 1.0174 (1.0145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.1%)	
11/27 07:49:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][351/351]	Step 21063	lr 0.01975	Loss 1.0490 (1.0227)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.1%)	
11/27 07:49:45午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 81/149] Final Prec@1 69.8444%
11/27 07:49:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][39/40]	Step 21064	Loss 1.6031	Prec@(1,5) (56.9%, 85.2%)
11/27 07:49:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 56.9000%
11/27 07:49:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:50:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][100/351]	Step 21164	lr 0.01943	Loss 1.0357 (0.9709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.8%)	
11/27 07:51:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][200/351]	Step 21264	lr 0.01943	Loss 1.0765 (1.0007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.2%)	
11/27 07:51:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][300/351]	Step 21364	lr 0.01943	Loss 0.9830 (1.0141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.1%)	
11/27 07:52:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][351/351]	Step 21415	lr 0.01943	Loss 1.0400 (1.0154)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.0%)	
11/27 07:52:13午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 82/149] Final Prec@1 70.0089%
11/27 07:52:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][39/40]	Step 21416	Loss 1.7178	Prec@(1,5) (55.6%, 83.8%)
11/27 07:52:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 55.6000%
11/27 07:52:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:53:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][100/351]	Step 21516	lr 0.01911	Loss 1.0242 (0.9236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.0%)	
11/27 07:53:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][200/351]	Step 21616	lr 0.01911	Loss 0.8474 (0.9666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.4%)	
11/27 07:54:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][300/351]	Step 21716	lr 0.01911	Loss 1.1734 (0.9828)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.3%)	
11/27 07:54:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][351/351]	Step 21767	lr 0.01911	Loss 0.9977 (0.9892)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.3%)	
11/27 07:54:42午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 83/149] Final Prec@1 70.7444%
11/27 07:54:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][39/40]	Step 21768	Loss 1.6807	Prec@(1,5) (56.3%, 84.1%)
11/27 07:54:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 56.3000%
11/27 07:54:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:55:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][100/351]	Step 21868	lr 0.01878	Loss 0.9038 (0.9328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.2%)	
11/27 07:56:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][200/351]	Step 21968	lr 0.01878	Loss 1.1907 (0.9530)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 93.9%)	
11/27 07:56:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][300/351]	Step 22068	lr 0.01878	Loss 1.1878 (0.9738)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.6%)	
11/27 07:57:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][351/351]	Step 22119	lr 0.01878	Loss 1.1186 (0.9802)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.5%)	
11/27 07:57:10午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 84/149] Final Prec@1 71.0756%
11/27 07:57:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][39/40]	Step 22120	Loss 1.6871	Prec@(1,5) (54.5%, 84.0%)
11/27 07:57:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 54.4800%
11/27 07:57:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 07:57:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][100/351]	Step 22220	lr 0.01845	Loss 0.7645 (0.9343)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.3%)	
11/27 07:58:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][200/351]	Step 22320	lr 0.01845	Loss 1.0925 (0.9447)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.1%)	
11/27 07:59:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][300/351]	Step 22420	lr 0.01845	Loss 0.9671 (0.9577)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.8%)	
11/27 07:59:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][351/351]	Step 22471	lr 0.01845	Loss 0.8530 (0.9653)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.6%)	
11/27 07:59:38午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 85/149] Final Prec@1 71.1044%
11/27 07:59:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][39/40]	Step 22472	Loss 1.7178	Prec@(1,5) (54.6%, 83.6%)
11/27 07:59:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 54.6200%
11/27 07:59:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 08:00:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][100/351]	Step 22572	lr 0.01811	Loss 1.1054 (0.9017)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.4%)	
11/27 08:01:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][200/351]	Step 22672	lr 0.01811	Loss 1.0499 (0.9323)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.0%)	
11/27 08:01:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][300/351]	Step 22772	lr 0.01811	Loss 1.0107 (0.9519)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 93.7%)	
11/27 08:02:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][351/351]	Step 22823	lr 0.01811	Loss 0.8551 (0.9595)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.6%)	
11/27 08:02:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 86/149] Final Prec@1 71.5222%
11/27 08:02:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][39/40]	Step 22824	Loss 1.6691	Prec@(1,5) (56.8%, 84.1%)
11/27 08:02:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 56.8000%
11/27 08:02:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 08:02:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][100/351]	Step 22924	lr 0.01777	Loss 0.7090 (0.9053)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.3%)	
11/27 08:03:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][200/351]	Step 23024	lr 0.01777	Loss 1.0348 (0.9196)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.1%)	
11/27 08:04:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][300/351]	Step 23124	lr 0.01777	Loss 0.8400 (0.9295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.1%)	
11/27 08:04:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][351/351]	Step 23175	lr 0.01777	Loss 0.8372 (0.9349)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.0%)	
11/27 08:04:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 87/149] Final Prec@1 72.2089%
11/27 08:04:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][39/40]	Step 23176	Loss 1.6189	Prec@(1,5) (57.3%, 85.7%)
11/27 08:04:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 57.3400%
11/27 08:04:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 08:05:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][100/351]	Step 23276	lr 0.01742	Loss 1.2063 (0.8999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.5%)	
11/27 08:06:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][200/351]	Step 23376	lr 0.01742	Loss 1.0777 (0.9211)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
11/27 08:06:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][300/351]	Step 23476	lr 0.01742	Loss 1.1289 (0.9339)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.1%)	
11/27 08:07:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][351/351]	Step 23527	lr 0.01742	Loss 0.8884 (0.9416)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
11/27 08:07:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 88/149] Final Prec@1 71.8911%
11/27 08:07:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][39/40]	Step 23528	Loss 1.6172	Prec@(1,5) (57.8%, 85.1%)
11/27 08:07:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 57.8400%
11/27 08:07:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/27 08:07:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][100/351]	Step 23628	lr 0.01706	Loss 0.7320 (0.8547)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 94.9%)	
11/27 08:08:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][200/351]	Step 23728	lr 0.01706	Loss 0.8010 (0.8811)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.6%)	
11/27 08:09:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][300/351]	Step 23828	lr 0.01706	Loss 1.0845 (0.9046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.3%)	
11/27 08:09:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][351/351]	Step 23879	lr 0.01706	Loss 1.1636 (0.9124)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.2%)	
11/27 08:09:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 89/149] Final Prec@1 72.7178%
11/27 08:09:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][39/40]	Step 23880	Loss 1.5207	Prec@(1,5) (58.8%, 86.4%)
11/27 08:09:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 58.7400%
11/27 08:09:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7400%
11/27 08:10:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][100/351]	Step 23980	lr 0.01671	Loss 0.9692 (0.8592)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
11/27 08:10:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][200/351]	Step 24080	lr 0.01671	Loss 0.9964 (0.8812)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.6%)	
11/27 08:11:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][300/351]	Step 24180	lr 0.01671	Loss 0.9293 (0.8969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.3%)	
11/27 08:11:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][351/351]	Step 24231	lr 0.01671	Loss 0.8389 (0.9034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.2%)	
11/27 08:12:00午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 90/149] Final Prec@1 73.0356%
11/27 08:12:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][39/40]	Step 24232	Loss 1.6353	Prec@(1,5) (57.2%, 85.5%)
11/27 08:12:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 57.2400%
11/27 08:12:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7400%
11/27 08:12:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][100/351]	Step 24332	lr 0.01635	Loss 0.8869 (0.8586)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.0%)	
11/27 08:13:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][200/351]	Step 24432	lr 0.01635	Loss 0.8052 (0.8613)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
11/27 08:14:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][300/351]	Step 24532	lr 0.01635	Loss 0.8680 (0.8755)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.8%)	
11/27 08:14:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][351/351]	Step 24583	lr 0.01635	Loss 1.0532 (0.8826)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.6%)	
11/27 08:14:28午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 91/149] Final Prec@1 73.4578%
11/27 08:14:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][39/40]	Step 24584	Loss 1.6062	Prec@(1,5) (56.7%, 84.9%)
11/27 08:14:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 56.7200%
11/27 08:14:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7400%
11/27 08:15:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][100/351]	Step 24684	lr 0.01598	Loss 0.9482 (0.8234)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.6%)	
11/27 08:15:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][200/351]	Step 24784	lr 0.01598	Loss 0.9749 (0.8507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.2%)	
11/27 08:16:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][300/351]	Step 24884	lr 0.01598	Loss 0.7995 (0.8676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.9%)	
11/27 08:16:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][351/351]	Step 24935	lr 0.01598	Loss 0.8795 (0.8729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.9%)	
11/27 08:16:56午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 92/149] Final Prec@1 73.7156%
11/27 08:17:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][39/40]	Step 24936	Loss 1.5203	Prec@(1,5) (59.3%, 86.7%)
11/27 08:17:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 59.2800%
11/27 08:17:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2800%
11/27 08:17:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][100/351]	Step 25036	lr 0.01562	Loss 0.7346 (0.8152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.3%)	
11/27 08:18:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][200/351]	Step 25136	lr 0.01562	Loss 0.9895 (0.8297)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.2%)	
11/27 08:19:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][300/351]	Step 25236	lr 0.01562	Loss 0.8860 (0.8449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/27 08:19:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][351/351]	Step 25287	lr 0.01562	Loss 1.0324 (0.8526)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.0%)	
11/27 08:19:24午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 93/149] Final Prec@1 74.2311%
11/27 08:19:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][39/40]	Step 25288	Loss 1.6620	Prec@(1,5) (56.7%, 85.6%)
11/27 08:19:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 56.6200%
11/27 08:19:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2800%
11/27 08:20:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][100/351]	Step 25388	lr 0.01525	Loss 0.9119 (0.7960)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.8%)	
11/27 08:20:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][200/351]	Step 25488	lr 0.01525	Loss 0.8721 (0.8201)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.5%)	
11/27 08:21:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][300/351]	Step 25588	lr 0.01525	Loss 0.9758 (0.8415)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.1%)	
11/27 08:21:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][351/351]	Step 25639	lr 0.01525	Loss 0.8476 (0.8476)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/27 08:21:53午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 94/149] Final Prec@1 74.4267%
11/27 08:21:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][39/40]	Step 25640	Loss 1.5339	Prec@(1,5) (58.5%, 86.1%)
11/27 08:21:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 58.5400%
11/27 08:21:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2800%
11/27 08:22:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][100/351]	Step 25740	lr 0.01488	Loss 0.8117 (0.8227)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.2%)	
11/27 08:23:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][200/351]	Step 25840	lr 0.01488	Loss 0.9252 (0.8293)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.2%)	
11/27 08:24:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][300/351]	Step 25940	lr 0.01488	Loss 0.8927 (0.8360)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.2%)	
11/27 08:24:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][351/351]	Step 25991	lr 0.01488	Loss 0.8229 (0.8391)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.2%)	
11/27 08:24:21午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 95/149] Final Prec@1 74.6289%
11/27 08:24:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][39/40]	Step 25992	Loss 1.5184	Prec@(1,5) (59.9%, 86.4%)
11/27 08:24:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 59.9600%
11/27 08:24:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:25:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][100/351]	Step 26092	lr 0.0145	Loss 0.8425 (0.7689)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.9%)	
11/27 08:25:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][200/351]	Step 26192	lr 0.0145	Loss 0.8242 (0.7953)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.6%)	
11/27 08:26:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][300/351]	Step 26292	lr 0.0145	Loss 0.7693 (0.8081)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.4%)	
11/27 08:26:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][351/351]	Step 26343	lr 0.0145	Loss 0.9367 (0.8135)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.4%)	
11/27 08:26:49午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 96/149] Final Prec@1 75.5044%
11/27 08:26:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][39/40]	Step 26344	Loss 1.5957	Prec@(1,5) (58.3%, 86.1%)
11/27 08:26:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 58.2800%
11/27 08:26:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:27:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][100/351]	Step 26444	lr 0.01413	Loss 0.7543 (0.7585)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
11/27 08:28:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][200/351]	Step 26544	lr 0.01413	Loss 0.9238 (0.7756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.9%)	
11/27 08:28:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][300/351]	Step 26644	lr 0.01413	Loss 0.7039 (0.7922)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.6%)	
11/27 08:29:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][351/351]	Step 26695	lr 0.01413	Loss 0.9028 (0.7984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.5%)	
11/27 08:29:18午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 97/149] Final Prec@1 75.9267%
11/27 08:29:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][39/40]	Step 26696	Loss 1.6801	Prec@(1,5) (56.9%, 84.8%)
11/27 08:29:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 56.9000%
11/27 08:29:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:30:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][100/351]	Step 26796	lr 0.01375	Loss 0.8366 (0.7601)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.0%)	
11/27 08:30:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][200/351]	Step 26896	lr 0.01375	Loss 0.7224 (0.7777)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.8%)	
11/27 08:31:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][300/351]	Step 26996	lr 0.01375	Loss 0.8867 (0.7895)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.6%)	
11/27 08:31:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][351/351]	Step 27047	lr 0.01375	Loss 0.7585 (0.7927)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.5%)	
11/27 08:31:46午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 98/149] Final Prec@1 75.9244%
11/27 08:31:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][39/40]	Step 27048	Loss 1.5894	Prec@(1,5) (58.1%, 85.7%)
11/27 08:31:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 58.1200%
11/27 08:31:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:32:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][100/351]	Step 27148	lr 0.01338	Loss 0.7329 (0.7441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.4%)	
11/27 08:33:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][200/351]	Step 27248	lr 0.01338	Loss 0.7344 (0.7534)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
11/27 08:33:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][300/351]	Step 27348	lr 0.01338	Loss 0.7925 (0.7679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.9%)	
11/27 08:34:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][351/351]	Step 27399	lr 0.01338	Loss 0.8360 (0.7733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.8%)	
11/27 08:34:14午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 99/149] Final Prec@1 76.5889%
11/27 08:34:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][39/40]	Step 27400	Loss 1.5573	Prec@(1,5) (58.9%, 86.7%)
11/27 08:34:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 58.8400%
11/27 08:34:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:35:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][100/351]	Step 27500	lr 0.013	Loss 0.7767 (0.7149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
11/27 08:35:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][200/351]	Step 27600	lr 0.013	Loss 0.7295 (0.7362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.3%)	
11/27 08:36:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][300/351]	Step 27700	lr 0.013	Loss 0.8378 (0.7510)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
11/27 08:36:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][351/351]	Step 27751	lr 0.013	Loss 0.6542 (0.7568)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.0%)	
11/27 08:36:42午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [100/149] Final Prec@1 76.9733%
11/27 08:36:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][39/40]	Step 27752	Loss 1.5167	Prec@(1,5) (59.7%, 87.3%)
11/27 08:36:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 59.7600%
11/27 08:36:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:37:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][100/351]	Step 27852	lr 0.01262	Loss 0.6210 (0.7080)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.3%)	
11/27 08:38:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][200/351]	Step 27952	lr 0.01262	Loss 0.9073 (0.7283)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.2%)	
11/27 08:38:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][300/351]	Step 28052	lr 0.01262	Loss 0.8303 (0.7461)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.0%)	
11/27 08:39:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][351/351]	Step 28103	lr 0.01262	Loss 0.7629 (0.7520)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.0%)	
11/27 08:39:10午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [101/149] Final Prec@1 77.1133%
11/27 08:39:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][39/40]	Step 28104	Loss 1.5881	Prec@(1,5) (58.9%, 86.5%)
11/27 08:39:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 58.8400%
11/27 08:39:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.9600%
11/27 08:39:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][100/351]	Step 28204	lr 0.01225	Loss 0.7660 (0.6909)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.6%)	
11/27 08:40:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][200/351]	Step 28304	lr 0.01225	Loss 0.7350 (0.7077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
11/27 08:41:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][300/351]	Step 28404	lr 0.01225	Loss 0.8896 (0.7217)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.2%)	
11/27 08:41:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][351/351]	Step 28455	lr 0.01225	Loss 0.8144 (0.7265)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.2%)	
11/27 08:41:38午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [102/149] Final Prec@1 77.8067%
11/27 08:41:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][39/40]	Step 28456	Loss 1.5241	Prec@(1,5) (60.1%, 86.8%)
11/27 08:41:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 60.0800%
11/27 08:41:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.0800%
11/27 08:42:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][100/351]	Step 28556	lr 0.01187	Loss 0.6764 (0.6799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.9%)	
11/27 08:43:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][200/351]	Step 28656	lr 0.01187	Loss 0.6716 (0.6965)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.7%)	
11/27 08:43:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][300/351]	Step 28756	lr 0.01187	Loss 0.7760 (0.7135)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.5%)	
11/27 08:44:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][351/351]	Step 28807	lr 0.01187	Loss 0.8325 (0.7173)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.4%)	
11/27 08:44:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [103/149] Final Prec@1 78.0844%
11/27 08:44:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][39/40]	Step 28808	Loss 1.6414	Prec@(1,5) (58.4%, 85.8%)
11/27 08:44:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 58.3600%
11/27 08:44:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.0800%
11/27 08:44:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][100/351]	Step 28908	lr 0.0115	Loss 0.5906 (0.6714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
11/27 08:45:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][200/351]	Step 29008	lr 0.0115	Loss 0.8286 (0.6882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/27 08:46:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][300/351]	Step 29108	lr 0.0115	Loss 0.7835 (0.7055)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
11/27 08:46:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][351/351]	Step 29159	lr 0.0115	Loss 0.5829 (0.7091)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.5%)	
11/27 08:46:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [104/149] Final Prec@1 78.2889%
11/27 08:46:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][39/40]	Step 29160	Loss 1.5237	Prec@(1,5) (60.6%, 86.6%)
11/27 08:46:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 60.6400%
11/27 08:46:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6400%
11/27 08:47:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][100/351]	Step 29260	lr 0.01112	Loss 0.5542 (0.6605)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.7%)	
11/27 08:48:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][200/351]	Step 29360	lr 0.01112	Loss 0.4958 (0.6714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.7%)	
11/27 08:48:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][300/351]	Step 29460	lr 0.01112	Loss 0.7580 (0.6813)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.5%)	
11/27 08:49:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][351/351]	Step 29511	lr 0.01112	Loss 0.7208 (0.6859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.5%)	
11/27 08:49:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [105/149] Final Prec@1 79.0556%
11/27 08:49:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][39/40]	Step 29512	Loss 1.5811	Prec@(1,5) (58.2%, 86.7%)
11/27 08:49:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 58.1800%
11/27 08:49:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6400%
11/27 08:49:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][100/351]	Step 29612	lr 0.01075	Loss 0.5693 (0.6526)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.2%)	
11/27 08:50:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][200/351]	Step 29712	lr 0.01075	Loss 0.5016 (0.6590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 97.1%)	
11/27 08:51:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][300/351]	Step 29812	lr 0.01075	Loss 0.6086 (0.6728)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.9%)	
11/27 08:51:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][351/351]	Step 29863	lr 0.01075	Loss 0.6223 (0.6790)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.8%)	
11/27 08:51:32午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [106/149] Final Prec@1 78.9089%
11/27 08:51:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][39/40]	Step 29864	Loss 1.4950	Prec@(1,5) (60.6%, 87.6%)
11/27 08:51:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 60.6800%
11/27 08:51:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6800%
11/27 08:52:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][100/351]	Step 29964	lr 0.01038	Loss 0.6188 (0.6266)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.1%)	
11/27 08:52:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][200/351]	Step 30064	lr 0.01038	Loss 0.4801 (0.6447)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 96.9%)	
11/27 08:53:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][300/351]	Step 30164	lr 0.01038	Loss 0.6757 (0.6567)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.8%)	
11/27 08:54:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][351/351]	Step 30215	lr 0.01038	Loss 0.7049 (0.6642)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.8%)	
11/27 08:54:00午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [107/149] Final Prec@1 79.5178%
11/27 08:54:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][39/40]	Step 30216	Loss 1.5136	Prec@(1,5) (60.6%, 87.3%)
11/27 08:54:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 60.6200%
11/27 08:54:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6800%
11/27 08:54:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][100/351]	Step 30316	lr 0.01002	Loss 0.5840 (0.6276)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.1%)	
11/27 08:55:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][200/351]	Step 30416	lr 0.01002	Loss 0.6141 (0.6259)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.1%)	
11/27 08:56:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][300/351]	Step 30516	lr 0.01002	Loss 0.7082 (0.6404)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.1%)	
11/27 08:56:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][351/351]	Step 30567	lr 0.01002	Loss 0.7835 (0.6485)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.0%)	
11/27 08:56:28午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [108/149] Final Prec@1 80.1422%
11/27 08:56:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][39/40]	Step 30568	Loss 1.5253	Prec@(1,5) (60.1%, 87.1%)
11/27 08:56:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 60.1000%
11/27 08:56:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6800%
11/27 08:57:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][100/351]	Step 30668	lr 0.00965	Loss 0.7431 (0.5818)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.6%)	
11/27 08:57:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][200/351]	Step 30768	lr 0.00965	Loss 0.5610 (0.6007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.4%)	
11/27 08:58:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][300/351]	Step 30868	lr 0.00965	Loss 0.7771 (0.6222)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.2%)	
11/27 08:58:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][351/351]	Step 30919	lr 0.00965	Loss 0.7934 (0.6268)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
11/27 08:58:56午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [109/149] Final Prec@1 80.7622%
11/27 08:59:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][39/40]	Step 30920	Loss 1.5379	Prec@(1,5) (60.4%, 87.2%)
11/27 08:59:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 60.4400%
11/27 08:59:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6800%
11/27 08:59:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][100/351]	Step 31020	lr 0.00929	Loss 0.4679 (0.5921)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.5%)	
11/27 09:00:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][200/351]	Step 31120	lr 0.00929	Loss 0.4886 (0.6008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/27 09:01:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][300/351]	Step 31220	lr 0.00929	Loss 0.5216 (0.6138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.4%)	
11/27 09:01:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][351/351]	Step 31271	lr 0.00929	Loss 0.6721 (0.6207)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
11/27 09:01:24午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [110/149] Final Prec@1 80.6022%
11/27 09:01:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][39/40]	Step 31272	Loss 1.4835	Prec@(1,5) (62.4%, 87.1%)
11/27 09:01:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 62.3800%
11/27 09:01:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:02:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][100/351]	Step 31372	lr 0.00894	Loss 0.5477 (0.5669)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.9%)	
11/27 09:02:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][200/351]	Step 31472	lr 0.00894	Loss 0.4969 (0.5818)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.8%)	
11/27 09:03:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][300/351]	Step 31572	lr 0.00894	Loss 0.7669 (0.5940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
11/27 09:03:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][351/351]	Step 31623	lr 0.00894	Loss 0.4390 (0.5984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
11/27 09:03:53午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [111/149] Final Prec@1 81.4067%
11/27 09:03:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][39/40]	Step 31624	Loss 1.5240	Prec@(1,5) (60.6%, 86.5%)
11/27 09:03:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 60.6000%
11/27 09:03:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:04:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][100/351]	Step 31724	lr 0.00858	Loss 0.5504 (0.5719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.6%)	
11/27 09:05:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][200/351]	Step 31824	lr 0.00858	Loss 0.5886 (0.5746)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.7%)	
11/27 09:06:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][300/351]	Step 31924	lr 0.00858	Loss 0.6310 (0.5815)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.6%)	
11/27 09:06:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][351/351]	Step 31975	lr 0.00858	Loss 0.4770 (0.5885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/27 09:06:21午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [112/149] Final Prec@1 81.8978%
11/27 09:06:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][39/40]	Step 31976	Loss 1.5062	Prec@(1,5) (61.8%, 87.6%)
11/27 09:06:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 61.7600%
11/27 09:06:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:07:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][100/351]	Step 32076	lr 0.00823	Loss 0.6865 (0.5456)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.7%)	
11/27 09:07:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][200/351]	Step 32176	lr 0.00823	Loss 0.6704 (0.5606)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.6%)	
11/27 09:08:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][300/351]	Step 32276	lr 0.00823	Loss 0.5485 (0.5677)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.6%)	
11/27 09:08:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][351/351]	Step 32327	lr 0.00823	Loss 0.6714 (0.5717)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.6%)	
11/27 09:08:49午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [113/149] Final Prec@1 82.3467%
11/27 09:08:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][39/40]	Step 32328	Loss 1.4723	Prec@(1,5) (62.3%, 87.7%)
11/27 09:08:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 62.2600%
11/27 09:08:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:09:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][100/351]	Step 32428	lr 0.00789	Loss 0.5287 (0.5295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.0%)	
11/27 09:10:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][200/351]	Step 32528	lr 0.00789	Loss 0.4803 (0.5404)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/27 09:10:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][300/351]	Step 32628	lr 0.00789	Loss 0.5514 (0.5512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.7%)	
11/27 09:11:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][351/351]	Step 32679	lr 0.00789	Loss 0.6790 (0.5569)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.7%)	
11/27 09:11:17午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [114/149] Final Prec@1 82.7822%
11/27 09:11:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][39/40]	Step 32680	Loss 1.5273	Prec@(1,5) (61.3%, 87.6%)
11/27 09:11:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 61.3000%
11/27 09:11:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:12:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][100/351]	Step 32780	lr 0.00755	Loss 0.5593 (0.5083)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
11/27 09:12:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][200/351]	Step 32880	lr 0.00755	Loss 0.5140 (0.5215)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.1%)	
11/27 09:13:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][300/351]	Step 32980	lr 0.00755	Loss 0.5477 (0.5337)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.0%)	
11/27 09:13:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][351/351]	Step 33031	lr 0.00755	Loss 0.5766 (0.5411)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.9%)	
11/27 09:13:46午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [115/149] Final Prec@1 83.0778%
11/27 09:13:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][39/40]	Step 33032	Loss 1.5097	Prec@(1,5) (62.0%, 87.5%)
11/27 09:13:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 61.9000%
11/27 09:13:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:14:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][100/351]	Step 33132	lr 0.00722	Loss 0.4059 (0.5045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
11/27 09:15:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][200/351]	Step 33232	lr 0.00722	Loss 0.5187 (0.5135)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
11/27 09:15:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][300/351]	Step 33332	lr 0.00722	Loss 0.5466 (0.5223)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
11/27 09:16:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][351/351]	Step 33383	lr 0.00722	Loss 0.4732 (0.5310)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
11/27 09:16:14午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [116/149] Final Prec@1 83.6000%
11/27 09:16:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][39/40]	Step 33384	Loss 1.4856	Prec@(1,5) (62.2%, 87.7%)
11/27 09:16:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 62.1400%
11/27 09:16:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:17:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][100/351]	Step 33484	lr 0.00689	Loss 0.4025 (0.4742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/27 09:17:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][200/351]	Step 33584	lr 0.00689	Loss 0.6157 (0.4926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.3%)	
11/27 09:18:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][300/351]	Step 33684	lr 0.00689	Loss 0.6300 (0.5111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/27 09:18:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][351/351]	Step 33735	lr 0.00689	Loss 0.3607 (0.5136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.1%)	
11/27 09:18:42午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [117/149] Final Prec@1 84.0933%
11/27 09:18:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][39/40]	Step 33736	Loss 1.5775	Prec@(1,5) (61.1%, 87.2%)
11/27 09:18:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 61.0200%
11/27 09:18:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:19:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][100/351]	Step 33836	lr 0.00657	Loss 0.4839 (0.4709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.4%)	
11/27 09:20:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][200/351]	Step 33936	lr 0.00657	Loss 0.4581 (0.4866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
11/27 09:20:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][300/351]	Step 34036	lr 0.00657	Loss 0.6583 (0.5013)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
11/27 09:21:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][351/351]	Step 34087	lr 0.00657	Loss 0.3660 (0.5046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.2%)	
11/27 09:21:10午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [118/149] Final Prec@1 84.3378%
11/27 09:21:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][39/40]	Step 34088	Loss 1.4969	Prec@(1,5) (62.2%, 88.1%)
11/27 09:21:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 62.1600%
11/27 09:21:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:21:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][100/351]	Step 34188	lr 0.00625	Loss 0.4502 (0.4634)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.6%)	
11/27 09:22:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][200/351]	Step 34288	lr 0.00625	Loss 0.5241 (0.4756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.5%)	
11/27 09:23:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][300/351]	Step 34388	lr 0.00625	Loss 0.6430 (0.4847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/27 09:23:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][351/351]	Step 34439	lr 0.00625	Loss 0.6347 (0.4897)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.3%)	
11/27 09:23:39午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [119/149] Final Prec@1 84.8311%
11/27 09:23:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][39/40]	Step 34440	Loss 1.5095	Prec@(1,5) (62.4%, 87.9%)
11/27 09:23:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 62.3800%
11/27 09:23:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3800%
11/27 09:24:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][100/351]	Step 34540	lr 0.00595	Loss 0.4679 (0.4565)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.6%)	
11/27 09:25:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][200/351]	Step 34640	lr 0.00595	Loss 0.4799 (0.4652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.6%)	
11/27 09:25:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][300/351]	Step 34740	lr 0.00595	Loss 0.5416 (0.4718)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.5%)	
11/27 09:26:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][351/351]	Step 34791	lr 0.00595	Loss 0.4716 (0.4765)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.5%)	
11/27 09:26:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [120/149] Final Prec@1 84.9956%
11/27 09:26:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][39/40]	Step 34792	Loss 1.4741	Prec@(1,5) (63.3%, 87.9%)
11/27 09:26:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 63.3000%
11/27 09:26:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3000%
11/27 09:26:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][100/351]	Step 34892	lr 0.00565	Loss 0.5346 (0.4309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.8%)	
11/27 09:27:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][200/351]	Step 34992	lr 0.00565	Loss 0.4991 (0.4427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.7%)	
11/27 09:28:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][300/351]	Step 35092	lr 0.00565	Loss 0.4746 (0.4528)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
11/27 09:28:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][351/351]	Step 35143	lr 0.00565	Loss 0.4051 (0.4575)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.5%)	
11/27 09:28:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [121/149] Final Prec@1 85.8778%
11/27 09:28:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][39/40]	Step 35144	Loss 1.4704	Prec@(1,5) (63.3%, 88.0%)
11/27 09:28:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 63.3200%
11/27 09:28:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/27 09:29:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][100/351]	Step 35244	lr 0.00535	Loss 0.3863 (0.4213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.7%)	
11/27 09:30:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][200/351]	Step 35344	lr 0.00535	Loss 0.5190 (0.4322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.7%)	
11/27 09:30:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][300/351]	Step 35444	lr 0.00535	Loss 0.4226 (0.4402)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.6%)	
11/27 09:31:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][351/351]	Step 35495	lr 0.00535	Loss 0.6070 (0.4470)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.6%)	
11/27 09:31:04午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [122/149] Final Prec@1 86.2467%
11/27 09:31:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][39/40]	Step 35496	Loss 1.4833	Prec@(1,5) (62.4%, 88.3%)
11/27 09:31:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 62.4000%
11/27 09:31:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/27 09:31:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][100/351]	Step 35596	lr 0.00506	Loss 0.3532 (0.3977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
11/27 09:32:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][200/351]	Step 35696	lr 0.00506	Loss 0.3699 (0.4099)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
11/27 09:33:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][300/351]	Step 35796	lr 0.00506	Loss 0.4886 (0.4227)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
11/27 09:33:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][351/351]	Step 35847	lr 0.00506	Loss 0.5626 (0.4280)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.7%)	
11/27 09:33:32午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [123/149] Final Prec@1 86.7467%
11/27 09:33:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][39/40]	Step 35848	Loss 1.4845	Prec@(1,5) (63.3%, 88.2%)
11/27 09:33:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 63.3600%
11/27 09:33:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:34:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][100/351]	Step 35948	lr 0.00479	Loss 0.4093 (0.4007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 98.9%)	
11/27 09:35:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][200/351]	Step 36048	lr 0.00479	Loss 0.5631 (0.4078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.9%)	
11/27 09:35:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][300/351]	Step 36148	lr 0.00479	Loss 0.3831 (0.4129)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.8%)	
11/27 09:36:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][351/351]	Step 36199	lr 0.00479	Loss 0.5040 (0.4169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/27 09:36:01午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [124/149] Final Prec@1 87.2244%
11/27 09:36:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][39/40]	Step 36200	Loss 1.4920	Prec@(1,5) (62.9%, 88.0%)
11/27 09:36:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 62.9400%
11/27 09:36:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:36:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][100/351]	Step 36300	lr 0.00451	Loss 0.4407 (0.3845)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.1%, 99.0%)	
11/27 09:37:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][200/351]	Step 36400	lr 0.00451	Loss 0.3290 (0.3919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 99.1%)	
11/27 09:38:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][300/351]	Step 36500	lr 0.00451	Loss 0.4327 (0.4034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.9%)	
11/27 09:38:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][351/351]	Step 36551	lr 0.00451	Loss 0.5000 (0.4095)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.9%)	
11/27 09:38:29午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [125/149] Final Prec@1 87.4578%
11/27 09:38:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][39/40]	Step 36552	Loss 1.5070	Prec@(1,5) (62.7%, 88.7%)
11/27 09:38:35午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 62.7400%
11/27 09:38:35午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:39:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][100/351]	Step 36652	lr 0.00425	Loss 0.3910 (0.3852)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
11/27 09:39:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][200/351]	Step 36752	lr 0.00425	Loss 0.4239 (0.3858)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
11/27 09:40:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][300/351]	Step 36852	lr 0.00425	Loss 0.3132 (0.3867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
11/27 09:40:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][351/351]	Step 36903	lr 0.00425	Loss 0.5134 (0.3928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.0%, 98.9%)	
11/27 09:40:57午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [126/149] Final Prec@1 88.0400%
11/27 09:41:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][39/40]	Step 36904	Loss 1.5273	Prec@(1,5) (62.0%, 88.6%)
11/27 09:41:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 61.9800%
11/27 09:41:04午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:41:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][100/351]	Step 37004	lr 0.004	Loss 0.2928 (0.3614)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.2%)	
11/27 09:42:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][200/351]	Step 37104	lr 0.004	Loss 0.5070 (0.3664)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.2%)	
11/27 09:43:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][300/351]	Step 37204	lr 0.004	Loss 0.4842 (0.3720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.1%)	
11/27 09:43:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][351/351]	Step 37255	lr 0.004	Loss 0.3550 (0.3767)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.1%)	
11/27 09:43:26午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [127/149] Final Prec@1 88.5444%
11/27 09:43:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][39/40]	Step 37256	Loss 1.4906	Prec@(1,5) (63.0%, 88.6%)
11/27 09:43:32午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 63.0400%
11/27 09:43:32午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:44:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][100/351]	Step 37356	lr 0.00375	Loss 0.5194 (0.3456)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.2%)	
11/27 09:44:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][200/351]	Step 37456	lr 0.00375	Loss 0.4620 (0.3555)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
11/27 09:45:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][300/351]	Step 37556	lr 0.00375	Loss 0.3485 (0.3650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.1%)	
11/27 09:45:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][351/351]	Step 37607	lr 0.00375	Loss 0.4065 (0.3671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.1%)	
11/27 09:45:54午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [128/149] Final Prec@1 88.9733%
11/27 09:46:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][39/40]	Step 37608	Loss 1.4607	Prec@(1,5) (63.2%, 88.8%)
11/27 09:46:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 63.2200%
11/27 09:46:00午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:46:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][100/351]	Step 37708	lr 0.00352	Loss 0.3959 (0.3386)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.3%)	
11/27 09:47:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][200/351]	Step 37808	lr 0.00352	Loss 0.4070 (0.3451)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
11/27 09:48:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][300/351]	Step 37908	lr 0.00352	Loss 0.3612 (0.3524)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
11/27 09:48:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][351/351]	Step 37959	lr 0.00352	Loss 0.4345 (0.3560)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.2%)	
11/27 09:48:22午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [129/149] Final Prec@1 89.2667%
11/27 09:48:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][39/40]	Step 37960	Loss 1.4960	Prec@(1,5) (63.3%, 88.7%)
11/27 09:48:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 63.2600%
11/27 09:48:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3600%
11/27 09:49:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][100/351]	Step 38060	lr 0.00329	Loss 0.3559 (0.3278)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
11/27 09:49:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][200/351]	Step 38160	lr 0.00329	Loss 0.3885 (0.3362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.4%)	
11/27 09:50:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][300/351]	Step 38260	lr 0.00329	Loss 0.2893 (0.3387)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
11/27 09:50:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][351/351]	Step 38311	lr 0.00329	Loss 0.3923 (0.3431)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
11/27 09:50:51午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [130/149] Final Prec@1 89.7600%
11/27 09:50:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][39/40]	Step 38312	Loss 1.4591	Prec@(1,5) (64.0%, 89.0%)
11/27 09:50:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 63.9800%
11/27 09:50:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.9800%
11/27 09:51:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][100/351]	Step 38412	lr 0.00308	Loss 0.3841 (0.3231)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.4%)	
11/27 09:52:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][200/351]	Step 38512	lr 0.00308	Loss 0.3653 (0.3266)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.3%)	
11/27 09:52:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][300/351]	Step 38612	lr 0.00308	Loss 0.4161 (0.3339)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
11/27 09:53:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][351/351]	Step 38663	lr 0.00308	Loss 0.2609 (0.3352)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.2%)	
11/27 09:53:19午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [131/149] Final Prec@1 89.9400%
11/27 09:53:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][39/40]	Step 38664	Loss 1.4915	Prec@(1,5) (64.1%, 88.1%)
11/27 09:53:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 64.1800%
11/27 09:53:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.1800%
11/27 09:54:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][100/351]	Step 38764	lr 0.00287	Loss 0.3012 (0.3170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
11/27 09:54:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][200/351]	Step 38864	lr 0.00287	Loss 0.2882 (0.3284)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.3%)	
11/27 09:55:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][300/351]	Step 38964	lr 0.00287	Loss 0.3550 (0.3290)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.3%)	
11/27 09:55:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][351/351]	Step 39015	lr 0.00287	Loss 0.3844 (0.3316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.3%)	
11/27 09:55:48午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [132/149] Final Prec@1 90.1578%
11/27 09:55:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][39/40]	Step 39016	Loss 1.4944	Prec@(1,5) (63.7%, 88.4%)
11/27 09:55:54午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 63.7200%
11/27 09:55:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.1800%
11/27 09:56:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][100/351]	Step 39116	lr 0.00267	Loss 0.3370 (0.3062)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
11/27 09:57:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][200/351]	Step 39216	lr 0.00267	Loss 0.3766 (0.3078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
11/27 09:57:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][300/351]	Step 39316	lr 0.00267	Loss 0.3988 (0.3141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
11/27 09:58:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][351/351]	Step 39367	lr 0.00267	Loss 0.2796 (0.3176)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
11/27 09:58:16午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [133/149] Final Prec@1 90.6933%
11/27 09:58:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][39/40]	Step 39368	Loss 1.4653	Prec@(1,5) (64.0%, 87.9%)
11/27 09:58:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 64.0200%
11/27 09:58:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.1800%
11/27 09:59:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][100/351]	Step 39468	lr 0.00248	Loss 0.2852 (0.3000)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
11/27 09:59:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][200/351]	Step 39568	lr 0.00248	Loss 0.3421 (0.3026)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
11/27 10:00:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][300/351]	Step 39668	lr 0.00248	Loss 0.4247 (0.3061)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
11/27 10:00:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][351/351]	Step 39719	lr 0.00248	Loss 0.3622 (0.3071)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
11/27 10:00:44午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [134/149] Final Prec@1 90.9844%
11/27 10:00:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][39/40]	Step 39720	Loss 1.4693	Prec@(1,5) (64.0%, 88.3%)
11/27 10:00:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 63.9600%
11/27 10:00:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.1800%
11/27 10:01:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][100/351]	Step 39820	lr 0.00231	Loss 0.1997 (0.2906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.4%)	
11/27 10:02:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][200/351]	Step 39920	lr 0.00231	Loss 0.2741 (0.2948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
11/27 10:02:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][300/351]	Step 40020	lr 0.00231	Loss 0.2511 (0.2946)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
11/27 10:03:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][351/351]	Step 40071	lr 0.00231	Loss 0.3204 (0.2973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.4%)	
11/27 10:03:12午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [135/149] Final Prec@1 91.3222%
11/27 10:03:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][39/40]	Step 40072	Loss 1.4704	Prec@(1,5) (64.5%, 88.8%)
11/27 10:03:19午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 64.5000%
11/27 10:03:19午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5000%
11/27 10:04:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][100/351]	Step 40172	lr 0.00214	Loss 0.2522 (0.2823)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
11/27 10:04:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][200/351]	Step 40272	lr 0.00214	Loss 0.2659 (0.2851)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.4%)	
11/27 10:05:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][300/351]	Step 40372	lr 0.00214	Loss 0.3581 (0.2925)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
11/27 10:05:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][351/351]	Step 40423	lr 0.00214	Loss 0.2054 (0.2940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
11/27 10:05:41午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [136/149] Final Prec@1 91.5800%
11/27 10:05:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][39/40]	Step 40424	Loss 1.4917	Prec@(1,5) (63.6%, 88.5%)
11/27 10:05:47午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 63.6600%
11/27 10:05:47午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5000%
11/27 10:06:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][100/351]	Step 40524	lr 0.00199	Loss 0.3938 (0.2747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
11/27 10:07:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][200/351]	Step 40624	lr 0.00199	Loss 0.2548 (0.2809)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
11/27 10:07:48午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][300/351]	Step 40724	lr 0.00199	Loss 0.2693 (0.2877)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.5%)	
11/27 10:08:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][351/351]	Step 40775	lr 0.00199	Loss 0.2648 (0.2890)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
11/27 10:08:09午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [137/149] Final Prec@1 91.5422%
11/27 10:08:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][39/40]	Step 40776	Loss 1.4726	Prec@(1,5) (63.8%, 88.6%)
11/27 10:08:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 63.8400%
11/27 10:08:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5000%
11/27 10:08:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][100/351]	Step 40876	lr 0.00184	Loss 0.2358 (0.2637)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
11/27 10:09:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][200/351]	Step 40976	lr 0.00184	Loss 0.2719 (0.2727)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
11/27 10:10:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][300/351]	Step 41076	lr 0.00184	Loss 0.2562 (0.2772)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
11/27 10:10:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][351/351]	Step 41127	lr 0.00184	Loss 0.3775 (0.2778)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
11/27 10:10:37午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [138/149] Final Prec@1 92.1756%
11/27 10:10:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][39/40]	Step 41128	Loss 1.4871	Prec@(1,5) (63.8%, 88.7%)
11/27 10:10:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 63.8600%
11/27 10:10:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5000%
11/27 10:11:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][100/351]	Step 41228	lr 0.00171	Loss 0.2462 (0.2622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/27 10:12:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][200/351]	Step 41328	lr 0.00171	Loss 0.2580 (0.2695)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
11/27 10:12:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][300/351]	Step 41428	lr 0.00171	Loss 0.3668 (0.2727)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
11/27 10:13:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][351/351]	Step 41479	lr 0.00171	Loss 0.1997 (0.2747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
11/27 10:13:06午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [139/149] Final Prec@1 92.2911%
11/27 10:13:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][39/40]	Step 41480	Loss 1.4742	Prec@(1,5) (64.6%, 89.0%)
11/27 10:13:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 64.5800%
11/27 10:13:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/27 10:13:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][100/351]	Step 41580	lr 0.00159	Loss 0.2465 (0.2538)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
11/27 10:14:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][200/351]	Step 41680	lr 0.00159	Loss 0.2294 (0.2644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.5%)	
11/27 10:15:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][300/351]	Step 41780	lr 0.00159	Loss 0.2056 (0.2663)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.5%)	
11/27 10:15:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][351/351]	Step 41831	lr 0.00159	Loss 0.3470 (0.2685)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
11/27 10:15:34午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [140/149] Final Prec@1 92.3800%
11/27 10:15:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][39/40]	Step 41832	Loss 1.4844	Prec@(1,5) (64.3%, 88.3%)
11/27 10:15:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 64.3000%
11/27 10:15:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/27 10:16:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][100/351]	Step 41932	lr 0.00148	Loss 0.2855 (0.2446)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.6%)	
11/27 10:17:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][200/351]	Step 42032	lr 0.00148	Loss 0.2522 (0.2531)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
11/27 10:17:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][300/351]	Step 42132	lr 0.00148	Loss 0.2680 (0.2572)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
11/27 10:18:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][351/351]	Step 42183	lr 0.00148	Loss 0.3133 (0.2611)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.5%)	
11/27 10:18:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [141/149] Final Prec@1 92.7889%
11/27 10:18:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][39/40]	Step 42184	Loss 1.4623	Prec@(1,5) (64.5%, 88.8%)
11/27 10:18:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 64.5000%
11/27 10:18:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/27 10:18:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][100/351]	Step 42284	lr 0.00138	Loss 0.2668 (0.2485)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.5%)	
11/27 10:19:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][200/351]	Step 42384	lr 0.00138	Loss 0.3359 (0.2560)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.5%)	
11/27 10:20:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][300/351]	Step 42484	lr 0.00138	Loss 0.2026 (0.2582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/27 10:20:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][351/351]	Step 42535	lr 0.00138	Loss 0.2406 (0.2583)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/27 10:20:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [142/149] Final Prec@1 92.7356%
11/27 10:20:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][39/40]	Step 42536	Loss 1.4889	Prec@(1,5) (63.8%, 88.6%)
11/27 10:20:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 63.8800%
11/27 10:20:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/27 10:21:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][100/351]	Step 42636	lr 0.00129	Loss 0.2324 (0.2415)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
11/27 10:21:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][200/351]	Step 42736	lr 0.00129	Loss 0.1994 (0.2492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
11/27 10:22:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][300/351]	Step 42836	lr 0.00129	Loss 0.2552 (0.2529)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
11/27 10:22:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][351/351]	Step 42887	lr 0.00129	Loss 0.2994 (0.2532)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
11/27 10:22:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [143/149] Final Prec@1 92.9133%
11/27 10:23:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][39/40]	Step 42888	Loss 1.4815	Prec@(1,5) (64.6%, 88.9%)
11/27 10:23:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 64.6200%
11/27 10:23:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.6200%
11/27 10:23:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][100/351]	Step 42988	lr 0.00121	Loss 0.1868 (0.2426)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
11/27 10:24:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][200/351]	Step 43088	lr 0.00121	Loss 0.3248 (0.2442)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
11/27 10:25:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][300/351]	Step 43188	lr 0.00121	Loss 0.2297 (0.2482)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
11/27 10:25:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][351/351]	Step 43239	lr 0.00121	Loss 0.3190 (0.2491)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
11/27 10:25:28午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [144/149] Final Prec@1 93.1311%
11/27 10:25:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][39/40]	Step 43240	Loss 1.5003	Prec@(1,5) (64.7%, 88.4%)
11/27 10:25:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 64.6600%
11/27 10:25:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.6600%
11/27 10:26:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][100/351]	Step 43340	lr 0.00115	Loss 0.2571 (0.2321)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
11/27 10:26:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][200/351]	Step 43440	lr 0.00115	Loss 0.1998 (0.2393)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
11/27 10:27:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][300/351]	Step 43540	lr 0.00115	Loss 0.2059 (0.2434)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
11/27 10:27:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][351/351]	Step 43591	lr 0.00115	Loss 0.2641 (0.2452)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
11/27 10:27:56午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [145/149] Final Prec@1 93.2867%
11/27 10:28:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][39/40]	Step 43592	Loss 1.4936	Prec@(1,5) (64.3%, 88.6%)
11/27 10:28:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 64.2600%
11/27 10:28:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.6600%
11/27 10:28:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][100/351]	Step 43692	lr 0.00109	Loss 0.1619 (0.2391)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.6%)	
11/27 10:29:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][200/351]	Step 43792	lr 0.00109	Loss 0.2989 (0.2439)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.6%)	
11/27 10:30:04午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][300/351]	Step 43892	lr 0.00109	Loss 0.1862 (0.2441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.6%)	
11/27 10:30:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][351/351]	Step 43943	lr 0.00109	Loss 0.2371 (0.2449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.6%)	
11/27 10:30:25午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [146/149] Final Prec@1 93.3511%
11/27 10:30:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][39/40]	Step 43944	Loss 1.4851	Prec@(1,5) (64.4%, 88.8%)
11/27 10:30:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 64.4400%
11/27 10:30:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.6600%
11/27 10:31:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][100/351]	Step 44044	lr 0.00105	Loss 0.1894 (0.2325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.8%)	
11/27 10:31:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][200/351]	Step 44144	lr 0.00105	Loss 0.2145 (0.2365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/27 10:32:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][300/351]	Step 44244	lr 0.00105	Loss 0.2462 (0.2377)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/27 10:32:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][351/351]	Step 44295	lr 0.00105	Loss 0.1887 (0.2380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/27 10:32:53午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [147/149] Final Prec@1 93.5867%
11/27 10:32:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][39/40]	Step 44296	Loss 1.4867	Prec@(1,5) (65.0%, 88.6%)
11/27 10:32:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 65.0200%
11/27 10:32:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0200%
11/27 10:33:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][100/351]	Step 44396	lr 0.00102	Loss 0.2088 (0.2252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.8%)	
11/27 10:34:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][200/351]	Step 44496	lr 0.00102	Loss 0.1598 (0.2321)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
11/27 10:35:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][300/351]	Step 44596	lr 0.00102	Loss 0.1920 (0.2341)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/27 10:35:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][351/351]	Step 44647	lr 0.00102	Loss 0.2116 (0.2371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
11/27 10:35:21午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [148/149] Final Prec@1 93.5178%
11/27 10:35:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][39/40]	Step 44648	Loss 1.4892	Prec@(1,5) (64.8%, 88.6%)
11/27 10:35:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 64.8200%
11/27 10:35:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0200%
11/27 10:36:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][100/351]	Step 44748	lr 0.00101	Loss 0.1885 (0.2218)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.7%)	
11/27 10:36:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][200/351]	Step 44848	lr 0.00101	Loss 0.1812 (0.2304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.9%, 99.7%)	
11/27 10:37:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][300/351]	Step 44948	lr 0.00101	Loss 0.2193 (0.2347)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/27 10:37:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][351/351]	Step 44999	lr 0.00101	Loss 0.2397 (0.2345)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/27 10:37:50午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [149/149] Final Prec@1 93.6222%
11/27 10:37:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][39/40]	Step 45000	Loss 1.4961	Prec@(1,5) (64.4%, 88.3%)
11/27 10:37:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 64.4400%
11/27 10:37:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0200%
11/27 10:37:56午前 searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 65.0200%
11/27 10:37:56午前 searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
