12/20 06:55:47PM parser.py:28 [INFO] 
12/20 06:55:47PM parser.py:29 [INFO] Parameters:
12/20 06:55:47PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g-1_0-50/DAG
12/20 06:55:47PM parser.py:31 [INFO] T=10.0
12/20 06:55:47PM parser.py:31 [INFO] ADVANCED=1
12/20 06:55:47PM parser.py:31 [INFO] ALPHA_LR=0.0003
12/20 06:55:47PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/20 06:55:47PM parser.py:31 [INFO] ARCH_CRITERION=expected
12/20 06:55:47PM parser.py:31 [INFO] BATCH_SIZE=64
12/20 06:55:47PM parser.py:31 [INFO] CASCADE=0
12/20 06:55:47PM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/20 06:55:47PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[0, 50]
12/20 06:55:47PM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/20 06:55:47PM parser.py:31 [INFO] DATA_PATH=../data/
12/20 06:55:47PM parser.py:31 [INFO] DATASET=cifar100
12/20 06:55:47PM parser.py:31 [INFO] DEPTH_COEF=0.0
12/20 06:55:47PM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/20 06:55:47PM parser.py:31 [INFO] DISCRETE=1
12/20 06:55:47PM parser.py:31 [INFO] EPOCHS=50
12/20 06:55:47PM parser.py:31 [INFO] EVAL_EPOCHS=100
12/20 06:55:47PM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g-1_0-50
12/20 06:55:47PM parser.py:31 [INFO] FINAL_L=0.0
12/20 06:55:47PM parser.py:31 [INFO] G=-1.0
12/20 06:55:47PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/20 06:55:47PM parser.py:31 [INFO] GPUS=[0]
12/20 06:55:47PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/20 06:55:47PM parser.py:31 [INFO] INIT_CHANNELS=16
12/20 06:55:47PM parser.py:31 [INFO] L=0.0
12/20 06:55:47PM parser.py:31 [INFO] LAYERS=32
12/20 06:55:47PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/20 06:55:47PM parser.py:31 [INFO] NAME=Curriculum
12/20 06:55:47PM parser.py:31 [INFO] NONKD=1
12/20 06:55:47PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g-1_0-50
12/20 06:55:47PM parser.py:31 [INFO] PCDARTS=0
12/20 06:55:47PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g-1_0-50/plots
12/20 06:55:47PM parser.py:31 [INFO] PRINT_FREQ=100
12/20 06:55:47PM parser.py:31 [INFO] RESET=0
12/20 06:55:47PM parser.py:31 [INFO] RESUME_PATH=None
12/20 06:55:47PM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g-1_0-50
12/20 06:55:47PM parser.py:31 [INFO] SEED=0
12/20 06:55:47PM parser.py:31 [INFO] SHARE_STAGE=0
12/20 06:55:47PM parser.py:31 [INFO] SLIDE_WINDOW=3
12/20 06:55:47PM parser.py:31 [INFO] SPEC_CELL=1
12/20 06:55:47PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/20 06:55:47PM parser.py:31 [INFO] TEACHER_NAME=none
12/20 06:55:47PM parser.py:31 [INFO] TEACHER_PATH=none
12/20 06:55:47PM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/20 06:55:47PM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
12/20 06:55:47PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/20 06:55:47PM parser.py:31 [INFO] W_LR=0.025
12/20 06:55:47PM parser.py:31 [INFO] W_LR_MIN=0.001
12/20 06:55:47PM parser.py:31 [INFO] W_MOMENTUM=0.9
12/20 06:55:47PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/20 06:55:47PM parser.py:31 [INFO] WORKERS=4
12/20 06:55:47PM parser.py:32 [INFO] 
12/20 06:55:49PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/20 06:55:49PM searchEvalStage_curriculum_trainer.py:151 [INFO] --> Curriculum part A finished. Part B begins!
12/20 06:56:40PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3537 (4.5255)	Arch Loss -1.9460 (-1.7321)	Arch Hard Loss 4.3573 (4.5163)	Arch Beta Loss 6.3034 (6.2484)	Arch depth Loss -0.0380 (-0.0181)	Prec@(1,5) (2.7%, 11.0%)	
12/20 06:57:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1503 (4.3811)	Arch Loss -2.1563 (-1.9275)	Arch Hard Loss 4.2618 (4.3771)	Arch Beta Loss 6.4181 (6.3046)	Arch depth Loss -0.0854 (-0.0396)	Prec@(1,5) (3.6%, 14.7%)	
12/20 06:58:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9834 (4.2832)	Arch Loss -2.5885 (-2.0849)	Arch Hard Loss 3.9488 (4.2775)	Arch Beta Loss 6.5373 (6.3624)	Arch depth Loss -0.1412 (-0.0641)	Prec@(1,5) (4.3%, 17.4%)	
12/20 06:59:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8091 (4.2205)	Arch Loss -2.7422 (-2.2043)	Arch Hard Loss 3.9055 (4.2113)	Arch Beta Loss 6.6478 (6.4156)	Arch depth Loss -0.1982 (-0.0884)	Prec@(1,5) (5.0%, 19.2%)	
12/20 06:59:02PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  0/149] Final Prec@1 5.0040%
12/20 06:59:08PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9719	Prec@(1,5) (7.7%, 27.2%)
12/20 06:59:15PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9589	Prec@(1,5) (7.7%, 27.3%)
12/20 06:59:21PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9570	Prec@(1,5) (7.8%, 27.5%)
12/20 06:59:27PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9577	Prec@(1,5) (7.7%, 27.3%)
12/20 06:59:27PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 7.6840%
12/20 06:59:27PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[8, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[9, 11])
12/20 06:59:28PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 7.6840%
12/20 07:00:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.025	Loss 3.8941 (3.9345)	Arch Loss -2.7981 (-2.7958)	Arch Hard Loss 3.9783 (3.9171)	Arch Beta Loss 6.7764 (6.7130)	Arch depth Loss -0.2674 (-0.2332)	Prec@(1,5) (7.9%, 28.3%)	
12/20 07:01:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.025	Loss 3.7878 (3.8975)	Arch Loss -3.1046 (-2.9090)	Arch Hard Loss 3.8035 (3.8689)	Arch Beta Loss 6.9081 (6.7778)	Arch depth Loss -0.3415 (-0.2686)	Prec@(1,5) (8.6%, 29.3%)	
12/20 07:01:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.025	Loss 3.8556 (3.8602)	Arch Loss -3.4418 (-3.0071)	Arch Hard Loss 3.6019 (3.8369)	Arch Beta Loss 7.0437 (6.8440)	Arch depth Loss -0.4149 (-0.3052)	Prec@(1,5) (9.4%, 30.6%)	
12/20 07:02:39PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.025	Loss 3.9073 (3.8223)	Arch Loss -3.1396 (-3.1010)	Arch Hard Loss 4.0310 (3.8038)	Arch Beta Loss 7.1706 (6.9048)	Arch depth Loss -0.4828 (-0.3383)	Prec@(1,5) (9.8%, 31.9%)	
12/20 07:02:39PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  1/149] Final Prec@1 9.8200%
12/20 07:02:46PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6680	Prec@(1,5) (12.7%, 35.9%)
12/20 07:02:53PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6597	Prec@(1,5) (12.9%, 36.3%)
12/20 07:03:00PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6653	Prec@(1,5) (12.6%, 36.3%)
12/20 07:03:05PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6598	Prec@(1,5) (12.5%, 36.5%)
12/20 07:03:06PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 12.5040%
12/20 07:03:06PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:03:06PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 12.5040%
12/20 07:03:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02499	Loss 3.7729 (3.6470)	Arch Loss -3.7035 (-3.6157)	Arch Hard Loss 3.6131 (3.6288)	Arch Beta Loss 7.3165 (7.2446)	Arch depth Loss -0.5583 (-0.5214)	Prec@(1,5) (12.9%, 37.2%)	
12/20 07:04:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02499	Loss 3.5230 (3.6104)	Arch Loss -3.9570 (-3.7034)	Arch Hard Loss 3.5080 (3.6145)	Arch Beta Loss 7.4651 (7.3179)	Arch depth Loss -0.6335 (-0.5591)	Prec@(1,5) (13.8%, 38.5%)	
12/20 07:05:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02499	Loss 3.4650 (3.5752)	Arch Loss -4.0154 (-3.8061)	Arch Hard Loss 3.6031 (3.5865)	Arch Beta Loss 7.6184 (7.3926)	Arch depth Loss -0.7066 (-0.5964)	Prec@(1,5) (14.4%, 39.3%)	
12/20 07:06:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02499	Loss 3.4964 (3.5530)	Arch Loss -4.3999 (-3.8961)	Arch Hard Loss 3.3590 (3.5649)	Arch Beta Loss 7.7588 (7.4610)	Arch depth Loss -0.7724 (-0.6296)	Prec@(1,5) (14.7%, 39.9%)	
12/20 07:06:20PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  2/149] Final Prec@1 14.7160%
12/20 07:06:27PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.5310	Prec@(1,5) (14.5%, 40.8%)
12/20 07:06:33PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.5432	Prec@(1,5) (14.1%, 40.5%)
12/20 07:06:39PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.5431	Prec@(1,5) (14.3%, 40.7%)
12/20 07:06:45PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.5474	Prec@(1,5) (14.3%, 40.6%)
12/20 07:06:45PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 14.2720%
12/20 07:06:45PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:06:46PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 14.2720%
12/20 07:07:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02498	Loss 3.5743 (3.4248)	Arch Loss -4.4972 (-4.4169)	Arch Hard Loss 3.4238 (3.4243)	Arch Beta Loss 7.9210 (7.8413)	Arch depth Loss -0.8466 (-0.8107)	Prec@(1,5) (16.6%, 43.4%)	
12/20 07:08:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02498	Loss 3.1252 (3.3913)	Arch Loss -4.4563 (-4.5268)	Arch Hard Loss 3.6315 (3.3964)	Arch Beta Loss 8.0878 (7.9232)	Arch depth Loss -0.9191 (-0.8467)	Prec@(1,5) (17.3%, 44.4%)	
12/20 07:09:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02498	Loss 3.2353 (3.3652)	Arch Loss -4.7470 (-4.6288)	Arch Hard Loss 3.5114 (3.3777)	Arch Beta Loss 8.2584 (8.0066)	Arch depth Loss -0.9889 (-0.8828)	Prec@(1,5) (17.7%, 45.2%)	
12/20 07:09:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02498	Loss 3.0796 (3.3455)	Arch Loss -5.3228 (-4.7199)	Arch Hard Loss 3.0925 (3.3630)	Arch Beta Loss 8.4152 (8.0829)	Arch depth Loss -1.0513 (-0.9147)	Prec@(1,5) (18.0%, 45.8%)	
12/20 07:09:58PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  3/149] Final Prec@1 18.0200%
12/20 07:10:05PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.3158	Prec@(1,5) (18.8%, 46.6%)
12/20 07:10:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.3114	Prec@(1,5) (18.6%, 46.9%)
12/20 07:10:18PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.3170	Prec@(1,5) (18.6%, 46.7%)
12/20 07:10:24PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.3198	Prec@(1,5) (18.6%, 46.6%)
12/20 07:10:24PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 18.5920%
12/20 07:10:24PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:10:25PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 18.5920%
12/20 07:11:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02496	Loss 3.0967 (3.2086)	Arch Loss -5.4576 (-5.1991)	Arch Hard Loss 3.1375 (3.3076)	Arch Beta Loss 8.5951 (8.5068)	Arch depth Loss -1.1206 (-1.0865)	Prec@(1,5) (20.7%, 50.4%)	
12/20 07:12:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02496	Loss 3.1748 (3.1950)	Arch Loss -5.5569 (-5.3295)	Arch Hard Loss 3.2188 (3.2669)	Arch Beta Loss 8.7758 (8.5965)	Arch depth Loss -1.1911 (-1.1214)	Prec@(1,5) (21.3%, 50.8%)	
12/20 07:12:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02496	Loss 2.6790 (3.1919)	Arch Loss -5.7143 (-5.4438)	Arch Hard Loss 3.2421 (3.2427)	Arch Beta Loss 8.9563 (8.6865)	Arch depth Loss -1.2587 (-1.1561)	Prec@(1,5) (21.2%, 50.7%)	
12/20 07:13:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02496	Loss 2.9926 (3.1802)	Arch Loss -6.1368 (-5.5526)	Arch Hard Loss 2.9838 (3.2153)	Arch Beta Loss 9.1207 (8.7679)	Arch depth Loss -1.3193 (-1.1869)	Prec@(1,5) (21.4%, 50.9%)	
12/20 07:13:38PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  4/149] Final Prec@1 21.3720%
12/20 07:13:45PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1633	Prec@(1,5) (21.8%, 51.3%)
12/20 07:13:52PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.1281	Prec@(1,5) (22.2%, 52.3%)
12/20 07:13:58PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.1251	Prec@(1,5) (22.1%, 52.6%)
12/20 07:14:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.1250	Prec@(1,5) (22.1%, 52.5%)
12/20 07:14:04PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 22.1360%
12/20 07:14:05PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:14:05PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 22.1360%
12/20 07:14:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02493	Loss 3.3241 (3.0442)	Arch Loss -6.1556 (-6.1409)	Arch Hard Loss 3.1505 (3.0745)	Arch Beta Loss 9.3061 (9.2154)	Arch depth Loss -1.3827 (-1.3510)	Prec@(1,5) (23.7%, 53.6%)	
12/20 07:15:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02493	Loss 3.3331 (3.0425)	Arch Loss -6.1079 (-6.2122)	Arch Hard Loss 3.3826 (3.0950)	Arch Beta Loss 9.4905 (9.3073)	Arch depth Loss -1.4463 (-1.3831)	Prec@(1,5) (24.0%, 53.7%)	
12/20 07:16:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02493	Loss 2.8965 (3.0388)	Arch Loss -6.8667 (-6.3221)	Arch Hard Loss 2.8078 (3.0772)	Arch Beta Loss 9.6745 (9.3993)	Arch depth Loss -1.5071 (-1.4146)	Prec@(1,5) (24.1%, 53.8%)	
12/20 07:17:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02493	Loss 2.6764 (3.0252)	Arch Loss -6.9418 (-6.4245)	Arch Hard Loss 2.8989 (3.0577)	Arch Beta Loss 9.8407 (9.4822)	Arch depth Loss -1.5601 (-1.4421)	Prec@(1,5) (24.3%, 54.4%)	
12/20 07:17:19PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  5/149] Final Prec@1 24.2440%
12/20 07:17:26PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.9914	Prec@(1,5) (24.4%, 56.3%)
12/20 07:17:32PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.9961	Prec@(1,5) (24.6%, 56.2%)
12/20 07:17:39PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.0044	Prec@(1,5) (24.6%, 55.7%)
12/20 07:17:45PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.9955	Prec@(1,5) (24.6%, 55.8%)
12/20 07:17:45PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 24.6120%
12/20 07:17:45PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:17:46PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 24.6120%
12/20 07:18:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02491	Loss 2.9173 (2.8701)	Arch Loss -6.9813 (-6.9685)	Arch Hard Loss 3.0449 (2.9669)	Arch Beta Loss 10.0262 (9.9354)	Arch depth Loss -1.6182 (-1.5896)	Prec@(1,5) (27.6%, 58.7%)	
12/20 07:19:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02491	Loss 2.9366 (2.8909)	Arch Loss -7.2682 (-7.0670)	Arch Hard Loss 2.9397 (2.9600)	Arch Beta Loss 10.2079 (10.0269)	Arch depth Loss -1.6748 (-1.6183)	Prec@(1,5) (26.6%, 57.9%)	
12/20 07:20:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02491	Loss 3.1061 (2.8890)	Arch Loss -7.6004 (-7.1768)	Arch Hard Loss 2.7890 (2.9412)	Arch Beta Loss 10.3894 (10.1179)	Arch depth Loss -1.7275 (-1.6460)	Prec@(1,5) (26.5%, 58.1%)	
12/20 07:20:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02491	Loss 3.0486 (2.8885)	Arch Loss -7.6362 (-7.2499)	Arch Hard Loss 2.9131 (2.9492)	Arch Beta Loss 10.5493 (10.1991)	Arch depth Loss -1.7732 (-1.6701)	Prec@(1,5) (26.8%, 58.1%)	
12/20 07:20:58PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  6/149] Final Prec@1 26.7560%
12/20 07:21:05PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.8752	Prec@(1,5) (27.0%, 58.7%)
12/20 07:21:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.8690	Prec@(1,5) (27.1%, 59.0%)
12/20 07:21:18PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.8743	Prec@(1,5) (26.6%, 58.9%)
12/20 07:21:24PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.8820	Prec@(1,5) (26.6%, 58.7%)
12/20 07:21:24PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 26.6520%
12/20 07:21:24PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:21:25PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 26.6520%
12/20 07:22:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02487	Loss 3.0163 (2.7739)	Arch Loss -7.8911 (-7.7580)	Arch Hard Loss 2.8374 (2.8828)	Arch Beta Loss 10.7285 (10.6408)	Arch depth Loss -1.8244 (-1.7995)	Prec@(1,5) (29.1%, 61.3%)	
12/20 07:23:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02487	Loss 2.7165 (2.7698)	Arch Loss -7.9690 (-7.8651)	Arch Hard Loss 2.9342 (2.8638)	Arch Beta Loss 10.9032 (10.7289)	Arch depth Loss -1.8742 (-1.8245)	Prec@(1,5) (29.0%, 61.1%)	
12/20 07:23:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02487	Loss 3.0783 (2.7691)	Arch Loss -7.7623 (-7.9499)	Arch Hard Loss 3.3145 (2.8664)	Arch Beta Loss 11.0768 (10.8162)	Arch depth Loss -1.9207 (-1.8489)	Prec@(1,5) (29.3%, 61.1%)	
12/20 07:24:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02487	Loss 2.8907 (2.7631)	Arch Loss -8.4724 (-8.0402)	Arch Hard Loss 2.7581 (2.8542)	Arch Beta Loss 11.2305 (10.8944)	Arch depth Loss -1.9633 (-1.8704)	Prec@(1,5) (29.3%, 61.2%)	
12/20 07:24:36PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  7/149] Final Prec@1 29.2600%
12/20 07:24:43PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.8557	Prec@(1,5) (28.0%, 59.3%)
12/20 07:24:50PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.8335	Prec@(1,5) (28.2%, 59.9%)
12/20 07:24:56PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.8277	Prec@(1,5) (28.1%, 60.1%)
12/20 07:25:02PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.8357	Prec@(1,5) (28.0%, 59.9%)
12/20 07:25:02PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 27.9560%
12/20 07:25:02PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:25:03PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 27.9560%
12/20 07:25:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02483	Loss 2.5517 (2.6584)	Arch Loss -8.1514 (-8.5285)	Arch Hard Loss 3.2484 (2.7884)	Arch Beta Loss 11.3998 (11.3169)	Arch depth Loss -2.0070 (-1.9857)	Prec@(1,5) (30.8%, 64.3%)	
12/20 07:26:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02483	Loss 2.4615 (2.6629)	Arch Loss -8.3290 (-8.6078)	Arch Hard Loss 3.2347 (2.7922)	Arch Beta Loss 11.5637 (11.3999)	Arch depth Loss -2.0508 (-2.0076)	Prec@(1,5) (30.6%, 64.3%)	
12/20 07:27:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02483	Loss 2.6092 (2.6639)	Arch Loss -9.0030 (-8.6952)	Arch Hard Loss 2.7235 (2.7867)	Arch Beta Loss 11.7265 (11.4819)	Arch depth Loss -2.0913 (-2.0288)	Prec@(1,5) (31.0%, 64.2%)	
12/20 07:28:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02483	Loss 2.5596 (2.6637)	Arch Loss -9.1505 (-8.7804)	Arch Hard Loss 2.7199 (2.7748)	Arch Beta Loss 11.8704 (11.5552)	Arch depth Loss -2.1266 (-2.0474)	Prec@(1,5) (31.0%, 64.1%)	
12/20 07:28:18PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  8/149] Final Prec@1 31.0080%
12/20 07:28:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.6869	Prec@(1,5) (31.0%, 63.1%)
12/20 07:28:32PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.7137	Prec@(1,5) (30.4%, 62.7%)
12/20 07:28:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.7243	Prec@(1,5) (30.3%, 62.3%)
12/20 07:28:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.7281	Prec@(1,5) (30.1%, 62.1%)
12/20 07:28:44PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 30.1360%
12/20 07:28:44PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:28:45PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 30.1360%
12/20 07:29:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02479	Loss 2.7329 (2.5755)	Arch Loss -9.1948 (-9.2086)	Arch Hard Loss 2.8332 (2.7423)	Arch Beta Loss 12.0280 (11.9508)	Arch depth Loss -2.1657 (-2.1468)	Prec@(1,5) (32.6%, 65.7%)	
12/20 07:30:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02479	Loss 2.6321 (2.5897)	Arch Loss -9.3312 (-9.3034)	Arch Hard Loss 2.8485 (2.7244)	Arch Beta Loss 12.1796 (12.0278)	Arch depth Loss -2.2041 (-2.1661)	Prec@(1,5) (32.5%, 65.4%)	
12/20 07:31:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02479	Loss 2.4820 (2.5800)	Arch Loss -9.7768 (-9.3955)	Arch Hard Loss 2.5525 (2.7083)	Arch Beta Loss 12.3293 (12.1038)	Arch depth Loss -2.2403 (-2.1849)	Prec@(1,5) (32.8%, 65.6%)	
12/20 07:31:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02479	Loss 2.5102 (2.5782)	Arch Loss -9.6140 (-9.4716)	Arch Hard Loss 2.8471 (2.6996)	Arch Beta Loss 12.4610 (12.1712)	Arch depth Loss -2.2728 (-2.2014)	Prec@(1,5) (32.7%, 65.5%)	
12/20 07:31:59PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  9/149] Final Prec@1 32.7080%
12/20 07:32:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.6673	Prec@(1,5) (31.6%, 64.5%)
12/20 07:32:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.6451	Prec@(1,5) (32.4%, 64.8%)
12/20 07:32:19PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.6540	Prec@(1,5) (32.2%, 64.4%)
12/20 07:32:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.6567	Prec@(1,5) (31.9%, 64.1%)
12/20 07:32:25PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 31.9360%
12/20 07:32:25PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:32:26PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.9360%
12/20 07:33:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02474	Loss 2.5854 (2.4761)	Arch Loss -9.7715 (-9.8214)	Arch Hard Loss 2.8346 (2.7141)	Arch Beta Loss 12.6061 (12.5354)	Arch depth Loss -2.3082 (-2.2913)	Prec@(1,5) (34.3%, 68.2%)	
12/20 07:34:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02474	Loss 2.7243 (2.4966)	Arch Loss -10.0714 (-9.9311)	Arch Hard Loss 2.6743 (2.6752)	Arch Beta Loss 12.7457 (12.6063)	Arch depth Loss -2.3410 (-2.3080)	Prec@(1,5) (33.9%, 67.7%)	
12/20 07:34:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02474	Loss 2.5828 (2.5083)	Arch Loss -10.4790 (-10.0145)	Arch Hard Loss 2.4037 (2.6615)	Arch Beta Loss 12.8827 (12.6760)	Arch depth Loss -2.3738 (-2.3245)	Prec@(1,5) (33.8%, 67.5%)	
12/20 07:35:40PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02474	Loss 2.6081 (2.5038)	Arch Loss -10.4814 (-10.0917)	Arch Hard Loss 2.5208 (2.6460)	Arch Beta Loss 13.0022 (12.7377)	Arch depth Loss -2.4005 (-2.3390)	Prec@(1,5) (34.0%, 67.6%)	
12/20 07:35:41PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 10/149] Final Prec@1 33.9360%
12/20 07:35:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.6681	Prec@(1,5) (32.1%, 63.4%)
12/20 07:35:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.6517	Prec@(1,5) (32.0%, 64.1%)
12/20 07:36:01PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.6662	Prec@(1,5) (31.7%, 63.9%)
12/20 07:36:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.6582	Prec@(1,5) (31.9%, 64.0%)
12/20 07:36:07PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 31.9240%
12/20 07:36:07PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:36:07PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.9360%
12/20 07:36:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02468	Loss 2.0875 (2.4068)	Arch Loss -10.3015 (-10.4671)	Arch Hard Loss 2.8325 (2.6027)	Arch Beta Loss 13.1341 (13.0699)	Arch depth Loss -2.4302 (-2.4160)	Prec@(1,5) (36.1%, 69.3%)	
12/20 07:37:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02468	Loss 2.6253 (2.4100)	Arch Loss -10.3750 (-10.5295)	Arch Hard Loss 2.8865 (2.6047)	Arch Beta Loss 13.2615 (13.1342)	Arch depth Loss -2.4584 (-2.4304)	Prec@(1,5) (36.0%, 69.2%)	
12/20 07:38:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02468	Loss 2.6019 (2.4202)	Arch Loss -11.0802 (-10.6048)	Arch Hard Loss 2.3053 (2.5928)	Arch Beta Loss 13.3855 (13.1976)	Arch depth Loss -2.4870 (-2.4444)	Prec@(1,5) (36.0%, 69.0%)	
12/20 07:39:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02468	Loss 2.3730 (2.4230)	Arch Loss -10.9898 (-10.6701)	Arch Hard Loss 2.5050 (2.5837)	Arch Beta Loss 13.4948 (13.2538)	Arch depth Loss -2.5127 (-2.4572)	Prec@(1,5) (35.9%, 69.0%)	
12/20 07:39:21PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 11/149] Final Prec@1 35.8880%
12/20 07:39:28PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.5395	Prec@(1,5) (34.2%, 66.6%)
12/20 07:39:34PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.5275	Prec@(1,5) (34.4%, 67.2%)
12/20 07:39:41PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.5296	Prec@(1,5) (34.3%, 66.9%)
12/20 07:39:46PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.5314	Prec@(1,5) (34.4%, 66.9%)
12/20 07:39:47PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 34.3400%
12/20 07:39:47PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:39:47PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 34.3400%
12/20 07:40:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02462	Loss 2.2994 (2.3292)	Arch Loss -11.2719 (-11.0000)	Arch Hard Loss 2.3431 (2.5566)	Arch Beta Loss 13.6150 (13.5566)	Arch depth Loss -2.5398 (-2.5268)	Prec@(1,5) (37.6%, 71.4%)	
12/20 07:41:26PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02462	Loss 2.3528 (2.3476)	Arch Loss -11.4066 (-11.0433)	Arch Hard Loss 2.3237 (2.5717)	Arch Beta Loss 13.7302 (13.6150)	Arch depth Loss -2.5639 (-2.5397)	Prec@(1,5) (37.8%, 70.9%)	
12/20 07:42:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02462	Loss 2.3787 (2.3495)	Arch Loss -11.1808 (-11.1186)	Arch Hard Loss 2.6606 (2.5537)	Arch Beta Loss 13.8414 (13.6722)	Arch depth Loss -2.5855 (-2.5514)	Prec@(1,5) (37.7%, 70.7%)	
12/20 07:43:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02462	Loss 2.0291 (2.3562)	Arch Loss -11.3741 (-11.1839)	Arch Hard Loss 2.5665 (2.5390)	Arch Beta Loss 13.9406 (13.7229)	Arch depth Loss -2.6054 (-2.5616)	Prec@(1,5) (37.6%, 70.5%)	
12/20 07:43:01PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 12/149] Final Prec@1 37.6320%
12/20 07:43:07PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.4971	Prec@(1,5) (35.4%, 67.7%)
12/20 07:43:14PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.4982	Prec@(1,5) (35.1%, 67.3%)
12/20 07:43:20PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.4898	Prec@(1,5) (35.3%, 67.6%)
12/20 07:43:26PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.5033	Prec@(1,5) (35.2%, 67.2%)
12/20 07:43:26PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 35.1840%
12/20 07:43:26PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:43:27PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 35.1840%
12/20 07:44:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02456	Loss 2.3459 (2.2629)	Arch Loss -11.6244 (-11.4981)	Arch Hard Loss 2.4242 (2.4980)	Arch Beta Loss 14.0486 (13.9962)	Arch depth Loss -2.6258 (-2.6160)	Prec@(1,5) (38.7%, 72.6%)	
12/20 07:45:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02456	Loss 2.0971 (2.2988)	Arch Loss -11.6465 (-11.5529)	Arch Hard Loss 2.5061 (2.4959)	Arch Beta Loss 14.1526 (14.0488)	Arch depth Loss -2.6456 (-2.6259)	Prec@(1,5) (38.3%, 71.6%)	
12/20 07:45:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02456	Loss 2.0918 (2.2957)	Arch Loss -11.6887 (-11.6046)	Arch Hard Loss 2.5673 (2.4963)	Arch Beta Loss 14.2560 (14.1009)	Arch depth Loss -2.6644 (-2.6356)	Prec@(1,5) (38.6%, 71.6%)	
12/20 07:46:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02456	Loss 2.0713 (2.2979)	Arch Loss -12.0367 (-11.6585)	Arch Hard Loss 2.3099 (2.4889)	Arch Beta Loss 14.3466 (14.1474)	Arch depth Loss -2.6822 (-2.6443)	Prec@(1,5) (38.4%, 71.7%)	
12/20 07:46:42PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 13/149] Final Prec@1 38.3600%
12/20 07:46:49PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.4227	Prec@(1,5) (36.1%, 69.6%)
12/20 07:46:55PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.4318	Prec@(1,5) (36.2%, 69.5%)
12/20 07:47:02PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.4133	Prec@(1,5) (36.8%, 69.5%)
12/20 07:47:08PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.4159	Prec@(1,5) (36.9%, 69.5%)
12/20 07:47:08PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 36.9040%
12/20 07:47:08PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:47:08PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.9040%
12/20 07:47:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02449	Loss 2.1634 (2.1908)	Arch Loss -12.0479 (-11.9031)	Arch Hard Loss 2.3970 (2.4935)	Arch Beta Loss 14.4449 (14.3966)	Arch depth Loss -2.7010 (-2.6919)	Prec@(1,5) (40.9%, 74.4%)	
12/20 07:48:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02449	Loss 2.1732 (2.2231)	Arch Loss -12.1094 (-11.9586)	Arch Hard Loss 2.4299 (2.4861)	Arch Beta Loss 14.5393 (14.4447)	Arch depth Loss -2.7155 (-2.7003)	Prec@(1,5) (40.2%, 73.2%)	
12/20 07:49:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02449	Loss 2.1649 (2.2312)	Arch Loss -12.1624 (-12.0293)	Arch Hard Loss 2.4697 (2.4626)	Arch Beta Loss 14.6321 (14.4919)	Arch depth Loss -2.7303 (-2.7080)	Prec@(1,5) (39.9%, 73.0%)	
12/20 07:50:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02449	Loss 2.0929 (2.2361)	Arch Loss -12.1146 (-12.0757)	Arch Hard Loss 2.5988 (2.4579)	Arch Beta Loss 14.7134 (14.5337)	Arch depth Loss -2.7388 (-2.7142)	Prec@(1,5) (39.8%, 72.9%)	
12/20 07:50:19PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 14/149] Final Prec@1 39.7680%
12/20 07:50:26PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.3830	Prec@(1,5) (38.1%, 70.0%)
12/20 07:50:33PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.4041	Prec@(1,5) (37.5%, 69.8%)
12/20 07:50:39PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.4058	Prec@(1,5) (37.6%, 69.5%)
12/20 07:50:45PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.4085	Prec@(1,5) (37.5%, 69.5%)
12/20 07:50:45PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 37.5080%
12/20 07:50:45PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 07:50:45PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.5080%
12/20 07:51:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02441	Loss 2.3839 (2.1571)	Arch Loss -12.2465 (-12.3091)	Arch Hard Loss 2.5558 (2.4500)	Arch Beta Loss 14.8024 (14.7591)	Arch depth Loss -2.7486 (-2.7443)	Prec@(1,5) (41.8%, 74.8%)	
12/20 07:52:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02441	Loss 2.0461 (2.1675)	Arch Loss -12.6477 (-12.3593)	Arch Hard Loss 2.2391 (2.4427)	Arch Beta Loss 14.8868 (14.8020)	Arch depth Loss -2.7581 (-2.7490)	Prec@(1,5) (42.0%, 74.2%)	
12/20 07:53:11PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02441	Loss 2.2467 (2.1712)	Arch Loss -12.6561 (-12.4012)	Arch Hard Loss 2.3133 (2.4430)	Arch Beta Loss 14.9695 (14.8442)	Arch depth Loss -2.7679 (-2.7537)	Prec@(1,5) (41.6%, 74.3%)	
12/20 07:53:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02441	Loss 1.8358 (2.1764)	Arch Loss -13.0547 (-12.4450)	Arch Hard Loss 1.9887 (2.4368)	Arch Beta Loss 15.0434 (14.8818)	Arch depth Loss -2.7762 (-2.7580)	Prec@(1,5) (41.4%, 74.3%)	
12/20 07:53:55PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 15/149] Final Prec@1 41.3520%
12/20 07:54:02PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.3962	Prec@(1,5) (37.8%, 69.7%)
12/20 07:54:08PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.3650	Prec@(1,5) (38.1%, 70.3%)
12/20 07:54:15PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.3775	Prec@(1,5) (37.9%, 70.0%)
12/20 07:54:21PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.3714	Prec@(1,5) (37.9%, 70.2%)
12/20 07:54:21PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 37.9360%
12/20 07:54:21PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:54:21PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.9360%
12/20 07:55:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.02433	Loss 2.0488 (2.1046)	Arch Loss -13.1299 (-12.6771)	Arch Hard Loss 1.9935 (2.4070)	Arch Beta Loss 15.1234 (15.0841)	Arch depth Loss -2.7837 (-2.7803)	Prec@(1,5) (42.4%, 75.8%)	
12/20 07:56:01PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.02433	Loss 2.3805 (2.1216)	Arch Loss -12.7974 (-12.7153)	Arch Hard Loss 2.4029 (2.4078)	Arch Beta Loss 15.2003 (15.1231)	Arch depth Loss -2.7899 (-2.7835)	Prec@(1,5) (42.1%, 75.3%)	
12/20 07:56:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.02433	Loss 2.2175 (2.1321)	Arch Loss -12.7862 (-12.7455)	Arch Hard Loss 2.4890 (2.4160)	Arch Beta Loss 15.2752 (15.1615)	Arch depth Loss -2.7928 (-2.7860)	Prec@(1,5) (42.1%, 75.2%)	
12/20 07:57:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.02433	Loss 2.1506 (2.1346)	Arch Loss -12.8468 (-12.7959)	Arch Hard Loss 2.4952 (2.3996)	Arch Beta Loss 15.3419 (15.1955)	Arch depth Loss -2.7951 (-2.7878)	Prec@(1,5) (42.1%, 75.1%)	
12/20 07:57:35PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 16/149] Final Prec@1 42.1320%
12/20 07:57:42PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.3726	Prec@(1,5) (37.8%, 70.7%)
12/20 07:57:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.3513	Prec@(1,5) (38.1%, 70.9%)
12/20 07:57:55PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.3483	Prec@(1,5) (38.2%, 71.1%)
12/20 07:58:01PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.3447	Prec@(1,5) (38.4%, 71.2%)
12/20 07:58:01PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 38.3480%
12/20 07:58:01PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 07:58:02PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 38.3480%
12/20 07:58:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.02425	Loss 1.8987 (2.0146)	Arch Loss -12.9853 (-13.0062)	Arch Hard Loss 2.4304 (2.3734)	Arch Beta Loss 15.4158 (15.3795)	Arch depth Loss -2.7955 (-2.7952)	Prec@(1,5) (45.4%, 77.8%)	
12/20 07:59:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.02425	Loss 2.1191 (2.0568)	Arch Loss -13.0994 (-13.0372)	Arch Hard Loss 2.3871 (2.3784)	Arch Beta Loss 15.4865 (15.4156)	Arch depth Loss -2.7928 (-2.7947)	Prec@(1,5) (44.5%, 76.7%)	
12/20 08:00:31PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.02425	Loss 2.1141 (2.0759)	Arch Loss -13.4473 (-13.0706)	Arch Hard Loss 2.1069 (2.3799)	Arch Beta Loss 15.5542 (15.4505)	Arch depth Loss -2.7934 (-2.7942)	Prec@(1,5) (43.8%, 76.3%)	
12/20 08:01:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.02425	Loss 1.7548 (2.0836)	Arch Loss -13.4797 (-13.1068)	Arch Hard Loss 2.1348 (2.3746)	Arch Beta Loss 15.6145 (15.4814)	Arch depth Loss -2.7896 (-2.7935)	Prec@(1,5) (43.5%, 76.2%)	
12/20 08:01:16PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 17/149] Final Prec@1 43.5440%
12/20 08:01:23PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.3223	Prec@(1,5) (39.0%, 71.6%)
12/20 08:01:29PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.3159	Prec@(1,5) (39.2%, 71.9%)
12/20 08:01:36PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.3129	Prec@(1,5) (39.1%, 71.8%)
12/20 08:01:42PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.3122	Prec@(1,5) (39.1%, 71.6%)
12/20 08:01:42PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 39.0880%
12/20 08:01:42PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 08:01:42PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.0880%
12/20 08:02:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.02416	Loss 1.8880 (1.9880)	Arch Loss -13.0293 (-13.3326)	Arch Hard Loss 2.6512 (2.3161)	Arch Beta Loss 15.6804 (15.6487)	Arch depth Loss -2.7850 (-2.7879)	Prec@(1,5) (45.3%, 78.1%)	
12/20 08:03:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.02416	Loss 1.9647 (2.0220)	Arch Loss -13.7585 (-13.3373)	Arch Hard Loss 1.9846 (2.3431)	Arch Beta Loss 15.7431 (15.6805)	Arch depth Loss -2.7811 (-2.7854)	Prec@(1,5) (44.7%, 77.4%)	
12/20 08:04:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.02416	Loss 2.0749 (2.0243)	Arch Loss -13.2888 (-13.3618)	Arch Hard Loss 2.5173 (2.3503)	Arch Beta Loss 15.8061 (15.7120)	Arch depth Loss -2.7710 (-2.7823)	Prec@(1,5) (44.7%, 77.3%)	
12/20 08:04:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.02416	Loss 2.1119 (2.0402)	Arch Loss -14.1258 (-13.3949)	Arch Hard Loss 1.7346 (2.3451)	Arch Beta Loss 15.8603 (15.7400)	Arch depth Loss -2.7612 (-2.7783)	Prec@(1,5) (44.3%, 77.1%)	
12/20 08:04:57PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 18/149] Final Prec@1 44.2800%
12/20 08:05:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.3285	Prec@(1,5) (39.3%, 70.8%)
12/20 08:05:10PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.3088	Prec@(1,5) (39.4%, 71.4%)
12/20 08:05:17PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.3030	Prec@(1,5) (39.8%, 71.4%)
12/20 08:05:23PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.3102	Prec@(1,5) (39.6%, 71.4%)
12/20 08:05:23PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 39.5840%
12/20 08:05:23PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 08:05:23PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.5840%
12/20 08:06:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.02406	Loss 1.7441 (1.9327)	Arch Loss -13.3767 (-13.5683)	Arch Hard Loss 2.5434 (2.3226)	Arch Beta Loss 15.9201 (15.8909)	Arch depth Loss -2.7470 (-2.7544)	Prec@(1,5) (47.4%, 78.6%)	
12/20 08:07:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.02406	Loss 2.0754 (1.9711)	Arch Loss -13.6138 (-13.6035)	Arch Hard Loss 2.3643 (2.3167)	Arch Beta Loss 15.9781 (15.9201)	Arch depth Loss -2.7339 (-2.7467)	Prec@(1,5) (45.8%, 78.2%)	
12/20 08:07:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.02406	Loss 2.2128 (1.9830)	Arch Loss -14.1136 (-13.6497)	Arch Hard Loss 1.9203 (2.2991)	Arch Beta Loss 16.0338 (15.9488)	Arch depth Loss -2.7182 (-2.7397)	Prec@(1,5) (45.8%, 78.1%)	
12/20 08:08:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.02406	Loss 1.9107 (1.9939)	Arch Loss -13.8835 (-13.6830)	Arch Hard Loss 2.2004 (2.2912)	Arch Beta Loss 16.0839 (15.9742)	Arch depth Loss -2.7070 (-2.7334)	Prec@(1,5) (45.6%, 77.8%)	
12/20 08:08:37PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 19/149] Final Prec@1 45.5760%
12/20 08:08:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.3287	Prec@(1,5) (39.6%, 71.2%)
12/20 08:08:51PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.3385	Prec@(1,5) (39.3%, 71.0%)
12/20 08:08:57PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.3219	Prec@(1,5) (39.4%, 71.4%)
12/20 08:09:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.3156	Prec@(1,5) (39.4%, 71.6%)
12/20 08:09:03PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 39.4560%
12/20 08:09:03PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 08:09:03PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.5840%
12/20 08:09:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.02396	Loss 2.0679 (1.9063)	Arch Loss -14.0007 (-13.8334)	Arch Hard Loss 2.1377 (2.2783)	Arch Beta Loss 16.1383 (16.1117)	Arch depth Loss -2.6891 (-2.6980)	Prec@(1,5) (47.7%, 79.8%)	
12/20 08:10:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.02396	Loss 1.9936 (1.9231)	Arch Loss -13.3431 (-13.8530)	Arch Hard Loss 2.8491 (2.2856)	Arch Beta Loss 16.1922 (16.1386)	Arch depth Loss -2.6674 (-2.6884)	Prec@(1,5) (46.9%, 79.4%)	
12/20 08:11:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.02396	Loss 1.4741 (1.9363)	Arch Loss -14.1227 (-13.8709)	Arch Hard Loss 2.1185 (2.2940)	Arch Beta Loss 16.2412 (16.1648)	Arch depth Loss -2.6494 (-2.6785)	Prec@(1,5) (46.8%, 79.1%)	
12/20 08:12:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.02396	Loss 1.8226 (1.9511)	Arch Loss -14.3014 (-13.9009)	Arch Hard Loss 1.9851 (2.2868)	Arch Beta Loss 16.2865 (16.1877)	Arch depth Loss -2.6324 (-2.6697)	Prec@(1,5) (46.6%, 78.9%)	
12/20 08:12:18PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 20/149] Final Prec@1 46.5720%
12/20 08:12:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.3130	Prec@(1,5) (40.1%, 71.9%)
12/20 08:12:31PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.2956	Prec@(1,5) (40.2%, 71.9%)
12/20 08:12:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.3074	Prec@(1,5) (39.8%, 71.7%)
12/20 08:12:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.3076	Prec@(1,5) (40.0%, 71.7%)
12/20 08:12:44PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 39.9520%
12/20 08:12:44PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:12:44PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.9520%
12/20 08:13:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.02386	Loss 1.8778 (1.8411)	Arch Loss -13.5611 (-14.0251)	Arch Hard Loss 2.7736 (2.2860)	Arch Beta Loss 16.3347 (16.3111)	Arch depth Loss -2.6060 (-2.6180)	Prec@(1,5) (48.0%, 80.8%)	
12/20 08:14:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.02386	Loss 1.8832 (1.8804)	Arch Loss -13.7741 (-14.0628)	Arch Hard Loss 2.6084 (2.2722)	Arch Beta Loss 16.3825 (16.3350)	Arch depth Loss -2.5832 (-2.6058)	Prec@(1,5) (47.3%, 80.0%)	
12/20 08:15:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.02386	Loss 2.0644 (1.9073)	Arch Loss -14.4375 (-14.1014)	Arch Hard Loss 1.9918 (2.2575)	Arch Beta Loss 16.4293 (16.3588)	Arch depth Loss -2.5555 (-2.5939)	Prec@(1,5) (46.7%, 79.5%)	
12/20 08:15:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.02386	Loss 1.8527 (1.9182)	Arch Loss -14.2749 (-14.1208)	Arch Hard Loss 2.1967 (2.2593)	Arch Beta Loss 16.4716 (16.3801)	Arch depth Loss -2.5349 (-2.5827)	Prec@(1,5) (46.7%, 79.3%)	
12/20 08:15:59PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 21/149] Final Prec@1 46.6840%
12/20 08:16:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.3001	Prec@(1,5) (40.8%, 71.5%)
12/20 08:16:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.3213	Prec@(1,5) (40.2%, 71.4%)
12/20 08:16:19PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.3268	Prec@(1,5) (39.9%, 71.0%)
12/20 08:16:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.3172	Prec@(1,5) (40.0%, 71.3%)
12/20 08:16:25PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 39.9600%
12/20 08:16:25PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 08:16:25PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.9600%
12/20 08:17:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.02375	Loss 2.1264 (1.7832)	Arch Loss -14.2421 (-14.2482)	Arch Hard Loss 2.2749 (2.2466)	Arch Beta Loss 16.5170 (16.4948)	Arch depth Loss -2.5076 (-2.5206)	Prec@(1,5) (50.0%, 82.0%)	
12/20 08:18:05PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.02375	Loss 1.8885 (1.8312)	Arch Loss -14.3992 (-14.2810)	Arch Hard Loss 2.1628 (2.2363)	Arch Beta Loss 16.5620 (16.5173)	Arch depth Loss -2.4770 (-2.5067)	Prec@(1,5) (49.0%, 80.7%)	
12/20 08:18:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.02375	Loss 1.5386 (1.8578)	Arch Loss -14.1335 (-14.3044)	Arch Hard Loss 2.4719 (2.2350)	Arch Beta Loss 16.6054 (16.5395)	Arch depth Loss -2.4436 (-2.4912)	Prec@(1,5) (48.4%, 80.4%)	
12/20 08:19:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.02375	Loss 2.0344 (1.8673)	Arch Loss -14.4947 (-14.3209)	Arch Hard Loss 2.1502 (2.2384)	Arch Beta Loss 16.6449 (16.5593)	Arch depth Loss -2.4207 (-2.4775)	Prec@(1,5) (48.3%, 80.3%)	
12/20 08:19:39PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 22/149] Final Prec@1 48.2840%
12/20 08:19:46PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.2444	Prec@(1,5) (41.3%, 72.9%)
12/20 08:19:52PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.2408	Prec@(1,5) (41.4%, 73.0%)
12/20 08:19:58PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.2323	Prec@(1,5) (41.5%, 73.2%)
12/20 08:20:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.2413	Prec@(1,5) (41.5%, 73.2%)
12/20 08:20:04PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 41.5400%
12/20 08:20:04PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:20:05PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.5400%
12/20 08:20:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.02363	Loss 1.8444 (1.7726)	Arch Loss -14.7617 (-14.4521)	Arch Hard Loss 1.9263 (2.2148)	Arch Beta Loss 16.6880 (16.6669)	Arch depth Loss -2.3843 (-2.4021)	Prec@(1,5) (50.6%, 82.2%)	
12/20 08:21:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.02363	Loss 1.7829 (1.8066)	Arch Loss -14.1131 (-14.4724)	Arch Hard Loss 2.6162 (2.2155)	Arch Beta Loss 16.7293 (16.6878)	Arch depth Loss -2.3438 (-2.3830)	Prec@(1,5) (49.8%, 81.4%)	
12/20 08:22:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.02363	Loss 1.9865 (1.8309)	Arch Loss -14.7406 (-14.4750)	Arch Hard Loss 2.0287 (2.2335)	Arch Beta Loss 16.7693 (16.7084)	Arch depth Loss -2.3045 (-2.3629)	Prec@(1,5) (49.2%, 81.1%)	
12/20 08:23:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.02363	Loss 1.8714 (1.8433)	Arch Loss -14.5976 (-14.5004)	Arch Hard Loss 2.2090 (2.2265)	Arch Beta Loss 16.8066 (16.7269)	Arch depth Loss -2.2730 (-2.3459)	Prec@(1,5) (49.1%, 80.8%)	
12/20 08:23:19PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 23/149] Final Prec@1 49.0600%
12/20 08:23:26PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.1880	Prec@(1,5) (42.6%, 73.8%)
12/20 08:23:32PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.2075	Prec@(1,5) (42.2%, 73.7%)
12/20 08:23:39PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.2199	Prec@(1,5) (42.1%, 73.5%)
12/20 08:23:45PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.2197	Prec@(1,5) (41.9%, 73.7%)
12/20 08:23:45PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 41.9400%
12/20 08:23:45PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:23:45PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.9400%
12/20 08:24:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.02352	Loss 1.5556 (1.7301)	Arch Loss -14.4028 (-14.6439)	Arch Hard Loss 2.4434 (2.1829)	Arch Beta Loss 16.8462 (16.8268)	Arch depth Loss -2.2300 (-2.2519)	Prec@(1,5) (51.7%, 82.6%)	
12/20 08:25:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.02352	Loss 1.6748 (1.7751)	Arch Loss -14.4662 (-14.6551)	Arch Hard Loss 2.4197 (2.1916)	Arch Beta Loss 16.8859 (16.8467)	Arch depth Loss -2.1852 (-2.2299)	Prec@(1,5) (50.7%, 82.1%)	
12/20 08:26:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.02352	Loss 2.2648 (1.7738)	Arch Loss -14.8396 (-14.6727)	Arch Hard Loss 2.0850 (2.1937)	Arch Beta Loss 16.9246 (16.8664)	Arch depth Loss -2.1426 (-2.2078)	Prec@(1,5) (50.6%, 82.1%)	
12/20 08:26:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.02352	Loss 1.6525 (1.7904)	Arch Loss -14.9226 (-14.6893)	Arch Hard Loss 2.0359 (2.1945)	Arch Beta Loss 16.9585 (16.8838)	Arch depth Loss -2.1060 (-2.1887)	Prec@(1,5) (50.3%, 81.9%)	
12/20 08:26:59PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 24/149] Final Prec@1 50.2520%
12/20 08:27:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.2733	Prec@(1,5) (41.6%, 72.7%)
12/20 08:27:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.2463	Prec@(1,5) (41.7%, 73.6%)
12/20 08:27:19PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.2534	Prec@(1,5) (41.6%, 73.4%)
12/20 08:27:24PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.2449	Prec@(1,5) (41.8%, 73.5%)
12/20 08:27:25PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 41.7720%
12/20 08:27:25PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 08:27:25PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.9400%
12/20 08:28:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.02339	Loss 1.7973 (1.7206)	Arch Loss -14.6795 (-14.8088)	Arch Hard Loss 2.3165 (2.1689)	Arch Beta Loss 16.9960 (16.9777)	Arch depth Loss -2.0650 (-2.0859)	Prec@(1,5) (51.9%, 83.1%)	
12/20 08:29:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.02339	Loss 2.2183 (1.7652)	Arch Loss -14.5543 (-14.8144)	Arch Hard Loss 2.4776 (2.1816)	Arch Beta Loss 17.0319 (16.9959)	Arch depth Loss -2.0204 (-2.0643)	Prec@(1,5) (50.4%, 82.3%)	
12/20 08:29:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.02339	Loss 1.5558 (1.7866)	Arch Loss -15.5191 (-14.8163)	Arch Hard Loss 1.5474 (2.1974)	Arch Beta Loss 17.0665 (17.0137)	Arch depth Loss -1.9717 (-2.0415)	Prec@(1,5) (50.0%, 82.2%)	
12/20 08:30:39PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.02339	Loss 1.5159 (1.7885)	Arch Loss -15.0583 (-14.8402)	Arch Hard Loss 2.0394 (2.1894)	Arch Beta Loss 17.0978 (17.0296)	Arch depth Loss -1.9303 (-2.0205)	Prec@(1,5) (50.2%, 82.0%)	
12/20 08:30:40PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 25/149] Final Prec@1 50.1840%
12/20 08:30:47PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.1347	Prec@(1,5) (43.6%, 75.2%)
12/20 08:30:53PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.1362	Prec@(1,5) (43.7%, 75.2%)
12/20 08:31:00PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.1199	Prec@(1,5) (43.8%, 75.5%)
12/20 08:31:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.1276	Prec@(1,5) (43.7%, 75.4%)
12/20 08:31:06PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 43.7520%
12/20 08:31:06PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/20 08:31:06PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:31:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.02326	Loss 1.9994 (1.6836)	Arch Loss -15.2069 (-15.0133)	Arch Hard Loss 1.9258 (2.1020)	Arch Beta Loss 17.1327 (17.1153)	Arch depth Loss -1.8767 (-1.9025)	Prec@(1,5) (52.6%, 84.2%)	
12/20 08:32:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.02326	Loss 1.4547 (1.7075)	Arch Loss -14.8315 (-15.0045)	Arch Hard Loss 2.3344 (2.1278)	Arch Beta Loss 17.1659 (17.1323)	Arch depth Loss -1.8234 (-1.8764)	Prec@(1,5) (52.1%, 83.6%)	
12/20 08:33:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.02326	Loss 1.5668 (1.7158)	Arch Loss -15.2769 (-15.0019)	Arch Hard Loss 1.9212 (2.1470)	Arch Beta Loss 17.1982 (17.1489)	Arch depth Loss -1.7687 (-1.8493)	Prec@(1,5) (51.6%, 83.6%)	
12/20 08:34:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.02326	Loss 1.5199 (1.7370)	Arch Loss -14.9771 (-15.0059)	Arch Hard Loss 2.2498 (2.1576)	Arch Beta Loss 17.2268 (17.1636)	Arch depth Loss -1.7254 (-1.8258)	Prec@(1,5) (51.0%, 82.9%)	
12/20 08:34:17PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 26/149] Final Prec@1 50.9760%
12/20 08:34:24PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2404	Prec@(1,5) (42.1%, 73.2%)
12/20 08:34:30PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.2355	Prec@(1,5) (41.9%, 73.0%)
12/20 08:34:37PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.2409	Prec@(1,5) (41.9%, 73.1%)
12/20 08:34:43PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.2427	Prec@(1,5) (41.6%, 73.1%)
12/20 08:34:43PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 41.6600%
12/20 08:34:43PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:34:43PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:35:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.02313	Loss 1.3974 (1.5897)	Arch Loss -14.4629 (-15.0734)	Arch Hard Loss 2.7942 (2.1688)	Arch Beta Loss 17.2571 (17.2422)	Arch depth Loss -1.6650 (-1.6958)	Prec@(1,5) (54.5%, 85.1%)	
12/20 08:36:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.02313	Loss 2.0864 (1.6541)	Arch Loss -15.1122 (-15.0843)	Arch Hard Loss 2.1742 (2.1728)	Arch Beta Loss 17.2864 (17.2571)	Arch depth Loss -1.6130 (-1.6681)	Prec@(1,5) (53.1%, 84.2%)	
12/20 08:37:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.02313	Loss 1.6666 (1.6759)	Arch Loss -14.8803 (-15.1056)	Arch Hard Loss 2.4350 (2.1662)	Arch Beta Loss 17.3153 (17.2717)	Arch depth Loss -1.5518 (-1.6398)	Prec@(1,5) (52.5%, 83.6%)	
12/20 08:37:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.02313	Loss 1.7738 (1.6989)	Arch Loss -15.4277 (-15.1277)	Arch Hard Loss 1.9149 (2.1572)	Arch Beta Loss 17.3426 (17.2850)	Arch depth Loss -1.5042 (-1.6140)	Prec@(1,5) (52.1%, 83.2%)	
12/20 08:37:59PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 27/149] Final Prec@1 52.0520%
12/20 08:38:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.1840	Prec@(1,5) (42.9%, 73.9%)
12/20 08:38:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.1745	Prec@(1,5) (42.9%, 74.2%)
12/20 08:38:19PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.1755	Prec@(1,5) (42.7%, 74.5%)
12/20 08:38:24PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.1709	Prec@(1,5) (42.9%, 74.6%)
12/20 08:38:24PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 42.9000%
12/20 08:38:24PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:38:25PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:39:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.023	Loss 1.9371 (1.6200)	Arch Loss -15.2349 (-15.2655)	Arch Hard Loss 2.1365 (2.0920)	Arch Beta Loss 17.3714 (17.3574)	Arch depth Loss -1.4457 (-1.4739)	Prec@(1,5) (54.3%, 84.9%)	
12/20 08:40:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.023	Loss 1.6009 (1.6531)	Arch Loss -15.8586 (-15.2470)	Arch Hard Loss 1.5395 (2.1242)	Arch Beta Loss 17.3982 (17.3712)	Arch depth Loss -1.3854 (-1.4451)	Prec@(1,5) (53.4%, 84.3%)	
12/20 08:40:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.023	Loss 1.8516 (1.6632)	Arch Loss -15.2943 (-15.2525)	Arch Hard Loss 2.1316 (2.1323)	Arch Beta Loss 17.4259 (17.3849)	Arch depth Loss -1.3279 (-1.4155)	Prec@(1,5) (53.1%, 83.9%)	
12/20 08:41:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.023	Loss 1.5396 (1.6853)	Arch Loss -15.5221 (-15.2566)	Arch Hard Loss 1.9276 (2.1405)	Arch Beta Loss 17.4497 (17.3971)	Arch depth Loss -1.2758 (-1.3894)	Prec@(1,5) (52.6%, 83.5%)	
12/20 08:41:38PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 28/149] Final Prec@1 52.5840%
12/20 08:41:45PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.2393	Prec@(1,5) (41.7%, 73.1%)
12/20 08:41:52PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.2671	Prec@(1,5) (41.1%, 72.7%)
12/20 08:41:58PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.2509	Prec@(1,5) (41.6%, 73.1%)
12/20 08:42:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.2493	Prec@(1,5) (41.6%, 73.3%)
12/20 08:42:04PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 41.6520%
12/20 08:42:04PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:42:05PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:42:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.02285	Loss 1.8105 (1.5640)	Arch Loss -15.3864 (-15.3390)	Arch Hard Loss 2.0899 (2.1241)	Arch Beta Loss 17.4763 (17.4631)	Arch depth Loss -1.2175 (-1.2455)	Prec@(1,5) (54.9%, 86.0%)	
12/20 08:43:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.02285	Loss 1.3499 (1.5868)	Arch Loss -15.8041 (-15.3459)	Arch Hard Loss 1.6983 (2.1304)	Arch Beta Loss 17.5024 (17.4762)	Arch depth Loss -1.1580 (-1.2164)	Prec@(1,5) (54.8%, 85.5%)	
12/20 08:44:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.02285	Loss 1.4757 (1.6334)	Arch Loss -15.1589 (-15.3471)	Arch Hard Loss 2.3680 (2.1422)	Arch Beta Loss 17.5270 (17.4892)	Arch depth Loss -1.0927 (-1.1862)	Prec@(1,5) (53.9%, 84.5%)	
12/20 08:45:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.02285	Loss 1.3038 (1.6505)	Arch Loss -15.2285 (-15.3658)	Arch Hard Loss 2.3216 (2.1348)	Arch Beta Loss 17.5500 (17.5007)	Arch depth Loss -1.0369 (-1.1584)	Prec@(1,5) (53.4%, 84.2%)	
12/20 08:45:18PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 29/149] Final Prec@1 53.4480%
12/20 08:45:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.6058	Prec@(1,5) (34.9%, 66.4%)
12/20 08:45:32PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.5969	Prec@(1,5) (35.1%, 66.7%)
12/20 08:45:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.6224	Prec@(1,5) (34.6%, 66.2%)
12/20 08:45:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.6148	Prec@(1,5) (34.7%, 66.3%)
12/20 08:45:44PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 34.7360%
12/20 08:45:44PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:45:44PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:46:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.02271	Loss 1.5932 (1.5700)	Arch Loss -15.7839 (-15.4442)	Arch Hard Loss 1.7910 (2.1185)	Arch Beta Loss 17.5750 (17.5627)	Arch depth Loss -0.9740 (-1.0061)	Prec@(1,5) (55.2%, 85.3%)	
12/20 08:47:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.02271	Loss 1.7647 (1.5835)	Arch Loss -15.2508 (-15.4410)	Arch Hard Loss 2.3485 (2.1340)	Arch Beta Loss 17.5993 (17.5750)	Arch depth Loss -0.9119 (-0.9739)	Prec@(1,5) (54.9%, 85.1%)	
12/20 08:48:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.02271	Loss 1.7423 (1.6075)	Arch Loss -15.9660 (-15.4654)	Arch Hard Loss 1.6585 (2.1219)	Arch Beta Loss 17.6245 (17.5874)	Arch depth Loss -0.8480 (-0.9429)	Prec@(1,5) (54.5%, 84.7%)	
12/20 08:48:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.02271	Loss 1.9118 (1.6332)	Arch Loss -15.0251 (-15.4802)	Arch Hard Loss 2.6219 (2.1184)	Arch Beta Loss 17.6469 (17.5986)	Arch depth Loss -0.7901 (-0.9141)	Prec@(1,5) (53.6%, 84.3%)	
12/20 08:48:57PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 30/149] Final Prec@1 53.5920%
12/20 08:49:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.4496	Prec@(1,5) (38.8%, 69.7%)
12/20 08:49:10PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.4461	Prec@(1,5) (38.9%, 69.5%)
12/20 08:49:16PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.4449	Prec@(1,5) (38.9%, 69.6%)
12/20 08:49:22PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.4411	Prec@(1,5) (38.9%, 69.5%)
12/20 08:49:22PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 38.8800%
12/20 08:49:22PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:49:23PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:50:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.02256	Loss 1.5336 (1.5276)	Arch Loss -15.3354 (-15.5829)	Arch Hard Loss 2.3350 (2.0764)	Arch Beta Loss 17.6704 (17.6593)	Arch depth Loss -0.7243 (-0.7568)	Prec@(1,5) (56.9%, 85.9%)	
12/20 08:51:02PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.02256	Loss 1.3780 (1.5542)	Arch Loss -15.9458 (-15.5692)	Arch Hard Loss 1.7481 (2.1015)	Arch Beta Loss 17.6938 (17.6708)	Arch depth Loss -0.6553 (-0.7234)	Prec@(1,5) (56.0%, 86.0%)	
12/20 08:51:51PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.02256	Loss 1.8479 (1.5928)	Arch Loss -15.3865 (-15.5568)	Arch Hard Loss 2.3301 (2.1256)	Arch Beta Loss 17.7167 (17.6823)	Arch depth Loss -0.5929 (-0.6902)	Prec@(1,5) (55.0%, 85.4%)	
12/20 08:52:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.02256	Loss 1.7086 (1.6071)	Arch Loss -15.8107 (-15.5786)	Arch Hard Loss 1.9281 (2.1143)	Arch Beta Loss 17.7388 (17.6929)	Arch depth Loss -0.5370 (-0.6610)	Prec@(1,5) (54.8%, 85.1%)	
12/20 08:52:36PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 31/149] Final Prec@1 54.8120%
12/20 08:52:43PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.2959	Prec@(1,5) (41.9%, 71.8%)
12/20 08:52:50PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.2899	Prec@(1,5) (41.7%, 72.2%)
12/20 08:52:56PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.3069	Prec@(1,5) (41.5%, 72.0%)
12/20 08:53:02PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.3127	Prec@(1,5) (41.3%, 71.9%)
12/20 08:53:02PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 41.2640%
12/20 08:53:02PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:53:02PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:53:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.0224	Loss 1.6800 (1.5314)	Arch Loss -15.9489 (-15.7078)	Arch Hard Loss 1.8128 (2.0427)	Arch Beta Loss 17.7617 (17.7506)	Arch depth Loss -0.4718 (-0.5032)	Prec@(1,5) (56.1%, 86.2%)	
12/20 08:54:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.0224	Loss 1.4782 (1.5387)	Arch Loss -15.4484 (-15.6836)	Arch Hard Loss 2.3346 (2.0780)	Arch Beta Loss 17.7830 (17.7617)	Arch depth Loss -0.4000 (-0.4690)	Prec@(1,5) (56.1%, 86.1%)	
12/20 08:55:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.0224	Loss 1.3504 (1.5507)	Arch Loss -15.6694 (-15.6779)	Arch Hard Loss 2.1350 (2.0945)	Arch Beta Loss 17.8044 (17.7724)	Arch depth Loss -0.3348 (-0.4351)	Prec@(1,5) (55.9%, 85.9%)	
12/20 08:56:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.0224	Loss 1.5791 (1.5735)	Arch Loss -15.8328 (-15.6841)	Arch Hard Loss 1.9906 (2.0979)	Arch Beta Loss 17.8234 (17.7820)	Arch depth Loss -0.2740 (-0.4049)	Prec@(1,5) (55.5%, 85.5%)	
12/20 08:56:17PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 32/149] Final Prec@1 55.4560%
12/20 08:56:24PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 3.9790	Prec@(1,5) (22.0%, 47.5%)
12/20 08:56:30PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 3.9888	Prec@(1,5) (21.7%, 47.5%)
12/20 08:56:37PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 3.9989	Prec@(1,5) (21.7%, 47.4%)
12/20 08:56:43PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 3.9989	Prec@(1,5) (21.8%, 47.5%)
12/20 08:56:43PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 21.7840%
12/20 08:56:43PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 08:56:43PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 08:57:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.02225	Loss 1.6016 (1.4818)	Arch Loss -15.8380 (-15.7281)	Arch Hard Loss 2.0061 (2.1058)	Arch Beta Loss 17.8441 (17.8339)	Arch depth Loss -0.2102 (-0.2408)	Prec@(1,5) (56.7%, 86.9%)	
12/20 08:58:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.02225	Loss 1.4273 (1.5373)	Arch Loss -15.8533 (-15.7659)	Arch Hard Loss 2.0112 (2.0782)	Arch Beta Loss 17.8644 (17.8441)	Arch depth Loss -0.1365 (-0.2060)	Prec@(1,5) (55.3%, 86.1%)	
12/20 08:59:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.02225	Loss 1.8845 (1.5645)	Arch Loss -15.6794 (-15.7508)	Arch Hard Loss 2.2047 (2.1034)	Arch Beta Loss 17.8841 (17.8543)	Arch depth Loss -0.0596 (-0.1703)	Prec@(1,5) (54.9%, 85.5%)	
12/20 08:59:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.02225	Loss 1.6448 (1.5833)	Arch Loss -15.7937 (-15.7506)	Arch Hard Loss 2.1085 (2.1127)	Arch Beta Loss 17.9021 (17.8633)	Arch depth Loss 0.0049 (-0.1375)	Prec@(1,5) (54.8%, 85.3%)	
12/20 08:59:58PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 33/149] Final Prec@1 54.7720%
12/20 09:00:05PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.6567	Prec@(1,5) (36.5%, 66.4%)
12/20 09:00:11PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.6420	Prec@(1,5) (36.9%, 66.8%)
12/20 09:00:17PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.6491	Prec@(1,5) (36.6%, 66.9%)
12/20 09:00:23PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.6556	Prec@(1,5) (36.5%, 66.9%)
12/20 09:00:23PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 36.5120%
12/20 09:00:23PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:00:23PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:01:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.02208	Loss 1.4249 (1.4489)	Arch Loss -15.6847 (-15.8356)	Arch Hard Loss 2.2367 (2.0763)	Arch Beta Loss 17.9214 (17.9119)	Arch depth Loss 0.0787 (0.0396)	Prec@(1,5) (57.8%, 87.7%)	
12/20 09:02:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.02208	Loss 1.5162 (1.5173)	Arch Loss -15.5516 (-15.8009)	Arch Hard Loss 2.3878 (2.1203)	Arch Beta Loss 17.9394 (17.9212)	Arch depth Loss 0.1438 (0.0753)	Prec@(1,5) (56.4%, 86.6%)	
12/20 09:02:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.02208	Loss 1.7866 (1.5311)	Arch Loss -15.3130 (-15.8160)	Arch Hard Loss 2.6447 (2.1143)	Arch Beta Loss 17.9577 (17.9303)	Arch depth Loss 0.2158 (0.1108)	Prec@(1,5) (56.4%, 86.2%)	
12/20 09:03:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.02208	Loss 1.7985 (1.5546)	Arch Loss -15.8806 (-15.8196)	Arch Hard Loss 2.0932 (2.1189)	Arch Beta Loss 17.9738 (17.9385)	Arch depth Loss 0.2727 (0.1414)	Prec@(1,5) (55.6%, 85.9%)	
12/20 09:03:37PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 34/149] Final Prec@1 55.6400%
12/20 09:03:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 5.7229	Prec@(1,5) (7.8%, 24.6%)
12/20 09:03:50PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 5.7201	Prec@(1,5) (7.9%, 24.9%)
12/20 09:03:57PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 5.7282	Prec@(1,5) (7.7%, 24.9%)
12/20 09:04:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 5.7317	Prec@(1,5) (7.5%, 24.9%)
12/20 09:04:03PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 7.5200%
12/20 09:04:03PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:04:04PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:04:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.02192	Loss 1.4156 (1.4471)	Arch Loss -15.8585 (-15.9084)	Arch Hard Loss 2.1326 (2.0741)	Arch Beta Loss 17.9911 (17.9825)	Arch depth Loss 0.3486 (0.3134)	Prec@(1,5) (58.0%, 87.3%)	
12/20 09:05:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.02192	Loss 2.0401 (1.5315)	Arch Loss -15.9610 (-15.8772)	Arch Hard Loss 2.0458 (2.1134)	Arch Beta Loss 18.0068 (17.9906)	Arch depth Loss 0.4233 (0.3488)	Prec@(1,5) (56.4%, 85.9%)	
12/20 09:06:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.02192	Loss 1.7792 (1.5548)	Arch Loss -16.0098 (-15.8973)	Arch Hard Loss 2.0137 (2.1016)	Arch Beta Loss 18.0236 (17.9989)	Arch depth Loss 0.4883 (0.3853)	Prec@(1,5) (55.8%, 85.7%)	
12/20 09:07:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.02192	Loss 1.8400 (1.5556)	Arch Loss -16.2145 (-15.8949)	Arch Hard Loss 1.8239 (2.1114)	Arch Beta Loss 18.0384 (18.0063)	Arch depth Loss 0.5500 (0.4166)	Prec@(1,5) (55.7%, 85.8%)	
12/20 09:07:18PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 35/149] Final Prec@1 55.7120%
12/20 09:07:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 3.4267	Prec@(1,5) (23.2%, 53.8%)
12/20 09:07:31PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 3.4280	Prec@(1,5) (23.5%, 53.4%)
12/20 09:07:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 3.4200	Prec@(1,5) (23.6%, 53.8%)
12/20 09:07:43PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 3.4186	Prec@(1,5) (23.8%, 53.7%)
12/20 09:07:44PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 23.7680%
12/20 09:07:44PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:07:44PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:08:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.02175	Loss 1.3351 (1.4384)	Arch Loss -15.4173 (-15.9431)	Arch Hard Loss 2.6380 (2.1044)	Arch Beta Loss 18.0554 (18.0475)	Arch depth Loss 0.6249 (0.5873)	Prec@(1,5) (57.9%, 88.0%)	
12/20 09:09:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.02175	Loss 1.6100 (1.4817)	Arch Loss -16.3653 (-15.9517)	Arch Hard Loss 1.7046 (2.1033)	Arch Beta Loss 18.0698 (18.0550)	Arch depth Loss 0.6803 (0.6200)	Prec@(1,5) (56.9%, 87.5%)	
12/20 09:10:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.02175	Loss 1.4383 (1.5089)	Arch Loss -15.9526 (-15.9658)	Arch Hard Loss 2.1319 (2.0966)	Arch Beta Loss 18.0845 (18.0625)	Arch depth Loss 0.7527 (0.6534)	Prec@(1,5) (56.6%, 86.7%)	
12/20 09:10:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.02175	Loss 1.3133 (1.5160)	Arch Loss -16.2031 (-15.9745)	Arch Hard Loss 1.8951 (2.0946)	Arch Beta Loss 18.0982 (18.0691)	Arch depth Loss 0.8069 (0.6823)	Prec@(1,5) (56.5%, 86.6%)	
12/20 09:10:51PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 36/149] Final Prec@1 56.5320%
12/20 09:10:58PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.5703	Prec@(1,5) (37.8%, 69.6%)
12/20 09:11:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.5628	Prec@(1,5) (38.4%, 69.6%)
12/20 09:11:11PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.5755	Prec@(1,5) (38.2%, 69.5%)
12/20 09:11:17PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.5894	Prec@(1,5) (38.0%, 69.2%)
12/20 09:11:17PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 38.0080%
12/20 09:11:17PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/20 09:11:17PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:12:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.02157	Loss 1.6010 (1.4102)	Arch Loss -15.7415 (-16.0074)	Arch Hard Loss 2.3714 (2.0984)	Arch Beta Loss 18.1129 (18.1058)	Arch depth Loss 0.8642 (0.8347)	Prec@(1,5) (58.6%, 88.5%)	
12/20 09:12:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.02157	Loss 1.6777 (1.4398)	Arch Loss -15.5231 (-16.0324)	Arch Hard Loss 2.6034 (2.0802)	Arch Beta Loss 18.1265 (18.1126)	Arch depth Loss 0.9374 (0.8677)	Prec@(1,5) (57.9%, 87.8%)	
12/20 09:13:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.02157	Loss 1.5500 (1.4657)	Arch Loss -16.2173 (-16.0328)	Arch Hard Loss 1.9215 (2.0865)	Arch Beta Loss 18.1387 (18.1193)	Arch depth Loss 1.0057 (0.9017)	Prec@(1,5) (57.6%, 87.3%)	
12/20 09:14:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.02157	Loss 1.0784 (1.4736)	Arch Loss -16.2861 (-16.0442)	Arch Hard Loss 1.8645 (2.0810)	Arch Beta Loss 18.1507 (18.1252)	Arch depth Loss 1.0712 (0.9342)	Prec@(1,5) (57.4%, 87.2%)	
12/20 09:14:30PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 37/149] Final Prec@1 57.4560%
12/20 09:14:37PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 3.4972	Prec@(1,5) (25.2%, 53.5%)
12/20 09:14:43PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 3.4464	Prec@(1,5) (25.6%, 54.1%)
12/20 09:14:50PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 3.4360	Prec@(1,5) (25.7%, 54.4%)
12/20 09:14:55PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 3.4434	Prec@(1,5) (25.9%, 54.3%)
12/20 09:14:55PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 25.8560%
12/20 09:14:55PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/20 09:14:56PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:15:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.0214	Loss 1.2463 (1.4021)	Arch Loss -16.2565 (-16.0970)	Arch Hard Loss 1.9067 (2.0602)	Arch Beta Loss 18.1632 (18.1572)	Arch depth Loss 1.1503 (1.1076)	Prec@(1,5) (59.5%, 87.9%)	
12/20 09:16:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.0214	Loss 1.3251 (1.4413)	Arch Loss -16.0201 (-16.1011)	Arch Hard Loss 2.1551 (2.0622)	Arch Beta Loss 18.1751 (18.1633)	Arch depth Loss 1.2199 (1.1455)	Prec@(1,5) (58.2%, 87.5%)	
12/20 09:17:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.0214	Loss 1.5875 (1.4698)	Arch Loss -16.1539 (-16.0883)	Arch Hard Loss 2.0320 (2.0810)	Arch Beta Loss 18.1859 (18.1692)	Arch depth Loss 1.2923 (1.1811)	Prec@(1,5) (57.5%, 87.0%)	
12/20 09:18:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.0214	Loss 1.4195 (1.4863)	Arch Loss -16.0091 (-16.0737)	Arch Hard Loss 2.1864 (2.1005)	Arch Beta Loss 18.1955 (18.1742)	Arch depth Loss 1.3501 (1.2128)	Prec@(1,5) (57.2%, 86.7%)	
12/20 09:18:09PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 38/149] Final Prec@1 57.2040%
12/20 09:18:16PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.6602	Prec@(1,5) (36.4%, 66.9%)
12/20 09:18:23PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.6578	Prec@(1,5) (36.2%, 67.1%)
12/20 09:18:29PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.6572	Prec@(1,5) (36.1%, 67.3%)
12/20 09:18:35PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.6502	Prec@(1,5) (36.3%, 67.4%)
12/20 09:18:35PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 36.2840%
12/20 09:18:35PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/20 09:18:35PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:19:26PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.02121	Loss 1.5096 (1.3554)	Arch Loss -16.2371 (-16.1150)	Arch Hard Loss 1.9693 (2.0862)	Arch Beta Loss 18.2064 (18.2012)	Arch depth Loss 1.4147 (1.3794)	Prec@(1,5) (59.8%, 89.1%)	
12/20 09:20:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.02121	Loss 1.2828 (1.3999)	Arch Loss -16.4310 (-16.1263)	Arch Hard Loss 1.7855 (2.0800)	Arch Beta Loss 18.2165 (18.2064)	Arch depth Loss 1.4869 (1.4132)	Prec@(1,5) (59.1%, 88.5%)	
12/20 09:21:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.02121	Loss 1.3848 (1.4294)	Arch Loss -15.7704 (-16.1293)	Arch Hard Loss 2.4567 (2.0823)	Arch Beta Loss 18.2271 (18.2116)	Arch depth Loss 1.5520 (1.4478)	Prec@(1,5) (58.4%, 87.8%)	
12/20 09:21:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.02121	Loss 1.5740 (1.4472)	Arch Loss -15.9384 (-16.1296)	Arch Hard Loss 2.2981 (2.0867)	Arch Beta Loss 18.2365 (18.2163)	Arch depth Loss 1.6017 (1.4768)	Prec@(1,5) (57.9%, 87.5%)	
12/20 09:21:48PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 39/149] Final Prec@1 57.8680%
12/20 09:21:55PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 6.9016	Prec@(1,5) (5.3%, 16.2%)
12/20 09:22:01PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 6.9182	Prec@(1,5) (5.3%, 16.3%)
12/20 09:22:08PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 6.9319	Prec@(1,5) (5.4%, 16.2%)
12/20 09:22:14PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 6.9213	Prec@(1,5) (5.3%, 16.2%)
12/20 09:22:14PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 5.3280%
12/20 09:22:14PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:22:14PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:23:05PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.02103	Loss 1.3957 (1.3886)	Arch Loss -16.0287 (-16.0873)	Arch Hard Loss 2.2161 (2.1539)	Arch Beta Loss 18.2448 (18.2412)	Arch depth Loss 1.6665 (1.6363)	Prec@(1,5) (60.0%, 88.3%)	
12/20 09:23:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.02103	Loss 1.5606 (1.4072)	Arch Loss -16.1141 (-16.1010)	Arch Hard Loss 2.1396 (2.1442)	Arch Beta Loss 18.2537 (18.2452)	Arch depth Loss 1.7357 (1.6671)	Prec@(1,5) (59.2%, 88.6%)	
12/20 09:24:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.02103	Loss 1.1531 (1.4297)	Arch Loss -16.0894 (-16.1159)	Arch Hard Loss 2.1726 (2.1337)	Arch Beta Loss 18.2620 (18.2495)	Arch depth Loss 1.7971 (1.7005)	Prec@(1,5) (58.7%, 87.9%)	
12/20 09:25:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.02103	Loss 1.7861 (1.4294)	Arch Loss -16.4349 (-16.1447)	Arch Hard Loss 1.8369 (2.1088)	Arch Beta Loss 18.2718 (18.2535)	Arch depth Loss 1.8552 (1.7298)	Prec@(1,5) (58.8%, 87.7%)	
12/20 09:25:28PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 40/149] Final Prec@1 58.8200%
12/20 09:25:35PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.3587	Prec@(1,5) (40.9%, 71.9%)
12/20 09:25:42PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.3874	Prec@(1,5) (40.3%, 71.5%)
12/20 09:25:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.3758	Prec@(1,5) (40.5%, 71.8%)
12/20 09:25:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.3824	Prec@(1,5) (40.5%, 71.7%)
12/20 09:25:54PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 40.4960%
12/20 09:25:54PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/20 09:25:55PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:26:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.02084	Loss 1.2057 (1.3147)	Arch Loss -16.2960 (-16.1943)	Arch Hard Loss 1.9853 (2.0823)	Arch Beta Loss 18.2813 (18.2766)	Arch depth Loss 1.9150 (1.8917)	Prec@(1,5) (61.8%, 89.9%)	
12/20 09:27:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.02084	Loss 1.0384 (1.3470)	Arch Loss -16.3070 (-16.1883)	Arch Hard Loss 1.9816 (2.0926)	Arch Beta Loss 18.2886 (18.2810)	Arch depth Loss 1.9734 (1.9172)	Prec@(1,5) (60.5%, 89.4%)	
12/20 09:28:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.02084	Loss 1.4460 (1.3675)	Arch Loss -16.2973 (-16.1933)	Arch Hard Loss 1.9999 (2.0917)	Arch Beta Loss 18.2972 (18.2850)	Arch depth Loss 2.0447 (1.9452)	Prec@(1,5) (60.1%, 88.8%)	
12/20 09:29:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.02084	Loss 1.7000 (1.3927)	Arch Loss -16.2069 (-16.1989)	Arch Hard Loss 2.0975 (2.0897)	Arch Beta Loss 18.3044 (18.2886)	Arch depth Loss 2.0934 (1.9740)	Prec@(1,5) (59.3%, 88.5%)	
12/20 09:29:09PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 41/149] Final Prec@1 59.3440%
12/20 09:29:16PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 6.5336	Prec@(1,5) (7.7%, 25.0%)
12/20 09:29:22PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 6.5469	Prec@(1,5) (7.6%, 24.8%)
12/20 09:29:29PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 6.5454	Prec@(1,5) (7.5%, 24.9%)
12/20 09:29:34PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 6.5323	Prec@(1,5) (7.5%, 25.1%)
12/20 09:29:35PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 7.5080%
12/20 09:29:35PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/20 09:29:35PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:30:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.02065	Loss 1.6464 (1.3044)	Arch Loss -16.3439 (-16.2021)	Arch Hard Loss 1.9681 (2.1064)	Arch Beta Loss 18.3119 (18.3085)	Arch depth Loss 2.1480 (2.1209)	Prec@(1,5) (61.7%, 89.5%)	
12/20 09:31:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.02065	Loss 1.3418 (1.3393)	Arch Loss -16.3007 (-16.2232)	Arch Hard Loss 2.0178 (2.0886)	Arch Beta Loss 18.3186 (18.3118)	Arch depth Loss 2.2207 (2.1535)	Prec@(1,5) (60.9%, 89.2%)	
12/20 09:32:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.02065	Loss 1.4373 (1.3662)	Arch Loss -15.7766 (-16.2227)	Arch Hard Loss 2.5490 (2.0924)	Arch Beta Loss 18.3256 (18.3152)	Arch depth Loss 2.2809 (2.1849)	Prec@(1,5) (60.2%, 88.7%)	
12/20 09:32:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.02065	Loss 1.4337 (1.3792)	Arch Loss -16.2323 (-16.2259)	Arch Hard Loss 2.0997 (2.0924)	Arch Beta Loss 18.3320 (18.3183)	Arch depth Loss 2.3294 (2.2127)	Prec@(1,5) (59.8%, 88.6%)	
12/20 09:32:47PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 42/149] Final Prec@1 59.8240%
12/20 09:32:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 6.5544	Prec@(1,5) (7.2%, 23.0%)
12/20 09:33:00PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 6.5791	Prec@(1,5) (6.9%, 22.8%)
12/20 09:33:07PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 6.6010	Prec@(1,5) (7.0%, 22.6%)
12/20 09:33:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 6.5960	Prec@(1,5) (7.0%, 22.5%)
12/20 09:33:12PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 6.9800%
12/20 09:33:13PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:33:13PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:34:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.02045	Loss 1.2450 (1.2744)	Arch Loss -16.1557 (-16.2668)	Arch Hard Loss 2.1825 (2.0682)	Arch Beta Loss 18.3383 (18.3350)	Arch depth Loss 2.4036 (2.3660)	Prec@(1,5) (62.1%, 90.5%)	
12/20 09:34:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.02045	Loss 1.3738 (1.3094)	Arch Loss -16.4303 (-16.2681)	Arch Hard Loss 1.9144 (2.0702)	Arch Beta Loss 18.3447 (18.3383)	Arch depth Loss 2.4621 (2.3984)	Prec@(1,5) (61.5%, 89.9%)	
12/20 09:35:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.02045	Loss 1.3720 (1.3278)	Arch Loss -15.9740 (-16.2792)	Arch Hard Loss 2.3779 (2.0625)	Arch Beta Loss 18.3519 (18.3417)	Arch depth Loss 2.5257 (2.4314)	Prec@(1,5) (61.0%, 89.5%)	
12/20 09:36:28PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.02045	Loss 1.2812 (1.3409)	Arch Loss -16.1774 (-16.2742)	Arch Hard Loss 2.1798 (2.0704)	Arch Beta Loss 18.3572 (18.3446)	Arch depth Loss 2.5702 (2.4580)	Prec@(1,5) (60.6%, 89.4%)	
12/20 09:36:28PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 43/149] Final Prec@1 60.5920%
12/20 09:36:35PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 4.9113	Prec@(1,5) (20.0%, 44.3%)
12/20 09:36:42PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 4.9414	Prec@(1,5) (20.1%, 44.6%)
12/20 09:36:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 4.9610	Prec@(1,5) (19.8%, 44.2%)
12/20 09:36:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 4.9390	Prec@(1,5) (19.9%, 44.1%)
12/20 09:36:54PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 19.9080%
12/20 09:36:54PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/20 09:36:54PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:37:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.02026	Loss 1.3173 (1.2692)	Arch Loss -16.1551 (-16.2591)	Arch Hard Loss 2.2073 (2.1008)	Arch Beta Loss 18.3624 (18.3600)	Arch depth Loss 2.6273 (2.5978)	Prec@(1,5) (62.4%, 90.2%)	
12/20 09:38:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.02026	Loss 1.7480 (1.3131)	Arch Loss -15.7031 (-16.2489)	Arch Hard Loss 2.6640 (2.1134)	Arch Beta Loss 18.3671 (18.3623)	Arch depth Loss 2.6614 (2.6229)	Prec@(1,5) (61.5%, 89.6%)	
12/20 09:39:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.02026	Loss 1.5092 (1.3380)	Arch Loss -16.2805 (-16.2526)	Arch Hard Loss 2.0925 (2.1123)	Arch Beta Loss 18.3730 (18.3649)	Arch depth Loss 2.6802 (2.6381)	Prec@(1,5) (61.0%, 89.1%)	
12/20 09:40:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.02026	Loss 1.1130 (1.3524)	Arch Loss -16.2189 (-16.2551)	Arch Hard Loss 2.1578 (2.1122)	Arch Beta Loss 18.3767 (18.3673)	Arch depth Loss 2.7190 (2.6504)	Prec@(1,5) (60.6%, 88.9%)	
12/20 09:40:08PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 44/149] Final Prec@1 60.5600%
12/20 09:40:15PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 8.4010	Prec@(1,5) (1.4%, 9.1%)
12/20 09:40:21PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 8.3327	Prec@(1,5) (1.5%, 9.3%)
12/20 09:40:28PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 8.3669	Prec@(1,5) (1.4%, 9.4%)
12/20 09:40:34PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 8.3529	Prec@(1,5) (1.4%, 9.5%)
12/20 09:40:34PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 1.4160%
12/20 09:40:34PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:40:34PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:41:26PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.02005	Loss 1.2253 (1.3453)	Arch Loss -16.7540 (-16.2921)	Arch Hard Loss 1.6290 (2.0880)	Arch Beta Loss 18.3831 (18.3801)	Arch depth Loss 2.7603 (2.7455)	Prec@(1,5) (61.2%, 89.4%)	
12/20 09:42:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.02005	Loss 1.5393 (1.3480)	Arch Loss -16.0311 (-16.2774)	Arch Hard Loss 2.3566 (2.1055)	Arch Beta Loss 18.3877 (18.3829)	Arch depth Loss 2.8040 (2.7656)	Prec@(1,5) (61.1%, 89.1%)	
12/20 09:43:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.02005	Loss 1.3682 (1.3628)	Arch Loss -16.1195 (-16.2721)	Arch Hard Loss 2.2730 (2.1133)	Arch Beta Loss 18.3925 (18.3854)	Arch depth Loss 2.8437 (2.7843)	Prec@(1,5) (60.5%, 88.9%)	
12/20 09:43:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.02005	Loss 1.3558 (1.3588)	Arch Loss -16.2903 (-16.2785)	Arch Hard Loss 2.1066 (2.1090)	Arch Beta Loss 18.3969 (18.3875)	Arch depth Loss 2.9016 (2.8036)	Prec@(1,5) (60.5%, 88.9%)	
12/20 09:43:48PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 45/149] Final Prec@1 60.4800%
12/20 09:43:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 9.5293	Prec@(1,5) (2.5%, 12.2%)
12/20 09:44:01PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 9.5491	Prec@(1,5) (2.3%, 12.1%)
12/20 09:44:07PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 9.5727	Prec@(1,5) (2.2%, 11.8%)
12/20 09:44:13PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 9.5923	Prec@(1,5) (2.2%, 11.6%)
12/20 09:44:13PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 2.2320%
12/20 09:44:13PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:44:14PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:45:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.01985	Loss 1.5927 (1.2023)	Arch Loss -16.2452 (-16.3338)	Arch Hard Loss 2.1569 (2.0659)	Arch Beta Loss 18.4021 (18.3997)	Arch depth Loss 2.9458 (2.9270)	Prec@(1,5) (64.2%, 91.1%)	
12/20 09:45:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.01985	Loss 1.1214 (1.2760)	Arch Loss -16.4625 (-16.3093)	Arch Hard Loss 1.9438 (2.0929)	Arch Beta Loss 18.4063 (18.4021)	Arch depth Loss 2.9938 (2.9465)	Prec@(1,5) (62.4%, 90.1%)	
12/20 09:46:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.01985	Loss 1.2345 (1.2947)	Arch Loss -16.4228 (-16.3138)	Arch Hard Loss 1.9883 (2.0905)	Arch Beta Loss 18.4110 (18.4044)	Arch depth Loss 3.0512 (2.9718)	Prec@(1,5) (61.9%, 90.0%)	
12/20 09:47:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.01985	Loss 1.2989 (1.3247)	Arch Loss -16.0597 (-16.3048)	Arch Hard Loss 2.3538 (2.1014)	Arch Beta Loss 18.4135 (18.4062)	Arch depth Loss 3.0847 (2.9962)	Prec@(1,5) (61.2%, 89.6%)	
12/20 09:47:28PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 46/149] Final Prec@1 61.2080%
12/20 09:47:35PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 13.9568	Prec@(1,5) (1.4%, 5.7%)
12/20 09:47:41PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 13.9648	Prec@(1,5) (1.4%, 5.6%)
12/20 09:47:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 13.9499	Prec@(1,5) (1.4%, 5.5%)
12/20 09:47:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 13.9796	Prec@(1,5) (1.4%, 5.4%)
12/20 09:47:54PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 1.3680%
12/20 09:47:54PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:47:54PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:48:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.01964	Loss 1.1857 (1.2729)	Arch Loss -16.7308 (-16.3266)	Arch Hard Loss 1.6864 (2.0890)	Arch Beta Loss 18.4172 (18.4156)	Arch depth Loss 3.1051 (3.0976)	Prec@(1,5) (62.4%, 90.0%)	
12/20 09:49:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.01964	Loss 1.1465 (1.2768)	Arch Loss -16.5887 (-16.2959)	Arch Hard Loss 1.8309 (2.1213)	Arch Beta Loss 18.4196 (18.4172)	Arch depth Loss 3.1199 (3.1023)	Prec@(1,5) (62.1%, 90.0%)	
12/20 09:50:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.01964	Loss 1.2512 (1.2938)	Arch Loss -16.5132 (-16.3080)	Arch Hard Loss 1.9095 (2.1106)	Arch Beta Loss 18.4227 (18.4185)	Arch depth Loss 3.1766 (3.1180)	Prec@(1,5) (61.7%, 89.8%)	
12/20 09:51:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.01964	Loss 1.6149 (1.2998)	Arch Loss -16.3286 (-16.3055)	Arch Hard Loss 2.0965 (2.1143)	Arch Beta Loss 18.4251 (18.4197)	Arch depth Loss 3.2018 (3.1324)	Prec@(1,5) (61.7%, 89.8%)	
12/20 09:51:09PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 47/149] Final Prec@1 61.6560%
12/20 09:51:16PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 9.6428	Prec@(1,5) (1.7%, 5.7%)
12/20 09:51:22PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 9.6198	Prec@(1,5) (1.6%, 5.5%)
12/20 09:51:29PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 9.5901	Prec@(1,5) (1.8%, 5.7%)
12/20 09:51:35PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 9.5763	Prec@(1,5) (1.8%, 5.8%)
12/20 09:51:35PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 1.7640%
12/20 09:51:35PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:51:35PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:52:26PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.01943	Loss 1.1523 (1.2046)	Arch Loss -16.4419 (-16.3192)	Arch Hard Loss 1.9857 (2.1073)	Arch Beta Loss 18.4276 (18.4265)	Arch depth Loss 3.2223 (3.2134)	Prec@(1,5) (64.2%, 91.3%)	
12/20 09:53:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.01943	Loss 1.4065 (1.2270)	Arch Loss -16.1193 (-16.3099)	Arch Hard Loss 2.3110 (2.1178)	Arch Beta Loss 18.4304 (18.4277)	Arch depth Loss 3.2605 (3.2278)	Prec@(1,5) (63.4%, 91.1%)	
12/20 09:54:05PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.01943	Loss 1.3547 (1.2410)	Arch Loss -16.5126 (-16.3236)	Arch Hard Loss 1.9206 (2.1053)	Arch Beta Loss 18.4331 (18.4289)	Arch depth Loss 3.3178 (3.2481)	Prec@(1,5) (63.2%, 90.8%)	
12/20 09:54:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.01943	Loss 1.4202 (1.2610)	Arch Loss -16.6343 (-16.3347)	Arch Hard Loss 1.8019 (2.0956)	Arch Beta Loss 18.4361 (18.4303)	Arch depth Loss 3.3373 (3.2667)	Prec@(1,5) (62.8%, 90.5%)	
12/20 09:54:51PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 48/149] Final Prec@1 62.7840%
12/20 09:54:57PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.7966	Prec@(1,5) (36.9%, 68.0%)
12/20 09:55:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.7755	Prec@(1,5) (37.5%, 68.3%)
12/20 09:55:10PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.7641	Prec@(1,5) (37.5%, 68.5%)
12/20 09:55:16PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.7813	Prec@(1,5) (37.2%, 68.4%)
12/20 09:55:16PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 37.1960%
12/20 09:55:16PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:55:16PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:56:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.01922	Loss 1.1777 (1.1548)	Arch Loss -16.4664 (-16.3285)	Arch Hard Loss 1.9717 (2.1088)	Arch Beta Loss 18.4382 (18.4373)	Arch depth Loss 3.3747 (3.3525)	Prec@(1,5) (65.3%, 92.3%)	
12/20 09:56:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.01922	Loss 0.9146 (1.1645)	Arch Loss -16.3802 (-16.3380)	Arch Hard Loss 2.0598 (2.1002)	Arch Beta Loss 18.4400 (18.4382)	Arch depth Loss 3.4077 (3.3710)	Prec@(1,5) (64.9%, 92.0%)	
12/20 09:57:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.01922	Loss 1.0687 (1.1908)	Arch Loss -16.2944 (-16.3484)	Arch Hard Loss 2.1482 (2.0908)	Arch Beta Loss 18.4426 (18.4393)	Arch depth Loss 3.4439 (3.3901)	Prec@(1,5) (64.4%, 91.6%)	
12/20 09:58:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.01922	Loss 1.4696 (1.2118)	Arch Loss -16.7005 (-16.3565)	Arch Hard Loss 1.7450 (2.0840)	Arch Beta Loss 18.4455 (18.4404)	Arch depth Loss 3.4775 (3.4043)	Prec@(1,5) (64.0%, 91.2%)	
12/20 09:58:31PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 49/149] Final Prec@1 64.0280%
12/20 09:58:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.4244	Prec@(1,5) (41.0%, 71.9%)
12/20 09:58:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.4273	Prec@(1,5) (41.1%, 72.2%)
12/20 09:58:51PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.4513	Prec@(1,5) (40.7%, 71.6%)
12/20 09:58:57PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.4412	Prec@(1,5) (40.8%, 71.7%)
12/20 09:58:57PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 40.8320%
12/20 09:58:57PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/20 09:58:57PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 09:58:58PM searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
12/20 09:58:59PM searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 1., 0., 0.],
        [0., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
#####################
12/20 09:59:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][100/703]	Step 19650	lr 0.025	Loss 4.6605 (4.8833)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.9%, 8.3%)	
12/20 09:59:39PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][200/703]	Step 19750	lr 0.025	Loss 4.1036 (4.6397)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 10.8%)	
12/20 09:59:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][300/703]	Step 19850	lr 0.025	Loss 4.2309 (4.4931)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.4%, 14.0%)	
12/20 10:00:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][400/703]	Step 19950	lr 0.025	Loss 3.8122 (4.3722)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.5%, 17.1%)	
12/20 10:00:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][500/703]	Step 20050	lr 0.025	Loss 3.7737 (4.2764)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 19.5%)	
12/20 10:00:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][600/703]	Step 20150	lr 0.025	Loss 3.3443 (4.1914)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.5%, 21.7%)	
12/20 10:01:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][700/703]	Step 20250	lr 0.025	Loss 3.7932 (4.1224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.2%, 23.7%)	
12/20 10:01:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][703/703]	Step 20253	lr 0.025	Loss 3.6209 (4.1200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.3%, 23.8%)	
12/20 10:01:18PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 50/149] Final Prec@1 7.2644%
12/20 10:01:23PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][78/79]	Step 20254	Loss 3.8539	Prec@(1,5) (10.2%, 30.8%)
12/20 10:01:23PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 10.2000%
12/20 10:01:23PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:01:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][100/703]	Step 20354	lr 0.02499	Loss 3.5121 (3.6075)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.9%, 37.8%)	
12/20 10:02:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][200/703]	Step 20454	lr 0.02499	Loss 3.4284 (3.5763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.6%, 38.9%)	
12/20 10:02:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][300/703]	Step 20554	lr 0.02499	Loss 3.1754 (3.5355)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.5%, 40.2%)	
12/20 10:02:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][400/703]	Step 20654	lr 0.02499	Loss 3.0475 (3.4988)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.4%)	
12/20 10:03:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][500/703]	Step 20754	lr 0.02499	Loss 3.5969 (3.4690)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.9%, 42.3%)	
12/20 10:03:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][600/703]	Step 20854	lr 0.02499	Loss 3.3088 (3.4296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.7%, 43.4%)	
12/20 10:03:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][700/703]	Step 20954	lr 0.02499	Loss 3.3127 (3.3957)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 44.3%)	
12/20 10:03:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][703/703]	Step 20957	lr 0.02499	Loss 3.2582 (3.3947)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.4%, 44.3%)	
12/20 10:03:42PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 51/149] Final Prec@1 17.3756%
12/20 10:03:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][78/79]	Step 20958	Loss 3.2672	Prec@(1,5) (19.7%, 48.5%)
12/20 10:03:48PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 19.7000%
12/20 10:03:48PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:04:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][100/703]	Step 21058	lr 0.02498	Loss 3.3532 (3.1160)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.7%, 51.3%)	
12/20 10:04:28PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][200/703]	Step 21158	lr 0.02498	Loss 3.0572 (3.0954)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 52.2%)	
12/20 10:04:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][300/703]	Step 21258	lr 0.02498	Loss 2.9545 (3.0731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.3%, 52.8%)	
12/20 10:05:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][400/703]	Step 21358	lr 0.02498	Loss 3.1760 (3.0510)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.7%, 53.4%)	
12/20 10:05:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][500/703]	Step 21458	lr 0.02498	Loss 3.0588 (3.0335)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.2%, 54.0%)	
12/20 10:05:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][600/703]	Step 21558	lr 0.02498	Loss 2.6968 (3.0168)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.4%, 54.4%)	
12/20 10:06:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][700/703]	Step 21658	lr 0.02498	Loss 2.6095 (2.9961)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 54.9%)	
12/20 10:06:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][703/703]	Step 21661	lr 0.02498	Loss 2.5797 (2.9950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.0%)	
12/20 10:06:07PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 52/149] Final Prec@1 24.6978%
12/20 10:06:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][78/79]	Step 21662	Loss 3.0507	Prec@(1,5) (23.8%, 54.5%)
12/20 10:06:13PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 23.8000%
12/20 10:06:13PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:06:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][100/703]	Step 21762	lr 0.02495	Loss 2.8453 (2.8002)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 59.8%)	
12/20 10:06:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][200/703]	Step 21862	lr 0.02495	Loss 2.9239 (2.8015)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 59.7%)	
12/20 10:07:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][300/703]	Step 21962	lr 0.02495	Loss 2.6237 (2.7990)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 59.9%)	
12/20 10:07:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][400/703]	Step 22062	lr 0.02495	Loss 2.8337 (2.7912)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.6%, 60.2%)	
12/20 10:07:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][500/703]	Step 22162	lr 0.02495	Loss 2.6716 (2.7774)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 60.5%)	
12/20 10:08:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][600/703]	Step 22262	lr 0.02495	Loss 2.4929 (2.7700)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.1%, 60.6%)	
12/20 10:08:31PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][700/703]	Step 22362	lr 0.02495	Loss 2.4461 (2.7575)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 61.0%)	
12/20 10:08:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][703/703]	Step 22365	lr 0.02495	Loss 3.0795 (2.7576)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 60.9%)	
12/20 10:08:32PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 53/149] Final Prec@1 29.2822%
12/20 10:08:37PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][78/79]	Step 22366	Loss 3.2938	Prec@(1,5) (22.1%, 48.7%)
12/20 10:08:37PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 22.1000%
12/20 10:08:38PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:08:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][100/703]	Step 22466	lr 0.02491	Loss 2.3119 (2.6453)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.7%, 63.9%)	
12/20 10:09:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][200/703]	Step 22566	lr 0.02491	Loss 2.8279 (2.6294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.1%, 63.9%)	
12/20 10:09:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][300/703]	Step 22666	lr 0.02491	Loss 2.5916 (2.6285)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.0%)	
12/20 10:09:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][400/703]	Step 22766	lr 0.02491	Loss 2.3370 (2.6061)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.3%, 64.6%)	
12/20 10:10:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][500/703]	Step 22866	lr 0.02491	Loss 2.1400 (2.5989)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.5%, 64.7%)	
12/20 10:10:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][600/703]	Step 22966	lr 0.02491	Loss 2.5140 (2.5944)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.6%, 64.9%)	
12/20 10:10:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][700/703]	Step 23066	lr 0.02491	Loss 3.1769 (2.5920)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.0%)	
12/20 10:10:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][703/703]	Step 23069	lr 0.02491	Loss 2.4883 (2.5916)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.0%)	
12/20 10:10:58PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 54/149] Final Prec@1 32.7200%
12/20 10:11:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][78/79]	Step 23070	Loss 3.3099	Prec@(1,5) (22.6%, 50.2%)
12/20 10:11:04PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 22.5200%
12/20 10:11:04PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:11:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][100/703]	Step 23170	lr 0.02485	Loss 2.0352 (2.4831)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 67.3%)	
12/20 10:11:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][200/703]	Step 23270	lr 0.02485	Loss 2.1181 (2.4906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.0%, 67.6%)	
12/20 10:12:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][300/703]	Step 23370	lr 0.02485	Loss 2.3992 (2.4918)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 67.3%)	
12/20 10:12:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][400/703]	Step 23470	lr 0.02485	Loss 2.5910 (2.4785)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 67.5%)	
12/20 10:12:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][500/703]	Step 23570	lr 0.02485	Loss 2.4966 (2.4807)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 67.3%)	
12/20 10:13:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][600/703]	Step 23670	lr 0.02485	Loss 2.7770 (2.4746)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 67.4%)	
12/20 10:13:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][700/703]	Step 23770	lr 0.02485	Loss 2.3430 (2.4722)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 67.4%)	
12/20 10:13:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][703/703]	Step 23773	lr 0.02485	Loss 2.2006 (2.4716)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 67.4%)	
12/20 10:13:25PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 55/149] Final Prec@1 35.3244%
12/20 10:13:31PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][78/79]	Step 23774	Loss 2.5566	Prec@(1,5) (34.0%, 66.0%)
12/20 10:13:31PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 34.0000%
12/20 10:13:31PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:13:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][100/703]	Step 23874	lr 0.02479	Loss 2.3972 (2.3620)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.4%, 70.1%)	
12/20 10:14:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][200/703]	Step 23974	lr 0.02479	Loss 2.3629 (2.3708)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 69.6%)	
12/20 10:14:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][300/703]	Step 24074	lr 0.02479	Loss 2.5851 (2.3675)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.8%)	
12/20 10:14:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][400/703]	Step 24174	lr 0.02479	Loss 2.4615 (2.3673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.9%)	
12/20 10:15:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][500/703]	Step 24274	lr 0.02479	Loss 2.4600 (2.3696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.7%)	
12/20 10:15:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][600/703]	Step 24374	lr 0.02479	Loss 2.2488 (2.3662)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 69.9%)	
12/20 10:15:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][700/703]	Step 24474	lr 0.02479	Loss 2.2172 (2.3648)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 70.0%)	
12/20 10:15:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][703/703]	Step 24477	lr 0.02479	Loss 2.4893 (2.3652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 70.0%)	
12/20 10:15:53PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 56/149] Final Prec@1 37.5822%
12/20 10:15:59PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][78/79]	Step 24478	Loss 3.4699	Prec@(1,5) (21.2%, 48.5%)
12/20 10:15:59PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 21.2200%
12/20 10:15:59PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:16:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][100/703]	Step 24578	lr 0.02471	Loss 2.3516 (2.3079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.1%)	
12/20 10:16:40PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][200/703]	Step 24678	lr 0.02471	Loss 2.2038 (2.3076)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.3%)	
12/20 10:16:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][300/703]	Step 24778	lr 0.02471	Loss 2.3026 (2.3017)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.0%, 71.2%)	
12/20 10:17:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][400/703]	Step 24878	lr 0.02471	Loss 2.7232 (2.2926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 71.4%)	
12/20 10:17:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][500/703]	Step 24978	lr 0.02471	Loss 2.6287 (2.2923)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 71.4%)	
12/20 10:17:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][600/703]	Step 25078	lr 0.02471	Loss 2.4646 (2.2855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 71.6%)	
12/20 10:18:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][700/703]	Step 25178	lr 0.02471	Loss 2.3659 (2.2822)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 71.7%)	
12/20 10:18:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][703/703]	Step 25181	lr 0.02471	Loss 1.9868 (2.2820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 71.7%)	
12/20 10:18:17PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 57/149] Final Prec@1 39.3178%
12/20 10:18:23PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][78/79]	Step 25182	Loss 2.9638	Prec@(1,5) (28.1%, 59.1%)
12/20 10:18:23PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 28.1200%
12/20 10:18:23PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:18:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][100/703]	Step 25282	lr 0.02462	Loss 2.3660 (2.1564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 73.7%)	
12/20 10:19:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][200/703]	Step 25382	lr 0.02462	Loss 2.0324 (2.2060)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.0%)	
12/20 10:19:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][300/703]	Step 25482	lr 0.02462	Loss 2.5265 (2.2194)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 72.9%)	
12/20 10:19:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][400/703]	Step 25582	lr 0.02462	Loss 1.8697 (2.2210)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.1%)	
12/20 10:20:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][500/703]	Step 25682	lr 0.02462	Loss 1.9584 (2.2228)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.0%)	
12/20 10:20:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][600/703]	Step 25782	lr 0.02462	Loss 1.7888 (2.2169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.2%)	
12/20 10:20:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][700/703]	Step 25882	lr 0.02462	Loss 2.4954 (2.2188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.0%)	
12/20 10:20:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][703/703]	Step 25885	lr 0.02462	Loss 2.3306 (2.2192)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.0%)	
12/20 10:20:43PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 58/149] Final Prec@1 40.7778%
12/20 10:20:49PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][78/79]	Step 25886	Loss 2.9521	Prec@(1,5) (28.0%, 59.5%)
12/20 10:20:49PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 27.9800%
12/20 10:20:49PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:21:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][100/703]	Step 25986	lr 0.02452	Loss 2.2702 (2.1891)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 73.8%)	
12/20 10:21:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][200/703]	Step 26086	lr 0.02452	Loss 2.5320 (2.1839)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.1%)	
12/20 10:21:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][300/703]	Step 26186	lr 0.02452	Loss 1.7757 (2.1784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.2%)	
12/20 10:22:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][400/703]	Step 26286	lr 0.02452	Loss 2.0735 (2.1627)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 74.4%)	
12/20 10:22:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][500/703]	Step 26386	lr 0.02452	Loss 2.2737 (2.1609)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 74.4%)	
12/20 10:22:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][600/703]	Step 26486	lr 0.02452	Loss 1.7106 (2.1583)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 74.4%)	
12/20 10:23:05PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][700/703]	Step 26586	lr 0.02452	Loss 2.1730 (2.1625)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 74.3%)	
12/20 10:23:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][703/703]	Step 26589	lr 0.02452	Loss 2.5105 (2.1632)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 74.3%)	
12/20 10:23:06PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 59/149] Final Prec@1 42.0333%
12/20 10:23:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][78/79]	Step 26590	Loss 2.6078	Prec@(1,5) (33.8%, 65.6%)
12/20 10:23:12PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 33.7800%
12/20 10:23:12PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:23:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][100/703]	Step 26690	lr 0.02441	Loss 1.8395 (2.1147)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 75.1%)	
12/20 10:23:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][200/703]	Step 26790	lr 0.02441	Loss 2.2634 (2.1125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.1%)	
12/20 10:24:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][300/703]	Step 26890	lr 0.02441	Loss 2.5663 (2.1169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.2%)	
12/20 10:24:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][400/703]	Step 26990	lr 0.02441	Loss 2.0920 (2.1172)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.3%)	
12/20 10:24:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][500/703]	Step 27090	lr 0.02441	Loss 2.0305 (2.1157)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.3%)	
12/20 10:25:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][600/703]	Step 27190	lr 0.02441	Loss 2.1377 (2.1182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.3%)	
12/20 10:25:31PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][700/703]	Step 27290	lr 0.02441	Loss 2.0443 (2.1188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.4%)	
12/20 10:25:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][703/703]	Step 27293	lr 0.02441	Loss 2.2507 (2.1188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.4%)	
12/20 10:25:32PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 60/149] Final Prec@1 42.9022%
12/20 10:25:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][78/79]	Step 27294	Loss 2.4688	Prec@(1,5) (36.7%, 68.1%)
12/20 10:25:38PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 36.7400%
12/20 10:25:38PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:25:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][100/703]	Step 27394	lr 0.02429	Loss 1.9396 (2.0798)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 75.7%)	
12/20 10:26:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][200/703]	Step 27494	lr 0.02429	Loss 2.3519 (2.0826)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 75.7%)	
12/20 10:26:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][300/703]	Step 27594	lr 0.02429	Loss 1.9329 (2.0817)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 75.6%)	
12/20 10:26:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][400/703]	Step 27694	lr 0.02429	Loss 1.9740 (2.0787)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 75.7%)	
12/20 10:27:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][500/703]	Step 27794	lr 0.02429	Loss 2.0633 (2.0853)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 75.7%)	
12/20 10:27:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][600/703]	Step 27894	lr 0.02429	Loss 2.1730 (2.0834)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 75.7%)	
12/20 10:27:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][700/703]	Step 27994	lr 0.02429	Loss 2.2289 (2.0835)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 75.7%)	
12/20 10:27:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][703/703]	Step 27997	lr 0.02429	Loss 1.8577 (2.0833)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 75.7%)	
12/20 10:27:57PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 61/149] Final Prec@1 43.9889%
12/20 10:28:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][78/79]	Step 27998	Loss 2.4194	Prec@(1,5) (37.9%, 69.6%)
12/20 10:28:03PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 37.9200%
12/20 10:28:03PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:28:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][100/703]	Step 28098	lr 0.02416	Loss 2.2304 (2.0388)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 76.5%)	
12/20 10:28:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][200/703]	Step 28198	lr 0.02416	Loss 1.9857 (2.0411)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 76.2%)	
12/20 10:29:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][300/703]	Step 28298	lr 0.02416	Loss 1.9429 (2.0345)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 76.5%)	
12/20 10:29:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][400/703]	Step 28398	lr 0.02416	Loss 2.3197 (2.0288)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 76.7%)	
12/20 10:29:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][500/703]	Step 28498	lr 0.02416	Loss 2.1331 (2.0339)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 76.7%)	
12/20 10:30:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][600/703]	Step 28598	lr 0.02416	Loss 2.1311 (2.0318)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 76.8%)	
12/20 10:30:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][700/703]	Step 28698	lr 0.02416	Loss 2.1754 (2.0363)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 76.7%)	
12/20 10:30:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][703/703]	Step 28701	lr 0.02416	Loss 1.9485 (2.0358)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 76.7%)	
12/20 10:30:24PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 62/149] Final Prec@1 45.0267%
12/20 10:30:30PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][78/79]	Step 28702	Loss 2.4433	Prec@(1,5) (38.0%, 69.5%)
12/20 10:30:30PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 38.0200%
12/20 10:30:30PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:30:51PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][100/703]	Step 28802	lr 0.02401	Loss 2.0482 (1.9676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 77.9%)	
12/20 10:31:11PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][200/703]	Step 28902	lr 0.02401	Loss 2.2005 (1.9878)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 77.5%)	
12/20 10:31:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][300/703]	Step 29002	lr 0.02401	Loss 1.7438 (1.9837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 77.5%)	
12/20 10:31:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][400/703]	Step 29102	lr 0.02401	Loss 2.1847 (1.9966)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 77.3%)	
12/20 10:32:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][500/703]	Step 29202	lr 0.02401	Loss 2.0521 (1.9931)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 77.4%)	
12/20 10:32:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][600/703]	Step 29302	lr 0.02401	Loss 2.0345 (1.9925)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 77.5%)	
12/20 10:32:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][700/703]	Step 29402	lr 0.02401	Loss 1.6025 (1.9966)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 77.4%)	
12/20 10:32:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][703/703]	Step 29405	lr 0.02401	Loss 2.0784 (1.9975)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 77.4%)	
12/20 10:32:50PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 63/149] Final Prec@1 45.8444%
12/20 10:32:55PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][78/79]	Step 29406	Loss 2.8592	Prec@(1,5) (32.1%, 63.5%)
12/20 10:32:55PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 32.0600%
12/20 10:32:55PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:33:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][100/703]	Step 29506	lr 0.02386	Loss 2.6408 (1.9116)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.3%, 79.2%)	
12/20 10:33:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][200/703]	Step 29606	lr 0.02386	Loss 1.9177 (1.9287)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.2%)	
12/20 10:33:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][300/703]	Step 29706	lr 0.02386	Loss 1.8384 (1.9372)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 78.9%)	
12/20 10:34:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][400/703]	Step 29806	lr 0.02386	Loss 1.9844 (1.9481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 78.6%)	
12/20 10:34:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][500/703]	Step 29906	lr 0.02386	Loss 1.8103 (1.9519)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 78.5%)	
12/20 10:34:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][600/703]	Step 30006	lr 0.02386	Loss 2.0005 (1.9557)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 78.3%)	
12/20 10:35:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][700/703]	Step 30106	lr 0.02386	Loss 2.2207 (1.9547)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 78.4%)	
12/20 10:35:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][703/703]	Step 30109	lr 0.02386	Loss 2.2725 (1.9554)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 78.4%)	
12/20 10:35:17PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 64/149] Final Prec@1 46.7644%
12/20 10:35:22PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][78/79]	Step 30110	Loss 2.8000	Prec@(1,5) (30.7%, 62.5%)
12/20 10:35:22PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 30.7800%
12/20 10:35:22PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:35:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][100/703]	Step 30210	lr 0.02369	Loss 2.0758 (1.8810)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 79.8%)	
12/20 10:36:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][200/703]	Step 30310	lr 0.02369	Loss 2.2768 (1.9065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 79.3%)	
12/20 10:36:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][300/703]	Step 30410	lr 0.02369	Loss 1.6393 (1.9235)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 78.9%)	
12/20 10:36:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][400/703]	Step 30510	lr 0.02369	Loss 2.0552 (1.9282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 78.9%)	
12/20 10:37:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][500/703]	Step 30610	lr 0.02369	Loss 1.9251 (1.9287)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 78.9%)	
12/20 10:37:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][600/703]	Step 30710	lr 0.02369	Loss 1.6859 (1.9249)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 78.8%)	
12/20 10:37:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][700/703]	Step 30810	lr 0.02369	Loss 2.1675 (1.9283)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 78.7%)	
12/20 10:37:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][703/703]	Step 30813	lr 0.02369	Loss 1.7710 (1.9283)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 78.7%)	
12/20 10:37:43PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 65/149] Final Prec@1 47.5222%
12/20 10:37:49PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][78/79]	Step 30814	Loss 2.3130	Prec@(1,5) (40.1%, 71.9%)
12/20 10:37:49PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 40.1600%
12/20 10:37:49PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:38:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][100/703]	Step 30914	lr 0.02352	Loss 1.4532 (1.8781)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.3%, 79.7%)	
12/20 10:38:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][200/703]	Step 31014	lr 0.02352	Loss 2.0275 (1.8819)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 79.8%)	
12/20 10:38:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][300/703]	Step 31114	lr 0.02352	Loss 2.0430 (1.8862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 79.8%)	
12/20 10:39:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][400/703]	Step 31214	lr 0.02352	Loss 1.3829 (1.8960)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.5%)	
12/20 10:39:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][500/703]	Step 31314	lr 0.02352	Loss 2.0896 (1.8954)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 79.4%)	
12/20 10:39:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][600/703]	Step 31414	lr 0.02352	Loss 2.3410 (1.8930)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.5%)	
12/20 10:40:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][700/703]	Step 31514	lr 0.02352	Loss 2.1464 (1.9021)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.3%)	
12/20 10:40:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][703/703]	Step 31517	lr 0.02352	Loss 1.6192 (1.9017)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.3%)	
12/20 10:40:10PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 66/149] Final Prec@1 47.8133%
12/20 10:40:15PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][78/79]	Step 31518	Loss 2.5566	Prec@(1,5) (36.4%, 67.8%)
12/20 10:40:15PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 36.3800%
12/20 10:40:15PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:40:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][100/703]	Step 31618	lr 0.02333	Loss 1.9277 (1.8056)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 80.4%)	
12/20 10:40:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][200/703]	Step 31718	lr 0.02333	Loss 1.7106 (1.8264)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.4%)	
12/20 10:41:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][300/703]	Step 31818	lr 0.02333	Loss 1.9838 (1.8351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.5%)	
12/20 10:41:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][400/703]	Step 31918	lr 0.02333	Loss 1.8719 (1.8483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.2%)	
12/20 10:41:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][500/703]	Step 32018	lr 0.02333	Loss 1.7424 (1.8587)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.0%)	
12/20 10:42:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][600/703]	Step 32118	lr 0.02333	Loss 2.1096 (1.8697)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 79.8%)	
12/20 10:42:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][700/703]	Step 32218	lr 0.02333	Loss 1.8530 (1.8748)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 79.8%)	
12/20 10:42:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][703/703]	Step 32221	lr 0.02333	Loss 1.6666 (1.8745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 79.8%)	
12/20 10:42:36PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 67/149] Final Prec@1 48.3978%
12/20 10:42:42PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][78/79]	Step 32222	Loss 2.2210	Prec@(1,5) (42.1%, 73.1%)
12/20 10:42:42PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 42.1800%
12/20 10:42:42PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:43:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][100/703]	Step 32322	lr 0.02313	Loss 1.5501 (1.7919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.4%)	
12/20 10:43:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][200/703]	Step 32422	lr 0.02313	Loss 1.9467 (1.8082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 80.9%)	
12/20 10:43:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][300/703]	Step 32522	lr 0.02313	Loss 1.8435 (1.8237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 80.8%)	
12/20 10:44:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][400/703]	Step 32622	lr 0.02313	Loss 1.4385 (1.8220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 80.7%)	
12/20 10:44:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][500/703]	Step 32722	lr 0.02313	Loss 1.9117 (1.8383)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 80.3%)	
12/20 10:44:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][600/703]	Step 32822	lr 0.02313	Loss 1.7115 (1.8376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 80.3%)	
12/20 10:45:02PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][700/703]	Step 32922	lr 0.02313	Loss 1.9615 (1.8413)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 80.2%)	
12/20 10:45:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][703/703]	Step 32925	lr 0.02313	Loss 1.7682 (1.8410)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 80.2%)	
12/20 10:45:03PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 68/149] Final Prec@1 49.6800%
12/20 10:45:08PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][78/79]	Step 32926	Loss 2.6876	Prec@(1,5) (34.5%, 65.7%)
12/20 10:45:09PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 34.5000%
12/20 10:45:09PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:45:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][100/703]	Step 33026	lr 0.02292	Loss 1.9872 (1.7384)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.6%)	
12/20 10:45:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][200/703]	Step 33126	lr 0.02292	Loss 2.1894 (1.7777)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.8%)	
12/20 10:46:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][300/703]	Step 33226	lr 0.02292	Loss 1.8291 (1.7931)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.3%)	
12/20 10:46:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][400/703]	Step 33326	lr 0.02292	Loss 1.6741 (1.8036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.2%)	
12/20 10:46:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][500/703]	Step 33426	lr 0.02292	Loss 1.5747 (1.8124)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.0%, 80.9%)	
12/20 10:47:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][600/703]	Step 33526	lr 0.02292	Loss 1.7377 (1.8150)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 80.9%)	
12/20 10:47:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][700/703]	Step 33626	lr 0.02292	Loss 1.6153 (1.8190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 80.8%)	
12/20 10:47:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][703/703]	Step 33629	lr 0.02292	Loss 1.4800 (1.8186)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 80.8%)	
12/20 10:47:30PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 69/149] Final Prec@1 49.8756%
12/20 10:47:36PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][78/79]	Step 33630	Loss 2.2014	Prec@(1,5) (42.1%, 75.1%)
12/20 10:47:36PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 42.1400%
12/20 10:47:36PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:47:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][100/703]	Step 33730	lr 0.02271	Loss 1.9481 (1.7271)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.4%)	
12/20 10:48:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][200/703]	Step 33830	lr 0.02271	Loss 1.8565 (1.7483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.0%)	
12/20 10:48:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][300/703]	Step 33930	lr 0.02271	Loss 1.8314 (1.7612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 81.8%)	
12/20 10:48:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][400/703]	Step 34030	lr 0.02271	Loss 1.7163 (1.7756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.7%)	
12/20 10:49:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][500/703]	Step 34130	lr 0.02271	Loss 1.9147 (1.7855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.5%)	
12/20 10:49:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][600/703]	Step 34230	lr 0.02271	Loss 1.6092 (1.7893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.4%)	
12/20 10:49:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][700/703]	Step 34330	lr 0.02271	Loss 1.3045 (1.7974)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.3%)	
12/20 10:49:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][703/703]	Step 34333	lr 0.02271	Loss 1.8277 (1.7980)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.2%)	
12/20 10:49:57PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 70/149] Final Prec@1 50.2511%
12/20 10:50:02PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][78/79]	Step 34334	Loss 2.3922	Prec@(1,5) (38.0%, 71.1%)
12/20 10:50:03PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 37.9800%
12/20 10:50:03PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:50:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][100/703]	Step 34434	lr 0.02248	Loss 1.8682 (1.7188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.0%, 83.0%)	
12/20 10:50:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][200/703]	Step 34534	lr 0.02248	Loss 1.7959 (1.7383)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.6%)	
12/20 10:51:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][300/703]	Step 34634	lr 0.02248	Loss 1.4572 (1.7382)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 82.4%)	
12/20 10:51:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][400/703]	Step 34734	lr 0.02248	Loss 1.6221 (1.7563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.0%)	
12/20 10:51:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][500/703]	Step 34834	lr 0.02248	Loss 2.1333 (1.7639)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.8%)	
12/20 10:52:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][600/703]	Step 34934	lr 0.02248	Loss 1.9629 (1.7705)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.7%)	
12/20 10:52:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][700/703]	Step 35034	lr 0.02248	Loss 1.8181 (1.7744)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.5%)	
12/20 10:52:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][703/703]	Step 35037	lr 0.02248	Loss 1.3710 (1.7739)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.6%)	
12/20 10:52:24PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 71/149] Final Prec@1 50.7467%
12/20 10:52:29PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][78/79]	Step 35038	Loss 2.2286	Prec@(1,5) (41.4%, 73.7%)
12/20 10:52:29PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 41.4200%
12/20 10:52:29PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:52:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][100/703]	Step 35138	lr 0.02225	Loss 1.5691 (1.6856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 82.7%)	
12/20 10:53:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][200/703]	Step 35238	lr 0.02225	Loss 1.9834 (1.6975)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 82.6%)	
12/20 10:53:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][300/703]	Step 35338	lr 0.02225	Loss 2.0682 (1.7163)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 82.5%)	
12/20 10:53:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][400/703]	Step 35438	lr 0.02225	Loss 2.0317 (1.7307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 82.3%)	
12/20 10:54:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][500/703]	Step 35538	lr 0.02225	Loss 1.4564 (1.7307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.4%)	
12/20 10:54:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][600/703]	Step 35638	lr 0.02225	Loss 1.7849 (1.7370)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.3%)	
12/20 10:54:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][700/703]	Step 35738	lr 0.02225	Loss 1.5633 (1.7452)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 82.2%)	
12/20 10:54:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][703/703]	Step 35741	lr 0.02225	Loss 1.8631 (1.7452)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.2%)	
12/20 10:54:47PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 72/149] Final Prec@1 51.7422%
12/20 10:54:52PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][78/79]	Step 35742	Loss 2.2152	Prec@(1,5) (43.0%, 74.8%)
12/20 10:54:53PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 43.0200%
12/20 10:54:53PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:55:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][100/703]	Step 35842	lr 0.022	Loss 1.5128 (1.7010)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.4%, 82.5%)	
12/20 10:55:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][200/703]	Step 35942	lr 0.022	Loss 1.6378 (1.7058)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 82.5%)	
12/20 10:55:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][300/703]	Step 36042	lr 0.022	Loss 1.7101 (1.7001)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 82.7%)	
12/20 10:56:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][400/703]	Step 36142	lr 0.022	Loss 1.9297 (1.7078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 82.6%)	
12/20 10:56:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][500/703]	Step 36242	lr 0.022	Loss 1.7335 (1.7168)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 82.4%)	
12/20 10:56:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][600/703]	Step 36342	lr 0.022	Loss 1.9435 (1.7238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.0%, 82.3%)	
12/20 10:57:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][700/703]	Step 36442	lr 0.022	Loss 1.9185 (1.7295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.0%, 82.2%)	
12/20 10:57:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][703/703]	Step 36445	lr 0.022	Loss 1.5067 (1.7289)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.0%, 82.2%)	
12/20 10:57:13PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 73/149] Final Prec@1 51.9667%
12/20 10:57:18PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][78/79]	Step 36446	Loss 2.5024	Prec@(1,5) (37.2%, 67.9%)
12/20 10:57:18PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 37.2400%
12/20 10:57:18PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 10:57:39PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][100/703]	Step 36546	lr 0.02175	Loss 1.5332 (1.6755)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.1%)	
12/20 10:57:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][200/703]	Step 36646	lr 0.02175	Loss 1.2975 (1.6889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 82.7%)	
12/20 10:58:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][300/703]	Step 36746	lr 0.02175	Loss 1.6076 (1.6949)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 82.8%)	
12/20 10:58:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][400/703]	Step 36846	lr 0.02175	Loss 2.0726 (1.6963)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 82.8%)	
12/20 10:58:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][500/703]	Step 36946	lr 0.02175	Loss 1.8949 (1.7007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 82.7%)	
12/20 10:59:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][600/703]	Step 37046	lr 0.02175	Loss 1.6387 (1.7089)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 82.6%)	
12/20 10:59:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][700/703]	Step 37146	lr 0.02175	Loss 1.6393 (1.7135)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 82.6%)	
12/20 10:59:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][703/703]	Step 37149	lr 0.02175	Loss 1.8408 (1.7137)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 82.6%)	
12/20 10:59:34PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 74/149] Final Prec@1 52.2844%
12/20 10:59:40PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][78/79]	Step 37150	Loss 2.2229	Prec@(1,5) (42.8%, 73.6%)
12/20 10:59:40PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 42.8400%
12/20 10:59:40PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 11:00:01PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][100/703]	Step 37250	lr 0.02149	Loss 1.8198 (1.6338)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.3%, 83.5%)	
12/20 11:00:21PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][200/703]	Step 37350	lr 0.02149	Loss 1.8959 (1.6470)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.3%, 83.0%)	
12/20 11:00:40PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][300/703]	Step 37450	lr 0.02149	Loss 1.4049 (1.6585)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.0%, 83.0%)	
12/20 11:00:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][400/703]	Step 37550	lr 0.02149	Loss 1.5240 (1.6695)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 83.0%)	
12/20 11:01:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][500/703]	Step 37650	lr 0.02149	Loss 2.0615 (1.6853)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.3%, 82.8%)	
12/20 11:01:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][600/703]	Step 37750	lr 0.02149	Loss 1.8498 (1.6859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.3%, 82.9%)	
12/20 11:01:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][700/703]	Step 37850	lr 0.02149	Loss 1.7561 (1.6944)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 82.7%)	
12/20 11:01:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][703/703]	Step 37853	lr 0.02149	Loss 1.3984 (1.6942)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 82.7%)	
12/20 11:01:58PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 75/149] Final Prec@1 53.0644%
12/20 11:02:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][78/79]	Step 37854	Loss 2.1454	Prec@(1,5) (43.3%, 75.4%)
12/20 11:02:03PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 43.4200%
12/20 11:02:03PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7520%
12/20 11:02:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][100/703]	Step 37954	lr 0.02121	Loss 1.4562 (1.6060)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 84.7%)	
12/20 11:02:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][200/703]	Step 38054	lr 0.02121	Loss 1.8346 (1.6272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.2%)	
12/20 11:03:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][300/703]	Step 38154	lr 0.02121	Loss 1.4618 (1.6365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.1%)	
12/20 11:03:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][400/703]	Step 38254	lr 0.02121	Loss 1.5256 (1.6474)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 83.8%)	
12/20 11:03:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][500/703]	Step 38354	lr 0.02121	Loss 1.9208 (1.6555)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 83.6%)	
12/20 11:04:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][600/703]	Step 38454	lr 0.02121	Loss 1.9206 (1.6652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.5%)	
12/20 11:04:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][700/703]	Step 38554	lr 0.02121	Loss 1.5921 (1.6720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.3%)	
12/20 11:04:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][703/703]	Step 38557	lr 0.02121	Loss 1.5635 (1.6721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.3%)	
12/20 11:04:23PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 76/149] Final Prec@1 53.4511%
12/20 11:04:29PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][78/79]	Step 38558	Loss 2.1772	Prec@(1,5) (43.9%, 74.0%)
12/20 11:04:29PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 43.8600%
12/20 11:04:29PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.8600%
12/20 11:04:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][100/703]	Step 38658	lr 0.02094	Loss 1.4609 (1.6051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.4%)	
12/20 11:05:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][200/703]	Step 38758	lr 0.02094	Loss 1.4173 (1.6209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.3%)	
12/20 11:05:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][300/703]	Step 38858	lr 0.02094	Loss 1.5869 (1.6354)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.1%)	
12/20 11:05:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][400/703]	Step 38958	lr 0.02094	Loss 1.8417 (1.6449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 83.9%)	
12/20 11:06:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][500/703]	Step 39058	lr 0.02094	Loss 1.1772 (1.6467)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.7%, 83.9%)	
12/20 11:06:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][600/703]	Step 39158	lr 0.02094	Loss 1.6258 (1.6489)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.7%, 83.8%)	
12/20 11:06:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][700/703]	Step 39258	lr 0.02094	Loss 1.6757 (1.6491)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 83.8%)	
12/20 11:06:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][703/703]	Step 39261	lr 0.02094	Loss 1.8435 (1.6495)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 83.8%)	
12/20 11:06:50PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 77/149] Final Prec@1 53.7822%
12/20 11:06:55PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][78/79]	Step 39262	Loss 2.3425	Prec@(1,5) (40.8%, 72.3%)
12/20 11:06:55PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 40.8800%
12/20 11:06:55PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.8600%
12/20 11:07:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][100/703]	Step 39362	lr 0.02065	Loss 1.2136 (1.5656)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.2%)	
12/20 11:07:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][200/703]	Step 39462	lr 0.02065	Loss 1.6586 (1.5886)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 84.6%)	
12/20 11:07:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][300/703]	Step 39562	lr 0.02065	Loss 1.5717 (1.6111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.4%)	
12/20 11:08:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][400/703]	Step 39662	lr 0.02065	Loss 1.6212 (1.6186)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.4%)	
12/20 11:08:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][500/703]	Step 39762	lr 0.02065	Loss 1.5346 (1.6232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.2%)	
12/20 11:08:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][600/703]	Step 39862	lr 0.02065	Loss 1.6310 (1.6262)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.1%)	
12/20 11:09:11PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][700/703]	Step 39962	lr 0.02065	Loss 1.9366 (1.6273)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.0%)	
12/20 11:09:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][703/703]	Step 39965	lr 0.02065	Loss 1.2097 (1.6270)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.0%)	
12/20 11:09:12PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 78/149] Final Prec@1 54.1333%
12/20 11:09:17PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][78/79]	Step 39966	Loss 2.0475	Prec@(1,5) (45.8%, 76.9%)
12/20 11:09:18PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 45.7400%
12/20 11:09:18PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.7400%
12/20 11:09:39PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][100/703]	Step 40066	lr 0.02035	Loss 1.4951 (1.5337)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.7%)	
12/20 11:09:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][200/703]	Step 40166	lr 0.02035	Loss 1.2120 (1.5246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 85.6%)	
12/20 11:10:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][300/703]	Step 40266	lr 0.02035	Loss 1.5158 (1.5480)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 85.3%)	
12/20 11:10:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][400/703]	Step 40366	lr 0.02035	Loss 1.5817 (1.5679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.0%)	
12/20 11:10:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][500/703]	Step 40466	lr 0.02035	Loss 1.5531 (1.5810)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 84.9%)	
12/20 11:11:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][600/703]	Step 40566	lr 0.02035	Loss 1.5079 (1.5893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 84.7%)	
12/20 11:11:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][700/703]	Step 40666	lr 0.02035	Loss 1.7819 (1.5962)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.5%)	
12/20 11:11:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][703/703]	Step 40669	lr 0.02035	Loss 1.9117 (1.5970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.5%)	
12/20 11:11:39PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 79/149] Final Prec@1 55.2956%
12/20 11:11:44PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][78/79]	Step 40670	Loss 2.1613	Prec@(1,5) (43.9%, 74.9%)
12/20 11:11:44PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 43.9000%
12/20 11:11:44PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.7400%
12/20 11:12:05PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][100/703]	Step 40770	lr 0.02005	Loss 1.3772 (1.5377)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.2%, 85.8%)	
12/20 11:12:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][200/703]	Step 40870	lr 0.02005	Loss 1.3623 (1.5304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 85.6%)	
12/20 11:12:45PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][300/703]	Step 40970	lr 0.02005	Loss 1.6181 (1.5523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.3%)	
12/20 11:13:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][400/703]	Step 41070	lr 0.02005	Loss 1.4713 (1.5638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.1%)	
12/20 11:13:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][500/703]	Step 41170	lr 0.02005	Loss 1.7786 (1.5727)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.0%)	
12/20 11:13:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][600/703]	Step 41270	lr 0.02005	Loss 1.8615 (1.5750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 84.9%)	
12/20 11:14:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][700/703]	Step 41370	lr 0.02005	Loss 1.3278 (1.5763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.8%, 84.9%)	
12/20 11:14:04PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][703/703]	Step 41373	lr 0.02005	Loss 1.5828 (1.5761)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.8%, 84.9%)	
12/20 11:14:05PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 80/149] Final Prec@1 55.7911%
12/20 11:14:10PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][78/79]	Step 41374	Loss 2.3232	Prec@(1,5) (41.1%, 72.6%)
12/20 11:14:10PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 41.1000%
12/20 11:14:10PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.7400%
12/20 11:14:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][100/703]	Step 41474	lr 0.01975	Loss 1.5082 (1.4986)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.5%)	
12/20 11:14:51PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][200/703]	Step 41574	lr 0.01975	Loss 1.4997 (1.5337)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.8%)	
12/20 11:15:11PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][300/703]	Step 41674	lr 0.01975	Loss 1.3463 (1.5315)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.6%)	
12/20 11:15:31PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][400/703]	Step 41774	lr 0.01975	Loss 1.1071 (1.5331)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.6%)	
12/20 11:15:50PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][500/703]	Step 41874	lr 0.01975	Loss 1.6294 (1.5438)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.4%)	
12/20 11:16:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][600/703]	Step 41974	lr 0.01975	Loss 1.7724 (1.5588)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.3%)	
12/20 11:16:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][700/703]	Step 42074	lr 0.01975	Loss 1.5382 (1.5633)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.1%)	
12/20 11:16:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][703/703]	Step 42077	lr 0.01975	Loss 1.4762 (1.5631)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.1%)	
12/20 11:16:31PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 81/149] Final Prec@1 55.9822%
12/20 11:16:36PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][78/79]	Step 42078	Loss 2.1015	Prec@(1,5) (45.8%, 76.3%)
12/20 11:16:36PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 45.8000%
12/20 11:16:37PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8000%
12/20 11:16:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][100/703]	Step 42178	lr 0.01943	Loss 1.4614 (1.4779)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.9%)	
12/20 11:17:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][200/703]	Step 42278	lr 0.01943	Loss 1.5468 (1.4820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.7%)	
12/20 11:17:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][300/703]	Step 42378	lr 0.01943	Loss 1.4551 (1.5090)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.4%)	
12/20 11:17:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][400/703]	Step 42478	lr 0.01943	Loss 2.1127 (1.5190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.2%)	
12/20 11:18:17PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][500/703]	Step 42578	lr 0.01943	Loss 1.2293 (1.5272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.0%)	
12/20 11:18:37PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][600/703]	Step 42678	lr 0.01943	Loss 1.5057 (1.5311)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.9%)	
12/20 11:18:57PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][700/703]	Step 42778	lr 0.01943	Loss 1.3294 (1.5411)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.8%)	
12/20 11:18:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][703/703]	Step 42781	lr 0.01943	Loss 1.9145 (1.5423)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.8%)	
12/20 11:18:58PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 82/149] Final Prec@1 56.2644%
12/20 11:19:03PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][78/79]	Step 42782	Loss 2.4106	Prec@(1,5) (39.9%, 71.7%)
12/20 11:19:03PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 39.9000%
12/20 11:19:03PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8000%
12/20 11:19:24PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][100/703]	Step 42882	lr 0.01911	Loss 1.4008 (1.4925)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.6%)	
12/20 11:19:43PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][200/703]	Step 42982	lr 0.01911	Loss 1.3787 (1.4934)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.7%)	
12/20 11:20:02PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][300/703]	Step 43082	lr 0.01911	Loss 1.2698 (1.4864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.7%)	
12/20 11:20:21PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][400/703]	Step 43182	lr 0.01911	Loss 1.6358 (1.4973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.4%)	
12/20 11:20:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][500/703]	Step 43282	lr 0.01911	Loss 1.5315 (1.5067)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.2%)	
12/20 11:21:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][600/703]	Step 43382	lr 0.01911	Loss 1.8483 (1.5096)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.2%)	
12/20 11:21:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][700/703]	Step 43482	lr 0.01911	Loss 1.7327 (1.5172)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.1%)	
12/20 11:21:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][703/703]	Step 43485	lr 0.01911	Loss 1.7266 (1.5182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.0%)	
12/20 11:21:20PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 83/149] Final Prec@1 57.1244%
12/20 11:21:25PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][78/79]	Step 43486	Loss 2.0314	Prec@(1,5) (46.6%, 77.3%)
12/20 11:21:25PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 46.6600%
12/20 11:21:26PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.6600%
12/20 11:21:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][100/703]	Step 43586	lr 0.01878	Loss 1.2681 (1.4013)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.0%)	
12/20 11:22:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][200/703]	Step 43686	lr 0.01878	Loss 1.4401 (1.4445)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.4%)	
12/20 11:22:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][300/703]	Step 43786	lr 0.01878	Loss 1.1952 (1.4578)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.1%)	
12/20 11:22:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][400/703]	Step 43886	lr 0.01878	Loss 1.7731 (1.4710)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.9%)	
12/20 11:23:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][500/703]	Step 43986	lr 0.01878	Loss 1.3347 (1.4844)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.6%)	
12/20 11:23:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][600/703]	Step 44086	lr 0.01878	Loss 1.3741 (1.4880)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.6%)	
12/20 11:23:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][700/703]	Step 44186	lr 0.01878	Loss 1.5825 (1.4919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.4%)	
12/20 11:23:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][703/703]	Step 44189	lr 0.01878	Loss 1.4940 (1.4922)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.4%)	
12/20 11:23:43PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 84/149] Final Prec@1 57.6333%
12/20 11:23:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][78/79]	Step 44190	Loss 2.0791	Prec@(1,5) (46.5%, 76.6%)
12/20 11:23:48PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 46.4400%
12/20 11:23:48PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.6600%
12/20 11:24:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][100/703]	Step 44290	lr 0.01845	Loss 1.5665 (1.4454)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.7%)	
12/20 11:24:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][200/703]	Step 44390	lr 0.01845	Loss 1.5103 (1.4622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.6%)	
12/20 11:24:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][300/703]	Step 44490	lr 0.01845	Loss 1.5409 (1.4638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.5%)	
12/20 11:25:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][400/703]	Step 44590	lr 0.01845	Loss 1.2218 (1.4694)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.5%)	
12/20 11:25:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][500/703]	Step 44690	lr 0.01845	Loss 1.7974 (1.4731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.5%)	
12/20 11:25:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][600/703]	Step 44790	lr 0.01845	Loss 1.4603 (1.4735)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.5%)	
12/20 11:26:05PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][700/703]	Step 44890	lr 0.01845	Loss 1.2955 (1.4770)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.5%)	
12/20 11:26:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][703/703]	Step 44893	lr 0.01845	Loss 1.4425 (1.4773)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.5%)	
12/20 11:26:06PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 85/149] Final Prec@1 57.6778%
12/20 11:26:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][78/79]	Step 44894	Loss 2.0611	Prec@(1,5) (47.1%, 77.4%)
12/20 11:26:12PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 47.1800%
12/20 11:26:12PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.1800%
12/20 11:26:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][100/703]	Step 44994	lr 0.01811	Loss 1.1199 (1.3670)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.3%)	
12/20 11:26:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][200/703]	Step 45094	lr 0.01811	Loss 1.9053 (1.4249)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.3%)	
12/20 11:27:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][300/703]	Step 45194	lr 0.01811	Loss 1.3411 (1.4356)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.0%)	
12/20 11:27:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][400/703]	Step 45294	lr 0.01811	Loss 1.3244 (1.4376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.0%)	
12/20 11:27:52PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][500/703]	Step 45394	lr 0.01811	Loss 1.4673 (1.4428)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 86.9%)	
12/20 11:28:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][600/703]	Step 45494	lr 0.01811	Loss 1.6880 (1.4527)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 86.8%)	
12/20 11:28:31PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][700/703]	Step 45594	lr 0.01811	Loss 1.5793 (1.4592)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.3%, 86.8%)	
12/20 11:28:32PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][703/703]	Step 45597	lr 0.01811	Loss 1.2472 (1.4586)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.3%, 86.8%)	
12/20 11:28:32PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 86/149] Final Prec@1 58.3178%
12/20 11:28:38PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][78/79]	Step 45598	Loss 2.4411	Prec@(1,5) (39.4%, 70.7%)
12/20 11:28:38PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 39.3600%
12/20 11:28:38PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.1800%
12/20 11:28:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][100/703]	Step 45698	lr 0.01777	Loss 1.7376 (1.3806)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.8%)	
12/20 11:29:19PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][200/703]	Step 45798	lr 0.01777	Loss 1.2159 (1.3826)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.6%)	
12/20 11:29:39PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][300/703]	Step 45898	lr 0.01777	Loss 1.6871 (1.4001)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.4%)	
12/20 11:29:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][400/703]	Step 45998	lr 0.01777	Loss 1.4969 (1.4164)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 88.0%)	
12/20 11:30:18PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][500/703]	Step 46098	lr 0.01777	Loss 1.2510 (1.4194)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.9%)	
12/20 11:30:38PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][600/703]	Step 46198	lr 0.01777	Loss 1.3791 (1.4260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.7%)	
12/20 11:30:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][700/703]	Step 46298	lr 0.01777	Loss 1.3023 (1.4345)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.5%)	
12/20 11:30:58PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][703/703]	Step 46301	lr 0.01777	Loss 1.1909 (1.4350)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.5%)	
12/20 11:30:59PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 87/149] Final Prec@1 58.9356%
12/20 11:31:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][78/79]	Step 46302	Loss 2.2293	Prec@(1,5) (43.6%, 73.5%)
12/20 11:31:04PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 43.6400%
12/20 11:31:04PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.1800%
12/20 11:31:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][100/703]	Step 46402	lr 0.01742	Loss 1.2782 (1.3703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.5%)	
12/20 11:31:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][200/703]	Step 46502	lr 0.01742	Loss 1.6948 (1.3963)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.1%)	
12/20 11:32:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][300/703]	Step 46602	lr 0.01742	Loss 1.7453 (1.4035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 87.8%)	
12/20 11:32:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][400/703]	Step 46702	lr 0.01742	Loss 1.7155 (1.4085)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.6%)	
12/20 11:32:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][500/703]	Step 46802	lr 0.01742	Loss 1.4845 (1.4117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.6%)	
12/20 11:33:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][600/703]	Step 46902	lr 0.01742	Loss 1.1901 (1.4076)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 87.6%)	
12/20 11:33:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][700/703]	Step 47002	lr 0.01742	Loss 1.3347 (1.4117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.6%)	
12/20 11:33:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][703/703]	Step 47005	lr 0.01742	Loss 1.7210 (1.4117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.6%)	
12/20 11:33:20PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 88/149] Final Prec@1 59.5667%
12/20 11:33:26PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][78/79]	Step 47006	Loss 2.5628	Prec@(1,5) (38.2%, 69.4%)
12/20 11:33:26PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 38.2600%
12/20 11:33:26PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.1800%
12/20 11:33:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][100/703]	Step 47106	lr 0.01706	Loss 1.7403 (1.3519)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.4%)	
12/20 11:34:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][200/703]	Step 47206	lr 0.01706	Loss 1.2098 (1.3488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.7%)	
12/20 11:34:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][300/703]	Step 47306	lr 0.01706	Loss 1.1318 (1.3482)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.5%)	
12/20 11:34:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][400/703]	Step 47406	lr 0.01706	Loss 1.7344 (1.3649)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.3%)	
12/20 11:35:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][500/703]	Step 47506	lr 0.01706	Loss 1.1307 (1.3731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.1%)	
12/20 11:35:23PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][600/703]	Step 47606	lr 0.01706	Loss 1.2830 (1.3832)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 87.9%)	
12/20 11:35:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][700/703]	Step 47706	lr 0.01706	Loss 1.3671 (1.3932)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 87.8%)	
12/20 11:35:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][703/703]	Step 47709	lr 0.01706	Loss 1.1444 (1.3928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 87.8%)	
12/20 11:35:43PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 89/149] Final Prec@1 60.3378%
12/20 11:35:48PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][78/79]	Step 47710	Loss 1.9415	Prec@(1,5) (48.6%, 79.4%)
12/20 11:35:48PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 48.6200%
12/20 11:35:49PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6200%
12/20 11:36:10PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][100/703]	Step 47810	lr 0.01671	Loss 1.2554 (1.2959)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.6%)	
12/20 11:36:30PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][200/703]	Step 47910	lr 0.01671	Loss 1.1265 (1.3107)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.4%)	
12/20 11:36:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][300/703]	Step 48010	lr 0.01671	Loss 1.2823 (1.3356)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.2%)	
12/20 11:37:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][400/703]	Step 48110	lr 0.01671	Loss 1.5332 (1.3464)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.9%)	
12/20 11:37:29PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][500/703]	Step 48210	lr 0.01671	Loss 1.6426 (1.3635)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.5%)	
12/20 11:37:49PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][600/703]	Step 48310	lr 0.01671	Loss 1.8736 (1.3728)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.4%)	
12/20 11:38:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][700/703]	Step 48410	lr 0.01671	Loss 1.3580 (1.3785)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.2%)	
12/20 11:38:09PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][703/703]	Step 48413	lr 0.01671	Loss 1.2537 (1.3784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.2%)	
12/20 11:38:10PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 90/149] Final Prec@1 60.5844%
12/20 11:38:15PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][78/79]	Step 48414	Loss 1.9240	Prec@(1,5) (48.4%, 80.1%)
12/20 11:38:15PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 48.4400%
12/20 11:38:15PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6200%
12/20 11:38:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][100/703]	Step 48514	lr 0.01635	Loss 0.9747 (1.2628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.0%)	
12/20 11:38:56PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][200/703]	Step 48614	lr 0.01635	Loss 1.7500 (1.2906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.4%)	
12/20 11:39:16PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][300/703]	Step 48714	lr 0.01635	Loss 1.6535 (1.3048)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.2%)	
12/20 11:39:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][400/703]	Step 48814	lr 0.01635	Loss 1.2761 (1.3180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.9%)	
12/20 11:39:55PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][500/703]	Step 48914	lr 0.01635	Loss 1.6521 (1.3300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.8%)	
12/20 11:40:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][600/703]	Step 49014	lr 0.01635	Loss 1.1439 (1.3340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.7%)	
12/20 11:40:35PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][700/703]	Step 49114	lr 0.01635	Loss 1.4894 (1.3453)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.6%)	
12/20 11:40:36PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][703/703]	Step 49117	lr 0.01635	Loss 1.7884 (1.3469)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.5%)	
12/20 11:40:36PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 91/149] Final Prec@1 61.1089%
12/20 11:40:41PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][78/79]	Step 49118	Loss 2.5069	Prec@(1,5) (40.3%, 70.4%)
12/20 11:40:41PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 40.2800%
12/20 11:40:42PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6200%
12/20 11:41:03PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][100/703]	Step 49218	lr 0.01598	Loss 1.2273 (1.2542)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 89.8%)	
12/20 11:41:22PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][200/703]	Step 49318	lr 0.01598	Loss 1.7751 (1.2836)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.4%)	
12/20 11:41:42PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][300/703]	Step 49418	lr 0.01598	Loss 1.8010 (1.2955)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.2%)	
12/20 11:42:01PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][400/703]	Step 49518	lr 0.01598	Loss 1.1404 (1.3006)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.1%)	
12/20 11:42:21PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][500/703]	Step 49618	lr 0.01598	Loss 1.4129 (1.3081)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.0%)	
12/20 11:42:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][600/703]	Step 49718	lr 0.01598	Loss 1.0574 (1.3189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 88.9%)	
12/20 11:43:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][700/703]	Step 49818	lr 0.01598	Loss 1.3959 (1.3244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
12/20 11:43:01PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][703/703]	Step 49821	lr 0.01598	Loss 1.6228 (1.3247)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
12/20 11:43:01PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 92/149] Final Prec@1 61.8800%
12/20 11:43:06PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][78/79]	Step 49822	Loss 2.0583	Prec@(1,5) (47.5%, 78.2%)
12/20 11:43:07PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 47.5000%
12/20 11:43:07PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6200%
12/20 11:43:28PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][100/703]	Step 49922	lr 0.01562	Loss 1.4481 (1.2389)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.0%)	
12/20 11:43:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][200/703]	Step 50022	lr 0.01562	Loss 0.9911 (1.2565)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.9%)	
12/20 11:44:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][300/703]	Step 50122	lr 0.01562	Loss 1.6051 (1.2876)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.4%)	
12/20 11:44:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][400/703]	Step 50222	lr 0.01562	Loss 1.2673 (1.2919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.3%)	
12/20 11:44:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][500/703]	Step 50322	lr 0.01562	Loss 1.1258 (1.2957)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.2%)	
12/20 11:45:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][600/703]	Step 50422	lr 0.01562	Loss 1.3177 (1.3071)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.1%)	
12/20 11:45:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][700/703]	Step 50522	lr 0.01562	Loss 1.8035 (1.3160)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.1%)	
12/20 11:45:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][703/703]	Step 50525	lr 0.01562	Loss 1.2840 (1.3161)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.1%)	
12/20 11:45:28PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 93/149] Final Prec@1 61.6644%
12/20 11:45:33PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][78/79]	Step 50526	Loss 1.9846	Prec@(1,5) (48.1%, 77.4%)
12/20 11:45:33PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 48.0800%
12/20 11:45:33PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6200%
12/20 11:45:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][100/703]	Step 50626	lr 0.01525	Loss 1.2872 (1.2262)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
12/20 11:46:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][200/703]	Step 50726	lr 0.01525	Loss 0.9913 (1.2320)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.1%)	
12/20 11:46:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][300/703]	Step 50826	lr 0.01525	Loss 1.5190 (1.2516)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.8%)	
12/20 11:46:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][400/703]	Step 50926	lr 0.01525	Loss 1.2441 (1.2541)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 89.8%)	
12/20 11:47:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][500/703]	Step 51026	lr 0.01525	Loss 1.4514 (1.2735)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.5%)	
12/20 11:47:33PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][600/703]	Step 51126	lr 0.01525	Loss 1.4777 (1.2801)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.5%)	
12/20 11:47:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][700/703]	Step 51226	lr 0.01525	Loss 1.5851 (1.2949)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.3%)	
12/20 11:47:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][703/703]	Step 51229	lr 0.01525	Loss 1.3807 (1.2948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.3%)	
12/20 11:47:54PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 94/149] Final Prec@1 62.2956%
12/20 11:47:59PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][78/79]	Step 51230	Loss 2.0177	Prec@(1,5) (48.3%, 78.5%)
12/20 11:47:59PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 48.2400%
12/20 11:48:00PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6200%
12/20 11:48:21PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][100/703]	Step 51330	lr 0.01488	Loss 1.2537 (1.1638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 90.9%)	
12/20 11:48:40PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][200/703]	Step 51430	lr 0.01488	Loss 1.0047 (1.1949)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.7%)	
12/20 11:49:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][300/703]	Step 51530	lr 0.01488	Loss 1.7245 (1.2170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.2%)	
12/20 11:49:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][400/703]	Step 51630	lr 0.01488	Loss 0.9330 (1.2328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 89.9%)	
12/20 11:49:40PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][500/703]	Step 51730	lr 0.01488	Loss 1.2883 (1.2464)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.8%)	
12/20 11:50:00PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][600/703]	Step 51830	lr 0.01488	Loss 1.4083 (1.2569)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 89.7%)	
12/20 11:50:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][700/703]	Step 51930	lr 0.01488	Loss 1.7304 (1.2695)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.6%)	
12/20 11:50:20PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][703/703]	Step 51933	lr 0.01488	Loss 1.4923 (1.2704)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.6%)	
12/20 11:50:21PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 95/149] Final Prec@1 63.0844%
12/20 11:50:27PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][78/79]	Step 51934	Loss 1.9291	Prec@(1,5) (49.1%, 79.3%)
12/20 11:50:27PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 49.1200%
12/20 11:50:27PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1200%
12/20 11:50:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][100/703]	Step 52034	lr 0.0145	Loss 1.1739 (1.1789)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.7%)	
12/20 11:51:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][200/703]	Step 52134	lr 0.0145	Loss 1.4765 (1.2056)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.5%)	
12/20 11:51:28PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][300/703]	Step 52234	lr 0.0145	Loss 1.6169 (1.2129)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.2%)	
12/20 11:51:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][400/703]	Step 52334	lr 0.0145	Loss 1.2609 (1.2207)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.1%)	
12/20 11:52:07PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][500/703]	Step 52434	lr 0.0145	Loss 1.7222 (1.2377)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
12/20 11:52:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][600/703]	Step 52534	lr 0.0145	Loss 1.0803 (1.2429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.8%, 89.9%)	
12/20 11:52:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][700/703]	Step 52634	lr 0.0145	Loss 1.0583 (1.2495)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.9%)	
12/20 11:52:48PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][703/703]	Step 52637	lr 0.0145	Loss 1.6685 (1.2506)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.8%)	
12/20 11:52:48PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 96/149] Final Prec@1 63.6578%
12/20 11:52:54PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][78/79]	Step 52638	Loss 2.0933	Prec@(1,5) (47.3%, 76.6%)
12/20 11:52:54PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 47.3000%
12/20 11:52:54PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1200%
12/20 11:53:15PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][100/703]	Step 52738	lr 0.01413	Loss 1.1702 (1.1966)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.8%)	
12/20 11:53:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][200/703]	Step 52838	lr 0.01413	Loss 0.9228 (1.1904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.7%)	
12/20 11:53:54PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][300/703]	Step 52938	lr 0.01413	Loss 1.3293 (1.1990)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.8%)	
12/20 11:54:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][400/703]	Step 53038	lr 0.01413	Loss 1.0153 (1.2170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.6%)	
12/20 11:54:34PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][500/703]	Step 53138	lr 0.01413	Loss 0.8971 (1.2247)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.5%)	
12/20 11:54:53PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][600/703]	Step 53238	lr 0.01413	Loss 1.1628 (1.2282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
12/20 11:55:13PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][700/703]	Step 53338	lr 0.01413	Loss 1.3091 (1.2351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.2%)	
12/20 11:55:14PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][703/703]	Step 53341	lr 0.01413	Loss 1.3219 (1.2352)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.2%)	
12/20 11:55:14PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 97/149] Final Prec@1 64.0267%
12/20 11:55:19PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][78/79]	Step 53342	Loss 2.0145	Prec@(1,5) (48.8%, 79.2%)
12/20 11:55:20PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 48.7800%
12/20 11:55:20PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1200%
12/20 11:55:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][100/703]	Step 53442	lr 0.01375	Loss 1.2201 (1.1503)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.1%)	
12/20 11:56:01PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][200/703]	Step 53542	lr 0.01375	Loss 1.0603 (1.1609)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.1%)	
12/20 11:56:21PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][300/703]	Step 53642	lr 0.01375	Loss 0.8784 (1.1644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.0%)	
12/20 11:56:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][400/703]	Step 53742	lr 0.01375	Loss 1.1580 (1.1716)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.0%)	
12/20 11:57:01PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][500/703]	Step 53842	lr 0.01375	Loss 0.9517 (1.1791)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 90.8%)	
12/20 11:57:21PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][600/703]	Step 53942	lr 0.01375	Loss 1.0713 (1.1910)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 90.7%)	
12/20 11:57:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][700/703]	Step 54042	lr 0.01375	Loss 1.0518 (1.2020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.5%)	
12/20 11:57:41PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][703/703]	Step 54045	lr 0.01375	Loss 1.1268 (1.2026)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.5%)	
12/20 11:57:42PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 98/149] Final Prec@1 64.9911%
12/20 11:57:47PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][78/79]	Step 54046	Loss 2.0673	Prec@(1,5) (47.8%, 78.5%)
12/20 11:57:47PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 47.7800%
12/20 11:57:47PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1200%
12/20 11:58:08PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][100/703]	Step 54146	lr 0.01338	Loss 1.3377 (1.1035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 91.9%)	
12/20 11:58:27PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][200/703]	Step 54246	lr 0.01338	Loss 1.1245 (1.1416)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.2%)	
12/20 11:58:46PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][300/703]	Step 54346	lr 0.01338	Loss 1.2078 (1.1572)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.2%)	
12/20 11:59:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][400/703]	Step 54446	lr 0.01338	Loss 1.1981 (1.1622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.1%)	
12/20 11:59:25PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][500/703]	Step 54546	lr 0.01338	Loss 1.5191 (1.1707)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.0%)	
12/20 11:59:44PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][600/703]	Step 54646	lr 0.01338	Loss 1.0052 (1.1757)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.0%)	
12/21 12:00:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][700/703]	Step 54746	lr 0.01338	Loss 0.8661 (1.1877)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.8%)	
12/21 12:00:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][703/703]	Step 54749	lr 0.01338	Loss 1.5914 (1.1885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.8%)	
12/21 12:00:04AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 99/149] Final Prec@1 65.1311%
12/21 12:00:10AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][78/79]	Step 54750	Loss 1.9909	Prec@(1,5) (48.5%, 79.7%)
12/21 12:00:10AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 48.4800%
12/21 12:00:10AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1200%
12/21 12:00:31AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][100/703]	Step 54850	lr 0.013	Loss 0.7366 (1.0833)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
12/21 12:00:51AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][200/703]	Step 54950	lr 0.013	Loss 1.1647 (1.1025)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.3%)	
12/21 12:01:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][300/703]	Step 55050	lr 0.013	Loss 1.1387 (1.1198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.9%)	
12/21 12:01:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][400/703]	Step 55150	lr 0.013	Loss 1.5569 (1.1351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.8%)	
12/21 12:01:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][500/703]	Step 55250	lr 0.013	Loss 1.0112 (1.1443)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.6%)	
12/21 12:02:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][600/703]	Step 55350	lr 0.013	Loss 0.9761 (1.1598)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.3%)	
12/21 12:02:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][700/703]	Step 55450	lr 0.013	Loss 1.4032 (1.1664)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.2%)	
12/21 12:02:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][703/703]	Step 55453	lr 0.013	Loss 1.5871 (1.1667)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.2%)	
12/21 12:02:30AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [100/149] Final Prec@1 65.8644%
12/21 12:02:36AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][78/79]	Step 55454	Loss 2.2540	Prec@(1,5) (45.0%, 75.2%)
12/21 12:02:36AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 45.0200%
12/21 12:02:36AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1200%
12/21 12:02:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][100/703]	Step 55554	lr 0.01262	Loss 1.2805 (1.0803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.0%)	
12/21 12:03:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][200/703]	Step 55654	lr 0.01262	Loss 1.1576 (1.0725)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.5%)	
12/21 12:03:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][300/703]	Step 55754	lr 0.01262	Loss 1.0899 (1.0970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.1%)	
12/21 12:03:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][400/703]	Step 55854	lr 0.01262	Loss 1.0938 (1.1183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.8%)	
12/21 12:04:14AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][500/703]	Step 55954	lr 0.01262	Loss 1.1756 (1.1341)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.7%)	
12/21 12:04:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][600/703]	Step 56054	lr 0.01262	Loss 1.2060 (1.1447)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.5%)	
12/21 12:04:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][700/703]	Step 56154	lr 0.01262	Loss 1.3241 (1.1543)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.4%)	
12/21 12:04:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][703/703]	Step 56157	lr 0.01262	Loss 1.1716 (1.1550)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.4%)	
12/21 12:04:53AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [101/149] Final Prec@1 65.6444%
12/21 12:04:59AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][78/79]	Step 56158	Loss 1.9509	Prec@(1,5) (49.3%, 79.5%)
12/21 12:04:59AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 49.2800%
12/21 12:04:59AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.2800%
12/21 12:05:21AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][100/703]	Step 56258	lr 0.01225	Loss 0.9719 (1.0223)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.1%)	
12/21 12:05:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][200/703]	Step 56358	lr 0.01225	Loss 1.0691 (1.0266)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.1%)	
12/21 12:06:00AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][300/703]	Step 56458	lr 0.01225	Loss 1.2054 (1.0539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.6%)	
12/21 12:06:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][400/703]	Step 56558	lr 0.01225	Loss 1.0283 (1.0687)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.4%)	
12/21 12:06:39AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][500/703]	Step 56658	lr 0.01225	Loss 1.2921 (1.0926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.1%)	
12/21 12:06:59AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][600/703]	Step 56758	lr 0.01225	Loss 1.3393 (1.1109)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.9%)	
12/21 12:07:19AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][700/703]	Step 56858	lr 0.01225	Loss 0.9712 (1.1158)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.8%)	
12/21 12:07:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][703/703]	Step 56861	lr 0.01225	Loss 1.0701 (1.1165)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.8%)	
12/21 12:07:20AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [102/149] Final Prec@1 67.0844%
12/21 12:07:26AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][78/79]	Step 56862	Loss 1.8849	Prec@(1,5) (51.7%, 80.6%)
12/21 12:07:26AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 51.6600%
12/21 12:07:26AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.6600%
12/21 12:07:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][100/703]	Step 56962	lr 0.01187	Loss 1.2629 (1.0446)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.7%)	
12/21 12:08:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][200/703]	Step 57062	lr 0.01187	Loss 1.4721 (1.0494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.7%)	
12/21 12:08:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][300/703]	Step 57162	lr 0.01187	Loss 1.0037 (1.0659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.5%)	
12/21 12:08:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][400/703]	Step 57262	lr 0.01187	Loss 1.0903 (1.0803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.4%)	
12/21 12:09:06AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][500/703]	Step 57362	lr 0.01187	Loss 1.1713 (1.0889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
12/21 12:09:26AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][600/703]	Step 57462	lr 0.01187	Loss 0.8056 (1.0991)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.2%)	
12/21 12:09:46AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][700/703]	Step 57562	lr 0.01187	Loss 1.1236 (1.1046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.1%)	
12/21 12:09:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][703/703]	Step 57565	lr 0.01187	Loss 0.9305 (1.1044)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.1%)	
12/21 12:09:47AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [103/149] Final Prec@1 67.3467%
12/21 12:09:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][78/79]	Step 57566	Loss 1.8404	Prec@(1,5) (52.9%, 81.8%)
12/21 12:09:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 52.9400%
12/21 12:09:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:10:14AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][100/703]	Step 57666	lr 0.0115	Loss 1.2141 (1.0538)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.7%)	
12/21 12:10:34AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][200/703]	Step 57766	lr 0.0115	Loss 0.8302 (1.0338)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.9%)	
12/21 12:10:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][300/703]	Step 57866	lr 0.0115	Loss 0.6887 (1.0371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.0%)	
12/21 12:11:13AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][400/703]	Step 57966	lr 0.0115	Loss 1.0853 (1.0525)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.7%)	
12/21 12:11:32AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][500/703]	Step 58066	lr 0.0115	Loss 1.1704 (1.0602)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.6%)	
12/21 12:11:52AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][600/703]	Step 58166	lr 0.0115	Loss 0.7667 (1.0721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
12/21 12:12:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][700/703]	Step 58266	lr 0.0115	Loss 1.5287 (1.0826)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
12/21 12:12:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][703/703]	Step 58269	lr 0.0115	Loss 1.0782 (1.0826)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
12/21 12:12:12AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [104/149] Final Prec@1 67.6711%
12/21 12:12:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][78/79]	Step 58270	Loss 1.9874	Prec@(1,5) (50.3%, 79.0%)
12/21 12:12:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 50.3200%
12/21 12:12:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:12:39AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][100/703]	Step 58370	lr 0.01112	Loss 1.1611 (1.0093)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.1%)	
12/21 12:12:58AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][200/703]	Step 58470	lr 0.01112	Loss 1.3357 (1.0125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.4%)	
12/21 12:13:18AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][300/703]	Step 58570	lr 0.01112	Loss 1.1208 (1.0210)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.3%)	
12/21 12:13:38AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][400/703]	Step 58670	lr 0.01112	Loss 0.9547 (1.0316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.0%)	
12/21 12:13:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][500/703]	Step 58770	lr 0.01112	Loss 1.0092 (1.0426)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.8%)	
12/21 12:14:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][600/703]	Step 58870	lr 0.01112	Loss 1.1703 (1.0540)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.7%)	
12/21 12:14:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][700/703]	Step 58970	lr 0.01112	Loss 1.1658 (1.0586)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.6%)	
12/21 12:14:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][703/703]	Step 58973	lr 0.01112	Loss 0.7954 (1.0594)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.6%)	
12/21 12:14:37AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [105/149] Final Prec@1 68.5156%
12/21 12:14:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][78/79]	Step 58974	Loss 1.9549	Prec@(1,5) (50.5%, 79.8%)
12/21 12:14:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 50.5200%
12/21 12:14:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:15:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][100/703]	Step 59074	lr 0.01075	Loss 1.4153 (0.9598)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
12/21 12:15:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][200/703]	Step 59174	lr 0.01075	Loss 0.8177 (0.9813)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.4%)	
12/21 12:15:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][300/703]	Step 59274	lr 0.01075	Loss 1.0261 (0.9917)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.5%)	
12/21 12:16:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][400/703]	Step 59374	lr 0.01075	Loss 1.0207 (1.0012)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.2%)	
12/21 12:16:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][500/703]	Step 59474	lr 0.01075	Loss 0.7930 (1.0055)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
12/21 12:16:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][600/703]	Step 59574	lr 0.01075	Loss 0.9627 (1.0171)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
12/21 12:17:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][700/703]	Step 59674	lr 0.01075	Loss 1.1668 (1.0275)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.9%)	
12/21 12:17:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][703/703]	Step 59677	lr 0.01075	Loss 1.0102 (1.0269)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.9%)	
12/21 12:17:04AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [106/149] Final Prec@1 69.3044%
12/21 12:17:09AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][78/79]	Step 59678	Loss 1.8386	Prec@(1,5) (52.6%, 81.8%)
12/21 12:17:09AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 52.6400%
12/21 12:17:09AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:17:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][100/703]	Step 59778	lr 0.01038	Loss 0.9868 (0.9716)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.7%)	
12/21 12:17:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][200/703]	Step 59878	lr 0.01038	Loss 0.7563 (0.9825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.4%)	
12/21 12:18:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][300/703]	Step 59978	lr 0.01038	Loss 1.0973 (0.9877)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.4%)	
12/21 12:18:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][400/703]	Step 60078	lr 0.01038	Loss 1.2829 (0.9903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.4%)	
12/21 12:18:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][500/703]	Step 60178	lr 0.01038	Loss 1.1043 (1.0058)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.1%)	
12/21 12:19:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][600/703]	Step 60278	lr 0.01038	Loss 0.9989 (1.0111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.1%)	
12/21 12:19:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][700/703]	Step 60378	lr 0.01038	Loss 1.0319 (1.0186)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
12/21 12:19:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][703/703]	Step 60381	lr 0.01038	Loss 1.0390 (1.0192)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
12/21 12:19:30AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [107/149] Final Prec@1 69.5800%
12/21 12:19:36AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][78/79]	Step 60382	Loss 2.1301	Prec@(1,5) (48.2%, 78.4%)
12/21 12:19:36AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 48.2200%
12/21 12:19:36AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:19:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][100/703]	Step 60482	lr 0.01002	Loss 0.9061 (0.9305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.3%)	
12/21 12:20:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][200/703]	Step 60582	lr 0.01002	Loss 1.1599 (0.9340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.1%)	
12/21 12:20:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][300/703]	Step 60682	lr 0.01002	Loss 0.9277 (0.9500)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
12/21 12:20:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][400/703]	Step 60782	lr 0.01002	Loss 0.6663 (0.9624)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.7%)	
12/21 12:21:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][500/703]	Step 60882	lr 0.01002	Loss 1.1486 (0.9714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
12/21 12:21:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][600/703]	Step 60982	lr 0.01002	Loss 1.1571 (0.9831)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.5%)	
12/21 12:21:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][700/703]	Step 61082	lr 0.01002	Loss 1.0738 (0.9878)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.5%)	
12/21 12:21:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][703/703]	Step 61085	lr 0.01002	Loss 1.3852 (0.9888)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.5%)	
12/21 12:21:57AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [108/149] Final Prec@1 70.2267%
12/21 12:22:03AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][78/79]	Step 61086	Loss 2.0599	Prec@(1,5) (49.2%, 78.9%)
12/21 12:22:03AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 49.2000%
12/21 12:22:03AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:22:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][100/703]	Step 61186	lr 0.00965	Loss 0.8630 (0.8958)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.3%)	
12/21 12:22:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][200/703]	Step 61286	lr 0.00965	Loss 0.6189 (0.9170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.2%)	
12/21 12:23:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][300/703]	Step 61386	lr 0.00965	Loss 1.1464 (0.9240)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.0%)	
12/21 12:23:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][400/703]	Step 61486	lr 0.00965	Loss 0.9092 (0.9257)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.1%)	
12/21 12:23:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][500/703]	Step 61586	lr 0.00965	Loss 0.9558 (0.9334)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
12/21 12:24:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][600/703]	Step 61686	lr 0.00965	Loss 1.0276 (0.9409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.0%)	
12/21 12:24:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][700/703]	Step 61786	lr 0.00965	Loss 1.2155 (0.9501)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.9%)	
12/21 12:24:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][703/703]	Step 61789	lr 0.00965	Loss 1.1079 (0.9508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.9%)	
12/21 12:24:24AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [109/149] Final Prec@1 71.4111%
12/21 12:24:29AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][78/79]	Step 61790	Loss 2.1048	Prec@(1,5) (49.2%, 78.8%)
12/21 12:24:30AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 49.2200%
12/21 12:24:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:24:51AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][100/703]	Step 61890	lr 0.00929	Loss 0.9840 (0.8839)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.5%)	
12/21 12:25:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][200/703]	Step 61990	lr 0.00929	Loss 0.8862 (0.8806)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.4%)	
12/21 12:25:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][300/703]	Step 62090	lr 0.00929	Loss 0.7190 (0.8830)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.5%)	
12/21 12:25:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][400/703]	Step 62190	lr 0.00929	Loss 0.7109 (0.9059)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.3%)	
12/21 12:26:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][500/703]	Step 62290	lr 0.00929	Loss 0.8466 (0.9174)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.2%)	
12/21 12:26:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][600/703]	Step 62390	lr 0.00929	Loss 1.2587 (0.9286)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.1%)	
12/21 12:26:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][700/703]	Step 62490	lr 0.00929	Loss 0.9028 (0.9372)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
12/21 12:26:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][703/703]	Step 62493	lr 0.00929	Loss 0.9859 (0.9378)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
12/21 12:26:50AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [110/149] Final Prec@1 71.8467%
12/21 12:26:56AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][78/79]	Step 62494	Loss 1.9655	Prec@(1,5) (50.4%, 79.8%)
12/21 12:26:56AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 50.4800%
12/21 12:26:56AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.9400%
12/21 12:27:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][100/703]	Step 62594	lr 0.00894	Loss 0.7676 (0.8473)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.2%)	
12/21 12:27:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][200/703]	Step 62694	lr 0.00894	Loss 1.0822 (0.8541)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.1%)	
12/21 12:27:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][300/703]	Step 62794	lr 0.00894	Loss 0.7760 (0.8665)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.9%)	
12/21 12:28:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][400/703]	Step 62894	lr 0.00894	Loss 1.2019 (0.8827)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
12/21 12:28:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][500/703]	Step 62994	lr 0.00894	Loss 1.1085 (0.8924)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.6%)	
12/21 12:28:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][600/703]	Step 63094	lr 0.00894	Loss 1.1988 (0.8961)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.6%)	
12/21 12:29:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][700/703]	Step 63194	lr 0.00894	Loss 0.8524 (0.9041)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.5%)	
12/21 12:29:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][703/703]	Step 63197	lr 0.00894	Loss 1.0725 (0.9048)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.5%)	
12/21 12:29:17AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [111/149] Final Prec@1 72.6444%
12/21 12:29:22AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][78/79]	Step 63198	Loss 1.8616	Prec@(1,5) (53.1%, 82.9%)
12/21 12:29:23AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 53.1000%
12/21 12:29:23AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.1000%
12/21 12:29:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][100/703]	Step 63298	lr 0.00858	Loss 0.6237 (0.8220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.1%)	
12/21 12:30:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][200/703]	Step 63398	lr 0.00858	Loss 1.0154 (0.8414)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.0%)	
12/21 12:30:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][300/703]	Step 63498	lr 0.00858	Loss 0.8733 (0.8478)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 94.8%)	
12/21 12:30:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][400/703]	Step 63598	lr 0.00858	Loss 0.9625 (0.8561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 94.9%)	
12/21 12:31:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][500/703]	Step 63698	lr 0.00858	Loss 0.9605 (0.8706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.8%)	
12/21 12:31:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][600/703]	Step 63798	lr 0.00858	Loss 0.7865 (0.8754)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
12/21 12:31:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][700/703]	Step 63898	lr 0.00858	Loss 0.6484 (0.8825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
12/21 12:31:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][703/703]	Step 63901	lr 0.00858	Loss 0.9764 (0.8827)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
12/21 12:31:44AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [112/149] Final Prec@1 73.2400%
12/21 12:31:49AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][78/79]	Step 63902	Loss 1.9899	Prec@(1,5) (50.8%, 79.4%)
12/21 12:31:49AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 50.7600%
12/21 12:31:49AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.1000%
12/21 12:32:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][100/703]	Step 64002	lr 0.00823	Loss 0.8021 (0.7879)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.9%)	
12/21 12:32:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][200/703]	Step 64102	lr 0.00823	Loss 0.7502 (0.7916)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
12/21 12:32:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][300/703]	Step 64202	lr 0.00823	Loss 0.8967 (0.8134)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.4%)	
12/21 12:33:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][400/703]	Step 64302	lr 0.00823	Loss 0.7430 (0.8270)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.3%)	
12/21 12:33:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][500/703]	Step 64402	lr 0.00823	Loss 0.6857 (0.8355)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.3%)	
12/21 12:33:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][600/703]	Step 64502	lr 0.00823	Loss 1.3745 (0.8463)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.1%)	
12/21 12:34:09AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][700/703]	Step 64602	lr 0.00823	Loss 0.8133 (0.8506)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.2%)	
12/21 12:34:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][703/703]	Step 64605	lr 0.00823	Loss 0.8598 (0.8507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.2%)	
12/21 12:34:10AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [113/149] Final Prec@1 74.0800%
12/21 12:34:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][78/79]	Step 64606	Loss 1.9185	Prec@(1,5) (53.1%, 81.5%)
12/21 12:34:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 53.0400%
12/21 12:34:16AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.1000%
12/21 12:34:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][100/703]	Step 64706	lr 0.00789	Loss 0.7330 (0.7663)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.9%)	
12/21 12:34:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][200/703]	Step 64806	lr 0.00789	Loss 0.9822 (0.7754)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
12/21 12:35:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][300/703]	Step 64906	lr 0.00789	Loss 0.5745 (0.7951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.7%)	
12/21 12:35:35AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][400/703]	Step 65006	lr 0.00789	Loss 0.8042 (0.8036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.6%)	
12/21 12:35:54AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][500/703]	Step 65106	lr 0.00789	Loss 0.8145 (0.8079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.6%)	
12/21 12:36:14AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][600/703]	Step 65206	lr 0.00789	Loss 1.0186 (0.8220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.4%)	
12/21 12:36:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][700/703]	Step 65306	lr 0.00789	Loss 0.8035 (0.8305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.3%)	
12/21 12:36:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][703/703]	Step 65309	lr 0.00789	Loss 0.9970 (0.8307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.3%)	
12/21 12:36:34AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [114/149] Final Prec@1 74.3956%
12/21 12:36:39AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][78/79]	Step 65310	Loss 1.8300	Prec@(1,5) (54.0%, 82.4%)
12/21 12:36:39AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 53.9400%
12/21 12:36:40AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9400%
12/21 12:37:01AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][100/703]	Step 65410	lr 0.00755	Loss 0.8144 (0.7640)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.7%)	
12/21 12:37:21AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][200/703]	Step 65510	lr 0.00755	Loss 0.7001 (0.7660)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.0%)	
12/21 12:37:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][300/703]	Step 65610	lr 0.00755	Loss 0.9058 (0.7741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.9%)	
12/21 12:38:00AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][400/703]	Step 65710	lr 0.00755	Loss 0.9982 (0.7750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.9%)	
12/21 12:38:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][500/703]	Step 65810	lr 0.00755	Loss 1.1744 (0.7875)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.8%)	
12/21 12:38:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][600/703]	Step 65910	lr 0.00755	Loss 0.9274 (0.7972)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.6%)	
12/21 12:39:00AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][700/703]	Step 66010	lr 0.00755	Loss 0.9254 (0.8033)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.6%)	
12/21 12:39:00AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][703/703]	Step 66013	lr 0.00755	Loss 0.9516 (0.8034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.6%)	
12/21 12:39:00AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [115/149] Final Prec@1 75.2333%
12/21 12:39:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][78/79]	Step 66014	Loss 1.9335	Prec@(1,5) (53.4%, 80.5%)
12/21 12:39:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 53.3600%
12/21 12:39:06AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9400%
12/21 12:39:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][100/703]	Step 66114	lr 0.00722	Loss 0.7918 (0.7302)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.5%)	
12/21 12:39:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][200/703]	Step 66214	lr 0.00722	Loss 0.7494 (0.7375)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.4%)	
12/21 12:40:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][300/703]	Step 66314	lr 0.00722	Loss 1.0091 (0.7424)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.2%)	
12/21 12:40:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][400/703]	Step 66414	lr 0.00722	Loss 0.7571 (0.7547)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.0%)	
12/21 12:40:46AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][500/703]	Step 66514	lr 0.00722	Loss 0.8938 (0.7592)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.0%)	
12/21 12:41:06AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][600/703]	Step 66614	lr 0.00722	Loss 1.0212 (0.7689)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
12/21 12:41:25AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][700/703]	Step 66714	lr 0.00722	Loss 0.9160 (0.7723)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.9%)	
12/21 12:41:25AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][703/703]	Step 66717	lr 0.00722	Loss 0.9980 (0.7729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.8%)	
12/21 12:41:26AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [116/149] Final Prec@1 76.3022%
12/21 12:41:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][78/79]	Step 66718	Loss 1.9205	Prec@(1,5) (53.0%, 82.1%)
12/21 12:41:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 52.9400%
12/21 12:41:32AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9400%
12/21 12:41:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][100/703]	Step 66818	lr 0.00689	Loss 0.6263 (0.7317)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.3%)	
12/21 12:42:13AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][200/703]	Step 66918	lr 0.00689	Loss 0.6549 (0.7246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.3%)	
12/21 12:42:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][300/703]	Step 67018	lr 0.00689	Loss 0.7103 (0.7182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.2%)	
12/21 12:42:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][400/703]	Step 67118	lr 0.00689	Loss 0.6273 (0.7271)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.2%)	
12/21 12:43:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][500/703]	Step 67218	lr 0.00689	Loss 0.5094 (0.7310)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
12/21 12:43:32AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][600/703]	Step 67318	lr 0.00689	Loss 0.5240 (0.7420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
12/21 12:43:52AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][700/703]	Step 67418	lr 0.00689	Loss 0.6181 (0.7482)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
12/21 12:43:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][703/703]	Step 67421	lr 0.00689	Loss 0.8238 (0.7478)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
12/21 12:43:53AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [117/149] Final Prec@1 77.0289%
12/21 12:43:58AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][78/79]	Step 67422	Loss 1.9107	Prec@(1,5) (54.6%, 81.6%)
12/21 12:43:59AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 54.6000%
12/21 12:43:59AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6000%
12/21 12:44:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][100/703]	Step 67522	lr 0.00657	Loss 0.7468 (0.6703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.7%)	
12/21 12:44:39AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][200/703]	Step 67622	lr 0.00657	Loss 0.6802 (0.6750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
12/21 12:44:59AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][300/703]	Step 67722	lr 0.00657	Loss 0.6460 (0.6873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.7%)	
12/21 12:45:19AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][400/703]	Step 67822	lr 0.00657	Loss 0.9722 (0.6923)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.6%)	
12/21 12:45:38AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][500/703]	Step 67922	lr 0.00657	Loss 0.8823 (0.6998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.6%)	
12/21 12:45:58AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][600/703]	Step 68022	lr 0.00657	Loss 0.6166 (0.7036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.6%)	
12/21 12:46:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][700/703]	Step 68122	lr 0.00657	Loss 0.8994 (0.7153)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.4%)	
12/21 12:46:18AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][703/703]	Step 68125	lr 0.00657	Loss 0.7604 (0.7158)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.4%)	
12/21 12:46:18AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [118/149] Final Prec@1 77.7689%
12/21 12:46:23AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][78/79]	Step 68126	Loss 1.8602	Prec@(1,5) (54.6%, 83.2%)
12/21 12:46:24AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 54.5800%
12/21 12:46:24AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6000%
12/21 12:46:45AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][100/703]	Step 68226	lr 0.00625	Loss 0.6542 (0.6300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 96.9%)	
12/21 12:47:05AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][200/703]	Step 68326	lr 0.00625	Loss 0.7311 (0.6438)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 96.9%)	
12/21 12:47:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][300/703]	Step 68426	lr 0.00625	Loss 0.6802 (0.6502)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
12/21 12:47:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][400/703]	Step 68526	lr 0.00625	Loss 0.4695 (0.6595)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.8%)	
12/21 12:48:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][500/703]	Step 68626	lr 0.00625	Loss 0.6859 (0.6687)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.8%)	
12/21 12:48:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][600/703]	Step 68726	lr 0.00625	Loss 0.5855 (0.6760)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.8%)	
12/21 12:48:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][700/703]	Step 68826	lr 0.00625	Loss 0.8203 (0.6838)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
12/21 12:48:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][703/703]	Step 68829	lr 0.00625	Loss 0.8864 (0.6839)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
12/21 12:48:44AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [119/149] Final Prec@1 78.7533%
12/21 12:48:50AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][78/79]	Step 68830	Loss 1.8561	Prec@(1,5) (55.4%, 83.5%)
12/21 12:48:50AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 55.4200%
12/21 12:48:50AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.4200%
12/21 12:49:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][100/703]	Step 68930	lr 0.00595	Loss 0.5827 (0.6303)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.0%)	
12/21 12:49:31AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][200/703]	Step 69030	lr 0.00595	Loss 0.4559 (0.6214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.3%)	
12/21 12:49:51AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][300/703]	Step 69130	lr 0.00595	Loss 0.5588 (0.6309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.2%)	
12/21 12:50:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][400/703]	Step 69230	lr 0.00595	Loss 0.7144 (0.6448)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
12/21 12:50:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][500/703]	Step 69330	lr 0.00595	Loss 1.0526 (0.6493)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
12/21 12:50:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][600/703]	Step 69430	lr 0.00595	Loss 0.7454 (0.6572)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
12/21 12:51:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][700/703]	Step 69530	lr 0.00595	Loss 0.7593 (0.6608)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 97.0%)	
12/21 12:51:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][703/703]	Step 69533	lr 0.00595	Loss 0.8938 (0.6614)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 97.0%)	
12/21 12:51:11AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [120/149] Final Prec@1 79.5044%
12/21 12:51:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][78/79]	Step 69534	Loss 1.9532	Prec@(1,5) (53.8%, 82.0%)
12/21 12:51:17AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 53.8400%
12/21 12:51:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.4200%
12/21 12:51:38AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][100/703]	Step 69634	lr 0.00565	Loss 0.7543 (0.5899)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.5%)	
12/21 12:51:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][200/703]	Step 69734	lr 0.00565	Loss 0.5111 (0.6131)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
12/21 12:52:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][300/703]	Step 69834	lr 0.00565	Loss 0.7429 (0.6136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
12/21 12:52:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][400/703]	Step 69934	lr 0.00565	Loss 0.7378 (0.6189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.4%)	
12/21 12:52:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][500/703]	Step 70034	lr 0.00565	Loss 0.5984 (0.6214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
12/21 12:53:14AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][600/703]	Step 70134	lr 0.00565	Loss 0.7887 (0.6237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.3%)	
12/21 12:53:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][700/703]	Step 70234	lr 0.00565	Loss 0.6159 (0.6278)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.3%)	
12/21 12:53:34AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][703/703]	Step 70237	lr 0.00565	Loss 0.6431 (0.6279)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.3%)	
12/21 12:53:34AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [121/149] Final Prec@1 80.3511%
12/21 12:53:40AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][78/79]	Step 70238	Loss 1.9315	Prec@(1,5) (53.8%, 82.4%)
12/21 12:53:40AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 53.8600%
12/21 12:53:40AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.4200%
12/21 12:54:00AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][100/703]	Step 70338	lr 0.00535	Loss 0.5389 (0.5626)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.4%)	
12/21 12:54:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][200/703]	Step 70438	lr 0.00535	Loss 0.5417 (0.5638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.6%)	
12/21 12:54:39AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][300/703]	Step 70538	lr 0.00535	Loss 0.6812 (0.5701)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.6%)	
12/21 12:54:58AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][400/703]	Step 70638	lr 0.00535	Loss 0.6530 (0.5803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.5%)	
12/21 12:55:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][500/703]	Step 70738	lr 0.00535	Loss 0.8567 (0.5885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.5%)	
12/21 12:55:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][600/703]	Step 70838	lr 0.00535	Loss 0.5432 (0.5993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
12/21 12:55:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][700/703]	Step 70938	lr 0.00535	Loss 0.6129 (0.6029)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.5%)	
12/21 12:55:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][703/703]	Step 70941	lr 0.00535	Loss 0.7136 (0.6032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.5%)	
12/21 12:55:56AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [122/149] Final Prec@1 81.2800%
12/21 12:56:02AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][78/79]	Step 70942	Loss 1.9039	Prec@(1,5) (55.7%, 83.5%)
12/21 12:56:02AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 55.6800%
12/21 12:56:02AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.6800%
12/21 12:56:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][100/703]	Step 71042	lr 0.00506	Loss 0.5324 (0.5378)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.7%)	
12/21 12:56:42AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][200/703]	Step 71142	lr 0.00506	Loss 0.5536 (0.5340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
12/21 12:57:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][300/703]	Step 71242	lr 0.00506	Loss 0.6640 (0.5452)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.7%)	
12/21 12:57:21AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][400/703]	Step 71342	lr 0.00506	Loss 0.5645 (0.5568)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.7%)	
12/21 12:57:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][500/703]	Step 71442	lr 0.00506	Loss 0.6292 (0.5669)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.6%)	
12/21 12:57:59AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][600/703]	Step 71542	lr 0.00506	Loss 0.3689 (0.5717)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.6%)	
12/21 12:58:19AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][700/703]	Step 71642	lr 0.00506	Loss 0.4320 (0.5755)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.6%)	
12/21 12:58:19AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][703/703]	Step 71645	lr 0.00506	Loss 0.5291 (0.5755)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.6%)	
12/21 12:58:19AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [123/149] Final Prec@1 82.1556%
12/21 12:58:25AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][78/79]	Step 71646	Loss 1.9082	Prec@(1,5) (54.0%, 83.7%)
12/21 12:58:25AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 54.0400%
12/21 12:58:25AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.6800%
12/21 12:58:46AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][100/703]	Step 71746	lr 0.00479	Loss 0.5584 (0.5198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.9%)	
12/21 12:59:05AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][200/703]	Step 71846	lr 0.00479	Loss 0.3668 (0.5273)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
12/21 12:59:25AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][300/703]	Step 71946	lr 0.00479	Loss 0.6820 (0.5332)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.1%)	
12/21 12:59:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][400/703]	Step 72046	lr 0.00479	Loss 0.5216 (0.5325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.1%)	
12/21 01:00:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][500/703]	Step 72146	lr 0.00479	Loss 0.4918 (0.5387)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.0%)	
12/21 01:00:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][600/703]	Step 72246	lr 0.00479	Loss 0.4819 (0.5455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 98.0%)	
12/21 01:00:42AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][700/703]	Step 72346	lr 0.00479	Loss 0.4255 (0.5498)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.9%)	
12/21 01:00:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][703/703]	Step 72349	lr 0.00479	Loss 0.5058 (0.5500)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.9%)	
12/21 01:00:43AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [124/149] Final Prec@1 82.6800%
12/21 01:00:49AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][78/79]	Step 72350	Loss 2.0302	Prec@(1,5) (55.1%, 82.0%)
12/21 01:00:49AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 55.1000%
12/21 01:00:49AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.6800%
12/21 01:01:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][100/703]	Step 72450	lr 0.00451	Loss 0.5205 (0.4970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.1%)	
12/21 01:01:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][200/703]	Step 72550	lr 0.00451	Loss 0.6734 (0.5155)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
12/21 01:01:48AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][300/703]	Step 72650	lr 0.00451	Loss 0.7252 (0.5109)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.1%)	
12/21 01:02:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][400/703]	Step 72750	lr 0.00451	Loss 0.5427 (0.5146)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
12/21 01:02:26AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][500/703]	Step 72850	lr 0.00451	Loss 0.6078 (0.5189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.1%)	
12/21 01:02:46AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][600/703]	Step 72950	lr 0.00451	Loss 0.4320 (0.5224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.1%)	
12/21 01:03:05AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][700/703]	Step 73050	lr 0.00451	Loss 0.5361 (0.5242)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.1%)	
12/21 01:03:05AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][703/703]	Step 73053	lr 0.00451	Loss 0.3324 (0.5239)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
12/21 01:03:06AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [125/149] Final Prec@1 83.6533%
12/21 01:03:11AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][78/79]	Step 73054	Loss 1.9167	Prec@(1,5) (56.4%, 83.6%)
12/21 01:03:11AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 56.3600%
12/21 01:03:12AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.3600%
12/21 01:03:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][100/703]	Step 73154	lr 0.00425	Loss 0.6440 (0.4726)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.3%)	
12/21 01:03:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][200/703]	Step 73254	lr 0.00425	Loss 0.6481 (0.4793)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
12/21 01:04:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][300/703]	Step 73354	lr 0.00425	Loss 0.5389 (0.4837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
12/21 01:04:32AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][400/703]	Step 73454	lr 0.00425	Loss 0.3945 (0.4863)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.2%)	
12/21 01:04:52AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][500/703]	Step 73554	lr 0.00425	Loss 0.5333 (0.4932)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
12/21 01:05:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][600/703]	Step 73654	lr 0.00425	Loss 0.3512 (0.4948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
12/21 01:05:31AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][700/703]	Step 73754	lr 0.00425	Loss 0.6472 (0.4971)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
12/21 01:05:32AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][703/703]	Step 73757	lr 0.00425	Loss 0.3216 (0.4973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
12/21 01:05:32AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [126/149] Final Prec@1 84.4422%
12/21 01:05:38AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][78/79]	Step 73758	Loss 1.9098	Prec@(1,5) (55.5%, 83.5%)
12/21 01:05:38AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 55.5400%
12/21 01:05:38AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.3600%
12/21 01:05:59AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][100/703]	Step 73858	lr 0.004	Loss 0.3459 (0.4420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.7%)	
12/21 01:06:18AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][200/703]	Step 73958	lr 0.004	Loss 0.3580 (0.4448)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.7%)	
12/21 01:06:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][300/703]	Step 74058	lr 0.004	Loss 0.6203 (0.4498)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
12/21 01:06:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][400/703]	Step 74158	lr 0.004	Loss 0.5674 (0.4574)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.6%)	
12/21 01:07:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][500/703]	Step 74258	lr 0.004	Loss 0.6880 (0.4638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
12/21 01:07:35AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][600/703]	Step 74358	lr 0.004	Loss 0.3795 (0.4723)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.5%)	
12/21 01:07:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][700/703]	Step 74458	lr 0.004	Loss 0.1870 (0.4753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
12/21 01:07:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][703/703]	Step 74461	lr 0.004	Loss 0.4792 (0.4756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
12/21 01:07:55AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [127/149] Final Prec@1 85.1200%
12/21 01:08:01AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][78/79]	Step 74462	Loss 1.8793	Prec@(1,5) (56.6%, 83.8%)
12/21 01:08:01AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 56.6200%
12/21 01:08:02AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6200%
12/21 01:08:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][100/703]	Step 74562	lr 0.00375	Loss 0.3233 (0.4148)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.9%)	
12/21 01:08:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][200/703]	Step 74662	lr 0.00375	Loss 0.4973 (0.4228)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.8%)	
12/21 01:09:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][300/703]	Step 74762	lr 0.00375	Loss 0.5607 (0.4277)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.8%)	
12/21 01:09:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][400/703]	Step 74862	lr 0.00375	Loss 0.4414 (0.4305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.8%)	
12/21 01:09:42AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][500/703]	Step 74962	lr 0.00375	Loss 0.5559 (0.4341)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.8%)	
12/21 01:10:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][600/703]	Step 75062	lr 0.00375	Loss 0.4527 (0.4376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.7%)	
12/21 01:10:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][700/703]	Step 75162	lr 0.00375	Loss 0.4720 (0.4416)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.7%)	
12/21 01:10:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][703/703]	Step 75165	lr 0.00375	Loss 0.3599 (0.4417)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.7%)	
12/21 01:10:23AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [128/149] Final Prec@1 86.0756%
12/21 01:10:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][78/79]	Step 75166	Loss 1.9246	Prec@(1,5) (57.1%, 84.1%)
12/21 01:10:28AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 57.0400%
12/21 01:10:29AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
12/21 01:10:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][100/703]	Step 75266	lr 0.00352	Loss 0.3374 (0.3854)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.1%)	
12/21 01:11:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][200/703]	Step 75366	lr 0.00352	Loss 0.2550 (0.3972)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 99.1%)	
12/21 01:11:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][300/703]	Step 75466	lr 0.00352	Loss 0.3527 (0.4097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.9%)	
12/21 01:11:49AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][400/703]	Step 75566	lr 0.00352	Loss 0.5373 (0.4087)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 99.0%)	
12/21 01:12:09AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][500/703]	Step 75666	lr 0.00352	Loss 0.3710 (0.4115)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 99.0%)	
12/21 01:12:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][600/703]	Step 75766	lr 0.00352	Loss 0.4099 (0.4139)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.9%)	
12/21 01:12:49AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][700/703]	Step 75866	lr 0.00352	Loss 0.5849 (0.4193)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.9%)	
12/21 01:12:49AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][703/703]	Step 75869	lr 0.00352	Loss 0.3713 (0.4192)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.9%)	
12/21 01:12:50AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [129/149] Final Prec@1 86.7000%
12/21 01:12:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][78/79]	Step 75870	Loss 1.9528	Prec@(1,5) (56.1%, 83.9%)
12/21 01:12:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 56.1200%
12/21 01:12:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
12/21 01:13:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][100/703]	Step 75970	lr 0.00329	Loss 0.4940 (0.3612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.1%)	
12/21 01:13:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][200/703]	Step 76070	lr 0.00329	Loss 0.4174 (0.3664)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.1%)	
12/21 01:13:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][300/703]	Step 76170	lr 0.00329	Loss 0.2310 (0.3837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 99.0%)	
12/21 01:14:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][400/703]	Step 76270	lr 0.00329	Loss 0.3253 (0.3863)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 99.0%)	
12/21 01:14:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][500/703]	Step 76370	lr 0.00329	Loss 0.2597 (0.3898)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 99.0%)	
12/21 01:14:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][600/703]	Step 76470	lr 0.00329	Loss 0.4073 (0.3950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.9%)	
12/21 01:15:15AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][700/703]	Step 76570	lr 0.00329	Loss 0.3990 (0.3993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.9%)	
12/21 01:15:15AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][703/703]	Step 76573	lr 0.00329	Loss 0.5524 (0.3999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.9%)	
12/21 01:15:16AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [130/149] Final Prec@1 87.4156%
12/21 01:15:21AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][78/79]	Step 76574	Loss 1.9607	Prec@(1,5) (56.6%, 84.0%)
12/21 01:15:21AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 56.6400%
12/21 01:15:21AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
12/21 01:15:42AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][100/703]	Step 76674	lr 0.00308	Loss 0.4940 (0.3508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.3%)	
12/21 01:16:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][200/703]	Step 76774	lr 0.00308	Loss 0.3210 (0.3604)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.2%)	
12/21 01:16:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][300/703]	Step 76874	lr 0.00308	Loss 0.3236 (0.3666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/21 01:16:41AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][400/703]	Step 76974	lr 0.00308	Loss 0.2880 (0.3665)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/21 01:17:01AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][500/703]	Step 77074	lr 0.00308	Loss 0.3066 (0.3695)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/21 01:17:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][600/703]	Step 77174	lr 0.00308	Loss 0.3295 (0.3747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.1%)	
12/21 01:17:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][700/703]	Step 77274	lr 0.00308	Loss 0.4496 (0.3765)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.1%)	
12/21 01:17:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][703/703]	Step 77277	lr 0.00308	Loss 0.6473 (0.3770)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.1%, 99.1%)	
12/21 01:17:41AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [131/149] Final Prec@1 88.1311%
12/21 01:17:47AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][78/79]	Step 77278	Loss 1.9232	Prec@(1,5) (57.3%, 84.5%)
12/21 01:17:47AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 57.2600%
12/21 01:17:47AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2600%
12/21 01:18:08AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][100/703]	Step 77378	lr 0.00287	Loss 0.4093 (0.3265)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/21 01:18:28AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][200/703]	Step 77478	lr 0.00287	Loss 0.3545 (0.3262)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
12/21 01:18:48AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][300/703]	Step 77578	lr 0.00287	Loss 0.5032 (0.3377)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
12/21 01:19:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][400/703]	Step 77678	lr 0.00287	Loss 0.4520 (0.3400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.3%)	
12/21 01:19:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][500/703]	Step 77778	lr 0.00287	Loss 0.4125 (0.3487)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
12/21 01:19:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][600/703]	Step 77878	lr 0.00287	Loss 0.3559 (0.3504)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
12/21 01:20:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][700/703]	Step 77978	lr 0.00287	Loss 0.3804 (0.3535)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
12/21 01:20:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][703/703]	Step 77981	lr 0.00287	Loss 0.3834 (0.3539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
12/21 01:20:07AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [132/149] Final Prec@1 89.0089%
12/21 01:20:13AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][78/79]	Step 77982	Loss 2.0199	Prec@(1,5) (56.6%, 83.6%)
12/21 01:20:13AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 56.6000%
12/21 01:20:13AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2600%
12/21 01:20:34AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][100/703]	Step 78082	lr 0.00267	Loss 0.2500 (0.3242)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/21 01:20:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][200/703]	Step 78182	lr 0.00267	Loss 0.2506 (0.3295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
12/21 01:21:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][300/703]	Step 78282	lr 0.00267	Loss 0.2668 (0.3233)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
12/21 01:21:31AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][400/703]	Step 78382	lr 0.00267	Loss 0.3592 (0.3272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
12/21 01:21:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][500/703]	Step 78482	lr 0.00267	Loss 0.4544 (0.3303)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.3%)	
12/21 01:22:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][600/703]	Step 78582	lr 0.00267	Loss 0.2523 (0.3332)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.3%)	
12/21 01:22:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][700/703]	Step 78682	lr 0.00267	Loss 0.2757 (0.3361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.2%)	
12/21 01:22:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][703/703]	Step 78685	lr 0.00267	Loss 0.5669 (0.3367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
12/21 01:22:30AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [133/149] Final Prec@1 89.5311%
12/21 01:22:35AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][78/79]	Step 78686	Loss 2.0053	Prec@(1,5) (56.3%, 83.6%)
12/21 01:22:35AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 56.3000%
12/21 01:22:35AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2600%
12/21 01:22:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][100/703]	Step 78786	lr 0.00248	Loss 0.3078 (0.2996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.5%)	
12/21 01:23:15AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][200/703]	Step 78886	lr 0.00248	Loss 0.4288 (0.3021)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.4%)	
12/21 01:23:35AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][300/703]	Step 78986	lr 0.00248	Loss 0.1376 (0.3030)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
12/21 01:23:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][400/703]	Step 79086	lr 0.00248	Loss 0.2914 (0.3082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
12/21 01:24:15AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][500/703]	Step 79186	lr 0.00248	Loss 0.3191 (0.3152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.3%)	
12/21 01:24:34AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][600/703]	Step 79286	lr 0.00248	Loss 0.3307 (0.3188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/21 01:24:54AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][700/703]	Step 79386	lr 0.00248	Loss 0.1466 (0.3220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
12/21 01:24:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][703/703]	Step 79389	lr 0.00248	Loss 0.3351 (0.3220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
12/21 01:24:55AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [134/149] Final Prec@1 89.9400%
12/21 01:25:00AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][78/79]	Step 79390	Loss 1.9646	Prec@(1,5) (57.1%, 84.1%)
12/21 01:25:00AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 57.0400%
12/21 01:25:01AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2600%
12/21 01:25:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][100/703]	Step 79490	lr 0.00231	Loss 0.3986 (0.2796)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
12/21 01:25:41AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][200/703]	Step 79590	lr 0.00231	Loss 0.2467 (0.2873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
12/21 01:26:01AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][300/703]	Step 79690	lr 0.00231	Loss 0.1513 (0.2891)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.5%)	
12/21 01:26:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][400/703]	Step 79790	lr 0.00231	Loss 0.4079 (0.2918)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
12/21 01:26:40AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][500/703]	Step 79890	lr 0.00231	Loss 0.4538 (0.2974)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
12/21 01:26:59AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][600/703]	Step 79990	lr 0.00231	Loss 0.3737 (0.2995)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
12/21 01:27:19AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][700/703]	Step 80090	lr 0.00231	Loss 0.2588 (0.3016)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
12/21 01:27:20AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][703/703]	Step 80093	lr 0.00231	Loss 0.3174 (0.3015)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.3%)	
12/21 01:27:20AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [135/149] Final Prec@1 90.6289%
12/21 01:27:26AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][78/79]	Step 80094	Loss 1.9560	Prec@(1,5) (58.0%, 84.0%)
12/21 01:27:26AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 58.0000%
12/21 01:27:26AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:27:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][100/703]	Step 80194	lr 0.00214	Loss 0.2386 (0.2651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.7%)	
12/21 01:28:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][200/703]	Step 80294	lr 0.00214	Loss 0.3099 (0.2666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
12/21 01:28:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][300/703]	Step 80394	lr 0.00214	Loss 0.3314 (0.2715)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
12/21 01:28:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][400/703]	Step 80494	lr 0.00214	Loss 0.2401 (0.2738)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.5%)	
12/21 01:29:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][500/703]	Step 80594	lr 0.00214	Loss 0.1856 (0.2775)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
12/21 01:29:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][600/703]	Step 80694	lr 0.00214	Loss 0.5910 (0.2814)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
12/21 01:29:46AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][700/703]	Step 80794	lr 0.00214	Loss 0.2937 (0.2859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
12/21 01:29:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][703/703]	Step 80797	lr 0.00214	Loss 0.2469 (0.2859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
12/21 01:29:47AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [136/149] Final Prec@1 91.0956%
12/21 01:29:53AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][78/79]	Step 80798	Loss 1.9446	Prec@(1,5) (57.3%, 84.4%)
12/21 01:29:53AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 57.2600%
12/21 01:29:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:30:13AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][100/703]	Step 80898	lr 0.00199	Loss 0.2449 (0.2558)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.7%)	
12/21 01:30:32AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][200/703]	Step 80998	lr 0.00199	Loss 0.2086 (0.2548)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
12/21 01:30:52AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][300/703]	Step 81098	lr 0.00199	Loss 0.2137 (0.2584)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.6%)	
12/21 01:31:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][400/703]	Step 81198	lr 0.00199	Loss 0.3193 (0.2632)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
12/21 01:31:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][500/703]	Step 81298	lr 0.00199	Loss 0.2816 (0.2658)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
12/21 01:31:49AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][600/703]	Step 81398	lr 0.00199	Loss 0.1103 (0.2676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
12/21 01:32:08AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][700/703]	Step 81498	lr 0.00199	Loss 0.3097 (0.2688)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.6%)	
12/21 01:32:09AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][703/703]	Step 81501	lr 0.00199	Loss 0.1692 (0.2687)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.6%)	
12/21 01:32:09AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [137/149] Final Prec@1 91.7289%
12/21 01:32:14AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][78/79]	Step 81502	Loss 2.0016	Prec@(1,5) (57.1%, 84.4%)
12/21 01:32:15AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 57.0800%
12/21 01:32:15AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:32:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][100/703]	Step 81602	lr 0.00184	Loss 0.2672 (0.2463)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.7%)	
12/21 01:32:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][200/703]	Step 81702	lr 0.00184	Loss 0.3510 (0.2483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
12/21 01:33:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][300/703]	Step 81802	lr 0.00184	Loss 0.2227 (0.2521)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
12/21 01:33:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][400/703]	Step 81902	lr 0.00184	Loss 0.3395 (0.2533)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
12/21 01:33:55AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][500/703]	Step 82002	lr 0.00184	Loss 0.3638 (0.2549)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
12/21 01:34:15AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][600/703]	Step 82102	lr 0.00184	Loss 0.2863 (0.2571)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
12/21 01:34:35AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][700/703]	Step 82202	lr 0.00184	Loss 0.3492 (0.2567)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
12/21 01:34:35AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][703/703]	Step 82205	lr 0.00184	Loss 0.1230 (0.2564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
12/21 01:34:35AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [138/149] Final Prec@1 92.2711%
12/21 01:34:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][78/79]	Step 82206	Loss 2.0212	Prec@(1,5) (57.3%, 84.0%)
12/21 01:34:41AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 57.2400%
12/21 01:34:41AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:35:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][100/703]	Step 82306	lr 0.00171	Loss 0.2623 (0.2330)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
12/21 01:35:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][200/703]	Step 82406	lr 0.00171	Loss 0.2342 (0.2368)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
12/21 01:35:42AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][300/703]	Step 82506	lr 0.00171	Loss 0.2496 (0.2379)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
12/21 01:36:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][400/703]	Step 82606	lr 0.00171	Loss 0.3963 (0.2400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
12/21 01:36:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][500/703]	Step 82706	lr 0.00171	Loss 0.1666 (0.2435)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
12/21 01:36:42AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][600/703]	Step 82806	lr 0.00171	Loss 0.1829 (0.2441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
12/21 01:37:01AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][700/703]	Step 82906	lr 0.00171	Loss 0.2819 (0.2463)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
12/21 01:37:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][703/703]	Step 82909	lr 0.00171	Loss 0.3750 (0.2467)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
12/21 01:37:02AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [139/149] Final Prec@1 92.6178%
12/21 01:37:08AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][78/79]	Step 82910	Loss 1.9659	Prec@(1,5) (57.5%, 84.7%)
12/21 01:37:08AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 57.5400%
12/21 01:37:08AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:37:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][100/703]	Step 83010	lr 0.00159	Loss 0.1292 (0.2250)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/21 01:37:49AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][200/703]	Step 83110	lr 0.00159	Loss 0.1552 (0.2264)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
12/21 01:38:09AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][300/703]	Step 83210	lr 0.00159	Loss 0.2924 (0.2314)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
12/21 01:38:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][400/703]	Step 83310	lr 0.00159	Loss 0.2301 (0.2343)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
12/21 01:38:48AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][500/703]	Step 83410	lr 0.00159	Loss 0.1835 (0.2331)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
12/21 01:39:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][600/703]	Step 83510	lr 0.00159	Loss 0.2539 (0.2348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
12/21 01:39:26AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][700/703]	Step 83610	lr 0.00159	Loss 0.3561 (0.2351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
12/21 01:39:27AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][703/703]	Step 83613	lr 0.00159	Loss 0.3663 (0.2351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
12/21 01:39:27AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [140/149] Final Prec@1 92.7844%
12/21 01:39:33AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][78/79]	Step 83614	Loss 2.0338	Prec@(1,5) (57.6%, 83.8%)
12/21 01:39:33AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 57.5800%
12/21 01:39:33AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:39:53AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][100/703]	Step 83714	lr 0.00148	Loss 0.1428 (0.2005)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.7%)	
12/21 01:40:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][200/703]	Step 83814	lr 0.00148	Loss 0.1123 (0.2046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.7%)	
12/21 01:40:31AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][300/703]	Step 83914	lr 0.00148	Loss 0.1280 (0.2141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
12/21 01:40:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][400/703]	Step 84014	lr 0.00148	Loss 0.2937 (0.2181)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/21 01:41:09AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][500/703]	Step 84114	lr 0.00148	Loss 0.0824 (0.2195)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/21 01:41:28AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][600/703]	Step 84214	lr 0.00148	Loss 0.1840 (0.2209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/21 01:41:47AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][700/703]	Step 84314	lr 0.00148	Loss 0.1520 (0.2212)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/21 01:41:48AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][703/703]	Step 84317	lr 0.00148	Loss 0.2163 (0.2213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/21 01:41:48AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [141/149] Final Prec@1 93.3622%
12/21 01:41:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][78/79]	Step 84318	Loss 2.0436	Prec@(1,5) (57.1%, 84.4%)
12/21 01:41:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 57.0800%
12/21 01:41:54AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:42:15AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][100/703]	Step 84418	lr 0.00138	Loss 0.3740 (0.2049)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.7%)	
12/21 01:42:35AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][200/703]	Step 84518	lr 0.00138	Loss 0.2071 (0.2045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.7%)	
12/21 01:42:54AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][300/703]	Step 84618	lr 0.00138	Loss 0.1574 (0.2063)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.7%)	
12/21 01:43:13AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][400/703]	Step 84718	lr 0.00138	Loss 0.1354 (0.2053)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.7%)	
12/21 01:43:33AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][500/703]	Step 84818	lr 0.00138	Loss 0.2387 (0.2069)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.7%)	
12/21 01:43:52AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][600/703]	Step 84918	lr 0.00138	Loss 0.3113 (0.2094)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/21 01:44:11AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][700/703]	Step 85018	lr 0.00138	Loss 0.2566 (0.2106)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/21 01:44:12AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][703/703]	Step 85021	lr 0.00138	Loss 0.2622 (0.2107)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/21 01:44:12AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [142/149] Final Prec@1 93.7533%
12/21 01:44:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][78/79]	Step 85022	Loss 2.0311	Prec@(1,5) (57.4%, 84.4%)
12/21 01:44:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 57.3800%
12/21 01:44:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:44:39AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][100/703]	Step 85122	lr 0.00129	Loss 0.2073 (0.1868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.7%)	
12/21 01:44:58AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][200/703]	Step 85222	lr 0.00129	Loss 0.1033 (0.1888)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/21 01:45:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][300/703]	Step 85322	lr 0.00129	Loss 0.0909 (0.1882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/21 01:45:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][400/703]	Step 85422	lr 0.00129	Loss 0.1285 (0.1915)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/21 01:45:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][500/703]	Step 85522	lr 0.00129	Loss 0.1603 (0.1937)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/21 01:46:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][600/703]	Step 85622	lr 0.00129	Loss 0.1852 (0.1959)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.7%)	
12/21 01:46:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][700/703]	Step 85722	lr 0.00129	Loss 0.3925 (0.1974)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.7%)	
12/21 01:46:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][703/703]	Step 85725	lr 0.00129	Loss 0.2062 (0.1973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.7%)	
12/21 01:46:38AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [143/149] Final Prec@1 94.3511%
12/21 01:46:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][78/79]	Step 85726	Loss 2.0197	Prec@(1,5) (57.9%, 84.5%)
12/21 01:46:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 57.8800%
12/21 01:46:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:47:05AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][100/703]	Step 85826	lr 0.00121	Loss 0.2567 (0.1794)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.9%, 99.8%)	
12/21 01:47:24AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][200/703]	Step 85926	lr 0.00121	Loss 0.2146 (0.1790)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/21 01:47:44AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][300/703]	Step 86026	lr 0.00121	Loss 0.2816 (0.1818)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/21 01:48:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][400/703]	Step 86126	lr 0.00121	Loss 0.2091 (0.1832)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/21 01:48:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][500/703]	Step 86226	lr 0.00121	Loss 0.2257 (0.1855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/21 01:48:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][600/703]	Step 86326	lr 0.00121	Loss 0.2329 (0.1888)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/21 01:49:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][700/703]	Step 86426	lr 0.00121	Loss 0.1446 (0.1919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
12/21 01:49:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][703/703]	Step 86429	lr 0.00121	Loss 0.2143 (0.1919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
12/21 01:49:04AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [144/149] Final Prec@1 94.3533%
12/21 01:49:10AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][78/79]	Step 86430	Loss 2.0222	Prec@(1,5) (57.9%, 84.5%)
12/21 01:49:10AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 57.8800%
12/21 01:49:10AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:49:31AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][100/703]	Step 86530	lr 0.00115	Loss 0.1881 (0.1722)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 01:49:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][200/703]	Step 86630	lr 0.00115	Loss 0.1263 (0.1730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.9%)	
12/21 01:50:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][300/703]	Step 86730	lr 0.00115	Loss 0.1970 (0.1769)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.9%, 99.9%)	
12/21 01:50:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][400/703]	Step 86830	lr 0.00115	Loss 0.1670 (0.1790)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.9%, 99.8%)	
12/21 01:50:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][500/703]	Step 86930	lr 0.00115	Loss 0.1869 (0.1824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/21 01:51:09AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][600/703]	Step 87030	lr 0.00115	Loss 0.1719 (0.1825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:51:29AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][700/703]	Step 87130	lr 0.00115	Loss 0.2600 (0.1864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/21 01:51:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][703/703]	Step 87133	lr 0.00115	Loss 0.2436 (0.1864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/21 01:51:30AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [145/149] Final Prec@1 94.6444%
12/21 01:51:36AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][78/79]	Step 87134	Loss 2.0616	Prec@(1,5) (57.9%, 84.3%)
12/21 01:51:36AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 57.8400%
12/21 01:51:36AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:51:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][100/703]	Step 87234	lr 0.00109	Loss 0.1539 (0.1769)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.8%)	
12/21 01:52:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][200/703]	Step 87334	lr 0.00109	Loss 0.1086 (0.1753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.9%)	
12/21 01:52:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][300/703]	Step 87434	lr 0.00109	Loss 0.1476 (0.1812)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:52:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][400/703]	Step 87534	lr 0.00109	Loss 0.1760 (0.1812)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:53:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][500/703]	Step 87634	lr 0.00109	Loss 0.1642 (0.1827)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:53:36AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][600/703]	Step 87734	lr 0.00109	Loss 0.1266 (0.1824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:53:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][700/703]	Step 87834	lr 0.00109	Loss 0.2446 (0.1833)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:53:56AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][703/703]	Step 87837	lr 0.00109	Loss 0.1731 (0.1832)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/21 01:53:57AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [146/149] Final Prec@1 94.7778%
12/21 01:54:02AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][78/79]	Step 87838	Loss 2.0598	Prec@(1,5) (57.5%, 84.1%)
12/21 01:54:02AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 57.5000%
12/21 01:54:02AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:54:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][100/703]	Step 87938	lr 0.00105	Loss 0.1071 (0.1552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
12/21 01:54:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][200/703]	Step 88038	lr 0.00105	Loss 0.0956 (0.1657)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.9%)	
12/21 01:55:03AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][300/703]	Step 88138	lr 0.00105	Loss 0.1170 (0.1702)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.8%)	
12/21 01:55:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][400/703]	Step 88238	lr 0.00105	Loss 0.2031 (0.1717)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 01:55:43AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][500/703]	Step 88338	lr 0.00105	Loss 0.1586 (0.1735)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.8%)	
12/21 01:56:02AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][600/703]	Step 88438	lr 0.00105	Loss 0.2319 (0.1744)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.8%)	
12/21 01:56:22AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][700/703]	Step 88538	lr 0.00105	Loss 0.1806 (0.1757)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.8%)	
12/21 01:56:23AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][703/703]	Step 88541	lr 0.00105	Loss 0.2361 (0.1759)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.8%)	
12/21 01:56:23AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [147/149] Final Prec@1 94.9489%
12/21 01:56:29AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][78/79]	Step 88542	Loss 2.1202	Prec@(1,5) (57.4%, 83.8%)
12/21 01:56:29AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 57.4000%
12/21 01:56:29AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:56:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][100/703]	Step 88642	lr 0.00102	Loss 0.1549 (0.1611)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
12/21 01:57:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][200/703]	Step 88742	lr 0.00102	Loss 0.1196 (0.1621)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/21 01:57:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][300/703]	Step 88842	lr 0.00102	Loss 0.1553 (0.1657)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.8%)	
12/21 01:57:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][400/703]	Step 88942	lr 0.00102	Loss 0.2086 (0.1673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.9%)	
12/21 01:58:10AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][500/703]	Step 89042	lr 0.00102	Loss 0.1147 (0.1704)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 01:58:30AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][600/703]	Step 89142	lr 0.00102	Loss 0.2531 (0.1721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.0%, 99.8%)	
12/21 01:58:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][700/703]	Step 89242	lr 0.00102	Loss 0.1658 (0.1714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 01:58:50AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][703/703]	Step 89245	lr 0.00102	Loss 0.2026 (0.1714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 01:58:51AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [148/149] Final Prec@1 95.0644%
12/21 01:58:56AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][78/79]	Step 89246	Loss 2.0347	Prec@(1,5) (57.7%, 84.6%)
12/21 01:58:56AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 57.6800%
12/21 01:58:56AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.0000%
12/21 01:59:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][100/703]	Step 89346	lr 0.00101	Loss 0.1648 (0.1622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/21 01:59:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][200/703]	Step 89446	lr 0.00101	Loss 0.1181 (0.1630)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/21 01:59:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][300/703]	Step 89546	lr 0.00101	Loss 0.1329 (0.1610)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/21 02:00:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][400/703]	Step 89646	lr 0.00101	Loss 0.1166 (0.1632)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/21 02:00:37AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][500/703]	Step 89746	lr 0.00101	Loss 0.1963 (0.1658)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.9%)	
12/21 02:00:57AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][600/703]	Step 89846	lr 0.00101	Loss 0.1003 (0.1679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 02:01:16AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][700/703]	Step 89946	lr 0.00101	Loss 0.2844 (0.1698)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 02:01:17AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][703/703]	Step 89949	lr 0.00101	Loss 0.1898 (0.1698)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/21 02:01:17AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [149/149] Final Prec@1 95.1000%
12/21 02:01:23AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][78/79]	Step 89950	Loss 2.0601	Prec@(1,5) (58.7%, 84.4%)
12/21 02:01:23AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 58.6800%
12/21 02:01:23AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6800%
12/21 02:01:23AM searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 58.6800%
12/21 02:01:23AM searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[10, 11])
