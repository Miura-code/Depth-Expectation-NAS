01/03 02:45:40AM parser.py:28 [INFO] 
01/03 02:45:40AM parser.py:29 [INFO] Parameters:
01/03 02:45:40AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s3-expected2-sw3-g-1_30-30/DAG
01/03 02:45:40AM parser.py:31 [INFO] T=10.0
01/03 02:45:40AM parser.py:31 [INFO] ADVANCED=1
01/03 02:45:40AM parser.py:31 [INFO] ALPHA_LR=0.0003
01/03 02:45:40AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
01/03 02:45:40AM parser.py:31 [INFO] ARCH_CRITERION=expected
01/03 02:45:40AM parser.py:31 [INFO] BATCH_SIZE=64
01/03 02:45:40AM parser.py:31 [INFO] CASCADE=0
01/03 02:45:40AM parser.py:31 [INFO] CHECKPOINT_RESET=False
01/03 02:45:40AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
01/03 02:45:40AM parser.py:31 [INFO] CUTOUT_LENGTH=0
01/03 02:45:40AM parser.py:31 [INFO] DATA_PATH=../data/
01/03 02:45:40AM parser.py:31 [INFO] DATASET=cifar100
01/03 02:45:40AM parser.py:31 [INFO] DEPTH_COEF=0.0
01/03 02:45:40AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
01/03 02:45:40AM parser.py:31 [INFO] DISCRETE=1
01/03 02:45:40AM parser.py:31 [INFO] EPOCHS=50
01/03 02:45:40AM parser.py:31 [INFO] EVAL_EPOCHS=90
01/03 02:45:40AM parser.py:31 [INFO] EXP_NAME=s3-expected2-sw3-g-1_30-30
01/03 02:45:40AM parser.py:31 [INFO] FINAL_L=0.0
01/03 02:45:40AM parser.py:31 [INFO] G=-1.0
01/03 02:45:40AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
01/03 02:45:40AM parser.py:31 [INFO] GPUS=[0]
01/03 02:45:40AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
01/03 02:45:40AM parser.py:31 [INFO] INIT_CHANNELS=16
01/03 02:45:40AM parser.py:31 [INFO] L=0.0
01/03 02:45:40AM parser.py:31 [INFO] LAYERS=32
01/03 02:45:40AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
01/03 02:45:40AM parser.py:31 [INFO] NAME=Pruning
01/03 02:45:40AM parser.py:31 [INFO] NONKD=1
01/03 02:45:40AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s3-expected2-sw3-g-1_30-30
01/03 02:45:40AM parser.py:31 [INFO] PCDARTS=0
01/03 02:45:40AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s3-expected2-sw3-g-1_30-30/plots
01/03 02:45:40AM parser.py:31 [INFO] PRINT_FREQ=100
01/03 02:45:40AM parser.py:31 [INFO] RESET=0
01/03 02:45:40AM parser.py:31 [INFO] RESUME_PATH=None
01/03 02:45:40AM parser.py:31 [INFO] SAVE=s3-expected2-sw3-g-1_30-30
01/03 02:45:40AM parser.py:31 [INFO] SEED=3
01/03 02:45:40AM parser.py:31 [INFO] SHARE_STAGE=0
01/03 02:45:40AM parser.py:31 [INFO] SLIDE_WINDOW=3
01/03 02:45:40AM parser.py:31 [INFO] SPEC_CELL=1
01/03 02:45:40AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
01/03 02:45:40AM parser.py:31 [INFO] TEACHER_NAME=none
01/03 02:45:40AM parser.py:31 [INFO] TEACHER_PATH=none
01/03 02:45:40AM parser.py:31 [INFO] TRAIN_PORTION=0.5
01/03 02:45:40AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
01/03 02:45:40AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
01/03 02:45:40AM parser.py:31 [INFO] W_LR=0.025
01/03 02:45:40AM parser.py:31 [INFO] W_LR_MIN=0.001
01/03 02:45:40AM parser.py:31 [INFO] W_MOMENTUM=0.9
01/03 02:45:40AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
01/03 02:45:40AM parser.py:31 [INFO] WORKERS=4
01/03 02:45:40AM parser.py:32 [INFO] 
01/03 02:45:41AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
01/03 02:46:04AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.4850 (4.5052)	Arch Loss 4.1776 (4.4970)	Arch Hard Loss 4.1776 (4.4970)	Arch Beta Loss 6.1917 (6.1943)	Arch depth Loss -0.0030 (-0.0018)	Prec@(1,5) (2.3%, 10.6%)	
01/03 02:46:26AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0947 (4.3697)	Arch Loss 4.0395 (4.3477)	Arch Hard Loss 4.0395 (4.3477)	Arch Beta Loss 6.1840 (6.1914)	Arch depth Loss -0.0057 (-0.0028)	Prec@(1,5) (3.5%, 14.6%)	
01/03 02:46:48AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9089 (4.2678)	Arch Loss 3.8478 (4.2552)	Arch Hard Loss 3.8478 (4.2552)	Arch Beta Loss 6.1787 (6.1881)	Arch depth Loss -0.0076 (-0.0039)	Prec@(1,5) (4.4%, 17.5%)	
01/03 02:47:07AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.0020 (4.1953)	Arch Loss 4.0060 (4.1845)	Arch Hard Loss 4.0060 (4.1845)	Arch Beta Loss 6.1710 (6.1857)	Arch depth Loss -0.0103 (-0.0050)	Prec@(1,5) (5.2%, 19.8%)	
01/03 02:47:08AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  0/149] Final Prec@1 5.1960%
01/03 02:47:11AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0139	Prec@(1,5) (7.9%, 27.1%)
01/03 02:47:14AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.0063	Prec@(1,5) (7.8%, 27.3%)
01/03 02:47:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0054	Prec@(1,5) (7.8%, 27.3%)
01/03 02:47:20AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0034	Prec@(1,5) (7.8%, 27.1%)
01/03 02:47:21AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 7.8280%
01/03 02:47:21AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
01/03 02:47:21AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 7.8280%
01/03 02:47:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.025	Loss 4.0249 (3.8595)	Arch Loss 3.8976 (3.8374)	Arch Hard Loss 3.8976 (3.8374)	Arch Beta Loss 6.1640 (6.1673)	Arch depth Loss -0.0113 (-0.0111)	Prec@(1,5) (9.1%, 30.0%)	
01/03 02:48:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.025	Loss 4.0236 (3.8174)	Arch Loss 3.6138 (3.8065)	Arch Hard Loss 3.6138 (3.8065)	Arch Beta Loss 6.1551 (6.1632)	Arch depth Loss -0.0120 (-0.0116)	Prec@(1,5) (9.6%, 31.5%)	
01/03 02:48:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.025	Loss 3.6849 (3.7807)	Arch Loss 3.5815 (3.7647)	Arch Hard Loss 3.5815 (3.7647)	Arch Beta Loss 6.1463 (6.1589)	Arch depth Loss -0.0130 (-0.0119)	Prec@(1,5) (10.7%, 32.8%)	
01/03 02:48:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.025	Loss 3.8307 (3.7521)	Arch Loss 3.6761 (3.7333)	Arch Hard Loss 3.6761 (3.7333)	Arch Beta Loss 6.1407 (6.1557)	Arch depth Loss -0.0110 (-0.0118)	Prec@(1,5) (11.2%, 33.7%)	
01/03 02:48:48午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  1/149] Final Prec@1 11.1600%
01/03 02:48:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5872	Prec@(1,5) (13.5%, 39.0%)
01/03 02:48:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6094	Prec@(1,5) (12.9%, 38.3%)
01/03 02:48:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6030	Prec@(1,5) (13.2%, 38.7%)
01/03 02:49:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6073	Prec@(1,5) (13.3%, 38.6%)
01/03 02:49:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 13.2560%
01/03 02:49:00午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
01/03 02:49:00午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 13.2560%
01/03 02:49:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02499	Loss 3.4595 (3.5261)	Arch Loss 3.6845 (3.5492)	Arch Hard Loss 3.6845 (3.5492)	Arch Beta Loss 6.1284 (6.1352)	Arch depth Loss -0.0147 (-0.0120)	Prec@(1,5) (14.4%, 40.5%)	
01/03 02:49:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02499	Loss 3.3115 (3.5259)	Arch Loss 3.6666 (3.5383)	Arch Hard Loss 3.6666 (3.5383)	Arch Beta Loss 6.1198 (6.1304)	Arch depth Loss -0.0131 (-0.0129)	Prec@(1,5) (14.9%, 40.7%)	
01/03 02:50:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02499	Loss 3.5508 (3.5128)	Arch Loss 3.6137 (3.5125)	Arch Hard Loss 3.6137 (3.5125)	Arch Beta Loss 6.1100 (6.1252)	Arch depth Loss -0.0148 (-0.0132)	Prec@(1,5) (15.2%, 41.0%)	
01/03 02:50:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02499	Loss 3.2721 (3.4920)	Arch Loss 3.6137 (3.4889)	Arch Hard Loss 3.6137 (3.4889)	Arch Beta Loss 6.1026 (6.1206)	Arch depth Loss -0.0145 (-0.0136)	Prec@(1,5) (15.5%, 41.8%)	
01/03 02:50:27午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  2/149] Final Prec@1 15.5120%
01/03 02:50:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3563	Prec@(1,5) (17.4%, 45.6%)
01/03 02:50:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3573	Prec@(1,5) (17.6%, 45.6%)
01/03 02:50:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3624	Prec@(1,5) (17.5%, 45.2%)
01/03 02:50:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3577	Prec@(1,5) (17.6%, 45.6%)
01/03 02:50:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 17.5520%
01/03 02:50:39午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
01/03 02:50:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 17.5520%
01/03 02:51:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02498	Loss 3.4830 (3.3283)	Arch Loss 3.3255 (3.3569)	Arch Hard Loss 3.3255 (3.3569)	Arch Beta Loss 6.0958 (6.0987)	Arch depth Loss -0.0142 (-0.0132)	Prec@(1,5) (18.4%, 46.9%)	
01/03 02:51:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02498	Loss 3.4590 (3.2980)	Arch Loss 3.4095 (3.3482)	Arch Hard Loss 3.4095 (3.3482)	Arch Beta Loss 6.0858 (6.0954)	Arch depth Loss -0.0148 (-0.0135)	Prec@(1,5) (18.7%, 47.7%)	
01/03 02:51:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02498	Loss 3.1905 (3.2952)	Arch Loss 3.3759 (3.3144)	Arch Hard Loss 3.3759 (3.3144)	Arch Beta Loss 6.0733 (6.0897)	Arch depth Loss -0.0138 (-0.0136)	Prec@(1,5) (19.0%, 47.6%)	
01/03 02:52:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02498	Loss 3.3786 (3.2738)	Arch Loss 3.0371 (3.2965)	Arch Hard Loss 3.0371 (3.2965)	Arch Beta Loss 6.0659 (6.0854)	Arch depth Loss -0.0162 (-0.0139)	Prec@(1,5) (19.5%, 48.2%)	
01/03 02:52:06午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  3/149] Final Prec@1 19.5520%
01/03 02:52:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1886	Prec@(1,5) (21.1%, 50.2%)
01/03 02:52:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1883	Prec@(1,5) (21.1%, 50.7%)
01/03 02:52:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1945	Prec@(1,5) (20.9%, 50.7%)
01/03 02:52:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1881	Prec@(1,5) (20.8%, 50.7%)
01/03 02:52:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 20.7720%
01/03 02:52:18午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
01/03 02:52:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 20.7720%
01/03 02:52:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02496	Loss 3.2226 (3.1216)	Arch Loss 2.9893 (3.1724)	Arch Hard Loss 2.9893 (3.1724)	Arch Beta Loss 6.0585 (6.0629)	Arch depth Loss -0.0153 (-0.0148)	Prec@(1,5) (22.0%, 52.0%)	
01/03 02:53:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02496	Loss 2.9614 (3.1131)	Arch Loss 3.1068 (3.1637)	Arch Hard Loss 3.1068 (3.1637)	Arch Beta Loss 6.0503 (6.0593)	Arch depth Loss -0.0172 (-0.0157)	Prec@(1,5) (22.1%, 52.4%)	
01/03 02:53:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02496	Loss 2.8497 (3.0901)	Arch Loss 3.0898 (3.1407)	Arch Hard Loss 3.0898 (3.1407)	Arch Beta Loss 6.0470 (6.0557)	Arch depth Loss -0.0173 (-0.0162)	Prec@(1,5) (22.3%, 53.2%)	
01/03 02:53:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02496	Loss 3.0752 (3.0769)	Arch Loss 3.0089 (3.1253)	Arch Hard Loss 3.0089 (3.1253)	Arch Beta Loss 6.0383 (6.0527)	Arch depth Loss -0.0169 (-0.0166)	Prec@(1,5) (22.7%, 53.4%)	
01/03 02:53:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  4/149] Final Prec@1 22.7120%
01/03 02:53:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0722	Prec@(1,5) (23.5%, 54.1%)
01/03 02:53:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0785	Prec@(1,5) (22.9%, 53.7%)
01/03 02:53:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0753	Prec@(1,5) (23.1%, 53.7%)
01/03 02:53:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0641	Prec@(1,5) (23.3%, 54.1%)
01/03 02:53:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 23.2720%
01/03 02:53:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
01/03 02:53:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 23.2720%
01/03 02:54:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02493	Loss 2.7538 (2.9393)	Arch Loss 3.1675 (3.0101)	Arch Hard Loss 3.1675 (3.0101)	Arch Beta Loss 6.0261 (6.0315)	Arch depth Loss -0.0172 (-0.0175)	Prec@(1,5) (26.0%, 56.7%)	
01/03 02:54:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02493	Loss 2.3850 (2.9340)	Arch Loss 2.7007 (3.0102)	Arch Hard Loss 2.7007 (3.0102)	Arch Beta Loss 6.0134 (6.0253)	Arch depth Loss -0.0167 (-0.0173)	Prec@(1,5) (25.7%, 56.9%)	
01/03 02:55:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02493	Loss 3.1289 (2.9251)	Arch Loss 2.9053 (2.9956)	Arch Hard Loss 2.9053 (2.9956)	Arch Beta Loss 6.0012 (6.0188)	Arch depth Loss -0.0170 (-0.0170)	Prec@(1,5) (25.8%, 57.1%)	
01/03 02:55:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02493	Loss 2.8273 (2.9074)	Arch Loss 3.1442 (2.9847)	Arch Hard Loss 3.1442 (2.9847)	Arch Beta Loss 5.9898 (6.0135)	Arch depth Loss -0.0188 (-0.0170)	Prec@(1,5) (26.1%, 57.6%)	
01/03 02:55:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  5/149] Final Prec@1 26.1440%
01/03 02:55:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.9383	Prec@(1,5) (26.7%, 57.5%)
01/03 02:55:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.9455	Prec@(1,5) (26.6%, 57.1%)
01/03 02:55:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.9435	Prec@(1,5) (26.5%, 57.3%)
01/03 02:55:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.9440	Prec@(1,5) (26.5%, 57.3%)
01/03 02:55:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 26.4800%
01/03 02:55:36午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
01/03 02:55:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 26.4800%
01/03 02:55:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02491	Loss 2.8322 (2.7844)	Arch Loss 3.0431 (2.8772)	Arch Hard Loss 3.0431 (2.8772)	Arch Beta Loss 5.9753 (5.9805)	Arch depth Loss -0.0214 (-0.0205)	Prec@(1,5) (28.7%, 60.5%)	
01/03 02:56:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02491	Loss 2.7500 (2.7854)	Arch Loss 3.1121 (2.8800)	Arch Hard Loss 3.1121 (2.8800)	Arch Beta Loss 5.9649 (5.9753)	Arch depth Loss -0.0201 (-0.0206)	Prec@(1,5) (28.4%, 60.6%)	
01/03 02:56:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02491	Loss 2.6405 (2.7696)	Arch Loss 2.7451 (2.8530)	Arch Hard Loss 2.7451 (2.8530)	Arch Beta Loss 5.9611 (5.9714)	Arch depth Loss -0.0201 (-0.0202)	Prec@(1,5) (28.5%, 60.9%)	
01/03 02:57:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02491	Loss 2.2714 (2.7580)	Arch Loss 2.6882 (2.8342)	Arch Hard Loss 2.6882 (2.8342)	Arch Beta Loss 5.9499 (5.9678)	Arch depth Loss -0.0216 (-0.0204)	Prec@(1,5) (28.9%, 61.1%)	
01/03 02:57:03午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  6/149] Final Prec@1 28.8880%
01/03 02:57:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7673	Prec@(1,5) (28.8%, 62.0%)
01/03 02:57:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7575	Prec@(1,5) (29.3%, 62.0%)
01/03 02:57:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7616	Prec@(1,5) (29.2%, 61.9%)
01/03 02:57:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7538	Prec@(1,5) (29.4%, 62.0%)
01/03 02:57:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 29.4440%
01/03 02:57:15午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
01/03 02:57:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 29.4440%
01/03 02:57:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02487	Loss 2.8230 (2.6322)	Arch Loss 2.9253 (2.7596)	Arch Hard Loss 2.9253 (2.7596)	Arch Beta Loss 5.9357 (5.9410)	Arch depth Loss -0.0240 (-0.0224)	Prec@(1,5) (31.0%, 64.7%)	
01/03 02:58:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02487	Loss 2.6961 (2.6207)	Arch Loss 2.4660 (2.7286)	Arch Hard Loss 2.4660 (2.7286)	Arch Beta Loss 5.9295 (5.9367)	Arch depth Loss -0.0227 (-0.0228)	Prec@(1,5) (31.3%, 64.8%)	
01/03 02:58:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02487	Loss 2.4790 (2.6206)	Arch Loss 2.9004 (2.7262)	Arch Hard Loss 2.9004 (2.7262)	Arch Beta Loss 5.9210 (5.9325)	Arch depth Loss -0.0234 (-0.0229)	Prec@(1,5) (31.2%, 64.6%)	
01/03 02:58:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02487	Loss 2.4258 (2.6125)	Arch Loss 2.8337 (2.7162)	Arch Hard Loss 2.8337 (2.7162)	Arch Beta Loss 5.9153 (5.9290)	Arch depth Loss -0.0240 (-0.0231)	Prec@(1,5) (31.6%, 64.6%)	
01/03 02:58:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  7/149] Final Prec@1 31.6560%
01/03 02:58:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6277	Prec@(1,5) (32.2%, 64.7%)
01/03 02:58:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6272	Prec@(1,5) (32.7%, 64.7%)
01/03 02:58:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6451	Prec@(1,5) (32.2%, 64.3%)
01/03 02:58:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6473	Prec@(1,5) (31.9%, 64.3%)
01/03 02:58:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 31.9120%
01/03 02:58:55午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
01/03 02:58:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.9120%
01/03 02:59:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02483	Loss 2.7475 (2.4831)	Arch Loss 2.5661 (2.6607)	Arch Hard Loss 2.5661 (2.6607)	Arch Beta Loss 5.9103 (5.9121)	Arch depth Loss -0.0244 (-0.0243)	Prec@(1,5) (34.3%, 67.3%)	
01/03 02:59:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02483	Loss 2.3838 (2.4790)	Arch Loss 2.7101 (2.6521)	Arch Hard Loss 2.7101 (2.6521)	Arch Beta Loss 5.8942 (5.9073)	Arch depth Loss -0.0261 (-0.0248)	Prec@(1,5) (34.3%, 67.7%)	
01/03 03:00:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02483	Loss 2.6337 (2.4828)	Arch Loss 2.6178 (2.6274)	Arch Hard Loss 2.6178 (2.6274)	Arch Beta Loss 5.8858 (5.9014)	Arch depth Loss -0.0266 (-0.0252)	Prec@(1,5) (34.6%, 67.6%)	
01/03 03:00:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02483	Loss 2.4525 (2.4890)	Arch Loss 2.6468 (2.6147)	Arch Hard Loss 2.6468 (2.6147)	Arch Beta Loss 5.8806 (5.8972)	Arch depth Loss -0.0275 (-0.0255)	Prec@(1,5) (34.7%, 67.6%)	
01/03 03:00:21午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  8/149] Final Prec@1 34.6680%
01/03 03:00:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5951	Prec@(1,5) (33.0%, 65.6%)
01/03 03:00:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5861	Prec@(1,5) (33.1%, 65.6%)
01/03 03:00:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5887	Prec@(1,5) (32.9%, 65.4%)
01/03 03:00:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5832	Prec@(1,5) (33.1%, 65.5%)
01/03 03:00:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 33.1200%
01/03 03:00:34午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:00:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.1200%
01/03 03:00:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02479	Loss 2.2125 (2.3877)	Arch Loss 2.6745 (2.5749)	Arch Hard Loss 2.6745 (2.5749)	Arch Beta Loss 5.8749 (5.8778)	Arch depth Loss -0.0280 (-0.0281)	Prec@(1,5) (36.3%, 70.1%)	
01/03 03:01:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02479	Loss 2.4407 (2.3714)	Arch Loss 2.8077 (2.5701)	Arch Hard Loss 2.8077 (2.5701)	Arch Beta Loss 5.8687 (5.8742)	Arch depth Loss -0.0292 (-0.0284)	Prec@(1,5) (36.9%, 70.4%)	
01/03 03:01:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02479	Loss 2.3053 (2.3792)	Arch Loss 2.4815 (2.5471)	Arch Hard Loss 2.4815 (2.5471)	Arch Beta Loss 5.8581 (5.8703)	Arch depth Loss -0.0305 (-0.0289)	Prec@(1,5) (36.8%, 70.0%)	
01/03 03:02:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02479	Loss 2.1554 (2.3856)	Arch Loss 2.2738 (2.5429)	Arch Hard Loss 2.2738 (2.5429)	Arch Beta Loss 5.8518 (5.8669)	Arch depth Loss -0.0294 (-0.0291)	Prec@(1,5) (36.8%, 69.8%)	
01/03 03:02:00午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  9/149] Final Prec@1 36.7560%
01/03 03:02:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.5029	Prec@(1,5) (35.4%, 67.5%)
01/03 03:02:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.5006	Prec@(1,5) (35.0%, 67.4%)
01/03 03:02:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.5102	Prec@(1,5) (34.7%, 67.3%)
01/03 03:02:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.5117	Prec@(1,5) (34.6%, 67.3%)
01/03 03:02:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 34.5520%
01/03 03:02:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:02:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 34.5520%
01/03 03:02:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02474	Loss 2.5363 (2.2190)	Arch Loss 2.6863 (2.4743)	Arch Hard Loss 2.6863 (2.4743)	Arch Beta Loss 5.8438 (5.8473)	Arch depth Loss -0.0291 (-0.0294)	Prec@(1,5) (40.6%, 73.4%)	
01/03 03:02:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02474	Loss 2.2304 (2.2673)	Arch Loss 2.4585 (2.4653)	Arch Hard Loss 2.4585 (2.4653)	Arch Beta Loss 5.8347 (5.8437)	Arch depth Loss -0.0309 (-0.0294)	Prec@(1,5) (39.4%, 72.1%)	
01/03 03:03:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02474	Loss 1.9745 (2.2765)	Arch Loss 2.6489 (2.4648)	Arch Hard Loss 2.6489 (2.4648)	Arch Beta Loss 5.8293 (5.8397)	Arch depth Loss -0.0302 (-0.0295)	Prec@(1,5) (39.2%, 72.0%)	
01/03 03:03:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02474	Loss 2.5609 (2.2808)	Arch Loss 2.0197 (2.4646)	Arch Hard Loss 2.0197 (2.4646)	Arch Beta Loss 5.8229 (5.8364)	Arch depth Loss -0.0316 (-0.0299)	Prec@(1,5) (39.1%, 71.9%)	
01/03 03:03:39午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 10/149] Final Prec@1 39.0680%
01/03 03:03:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4590	Prec@(1,5) (36.1%, 67.9%)
01/03 03:03:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.4391	Prec@(1,5) (36.7%, 68.6%)
01/03 03:03:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.4511	Prec@(1,5) (36.4%, 68.3%)
01/03 03:03:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.4579	Prec@(1,5) (36.1%, 68.0%)
01/03 03:03:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 36.0520%
01/03 03:03:52午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:03:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.0520%
01/03 03:04:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02468	Loss 2.0563 (2.1735)	Arch Loss 2.1141 (2.4051)	Arch Hard Loss 2.1141 (2.4051)	Arch Beta Loss 5.8132 (5.8175)	Arch depth Loss -0.0324 (-0.0320)	Prec@(1,5) (41.0%, 74.2%)	
01/03 03:04:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02468	Loss 2.1038 (2.1978)	Arch Loss 2.1056 (2.3974)	Arch Hard Loss 2.1056 (2.3974)	Arch Beta Loss 5.8034 (5.8132)	Arch depth Loss -0.0329 (-0.0324)	Prec@(1,5) (40.3%, 74.0%)	
01/03 03:04:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02468	Loss 1.9330 (2.1900)	Arch Loss 2.0516 (2.3833)	Arch Hard Loss 2.0516 (2.3833)	Arch Beta Loss 5.7935 (5.8084)	Arch depth Loss -0.0313 (-0.0321)	Prec@(1,5) (40.5%, 74.2%)	
01/03 03:05:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02468	Loss 2.3474 (2.1946)	Arch Loss 2.1874 (2.3841)	Arch Hard Loss 2.1874 (2.3841)	Arch Beta Loss 5.7852 (5.8042)	Arch depth Loss -0.0303 (-0.0319)	Prec@(1,5) (40.4%, 74.1%)	
01/03 03:05:19午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 11/149] Final Prec@1 40.4240%
01/03 03:05:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3574	Prec@(1,5) (38.7%, 70.4%)
01/03 03:05:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3820	Prec@(1,5) (37.9%, 70.2%)
01/03 03:05:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3929	Prec@(1,5) (37.7%, 70.0%)
01/03 03:05:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3976	Prec@(1,5) (37.7%, 69.9%)
01/03 03:05:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 37.6480%
01/03 03:05:31午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:05:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.6480%
01/03 03:05:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02462	Loss 1.9388 (2.1021)	Arch Loss 2.4744 (2.3557)	Arch Hard Loss 2.4744 (2.3557)	Arch Beta Loss 5.7816 (5.7833)	Arch depth Loss -0.0290 (-0.0287)	Prec@(1,5) (42.7%, 75.5%)	
01/03 03:06:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02462	Loss 2.0630 (2.1058)	Arch Loss 2.1249 (2.3204)	Arch Hard Loss 2.1249 (2.3204)	Arch Beta Loss 5.7714 (5.7806)	Arch depth Loss -0.0276 (-0.0280)	Prec@(1,5) (42.6%, 75.7%)	
01/03 03:06:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02462	Loss 2.2479 (2.1177)	Arch Loss 2.2307 (2.3253)	Arch Hard Loss 2.2307 (2.3253)	Arch Beta Loss 5.7592 (5.7756)	Arch depth Loss -0.0293 (-0.0282)	Prec@(1,5) (42.8%, 75.5%)	
01/03 03:06:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02462	Loss 1.8589 (2.1205)	Arch Loss 2.4245 (2.3196)	Arch Hard Loss 2.4245 (2.3196)	Arch Beta Loss 5.7515 (5.7710)	Arch depth Loss -0.0275 (-0.0281)	Prec@(1,5) (42.7%, 75.4%)	
01/03 03:06:58午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 12/149] Final Prec@1 42.7480%
01/03 03:07:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2966	Prec@(1,5) (39.2%, 71.9%)
01/03 03:07:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2941	Prec@(1,5) (39.5%, 72.1%)
01/03 03:07:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2918	Prec@(1,5) (39.6%, 72.1%)
01/03 03:07:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2887	Prec@(1,5) (39.6%, 72.2%)
01/03 03:07:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 39.6040%
01/03 03:07:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:07:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.6040%
01/03 03:07:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02456	Loss 1.9497 (1.9898)	Arch Loss 2.3070 (2.2883)	Arch Hard Loss 2.3070 (2.2883)	Arch Beta Loss 5.7383 (5.7461)	Arch depth Loss -0.0280 (-0.0282)	Prec@(1,5) (45.1%, 78.5%)	
01/03 03:07:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02456	Loss 2.0103 (2.0278)	Arch Loss 2.4598 (2.2775)	Arch Hard Loss 2.4598 (2.2775)	Arch Beta Loss 5.7329 (5.7409)	Arch depth Loss -0.0285 (-0.0284)	Prec@(1,5) (44.8%, 77.4%)	
01/03 03:08:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02456	Loss 2.1071 (2.0297)	Arch Loss 2.0393 (2.2875)	Arch Hard Loss 2.0393 (2.2875)	Arch Beta Loss 5.7253 (5.7368)	Arch depth Loss -0.0273 (-0.0281)	Prec@(1,5) (44.7%, 77.2%)	
01/03 03:08:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02456	Loss 1.9066 (2.0406)	Arch Loss 2.3615 (2.2837)	Arch Hard Loss 2.3615 (2.2837)	Arch Beta Loss 5.7198 (5.7333)	Arch depth Loss -0.0248 (-0.0277)	Prec@(1,5) (44.4%, 77.0%)	
01/03 03:08:37午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 13/149] Final Prec@1 44.3520%
01/03 03:08:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2545	Prec@(1,5) (40.5%, 73.1%)
01/03 03:08:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2744	Prec@(1,5) (40.1%, 72.2%)
01/03 03:08:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2618	Prec@(1,5) (40.3%, 72.4%)
01/03 03:08:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2572	Prec@(1,5) (40.4%, 72.2%)
01/03 03:08:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 40.3840%
01/03 03:08:50午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:08:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.3840%
01/03 03:09:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02449	Loss 1.9371 (1.9624)	Arch Loss 1.9285 (2.1937)	Arch Hard Loss 1.9285 (2.1937)	Arch Beta Loss 5.7097 (5.7146)	Arch depth Loss -0.0236 (-0.0238)	Prec@(1,5) (45.8%, 78.3%)	
01/03 03:09:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02449	Loss 2.0173 (1.9597)	Arch Loss 2.2759 (2.2332)	Arch Hard Loss 2.2759 (2.2332)	Arch Beta Loss 5.7043 (5.7112)	Arch depth Loss -0.0230 (-0.0233)	Prec@(1,5) (45.7%, 78.6%)	
01/03 03:09:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02449	Loss 2.0235 (1.9793)	Arch Loss 1.8905 (2.2218)	Arch Hard Loss 1.8905 (2.2218)	Arch Beta Loss 5.6924 (5.7071)	Arch depth Loss -0.0242 (-0.0235)	Prec@(1,5) (45.6%, 78.1%)	
01/03 03:10:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02449	Loss 2.0874 (1.9758)	Arch Loss 2.0855 (2.2181)	Arch Hard Loss 2.0855 (2.2181)	Arch Beta Loss 5.6889 (5.7036)	Arch depth Loss -0.0255 (-0.0238)	Prec@(1,5) (45.6%, 78.1%)	
01/03 03:10:17午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 14/149] Final Prec@1 45.6240%
01/03 03:10:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.2646	Prec@(1,5) (40.9%, 73.1%)
01/03 03:10:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.2587	Prec@(1,5) (40.4%, 73.4%)
01/03 03:10:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.2562	Prec@(1,5) (40.4%, 73.5%)
01/03 03:10:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.2571	Prec@(1,5) (40.4%, 73.5%)
01/03 03:10:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 40.3560%
01/03 03:10:29午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:10:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.3840%
01/03 03:10:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02441	Loss 1.5690 (1.8582)	Arch Loss 2.2988 (2.2295)	Arch Hard Loss 2.2988 (2.2295)	Arch Beta Loss 5.6815 (5.6858)	Arch depth Loss -0.0243 (-0.0256)	Prec@(1,5) (48.5%, 80.9%)	
01/03 03:11:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02441	Loss 1.7752 (1.8660)	Arch Loss 2.1939 (2.2094)	Arch Hard Loss 2.1939 (2.2094)	Arch Beta Loss 5.6741 (5.6814)	Arch depth Loss -0.0240 (-0.0251)	Prec@(1,5) (48.3%, 80.4%)	
01/03 03:11:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02441	Loss 1.9473 (1.8984)	Arch Loss 2.0326 (2.1924)	Arch Hard Loss 2.0326 (2.1924)	Arch Beta Loss 5.6666 (5.6781)	Arch depth Loss -0.0238 (-0.0245)	Prec@(1,5) (47.6%, 79.8%)	
01/03 03:11:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02441	Loss 1.7150 (1.9117)	Arch Loss 2.0422 (2.1855)	Arch Hard Loss 2.0422 (2.1855)	Arch Beta Loss 5.6591 (5.6746)	Arch depth Loss -0.0247 (-0.0245)	Prec@(1,5) (47.2%, 79.6%)	
01/03 03:11:56午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 15/149] Final Prec@1 47.2600%
01/03 03:11:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1419	Prec@(1,5) (43.0%, 74.9%)
01/03 03:12:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1602	Prec@(1,5) (42.7%, 74.5%)
01/03 03:12:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1587	Prec@(1,5) (42.6%, 74.6%)
01/03 03:12:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1528	Prec@(1,5) (42.8%, 74.7%)
01/03 03:12:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 42.7880%
01/03 03:12:08午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:12:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.7880%
01/03 03:12:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.02433	Loss 1.4955 (1.8006)	Arch Loss 2.0311 (2.0919)	Arch Hard Loss 2.0311 (2.0919)	Arch Beta Loss 5.6554 (5.6564)	Arch depth Loss -0.0261 (-0.0255)	Prec@(1,5) (50.2%, 81.5%)	
01/03 03:12:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.02433	Loss 1.9231 (1.8382)	Arch Loss 2.3815 (2.1217)	Arch Hard Loss 2.3815 (2.1217)	Arch Beta Loss 5.6481 (5.6547)	Arch depth Loss -0.0259 (-0.0255)	Prec@(1,5) (49.5%, 80.9%)	
01/03 03:13:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.02433	Loss 1.9065 (1.8557)	Arch Loss 2.0446 (2.1409)	Arch Hard Loss 2.0446 (2.1409)	Arch Beta Loss 5.6405 (5.6513)	Arch depth Loss -0.0226 (-0.0251)	Prec@(1,5) (48.7%, 80.4%)	
01/03 03:13:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.02433	Loss 1.6983 (1.8498)	Arch Loss 1.9362 (2.1405)	Arch Hard Loss 1.9362 (2.1405)	Arch Beta Loss 5.6348 (5.6481)	Arch depth Loss -0.0203 (-0.0241)	Prec@(1,5) (48.8%, 80.6%)	
01/03 03:13:36午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 16/149] Final Prec@1 48.7880%
01/03 03:13:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0841	Prec@(1,5) (44.5%, 75.9%)
01/03 03:13:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0947	Prec@(1,5) (43.8%, 75.6%)
01/03 03:13:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1078	Prec@(1,5) (43.6%, 75.4%)
01/03 03:13:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1138	Prec@(1,5) (43.5%, 75.3%)
01/03 03:13:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 43.5320%
01/03 03:13:48午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:13:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.5320%
01/03 03:14:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.02425	Loss 1.8018 (1.7308)	Arch Loss 1.8847 (2.1067)	Arch Hard Loss 1.8847 (2.1067)	Arch Beta Loss 5.6297 (5.6321)	Arch depth Loss -0.0183 (-0.0201)	Prec@(1,5) (51.6%, 82.9%)	
01/03 03:14:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.02425	Loss 1.8378 (1.7644)	Arch Loss 2.6699 (2.1087)	Arch Hard Loss 2.6699 (2.1087)	Arch Beta Loss 5.6208 (5.6288)	Arch depth Loss -0.0179 (-0.0196)	Prec@(1,5) (51.0%, 82.2%)	
01/03 03:14:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.02425	Loss 1.8839 (1.7747)	Arch Loss 1.9401 (2.0996)	Arch Hard Loss 1.9401 (2.0996)	Arch Beta Loss 5.6170 (5.6254)	Arch depth Loss -0.0172 (-0.0190)	Prec@(1,5) (50.6%, 82.1%)	
01/03 03:15:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.02425	Loss 1.6155 (1.7889)	Arch Loss 2.0343 (2.1055)	Arch Hard Loss 2.0343 (2.1055)	Arch Beta Loss 5.6126 (5.6227)	Arch depth Loss -0.0142 (-0.0183)	Prec@(1,5) (50.3%, 81.9%)	
01/03 03:15:15午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 17/149] Final Prec@1 50.3120%
01/03 03:15:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0581	Prec@(1,5) (45.1%, 76.5%)
01/03 03:15:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0915	Prec@(1,5) (44.5%, 75.7%)
01/03 03:15:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.1035	Prec@(1,5) (44.2%, 75.5%)
01/03 03:15:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.1061	Prec@(1,5) (44.2%, 75.6%)
01/03 03:15:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 44.1960%
01/03 03:15:27午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:15:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.1960%
01/03 03:15:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.02416	Loss 1.6336 (1.6671)	Arch Loss 2.4960 (2.0925)	Arch Hard Loss 2.4960 (2.0925)	Arch Beta Loss 5.6078 (5.6094)	Arch depth Loss -0.0114 (-0.0137)	Prec@(1,5) (53.0%, 83.9%)	
01/03 03:16:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.02416	Loss 1.3326 (1.6963)	Arch Loss 2.0722 (2.0744)	Arch Hard Loss 2.0722 (2.0744)	Arch Beta Loss 5.6005 (5.6069)	Arch depth Loss -0.0076 (-0.0114)	Prec@(1,5) (52.1%, 83.6%)	
01/03 03:16:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.02416	Loss 1.9490 (1.7258)	Arch Loss 1.8038 (2.0843)	Arch Hard Loss 1.8038 (2.0843)	Arch Beta Loss 5.5947 (5.6036)	Arch depth Loss -0.0070 (-0.0099)	Prec@(1,5) (51.5%, 82.9%)	
01/03 03:16:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.02416	Loss 1.9111 (1.7415)	Arch Loss 1.8040 (2.0830)	Arch Hard Loss 1.8040 (2.0830)	Arch Beta Loss 5.5883 (5.6008)	Arch depth Loss -0.0034 (-0.0090)	Prec@(1,5) (51.1%, 82.5%)	
01/03 03:16:54午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 18/149] Final Prec@1 51.1320%
01/03 03:16:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1663	Prec@(1,5) (42.5%, 75.0%)
01/03 03:17:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1545	Prec@(1,5) (42.7%, 75.3%)
01/03 03:17:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1313	Prec@(1,5) (43.2%, 75.9%)
01/03 03:17:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1307	Prec@(1,5) (43.3%, 75.8%)
01/03 03:17:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 43.2840%
01/03 03:17:07午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:17:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.1960%
01/03 03:17:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.02406	Loss 1.8209 (1.6323)	Arch Loss 2.1569 (2.0761)	Arch Hard Loss 2.1569 (2.0761)	Arch Beta Loss 5.5816 (5.5850)	Arch depth Loss -0.0014 (-0.0029)	Prec@(1,5) (54.4%, 85.1%)	
01/03 03:17:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.02406	Loss 1.9522 (1.6695)	Arch Loss 1.7429 (2.0767)	Arch Hard Loss 1.7429 (2.0767)	Arch Beta Loss 5.5714 (5.5814)	Arch depth Loss 0.0005 (-0.0018)	Prec@(1,5) (53.1%, 84.1%)	
01/03 03:18:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.02406	Loss 1.7908 (1.6902)	Arch Loss 2.1006 (2.0735)	Arch Hard Loss 2.1006 (2.0735)	Arch Beta Loss 5.5706 (5.5781)	Arch depth Loss 0.0025 (-0.0003)	Prec@(1,5) (52.6%, 83.7%)	
01/03 03:18:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.02406	Loss 1.7186 (1.7032)	Arch Loss 1.9084 (2.0686)	Arch Hard Loss 1.9084 (2.0686)	Arch Beta Loss 5.5649 (5.5758)	Arch depth Loss 0.0034 (0.0004)	Prec@(1,5) (52.2%, 83.3%)	
01/03 03:18:34午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 19/149] Final Prec@1 52.1680%
01/03 03:18:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0681	Prec@(1,5) (45.9%, 76.5%)
01/03 03:18:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0748	Prec@(1,5) (44.8%, 76.4%)
01/03 03:18:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0635	Prec@(1,5) (45.0%, 76.6%)
01/03 03:18:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0640	Prec@(1,5) (45.2%, 76.6%)
01/03 03:18:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 45.1600%
01/03 03:18:46午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
01/03 03:18:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1600%
01/03 03:19:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.02396	Loss 1.5638 (1.5983)	Arch Loss 1.6347 (2.0296)	Arch Hard Loss 1.6347 (2.0296)	Arch Beta Loss 5.5575 (5.5606)	Arch depth Loss 0.0047 (0.0040)	Prec@(1,5) (54.7%, 85.2%)	
01/03 03:19:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.02396	Loss 1.7464 (1.6181)	Arch Loss 1.9953 (2.0366)	Arch Hard Loss 1.9953 (2.0366)	Arch Beta Loss 5.5514 (5.5573)	Arch depth Loss 0.0070 (0.0051)	Prec@(1,5) (54.2%, 84.6%)	
01/03 03:19:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.02396	Loss 1.7967 (1.6364)	Arch Loss 1.9554 (2.0292)	Arch Hard Loss 1.9554 (2.0292)	Arch Beta Loss 5.5450 (5.5539)	Arch depth Loss 0.0095 (0.0059)	Prec@(1,5) (53.8%, 84.3%)	
01/03 03:20:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.02396	Loss 1.7831 (1.6454)	Arch Loss 2.4094 (2.0184)	Arch Hard Loss 2.4094 (2.0184)	Arch Beta Loss 5.5399 (5.5512)	Arch depth Loss 0.0127 (0.0071)	Prec@(1,5) (53.6%, 84.2%)	
01/03 03:20:13午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 20/149] Final Prec@1 53.5760%
01/03 03:20:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0848	Prec@(1,5) (44.0%, 76.7%)
01/03 03:20:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0754	Prec@(1,5) (44.5%, 76.6%)
01/03 03:20:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0723	Prec@(1,5) (44.7%, 76.5%)
01/03 03:20:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0715	Prec@(1,5) (44.7%, 76.8%)
01/03 03:20:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 44.6560%
01/03 03:20:25午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
01/03 03:20:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1600%
01/03 03:20:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.02386	Loss 1.5546 (1.5809)	Arch Loss 1.7212 (2.0203)	Arch Hard Loss 1.7212 (2.0203)	Arch Beta Loss 5.5346 (5.5380)	Arch depth Loss 0.0159 (0.0147)	Prec@(1,5) (55.5%, 85.1%)	
01/03 03:21:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.02386	Loss 1.7698 (1.5814)	Arch Loss 2.4591 (2.0174)	Arch Hard Loss 2.4591 (2.0174)	Arch Beta Loss 5.5324 (5.5360)	Arch depth Loss 0.0203 (0.0164)	Prec@(1,5) (55.4%, 85.4%)	
01/03 03:21:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.02386	Loss 1.7047 (1.6033)	Arch Loss 2.5322 (2.0112)	Arch Hard Loss 2.5322 (2.0112)	Arch Beta Loss 5.5302 (5.5346)	Arch depth Loss 0.0220 (0.0178)	Prec@(1,5) (54.8%, 85.0%)	
01/03 03:21:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.02386	Loss 1.4936 (1.6084)	Arch Loss 1.8854 (2.0063)	Arch Hard Loss 1.8854 (2.0063)	Arch Beta Loss 5.5245 (5.5328)	Arch depth Loss 0.0242 (0.0191)	Prec@(1,5) (54.6%, 84.8%)	
01/03 03:21:52午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 21/149] Final Prec@1 54.5920%
01/03 03:21:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.0250	Prec@(1,5) (45.6%, 77.1%)
01/03 03:21:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.0442	Prec@(1,5) (45.4%, 76.6%)
01/03 03:22:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.0532	Prec@(1,5) (45.2%, 76.9%)
01/03 03:22:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.0560	Prec@(1,5) (45.1%, 76.8%)
01/03 03:22:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 45.1120%
01/03 03:22:04午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
01/03 03:22:04午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1600%
01/03 03:22:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.02375	Loss 1.7998 (1.5002)	Arch Loss 1.7215 (1.9963)	Arch Hard Loss 1.7215 (1.9963)	Arch Beta Loss 5.5212 (5.5236)	Arch depth Loss 0.0308 (0.0263)	Prec@(1,5) (57.5%, 86.3%)	
01/03 03:22:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.02375	Loss 1.4661 (1.5442)	Arch Loss 2.0193 (2.0036)	Arch Hard Loss 2.0193 (2.0036)	Arch Beta Loss 5.5149 (5.5205)	Arch depth Loss 0.0362 (0.0296)	Prec@(1,5) (56.0%, 85.9%)	
01/03 03:23:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.02375	Loss 1.3870 (1.5609)	Arch Loss 1.7562 (1.9851)	Arch Hard Loss 1.7562 (1.9851)	Arch Beta Loss 5.5117 (5.5182)	Arch depth Loss 0.0386 (0.0324)	Prec@(1,5) (55.8%, 85.6%)	
01/03 03:23:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.02375	Loss 1.7252 (1.5770)	Arch Loss 1.6078 (1.9846)	Arch Hard Loss 1.6078 (1.9846)	Arch Beta Loss 5.5087 (5.5161)	Arch depth Loss 0.0404 (0.0341)	Prec@(1,5) (55.4%, 85.4%)	
01/03 03:23:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 22/149] Final Prec@1 55.4480%
01/03 03:23:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9291	Prec@(1,5) (48.4%, 78.6%)
01/03 03:23:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9281	Prec@(1,5) (48.6%, 78.8%)
01/03 03:23:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9277	Prec@(1,5) (48.2%, 79.1%)
01/03 03:23:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9304	Prec@(1,5) (48.2%, 79.0%)
01/03 03:23:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 48.1760%
01/03 03:23:44午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
01/03 03:23:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.1760%
01/03 03:24:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.02363	Loss 1.4583 (1.4754)	Arch Loss 2.0368 (1.9666)	Arch Hard Loss 2.0368 (1.9666)	Arch Beta Loss 5.5037 (5.5068)	Arch depth Loss 0.0417 (0.0410)	Prec@(1,5) (57.9%, 87.2%)	
01/03 03:24:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.02363	Loss 1.7519 (1.5004)	Arch Loss 1.6539 (1.9882)	Arch Hard Loss 1.6539 (1.9882)	Arch Beta Loss 5.4939 (5.5029)	Arch depth Loss 0.0479 (0.0427)	Prec@(1,5) (57.5%, 86.6%)	
01/03 03:24:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.02363	Loss 1.6658 (1.5161)	Arch Loss 1.7121 (1.9936)	Arch Hard Loss 1.7121 (1.9936)	Arch Beta Loss 5.4919 (5.4996)	Arch depth Loss 0.0510 (0.0448)	Prec@(1,5) (57.1%, 86.4%)	
01/03 03:25:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.02363	Loss 1.6553 (1.5251)	Arch Loss 2.2282 (1.9790)	Arch Hard Loss 2.2282 (1.9790)	Arch Beta Loss 5.4871 (5.4973)	Arch depth Loss 0.0541 (0.0467)	Prec@(1,5) (56.8%, 86.3%)	
01/03 03:25:10午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 23/149] Final Prec@1 56.8600%
01/03 03:25:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9353	Prec@(1,5) (48.1%, 78.8%)
01/03 03:25:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9469	Prec@(1,5) (48.2%, 78.8%)
01/03 03:25:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9455	Prec@(1,5) (48.2%, 78.8%)
01/03 03:25:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9454	Prec@(1,5) (48.2%, 78.8%)
01/03 03:25:23午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 48.2400%
01/03 03:25:23午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
01/03 03:25:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.2400%
01/03 03:25:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.02352	Loss 1.3701 (1.4344)	Arch Loss 2.1313 (1.9546)	Arch Hard Loss 2.1313 (1.9546)	Arch Beta Loss 5.4809 (5.4845)	Arch depth Loss 0.0546 (0.0536)	Prec@(1,5) (58.5%, 87.7%)	
01/03 03:26:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.02352	Loss 1.7367 (1.4604)	Arch Loss 1.8326 (1.9643)	Arch Hard Loss 1.8326 (1.9643)	Arch Beta Loss 5.4739 (5.4802)	Arch depth Loss 0.0588 (0.0547)	Prec@(1,5) (57.9%, 87.2%)	
01/03 03:26:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.02352	Loss 1.4236 (1.4769)	Arch Loss 1.6141 (1.9562)	Arch Hard Loss 1.6141 (1.9562)	Arch Beta Loss 5.4682 (5.4774)	Arch depth Loss 0.0612 (0.0567)	Prec@(1,5) (57.6%, 87.0%)	
01/03 03:26:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.02352	Loss 1.5687 (1.4939)	Arch Loss 2.1875 (1.9532)	Arch Hard Loss 2.1875 (1.9532)	Arch Beta Loss 5.4661 (5.4747)	Arch depth Loss 0.0649 (0.0581)	Prec@(1,5) (57.2%, 86.7%)	
01/03 03:26:50午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 24/149] Final Prec@1 57.1600%
01/03 03:26:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9960	Prec@(1,5) (46.6%, 78.2%)
01/03 03:26:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9943	Prec@(1,5) (46.9%, 77.9%)
01/03 03:26:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9959	Prec@(1,5) (46.7%, 77.8%)
01/03 03:27:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9932	Prec@(1,5) (46.7%, 77.8%)
01/03 03:27:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 46.6480%
01/03 03:27:02午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
01/03 03:27:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.2400%
01/03 03:27:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.02339	Loss 1.3852 (1.3898)	Arch Loss 1.9085 (1.9270)	Arch Hard Loss 1.9085 (1.9270)	Arch Beta Loss 5.4615 (5.4636)	Arch depth Loss 0.0697 (0.0684)	Prec@(1,5) (59.7%, 88.9%)	
01/03 03:27:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.02339	Loss 1.5045 (1.4204)	Arch Loss 1.8736 (1.9430)	Arch Hard Loss 1.8736 (1.9430)	Arch Beta Loss 5.4565 (5.4615)	Arch depth Loss 0.0720 (0.0697)	Prec@(1,5) (59.1%, 88.4%)	
01/03 03:28:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.02339	Loss 1.5912 (1.4437)	Arch Loss 2.3182 (1.9442)	Arch Hard Loss 2.3182 (1.9442)	Arch Beta Loss 5.4530 (5.4596)	Arch depth Loss 0.0748 (0.0704)	Prec@(1,5) (58.4%, 87.8%)	
01/03 03:28:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.02339	Loss 1.7393 (1.4615)	Arch Loss 1.6917 (1.9382)	Arch Hard Loss 1.6917 (1.9382)	Arch Beta Loss 5.4536 (5.4584)	Arch depth Loss 0.0786 (0.0716)	Prec@(1,5) (58.2%, 87.5%)	
01/03 03:28:29午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 25/149] Final Prec@1 58.1680%
01/03 03:28:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9515	Prec@(1,5) (47.4%, 79.2%)
01/03 03:28:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9446	Prec@(1,5) (47.6%, 79.2%)
01/03 03:28:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9768	Prec@(1,5) (47.1%, 78.7%)
01/03 03:28:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9802	Prec@(1,5) (47.1%, 78.5%)
01/03 03:28:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 47.1040%
01/03 03:28:41午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[10, 11])
01/03 03:28:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.2400%
01/03 03:29:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.02326	Loss 1.6062 (1.3916)	Arch Loss 1.9536 (1.9528)	Arch Hard Loss 1.9536 (1.9528)	Arch Beta Loss 5.4495 (5.4510)	Arch depth Loss 0.0824 (0.0808)	Prec@(1,5) (59.8%, 88.4%)	
01/03 03:29:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.02326	Loss 1.3211 (1.4143)	Arch Loss 1.8382 (1.9477)	Arch Hard Loss 1.8382 (1.9477)	Arch Beta Loss 5.4413 (5.4477)	Arch depth Loss 0.0836 (0.0820)	Prec@(1,5) (59.2%, 88.0%)	
01/03 03:29:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.02326	Loss 1.8485 (1.4278)	Arch Loss 2.0804 (1.9258)	Arch Hard Loss 2.0804 (1.9258)	Arch Beta Loss 5.4345 (5.4444)	Arch depth Loss 0.0843 (0.0826)	Prec@(1,5) (59.0%, 87.9%)	
01/03 03:30:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.02326	Loss 1.5037 (1.4438)	Arch Loss 1.8499 (1.9217)	Arch Hard Loss 1.8499 (1.9217)	Arch Beta Loss 5.4324 (5.4419)	Arch depth Loss 0.0888 (0.0835)	Prec@(1,5) (58.6%, 87.7%)	
01/03 03:30:08午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 26/149] Final Prec@1 58.5680%
01/03 03:30:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.9285	Prec@(1,5) (48.5%, 79.1%)
01/03 03:30:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.9266	Prec@(1,5) (49.0%, 79.3%)
01/03 03:30:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.9176	Prec@(1,5) (49.4%, 79.2%)
01/03 03:30:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9140	Prec@(1,5) (49.2%, 79.4%)
01/03 03:30:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 49.1920%
01/03 03:30:21午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[10, 11])
01/03 03:30:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
01/03 03:30:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.02313	Loss 1.2065 (1.3252)	Arch Loss 1.8345 (1.9009)	Arch Hard Loss 1.8345 (1.9009)	Arch Beta Loss 5.4306 (5.4326)	Arch depth Loss 0.0920 (0.0905)	Prec@(1,5) (61.8%, 89.4%)	
01/03 03:31:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.02313	Loss 1.4047 (1.3499)	Arch Loss 2.1906 (1.9122)	Arch Hard Loss 2.1906 (1.9122)	Arch Beta Loss 5.4278 (5.4309)	Arch depth Loss 0.0941 (0.0922)	Prec@(1,5) (61.1%, 89.2%)	
01/03 03:31:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.02313	Loss 1.1359 (1.3832)	Arch Loss 1.5881 (1.9007)	Arch Hard Loss 1.5881 (1.9007)	Arch Beta Loss 5.4222 (5.4287)	Arch depth Loss 0.0950 (0.0926)	Prec@(1,5) (60.1%, 88.6%)	
01/03 03:31:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.02313	Loss 1.5195 (1.3963)	Arch Loss 2.2243 (1.9009)	Arch Hard Loss 2.2243 (1.9009)	Arch Beta Loss 5.4195 (5.4269)	Arch depth Loss 0.0964 (0.0933)	Prec@(1,5) (59.8%, 88.3%)	
01/03 03:31:48午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 27/149] Final Prec@1 59.8040%
01/03 03:31:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9221	Prec@(1,5) (48.9%, 79.6%)
01/03 03:31:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.9243	Prec@(1,5) (48.8%, 79.7%)
01/03 03:31:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.9185	Prec@(1,5) (48.9%, 79.8%)
01/03 03:32:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.9223	Prec@(1,5) (48.8%, 79.8%)
01/03 03:32:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 48.8080%
01/03 03:32:01午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[10, 11])
01/03 03:32:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
01/03 03:32:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.023	Loss 1.3896 (1.3201)	Arch Loss 1.4059 (1.9124)	Arch Hard Loss 1.4059 (1.9124)	Arch Beta Loss 5.4148 (5.4179)	Arch depth Loss 0.1022 (0.1003)	Prec@(1,5) (61.9%, 89.2%)	
01/03 03:32:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.023	Loss 1.0279 (1.3429)	Arch Loss 1.8105 (1.9195)	Arch Hard Loss 1.8105 (1.9195)	Arch Beta Loss 5.4122 (5.4163)	Arch depth Loss 0.1081 (0.1025)	Prec@(1,5) (61.0%, 88.8%)	
01/03 03:33:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.023	Loss 1.2601 (1.3674)	Arch Loss 1.5237 (1.9145)	Arch Hard Loss 1.5237 (1.9145)	Arch Beta Loss 5.4077 (5.4139)	Arch depth Loss 0.1088 (0.1042)	Prec@(1,5) (60.3%, 88.7%)	
01/03 03:33:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.023	Loss 1.3476 (1.3744)	Arch Loss 2.1425 (1.9066)	Arch Hard Loss 2.1425 (1.9066)	Arch Beta Loss 5.4067 (5.4123)	Arch depth Loss 0.1084 (0.1054)	Prec@(1,5) (60.2%, 88.5%)	
01/03 03:33:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 28/149] Final Prec@1 60.1720%
01/03 03:33:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9094	Prec@(1,5) (48.2%, 79.8%)
01/03 03:33:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8995	Prec@(1,5) (48.7%, 80.1%)
01/03 03:33:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8997	Prec@(1,5) (48.8%, 80.0%)
01/03 03:33:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.9010	Prec@(1,5) (48.8%, 80.1%)
01/03 03:33:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 48.7720%
01/03 03:33:40午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[10, 11])
01/03 03:33:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
01/03 03:34:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.02285	Loss 1.2887 (1.2744)	Arch Loss 1.9256 (1.8969)	Arch Hard Loss 1.9256 (1.8969)	Arch Beta Loss 5.4019 (5.4039)	Arch depth Loss 0.1115 (0.1107)	Prec@(1,5) (62.4%, 90.2%)	
01/03 03:34:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.02285	Loss 1.3050 (1.3316)	Arch Loss 1.7761 (1.8953)	Arch Hard Loss 1.7761 (1.8953)	Arch Beta Loss 5.4013 (5.4028)	Arch depth Loss 0.1144 (0.1110)	Prec@(1,5) (61.2%, 89.3%)	
01/03 03:34:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.02285	Loss 1.2097 (1.3437)	Arch Loss 2.2100 (1.8880)	Arch Hard Loss 2.2100 (1.8880)	Arch Beta Loss 5.3986 (5.4021)	Arch depth Loss 0.1189 (0.1124)	Prec@(1,5) (60.8%, 89.0%)	
01/03 03:35:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.02285	Loss 1.6095 (1.3593)	Arch Loss 1.6464 (1.8906)	Arch Hard Loss 1.6464 (1.8906)	Arch Beta Loss 5.3962 (5.4010)	Arch depth Loss 0.1188 (0.1138)	Prec@(1,5) (60.5%, 88.8%)	
01/03 03:35:07午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 29/149] Final Prec@1 60.5360%
01/03 03:35:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.9012	Prec@(1,5) (48.3%, 80.0%)
01/03 03:35:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8960	Prec@(1,5) (48.9%, 80.0%)
01/03 03:35:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8946	Prec@(1,5) (49.0%, 79.9%)
01/03 03:35:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8931	Prec@(1,5) (49.2%, 80.0%)
01/03 03:35:19午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 49.1720%
01/03 03:35:19午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[10, 11])
01/03 03:35:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
01/03 03:35:20午前 searchEvalStage_curriculum_trainer.py:151 [INFO] --> Curriculum part A finished. Part B begins!
01/03 03:35:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.02271	Loss 1.3421 (1.2428)	Arch Loss -3.9362 (-3.7456)	Arch Hard Loss 1.8204 (1.8586)	Arch Beta Loss 5.7566 (5.6043)	Arch depth Loss 0.0786 (0.1007)	Prec@(1,5) (63.8%, 90.7%)	
01/03 03:36:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.02271	Loss 1.1385 (1.2721)	Arch Loss -4.0545 (-3.8522)	Arch Hard Loss 1.9366 (1.8892)	Arch Beta Loss 5.9912 (5.7414)	Arch depth Loss 0.0277 (0.0766)	Prec@(1,5) (62.8%, 90.4%)	
01/03 03:36:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.02271	Loss 1.4968 (1.3127)	Arch Loss -3.6962 (-3.9690)	Arch Hard Loss 2.5007 (1.8908)	Arch Beta Loss 6.1969 (5.8598)	Arch depth Loss -0.0185 (0.0526)	Prec@(1,5) (61.7%, 89.7%)	
01/03 03:36:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.02271	Loss 1.5733 (1.3337)	Arch Loss -4.4693 (-4.0674)	Arch Hard Loss 1.9033 (1.8907)	Arch Beta Loss 6.3727 (5.9581)	Arch depth Loss -0.0656 (0.0308)	Prec@(1,5) (61.2%, 89.2%)	
01/03 03:36:46午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 30/149] Final Prec@1 61.1800%
01/03 03:36:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9671	Prec@(1,5) (48.1%, 78.4%)
01/03 03:36:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9719	Prec@(1,5) (47.9%, 78.6%)
01/03 03:36:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9614	Prec@(1,5) (47.9%, 78.6%)
01/03 03:36:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9650	Prec@(1,5) (47.9%, 78.6%)
01/03 03:36:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 47.8640%
01/03 03:36:59午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[2, 3])
01/03 03:36:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
01/03 03:37:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.02256	Loss 1.2065 (1.2593)	Arch Loss -4.4807 (-4.5621)	Arch Hard Loss 2.0818 (1.9071)	Arch Beta Loss 6.5625 (6.4693)	Arch depth Loss -0.1134 (-0.0899)	Prec@(1,5) (62.7%, 90.5%)	
01/03 03:37:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.02256	Loss 1.2239 (1.2846)	Arch Loss -5.1246 (-4.6699)	Arch Hard Loss 1.6253 (1.8934)	Arch Beta Loss 6.7498 (6.5633)	Arch depth Loss -0.1632 (-0.1142)	Prec@(1,5) (62.7%, 89.9%)	
01/03 03:38:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.02256	Loss 1.3337 (1.3067)	Arch Loss -4.7797 (-4.7723)	Arch Hard Loss 2.1517 (1.8838)	Arch Beta Loss 6.9313 (6.6561)	Arch depth Loss -0.2143 (-0.1392)	Prec@(1,5) (62.1%, 89.5%)	
01/03 03:38:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.02256	Loss 1.3622 (1.3196)	Arch Loss -4.9994 (-4.8509)	Arch Hard Loss 2.0936 (1.8876)	Arch Beta Loss 7.0929 (6.7385)	Arch depth Loss -0.2598 (-0.1618)	Prec@(1,5) (61.8%, 89.3%)	
01/03 03:38:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 31/149] Final Prec@1 61.8040%
01/03 03:38:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.9111	Prec@(1,5) (49.2%, 80.2%)
01/03 03:38:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9230	Prec@(1,5) (49.1%, 80.1%)
01/03 03:38:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9285	Prec@(1,5) (48.8%, 79.8%)
01/03 03:38:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9238	Prec@(1,5) (49.0%, 79.7%)
01/03 03:38:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 48.9680%
01/03 03:38:38午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:38:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
01/03 03:39:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.0224	Loss 1.3985 (1.2304)	Arch Loss -5.4989 (-5.2969)	Arch Hard Loss 1.7762 (1.8891)	Arch Beta Loss 7.2751 (7.1860)	Arch depth Loss -0.3086 (-0.2847)	Prec@(1,5) (63.8%, 91.1%)	
01/03 03:39:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.0224	Loss 1.4547 (1.2664)	Arch Loss -5.3462 (-5.3844)	Arch Hard Loss 2.1092 (1.8919)	Arch Beta Loss 7.4554 (7.2763)	Arch depth Loss -0.3599 (-0.3099)	Prec@(1,5) (62.8%, 90.7%)	
01/03 03:39:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.0224	Loss 1.5620 (1.2910)	Arch Loss -5.4259 (-5.4694)	Arch Hard Loss 2.2095 (1.8971)	Arch Beta Loss 7.6354 (7.3664)	Arch depth Loss -0.4076 (-0.3347)	Prec@(1,5) (62.2%, 90.2%)	
01/03 03:40:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.0224	Loss 1.3598 (1.3049)	Arch Loss -5.8952 (-5.5573)	Arch Hard Loss 1.9031 (1.8901)	Arch Beta Loss 7.7983 (7.4475)	Arch depth Loss -0.4533 (-0.3569)	Prec@(1,5) (61.7%, 89.9%)	
01/03 03:40:05午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 32/149] Final Prec@1 61.7000%
01/03 03:40:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8934	Prec@(1,5) (50.0%, 79.4%)
01/03 03:40:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8851	Prec@(1,5) (50.1%, 79.8%)
01/03 03:40:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.9090	Prec@(1,5) (49.4%, 79.5%)
01/03 03:40:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.9114	Prec@(1,5) (49.3%, 79.7%)
01/03 03:40:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 49.2920%
01/03 03:40:17午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:40:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.2920%
01/03 03:40:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.02225	Loss 1.4589 (1.2220)	Arch Loss -5.7907 (-5.9643)	Arch Hard Loss 2.1883 (1.9259)	Arch Beta Loss 7.9790 (7.8902)	Arch depth Loss -0.5002 (-0.4776)	Prec@(1,5) (65.0%, 91.5%)	
01/03 03:41:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.02225	Loss 1.2617 (1.2520)	Arch Loss -6.5103 (-6.0741)	Arch Hard Loss 1.6502 (1.9063)	Arch Beta Loss 8.1605 (7.9804)	Arch depth Loss -0.5496 (-0.5017)	Prec@(1,5) (64.0%, 90.8%)	
01/03 03:41:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.02225	Loss 1.0815 (1.2747)	Arch Loss -6.0469 (-6.1838)	Arch Hard Loss 2.2945 (1.8870)	Arch Beta Loss 8.3415 (8.0708)	Arch depth Loss -0.5998 (-0.5263)	Prec@(1,5) (63.1%, 90.5%)	
01/03 03:41:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.02225	Loss 1.1415 (1.2847)	Arch Loss -6.3454 (-6.2652)	Arch Hard Loss 2.1585 (1.8869)	Arch Beta Loss 8.5039 (8.1521)	Arch depth Loss -0.6456 (-0.5487)	Prec@(1,5) (62.7%, 90.2%)	
01/03 03:41:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 33/149] Final Prec@1 62.7200%
01/03 03:41:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8782	Prec@(1,5) (50.6%, 80.6%)
01/03 03:41:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8762	Prec@(1,5) (50.6%, 80.4%)
01/03 03:41:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8727	Prec@(1,5) (50.2%, 80.5%)
01/03 03:41:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8733	Prec@(1,5) (50.2%, 80.4%)
01/03 03:41:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 50.2200%
01/03 03:41:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:41:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.2200%
01/03 03:42:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.02208	Loss 1.2529 (1.1999)	Arch Loss -6.9382 (-6.7417)	Arch Hard Loss 1.7500 (1.8560)	Arch Beta Loss 8.6883 (8.5977)	Arch depth Loss -0.6975 (-0.6725)	Prec@(1,5) (65.0%, 91.5%)	
01/03 03:42:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.02208	Loss 1.1297 (1.2386)	Arch Loss -7.0404 (-6.8174)	Arch Hard Loss 1.8291 (1.8713)	Arch Beta Loss 8.8696 (8.6888)	Arch depth Loss -0.7486 (-0.6980)	Prec@(1,5) (64.0%, 90.9%)	
01/03 03:43:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.02208	Loss 1.7851 (1.2591)	Arch Loss -7.2835 (-6.8890)	Arch Hard Loss 1.7681 (1.8907)	Arch Beta Loss 9.0516 (8.7797)	Arch depth Loss -0.8004 (-0.7235)	Prec@(1,5) (63.2%, 90.6%)	
01/03 03:43:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.02208	Loss 1.4124 (1.2780)	Arch Loss -7.5158 (-6.9683)	Arch Hard Loss 1.6996 (1.8932)	Arch Beta Loss 9.2153 (8.8615)	Arch depth Loss -0.8454 (-0.7465)	Prec@(1,5) (62.6%, 90.3%)	
01/03 03:43:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 34/149] Final Prec@1 62.6080%
01/03 03:43:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.9284	Prec@(1,5) (49.0%, 79.7%)
01/03 03:43:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9236	Prec@(1,5) (49.0%, 79.8%)
01/03 03:43:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9270	Prec@(1,5) (49.1%, 79.7%)
01/03 03:43:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9277	Prec@(1,5) (49.1%, 79.7%)
01/03 03:43:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 49.0760%
01/03 03:43:36午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:43:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.2200%
01/03 03:43:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.02192	Loss 1.2187 (1.2227)	Arch Loss -7.7443 (-7.4104)	Arch Hard Loss 1.6547 (1.8983)	Arch Beta Loss 9.3990 (9.3087)	Arch depth Loss -0.8973 (-0.8721)	Prec@(1,5) (64.1%, 91.0%)	
01/03 03:44:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.02192	Loss 1.3607 (1.2314)	Arch Loss -7.8721 (-7.5043)	Arch Hard Loss 1.7070 (1.8950)	Arch Beta Loss 9.5791 (9.3993)	Arch depth Loss -0.9436 (-0.8965)	Prec@(1,5) (63.5%, 91.0%)	
01/03 03:44:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.02192	Loss 1.3007 (1.2525)	Arch Loss -8.2856 (-7.5988)	Arch Hard Loss 1.4757 (1.8913)	Arch Beta Loss 9.7613 (9.4900)	Arch depth Loss -0.9919 (-0.9203)	Prec@(1,5) (63.2%, 90.5%)	
01/03 03:45:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.02192	Loss 1.4677 (1.2616)	Arch Loss -8.0112 (-7.6716)	Arch Hard Loss 1.9109 (1.8998)	Arch Beta Loss 9.9222 (9.5714)	Arch depth Loss -1.0342 (-0.9418)	Prec@(1,5) (62.9%, 90.4%)	
01/03 03:45:03午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 35/149] Final Prec@1 62.9040%
01/03 03:45:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9408	Prec@(1,5) (49.2%, 79.5%)
01/03 03:45:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9259	Prec@(1,5) (49.1%, 79.7%)
01/03 03:45:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9196	Prec@(1,5) (49.4%, 79.9%)
01/03 03:45:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9328	Prec@(1,5) (49.4%, 79.6%)
01/03 03:45:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 49.4080%
01/03 03:45:16午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[8, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:45:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.2200%
01/03 03:45:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.02175	Loss 1.2736 (1.1644)	Arch Loss -8.2731 (-8.1259)	Arch Hard Loss 1.8275 (1.8876)	Arch Beta Loss 10.1006 (10.0135)	Arch depth Loss -1.0823 (-1.0592)	Prec@(1,5) (65.5%, 91.8%)	
01/03 03:46:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.02175	Loss 1.4536 (1.2097)	Arch Loss -8.2780 (-8.1952)	Arch Hard Loss 1.9967 (1.9060)	Arch Beta Loss 10.2747 (10.1012)	Arch depth Loss -1.1266 (-1.0818)	Prec@(1,5) (64.4%, 91.2%)	
01/03 03:46:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.02175	Loss 1.3587 (1.2423)	Arch Loss -8.1572 (-8.2819)	Arch Hard Loss 2.2848 (1.9055)	Arch Beta Loss 10.4420 (10.1874)	Arch depth Loss -1.1693 (-1.1040)	Prec@(1,5) (63.6%, 90.8%)	
01/03 03:46:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.02175	Loss 1.4631 (1.2630)	Arch Loss -8.6493 (-8.3580)	Arch Hard Loss 1.9439 (1.9058)	Arch Beta Loss 10.5932 (10.2639)	Arch depth Loss -1.2058 (-1.1234)	Prec@(1,5) (63.2%, 90.5%)	
01/03 03:46:43午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 36/149] Final Prec@1 63.1600%
01/03 03:46:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.9622	Prec@(1,5) (48.3%, 78.6%)
01/03 03:46:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9556	Prec@(1,5) (48.3%, 79.0%)
01/03 03:46:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9561	Prec@(1,5) (48.3%, 79.2%)
01/03 03:46:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9604	Prec@(1,5) (48.3%, 79.1%)
01/03 03:46:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 48.2880%
01/03 03:46:55午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:46:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.2200%
01/03 03:47:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.02157	Loss 1.3656 (1.1779)	Arch Loss -8.8790 (-8.7965)	Arch Hard Loss 1.8800 (1.8814)	Arch Beta Loss 10.7590 (10.6779)	Arch depth Loss -1.2480 (-1.2278)	Prec@(1,5) (64.9%, 91.8%)	
01/03 03:47:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.02157	Loss 1.2631 (1.1995)	Arch Loss -8.7594 (-8.8911)	Arch Hard Loss 2.1606 (1.8681)	Arch Beta Loss 10.9201 (10.7592)	Arch depth Loss -1.2867 (-1.2476)	Prec@(1,5) (64.7%, 91.3%)	
01/03 03:48:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.02157	Loss 1.2334 (1.2192)	Arch Loss -9.2048 (-8.9637)	Arch Hard Loss 1.8728 (1.8757)	Arch Beta Loss 11.0777 (10.8395)	Arch depth Loss -1.3249 (-1.2672)	Prec@(1,5) (64.3%, 91.0%)	
01/03 03:48:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.02157	Loss 1.3186 (1.2381)	Arch Loss -9.4963 (-9.0157)	Arch Hard Loss 1.7201 (1.8951)	Arch Beta Loss 11.2164 (10.9108)	Arch depth Loss -1.3575 (-1.2844)	Prec@(1,5) (64.0%, 90.7%)	
01/03 03:48:22午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 37/149] Final Prec@1 64.0040%
01/03 03:48:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.9595	Prec@(1,5) (49.2%, 79.1%)
01/03 03:48:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.9417	Prec@(1,5) (49.5%, 79.3%)
01/03 03:48:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9363	Prec@(1,5) (49.5%, 79.6%)
01/03 03:48:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9309	Prec@(1,5) (49.5%, 79.6%)
01/03 03:48:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 49.4760%
01/03 03:48:34午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:48:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.2200%
01/03 03:48:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.0214	Loss 1.0754 (1.1767)	Arch Loss -9.3796 (-9.3641)	Arch Hard Loss 1.9895 (1.9305)	Arch Beta Loss 11.3691 (11.2947)	Arch depth Loss -1.3947 (-1.3767)	Prec@(1,5) (64.7%, 92.0%)	
01/03 03:49:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.0214	Loss 1.1476 (1.2016)	Arch Loss -9.1989 (-9.4749)	Arch Hard Loss 2.3198 (1.8947)	Arch Beta Loss 11.5187 (11.3696)	Arch depth Loss -1.4300 (-1.3946)	Prec@(1,5) (64.3%, 91.5%)	
01/03 03:49:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.0214	Loss 1.4057 (1.2280)	Arch Loss -9.9446 (-9.5458)	Arch Hard Loss 1.7189 (1.8980)	Arch Beta Loss 11.6635 (11.4437)	Arch depth Loss -1.4625 (-1.4121)	Prec@(1,5) (63.5%, 91.3%)	
01/03 03:50:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.0214	Loss 1.0733 (1.2351)	Arch Loss -10.0925 (-9.6056)	Arch Hard Loss 1.6984 (1.9038)	Arch Beta Loss 11.7909 (11.5095)	Arch depth Loss -1.4911 (-1.4270)	Prec@(1,5) (63.4%, 91.1%)	
01/03 03:50:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 38/149] Final Prec@1 63.3960%
01/03 03:50:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9007	Prec@(1,5) (50.6%, 79.9%)
01/03 03:50:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.8610	Prec@(1,5) (50.9%, 80.6%)
01/03 03:50:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.8782	Prec@(1,5) (50.5%, 80.5%)
01/03 03:50:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.8873	Prec@(1,5) (50.4%, 80.4%)
01/03 03:50:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 50.4440%
01/03 03:50:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
01/03 03:50:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4440%
01/03 03:50:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.02121	Loss 1.1521 (1.1678)	Arch Loss -10.2814 (-9.9686)	Arch Hard Loss 1.6499 (1.8942)	Arch Beta Loss 11.9313 (11.8628)	Arch depth Loss -1.5219 (-1.5072)	Prec@(1,5) (65.6%, 92.4%)	
01/03 03:50:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.02121	Loss 1.1981 (1.1979)	Arch Loss -10.5133 (-10.0276)	Arch Hard Loss 1.5529 (1.9038)	Arch Beta Loss 12.0661 (11.9314)	Arch depth Loss -1.5494 (-1.5216)	Prec@(1,5) (64.7%, 91.7%)	
01/03 03:51:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.02121	Loss 0.9704 (1.2064)	Arch Loss -10.3764 (-10.1042)	Arch Hard Loss 1.8214 (1.8943)	Arch Beta Loss 12.1979 (11.9985)	Arch depth Loss -1.5779 (-1.5357)	Prec@(1,5) (64.3%, 91.5%)	
01/03 03:51:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.02121	Loss 1.3906 (1.2206)	Arch Loss -10.0131 (-10.1589)	Arch Hard Loss 2.2994 (1.8990)	Arch Beta Loss 12.3125 (12.0579)	Arch depth Loss -1.6014 (-1.5481)	Prec@(1,5) (63.9%, 91.3%)	
01/03 03:51:40午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 39/149] Final Prec@1 63.8800%
01/03 03:51:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9124	Prec@(1,5) (50.3%, 80.2%)
01/03 03:51:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.8944	Prec@(1,5) (50.4%, 80.4%)
01/03 03:51:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.8812	Prec@(1,5) (50.6%, 80.6%)
01/03 03:51:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.9014	Prec@(1,5) (50.3%, 80.2%)
01/03 03:51:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 50.3160%
01/03 03:51:53午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 03:51:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4440%
01/03 03:52:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.02103	Loss 1.2371 (1.1506)	Arch Loss -10.5830 (-10.4688)	Arch Hard Loss 1.8559 (1.9081)	Arch Beta Loss 12.4389 (12.3769)	Arch depth Loss -1.6286 (-1.6160)	Prec@(1,5) (65.9%, 91.9%)	
01/03 03:52:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.02103	Loss 1.2042 (1.1483)	Arch Loss -10.8223 (-10.5390)	Arch Hard Loss 1.7397 (1.9000)	Arch Beta Loss 12.5620 (12.4390)	Arch depth Loss -1.6530 (-1.6287)	Prec@(1,5) (65.7%, 92.0%)	
01/03 03:53:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.02103	Loss 1.5464 (1.1829)	Arch Loss -10.5756 (-10.6065)	Arch Hard Loss 2.1058 (1.8937)	Arch Beta Loss 12.6814 (12.5002)	Arch depth Loss -1.6753 (-1.6406)	Prec@(1,5) (64.9%, 91.5%)	
01/03 03:53:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.02103	Loss 1.5252 (1.2013)	Arch Loss -10.6526 (-10.6615)	Arch Hard Loss 2.1323 (1.8925)	Arch Beta Loss 12.7848 (12.5540)	Arch depth Loss -1.6909 (-1.6504)	Prec@(1,5) (64.6%, 91.2%)	
01/03 03:53:20午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 40/149] Final Prec@1 64.5480%
01/03 03:53:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.8968	Prec@(1,5) (50.5%, 80.0%)
01/03 03:53:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.8865	Prec@(1,5) (50.8%, 80.2%)
01/03 03:53:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.8925	Prec@(1,5) (50.5%, 80.1%)
01/03 03:53:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9029	Prec@(1,5) (50.3%, 79.9%)
01/03 03:53:32午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 50.2800%
01/03 03:53:32午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 03:53:32午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4440%
01/03 03:53:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.02084	Loss 1.2073 (1.1648)	Arch Loss -10.9326 (-10.8905)	Arch Hard Loss 1.9666 (1.9530)	Arch Beta Loss 12.8993 (12.8435)	Arch depth Loss -1.7114 (-1.7023)	Prec@(1,5) (66.4%, 91.5%)	
01/03 03:54:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.02084	Loss 1.1601 (1.1579)	Arch Loss -11.0110 (-10.9812)	Arch Hard Loss 1.9969 (1.9178)	Arch Beta Loss 13.0079 (12.8990)	Arch depth Loss -1.7272 (-1.7106)	Prec@(1,5) (65.9%, 91.8%)	
01/03 03:54:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.02084	Loss 1.2027 (1.1880)	Arch Loss -11.0118 (-11.0583)	Arch Hard Loss 2.1040 (1.8953)	Arch Beta Loss 13.1158 (12.9536)	Arch depth Loss -1.7417 (-1.7187)	Prec@(1,5) (65.2%, 91.4%)	
01/03 03:54:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.02084	Loss 0.9614 (1.1972)	Arch Loss -11.2570 (-11.1138)	Arch Hard Loss 1.9534 (1.8884)	Arch Beta Loss 13.2104 (13.0022)	Arch depth Loss -1.7542 (-1.7254)	Prec@(1,5) (64.8%, 91.3%)	
01/03 03:54:59午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 41/149] Final Prec@1 64.7880%
01/03 03:55:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.8627	Prec@(1,5) (51.0%, 81.1%)
01/03 03:55:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.8824	Prec@(1,5) (50.2%, 80.4%)
01/03 03:55:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.9000	Prec@(1,5) (50.1%, 80.0%)
01/03 03:55:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9053	Prec@(1,5) (50.0%, 79.9%)
01/03 03:55:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 50.0440%
01/03 03:55:12午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 03:55:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4440%
01/03 03:55:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.02065	Loss 1.0088 (1.1145)	Arch Loss -11.5042 (-11.3748)	Arch Hard Loss 1.8087 (1.8879)	Arch Beta Loss 13.3129 (13.2627)	Arch depth Loss -1.7658 (-1.7603)	Prec@(1,5) (67.2%, 92.5%)	
01/03 03:55:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.02065	Loss 0.9718 (1.1370)	Arch Loss -10.9007 (-11.4077)	Arch Hard Loss 2.5124 (1.9055)	Arch Beta Loss 13.4131 (13.3133)	Arch depth Loss -1.7784 (-1.7664)	Prec@(1,5) (66.7%, 92.0%)	
01/03 03:56:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.02065	Loss 1.0182 (1.1601)	Arch Loss -11.4846 (-11.4507)	Arch Hard Loss 2.0260 (1.9122)	Arch Beta Loss 13.5105 (13.3629)	Arch depth Loss -1.7899 (-1.7724)	Prec@(1,5) (65.9%, 91.7%)	
01/03 03:56:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.02065	Loss 1.1912 (1.1744)	Arch Loss -11.8557 (-11.5020)	Arch Hard Loss 1.7405 (1.9050)	Arch Beta Loss 13.5961 (13.4070)	Arch depth Loss -1.7969 (-1.7773)	Prec@(1,5) (65.3%, 91.6%)	
01/03 03:56:38午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 42/149] Final Prec@1 65.3160%
01/03 03:56:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.9463	Prec@(1,5) (49.3%, 80.1%)
01/03 03:56:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.9291	Prec@(1,5) (49.8%, 80.2%)
01/03 03:56:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9470	Prec@(1,5) (49.7%, 79.7%)
01/03 03:56:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.9502	Prec@(1,5) (49.6%, 79.6%)
01/03 03:56:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 49.5600%
01/03 03:56:51午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 03:56:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4440%
01/03 03:57:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.02045	Loss 0.9696 (1.1054)	Arch Loss -11.7973 (-11.7852)	Arch Hard Loss 1.8921 (1.8589)	Arch Beta Loss 13.6894 (13.6440)	Arch depth Loss -1.8042 (-1.8008)	Prec@(1,5) (67.0%, 92.9%)	
01/03 03:57:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.02045	Loss 1.3774 (1.1237)	Arch Loss -12.0832 (-11.8107)	Arch Hard Loss 1.6961 (1.8790)	Arch Beta Loss 13.7793 (13.6897)	Arch depth Loss -1.8099 (-1.8041)	Prec@(1,5) (66.6%, 92.4%)	
01/03 03:57:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.02045	Loss 1.2606 (1.1526)	Arch Loss -12.0255 (-11.8523)	Arch Hard Loss 1.8405 (1.8821)	Arch Beta Loss 13.8660 (13.7344)	Arch depth Loss -1.8144 (-1.8068)	Prec@(1,5) (65.9%, 92.0%)	
01/03 03:58:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.02045	Loss 1.2146 (1.1598)	Arch Loss -12.0696 (-11.8850)	Arch Hard Loss 1.8742 (1.8890)	Arch Beta Loss 13.9438 (13.7739)	Arch depth Loss -1.8162 (-1.8089)	Prec@(1,5) (65.7%, 91.8%)	
01/03 03:58:18午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 43/149] Final Prec@1 65.7480%
01/03 03:58:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.9254	Prec@(1,5) (50.2%, 79.2%)
01/03 03:58:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.9198	Prec@(1,5) (50.0%, 79.6%)
01/03 03:58:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9093	Prec@(1,5) (50.2%, 79.7%)
01/03 03:58:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9153	Prec@(1,5) (50.0%, 79.7%)
01/03 03:58:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 49.9680%
01/03 03:58:30午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 03:58:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4440%
01/03 03:58:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.02026	Loss 1.0845 (1.1144)	Arch Loss -11.8211 (-12.1042)	Arch Hard Loss 2.2084 (1.8835)	Arch Beta Loss 14.0295 (13.9877)	Arch depth Loss -1.8190 (-1.8180)	Prec@(1,5) (67.1%, 92.2%)	
01/03 03:59:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.02026	Loss 1.1263 (1.1361)	Arch Loss -12.0795 (-12.1419)	Arch Hard Loss 2.0320 (1.8872)	Arch Beta Loss 14.1115 (14.0292)	Arch depth Loss -1.8238 (-1.8199)	Prec@(1,5) (66.5%, 92.0%)	
01/03 03:59:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.02026	Loss 1.2444 (1.1457)	Arch Loss -12.6122 (-12.1846)	Arch Hard Loss 1.5782 (1.8853)	Arch Beta Loss 14.1904 (14.0699)	Arch depth Loss -1.8238 (-1.8211)	Prec@(1,5) (66.3%, 91.8%)	
01/03 03:59:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.02026	Loss 1.4960 (1.1590)	Arch Loss -12.3193 (-12.2162)	Arch Hard Loss 1.9407 (1.8896)	Arch Beta Loss 14.2600 (14.1058)	Arch depth Loss -1.8248 (-1.8217)	Prec@(1,5) (65.8%, 91.6%)	
01/03 03:59:57午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 44/149] Final Prec@1 65.7680%
01/03 04:00:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.9312	Prec@(1,5) (50.9%, 80.3%)
01/03 04:00:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.9079	Prec@(1,5) (50.9%, 81.0%)
01/03 04:00:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.9031	Prec@(1,5) (51.0%, 80.8%)
01/03 04:00:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.9077	Prec@(1,5) (50.8%, 80.6%)
01/03 04:00:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 50.8280%
01/03 04:00:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:00:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8280%
01/03 04:00:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.02005	Loss 1.0798 (1.0898)	Arch Loss -12.3365 (-12.3682)	Arch Hard Loss 1.9981 (1.9300)	Arch Beta Loss 14.3345 (14.2983)	Arch depth Loss -1.8224 (-1.8246)	Prec@(1,5) (67.7%, 93.1%)	
01/03 04:00:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.02005	Loss 1.1722 (1.1120)	Arch Loss -12.7249 (-12.4167)	Arch Hard Loss 1.6817 (1.9180)	Arch Beta Loss 14.4067 (14.3346)	Arch depth Loss -1.8164 (-1.8221)	Prec@(1,5) (66.8%, 92.8%)	
01/03 04:01:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.02005	Loss 1.2074 (1.1232)	Arch Loss -12.7912 (-12.4630)	Arch Hard Loss 1.6867 (1.9077)	Arch Beta Loss 14.4779 (14.3707)	Arch depth Loss -1.8086 (-1.8190)	Prec@(1,5) (66.8%, 92.6%)	
01/03 04:01:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.02005	Loss 1.3078 (1.1420)	Arch Loss -13.0760 (-12.5003)	Arch Hard Loss 1.4666 (1.9028)	Arch Beta Loss 14.5425 (14.4030)	Arch depth Loss -1.8026 (-1.8161)	Prec@(1,5) (66.4%, 92.2%)	
01/03 04:01:37午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 45/149] Final Prec@1 66.3400%
01/03 04:01:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.9948	Prec@(1,5) (49.4%, 79.0%)
01/03 04:01:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.0041	Prec@(1,5) (49.0%, 78.9%)
01/03 04:01:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.0008	Prec@(1,5) (49.0%, 78.8%)
01/03 04:01:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9954	Prec@(1,5) (49.1%, 79.0%)
01/03 04:01:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 49.0520%
01/03 04:01:49午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:01:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8280%
01/03 04:02:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.01985	Loss 1.1379 (1.0771)	Arch Loss -12.5439 (-12.6742)	Arch Hard Loss 2.0670 (1.9034)	Arch Beta Loss 14.6110 (14.5777)	Arch depth Loss -1.7952 (-1.7984)	Prec@(1,5) (67.7%, 93.2%)	
01/03 04:02:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.01985	Loss 1.0938 (1.1019)	Arch Loss -12.8976 (-12.6987)	Arch Hard Loss 1.7791 (1.9124)	Arch Beta Loss 14.6768 (14.6110)	Arch depth Loss -1.7865 (-1.7946)	Prec@(1,5) (67.0%, 92.6%)	
01/03 04:02:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.01985	Loss 0.8918 (1.1123)	Arch Loss -12.5342 (-12.7309)	Arch Hard Loss 2.2082 (1.9130)	Arch Beta Loss 14.7423 (14.6439)	Arch depth Loss -1.7782 (-1.7903)	Prec@(1,5) (66.9%, 92.5%)	
01/03 04:03:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.01985	Loss 1.2825 (1.1359)	Arch Loss -12.5497 (-12.7630)	Arch Hard Loss 2.2507 (1.9104)	Arch Beta Loss 14.8004 (14.6734)	Arch depth Loss -1.7691 (-1.7866)	Prec@(1,5) (66.3%, 92.2%)	
01/03 04:03:16午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 46/149] Final Prec@1 66.2920%
01/03 04:03:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.9545	Prec@(1,5) (49.2%, 78.8%)
01/03 04:03:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.9380	Prec@(1,5) (49.7%, 79.2%)
01/03 04:03:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.9335	Prec@(1,5) (50.0%, 79.3%)
01/03 04:03:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.9368	Prec@(1,5) (50.0%, 79.4%)
01/03 04:03:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 50.0040%
01/03 04:03:28午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:03:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8280%
01/03 04:03:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.01964	Loss 1.2982 (1.0880)	Arch Loss -13.3120 (-12.9438)	Arch Hard Loss 1.5514 (1.8891)	Arch Beta Loss 14.8634 (14.8329)	Arch depth Loss -1.7566 (-1.7625)	Prec@(1,5) (67.4%, 93.2%)	
01/03 04:04:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.01964	Loss 1.5724 (1.0842)	Arch Loss -13.7212 (-12.9484)	Arch Hard Loss 1.2021 (1.9148)	Arch Beta Loss 14.9232 (14.8632)	Arch depth Loss -1.7441 (-1.7562)	Prec@(1,5) (67.9%, 92.9%)	
01/03 04:04:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.01964	Loss 1.3453 (1.0984)	Arch Loss -12.8869 (-12.9891)	Arch Hard Loss 2.0962 (1.9043)	Arch Beta Loss 14.9831 (14.8933)	Arch depth Loss -1.7330 (-1.7504)	Prec@(1,5) (67.3%, 92.9%)	
01/03 04:04:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.01964	Loss 1.0919 (1.1179)	Arch Loss -13.2387 (-13.0145)	Arch Hard Loss 1.7961 (1.9056)	Arch Beta Loss 15.0348 (14.9202)	Arch depth Loss -1.7183 (-1.7447)	Prec@(1,5) (66.8%, 92.5%)	
01/03 04:04:55午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 47/149] Final Prec@1 66.8040%
01/03 04:04:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.9119	Prec@(1,5) (50.5%, 80.0%)
01/03 04:05:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.9231	Prec@(1,5) (50.2%, 79.9%)
01/03 04:05:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.9268	Prec@(1,5) (50.2%, 80.1%)
01/03 04:05:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.9237	Prec@(1,5) (50.3%, 80.1%)
01/03 04:05:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 50.3320%
01/03 04:05:08午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:05:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8280%
01/03 04:05:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.01943	Loss 1.1604 (1.0486)	Arch Loss -13.2533 (-13.1489)	Arch Hard Loss 1.8392 (1.9152)	Arch Beta Loss 15.0925 (15.0641)	Arch depth Loss -1.6994 (-1.7094)	Prec@(1,5) (69.6%, 93.5%)	
01/03 04:05:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.01943	Loss 1.3438 (1.0482)	Arch Loss -13.3693 (-13.1685)	Arch Hard Loss 1.7773 (1.9235)	Arch Beta Loss 15.1466 (15.0921)	Arch depth Loss -1.6848 (-1.7009)	Prec@(1,5) (69.0%, 93.4%)	
01/03 04:06:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.01943	Loss 0.8922 (1.0746)	Arch Loss -13.2311 (-13.2008)	Arch Hard Loss 1.9685 (1.9183)	Arch Beta Loss 15.1997 (15.1192)	Arch depth Loss -1.6663 (-1.6924)	Prec@(1,5) (68.1%, 93.1%)	
01/03 04:06:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.01943	Loss 1.2128 (1.1035)	Arch Loss -13.5268 (-13.2312)	Arch Hard Loss 1.7199 (1.9120)	Arch Beta Loss 15.2467 (15.1432)	Arch depth Loss -1.6481 (-1.6842)	Prec@(1,5) (67.2%, 92.7%)	
01/03 04:06:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 48/149] Final Prec@1 67.2400%
01/03 04:06:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.9283	Prec@(1,5) (49.8%, 79.7%)
01/03 04:06:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.9228	Prec@(1,5) (50.0%, 79.7%)
01/03 04:06:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.9308	Prec@(1,5) (50.2%, 79.7%)
01/03 04:06:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.9269	Prec@(1,5) (50.5%, 79.9%)
01/03 04:06:47午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 50.4840%
01/03 04:06:47午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:06:47午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8280%
01/03 04:07:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.01922	Loss 1.2404 (1.0205)	Arch Loss -13.1341 (-13.3838)	Arch Hard Loss 2.1648 (1.8896)	Arch Beta Loss 15.2988 (15.2734)	Arch depth Loss -1.6288 (-1.6397)	Prec@(1,5) (69.1%, 93.7%)	
01/03 04:07:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.01922	Loss 1.2330 (1.0324)	Arch Loss -12.7309 (-13.4059)	Arch Hard Loss 2.6185 (1.8931)	Arch Beta Loss 15.3494 (15.2989)	Arch depth Loss -1.6120 (-1.6300)	Prec@(1,5) (69.0%, 93.6%)	
01/03 04:07:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.01922	Loss 1.1515 (1.0615)	Arch Loss -13.3164 (-13.4281)	Arch Hard Loss 2.0807 (1.8958)	Arch Beta Loss 15.3971 (15.3239)	Arch depth Loss -1.5861 (-1.6195)	Prec@(1,5) (68.2%, 92.9%)	
01/03 04:08:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.01922	Loss 1.4253 (1.0792)	Arch Loss -13.1694 (-13.4506)	Arch Hard Loss 2.2711 (1.8953)	Arch Beta Loss 15.4404 (15.3459)	Arch depth Loss -1.5581 (-1.6086)	Prec@(1,5) (67.7%, 92.8%)	
01/03 04:08:14午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 49/149] Final Prec@1 67.6920%
01/03 04:08:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.9429	Prec@(1,5) (50.1%, 79.7%)
01/03 04:08:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.9667	Prec@(1,5) (49.8%, 79.4%)
01/03 04:08:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.9574	Prec@(1,5) (49.7%, 79.5%)
01/03 04:08:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.9610	Prec@(1,5) (49.7%, 79.4%)
01/03 04:08:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 49.6800%
01/03 04:08:27午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:08:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8280%
01/03 04:08:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][100/390]	Step 19650	lr 0.019	Loss 0.7519 (0.9837)	Arch Loss -13.6037 (-13.5755)	Arch Hard Loss 1.8847 (1.8898)	Arch Beta Loss 15.4885 (15.4653)	Arch depth Loss -1.5309 (-1.5449)	Prec@(1,5) (70.1%, 93.8%)	
01/03 04:09:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][200/390]	Step 19750	lr 0.019	Loss 0.9326 (1.0249)	Arch Loss -13.8526 (-13.5908)	Arch Hard Loss 1.6803 (1.8972)	Arch Beta Loss 15.5329 (15.4880)	Arch depth Loss -1.5048 (-1.5310)	Prec@(1,5) (68.9%, 93.3%)	
01/03 04:09:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][300/390]	Step 19850	lr 0.019	Loss 1.1442 (1.0558)	Arch Loss -13.9339 (-13.6044)	Arch Hard Loss 1.6434 (1.9060)	Arch Beta Loss 15.5773 (15.5104)	Arch depth Loss -1.4766 (-1.5174)	Prec@(1,5) (68.2%, 92.9%)	
01/03 04:09:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][390/390]	Step 19940	lr 0.019	Loss 1.4602 (1.0765)	Arch Loss -13.9874 (-13.6219)	Arch Hard Loss 1.6284 (1.9083)	Arch Beta Loss 15.6158 (15.5303)	Arch depth Loss -1.4513 (-1.5051)	Prec@(1,5) (67.6%, 92.7%)	
01/03 04:09:53午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 50/149] Final Prec@1 67.6000%
01/03 04:09:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][100/391]	Step 19941	Loss 1.8444	Prec@(1,5) (51.7%, 81.1%)
01/03 04:10:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][200/391]	Step 19941	Loss 1.8734	Prec@(1,5) (51.5%, 80.7%)
01/03 04:10:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][300/391]	Step 19941	Loss 1.8703	Prec@(1,5) (51.7%, 80.8%)
01/03 04:10:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][390/391]	Step 19941	Loss 1.8695	Prec@(1,5) (51.8%, 80.8%)
01/03 04:10:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 51.7760%
01/03 04:10:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:10:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:10:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][100/390]	Step 20041	lr 0.01878	Loss 1.1023 (0.9837)	Arch Loss -13.9099 (-13.7428)	Arch Hard Loss 1.7491 (1.8953)	Arch Beta Loss 15.6590 (15.6381)	Arch depth Loss -1.4277 (-1.4402)	Prec@(1,5) (69.9%, 94.4%)	
01/03 04:10:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][200/390]	Step 20141	lr 0.01878	Loss 1.0969 (1.0106)	Arch Loss -13.1568 (-13.7488)	Arch Hard Loss 2.5444 (1.9104)	Arch Beta Loss 15.7012 (15.6592)	Arch depth Loss -1.3953 (-1.4258)	Prec@(1,5) (69.4%, 94.0%)	
01/03 04:11:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][300/390]	Step 20241	lr 0.01878	Loss 1.2597 (1.0447)	Arch Loss -13.8249 (-13.7638)	Arch Hard Loss 1.9181 (1.9163)	Arch Beta Loss 15.7430 (15.6802)	Arch depth Loss -1.3672 (-1.4111)	Prec@(1,5) (68.5%, 93.6%)	
01/03 04:11:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][390/390]	Step 20331	lr 0.01878	Loss 0.8796 (1.0586)	Arch Loss -14.0708 (-13.7894)	Arch Hard Loss 1.7106 (1.9097)	Arch Beta Loss 15.7814 (15.6992)	Arch depth Loss -1.3435 (-1.3983)	Prec@(1,5) (68.1%, 93.4%)	
01/03 04:11:33午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 51/149] Final Prec@1 68.0920%
01/03 04:11:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][100/391]	Step 20332	Loss 1.9431	Prec@(1,5) (49.8%, 80.0%)
01/03 04:11:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][200/391]	Step 20332	Loss 1.9766	Prec@(1,5) (49.8%, 79.9%)
01/03 04:11:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][300/391]	Step 20332	Loss 1.9644	Prec@(1,5) (50.1%, 80.2%)
01/03 04:11:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][390/391]	Step 20332	Loss 1.9618	Prec@(1,5) (50.1%, 80.2%)
01/03 04:11:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 50.0960%
01/03 04:11:45午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:11:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:12:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][100/390]	Step 20432	lr 0.01856	Loss 0.9618 (0.9828)	Arch Loss -14.2027 (-13.9371)	Arch Hard Loss 1.6189 (1.8653)	Arch Beta Loss 15.8217 (15.8024)	Arch depth Loss -1.3109 (-1.3267)	Prec@(1,5) (69.8%, 94.0%)	
01/03 04:12:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][200/390]	Step 20532	lr 0.01856	Loss 0.7454 (1.0046)	Arch Loss -13.6966 (-13.9147)	Arch Hard Loss 2.1648 (1.9075)	Arch Beta Loss 15.8614 (15.8222)	Arch depth Loss -1.2759 (-1.3093)	Prec@(1,5) (69.5%, 93.7%)	
01/03 04:12:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][300/390]	Step 20632	lr 0.01856	Loss 1.0081 (1.0271)	Arch Loss -14.0431 (-13.9207)	Arch Hard Loss 1.8578 (1.9213)	Arch Beta Loss 15.9009 (15.8420)	Arch depth Loss -1.2409 (-1.2918)	Prec@(1,5) (68.9%, 93.4%)	
01/03 04:13:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][390/390]	Step 20722	lr 0.01856	Loss 0.7673 (1.0414)	Arch Loss -14.3407 (-13.9372)	Arch Hard Loss 1.5954 (1.9224)	Arch Beta Loss 15.9361 (15.8596)	Arch depth Loss -1.2095 (-1.2763)	Prec@(1,5) (68.6%, 93.2%)	
01/03 04:13:13午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 52/149] Final Prec@1 68.5720%
01/03 04:13:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][100/391]	Step 20723	Loss 1.9688	Prec@(1,5) (49.8%, 79.4%)
01/03 04:13:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][200/391]	Step 20723	Loss 1.9753	Prec@(1,5) (49.5%, 79.5%)
01/03 04:13:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][300/391]	Step 20723	Loss 1.9733	Prec@(1,5) (49.7%, 79.7%)
01/03 04:13:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][390/391]	Step 20723	Loss 1.9566	Prec@(1,5) (49.9%, 79.8%)
01/03 04:13:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 49.9240%
01/03 04:13:25午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:13:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:13:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][100/390]	Step 20823	lr 0.01834	Loss 1.2187 (0.9388)	Arch Loss -14.3806 (-14.0604)	Arch Hard Loss 1.5949 (1.8960)	Arch Beta Loss 15.9754 (15.9564)	Arch depth Loss -1.1773 (-1.1929)	Prec@(1,5) (71.6%, 94.6%)	
01/03 04:14:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][200/390]	Step 20923	lr 0.01834	Loss 1.2789 (0.9910)	Arch Loss -14.0206 (-14.0462)	Arch Hard Loss 1.9917 (1.9292)	Arch Beta Loss 16.0124 (15.9753)	Arch depth Loss -1.1385 (-1.1753)	Prec@(1,5) (70.5%, 93.9%)	
01/03 04:14:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][300/390]	Step 21023	lr 0.01834	Loss 0.9384 (1.0182)	Arch Loss -14.1607 (-14.0558)	Arch Hard Loss 1.8870 (1.9378)	Arch Beta Loss 16.0477 (15.9936)	Arch depth Loss -1.1038 (-1.1578)	Prec@(1,5) (69.7%, 93.5%)	
01/03 04:14:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][390/390]	Step 21113	lr 0.01834	Loss 0.9607 (1.0393)	Arch Loss -14.0631 (-14.0788)	Arch Hard Loss 2.0173 (1.9311)	Arch Beta Loss 16.0804 (16.0099)	Arch depth Loss -1.0715 (-1.1418)	Prec@(1,5) (69.0%, 93.2%)	
01/03 04:14:53午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 53/149] Final Prec@1 68.9840%
01/03 04:14:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][100/391]	Step 21114	Loss 2.0184	Prec@(1,5) (49.9%, 79.7%)
01/03 04:14:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][200/391]	Step 21114	Loss 2.0187	Prec@(1,5) (50.1%, 79.8%)
01/03 04:15:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][300/391]	Step 21114	Loss 2.0270	Prec@(1,5) (49.7%, 79.7%)
01/03 04:15:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][390/391]	Step 21114	Loss 2.0342	Prec@(1,5) (49.7%, 79.4%)
01/03 04:15:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 49.7080%
01/03 04:15:05午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:15:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:15:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][100/390]	Step 21214	lr 0.01811	Loss 0.8774 (0.9294)	Arch Loss -14.1761 (-14.1611)	Arch Hard Loss 1.9396 (1.9371)	Arch Beta Loss 16.1157 (16.0982)	Arch depth Loss -1.0298 (-1.0494)	Prec@(1,5) (72.0%, 94.9%)	
01/03 04:15:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][200/390]	Step 21314	lr 0.01811	Loss 0.9733 (0.9559)	Arch Loss -14.2420 (-14.2068)	Arch Hard Loss 1.9090 (1.9091)	Arch Beta Loss 16.1510 (16.1160)	Arch depth Loss -0.9897 (-1.0301)	Prec@(1,5) (71.2%, 94.3%)	
01/03 04:16:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][300/390]	Step 21414	lr 0.01811	Loss 0.9785 (0.9788)	Arch Loss -14.7562 (-14.2144)	Arch Hard Loss 1.4285 (1.9189)	Arch Beta Loss 16.1847 (16.1333)	Arch depth Loss -0.9485 (-1.0097)	Prec@(1,5) (70.5%, 94.1%)	
01/03 04:16:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][390/390]	Step 21504	lr 0.01811	Loss 0.8686 (0.9971)	Arch Loss -13.7626 (-14.2300)	Arch Hard Loss 2.4524 (1.9188)	Arch Beta Loss 16.2149 (16.1487)	Arch depth Loss -0.9140 (-0.9913)	Prec@(1,5) (70.0%, 93.9%)	
01/03 04:16:32午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 54/149] Final Prec@1 70.0360%
01/03 04:16:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][100/391]	Step 21505	Loss 2.1442	Prec@(1,5) (47.4%, 77.8%)
01/03 04:16:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][200/391]	Step 21505	Loss 2.1495	Prec@(1,5) (47.4%, 78.1%)
01/03 04:16:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][300/391]	Step 21505	Loss 2.1555	Prec@(1,5) (47.0%, 77.8%)
01/03 04:16:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][390/391]	Step 21505	Loss 2.1516	Prec@(1,5) (46.9%, 77.7%)
01/03 04:16:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 46.9200%
01/03 04:16:44午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:16:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:17:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][100/390]	Step 21605	lr 0.01788	Loss 1.0674 (0.9586)	Arch Loss -14.2794 (-14.3214)	Arch Hard Loss 1.9683 (1.9104)	Arch Beta Loss 16.2477 (16.2318)	Arch depth Loss -0.8665 (-0.8892)	Prec@(1,5) (71.0%, 94.3%)	
01/03 04:17:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][200/390]	Step 21705	lr 0.01788	Loss 0.9041 (0.9744)	Arch Loss -14.4855 (-14.3045)	Arch Hard Loss 1.7913 (1.9427)	Arch Beta Loss 16.2768 (16.2473)	Arch depth Loss -0.8308 (-0.8685)	Prec@(1,5) (70.5%, 94.2%)	
01/03 04:17:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][300/390]	Step 21805	lr 0.01788	Loss 1.1364 (0.9986)	Arch Loss -14.2516 (-14.3291)	Arch Hard Loss 2.0552 (1.9330)	Arch Beta Loss 16.3067 (16.2621)	Arch depth Loss -0.7957 (-0.8504)	Prec@(1,5) (69.9%, 94.0%)	
01/03 04:18:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][390/390]	Step 21895	lr 0.01788	Loss 1.1936 (1.0192)	Arch Loss -14.7498 (-14.3538)	Arch Hard Loss 1.5841 (1.9217)	Arch Beta Loss 16.3339 (16.2755)	Arch depth Loss -0.7652 (-0.8344)	Prec@(1,5) (69.4%, 93.7%)	
01/03 04:18:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 55/149] Final Prec@1 69.3720%
01/03 04:18:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][100/391]	Step 21896	Loss 2.2169	Prec@(1,5) (45.8%, 76.5%)
01/03 04:18:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][200/391]	Step 21896	Loss 2.2033	Prec@(1,5) (46.3%, 76.3%)
01/03 04:18:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][300/391]	Step 21896	Loss 2.2059	Prec@(1,5) (46.0%, 76.3%)
01/03 04:18:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][390/391]	Step 21896	Loss 2.1964	Prec@(1,5) (46.3%, 76.3%)
01/03 04:18:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 46.3240%
01/03 04:18:24午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:18:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:18:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][100/390]	Step 21996	lr 0.01765	Loss 1.2312 (0.9057)	Arch Loss -14.6801 (-14.4557)	Arch Hard Loss 1.6837 (1.8934)	Arch Beta Loss 16.3638 (16.3491)	Arch depth Loss -0.7262 (-0.7442)	Prec@(1,5) (72.4%, 94.9%)	
01/03 04:19:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][200/390]	Step 22096	lr 0.01765	Loss 0.7937 (0.9317)	Arch Loss -14.3601 (-14.4507)	Arch Hard Loss 2.0324 (1.9130)	Arch Beta Loss 16.3925 (16.3637)	Arch depth Loss -0.6803 (-0.7235)	Prec@(1,5) (71.8%, 94.5%)	
01/03 04:19:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][300/390]	Step 22196	lr 0.01765	Loss 1.0953 (0.9607)	Arch Loss -14.1574 (-14.4731)	Arch Hard Loss 2.2619 (1.9047)	Arch Beta Loss 16.4193 (16.3779)	Arch depth Loss -0.6361 (-0.7011)	Prec@(1,5) (71.1%, 94.2%)	
01/03 04:19:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][390/390]	Step 22286	lr 0.01765	Loss 1.0903 (0.9831)	Arch Loss -14.6250 (-14.4792)	Arch Hard Loss 1.8183 (1.9111)	Arch Beta Loss 16.4433 (16.3903)	Arch depth Loss -0.6008 (-0.6817)	Prec@(1,5) (70.4%, 94.0%)	
01/03 04:19:51午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 56/149] Final Prec@1 70.4320%
01/03 04:19:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][100/391]	Step 22287	Loss 2.2230	Prec@(1,5) (46.5%, 75.5%)
01/03 04:19:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][200/391]	Step 22287	Loss 2.2133	Prec@(1,5) (46.8%, 75.6%)
01/03 04:20:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][300/391]	Step 22287	Loss 2.2108	Prec@(1,5) (46.6%, 75.8%)
01/03 04:20:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][390/391]	Step 22287	Loss 2.2084	Prec@(1,5) (46.6%, 75.8%)
01/03 04:20:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 46.5640%
01/03 04:20:04午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:20:04午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:20:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][100/390]	Step 22387	lr 0.01742	Loss 0.9461 (0.9028)	Arch Loss -13.9229 (-14.6085)	Arch Hard Loss 2.5481 (1.8487)	Arch Beta Loss 16.4709 (16.4572)	Arch depth Loss -0.5592 (-0.5811)	Prec@(1,5) (72.9%, 95.4%)	
01/03 04:20:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][200/390]	Step 22487	lr 0.01742	Loss 1.1054 (0.9276)	Arch Loss -14.6780 (-14.5662)	Arch Hard Loss 1.8180 (1.9040)	Arch Beta Loss 16.4960 (16.4703)	Arch depth Loss -0.5143 (-0.5594)	Prec@(1,5) (72.3%, 94.7%)	
01/03 04:21:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][300/390]	Step 22587	lr 0.01742	Loss 1.0477 (0.9540)	Arch Loss -14.5290 (-14.5701)	Arch Hard Loss 1.9919 (1.9130)	Arch Beta Loss 16.5209 (16.4831)	Arch depth Loss -0.4701 (-0.5368)	Prec@(1,5) (71.4%, 94.4%)	
01/03 04:21:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][390/390]	Step 22677	lr 0.01742	Loss 1.2056 (0.9677)	Arch Loss -14.5031 (-14.5758)	Arch Hard Loss 2.0398 (1.9186)	Arch Beta Loss 16.5428 (16.4944)	Arch depth Loss -0.4291 (-0.5167)	Prec@(1,5) (71.0%, 94.3%)	
01/03 04:21:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 57/149] Final Prec@1 71.0320%
01/03 04:21:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][100/391]	Step 22678	Loss 2.3637	Prec@(1,5) (44.0%, 75.4%)
01/03 04:21:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][200/391]	Step 22678	Loss 2.3969	Prec@(1,5) (43.9%, 74.8%)
01/03 04:21:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][300/391]	Step 22678	Loss 2.3992	Prec@(1,5) (43.9%, 74.6%)
01/03 04:21:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][390/391]	Step 22678	Loss 2.3973	Prec@(1,5) (44.0%, 74.5%)
01/03 04:21:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 44.0080%
01/03 04:21:43午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:21:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:22:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][100/390]	Step 22778	lr 0.01718	Loss 0.9032 (0.9000)	Arch Loss -14.5016 (-14.6515)	Arch Hard Loss 2.0662 (1.9039)	Arch Beta Loss 16.5678 (16.5554)	Arch depth Loss -0.3819 (-0.4041)	Prec@(1,5) (72.8%, 95.1%)	
01/03 04:22:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][200/390]	Step 22878	lr 0.01718	Loss 0.8389 (0.9035)	Arch Loss -14.6059 (-14.6519)	Arch Hard Loss 1.9855 (1.9155)	Arch Beta Loss 16.5914 (16.5675)	Arch depth Loss -0.3393 (-0.3819)	Prec@(1,5) (72.5%, 95.1%)	
01/03 04:22:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][300/390]	Step 22978	lr 0.01718	Loss 0.9580 (0.9317)	Arch Loss -14.3893 (-14.6596)	Arch Hard Loss 2.2242 (1.9195)	Arch Beta Loss 16.6135 (16.5791)	Arch depth Loss -0.2986 (-0.3606)	Prec@(1,5) (71.9%, 94.7%)	
01/03 04:23:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][390/390]	Step 23068	lr 0.01718	Loss 1.1412 (0.9432)	Arch Loss -14.8154 (-14.6790)	Arch Hard Loss 1.8190 (1.9105)	Arch Beta Loss 16.6344 (16.5894)	Arch depth Loss -0.2633 (-0.3419)	Prec@(1,5) (71.7%, 94.5%)	
01/03 04:23:10午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 58/149] Final Prec@1 71.7040%
01/03 04:23:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][100/391]	Step 23069	Loss 3.1893	Prec@(1,5) (33.1%, 63.4%)
01/03 04:23:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][200/391]	Step 23069	Loss 3.1527	Prec@(1,5) (32.8%, 63.8%)
01/03 04:23:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][300/391]	Step 23069	Loss 3.1529	Prec@(1,5) (33.0%, 63.8%)
01/03 04:23:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][390/391]	Step 23069	Loss 3.1462	Prec@(1,5) (33.1%, 64.0%)
01/03 04:23:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 33.1080%
01/03 04:23:22午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:23:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:23:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][100/390]	Step 23169	lr 0.01695	Loss 0.8819 (0.8965)	Arch Loss -14.6568 (-14.7488)	Arch Hard Loss 2.0010 (1.8979)	Arch Beta Loss 16.6577 (16.6467)	Arch depth Loss -0.2215 (-0.2415)	Prec@(1,5) (73.0%, 94.9%)	
01/03 04:24:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][200/390]	Step 23269	lr 0.01695	Loss 1.2700 (0.9049)	Arch Loss -14.9668 (-14.7235)	Arch Hard Loss 1.7127 (1.9342)	Arch Beta Loss 16.6795 (16.6577)	Arch depth Loss -0.1647 (-0.2160)	Prec@(1,5) (72.8%, 95.1%)	
01/03 04:24:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][300/390]	Step 23369	lr 0.01695	Loss 0.7697 (0.9388)	Arch Loss -14.5531 (-14.7389)	Arch Hard Loss 2.1474 (1.9297)	Arch Beta Loss 16.7005 (16.6685)	Arch depth Loss -0.1284 (-0.1933)	Prec@(1,5) (71.6%, 94.8%)	
01/03 04:24:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][390/390]	Step 23459	lr 0.01695	Loss 0.8684 (0.9531)	Arch Loss -14.7652 (-14.7606)	Arch Hard Loss 1.9566 (1.9178)	Arch Beta Loss 16.7218 (16.6784)	Arch depth Loss -0.0965 (-0.1743)	Prec@(1,5) (71.2%, 94.6%)	
01/03 04:24:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 59/149] Final Prec@1 71.1680%
01/03 04:24:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][100/391]	Step 23460	Loss 2.5292	Prec@(1,5) (40.8%, 71.0%)
01/03 04:24:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][200/391]	Step 23460	Loss 2.5143	Prec@(1,5) (40.7%, 71.2%)
01/03 04:24:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][300/391]	Step 23460	Loss 2.5177	Prec@(1,5) (41.2%, 71.1%)
01/03 04:25:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][390/391]	Step 23460	Loss 2.4859	Prec@(1,5) (41.6%, 71.6%)
01/03 04:25:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 41.5720%
01/03 04:25:01午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
01/03 04:25:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:25:02午前 searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
01/03 04:25:02午前 searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 1., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
01/03 04:25:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][100/703]	Step 23560	lr 0.025	Loss 4.6918 (4.7674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.3%, 6.5%)	
01/03 04:25:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][200/703]	Step 23660	lr 0.025	Loss 4.1660 (4.6177)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 9.2%)	
01/03 04:25:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][300/703]	Step 23760	lr 0.025	Loss 3.8187 (4.4396)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.5%, 13.7%)	
01/03 04:25:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][400/703]	Step 23860	lr 0.025	Loss 3.7510 (4.3151)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.7%, 17.1%)	
01/03 04:25:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][500/703]	Step 23960	lr 0.025	Loss 3.7670 (4.2147)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.8%, 20.0%)	
01/03 04:25:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][600/703]	Step 24060	lr 0.025	Loss 3.7391 (4.1317)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.7%, 22.4%)	
01/03 04:26:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][700/703]	Step 24160	lr 0.025	Loss 3.6311 (4.0570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.7%, 24.6%)	
01/03 04:26:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][703/703]	Step 24163	lr 0.025	Loss 3.4267 (4.0547)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.7%, 24.7%)	
01/03 04:26:04午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 60/149] Final Prec@1 7.6978%
01/03 04:26:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][78/79]	Step 24164	Loss 3.9143	Prec@(1,5) (11.4%, 32.4%)
01/03 04:26:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 11.4200%
01/03 04:26:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:26:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][100/703]	Step 24264	lr 0.02499	Loss 3.3625 (3.5236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.0%, 40.4%)	
01/03 04:26:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][200/703]	Step 24364	lr 0.02499	Loss 3.3406 (3.5113)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 40.8%)	
01/03 04:26:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][300/703]	Step 24464	lr 0.02499	Loss 3.6570 (3.4799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.9%, 41.6%)	
01/03 04:26:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][400/703]	Step 24564	lr 0.02499	Loss 3.2983 (3.4511)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.5%, 42.6%)	
01/03 04:26:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][500/703]	Step 24664	lr 0.02499	Loss 3.6928 (3.4200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.0%, 43.4%)	
01/03 04:26:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][600/703]	Step 24764	lr 0.02499	Loss 3.0552 (3.3948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.6%, 44.1%)	
01/03 04:27:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][700/703]	Step 24864	lr 0.02499	Loss 3.3863 (3.3725)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.0%, 44.7%)	
01/03 04:27:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][703/703]	Step 24867	lr 0.02499	Loss 3.2548 (3.3714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.0%, 44.8%)	
01/03 04:27:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 61/149] Final Prec@1 17.9978%
01/03 04:27:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][78/79]	Step 24868	Loss 4.4341	Prec@(1,5) (8.4%, 25.2%)
01/03 04:27:11午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 8.4400%
01/03 04:27:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:27:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][100/703]	Step 24968	lr 0.02497	Loss 2.8667 (3.1637)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.5%, 50.7%)	
01/03 04:27:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][200/703]	Step 25068	lr 0.02497	Loss 3.1351 (3.1319)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 51.7%)	
01/03 04:27:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][300/703]	Step 25168	lr 0.02497	Loss 3.1958 (3.1253)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.7%, 52.0%)	
01/03 04:27:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][400/703]	Step 25268	lr 0.02497	Loss 2.8995 (3.1194)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.7%, 52.0%)	
01/03 04:27:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][500/703]	Step 25368	lr 0.02497	Loss 3.0145 (3.1055)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 52.3%)	
01/03 04:28:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][600/703]	Step 25468	lr 0.02497	Loss 3.0305 (3.0875)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.1%, 52.6%)	
01/03 04:28:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][700/703]	Step 25568	lr 0.02497	Loss 2.9549 (3.0678)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 53.0%)	
01/03 04:28:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][703/703]	Step 25571	lr 0.02497	Loss 3.7794 (3.0688)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 53.0%)	
01/03 04:28:13午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 62/149] Final Prec@1 23.5022%
01/03 04:28:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][78/79]	Step 25572	Loss 3.1220	Prec@(1,5) (23.4%, 52.0%)
01/03 04:28:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 23.3600%
01/03 04:28:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:28:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][100/703]	Step 25672	lr 0.02493	Loss 2.6672 (2.9082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 56.7%)	
01/03 04:28:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][200/703]	Step 25772	lr 0.02493	Loss 2.5300 (2.8883)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.8%, 57.1%)	
01/03 04:28:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][300/703]	Step 25872	lr 0.02493	Loss 3.0908 (2.8824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.5%)	
01/03 04:28:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][400/703]	Step 25972	lr 0.02493	Loss 2.8428 (2.8776)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.1%, 57.8%)	
01/03 04:29:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][500/703]	Step 26072	lr 0.02493	Loss 2.5929 (2.8628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 58.2%)	
01/03 04:29:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][600/703]	Step 26172	lr 0.02493	Loss 2.8728 (2.8455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.8%, 58.6%)	
01/03 04:29:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][700/703]	Step 26272	lr 0.02493	Loss 2.7549 (2.8350)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 58.9%)	
01/03 04:29:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][703/703]	Step 26275	lr 0.02493	Loss 2.6261 (2.8342)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 58.9%)	
01/03 04:29:17午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 63/149] Final Prec@1 28.0111%
01/03 04:29:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][78/79]	Step 26276	Loss 3.0851	Prec@(1,5) (25.1%, 54.7%)
01/03 04:29:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 25.1400%
01/03 04:29:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:29:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][100/703]	Step 26376	lr 0.02488	Loss 2.5567 (2.6847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.2%, 62.6%)	
01/03 04:29:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][200/703]	Step 26476	lr 0.02488	Loss 2.7454 (2.7117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 61.8%)	
01/03 04:29:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][300/703]	Step 26576	lr 0.02488	Loss 2.4234 (2.6959)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.3%, 62.2%)	
01/03 04:29:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][400/703]	Step 26676	lr 0.02488	Loss 2.7646 (2.6894)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.6%, 62.5%)	
01/03 04:30:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][500/703]	Step 26776	lr 0.02488	Loss 2.7479 (2.6835)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 62.6%)	
01/03 04:30:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][600/703]	Step 26876	lr 0.02488	Loss 2.5266 (2.6655)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 63.1%)	
01/03 04:30:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][700/703]	Step 26976	lr 0.02488	Loss 2.4866 (2.6565)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 63.4%)	
01/03 04:30:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][703/703]	Step 26979	lr 0.02488	Loss 2.9763 (2.6570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 63.4%)	
01/03 04:30:22午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 64/149] Final Prec@1 31.3733%
01/03 04:30:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][78/79]	Step 26980	Loss 2.9018	Prec@(1,5) (27.2%, 59.3%)
01/03 04:30:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 27.1600%
01/03 04:30:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:30:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][100/703]	Step 27080	lr 0.02482	Loss 2.4716 (2.5407)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 65.6%)	
01/03 04:30:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][200/703]	Step 27180	lr 0.02482	Loss 2.5396 (2.5269)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 65.9%)	
01/03 04:30:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][300/703]	Step 27280	lr 0.02482	Loss 2.6684 (2.5272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.1%, 66.0%)	
01/03 04:31:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][400/703]	Step 27380	lr 0.02482	Loss 2.7691 (2.5316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.1%, 66.1%)	
01/03 04:31:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][500/703]	Step 27480	lr 0.02482	Loss 2.2066 (2.5264)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 66.3%)	
01/03 04:31:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][600/703]	Step 27580	lr 0.02482	Loss 2.4061 (2.5213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.3%, 66.4%)	
01/03 04:31:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][700/703]	Step 27680	lr 0.02482	Loss 2.3838 (2.5165)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 66.6%)	
01/03 04:31:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][703/703]	Step 27683	lr 0.02482	Loss 2.8282 (2.5162)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 66.6%)	
01/03 04:31:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 65/149] Final Prec@1 34.5067%
01/03 04:31:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][78/79]	Step 27684	Loss 2.9005	Prec@(1,5) (29.2%, 58.6%)
01/03 04:31:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 29.2000%
01/03 04:31:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:31:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][100/703]	Step 27784	lr 0.02474	Loss 2.3925 (2.4497)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 68.4%)	
01/03 04:31:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][200/703]	Step 27884	lr 0.02474	Loss 2.5678 (2.4383)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.3%)	
01/03 04:31:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][300/703]	Step 27984	lr 0.02474	Loss 2.5074 (2.4170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.1%, 68.6%)	
01/03 04:32:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][400/703]	Step 28084	lr 0.02474	Loss 2.9673 (2.4125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.3%, 68.7%)	
01/03 04:32:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][500/703]	Step 28184	lr 0.02474	Loss 2.1889 (2.4088)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 68.8%)	
01/03 04:32:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][600/703]	Step 28284	lr 0.02474	Loss 2.5146 (2.4057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.6%, 68.9%)	
01/03 04:32:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][700/703]	Step 28384	lr 0.02474	Loss 2.3652 (2.4001)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 69.0%)	
01/03 04:32:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][703/703]	Step 28387	lr 0.02474	Loss 2.2176 (2.3996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 69.0%)	
01/03 04:32:30午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 66/149] Final Prec@1 36.8178%
01/03 04:32:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][78/79]	Step 28388	Loss 2.5405	Prec@(1,5) (34.4%, 66.9%)
01/03 04:32:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 34.4800%
01/03 04:32:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:32:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][100/703]	Step 28488	lr 0.02464	Loss 2.5099 (2.3037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.2%)	
01/03 04:32:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][200/703]	Step 28588	lr 0.02464	Loss 2.5085 (2.3097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 70.9%)	
01/03 04:33:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][300/703]	Step 28688	lr 0.02464	Loss 2.3966 (2.2950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.2%)	
01/03 04:33:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][400/703]	Step 28788	lr 0.02464	Loss 2.4533 (2.2987)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 71.2%)	
01/03 04:33:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][500/703]	Step 28888	lr 0.02464	Loss 2.3064 (2.2953)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.4%)	
01/03 04:33:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][600/703]	Step 28988	lr 0.02464	Loss 1.8971 (2.2983)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 71.4%)	
01/03 04:33:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][700/703]	Step 29088	lr 0.02464	Loss 2.5105 (2.2972)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.5%)	
01/03 04:33:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][703/703]	Step 29091	lr 0.02464	Loss 2.5037 (2.2970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.5%)	
01/03 04:33:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 67/149] Final Prec@1 38.7933%
01/03 04:33:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][78/79]	Step 29092	Loss 2.5750	Prec@(1,5) (33.2%, 65.9%)
01/03 04:33:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 33.1800%
01/03 04:33:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:33:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][100/703]	Step 29192	lr 0.02454	Loss 2.1907 (2.2224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.8%, 73.5%)	
01/03 04:33:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][200/703]	Step 29292	lr 0.02454	Loss 2.3680 (2.2272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 73.1%)	
01/03 04:34:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][300/703]	Step 29392	lr 0.02454	Loss 2.3233 (2.2222)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.1%)	
01/03 04:34:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][400/703]	Step 29492	lr 0.02454	Loss 2.4235 (2.2137)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.6%, 73.4%)	
01/03 04:34:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][500/703]	Step 29592	lr 0.02454	Loss 2.3169 (2.2101)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.3%)	
01/03 04:34:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][600/703]	Step 29692	lr 0.02454	Loss 2.4378 (2.2117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.2%)	
01/03 04:34:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][700/703]	Step 29792	lr 0.02454	Loss 2.3180 (2.2122)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.1%)	
01/03 04:34:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][703/703]	Step 29795	lr 0.02454	Loss 2.0903 (2.2124)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.1%)	
01/03 04:34:39午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 68/149] Final Prec@1 40.8111%
01/03 04:34:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][78/79]	Step 29796	Loss 2.4566	Prec@(1,5) (35.4%, 68.4%)
01/03 04:34:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 35.4000%
01/03 04:34:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:34:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][100/703]	Step 29896	lr 0.02441	Loss 2.3162 (2.1224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 74.7%)	
01/03 04:35:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][200/703]	Step 29996	lr 0.02441	Loss 2.0136 (2.1287)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 74.7%)	
01/03 04:35:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][300/703]	Step 30096	lr 0.02441	Loss 2.3531 (2.1316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 74.7%)	
01/03 04:35:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][400/703]	Step 30196	lr 0.02441	Loss 2.4248 (2.1427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 74.3%)	
01/03 04:35:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][500/703]	Step 30296	lr 0.02441	Loss 1.8760 (2.1393)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 74.5%)	
01/03 04:35:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][600/703]	Step 30396	lr 0.02441	Loss 2.3457 (2.1365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 74.5%)	
01/03 04:35:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][700/703]	Step 30496	lr 0.02441	Loss 2.3554 (2.1364)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 74.6%)	
01/03 04:35:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][703/703]	Step 30499	lr 0.02441	Loss 1.9053 (2.1361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 74.6%)	
01/03 04:35:44午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 69/149] Final Prec@1 42.7000%
01/03 04:35:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][78/79]	Step 30500	Loss 2.5767	Prec@(1,5) (34.3%, 66.3%)
01/03 04:35:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 34.3600%
01/03 04:35:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:35:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][100/703]	Step 30600	lr 0.02428	Loss 1.8716 (2.0691)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.5%, 76.0%)	
01/03 04:36:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][200/703]	Step 30700	lr 0.02428	Loss 1.6398 (2.0652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.1%)	
01/03 04:36:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][300/703]	Step 30800	lr 0.02428	Loss 1.8079 (2.0695)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.1%)	
01/03 04:36:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][400/703]	Step 30900	lr 0.02428	Loss 2.2039 (2.0703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.1%)	
01/03 04:36:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][500/703]	Step 31000	lr 0.02428	Loss 1.8483 (2.0788)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 75.9%)	
01/03 04:36:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][600/703]	Step 31100	lr 0.02428	Loss 1.9582 (2.0800)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 75.8%)	
01/03 04:36:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][700/703]	Step 31200	lr 0.02428	Loss 2.1412 (2.0873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 75.7%)	
01/03 04:36:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][703/703]	Step 31203	lr 0.02428	Loss 2.3986 (2.0876)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 75.7%)	
01/03 04:36:48午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 70/149] Final Prec@1 43.6244%
01/03 04:36:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][78/79]	Step 31204	Loss 2.3728	Prec@(1,5) (37.9%, 70.3%)
01/03 04:36:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 37.8800%
01/03 04:36:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:37:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][100/703]	Step 31304	lr 0.02413	Loss 2.0929 (2.0008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.3%, 77.5%)	
01/03 04:37:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][200/703]	Step 31404	lr 0.02413	Loss 2.0161 (2.0171)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 76.8%)	
01/03 04:37:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][300/703]	Step 31504	lr 0.02413	Loss 2.1434 (2.0226)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 76.8%)	
01/03 04:37:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][400/703]	Step 31604	lr 0.02413	Loss 1.7589 (2.0222)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 76.8%)	
01/03 04:37:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][500/703]	Step 31704	lr 0.02413	Loss 1.9777 (2.0276)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 76.8%)	
01/03 04:37:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][600/703]	Step 31804	lr 0.02413	Loss 1.9237 (2.0273)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.3%, 76.8%)	
01/03 04:37:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][700/703]	Step 31904	lr 0.02413	Loss 2.2491 (2.0254)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 76.9%)	
01/03 04:37:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][703/703]	Step 31907	lr 0.02413	Loss 1.8778 (2.0252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 76.8%)	
01/03 04:37:52午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 71/149] Final Prec@1 45.2067%
01/03 04:37:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][78/79]	Step 31908	Loss 2.3156	Prec@(1,5) (40.5%, 71.2%)
01/03 04:37:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 40.5600%
01/03 04:37:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:38:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][100/703]	Step 32008	lr 0.02396	Loss 1.9869 (1.9728)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 77.9%)	
01/03 04:38:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][200/703]	Step 32108	lr 0.02396	Loss 1.9694 (1.9674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.6%, 77.9%)	
01/03 04:38:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][300/703]	Step 32208	lr 0.02396	Loss 2.1480 (1.9638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.0%)	
01/03 04:38:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][400/703]	Step 32308	lr 0.02396	Loss 1.5859 (1.9763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 77.7%)	
01/03 04:38:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][500/703]	Step 32408	lr 0.02396	Loss 1.8999 (1.9726)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 77.9%)	
01/03 04:38:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][600/703]	Step 32508	lr 0.02396	Loss 2.0561 (1.9703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 77.9%)	
01/03 04:38:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][700/703]	Step 32608	lr 0.02396	Loss 1.9608 (1.9726)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.2%, 77.9%)	
01/03 04:38:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][703/703]	Step 32611	lr 0.02396	Loss 2.1091 (1.9726)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.2%, 77.9%)	
01/03 04:38:57午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 72/149] Final Prec@1 46.1578%
01/03 04:39:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][78/79]	Step 32612	Loss 2.4515	Prec@(1,5) (37.8%, 69.4%)
01/03 04:39:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 37.7800%
01/03 04:39:00午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:39:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][100/703]	Step 32712	lr 0.02379	Loss 2.0432 (1.8889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.3%)	
01/03 04:39:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][200/703]	Step 32812	lr 0.02379	Loss 2.0126 (1.8952)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 79.6%)	
01/03 04:39:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][300/703]	Step 32912	lr 0.02379	Loss 1.7922 (1.8916)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.7%)	
01/03 04:39:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][400/703]	Step 33012	lr 0.02379	Loss 2.2727 (1.9087)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.7%, 79.3%)	
01/03 04:39:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][500/703]	Step 33112	lr 0.02379	Loss 1.5820 (1.9242)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.3%, 78.9%)	
01/03 04:39:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][600/703]	Step 33212	lr 0.02379	Loss 1.8983 (1.9315)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 78.8%)	
01/03 04:40:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][700/703]	Step 33312	lr 0.02379	Loss 1.7102 (1.9315)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 78.7%)	
01/03 04:40:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][703/703]	Step 33315	lr 0.02379	Loss 2.1358 (1.9314)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 78.7%)	
01/03 04:40:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 73/149] Final Prec@1 47.0467%
01/03 04:40:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][78/79]	Step 33316	Loss 2.3285	Prec@(1,5) (39.5%, 71.7%)
01/03 04:40:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 39.5400%
01/03 04:40:04午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:40:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][100/703]	Step 33416	lr 0.0236	Loss 2.0316 (1.8617)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 79.9%)	
01/03 04:40:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][200/703]	Step 33516	lr 0.0236	Loss 2.0053 (1.8795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 79.8%)	
01/03 04:40:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][300/703]	Step 33616	lr 0.0236	Loss 1.4867 (1.8778)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 79.8%)	
01/03 04:40:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][400/703]	Step 33716	lr 0.0236	Loss 1.9126 (1.8870)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.6%)	
01/03 04:40:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][500/703]	Step 33816	lr 0.0236	Loss 1.8822 (1.8881)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.6%)	
01/03 04:40:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][600/703]	Step 33916	lr 0.0236	Loss 1.8526 (1.8934)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.5%)	
01/03 04:41:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][700/703]	Step 34016	lr 0.0236	Loss 2.0142 (1.8986)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.3%)	
01/03 04:41:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][703/703]	Step 34019	lr 0.0236	Loss 2.0058 (1.8981)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.3%)	
01/03 04:41:06午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 74/149] Final Prec@1 47.6044%
01/03 04:41:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][78/79]	Step 34020	Loss 2.4130	Prec@(1,5) (37.4%, 70.0%)
01/03 04:41:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 37.4200%
01/03 04:41:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:41:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][100/703]	Step 34120	lr 0.02339	Loss 1.2989 (1.8216)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 80.9%)	
01/03 04:41:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][200/703]	Step 34220	lr 0.02339	Loss 1.8939 (1.8349)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 80.6%)	
01/03 04:41:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][300/703]	Step 34320	lr 0.02339	Loss 1.9178 (1.8400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.2%)	
01/03 04:41:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][400/703]	Step 34420	lr 0.02339	Loss 1.7495 (1.8459)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.2%)	
01/03 04:41:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][500/703]	Step 34520	lr 0.02339	Loss 1.9005 (1.8546)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.0%)	
01/03 04:42:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][600/703]	Step 34620	lr 0.02339	Loss 1.8152 (1.8567)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 79.9%)	
01/03 04:42:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][700/703]	Step 34720	lr 0.02339	Loss 1.5742 (1.8610)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 79.9%)	
01/03 04:42:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][703/703]	Step 34723	lr 0.02339	Loss 1.8171 (1.8610)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 79.9%)	
01/03 04:42:10午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 75/149] Final Prec@1 48.9467%
01/03 04:42:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][78/79]	Step 34724	Loss 2.3478	Prec@(1,5) (40.2%, 72.1%)
01/03 04:42:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 40.2000%
01/03 04:42:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:42:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][100/703]	Step 34824	lr 0.02318	Loss 1.7990 (1.8211)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.6%)	
01/03 04:42:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][200/703]	Step 34924	lr 0.02318	Loss 2.0880 (1.8224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.6%)	
01/03 04:42:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][300/703]	Step 35024	lr 0.02318	Loss 1.5600 (1.8055)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 80.9%)	
01/03 04:42:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][400/703]	Step 35124	lr 0.02318	Loss 1.8336 (1.8165)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 80.7%)	
01/03 04:42:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][500/703]	Step 35224	lr 0.02318	Loss 1.9698 (1.8193)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 80.7%)	
01/03 04:43:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][600/703]	Step 35324	lr 0.02318	Loss 2.1281 (1.8190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 80.7%)	
01/03 04:43:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][700/703]	Step 35424	lr 0.02318	Loss 1.6860 (1.8226)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.7%)	
01/03 04:43:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][703/703]	Step 35427	lr 0.02318	Loss 1.7423 (1.8231)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.7%)	
01/03 04:43:15午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 76/149] Final Prec@1 49.5644%
01/03 04:43:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][78/79]	Step 35428	Loss 2.1812	Prec@(1,5) (42.9%, 74.2%)
01/03 04:43:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 42.9400%
01/03 04:43:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:43:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][100/703]	Step 35528	lr 0.02295	Loss 1.6882 (1.7545)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 82.2%)	
01/03 04:43:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][200/703]	Step 35628	lr 0.02295	Loss 1.8884 (1.7675)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.8%)	
01/03 04:43:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][300/703]	Step 35728	lr 0.02295	Loss 1.9650 (1.7915)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.2%)	
01/03 04:43:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][400/703]	Step 35828	lr 0.02295	Loss 1.7807 (1.7867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.2%)	
01/03 04:44:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][500/703]	Step 35928	lr 0.02295	Loss 2.0698 (1.7883)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.2%)	
01/03 04:44:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][600/703]	Step 36028	lr 0.02295	Loss 1.9003 (1.7949)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.0%)	
01/03 04:44:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][700/703]	Step 36128	lr 0.02295	Loss 1.6843 (1.8028)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 80.9%)	
01/03 04:44:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][703/703]	Step 36131	lr 0.02295	Loss 2.0216 (1.8029)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 80.9%)	
01/03 04:44:19午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 77/149] Final Prec@1 50.2533%
01/03 04:44:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][78/79]	Step 36132	Loss 2.0905	Prec@(1,5) (43.4%, 75.5%)
01/03 04:44:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 43.4200%
01/03 04:44:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:44:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][100/703]	Step 36232	lr 0.02271	Loss 2.0958 (1.7422)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 81.8%)	
01/03 04:44:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][200/703]	Step 36332	lr 0.02271	Loss 1.4325 (1.7290)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 82.3%)	
01/03 04:44:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][300/703]	Step 36432	lr 0.02271	Loss 1.7837 (1.7294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.3%)	
01/03 04:44:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][400/703]	Step 36532	lr 0.02271	Loss 1.9495 (1.7390)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.1%)	
01/03 04:45:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][500/703]	Step 36632	lr 0.02271	Loss 1.6628 (1.7561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.4%, 81.8%)	
01/03 04:45:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][600/703]	Step 36732	lr 0.02271	Loss 1.7827 (1.7607)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 81.7%)	
01/03 04:45:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][700/703]	Step 36832	lr 0.02271	Loss 1.5366 (1.7676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 81.6%)	
01/03 04:45:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][703/703]	Step 36835	lr 0.02271	Loss 1.8537 (1.7676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 81.6%)	
01/03 04:45:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 78/149] Final Prec@1 51.1111%
01/03 04:45:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][78/79]	Step 36836	Loss 1.9783	Prec@(1,5) (46.6%, 78.6%)
01/03 04:45:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 46.5600%
01/03 04:45:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:45:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][100/703]	Step 36936	lr 0.02246	Loss 1.4962 (1.7039)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 83.4%)	
01/03 04:45:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][200/703]	Step 37036	lr 0.02246	Loss 1.9579 (1.7205)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.8%)	
01/03 04:45:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][300/703]	Step 37136	lr 0.02246	Loss 1.3673 (1.7212)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 82.7%)	
01/03 04:46:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][400/703]	Step 37236	lr 0.02246	Loss 1.6606 (1.7363)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 82.2%)	
01/03 04:46:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][500/703]	Step 37336	lr 0.02246	Loss 1.4980 (1.7377)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.3%)	
01/03 04:46:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][600/703]	Step 37436	lr 0.02246	Loss 1.5796 (1.7380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 82.2%)	
01/03 04:46:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][700/703]	Step 37536	lr 0.02246	Loss 1.7904 (1.7384)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.2%)	
01/03 04:46:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][703/703]	Step 37539	lr 0.02246	Loss 1.6419 (1.7386)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.2%)	
01/03 04:46:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 79/149] Final Prec@1 51.5911%
01/03 04:46:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][78/79]	Step 37540	Loss 2.0639	Prec@(1,5) (45.4%, 76.6%)
01/03 04:46:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 45.4000%
01/03 04:46:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:46:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][100/703]	Step 37640	lr 0.02219	Loss 1.6039 (1.6388)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 83.9%)	
01/03 04:46:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][200/703]	Step 37740	lr 0.02219	Loss 1.7897 (1.6713)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.2%)	
01/03 04:46:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][300/703]	Step 37840	lr 0.02219	Loss 1.5189 (1.6805)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.1%)	
01/03 04:47:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][400/703]	Step 37940	lr 0.02219	Loss 1.7607 (1.6951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 82.9%)	
01/03 04:47:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][500/703]	Step 38040	lr 0.02219	Loss 1.8996 (1.7070)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.7%)	
01/03 04:47:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][600/703]	Step 38140	lr 0.02219	Loss 1.9282 (1.7111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 82.6%)	
01/03 04:47:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][700/703]	Step 38240	lr 0.02219	Loss 1.4916 (1.7109)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.6%)	
01/03 04:47:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][703/703]	Step 38243	lr 0.02219	Loss 1.5184 (1.7107)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 82.6%)	
01/03 04:47:33午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 80/149] Final Prec@1 52.2489%
01/03 04:47:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][78/79]	Step 38244	Loss 2.0354	Prec@(1,5) (46.0%, 77.0%)
01/03 04:47:35午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 45.9800%
01/03 04:47:35午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:47:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][100/703]	Step 38344	lr 0.02192	Loss 1.8941 (1.6428)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.6%, 83.5%)	
01/03 04:47:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][200/703]	Step 38444	lr 0.02192	Loss 1.8039 (1.6671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.1%)	
01/03 04:48:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][300/703]	Step 38544	lr 0.02192	Loss 1.4878 (1.6666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.4%, 83.2%)	
01/03 04:48:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][400/703]	Step 38644	lr 0.02192	Loss 2.1168 (1.6711)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.2%)	
01/03 04:48:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][500/703]	Step 38744	lr 0.02192	Loss 1.4064 (1.6730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.2%)	
01/03 04:48:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][600/703]	Step 38844	lr 0.02192	Loss 1.7171 (1.6787)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.1%)	
01/03 04:48:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][700/703]	Step 38944	lr 0.02192	Loss 1.3650 (1.6856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.0%)	
01/03 04:48:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][703/703]	Step 38947	lr 0.02192	Loss 1.8704 (1.6862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.0%)	
01/03 04:48:37午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 81/149] Final Prec@1 52.8911%
01/03 04:48:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][78/79]	Step 38948	Loss 2.4866	Prec@(1,5) (39.1%, 70.9%)
01/03 04:48:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 39.1200%
01/03 04:48:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:48:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][100/703]	Step 39048	lr 0.02163	Loss 1.4607 (1.6241)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.5%)	
01/03 04:48:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][200/703]	Step 39148	lr 0.02163	Loss 1.9011 (1.6268)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.2%)	
01/03 04:49:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][300/703]	Step 39248	lr 0.02163	Loss 1.5894 (1.6412)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.0%, 83.8%)	
01/03 04:49:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][400/703]	Step 39348	lr 0.02163	Loss 1.6962 (1.6492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 83.6%)	
01/03 04:49:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][500/703]	Step 39448	lr 0.02163	Loss 1.5853 (1.6501)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 83.5%)	
01/03 04:49:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][600/703]	Step 39548	lr 0.02163	Loss 1.3753 (1.6600)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.4%)	
01/03 04:49:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][700/703]	Step 39648	lr 0.02163	Loss 1.3748 (1.6610)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.4%)	
01/03 04:49:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][703/703]	Step 39651	lr 0.02163	Loss 1.6608 (1.6620)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.3%)	
01/03 04:49:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 82/149] Final Prec@1 53.5889%
01/03 04:49:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][78/79]	Step 39652	Loss 2.2552	Prec@(1,5) (41.8%, 73.8%)
01/03 04:49:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 41.7800%
01/03 04:49:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:49:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][100/703]	Step 39752	lr 0.02134	Loss 1.6973 (1.5523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.5%)	
01/03 04:50:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][200/703]	Step 39852	lr 0.02134	Loss 1.6778 (1.6048)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.5%)	
01/03 04:50:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][300/703]	Step 39952	lr 0.02134	Loss 1.4288 (1.6232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.1%)	
01/03 04:50:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][400/703]	Step 40052	lr 0.02134	Loss 1.5770 (1.6288)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 83.8%)	
01/03 04:50:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][500/703]	Step 40152	lr 0.02134	Loss 1.5505 (1.6307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 83.9%)	
01/03 04:50:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][600/703]	Step 40252	lr 0.02134	Loss 2.1894 (1.6289)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 83.9%)	
01/03 04:50:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][700/703]	Step 40352	lr 0.02134	Loss 1.7074 (1.6324)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.3%, 83.9%)	
01/03 04:50:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][703/703]	Step 40355	lr 0.02134	Loss 1.7144 (1.6334)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.3%, 83.8%)	
01/03 04:50:46午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 83/149] Final Prec@1 54.3378%
01/03 04:50:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][78/79]	Step 40356	Loss 2.0001	Prec@(1,5) (45.9%, 77.6%)
01/03 04:50:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 45.8200%
01/03 04:50:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:50:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][100/703]	Step 40456	lr 0.02103	Loss 1.9697 (1.5748)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 84.8%)	
01/03 04:51:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][200/703]	Step 40556	lr 0.02103	Loss 1.5461 (1.5784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 84.7%)	
01/03 04:51:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][300/703]	Step 40656	lr 0.02103	Loss 1.6473 (1.5769)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 84.8%)	
01/03 04:51:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][400/703]	Step 40756	lr 0.02103	Loss 1.5906 (1.5902)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 84.7%)	
01/03 04:51:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][500/703]	Step 40856	lr 0.02103	Loss 2.1638 (1.5933)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 84.6%)	
01/03 04:51:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][600/703]	Step 40956	lr 0.02103	Loss 1.5579 (1.6037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 84.4%)	
01/03 04:51:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][700/703]	Step 41056	lr 0.02103	Loss 1.6556 (1.6074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.4%)	
01/03 04:51:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][703/703]	Step 41059	lr 0.02103	Loss 2.0304 (1.6086)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.3%)	
01/03 04:51:51午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 84/149] Final Prec@1 54.7644%
01/03 04:51:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][78/79]	Step 41060	Loss 2.0265	Prec@(1,5) (45.4%, 77.2%)
01/03 04:51:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 45.4000%
01/03 04:51:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:52:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][100/703]	Step 41160	lr 0.02071	Loss 1.3763 (1.5705)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.3%)	
01/03 04:52:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][200/703]	Step 41260	lr 0.02071	Loss 1.4783 (1.5505)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.4%)	
01/03 04:52:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][300/703]	Step 41360	lr 0.02071	Loss 1.6105 (1.5680)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.2%, 85.0%)	
01/03 04:52:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][400/703]	Step 41460	lr 0.02071	Loss 1.8325 (1.5846)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 84.7%)	
01/03 04:52:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][500/703]	Step 41560	lr 0.02071	Loss 1.5447 (1.5836)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 84.7%)	
01/03 04:52:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][600/703]	Step 41660	lr 0.02071	Loss 1.3962 (1.5869)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.7%)	
01/03 04:52:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][700/703]	Step 41760	lr 0.02071	Loss 1.6920 (1.5907)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.7%)	
01/03 04:52:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][703/703]	Step 41763	lr 0.02071	Loss 1.6588 (1.5911)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.7%)	
01/03 04:52:55午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 85/149] Final Prec@1 55.3133%
01/03 04:52:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][78/79]	Step 41764	Loss 1.9822	Prec@(1,5) (47.1%, 78.4%)
01/03 04:52:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 47.0600%
01/03 04:52:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:53:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][100/703]	Step 41864	lr 0.02039	Loss 1.6374 (1.5136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.5%)	
01/03 04:53:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][200/703]	Step 41964	lr 0.02039	Loss 1.9237 (1.5232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.4%)	
01/03 04:53:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][300/703]	Step 42064	lr 0.02039	Loss 1.2124 (1.5298)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.3%)	
01/03 04:53:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][400/703]	Step 42164	lr 0.02039	Loss 1.8695 (1.5336)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.5%)	
01/03 04:53:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][500/703]	Step 42264	lr 0.02039	Loss 1.7021 (1.5463)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.2%, 85.3%)	
01/03 04:53:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][600/703]	Step 42364	lr 0.02039	Loss 1.4970 (1.5537)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.2%)	
01/03 04:53:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][700/703]	Step 42464	lr 0.02039	Loss 1.5447 (1.5596)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.1%)	
01/03 04:54:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][703/703]	Step 42467	lr 0.02039	Loss 1.4435 (1.5584)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.1%)	
01/03 04:54:00午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 86/149] Final Prec@1 56.0156%
01/03 04:54:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][78/79]	Step 42468	Loss 2.0138	Prec@(1,5) (46.8%, 76.7%)
01/03 04:54:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 46.8000%
01/03 04:54:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:54:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][100/703]	Step 42568	lr 0.02005	Loss 1.5565 (1.4735)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.4%)	
01/03 04:54:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][200/703]	Step 42668	lr 0.02005	Loss 1.3470 (1.4740)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.0%, 86.5%)	
01/03 04:54:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][300/703]	Step 42768	lr 0.02005	Loss 1.7217 (1.4981)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.0%)	
01/03 04:54:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][400/703]	Step 42868	lr 0.02005	Loss 1.8602 (1.5121)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.0%)	
01/03 04:54:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][500/703]	Step 42968	lr 0.02005	Loss 1.6671 (1.5265)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.8%)	
01/03 04:54:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][600/703]	Step 43068	lr 0.02005	Loss 1.3816 (1.5307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.8%)	
01/03 04:55:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][700/703]	Step 43168	lr 0.02005	Loss 1.4424 (1.5351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.7%)	
01/03 04:55:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][703/703]	Step 43171	lr 0.02005	Loss 1.8148 (1.5359)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.7%)	
01/03 04:55:05午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 87/149] Final Prec@1 56.4133%
01/03 04:55:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][78/79]	Step 43172	Loss 1.9300	Prec@(1,5) (48.7%, 78.6%)
01/03 04:55:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 48.7400%
01/03 04:55:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:55:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][100/703]	Step 43272	lr 0.01971	Loss 1.1836 (1.4617)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.2%)	
01/03 04:55:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][200/703]	Step 43372	lr 0.01971	Loss 1.3832 (1.4812)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.6%)	
01/03 04:55:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][300/703]	Step 43472	lr 0.01971	Loss 1.5860 (1.4893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.3%)	
01/03 04:55:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][400/703]	Step 43572	lr 0.01971	Loss 1.1884 (1.4996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.1%)	
01/03 04:55:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][500/703]	Step 43672	lr 0.01971	Loss 1.6650 (1.5084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 85.9%)	
01/03 04:56:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][600/703]	Step 43772	lr 0.01971	Loss 1.9266 (1.5145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 85.9%)	
01/03 04:56:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][700/703]	Step 43872	lr 0.01971	Loss 1.6429 (1.5215)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.8%)	
01/03 04:56:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][703/703]	Step 43875	lr 0.01971	Loss 1.8192 (1.5210)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.8%)	
01/03 04:56:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 88/149] Final Prec@1 56.9178%
01/03 04:56:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][78/79]	Step 43876	Loss 2.1898	Prec@(1,5) (42.9%, 75.6%)
01/03 04:56:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 42.9400%
01/03 04:56:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:56:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][100/703]	Step 43976	lr 0.01936	Loss 1.5560 (1.4582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.6%)	
01/03 04:56:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][200/703]	Step 44076	lr 0.01936	Loss 1.4446 (1.4526)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 86.7%)	
01/03 04:56:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][300/703]	Step 44176	lr 0.01936	Loss 1.3107 (1.4650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.7%)	
01/03 04:56:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][400/703]	Step 44276	lr 0.01936	Loss 1.5069 (1.4820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.5%)	
01/03 04:56:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][500/703]	Step 44376	lr 0.01936	Loss 1.5037 (1.4900)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.3%)	
01/03 04:57:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][600/703]	Step 44476	lr 0.01936	Loss 1.4535 (1.5000)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.2%)	
01/03 04:57:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][700/703]	Step 44576	lr 0.01936	Loss 1.1766 (1.5014)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.2%)	
01/03 04:57:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][703/703]	Step 44579	lr 0.01936	Loss 1.4572 (1.5016)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.2%)	
01/03 04:57:14午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 89/149] Final Prec@1 57.5533%
01/03 04:57:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][78/79]	Step 44580	Loss 1.9308	Prec@(1,5) (48.5%, 78.8%)
01/03 04:57:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 48.5400%
01/03 04:57:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:57:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][100/703]	Step 44680	lr 0.019	Loss 1.1141 (1.4235)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.0%)	
01/03 04:57:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][200/703]	Step 44780	lr 0.019	Loss 1.4083 (1.4552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 86.8%)	
01/03 04:57:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][300/703]	Step 44880	lr 0.019	Loss 1.7229 (1.4558)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 86.7%)	
01/03 04:57:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][400/703]	Step 44980	lr 0.019	Loss 1.4292 (1.4581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 86.7%)	
01/03 04:58:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][500/703]	Step 45080	lr 0.019	Loss 1.4118 (1.4692)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.6%)	
01/03 04:58:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][600/703]	Step 45180	lr 0.019	Loss 1.1042 (1.4709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.6%)	
01/03 04:58:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][700/703]	Step 45280	lr 0.019	Loss 1.2120 (1.4766)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.5%)	
01/03 04:58:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][703/703]	Step 45283	lr 0.019	Loss 1.6767 (1.4771)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.4%)	
01/03 04:58:18午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 90/149] Final Prec@1 58.0933%
01/03 04:58:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][78/79]	Step 45284	Loss 1.9887	Prec@(1,5) (47.9%, 77.9%)
01/03 04:58:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 47.9600%
01/03 04:58:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:58:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][100/703]	Step 45384	lr 0.01863	Loss 1.1408 (1.3654)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.7%)	
01/03 04:58:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][200/703]	Step 45484	lr 0.01863	Loss 1.6128 (1.3964)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.3%)	
01/03 04:58:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][300/703]	Step 45584	lr 0.01863	Loss 1.1215 (1.4152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.9%)	
01/03 04:58:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][400/703]	Step 45684	lr 0.01863	Loss 1.3046 (1.4328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.4%)	
01/03 04:59:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][500/703]	Step 45784	lr 0.01863	Loss 1.5429 (1.4352)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.4%)	
01/03 04:59:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][600/703]	Step 45884	lr 0.01863	Loss 1.2262 (1.4433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.2%)	
01/03 04:59:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][700/703]	Step 45984	lr 0.01863	Loss 1.5378 (1.4512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.1%)	
01/03 04:59:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][703/703]	Step 45987	lr 0.01863	Loss 1.5139 (1.4516)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.1%)	
01/03 04:59:23午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 91/149] Final Prec@1 58.5644%
01/03 04:59:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][78/79]	Step 45988	Loss 2.2094	Prec@(1,5) (43.4%, 74.9%)
01/03 04:59:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 43.3800%
01/03 04:59:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 04:59:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][100/703]	Step 46088	lr 0.01826	Loss 1.4738 (1.3783)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 87.8%)	
01/03 04:59:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][200/703]	Step 46188	lr 0.01826	Loss 1.6229 (1.3834)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 87.9%)	
01/03 04:59:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][300/703]	Step 46288	lr 0.01826	Loss 1.1837 (1.4158)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.5%)	
01/03 05:00:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][400/703]	Step 46388	lr 0.01826	Loss 1.3012 (1.4184)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.4%)	
01/03 05:00:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][500/703]	Step 46488	lr 0.01826	Loss 1.9653 (1.4301)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.2%)	
01/03 05:00:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][600/703]	Step 46588	lr 0.01826	Loss 1.6116 (1.4302)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.1%)	
01/03 05:00:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][700/703]	Step 46688	lr 0.01826	Loss 1.9457 (1.4340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.0%)	
01/03 05:00:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][703/703]	Step 46691	lr 0.01826	Loss 1.4851 (1.4350)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.0%)	
01/03 05:00:27午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 92/149] Final Prec@1 59.0911%
01/03 05:00:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][78/79]	Step 46692	Loss 1.9576	Prec@(1,5) (48.4%, 79.5%)
01/03 05:00:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 48.3600%
01/03 05:00:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 05:00:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][100/703]	Step 46792	lr 0.01788	Loss 1.1289 (1.3596)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.5%)	
01/03 05:00:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][200/703]	Step 46892	lr 0.01788	Loss 1.4444 (1.3633)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.2%)	
01/03 05:00:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][300/703]	Step 46992	lr 0.01788	Loss 1.8735 (1.3774)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.0%)	
01/03 05:01:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][400/703]	Step 47092	lr 0.01788	Loss 1.2385 (1.3866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 87.8%)	
01/03 05:01:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][500/703]	Step 47192	lr 0.01788	Loss 1.7084 (1.3979)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.6%)	
01/03 05:01:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][600/703]	Step 47292	lr 0.01788	Loss 1.8597 (1.4074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.8%, 87.5%)	
01/03 05:01:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][700/703]	Step 47392	lr 0.01788	Loss 1.3607 (1.4133)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 87.4%)	
01/03 05:01:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][703/703]	Step 47395	lr 0.01788	Loss 1.3535 (1.4138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 87.4%)	
01/03 05:01:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 93/149] Final Prec@1 59.6689%
01/03 05:01:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][78/79]	Step 47396	Loss 1.9851	Prec@(1,5) (47.4%, 78.5%)
01/03 05:01:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 47.3800%
01/03 05:01:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 05:01:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][100/703]	Step 47496	lr 0.0175	Loss 1.4173 (1.3214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 88.9%)	
01/03 05:01:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][200/703]	Step 47596	lr 0.0175	Loss 1.1500 (1.3302)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.0%)	
01/03 05:02:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][300/703]	Step 47696	lr 0.0175	Loss 1.8459 (1.3481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.8%)	
01/03 05:02:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][400/703]	Step 47796	lr 0.0175	Loss 1.3209 (1.3596)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.6%)	
01/03 05:02:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][500/703]	Step 47896	lr 0.0175	Loss 1.1103 (1.3696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.3%)	
01/03 05:02:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][600/703]	Step 47996	lr 0.0175	Loss 1.3781 (1.3865)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.0%)	
01/03 05:02:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][700/703]	Step 48096	lr 0.0175	Loss 1.2689 (1.3976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 87.8%)	
01/03 05:02:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][703/703]	Step 48099	lr 0.0175	Loss 1.4850 (1.3977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 87.8%)	
01/03 05:02:36午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 94/149] Final Prec@1 59.9244%
01/03 05:02:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][78/79]	Step 48100	Loss 2.1431	Prec@(1,5) (45.3%, 76.6%)
01/03 05:02:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 45.2600%
01/03 05:02:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 05:02:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][100/703]	Step 48200	lr 0.0171	Loss 1.3129 (1.3322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.6%)	
01/03 05:02:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][200/703]	Step 48300	lr 0.0171	Loss 1.3616 (1.3361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.5%)	
01/03 05:03:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][300/703]	Step 48400	lr 0.0171	Loss 1.3612 (1.3453)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.6%)	
01/03 05:03:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][400/703]	Step 48500	lr 0.0171	Loss 1.4223 (1.3611)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.4%)	
01/03 05:03:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][500/703]	Step 48600	lr 0.0171	Loss 1.4612 (1.3699)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.2%)	
01/03 05:03:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][600/703]	Step 48700	lr 0.0171	Loss 1.5799 (1.3688)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.3%)	
01/03 05:03:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][700/703]	Step 48800	lr 0.0171	Loss 1.7245 (1.3674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.3%)	
01/03 05:03:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][703/703]	Step 48803	lr 0.0171	Loss 1.3916 (1.3673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.3%)	
01/03 05:03:41午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 95/149] Final Prec@1 60.8067%
01/03 05:03:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][78/79]	Step 48804	Loss 2.1353	Prec@(1,5) (44.8%, 76.5%)
01/03 05:03:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 44.8400%
01/03 05:03:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 05:03:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][100/703]	Step 48904	lr 0.01671	Loss 1.2960 (1.2838)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.2%)	
01/03 05:04:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][200/703]	Step 49004	lr 0.01671	Loss 1.0241 (1.2964)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.0%)	
01/03 05:04:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][300/703]	Step 49104	lr 0.01671	Loss 1.2698 (1.3049)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.0%)	
01/03 05:04:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][400/703]	Step 49204	lr 0.01671	Loss 1.6423 (1.3129)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.0%)	
01/03 05:04:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][500/703]	Step 49304	lr 0.01671	Loss 0.9814 (1.3282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.6%)	
01/03 05:04:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][600/703]	Step 49404	lr 0.01671	Loss 1.2066 (1.3410)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.4%)	
01/03 05:04:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][700/703]	Step 49504	lr 0.01671	Loss 1.4374 (1.3481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.4%)	
01/03 05:04:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][703/703]	Step 49507	lr 0.01671	Loss 1.4698 (1.3487)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.4%)	
01/03 05:04:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 96/149] Final Prec@1 61.3022%
01/03 05:04:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][78/79]	Step 49508	Loss 1.8633	Prec@(1,5) (50.5%, 80.2%)
01/03 05:04:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 50.4800%
01/03 05:04:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.7760%
01/03 05:04:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][100/703]	Step 49608	lr 0.01631	Loss 1.2351 (1.2623)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.6%, 90.2%)	
01/03 05:05:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][200/703]	Step 49708	lr 0.01631	Loss 1.6918 (1.2719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.0%)	
01/03 05:05:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][300/703]	Step 49808	lr 0.01631	Loss 1.0777 (1.2916)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.6%)	
01/03 05:05:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][400/703]	Step 49908	lr 0.01631	Loss 1.1653 (1.3036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.4%)	
01/03 05:05:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][500/703]	Step 50008	lr 0.01631	Loss 1.3477 (1.3082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.3%)	
01/03 05:05:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][600/703]	Step 50108	lr 0.01631	Loss 1.4971 (1.3237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.0%)	
01/03 05:05:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][700/703]	Step 50208	lr 0.01631	Loss 1.4255 (1.3288)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 88.9%)	
01/03 05:05:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][703/703]	Step 50211	lr 0.01631	Loss 1.5059 (1.3288)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 88.9%)	
01/03 05:05:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 97/149] Final Prec@1 61.7822%
01/03 05:05:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][78/79]	Step 50212	Loss 1.7489	Prec@(1,5) (52.3%, 82.4%)
01/03 05:05:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 52.2400%
01/03 05:05:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.2400%
01/03 05:06:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][100/703]	Step 50312	lr 0.0159	Loss 1.3069 (1.2680)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.6%)	
01/03 05:06:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][200/703]	Step 50412	lr 0.0159	Loss 1.2074 (1.2672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 89.8%)	
01/03 05:06:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][300/703]	Step 50512	lr 0.0159	Loss 1.0672 (1.2794)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.5%)	
01/03 05:06:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][400/703]	Step 50612	lr 0.0159	Loss 1.4330 (1.2921)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.4%)	
01/03 05:06:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][500/703]	Step 50712	lr 0.0159	Loss 1.1096 (1.2958)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.3%)	
01/03 05:06:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][600/703]	Step 50812	lr 0.0159	Loss 0.9836 (1.2985)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.3%)	
01/03 05:06:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][700/703]	Step 50912	lr 0.0159	Loss 1.3534 (1.3079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.1%)	
01/03 05:06:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][703/703]	Step 50915	lr 0.0159	Loss 1.3732 (1.3078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.1%)	
01/03 05:06:54午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 98/149] Final Prec@1 62.1689%
01/03 05:06:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][78/79]	Step 50916	Loss 1.8613	Prec@(1,5) (51.6%, 80.4%)
01/03 05:06:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 51.6400%
01/03 05:06:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.2400%
01/03 05:07:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][100/703]	Step 51016	lr 0.01549	Loss 1.4378 (1.2296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.4%)	
01/03 05:07:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][200/703]	Step 51116	lr 0.01549	Loss 1.2059 (1.2357)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.3%)	
01/03 05:07:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][300/703]	Step 51216	lr 0.01549	Loss 1.3763 (1.2492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.1%)	
01/03 05:07:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][400/703]	Step 51316	lr 0.01549	Loss 1.1059 (1.2553)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.1%)	
01/03 05:07:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][500/703]	Step 51416	lr 0.01549	Loss 1.1253 (1.2670)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.0%)	
01/03 05:07:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][600/703]	Step 51516	lr 0.01549	Loss 1.1911 (1.2714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.9%)	
01/03 05:07:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][700/703]	Step 51616	lr 0.01549	Loss 1.2404 (1.2847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.6%)	
01/03 05:07:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][703/703]	Step 51619	lr 0.01549	Loss 1.2470 (1.2848)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.6%)	
01/03 05:07:58午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 99/149] Final Prec@1 62.8622%
01/03 05:08:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][78/79]	Step 51620	Loss 1.8720	Prec@(1,5) (50.6%, 80.3%)
01/03 05:08:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 50.6000%
01/03 05:08:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.2400%
01/03 05:08:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][100/703]	Step 51720	lr 0.01508	Loss 1.3551 (1.2057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.7%)	
01/03 05:08:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][200/703]	Step 51820	lr 0.01508	Loss 1.8554 (1.2272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.3%)	
01/03 05:08:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][300/703]	Step 51920	lr 0.01508	Loss 1.4046 (1.2423)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
01/03 05:08:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][400/703]	Step 52020	lr 0.01508	Loss 1.4050 (1.2588)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.8%)	
01/03 05:08:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][500/703]	Step 52120	lr 0.01508	Loss 1.2391 (1.2602)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.7%)	
01/03 05:08:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][600/703]	Step 52220	lr 0.01508	Loss 1.5896 (1.2672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.6%)	
01/03 05:09:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][700/703]	Step 52320	lr 0.01508	Loss 1.2956 (1.2736)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.5%)	
01/03 05:09:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][703/703]	Step 52323	lr 0.01508	Loss 1.1048 (1.2729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.5%)	
01/03 05:09:03午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [100/149] Final Prec@1 63.1578%
01/03 05:09:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][78/79]	Step 52324	Loss 1.9089	Prec@(1,5) (50.5%, 80.5%)
01/03 05:09:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 50.4800%
01/03 05:09:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.2400%
01/03 05:09:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][100/703]	Step 52424	lr 0.01467	Loss 1.0848 (1.1812)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.9%)	
01/03 05:09:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][200/703]	Step 52524	lr 0.01467	Loss 1.0555 (1.2005)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.7%)	
01/03 05:09:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][300/703]	Step 52624	lr 0.01467	Loss 1.1343 (1.2116)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.5%)	
01/03 05:09:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][400/703]	Step 52724	lr 0.01467	Loss 1.1236 (1.2179)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
01/03 05:09:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][500/703]	Step 52824	lr 0.01467	Loss 1.4082 (1.2274)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.3%)	
01/03 05:09:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][600/703]	Step 52924	lr 0.01467	Loss 1.3691 (1.2438)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.0%)	
01/03 05:10:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][700/703]	Step 53024	lr 0.01467	Loss 1.2592 (1.2441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
01/03 05:10:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][703/703]	Step 53027	lr 0.01467	Loss 1.1271 (1.2447)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
01/03 05:10:07午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [101/149] Final Prec@1 63.8578%
01/03 05:10:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][78/79]	Step 53028	Loss 1.7847	Prec@(1,5) (52.6%, 81.8%)
01/03 05:10:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 52.4800%
01/03 05:10:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.4800%
01/03 05:10:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][100/703]	Step 53128	lr 0.01425	Loss 1.2386 (1.1889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.9%)	
01/03 05:10:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][200/703]	Step 53228	lr 0.01425	Loss 1.1843 (1.1671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.2%)	
01/03 05:10:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][300/703]	Step 53328	lr 0.01425	Loss 1.1532 (1.1846)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.9%)	
01/03 05:10:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][400/703]	Step 53428	lr 0.01425	Loss 1.0261 (1.1869)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.8%)	
01/03 05:10:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][500/703]	Step 53528	lr 0.01425	Loss 1.4178 (1.1913)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.8%)	
01/03 05:11:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][600/703]	Step 53628	lr 0.01425	Loss 1.4460 (1.2042)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.6%)	
01/03 05:11:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][700/703]	Step 53728	lr 0.01425	Loss 1.2331 (1.2142)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.5%)	
01/03 05:11:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][703/703]	Step 53731	lr 0.01425	Loss 1.3050 (1.2143)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.5%)	
01/03 05:11:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [102/149] Final Prec@1 64.6356%
01/03 05:11:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][78/79]	Step 53732	Loss 1.9467	Prec@(1,5) (49.6%, 79.8%)
01/03 05:11:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 49.6600%
01/03 05:11:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.4800%
01/03 05:11:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][100/703]	Step 53832	lr 0.01384	Loss 1.0503 (1.1522)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.5%)	
01/03 05:11:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][200/703]	Step 53932	lr 0.01384	Loss 1.1359 (1.1559)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.4%)	
01/03 05:11:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][300/703]	Step 54032	lr 0.01384	Loss 1.3170 (1.1677)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.3%)	
01/03 05:11:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][400/703]	Step 54132	lr 0.01384	Loss 1.0746 (1.1709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.2%)	
01/03 05:11:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][500/703]	Step 54232	lr 0.01384	Loss 1.0948 (1.1862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.9%)	
01/03 05:12:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][600/703]	Step 54332	lr 0.01384	Loss 1.2752 (1.1911)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.8%)	
01/03 05:12:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][700/703]	Step 54432	lr 0.01384	Loss 1.3211 (1.1978)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.8%)	
01/03 05:12:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][703/703]	Step 54435	lr 0.01384	Loss 1.4016 (1.1980)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.7%)	
01/03 05:12:16午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [103/149] Final Prec@1 64.9089%
01/03 05:12:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][78/79]	Step 54436	Loss 1.8132	Prec@(1,5) (52.5%, 82.2%)
01/03 05:12:19午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 52.5600%
01/03 05:12:19午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.5600%
01/03 05:12:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][100/703]	Step 54536	lr 0.01342	Loss 1.1713 (1.1166)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 91.6%)	
01/03 05:12:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][200/703]	Step 54636	lr 0.01342	Loss 1.1055 (1.1414)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.4%)	
01/03 05:12:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][300/703]	Step 54736	lr 0.01342	Loss 1.0421 (1.1396)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.5%)	
01/03 05:12:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][400/703]	Step 54836	lr 0.01342	Loss 1.1844 (1.1579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.2%)	
01/03 05:13:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][500/703]	Step 54936	lr 0.01342	Loss 1.1919 (1.1674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.0%)	
01/03 05:13:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][600/703]	Step 55036	lr 0.01342	Loss 1.0263 (1.1772)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.0%)	
01/03 05:13:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][700/703]	Step 55136	lr 0.01342	Loss 1.2292 (1.1853)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 90.9%)	
01/03 05:13:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][703/703]	Step 55139	lr 0.01342	Loss 1.3336 (1.1855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 90.8%)	
01/03 05:13:21午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [104/149] Final Prec@1 65.6200%
01/03 05:13:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][78/79]	Step 55140	Loss 1.7692	Prec@(1,5) (52.7%, 82.3%)
01/03 05:13:23午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 52.7000%
01/03 05:13:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.7000%
01/03 05:13:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][100/703]	Step 55240	lr 0.013	Loss 0.9973 (1.1203)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.8%)	
01/03 05:13:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][200/703]	Step 55340	lr 0.013	Loss 1.3094 (1.1185)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.9%)	
01/03 05:13:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][300/703]	Step 55440	lr 0.013	Loss 0.9911 (1.1183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.9%)	
01/03 05:13:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][400/703]	Step 55540	lr 0.013	Loss 1.2713 (1.1295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.7%)	
01/03 05:14:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][500/703]	Step 55640	lr 0.013	Loss 1.3880 (1.1409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.5%)	
01/03 05:14:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][600/703]	Step 55740	lr 0.013	Loss 0.9528 (1.1498)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.4%)	
01/03 05:14:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][700/703]	Step 55840	lr 0.013	Loss 1.0785 (1.1574)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.3%)	
01/03 05:14:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][703/703]	Step 55843	lr 0.013	Loss 0.8807 (1.1579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.3%)	
01/03 05:14:25午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [105/149] Final Prec@1 66.1756%
01/03 05:14:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][78/79]	Step 55844	Loss 1.7785	Prec@(1,5) (52.3%, 82.4%)
01/03 05:14:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 52.2800%
01/03 05:14:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.7000%
01/03 05:14:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][100/703]	Step 55944	lr 0.01258	Loss 1.1780 (1.0749)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.5%)	
01/03 05:14:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][200/703]	Step 56044	lr 0.01258	Loss 1.1587 (1.0855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.1%)	
01/03 05:14:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][300/703]	Step 56144	lr 0.01258	Loss 1.3472 (1.1032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.9%)	
01/03 05:15:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][400/703]	Step 56244	lr 0.01258	Loss 1.1598 (1.1104)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 91.7%)	
01/03 05:15:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][500/703]	Step 56344	lr 0.01258	Loss 1.1089 (1.1246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.5%)	
01/03 05:15:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][600/703]	Step 56444	lr 0.01258	Loss 1.2364 (1.1303)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.5%)	
01/03 05:15:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][700/703]	Step 56544	lr 0.01258	Loss 1.2001 (1.1355)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.4%)	
01/03 05:15:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][703/703]	Step 56547	lr 0.01258	Loss 1.1009 (1.1354)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.4%)	
01/03 05:15:30午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [106/149] Final Prec@1 66.5111%
01/03 05:15:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][78/79]	Step 56548	Loss 1.7625	Prec@(1,5) (53.0%, 82.5%)
01/03 05:15:32午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 53.0600%
01/03 05:15:32午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.0600%
01/03 05:15:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][100/703]	Step 56648	lr 0.01216	Loss 1.1230 (1.0478)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.9%)	
01/03 05:15:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][200/703]	Step 56748	lr 0.01216	Loss 0.9341 (1.0823)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.4%)	
01/03 05:15:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][300/703]	Step 56848	lr 0.01216	Loss 0.9365 (1.0960)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.1%)	
01/03 05:16:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][400/703]	Step 56948	lr 0.01216	Loss 1.4174 (1.0998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.1%)	
01/03 05:16:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][500/703]	Step 57048	lr 0.01216	Loss 1.2344 (1.0992)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.1%)	
01/03 05:16:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][600/703]	Step 57148	lr 0.01216	Loss 1.4700 (1.1118)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.9%)	
01/03 05:16:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][700/703]	Step 57248	lr 0.01216	Loss 1.0264 (1.1171)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
01/03 05:16:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][703/703]	Step 57251	lr 0.01216	Loss 1.2076 (1.1177)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
01/03 05:16:34午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [107/149] Final Prec@1 67.2267%
01/03 05:16:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][78/79]	Step 57252	Loss 1.8309	Prec@(1,5) (52.0%, 81.8%)
01/03 05:16:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 52.0400%
01/03 05:16:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.0600%
01/03 05:16:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][100/703]	Step 57352	lr 0.01175	Loss 1.1230 (0.9716)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 94.1%)	
01/03 05:16:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][200/703]	Step 57452	lr 0.01175	Loss 1.0321 (1.0100)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.2%)	
01/03 05:17:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][300/703]	Step 57552	lr 0.01175	Loss 0.9475 (1.0337)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.9%)	
01/03 05:17:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][400/703]	Step 57652	lr 0.01175	Loss 1.2356 (1.0499)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.7%)	
01/03 05:17:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][500/703]	Step 57752	lr 0.01175	Loss 0.9583 (1.0694)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.4%)	
01/03 05:17:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][600/703]	Step 57852	lr 0.01175	Loss 1.2463 (1.0803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.3%)	
01/03 05:17:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][700/703]	Step 57952	lr 0.01175	Loss 0.9066 (1.0843)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.3%)	
01/03 05:17:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][703/703]	Step 57955	lr 0.01175	Loss 1.1009 (1.0843)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.3%)	
01/03 05:17:39午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [108/149] Final Prec@1 68.0556%
01/03 05:17:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][78/79]	Step 57956	Loss 1.7066	Prec@(1,5) (55.0%, 83.3%)
01/03 05:17:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 55.0000%
01/03 05:17:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:17:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][100/703]	Step 58056	lr 0.01133	Loss 1.1347 (1.0120)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.1%)	
01/03 05:17:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][200/703]	Step 58156	lr 0.01133	Loss 1.3165 (1.0270)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.9%)	
01/03 05:18:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][300/703]	Step 58256	lr 0.01133	Loss 0.8530 (1.0307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.9%)	
01/03 05:18:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][400/703]	Step 58356	lr 0.01133	Loss 0.9826 (1.0460)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.8%)	
01/03 05:18:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][500/703]	Step 58456	lr 0.01133	Loss 1.5792 (1.0518)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
01/03 05:18:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][600/703]	Step 58556	lr 0.01133	Loss 1.1645 (1.0545)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
01/03 05:18:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][700/703]	Step 58656	lr 0.01133	Loss 1.2188 (1.0620)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.5%)	
01/03 05:18:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][703/703]	Step 58659	lr 0.01133	Loss 0.9064 (1.0617)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.5%)	
01/03 05:18:43午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [109/149] Final Prec@1 68.2311%
01/03 05:18:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][78/79]	Step 58660	Loss 1.6894	Prec@(1,5) (54.7%, 84.5%)
01/03 05:18:46午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 54.6600%
01/03 05:18:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:18:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][100/703]	Step 58760	lr 0.01092	Loss 0.8675 (0.9766)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 93.4%)	
01/03 05:19:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][200/703]	Step 58860	lr 0.01092	Loss 0.9938 (0.9855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.4%)	
01/03 05:19:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][300/703]	Step 58960	lr 0.01092	Loss 1.3387 (1.0000)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.2%)	
01/03 05:19:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][400/703]	Step 59060	lr 0.01092	Loss 1.2763 (1.0160)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.1%)	
01/03 05:19:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][500/703]	Step 59160	lr 0.01092	Loss 0.7844 (1.0279)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.9%)	
01/03 05:19:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][600/703]	Step 59260	lr 0.01092	Loss 1.1182 (1.0365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.8%)	
01/03 05:19:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][700/703]	Step 59360	lr 0.01092	Loss 1.1965 (1.0420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.8%)	
01/03 05:19:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][703/703]	Step 59363	lr 0.01092	Loss 1.1202 (1.0421)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.8%)	
01/03 05:19:48午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [110/149] Final Prec@1 69.1533%
01/03 05:19:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][78/79]	Step 59364	Loss 1.7613	Prec@(1,5) (53.9%, 83.4%)
01/03 05:19:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 53.9000%
01/03 05:19:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:20:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][100/703]	Step 59464	lr 0.01051	Loss 0.7026 (0.9891)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.5%)	
01/03 05:20:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][200/703]	Step 59564	lr 0.01051	Loss 1.2536 (0.9757)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.6%)	
01/03 05:20:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][300/703]	Step 59664	lr 0.01051	Loss 1.2035 (0.9886)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.5%)	
01/03 05:20:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][400/703]	Step 59764	lr 0.01051	Loss 0.8870 (0.9939)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
01/03 05:20:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][500/703]	Step 59864	lr 0.01051	Loss 0.9588 (1.0019)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.3%)	
01/03 05:20:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][600/703]	Step 59964	lr 0.01051	Loss 1.0508 (1.0125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.2%)	
01/03 05:20:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][700/703]	Step 60064	lr 0.01051	Loss 1.3245 (1.0205)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.0%)	
01/03 05:20:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][703/703]	Step 60067	lr 0.01051	Loss 1.0419 (1.0203)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.0%)	
01/03 05:20:52午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [111/149] Final Prec@1 69.8000%
01/03 05:20:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][78/79]	Step 60068	Loss 1.8107	Prec@(1,5) (52.9%, 82.4%)
01/03 05:20:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 52.9400%
01/03 05:20:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:21:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][100/703]	Step 60168	lr 0.0101	Loss 1.0634 (0.9316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 93.9%)	
01/03 05:21:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][200/703]	Step 60268	lr 0.0101	Loss 1.0170 (0.9397)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 93.9%)	
01/03 05:21:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][300/703]	Step 60368	lr 0.0101	Loss 1.0096 (0.9514)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.8%)	
01/03 05:21:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][400/703]	Step 60468	lr 0.0101	Loss 1.1167 (0.9593)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.7%)	
01/03 05:21:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][500/703]	Step 60568	lr 0.0101	Loss 1.0188 (0.9625)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.7%)	
01/03 05:21:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][600/703]	Step 60668	lr 0.0101	Loss 1.0773 (0.9769)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.6%)	
01/03 05:21:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][700/703]	Step 60768	lr 0.0101	Loss 1.1035 (0.9873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.5%)	
01/03 05:21:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][703/703]	Step 60771	lr 0.0101	Loss 0.8766 (0.9869)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.5%)	
01/03 05:21:57午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [112/149] Final Prec@1 70.3889%
01/03 05:21:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][78/79]	Step 60772	Loss 1.9212	Prec@(1,5) (50.9%, 80.6%)
01/03 05:21:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 50.8800%
01/03 05:21:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:22:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][100/703]	Step 60872	lr 0.00969	Loss 0.8460 (0.9233)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.1%)	
01/03 05:22:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][200/703]	Step 60972	lr 0.00969	Loss 1.0542 (0.9347)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.0%)	
01/03 05:22:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][300/703]	Step 61072	lr 0.00969	Loss 0.6796 (0.9497)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.8%)	
01/03 05:22:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][400/703]	Step 61172	lr 0.00969	Loss 0.9585 (0.9520)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.8%)	
01/03 05:22:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][500/703]	Step 61272	lr 0.00969	Loss 1.2380 (0.9577)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.8%)	
01/03 05:22:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][600/703]	Step 61372	lr 0.00969	Loss 0.9784 (0.9650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.7%)	
01/03 05:23:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][700/703]	Step 61472	lr 0.00969	Loss 1.1438 (0.9672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.6%)	
01/03 05:23:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][703/703]	Step 61475	lr 0.00969	Loss 0.8346 (0.9671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.6%)	
01/03 05:23:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [113/149] Final Prec@1 71.0067%
01/03 05:23:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][78/79]	Step 61476	Loss 1.7477	Prec@(1,5) (54.8%, 83.3%)
01/03 05:23:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 54.8600%
01/03 05:23:04午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:23:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][100/703]	Step 61576	lr 0.00929	Loss 1.0973 (0.9040)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.2%)	
01/03 05:23:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][200/703]	Step 61676	lr 0.00929	Loss 0.6924 (0.9154)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 93.9%)	
01/03 05:23:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][300/703]	Step 61776	lr 0.00929	Loss 0.8817 (0.9145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.2%)	
01/03 05:23:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][400/703]	Step 61876	lr 0.00929	Loss 0.8835 (0.9261)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.2%)	
01/03 05:23:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][500/703]	Step 61976	lr 0.00929	Loss 1.0218 (0.9345)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.1%)	
01/03 05:23:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][600/703]	Step 62076	lr 0.00929	Loss 0.8718 (0.9455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.0%)	
01/03 05:24:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][700/703]	Step 62176	lr 0.00929	Loss 0.8809 (0.9524)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.9%)	
01/03 05:24:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][703/703]	Step 62179	lr 0.00929	Loss 0.7252 (0.9523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.9%)	
01/03 05:24:06午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [114/149] Final Prec@1 71.5600%
01/03 05:24:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][78/79]	Step 62180	Loss 1.8419	Prec@(1,5) (53.3%, 82.0%)
01/03 05:24:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 53.2800%
01/03 05:24:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:24:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][100/703]	Step 62280	lr 0.0089	Loss 1.0317 (0.8660)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.9%)	
01/03 05:24:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][200/703]	Step 62380	lr 0.0089	Loss 1.0744 (0.8745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.7%)	
01/03 05:24:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][300/703]	Step 62480	lr 0.0089	Loss 1.0196 (0.8852)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.7%)	
01/03 05:24:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][400/703]	Step 62580	lr 0.0089	Loss 0.9772 (0.8955)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.5%)	
01/03 05:24:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][500/703]	Step 62680	lr 0.0089	Loss 0.8481 (0.9028)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.5%)	
01/03 05:25:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][600/703]	Step 62780	lr 0.0089	Loss 0.8349 (0.9086)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.4%)	
01/03 05:25:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][700/703]	Step 62880	lr 0.0089	Loss 1.2610 (0.9172)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
01/03 05:25:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][703/703]	Step 62883	lr 0.0089	Loss 1.1018 (0.9183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.2%)	
01/03 05:25:10午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [115/149] Final Prec@1 72.3911%
01/03 05:25:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][78/79]	Step 62884	Loss 1.7674	Prec@(1,5) (54.7%, 83.3%)
01/03 05:25:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 54.7200%
01/03 05:25:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:25:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][100/703]	Step 62984	lr 0.0085	Loss 0.7183 (0.8430)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.3%)	
01/03 05:25:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][200/703]	Step 63084	lr 0.0085	Loss 0.7589 (0.8504)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
01/03 05:25:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][300/703]	Step 63184	lr 0.0085	Loss 0.9455 (0.8652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
01/03 05:25:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][400/703]	Step 63284	lr 0.0085	Loss 0.6178 (0.8720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.9%)	
01/03 05:25:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][500/703]	Step 63384	lr 0.0085	Loss 0.7998 (0.8729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
01/03 05:26:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][600/703]	Step 63484	lr 0.0085	Loss 0.9929 (0.8840)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.7%)	
01/03 05:26:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][700/703]	Step 63584	lr 0.0085	Loss 0.6091 (0.8930)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.6%)	
01/03 05:26:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][703/703]	Step 63587	lr 0.0085	Loss 0.8079 (0.8922)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.6%)	
01/03 05:26:15午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [116/149] Final Prec@1 73.1289%
01/03 05:26:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][78/79]	Step 63588	Loss 1.7474	Prec@(1,5) (55.0%, 83.1%)
01/03 05:26:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 54.9600%
01/03 05:26:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0000%
01/03 05:26:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][100/703]	Step 63688	lr 0.00812	Loss 0.7216 (0.8325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 94.9%)	
01/03 05:26:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][200/703]	Step 63788	lr 0.00812	Loss 0.7200 (0.8451)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 94.9%)	
01/03 05:26:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][300/703]	Step 63888	lr 0.00812	Loss 0.9371 (0.8391)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.0%)	
01/03 05:26:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][400/703]	Step 63988	lr 0.00812	Loss 0.9746 (0.8529)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 94.9%)	
01/03 05:27:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][500/703]	Step 64088	lr 0.00812	Loss 1.0524 (0.8567)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 94.8%)	
01/03 05:27:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][600/703]	Step 64188	lr 0.00812	Loss 0.8539 (0.8582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 94.8%)	
01/03 05:27:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][700/703]	Step 64288	lr 0.00812	Loss 0.7793 (0.8622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
01/03 05:27:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][703/703]	Step 64291	lr 0.00812	Loss 0.8607 (0.8629)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
01/03 05:27:19午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [117/149] Final Prec@1 74.0311%
01/03 05:27:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][78/79]	Step 64292	Loss 1.6649	Prec@(1,5) (57.0%, 84.9%)
01/03 05:27:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 56.9800%
01/03 05:27:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.9800%
01/03 05:27:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][100/703]	Step 64392	lr 0.00774	Loss 0.7233 (0.7733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.9%)	
01/03 05:27:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][200/703]	Step 64492	lr 0.00774	Loss 0.8221 (0.7985)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.6%)	
01/03 05:27:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][300/703]	Step 64592	lr 0.00774	Loss 0.8558 (0.8060)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.5%)	
01/03 05:27:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][400/703]	Step 64692	lr 0.00774	Loss 0.6941 (0.8176)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.4%)	
01/03 05:28:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][500/703]	Step 64792	lr 0.00774	Loss 0.8356 (0.8268)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.3%)	
01/03 05:28:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][600/703]	Step 64892	lr 0.00774	Loss 0.9302 (0.8366)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
01/03 05:28:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][700/703]	Step 64992	lr 0.00774	Loss 0.6865 (0.8429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.1%)	
01/03 05:28:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][703/703]	Step 64995	lr 0.00774	Loss 0.6264 (0.8428)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.1%)	
01/03 05:28:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [118/149] Final Prec@1 74.2556%
01/03 05:28:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][78/79]	Step 64996	Loss 1.6378	Prec@(1,5) (57.0%, 85.3%)
01/03 05:28:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 57.0400%
01/03 05:28:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
01/03 05:28:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][100/703]	Step 65096	lr 0.00737	Loss 0.6352 (0.7674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.0%)	
01/03 05:28:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][200/703]	Step 65196	lr 0.00737	Loss 0.7735 (0.7652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.9%)	
01/03 05:28:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][300/703]	Step 65296	lr 0.00737	Loss 0.6128 (0.7796)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.8%)	
01/03 05:29:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][400/703]	Step 65396	lr 0.00737	Loss 0.7763 (0.7866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.7%)	
01/03 05:29:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][500/703]	Step 65496	lr 0.00737	Loss 0.7621 (0.8004)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.6%)	
01/03 05:29:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][600/703]	Step 65596	lr 0.00737	Loss 0.8331 (0.8057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.5%)	
01/03 05:29:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][700/703]	Step 65696	lr 0.00737	Loss 0.8645 (0.8136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.3%)	
01/03 05:29:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][703/703]	Step 65699	lr 0.00737	Loss 0.7598 (0.8136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.3%)	
01/03 05:29:29午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [119/149] Final Prec@1 75.2978%
01/03 05:29:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][78/79]	Step 65700	Loss 1.7024	Prec@(1,5) (56.9%, 84.3%)
01/03 05:29:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 56.8600%
01/03 05:29:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
01/03 05:29:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][100/703]	Step 65800	lr 0.007	Loss 0.4264 (0.7515)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.1%)	
01/03 05:29:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][200/703]	Step 65900	lr 0.007	Loss 0.7773 (0.7571)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 95.8%)	
01/03 05:29:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][300/703]	Step 66000	lr 0.007	Loss 0.5930 (0.7678)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.8%)	
01/03 05:30:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][400/703]	Step 66100	lr 0.007	Loss 0.5153 (0.7709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.7%)	
01/03 05:30:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][500/703]	Step 66200	lr 0.007	Loss 0.9510 (0.7754)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.8%)	
01/03 05:30:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][600/703]	Step 66300	lr 0.007	Loss 0.7275 (0.7800)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.6%)	
01/03 05:30:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][700/703]	Step 66400	lr 0.007	Loss 0.6143 (0.7893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.5%)	
01/03 05:30:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][703/703]	Step 66403	lr 0.007	Loss 1.3452 (0.7903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.5%)	
01/03 05:30:33午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [120/149] Final Prec@1 75.8933%
01/03 05:30:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][78/79]	Step 66404	Loss 1.7033	Prec@(1,5) (56.4%, 84.6%)
01/03 05:30:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 56.3400%
01/03 05:30:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
01/03 05:30:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][100/703]	Step 66504	lr 0.00664	Loss 0.7921 (0.7117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.3%)	
01/03 05:30:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][200/703]	Step 66604	lr 0.00664	Loss 0.9191 (0.7231)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
01/03 05:31:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][300/703]	Step 66704	lr 0.00664	Loss 0.8977 (0.7285)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.3%)	
01/03 05:31:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][400/703]	Step 66804	lr 0.00664	Loss 0.7061 (0.7412)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
01/03 05:31:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][500/703]	Step 66904	lr 0.00664	Loss 0.7805 (0.7467)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.2%)	
01/03 05:31:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][600/703]	Step 67004	lr 0.00664	Loss 0.7537 (0.7524)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.1%)	
01/03 05:31:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][700/703]	Step 67104	lr 0.00664	Loss 0.6861 (0.7570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
01/03 05:31:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][703/703]	Step 67107	lr 0.00664	Loss 0.7700 (0.7566)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
01/03 05:31:38午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [121/149] Final Prec@1 76.8889%
01/03 05:31:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][78/79]	Step 67108	Loss 1.7348	Prec@(1,5) (56.5%, 84.5%)
01/03 05:31:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 56.4200%
01/03 05:31:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0400%
01/03 05:31:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][100/703]	Step 67208	lr 0.00629	Loss 0.3929 (0.6749)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
01/03 05:31:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][200/703]	Step 67308	lr 0.00629	Loss 0.4330 (0.6822)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.7%)	
01/03 05:32:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][300/703]	Step 67408	lr 0.00629	Loss 0.6428 (0.6934)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.6%)	
01/03 05:32:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][400/703]	Step 67508	lr 0.00629	Loss 0.7280 (0.7013)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.5%)	
01/03 05:32:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][500/703]	Step 67608	lr 0.00629	Loss 0.9335 (0.7141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
01/03 05:32:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][600/703]	Step 67708	lr 0.00629	Loss 1.0850 (0.7246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.3%)	
01/03 05:32:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][700/703]	Step 67808	lr 0.00629	Loss 0.8002 (0.7310)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.2%)	
01/03 05:32:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][703/703]	Step 67811	lr 0.00629	Loss 0.7844 (0.7308)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.2%)	
01/03 05:32:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [122/149] Final Prec@1 77.8022%
01/03 05:32:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][78/79]	Step 67812	Loss 1.6740	Prec@(1,5) (57.9%, 84.6%)
01/03 05:32:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 57.8800%
01/03 05:32:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.8800%
01/03 05:32:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][100/703]	Step 67912	lr 0.00595	Loss 0.5149 (0.6636)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.8%)	
01/03 05:33:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][200/703]	Step 68012	lr 0.00595	Loss 0.4727 (0.6637)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.8%)	
01/03 05:33:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][300/703]	Step 68112	lr 0.00595	Loss 0.7342 (0.6716)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.8%)	
01/03 05:33:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][400/703]	Step 68212	lr 0.00595	Loss 0.7289 (0.6844)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.6%)	
01/03 05:33:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][500/703]	Step 68312	lr 0.00595	Loss 0.5957 (0.6894)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
01/03 05:33:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][600/703]	Step 68412	lr 0.00595	Loss 0.8160 (0.6949)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.6%)	
01/03 05:33:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][700/703]	Step 68512	lr 0.00595	Loss 0.7714 (0.7032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
01/03 05:33:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][703/703]	Step 68515	lr 0.00595	Loss 0.6489 (0.7034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
01/03 05:33:47午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [123/149] Final Prec@1 78.3978%
01/03 05:33:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][78/79]	Step 68516	Loss 1.6654	Prec@(1,5) (57.4%, 85.2%)
01/03 05:33:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 57.3600%
01/03 05:33:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.8800%
01/03 05:33:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][100/703]	Step 68616	lr 0.00561	Loss 0.6099 (0.6518)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.0%)	
01/03 05:34:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][200/703]	Step 68716	lr 0.00561	Loss 0.5950 (0.6529)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
01/03 05:34:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][300/703]	Step 68816	lr 0.00561	Loss 0.6475 (0.6579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
01/03 05:34:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][400/703]	Step 68916	lr 0.00561	Loss 0.7251 (0.6593)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.9%)	
01/03 05:34:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][500/703]	Step 69016	lr 0.00561	Loss 1.1887 (0.6638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.8%)	
01/03 05:34:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][600/703]	Step 69116	lr 0.00561	Loss 0.6595 (0.6698)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.7%)	
01/03 05:34:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][700/703]	Step 69216	lr 0.00561	Loss 0.8211 (0.6749)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.7%)	
01/03 05:34:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][703/703]	Step 69219	lr 0.00561	Loss 0.6243 (0.6750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.7%)	
01/03 05:34:51午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [124/149] Final Prec@1 79.3756%
01/03 05:34:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][78/79]	Step 69220	Loss 1.6451	Prec@(1,5) (58.3%, 85.8%)
01/03 05:34:54午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 58.2600%
01/03 05:34:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.2600%
01/03 05:35:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][100/703]	Step 69320	lr 0.00529	Loss 0.6511 (0.6047)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
01/03 05:35:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][200/703]	Step 69420	lr 0.00529	Loss 0.7945 (0.6137)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.4%)	
01/03 05:35:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][300/703]	Step 69520	lr 0.00529	Loss 0.6277 (0.6229)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.3%)	
01/03 05:35:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][400/703]	Step 69620	lr 0.00529	Loss 0.5553 (0.6316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
01/03 05:35:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][500/703]	Step 69720	lr 0.00529	Loss 0.5912 (0.6400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.0%)	
01/03 05:35:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][600/703]	Step 69820	lr 0.00529	Loss 0.7755 (0.6438)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
01/03 05:35:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][700/703]	Step 69920	lr 0.00529	Loss 0.4010 (0.6475)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.0%)	
01/03 05:35:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][703/703]	Step 69923	lr 0.00529	Loss 0.6375 (0.6473)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.0%)	
01/03 05:35:56午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [125/149] Final Prec@1 80.2378%
01/03 05:35:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][78/79]	Step 69924	Loss 1.6998	Prec@(1,5) (58.0%, 85.2%)
01/03 05:35:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 57.9800%
01/03 05:35:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.2600%
01/03 05:36:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][100/703]	Step 70024	lr 0.00497	Loss 0.6797 (0.5865)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.8%)	
01/03 05:36:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][200/703]	Step 70124	lr 0.00497	Loss 0.7519 (0.5978)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
01/03 05:36:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][300/703]	Step 70224	lr 0.00497	Loss 0.3816 (0.5948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.5%)	
01/03 05:36:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][400/703]	Step 70324	lr 0.00497	Loss 0.3905 (0.6035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
01/03 05:36:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][500/703]	Step 70424	lr 0.00497	Loss 0.5188 (0.6120)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
01/03 05:36:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][600/703]	Step 70524	lr 0.00497	Loss 0.8635 (0.6221)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.2%)	
01/03 05:37:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][700/703]	Step 70624	lr 0.00497	Loss 0.5363 (0.6264)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
01/03 05:37:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][703/703]	Step 70627	lr 0.00497	Loss 0.5134 (0.6260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
01/03 05:37:00午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [126/149] Final Prec@1 80.7711%
01/03 05:37:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][78/79]	Step 70628	Loss 1.6303	Prec@(1,5) (58.9%, 85.6%)
01/03 05:37:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 58.8400%
01/03 05:37:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.8400%
01/03 05:37:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][100/703]	Step 70728	lr 0.00466	Loss 0.6012 (0.5570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.5%)	
01/03 05:37:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][200/703]	Step 70828	lr 0.00466	Loss 0.5598 (0.5691)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.5%)	
01/03 05:37:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][300/703]	Step 70928	lr 0.00466	Loss 0.6359 (0.5803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.5%)	
01/03 05:37:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][400/703]	Step 71028	lr 0.00466	Loss 0.4885 (0.5852)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.5%)	
01/03 05:37:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][500/703]	Step 71128	lr 0.00466	Loss 0.5608 (0.5895)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.4%)	
01/03 05:37:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][600/703]	Step 71228	lr 0.00466	Loss 0.6815 (0.5956)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.3%)	
01/03 05:38:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][700/703]	Step 71328	lr 0.00466	Loss 0.6200 (0.5998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.3%)	
01/03 05:38:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][703/703]	Step 71331	lr 0.00466	Loss 0.5201 (0.5993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.3%)	
01/03 05:38:05午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [127/149] Final Prec@1 81.4222%
01/03 05:38:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][78/79]	Step 71332	Loss 1.6187	Prec@(1,5) (59.0%, 86.2%)
01/03 05:38:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 58.9600%
01/03 05:38:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9600%
01/03 05:38:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][100/703]	Step 71432	lr 0.00437	Loss 0.7919 (0.5434)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.8%)	
01/03 05:38:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][200/703]	Step 71532	lr 0.00437	Loss 0.6299 (0.5407)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
01/03 05:38:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][300/703]	Step 71632	lr 0.00437	Loss 0.7559 (0.5457)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
01/03 05:38:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][400/703]	Step 71732	lr 0.00437	Loss 0.6359 (0.5517)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.9%)	
01/03 05:38:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][500/703]	Step 71832	lr 0.00437	Loss 0.5238 (0.5573)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
01/03 05:39:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][600/703]	Step 71932	lr 0.00437	Loss 0.7545 (0.5630)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
01/03 05:39:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][700/703]	Step 72032	lr 0.00437	Loss 0.6134 (0.5686)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
01/03 05:39:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][703/703]	Step 72035	lr 0.00437	Loss 0.5272 (0.5690)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
01/03 05:39:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [128/149] Final Prec@1 82.4600%
01/03 05:39:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][78/79]	Step 72036	Loss 1.6314	Prec@(1,5) (58.9%, 86.1%)
01/03 05:39:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 58.9200%
01/03 05:39:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9600%
01/03 05:39:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][100/703]	Step 72136	lr 0.00408	Loss 0.3061 (0.5077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
01/03 05:39:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][200/703]	Step 72236	lr 0.00408	Loss 0.5501 (0.5162)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.1%)	
01/03 05:39:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][300/703]	Step 72336	lr 0.00408	Loss 0.5618 (0.5272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.9%)	
01/03 05:39:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][400/703]	Step 72436	lr 0.00408	Loss 0.3916 (0.5250)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.9%)	
01/03 05:39:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][500/703]	Step 72536	lr 0.00408	Loss 0.4823 (0.5305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
01/03 05:40:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][600/703]	Step 72636	lr 0.00408	Loss 0.4898 (0.5362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
01/03 05:40:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][700/703]	Step 72736	lr 0.00408	Loss 0.5938 (0.5414)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
01/03 05:40:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][703/703]	Step 72739	lr 0.00408	Loss 0.6181 (0.5420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
01/03 05:40:14午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [129/149] Final Prec@1 83.3689%
01/03 05:40:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][78/79]	Step 72740	Loss 1.6530	Prec@(1,5) (58.6%, 86.1%)
01/03 05:40:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 58.5600%
01/03 05:40:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9600%
01/03 05:40:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][100/703]	Step 72840	lr 0.00381	Loss 0.7512 (0.4868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.1%)	
01/03 05:40:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][200/703]	Step 72940	lr 0.00381	Loss 0.5040 (0.4965)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.2%)	
01/03 05:40:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][300/703]	Step 73040	lr 0.00381	Loss 0.4982 (0.5039)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.1%)	
01/03 05:40:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][400/703]	Step 73140	lr 0.00381	Loss 0.6725 (0.5094)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.1%)	
01/03 05:41:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][500/703]	Step 73240	lr 0.00381	Loss 0.4734 (0.5145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
01/03 05:41:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][600/703]	Step 73340	lr 0.00381	Loss 0.4454 (0.5194)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
01/03 05:41:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][700/703]	Step 73440	lr 0.00381	Loss 0.5623 (0.5209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.1%)	
01/03 05:41:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][703/703]	Step 73443	lr 0.00381	Loss 0.4237 (0.5211)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.1%)	
01/03 05:41:18午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [130/149] Final Prec@1 83.8489%
01/03 05:41:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][78/79]	Step 73444	Loss 1.6624	Prec@(1,5) (59.1%, 85.8%)
01/03 05:41:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 59.1000%
01/03 05:41:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1000%
01/03 05:41:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][100/703]	Step 73544	lr 0.00354	Loss 0.6116 (0.4613)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.4%)	
01/03 05:41:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][200/703]	Step 73644	lr 0.00354	Loss 0.5224 (0.4732)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.3%)	
01/03 05:41:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][300/703]	Step 73744	lr 0.00354	Loss 0.4458 (0.4697)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.4%)	
01/03 05:41:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][400/703]	Step 73844	lr 0.00354	Loss 0.2634 (0.4696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.4%)	
01/03 05:42:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][500/703]	Step 73944	lr 0.00354	Loss 0.6481 (0.4783)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.3%)	
01/03 05:42:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][600/703]	Step 74044	lr 0.00354	Loss 0.5884 (0.4867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.3%)	
01/03 05:42:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][700/703]	Step 74144	lr 0.00354	Loss 0.5755 (0.4908)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.3%)	
01/03 05:42:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][703/703]	Step 74147	lr 0.00354	Loss 0.5869 (0.4910)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.3%)	
01/03 05:42:23午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [131/149] Final Prec@1 84.7778%
01/03 05:42:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][78/79]	Step 74148	Loss 1.6211	Prec@(1,5) (59.6%, 86.2%)
01/03 05:42:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 59.6200%
01/03 05:42:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6200%
01/03 05:42:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][100/703]	Step 74248	lr 0.00329	Loss 0.4282 (0.4124)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 99.0%)	
01/03 05:42:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][200/703]	Step 74348	lr 0.00329	Loss 0.4715 (0.4285)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.9%)	
01/03 05:42:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][300/703]	Step 74448	lr 0.00329	Loss 0.3729 (0.4406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.7%)	
01/03 05:43:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][400/703]	Step 74548	lr 0.00329	Loss 0.3088 (0.4456)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.7%)	
01/03 05:43:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][500/703]	Step 74648	lr 0.00329	Loss 0.5143 (0.4525)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.7%)	
01/03 05:43:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][600/703]	Step 74748	lr 0.00329	Loss 0.4924 (0.4597)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.6%)	
01/03 05:43:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][700/703]	Step 74848	lr 0.00329	Loss 0.5906 (0.4658)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.6%)	
01/03 05:43:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][703/703]	Step 74851	lr 0.00329	Loss 0.5285 (0.4659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.6%)	
01/03 05:43:27午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [132/149] Final Prec@1 85.6422%
01/03 05:43:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][78/79]	Step 74852	Loss 1.6533	Prec@(1,5) (59.5%, 86.6%)
01/03 05:43:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 59.5200%
01/03 05:43:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6200%
01/03 05:43:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][100/703]	Step 74952	lr 0.00305	Loss 0.3456 (0.4190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 99.1%)	
01/03 05:43:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][200/703]	Step 75052	lr 0.00305	Loss 0.2512 (0.4295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
01/03 05:43:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][300/703]	Step 75152	lr 0.00305	Loss 0.2834 (0.4349)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.8%)	
01/03 05:44:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][400/703]	Step 75252	lr 0.00305	Loss 0.5028 (0.4381)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
01/03 05:44:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][500/703]	Step 75352	lr 0.00305	Loss 0.4758 (0.4413)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.7%)	
01/03 05:44:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][600/703]	Step 75452	lr 0.00305	Loss 0.2959 (0.4431)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.7%)	
01/03 05:44:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][700/703]	Step 75552	lr 0.00305	Loss 0.4556 (0.4475)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
01/03 05:44:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][703/703]	Step 75555	lr 0.00305	Loss 0.8335 (0.4481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
01/03 05:44:32午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [133/149] Final Prec@1 86.1133%
01/03 05:44:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][78/79]	Step 75556	Loss 1.6638	Prec@(1,5) (58.8%, 86.7%)
01/03 05:44:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 58.8200%
01/03 05:44:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6200%
01/03 05:44:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][100/703]	Step 75656	lr 0.00282	Loss 0.2925 (0.4061)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.9%)	
01/03 05:44:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][200/703]	Step 75756	lr 0.00282	Loss 0.4438 (0.4128)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.8%)	
01/03 05:45:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][300/703]	Step 75856	lr 0.00282	Loss 0.3411 (0.4112)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.8%)	
01/03 05:45:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][400/703]	Step 75956	lr 0.00282	Loss 0.3441 (0.4169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.8%)	
01/03 05:45:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][500/703]	Step 76056	lr 0.00282	Loss 0.5204 (0.4245)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.7%)	
01/03 05:45:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][600/703]	Step 76156	lr 0.00282	Loss 0.4494 (0.4265)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.7%)	
01/03 05:45:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][700/703]	Step 76256	lr 0.00282	Loss 0.4781 (0.4270)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.7%)	
01/03 05:45:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][703/703]	Step 76259	lr 0.00282	Loss 0.3437 (0.4267)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.7%)	
01/03 05:45:36午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [134/149] Final Prec@1 86.9222%
01/03 05:45:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][78/79]	Step 76260	Loss 1.6689	Prec@(1,5) (59.5%, 86.7%)
01/03 05:45:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 59.5000%
01/03 05:45:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6200%
01/03 05:45:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][100/703]	Step 76360	lr 0.00261	Loss 0.2669 (0.3830)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.1%, 99.0%)	
01/03 05:45:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][200/703]	Step 76460	lr 0.00261	Loss 0.4234 (0.3842)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
01/03 05:46:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][300/703]	Step 76560	lr 0.00261	Loss 0.3690 (0.3904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.0%)	
01/03 05:46:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][400/703]	Step 76660	lr 0.00261	Loss 0.4672 (0.3959)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
01/03 05:46:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][500/703]	Step 76760	lr 0.00261	Loss 0.3408 (0.4014)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
01/03 05:46:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][600/703]	Step 76860	lr 0.00261	Loss 0.4515 (0.4023)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
01/03 05:46:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][700/703]	Step 76960	lr 0.00261	Loss 0.4640 (0.4041)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
01/03 05:46:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][703/703]	Step 76963	lr 0.00261	Loss 0.4179 (0.4044)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
01/03 05:46:41午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [135/149] Final Prec@1 87.4889%
01/03 05:46:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][78/79]	Step 76964	Loss 1.6556	Prec@(1,5) (59.9%, 86.3%)
01/03 05:46:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 59.8800%
01/03 05:46:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.8800%
01/03 05:46:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][100/703]	Step 77064	lr 0.0024	Loss 0.3952 (0.3671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.0%)	
01/03 05:47:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][200/703]	Step 77164	lr 0.0024	Loss 0.2882 (0.3733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.1%)	
01/03 05:47:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][300/703]	Step 77264	lr 0.0024	Loss 0.3146 (0.3750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.1%)	
01/03 05:47:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][400/703]	Step 77364	lr 0.0024	Loss 0.4888 (0.3801)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.0%)	
01/03 05:47:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][500/703]	Step 77464	lr 0.0024	Loss 0.3453 (0.3847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
01/03 05:47:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][600/703]	Step 77564	lr 0.0024	Loss 0.5357 (0.3867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
01/03 05:47:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][700/703]	Step 77664	lr 0.0024	Loss 0.5863 (0.3883)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.0%)	
01/03 05:47:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][703/703]	Step 77667	lr 0.0024	Loss 0.4522 (0.3882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.0%)	
01/03 05:47:46午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [136/149] Final Prec@1 88.1756%
01/03 05:47:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][78/79]	Step 77668	Loss 1.6204	Prec@(1,5) (60.8%, 86.5%)
01/03 05:47:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 60.7600%
01/03 05:47:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
01/03 05:47:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][100/703]	Step 77768	lr 0.00221	Loss 0.5017 (0.3486)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 98.9%)	
01/03 05:48:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][200/703]	Step 77868	lr 0.00221	Loss 0.3585 (0.3491)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.1%)	
01/03 05:48:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][300/703]	Step 77968	lr 0.00221	Loss 0.2701 (0.3525)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.1%)	
01/03 05:48:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][400/703]	Step 78068	lr 0.00221	Loss 0.3200 (0.3521)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.1%)	
01/03 05:48:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][500/703]	Step 78168	lr 0.00221	Loss 0.4452 (0.3568)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.1%)	
01/03 05:48:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][600/703]	Step 78268	lr 0.00221	Loss 0.4117 (0.3608)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.1%)	
01/03 05:48:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][700/703]	Step 78368	lr 0.00221	Loss 0.4860 (0.3634)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.1%)	
01/03 05:48:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][703/703]	Step 78371	lr 0.00221	Loss 0.3904 (0.3635)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.1%)	
01/03 05:48:50午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [137/149] Final Prec@1 89.0556%
01/03 05:48:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][78/79]	Step 78372	Loss 1.6566	Prec@(1,5) (60.6%, 86.6%)
01/03 05:48:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 60.5800%
01/03 05:48:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
01/03 05:49:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][100/703]	Step 78472	lr 0.00204	Loss 0.2118 (0.3225)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.0%)	
01/03 05:49:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][200/703]	Step 78572	lr 0.00204	Loss 0.4869 (0.3287)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.1%)	
01/03 05:49:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][300/703]	Step 78672	lr 0.00204	Loss 0.4762 (0.3353)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.1%, 99.1%)	
01/03 05:49:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][400/703]	Step 78772	lr 0.00204	Loss 0.2056 (0.3404)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.1%)	
01/03 05:49:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][500/703]	Step 78872	lr 0.00204	Loss 0.3951 (0.3392)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.2%)	
01/03 05:49:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][600/703]	Step 78972	lr 0.00204	Loss 0.3329 (0.3430)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
01/03 05:49:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][700/703]	Step 79072	lr 0.00204	Loss 0.2564 (0.3468)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.1%)	
01/03 05:49:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][703/703]	Step 79075	lr 0.00204	Loss 0.5619 (0.3470)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.1%)	
01/03 05:49:55午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [138/149] Final Prec@1 89.5067%
01/03 05:49:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][78/79]	Step 79076	Loss 1.6418	Prec@(1,5) (61.1%, 87.0%)
01/03 05:49:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 61.0800%
01/03 05:49:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0800%
01/03 05:50:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][100/703]	Step 79176	lr 0.00187	Loss 0.2707 (0.2950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.4%)	
01/03 05:50:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][200/703]	Step 79276	lr 0.00187	Loss 0.4407 (0.3097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
01/03 05:50:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][300/703]	Step 79376	lr 0.00187	Loss 0.3979 (0.3147)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.3%)	
01/03 05:50:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][400/703]	Step 79476	lr 0.00187	Loss 0.3916 (0.3246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.3%)	
01/03 05:50:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][500/703]	Step 79576	lr 0.00187	Loss 0.3152 (0.3275)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.3%)	
01/03 05:50:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][600/703]	Step 79676	lr 0.00187	Loss 0.6519 (0.3282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.3%)	
01/03 05:50:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][700/703]	Step 79776	lr 0.00187	Loss 0.2299 (0.3304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
01/03 05:51:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][703/703]	Step 79779	lr 0.00187	Loss 0.3649 (0.3307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
01/03 05:51:00午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [139/149] Final Prec@1 90.0267%
01/03 05:51:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][78/79]	Step 79780	Loss 1.6454	Prec@(1,5) (60.8%, 86.4%)
01/03 05:51:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 60.8400%
01/03 05:51:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0800%
01/03 05:51:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][100/703]	Step 79880	lr 0.00172	Loss 0.2273 (0.2969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
01/03 05:51:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][200/703]	Step 79980	lr 0.00172	Loss 0.2539 (0.3028)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
01/03 05:51:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][300/703]	Step 80080	lr 0.00172	Loss 0.1707 (0.3024)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
01/03 05:51:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][400/703]	Step 80180	lr 0.00172	Loss 0.5325 (0.3040)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
01/03 05:51:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][500/703]	Step 80280	lr 0.00172	Loss 0.3310 (0.3067)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
01/03 05:51:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][600/703]	Step 80380	lr 0.00172	Loss 0.1880 (0.3126)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
01/03 05:52:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][700/703]	Step 80480	lr 0.00172	Loss 0.4154 (0.3147)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.3%)	
01/03 05:52:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][703/703]	Step 80483	lr 0.00172	Loss 0.3159 (0.3150)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
01/03 05:52:04午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [140/149] Final Prec@1 90.5467%
01/03 05:52:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][78/79]	Step 80484	Loss 1.6574	Prec@(1,5) (60.1%, 86.2%)
01/03 05:52:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 60.1600%
01/03 05:52:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0800%
01/03 05:52:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][100/703]	Step 80584	lr 0.00159	Loss 0.2582 (0.2954)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
01/03 05:52:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][200/703]	Step 80684	lr 0.00159	Loss 0.1871 (0.2928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
01/03 05:52:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][300/703]	Step 80784	lr 0.00159	Loss 0.2073 (0.2993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.5%)	
01/03 05:52:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][400/703]	Step 80884	lr 0.00159	Loss 0.3681 (0.3035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
01/03 05:52:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][500/703]	Step 80984	lr 0.00159	Loss 0.2394 (0.3047)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
01/03 05:52:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][600/703]	Step 81084	lr 0.00159	Loss 0.4564 (0.3078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
01/03 05:53:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][700/703]	Step 81184	lr 0.00159	Loss 0.3854 (0.3097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
01/03 05:53:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][703/703]	Step 81187	lr 0.00159	Loss 0.4373 (0.3099)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
01/03 05:53:08午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [141/149] Final Prec@1 90.6867%
01/03 05:53:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][78/79]	Step 81188	Loss 1.6911	Prec@(1,5) (60.7%, 86.2%)
01/03 05:53:11午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 60.7800%
01/03 05:53:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0800%
01/03 05:53:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][100/703]	Step 81288	lr 0.00146	Loss 0.2554 (0.2835)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
01/03 05:53:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][200/703]	Step 81388	lr 0.00146	Loss 0.4308 (0.2868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
01/03 05:53:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][300/703]	Step 81488	lr 0.00146	Loss 0.4154 (0.2939)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
01/03 05:53:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][400/703]	Step 81588	lr 0.00146	Loss 0.1825 (0.2921)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.4%)	
01/03 05:53:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][500/703]	Step 81688	lr 0.00146	Loss 0.3191 (0.2926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
01/03 05:54:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][600/703]	Step 81788	lr 0.00146	Loss 0.2899 (0.2925)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
01/03 05:54:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][700/703]	Step 81888	lr 0.00146	Loss 0.3016 (0.2950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.4%)	
01/03 05:54:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][703/703]	Step 81891	lr 0.00146	Loss 0.3122 (0.2951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.4%)	
01/03 05:54:13午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [142/149] Final Prec@1 91.3378%
01/03 05:54:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][78/79]	Step 81892	Loss 1.6809	Prec@(1,5) (60.7%, 86.6%)
01/03 05:54:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 60.7400%
01/03 05:54:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0800%
01/03 05:54:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][100/703]	Step 81992	lr 0.00136	Loss 0.3248 (0.2612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.5%)	
01/03 05:54:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][200/703]	Step 82092	lr 0.00136	Loss 0.3079 (0.2730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
01/03 05:54:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][300/703]	Step 82192	lr 0.00136	Loss 0.2846 (0.2752)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
01/03 05:54:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][400/703]	Step 82292	lr 0.00136	Loss 0.3733 (0.2767)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
01/03 05:54:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][500/703]	Step 82392	lr 0.00136	Loss 0.3187 (0.2796)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
01/03 05:55:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][600/703]	Step 82492	lr 0.00136	Loss 0.2561 (0.2815)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
01/03 05:55:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][700/703]	Step 82592	lr 0.00136	Loss 0.4601 (0.2820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
01/03 05:55:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][703/703]	Step 82595	lr 0.00136	Loss 0.2996 (0.2819)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
01/03 05:55:17午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [143/149] Final Prec@1 91.7089%
01/03 05:55:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][78/79]	Step 82596	Loss 1.6866	Prec@(1,5) (61.1%, 86.9%)
01/03 05:55:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 61.1200%
01/03 05:55:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1200%
01/03 05:55:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][100/703]	Step 82696	lr 0.00126	Loss 0.1810 (0.2568)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
01/03 05:55:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][200/703]	Step 82796	lr 0.00126	Loss 0.2001 (0.2581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
01/03 05:55:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][300/703]	Step 82896	lr 0.00126	Loss 0.2227 (0.2636)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
01/03 05:55:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][400/703]	Step 82996	lr 0.00126	Loss 0.2590 (0.2652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
01/03 05:56:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][500/703]	Step 83096	lr 0.00126	Loss 0.2511 (0.2653)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
01/03 05:56:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][600/703]	Step 83196	lr 0.00126	Loss 0.4007 (0.2671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
01/03 05:56:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][700/703]	Step 83296	lr 0.00126	Loss 0.4098 (0.2683)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
01/03 05:56:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][703/703]	Step 83299	lr 0.00126	Loss 0.4437 (0.2684)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
01/03 05:56:22午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [144/149] Final Prec@1 92.2111%
01/03 05:56:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][78/79]	Step 83300	Loss 1.7246	Prec@(1,5) (59.9%, 86.3%)
01/03 05:56:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 59.9000%
01/03 05:56:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1200%
01/03 05:56:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][100/703]	Step 83400	lr 0.00118	Loss 0.3153 (0.2671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
01/03 05:56:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][200/703]	Step 83500	lr 0.00118	Loss 0.1835 (0.2580)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.5%)	
01/03 05:56:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][300/703]	Step 83600	lr 0.00118	Loss 0.4790 (0.2630)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
01/03 05:57:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][400/703]	Step 83700	lr 0.00118	Loss 0.3097 (0.2669)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
01/03 05:57:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][500/703]	Step 83800	lr 0.00118	Loss 0.2625 (0.2671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
01/03 05:57:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][600/703]	Step 83900	lr 0.00118	Loss 0.2569 (0.2678)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
01/03 05:57:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][700/703]	Step 84000	lr 0.00118	Loss 0.2448 (0.2677)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
01/03 05:57:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][703/703]	Step 84003	lr 0.00118	Loss 0.2743 (0.2676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
01/03 05:57:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [145/149] Final Prec@1 92.2000%
01/03 05:57:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][78/79]	Step 84004	Loss 1.7047	Prec@(1,5) (60.1%, 86.5%)
01/03 05:57:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 60.0800%
01/03 05:57:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1200%
01/03 05:57:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][100/703]	Step 84104	lr 0.00112	Loss 0.3587 (0.2476)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.8%)	
01/03 05:57:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][200/703]	Step 84204	lr 0.00112	Loss 0.3231 (0.2479)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
01/03 05:57:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][300/703]	Step 84304	lr 0.00112	Loss 0.1390 (0.2513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
01/03 05:58:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][400/703]	Step 84404	lr 0.00112	Loss 0.2863 (0.2540)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.5%)	
01/03 05:58:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][500/703]	Step 84504	lr 0.00112	Loss 0.2127 (0.2558)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.5%)	
01/03 05:58:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][600/703]	Step 84604	lr 0.00112	Loss 0.3202 (0.2569)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.5%)	
01/03 05:58:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][700/703]	Step 84704	lr 0.00112	Loss 0.2250 (0.2596)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.5%)	
01/03 05:58:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][703/703]	Step 84707	lr 0.00112	Loss 0.2392 (0.2594)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.5%)	
01/03 05:58:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [146/149] Final Prec@1 92.5067%
01/03 05:58:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][78/79]	Step 84708	Loss 1.7283	Prec@(1,5) (60.0%, 86.2%)
01/03 05:58:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 60.0600%
01/03 05:58:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1200%
01/03 05:58:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][100/703]	Step 84808	lr 0.00107	Loss 0.0749 (0.2339)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.6%)	
01/03 05:58:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][200/703]	Step 84908	lr 0.00107	Loss 0.1381 (0.2392)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
01/03 05:59:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][300/703]	Step 85008	lr 0.00107	Loss 0.3715 (0.2494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
01/03 05:59:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][400/703]	Step 85108	lr 0.00107	Loss 0.2604 (0.2475)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
01/03 05:59:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][500/703]	Step 85208	lr 0.00107	Loss 0.2218 (0.2499)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
01/03 05:59:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][600/703]	Step 85308	lr 0.00107	Loss 0.4667 (0.2492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.7%)	
01/03 05:59:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][700/703]	Step 85408	lr 0.00107	Loss 0.2389 (0.2494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
01/03 05:59:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][703/703]	Step 85411	lr 0.00107	Loss 0.1565 (0.2496)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
01/03 05:59:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [147/149] Final Prec@1 92.8156%
01/03 05:59:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][78/79]	Step 85412	Loss 1.7066	Prec@(1,5) (60.7%, 86.4%)
01/03 05:59:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 60.7000%
01/03 05:59:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1200%
01/03 05:59:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][100/703]	Step 85512	lr 0.00103	Loss 0.3544 (0.2354)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
01/03 05:59:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][200/703]	Step 85612	lr 0.00103	Loss 0.1511 (0.2313)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.6%)	
01/03 06:00:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][300/703]	Step 85712	lr 0.00103	Loss 0.1990 (0.2334)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
01/03 06:00:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][400/703]	Step 85812	lr 0.00103	Loss 0.1958 (0.2382)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
01/03 06:00:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][500/703]	Step 85912	lr 0.00103	Loss 0.3121 (0.2398)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
01/03 06:00:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][600/703]	Step 86012	lr 0.00103	Loss 0.2142 (0.2426)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
01/03 06:00:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][700/703]	Step 86112	lr 0.00103	Loss 0.2905 (0.2427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
01/03 06:00:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][703/703]	Step 86115	lr 0.00103	Loss 0.2081 (0.2427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
01/03 06:00:40午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [148/149] Final Prec@1 93.0533%
01/03 06:00:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][78/79]	Step 86116	Loss 1.7040	Prec@(1,5) (61.3%, 86.6%)
01/03 06:00:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 61.3200%
01/03 06:00:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.3200%
01/03 06:00:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][100/703]	Step 86216	lr 0.00101	Loss 0.2737 (0.2161)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.7%)	
01/03 06:01:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][200/703]	Step 86316	lr 0.00101	Loss 0.3199 (0.2238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
01/03 06:01:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][300/703]	Step 86416	lr 0.00101	Loss 0.2429 (0.2312)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
01/03 06:01:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][400/703]	Step 86516	lr 0.00101	Loss 0.2739 (0.2320)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
01/03 06:01:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][500/703]	Step 86616	lr 0.00101	Loss 0.1221 (0.2322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
01/03 06:01:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][600/703]	Step 86716	lr 0.00101	Loss 0.2951 (0.2341)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
01/03 06:01:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][700/703]	Step 86816	lr 0.00101	Loss 0.2153 (0.2371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
01/03 06:01:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][703/703]	Step 86819	lr 0.00101	Loss 0.3113 (0.2373)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
01/03 06:01:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [149/149] Final Prec@1 93.2311%
01/03 06:01:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][78/79]	Step 86820	Loss 1.6867	Prec@(1,5) (61.1%, 87.0%)
01/03 06:01:47午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 61.0600%
01/03 06:01:47午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.3200%
01/03 06:01:47午前 searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 61.3200%
01/03 06:01:47午前 searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[6, 7])
