11/25 12:40:03AM parser.py:28 [INFO] 
11/25 12:40:03AM parser.py:29 [INFO] Parameters:
11/25 12:40:03AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s1--sw3-g_30-20/DAG
11/25 12:40:03AM parser.py:31 [INFO] T=10.0
11/25 12:40:03AM parser.py:31 [INFO] ADVANCED=1
11/25 12:40:03AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/25 12:40:03AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/25 12:40:03AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/25 12:40:03AM parser.py:31 [INFO] BATCH_SIZE=128
11/25 12:40:03AM parser.py:31 [INFO] CASCADE=0
11/25 12:40:03AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/25 12:40:03AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[1, 1]
11/25 12:40:03AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/25 12:40:03AM parser.py:31 [INFO] DATA_PATH=../data/
11/25 12:40:03AM parser.py:31 [INFO] DATASET=cifar100
11/25 12:40:03AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/25 12:40:03AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3_
11/25 12:40:03AM parser.py:31 [INFO] DISCRETE=1
11/25 12:40:03AM parser.py:31 [INFO] EPOCHS=50
11/25 12:40:03AM parser.py:31 [INFO] EVAL_EPOCHS=1
11/25 12:40:03AM parser.py:31 [INFO] EXP_NAME=s1--sw3-g_30-20
11/25 12:40:03AM parser.py:31 [INFO] FINAL_L=0.0
11/25 12:40:03AM parser.py:31 [INFO] G=1.0
11/25 12:40:03AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/25 12:40:03AM parser.py:31 [INFO] GPUS=[0]
11/25 12:40:03AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/25 12:40:03AM parser.py:31 [INFO] INIT_CHANNELS=16
11/25 12:40:03AM parser.py:31 [INFO] L=0.0
11/25 12:40:03AM parser.py:31 [INFO] LAYERS=32
11/25 12:40:03AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/25 12:40:03AM parser.py:31 [INFO] NAME=Curriculum
11/25 12:40:03AM parser.py:31 [INFO] NONKD=1
11/25 12:40:03AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s1--sw3-g_30-20
11/25 12:40:03AM parser.py:31 [INFO] PCDARTS=0
11/25 12:40:03AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s1--sw3-g_30-20/plots
11/25 12:40:03AM parser.py:31 [INFO] PRINT_FREQ=100
11/25 12:40:03AM parser.py:31 [INFO] RESET=0
11/25 12:40:03AM parser.py:31 [INFO] RESUME_PATH=None
11/25 12:40:03AM parser.py:31 [INFO] SAVE=s1--sw3-g_30-20
11/25 12:40:03AM parser.py:31 [INFO] SEED=1
11/25 12:40:03AM parser.py:31 [INFO] SHARE_STAGE=0
11/25 12:40:03AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/25 12:40:03AM parser.py:31 [INFO] SPEC_CELL=1
11/25 12:40:03AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/25 12:40:03AM parser.py:31 [INFO] TEACHER_NAME=none
11/25 12:40:03AM parser.py:31 [INFO] TEACHER_PATH=none
11/25 12:40:03AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/25 12:40:03AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
11/25 12:40:03AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/25 12:40:03AM parser.py:31 [INFO] W_LR=0.025
11/25 12:40:03AM parser.py:31 [INFO] W_LR_MIN=0.001
11/25 12:40:03AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/25 12:40:03AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/25 12:40:03AM parser.py:31 [INFO] WORKERS=4
11/25 12:40:03AM parser.py:32 [INFO] 
11/25 12:40:04AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/25 07:57:29AM parser.py:28 [INFO] 
11/25 07:57:29AM parser.py:29 [INFO] Parameters:
11/25 07:57:29AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s1--sw3-g_30-20/DAG
11/25 07:57:29AM parser.py:31 [INFO] T=10.0
11/25 07:57:29AM parser.py:31 [INFO] ADVANCED=1
11/25 07:57:29AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/25 07:57:29AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/25 07:57:29AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/25 07:57:29AM parser.py:31 [INFO] BATCH_SIZE=128
11/25 07:57:29AM parser.py:31 [INFO] CASCADE=0
11/25 07:57:29AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/25 07:57:29AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 20]
11/25 07:57:29AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/25 07:57:29AM parser.py:31 [INFO] DATA_PATH=../data/
11/25 07:57:29AM parser.py:31 [INFO] DATASET=cifar100
11/25 07:57:29AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/25 07:57:29AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3_
11/25 07:57:29AM parser.py:31 [INFO] DISCRETE=1
11/25 07:57:29AM parser.py:31 [INFO] EPOCHS=50
11/25 07:57:29AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/25 07:57:29AM parser.py:31 [INFO] EXP_NAME=s1--sw3-g_30-20
11/25 07:57:29AM parser.py:31 [INFO] FINAL_L=0.0
11/25 07:57:29AM parser.py:31 [INFO] G=0.001
11/25 07:57:29AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/25 07:57:29AM parser.py:31 [INFO] GPUS=[0]
11/25 07:57:29AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/25 07:57:29AM parser.py:31 [INFO] INIT_CHANNELS=16
11/25 07:57:29AM parser.py:31 [INFO] L=0.0
11/25 07:57:29AM parser.py:31 [INFO] LAYERS=32
11/25 07:57:29AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/25 07:57:29AM parser.py:31 [INFO] NAME=Curriculum
11/25 07:57:29AM parser.py:31 [INFO] NONKD=1
11/25 07:57:29AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s1--sw3-g_30-20
11/25 07:57:29AM parser.py:31 [INFO] PCDARTS=0
11/25 07:57:29AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s1--sw3-g_30-20/plots
11/25 07:57:29AM parser.py:31 [INFO] PRINT_FREQ=100
11/25 07:57:29AM parser.py:31 [INFO] RESET=0
11/25 07:57:29AM parser.py:31 [INFO] RESUME_PATH=None
11/25 07:57:29AM parser.py:31 [INFO] SAVE=s1--sw3-g_30-20
11/25 07:57:29AM parser.py:31 [INFO] SEED=1
11/25 07:57:29AM parser.py:31 [INFO] SHARE_STAGE=0
11/25 07:57:29AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/25 07:57:29AM parser.py:31 [INFO] SPEC_CELL=1
11/25 07:57:29AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/25 07:57:29AM parser.py:31 [INFO] TEACHER_NAME=none
11/25 07:57:29AM parser.py:31 [INFO] TEACHER_PATH=none
11/25 07:57:29AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/25 07:57:29AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
11/25 07:57:29AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/25 07:57:29AM parser.py:31 [INFO] W_LR=0.025
11/25 07:57:29AM parser.py:31 [INFO] W_LR_MIN=0.001
11/25 07:57:29AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/25 07:57:29AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/25 07:57:29AM parser.py:31 [INFO] WORKERS=4
11/25 07:57:29AM parser.py:32 [INFO] 
11/25 07:57:30AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/25 07:59:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][100/195]	Step 100	lr 0.025	Loss 4.1907 (4.4262)	Arch Loss 4.1876 (4.4279)	Arch Hard Loss 4.1876 (4.4279)	Arch Beta Loss 359.7618 (360.0280)	Arch depth Loss -0.0041 (-0.0027)	Prec@(1,5) (2.8%, 12.5%)	
11/25 08:00:44AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][195/195]	Step 195	lr 0.025	Loss 3.9187 (4.2695)	Arch Loss 3.9580 (4.2571)	Arch Hard Loss 3.9580 (4.2571)	Arch Beta Loss 359.1105 (359.7661)	Arch depth Loss -0.0058 (-0.0039)	Prec@(1,5) (4.4%, 17.6%)	
11/25 08:00:46AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  0/149] Final Prec@1 4.3840%
11/25 08:01:02AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/196]	Step 196	Loss 4.0525	Prec@(1,5) (7.1%, 25.6%)
11/25 08:01:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][195/196]	Step 196	Loss 4.0537	Prec@(1,5) (7.2%, 25.7%)
11/25 08:01:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 7.1720%
11/25 08:01:16AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/25 08:01:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 7.1720%
11/25 08:02:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][100/195]	Step 296	lr 0.025	Loss 3.7929 (3.8774)	Arch Loss 3.8812 (3.8791)	Arch Hard Loss 3.8812 (3.8791)	Arch Beta Loss 358.0644 (358.6589)	Arch depth Loss -0.0090 (-0.0084)	Prec@(1,5) (8.7%, 29.8%)	
11/25 08:04:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][195/195]	Step 391	lr 0.025	Loss 3.6429 (3.8057)	Arch Loss 3.7897 (3.7907)	Arch Hard Loss 3.7897 (3.7907)	Arch Beta Loss 357.5047 (358.3246)	Arch depth Loss -0.0082 (-0.0084)	Prec@(1,5) (10.2%, 32.2%)	
11/25 08:04:29午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  1/149] Final Prec@1 10.1920%
11/25 08:04:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/196]	Step 392	Loss 3.7036	Prec@(1,5) (11.7%, 35.9%)
11/25 08:04:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][195/196]	Step 392	Loss 3.6816	Prec@(1,5) (12.3%, 36.5%)
11/25 08:04:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 12.3440%
11/25 08:04:59午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 08:05:00午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 12.3440%
11/25 08:06:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][100/195]	Step 492	lr 0.02499	Loss 3.6974 (3.5961)	Arch Loss 3.3725 (3.5884)	Arch Hard Loss 3.3725 (3.5884)	Arch Beta Loss 356.5665 (357.1155)	Arch depth Loss -0.0118 (-0.0107)	Prec@(1,5) (13.4%, 38.6%)	
11/25 08:08:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][195/195]	Step 587	lr 0.02499	Loss 3.6156 (3.5447)	Arch Loss 3.1466 (3.5441)	Arch Hard Loss 3.1466 (3.5441)	Arch Beta Loss 355.9495 (356.7007)	Arch depth Loss -0.0125 (-0.0114)	Prec@(1,5) (14.2%, 40.3%)	
11/25 08:08:12午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  2/149] Final Prec@1 14.2000%
11/25 08:08:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/196]	Step 588	Loss 3.4895	Prec@(1,5) (15.4%, 42.4%)
11/25 08:08:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][195/196]	Step 588	Loss 3.4905	Prec@(1,5) (15.3%, 42.0%)
11/25 08:08:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 15.2760%
11/25 08:08:43午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 08:08:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 15.2760%
11/25 08:10:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][100/195]	Step 688	lr 0.02498	Loss 3.3669 (3.3532)	Arch Loss 3.3462 (3.4051)	Arch Hard Loss 3.3462 (3.4051)	Arch Beta Loss 354.7366 (355.2293)	Arch depth Loss -0.0129 (-0.0118)	Prec@(1,5) (17.6%, 46.0%)	
11/25 08:11:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][195/195]	Step 783	lr 0.02498	Loss 3.1717 (3.3233)	Arch Loss 3.1379 (3.3398)	Arch Hard Loss 3.1379 (3.3398)	Arch Beta Loss 353.9999 (354.7339)	Arch depth Loss -0.0127 (-0.0120)	Prec@(1,5) (18.3%, 46.7%)	
11/25 08:11:56午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  3/149] Final Prec@1 18.3040%
11/25 08:12:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/196]	Step 784	Loss 3.3929	Prec@(1,5) (18.3%, 46.9%)
11/25 08:12:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][195/196]	Step 784	Loss 3.3880	Prec@(1,5) (18.4%, 46.7%)
11/25 08:12:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 18.4160%
11/25 08:12:26午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 08:12:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 18.4160%
11/25 08:14:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][100/195]	Step 884	lr 0.02496	Loss 3.0312 (3.1699)	Arch Loss 3.1333 (3.2476)	Arch Hard Loss 3.1333 (3.2476)	Arch Beta Loss 353.0278 (353.4020)	Arch depth Loss -0.0173 (-0.0148)	Prec@(1,5) (20.6%, 50.7%)	
11/25 08:15:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][195/195]	Step 979	lr 0.02496	Loss 2.8767 (3.1489)	Arch Loss 2.9305 (3.1953)	Arch Hard Loss 2.9305 (3.1953)	Arch Beta Loss 352.3936 (353.1225)	Arch depth Loss -0.0156 (-0.0158)	Prec@(1,5) (21.1%, 51.4%)	
11/25 08:15:39午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  4/149] Final Prec@1 21.0640%
11/25 08:15:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/196]	Step 980	Loss 3.0917	Prec@(1,5) (22.6%, 53.2%)
11/25 08:16:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][195/196]	Step 980	Loss 3.0962	Prec@(1,5) (22.4%, 53.3%)
11/25 08:16:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 22.4440%
11/25 08:16:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 08:16:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 22.4440%
11/25 08:17:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][100/195]	Step 1080	lr 0.02493	Loss 2.9089 (2.9898)	Arch Loss 3.2044 (3.0669)	Arch Hard Loss 3.2044 (3.0669)	Arch Beta Loss 351.6346 (351.9904)	Arch depth Loss -0.0167 (-0.0151)	Prec@(1,5) (24.1%, 55.4%)	
11/25 08:19:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][195/195]	Step 1175	lr 0.02493	Loss 2.8084 (2.9710)	Arch Loss 3.0293 (3.0363)	Arch Hard Loss 3.0293 (3.0363)	Arch Beta Loss 350.6810 (351.5686)	Arch depth Loss -0.0222 (-0.0175)	Prec@(1,5) (24.6%, 56.1%)	
11/25 08:19:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  5/149] Final Prec@1 24.5640%
11/25 08:19:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/196]	Step 1176	Loss 3.1142	Prec@(1,5) (22.8%, 53.7%)
11/25 08:19:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][195/196]	Step 1176	Loss 3.1104	Prec@(1,5) (23.0%, 53.7%)
11/25 08:19:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 23.0480%
11/25 08:19:53午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 08:19:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 23.0480%
11/25 08:21:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][100/195]	Step 1276	lr 0.02491	Loss 2.4939 (2.8391)	Arch Loss 3.0116 (2.9549)	Arch Hard Loss 3.0116 (2.9549)	Arch Beta Loss 350.0099 (350.4868)	Arch depth Loss -0.0262 (-0.0242)	Prec@(1,5) (27.2%, 59.4%)	
11/25 08:23:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][195/195]	Step 1371	lr 0.02491	Loss 2.9495 (2.8297)	Arch Loss 2.8281 (2.9162)	Arch Hard Loss 2.8281 (2.9162)	Arch Beta Loss 349.5015 (350.1301)	Arch depth Loss -0.0261 (-0.0253)	Prec@(1,5) (27.5%, 59.5%)	
11/25 08:23:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  6/149] Final Prec@1 27.4680%
11/25 08:23:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/196]	Step 1372	Loss 2.9247	Prec@(1,5) (26.3%, 57.0%)
11/25 08:23:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][195/196]	Step 1372	Loss 2.9370	Prec@(1,5) (26.0%, 57.2%)
11/25 08:23:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 26.0200%
11/25 08:23:37午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 08:23:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 26.0200%
11/25 08:25:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][100/195]	Step 1472	lr 0.02487	Loss 2.7220 (2.6979)	Arch Loss 2.8512 (2.8152)	Arch Hard Loss 2.8512 (2.8152)	Arch Beta Loss 348.9120 (349.1483)	Arch depth Loss -0.0273 (-0.0273)	Prec@(1,5) (30.1%, 63.1%)	
11/25 08:26:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][195/195]	Step 1567	lr 0.02487	Loss 2.4725 (2.6885)	Arch Loss 2.4599 (2.7988)	Arch Hard Loss 2.4599 (2.7988)	Arch Beta Loss 348.4010 (348.8575)	Arch depth Loss -0.0287 (-0.0280)	Prec@(1,5) (30.0%, 62.9%)	
11/25 08:26:50午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  7/149] Final Prec@1 30.0440%
11/25 08:27:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/196]	Step 1568	Loss 2.8082	Prec@(1,5) (28.9%, 60.2%)
11/25 08:27:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][195/196]	Step 1568	Loss 2.8192	Prec@(1,5) (28.5%, 60.1%)
11/25 08:27:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 28.5480%
11/25 08:27:20午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 08:27:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 28.5480%
11/25 08:29:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][100/195]	Step 1668	lr 0.02483	Loss 2.5131 (2.5706)	Arch Loss 2.5367 (2.7409)	Arch Hard Loss 2.5367 (2.7409)	Arch Beta Loss 347.8912 (348.1002)	Arch depth Loss -0.0319 (-0.0309)	Prec@(1,5) (32.9%, 66.1%)	
11/25 08:30:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][195/195]	Step 1763	lr 0.02483	Loss 2.6051 (2.5702)	Arch Loss 2.7879 (2.7023)	Arch Hard Loss 2.7879 (2.7023)	Arch Beta Loss 347.3715 (347.8775)	Arch depth Loss -0.0324 (-0.0315)	Prec@(1,5) (33.1%, 66.0%)	
11/25 08:30:34午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  8/149] Final Prec@1 33.1200%
11/25 08:30:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/196]	Step 1764	Loss 2.7404	Prec@(1,5) (30.4%, 61.9%)
11/25 08:31:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][195/196]	Step 1764	Loss 2.7698	Prec@(1,5) (29.5%, 61.2%)
11/25 08:31:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 29.4440%
11/25 08:31:04午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 08:31:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 29.4440%
11/25 08:32:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][100/195]	Step 1864	lr 0.02479	Loss 2.4304 (2.4585)	Arch Loss 2.7043 (2.6328)	Arch Hard Loss 2.7043 (2.6328)	Arch Beta Loss 346.9113 (347.2682)	Arch depth Loss -0.0359 (-0.0329)	Prec@(1,5) (35.5%, 68.2%)	
11/25 08:34:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][195/195]	Step 1959	lr 0.02479	Loss 2.1858 (2.4594)	Arch Loss 2.6425 (2.6239)	Arch Hard Loss 2.6425 (2.6239)	Arch Beta Loss 346.5325 (346.9416)	Arch depth Loss -0.0373 (-0.0348)	Prec@(1,5) (35.3%, 68.1%)	
11/25 08:34:18午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  9/149] Final Prec@1 35.3160%
11/25 08:34:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/196]	Step 1960	Loss 2.5990	Prec@(1,5) (33.6%, 64.9%)
11/25 08:34:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][195/196]	Step 1960	Loss 2.5981	Prec@(1,5) (33.7%, 64.9%)
11/25 08:34:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 33.7280%
11/25 08:34:48午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 08:34:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.7280%
11/25 08:36:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][100/195]	Step 2060	lr 0.02474	Loss 2.3212 (2.3565)	Arch Loss 2.6454 (2.5757)	Arch Hard Loss 2.6454 (2.5757)	Arch Beta Loss 345.8302 (346.1973)	Arch depth Loss -0.0411 (-0.0398)	Prec@(1,5) (37.5%, 70.8%)	
11/25 08:38:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][195/195]	Step 2155	lr 0.02474	Loss 2.1177 (2.3604)	Arch Loss 2.4272 (2.5396)	Arch Hard Loss 2.4272 (2.5396)	Arch Beta Loss 345.4162 (345.8892)	Arch depth Loss -0.0403 (-0.0402)	Prec@(1,5) (37.2%, 70.6%)	
11/25 08:38:02午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 10/149] Final Prec@1 37.1760%
11/25 08:38:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/196]	Step 2156	Loss 2.5257	Prec@(1,5) (34.1%, 67.7%)
11/25 08:38:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][195/196]	Step 2156	Loss 2.5320	Prec@(1,5) (33.7%, 67.4%)
11/25 08:38:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 33.7640%
11/25 08:38:33午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/25 08:38:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.7640%
11/25 08:40:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][100/195]	Step 2256	lr 0.02468	Loss 2.1595 (2.2594)	Arch Loss 2.3483 (2.4758)	Arch Hard Loss 2.3483 (2.4758)	Arch Beta Loss 344.5710 (344.8070)	Arch depth Loss -0.0451 (-0.0425)	Prec@(1,5) (39.9%, 72.6%)	
11/25 08:41:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][195/195]	Step 2351	lr 0.02468	Loss 2.4395 (2.2670)	Arch Loss 2.6282 (2.4871)	Arch Hard Loss 2.6282 (2.4871)	Arch Beta Loss 344.0078 (344.5534)	Arch depth Loss -0.0476 (-0.0444)	Prec@(1,5) (39.5%, 72.5%)	
11/25 08:41:46午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 11/149] Final Prec@1 39.4680%
11/25 08:42:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/196]	Step 2352	Loss 2.7147	Prec@(1,5) (31.7%, 63.1%)
11/25 08:42:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][195/196]	Step 2352	Loss 2.7041	Prec@(1,5) (32.2%, 63.5%)
11/25 08:42:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 32.1640%
11/25 08:42:17午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 08:42:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.7640%
11/25 08:43:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][100/195]	Step 2452	lr 0.02462	Loss 2.2782 (2.1558)	Arch Loss 2.5217 (2.4342)	Arch Hard Loss 2.5217 (2.4342)	Arch Beta Loss 343.4341 (343.6791)	Arch depth Loss -0.0517 (-0.0501)	Prec@(1,5) (41.6%, 74.7%)	
11/25 08:45:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][195/195]	Step 2547	lr 0.02462	Loss 2.3413 (2.1856)	Arch Loss 2.5494 (2.4127)	Arch Hard Loss 2.5494 (2.4127)	Arch Beta Loss 342.7321 (343.3497)	Arch depth Loss -0.0508 (-0.0509)	Prec@(1,5) (41.1%, 74.1%)	
11/25 08:45:30午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 12/149] Final Prec@1 41.0920%
11/25 08:45:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/196]	Step 2548	Loss 2.4894	Prec@(1,5) (36.3%, 68.0%)
11/25 08:46:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][195/196]	Step 2548	Loss 2.4877	Prec@(1,5) (36.2%, 68.5%)
11/25 08:46:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 36.2320%
11/25 08:46:01午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 08:46:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.2320%
11/25 08:47:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][100/195]	Step 2648	lr 0.02456	Loss 2.1693 (2.0825)	Arch Loss 2.5379 (2.3867)	Arch Hard Loss 2.5379 (2.3867)	Arch Beta Loss 341.9840 (342.3855)	Arch depth Loss -0.0544 (-0.0520)	Prec@(1,5) (43.7%, 76.6%)	
11/25 08:49:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][195/195]	Step 2743	lr 0.02456	Loss 2.0882 (2.0996)	Arch Loss 2.5286 (2.3636)	Arch Hard Loss 2.5286 (2.3636)	Arch Beta Loss 341.8404 (342.1671)	Arch depth Loss -0.0542 (-0.0528)	Prec@(1,5) (43.1%, 75.9%)	
11/25 08:49:14午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 13/149] Final Prec@1 43.1120%
11/25 08:49:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/196]	Step 2744	Loss 2.3454	Prec@(1,5) (39.0%, 71.2%)
11/25 08:49:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][195/196]	Step 2744	Loss 2.3429	Prec@(1,5) (39.2%, 71.1%)
11/25 08:49:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 39.1480%
11/25 08:49:45午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 08:49:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.1480%
11/25 08:51:24午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][100/195]	Step 2844	lr 0.02449	Loss 1.8383 (2.0036)	Arch Loss 2.2780 (2.3235)	Arch Hard Loss 2.2780 (2.3235)	Arch Beta Loss 341.0948 (341.4453)	Arch depth Loss -0.0560 (-0.0546)	Prec@(1,5) (45.0%, 77.6%)	
11/25 08:52:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][195/195]	Step 2939	lr 0.02449	Loss 1.9424 (2.0302)	Arch Loss 2.5587 (2.2984)	Arch Hard Loss 2.5587 (2.2984)	Arch Beta Loss 340.3875 (341.1132)	Arch depth Loss -0.0551 (-0.0550)	Prec@(1,5) (44.7%, 76.9%)	
11/25 08:52:58午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 14/149] Final Prec@1 44.6960%
11/25 08:53:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/196]	Step 2940	Loss 2.3023	Prec@(1,5) (40.1%, 71.6%)
11/25 08:53:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][195/196]	Step 2940	Loss 2.2843	Prec@(1,5) (40.1%, 72.0%)
11/25 08:53:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 40.1160%
11/25 08:53:28午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 08:53:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.1160%
11/25 08:55:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][100/195]	Step 3040	lr 0.02441	Loss 1.9819 (1.9484)	Arch Loss 1.9214 (2.2903)	Arch Hard Loss 1.9214 (2.2903)	Arch Beta Loss 339.5213 (339.9411)	Arch depth Loss -0.0561 (-0.0555)	Prec@(1,5) (46.2%, 78.9%)	
11/25 08:56:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][195/195]	Step 3135	lr 0.02441	Loss 1.7141 (1.9611)	Arch Loss 1.9979 (2.2622)	Arch Hard Loss 1.9979 (2.2622)	Arch Beta Loss 339.2504 (339.6785)	Arch depth Loss -0.0545 (-0.0552)	Prec@(1,5) (46.2%, 78.5%)	
11/25 08:56:42午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 15/149] Final Prec@1 46.2120%
11/25 08:56:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/196]	Step 3136	Loss 2.3267	Prec@(1,5) (39.6%, 72.2%)
11/25 08:57:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][195/196]	Step 3136	Loss 2.3327	Prec@(1,5) (39.4%, 71.9%)
11/25 08:57:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 39.4120%
11/25 08:57:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 08:57:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.1160%
11/25 08:58:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][100/195]	Step 3236	lr 0.02433	Loss 1.8148 (1.8830)	Arch Loss 2.1323 (2.2252)	Arch Hard Loss 2.1323 (2.2252)	Arch Beta Loss 338.4853 (338.8845)	Arch depth Loss -0.0560 (-0.0549)	Prec@(1,5) (48.4%, 79.9%)	
11/25 09:00:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][195/195]	Step 3331	lr 0.02433	Loss 2.0697 (1.9118)	Arch Loss 2.1097 (2.2320)	Arch Hard Loss 2.1097 (2.2320)	Arch Beta Loss 338.1745 (338.6495)	Arch depth Loss -0.0574 (-0.0556)	Prec@(1,5) (47.8%, 79.3%)	
11/25 09:00:26午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 16/149] Final Prec@1 47.7560%
11/25 09:00:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/196]	Step 3332	Loss 2.1899	Prec@(1,5) (42.2%, 74.2%)
11/25 09:00:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][195/196]	Step 3332	Loss 2.1903	Prec@(1,5) (42.2%, 74.2%)
11/25 09:00:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 42.2080%
11/25 09:00:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:00:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.2080%
11/25 09:02:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][100/195]	Step 3432	lr 0.02425	Loss 1.6954 (1.8082)	Arch Loss 2.5101 (2.2073)	Arch Hard Loss 2.5101 (2.2073)	Arch Beta Loss 337.4318 (337.7939)	Arch depth Loss -0.0554 (-0.0563)	Prec@(1,5) (49.5%, 81.3%)	
11/25 09:04:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][195/195]	Step 3527	lr 0.02425	Loss 1.9888 (1.8425)	Arch Loss 2.3867 (2.1942)	Arch Hard Loss 2.3867 (2.1942)	Arch Beta Loss 336.6884 (337.5044)	Arch depth Loss -0.0558 (-0.0561)	Prec@(1,5) (48.6%, 80.8%)	
11/25 09:04:11午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 17/149] Final Prec@1 48.5880%
11/25 09:04:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/196]	Step 3528	Loss 2.2245	Prec@(1,5) (41.6%, 73.5%)
11/25 09:04:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][195/196]	Step 3528	Loss 2.2255	Prec@(1,5) (41.4%, 73.5%)
11/25 09:04:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 41.4200%
11/25 09:04:41午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:04:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.2080%
11/25 09:06:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][100/195]	Step 3628	lr 0.02416	Loss 1.6128 (1.7756)	Arch Loss 2.3519 (2.1896)	Arch Hard Loss 2.3519 (2.1896)	Arch Beta Loss 335.9594 (336.3187)	Arch depth Loss -0.0553 (-0.0558)	Prec@(1,5) (50.3%, 82.1%)	
11/25 09:07:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][195/195]	Step 3723	lr 0.02416	Loss 1.6860 (1.7845)	Arch Loss 2.1500 (2.1619)	Arch Hard Loss 2.1500 (2.1619)	Arch Beta Loss 335.2221 (336.0033)	Arch depth Loss -0.0514 (-0.0541)	Prec@(1,5) (50.1%, 81.8%)	
11/25 09:07:55午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 18/149] Final Prec@1 50.1000%
11/25 09:08:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/196]	Step 3724	Loss 2.1946	Prec@(1,5) (41.8%, 74.5%)
11/25 09:08:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][195/196]	Step 3724	Loss 2.1958	Prec@(1,5) (42.1%, 74.5%)
11/25 09:08:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 42.0640%
11/25 09:08:25午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:08:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.2080%
11/25 09:10:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][100/195]	Step 3824	lr 0.02406	Loss 1.7273 (1.7001)	Arch Loss 1.9882 (2.1439)	Arch Hard Loss 1.9882 (2.1439)	Arch Beta Loss 334.3868 (334.9268)	Arch depth Loss -0.0502 (-0.0504)	Prec@(1,5) (52.2%, 83.6%)	
11/25 09:11:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][195/195]	Step 3919	lr 0.02406	Loss 1.5387 (1.7393)	Arch Loss 2.1754 (2.1457)	Arch Hard Loss 2.1754 (2.1457)	Arch Beta Loss 333.2444 (334.3946)	Arch depth Loss -0.0476 (-0.0497)	Prec@(1,5) (51.4%, 82.9%)	
11/25 09:11:39午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 19/149] Final Prec@1 51.4200%
11/25 09:11:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/196]	Step 3920	Loss 2.2382	Prec@(1,5) (42.3%, 73.1%)
11/25 09:12:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][195/196]	Step 3920	Loss 2.2329	Prec@(1,5) (42.3%, 73.4%)
11/25 09:12:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 42.2560%
11/25 09:12:09午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:12:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.2560%
11/25 09:13:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][100/195]	Step 4020	lr 0.02396	Loss 1.6391 (1.6735)	Arch Loss 2.2125 (2.1236)	Arch Hard Loss 2.2125 (2.1236)	Arch Beta Loss 332.3775 (332.8225)	Arch depth Loss -0.0439 (-0.0462)	Prec@(1,5) (53.0%, 83.6%)	
11/25 09:15:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][195/195]	Step 4115	lr 0.02396	Loss 1.6314 (1.6891)	Arch Loss 1.9971 (2.1083)	Arch Hard Loss 1.9971 (2.1083)	Arch Beta Loss 331.5028 (332.4151)	Arch depth Loss -0.0393 (-0.0438)	Prec@(1,5) (52.5%, 83.4%)	
11/25 09:15:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 20/149] Final Prec@1 52.4880%
11/25 09:15:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/196]	Step 4116	Loss 2.1869	Prec@(1,5) (42.5%, 75.1%)
11/25 09:15:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][195/196]	Step 4116	Loss 2.1836	Prec@(1,5) (43.0%, 74.9%)
11/25 09:15:54午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 43.0280%
11/25 09:15:54午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:15:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.0280%
11/25 09:17:33午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][100/195]	Step 4216	lr 0.02386	Loss 1.5895 (1.6319)	Arch Loss 1.9325 (2.1072)	Arch Hard Loss 1.9325 (2.1072)	Arch Beta Loss 330.6830 (331.1456)	Arch depth Loss -0.0366 (-0.0377)	Prec@(1,5) (53.5%, 84.4%)	
11/25 09:19:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][195/195]	Step 4311	lr 0.02386	Loss 1.7698 (1.6441)	Arch Loss 1.9624 (2.0891)	Arch Hard Loss 1.9624 (2.0891)	Arch Beta Loss 329.8461 (330.7320)	Arch depth Loss -0.0321 (-0.0363)	Prec@(1,5) (53.2%, 84.3%)	
11/25 09:19:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 21/149] Final Prec@1 53.2160%
11/25 09:19:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/196]	Step 4312	Loss 2.0967	Prec@(1,5) (45.4%, 76.5%)
11/25 09:19:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][195/196]	Step 4312	Loss 2.1117	Prec@(1,5) (45.2%, 76.1%)
11/25 09:19:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 45.1360%
11/25 09:19:37午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:19:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1360%
11/25 09:21:17午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][100/195]	Step 4412	lr 0.02375	Loss 1.5588 (1.5659)	Arch Loss 1.9419 (2.0890)	Arch Hard Loss 1.9419 (2.0890)	Arch Beta Loss 328.6992 (329.1554)	Arch depth Loss -0.0278 (-0.0303)	Prec@(1,5) (55.9%, 85.9%)	
11/25 09:22:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][195/195]	Step 4507	lr 0.02375	Loss 1.7166 (1.5911)	Arch Loss 2.0112 (2.0673)	Arch Hard Loss 2.0112 (2.0673)	Arch Beta Loss 327.8093 (328.6923)	Arch depth Loss -0.0231 (-0.0276)	Prec@(1,5) (55.2%, 85.2%)	
11/25 09:22:51午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 22/149] Final Prec@1 55.1960%
11/25 09:23:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/196]	Step 4508	Loss 2.1191	Prec@(1,5) (44.4%, 76.1%)
11/25 09:23:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][195/196]	Step 4508	Loss 2.1280	Prec@(1,5) (44.0%, 75.7%)
11/25 09:23:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 44.0160%
11/25 09:23:22午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:23:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1360%
11/25 09:25:01午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][100/195]	Step 4608	lr 0.02363	Loss 1.4870 (1.5431)	Arch Loss 2.0475 (2.0432)	Arch Hard Loss 2.0475 (2.0432)	Arch Beta Loss 326.7601 (327.2193)	Arch depth Loss -0.0144 (-0.0195)	Prec@(1,5) (56.2%, 86.0%)	
11/25 09:26:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][195/195]	Step 4703	lr 0.02363	Loss 1.6215 (1.5657)	Arch Loss 1.9873 (2.0389)	Arch Hard Loss 1.9873 (2.0389)	Arch Beta Loss 325.9426 (326.7939)	Arch depth Loss -0.0099 (-0.0161)	Prec@(1,5) (55.4%, 85.5%)	
11/25 09:26:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 23/149] Final Prec@1 55.3800%
11/25 09:26:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/196]	Step 4704	Loss 2.0511	Prec@(1,5) (46.5%, 76.7%)
11/25 09:27:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][195/196]	Step 4704	Loss 2.0605	Prec@(1,5) (46.2%, 76.6%)
11/25 09:27:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 46.1960%
11/25 09:27:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:27:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.1960%
11/25 09:28:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][100/195]	Step 4804	lr 0.02352	Loss 1.3574 (1.4763)	Arch Loss 2.2035 (2.0211)	Arch Hard Loss 2.2035 (2.0211)	Arch Beta Loss 324.9453 (325.4727)	Arch depth Loss -0.0038 (-0.0074)	Prec@(1,5) (57.8%, 87.6%)	
11/25 09:30:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][195/195]	Step 4899	lr 0.02352	Loss 1.4861 (1.5143)	Arch Loss 1.9861 (2.0187)	Arch Hard Loss 1.9861 (2.0187)	Arch Beta Loss 324.2459 (325.0580)	Arch depth Loss 0.0039 (-0.0036)	Prec@(1,5) (57.1%, 86.5%)	
11/25 09:30:19午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 24/149] Final Prec@1 57.0560%
11/25 09:30:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/196]	Step 4900	Loss 2.0878	Prec@(1,5) (45.1%, 76.3%)
11/25 09:30:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][195/196]	Step 4900	Loss 2.0908	Prec@(1,5) (45.3%, 76.4%)
11/25 09:30:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 45.3000%
11/25 09:30:50午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:30:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.1960%
11/25 09:32:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][100/195]	Step 5000	lr 0.02339	Loss 1.5811 (1.4608)	Arch Loss 2.1044 (2.0047)	Arch Hard Loss 2.1044 (2.0047)	Arch Beta Loss 323.3228 (323.8565)	Arch depth Loss 0.0117 (0.0077)	Prec@(1,5) (58.0%, 87.6%)	
11/25 09:34:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][195/195]	Step 5095	lr 0.02339	Loss 1.5538 (1.4808)	Arch Loss 2.0949 (2.0191)	Arch Hard Loss 2.0949 (2.0191)	Arch Beta Loss 322.5656 (323.4169)	Arch depth Loss 0.0177 (0.0109)	Prec@(1,5) (57.6%, 87.0%)	
11/25 09:34:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 25/149] Final Prec@1 57.5640%
11/25 09:34:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/196]	Step 5096	Loss 2.0593	Prec@(1,5) (45.7%, 77.4%)
11/25 09:34:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][195/196]	Step 5096	Loss 2.0621	Prec@(1,5) (45.8%, 77.3%)
11/25 09:34:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 45.8160%
11/25 09:34:34午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:34:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.1960%
11/25 09:36:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][100/195]	Step 5196	lr 0.02326	Loss 1.4057 (1.4107)	Arch Loss 1.9711 (2.0128)	Arch Hard Loss 1.9711 (2.0128)	Arch Beta Loss 321.8604 (322.2702)	Arch depth Loss 0.0246 (0.0215)	Prec@(1,5) (59.6%, 88.0%)	
11/25 09:37:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][195/195]	Step 5291	lr 0.02326	Loss 1.4410 (1.4450)	Arch Loss 1.9344 (1.9996)	Arch Hard Loss 1.9344 (1.9996)	Arch Beta Loss 321.0405 (321.8438)	Arch depth Loss 0.0338 (0.0253)	Prec@(1,5) (58.7%, 87.5%)	
11/25 09:37:47午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 26/149] Final Prec@1 58.7560%
11/25 09:38:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/196]	Step 5292	Loss 2.0334	Prec@(1,5) (46.2%, 77.4%)
11/25 09:38:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][195/196]	Step 5292	Loss 2.0352	Prec@(1,5) (45.9%, 77.6%)
11/25 09:38:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 45.9120%
11/25 09:38:17午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:38:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.1960%
11/25 09:39:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][100/195]	Step 5392	lr 0.02313	Loss 1.2692 (1.3788)	Arch Loss 2.2095 (2.0022)	Arch Hard Loss 2.2095 (2.0022)	Arch Beta Loss 320.0087 (320.5651)	Arch depth Loss 0.0435 (0.0385)	Prec@(1,5) (60.2%, 88.5%)	
11/25 09:41:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][195/195]	Step 5487	lr 0.02313	Loss 1.4101 (1.4082)	Arch Loss 1.9173 (1.9884)	Arch Hard Loss 1.9173 (1.9884)	Arch Beta Loss 319.2743 (320.0980)	Arch depth Loss 0.0513 (0.0421)	Prec@(1,5) (59.1%, 88.2%)	
11/25 09:41:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 27/149] Final Prec@1 59.0880%
11/25 09:41:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/196]	Step 5488	Loss 1.9836	Prec@(1,5) (47.6%, 78.7%)
11/25 09:42:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][195/196]	Step 5488	Loss 1.9890	Prec@(1,5) (47.7%, 78.5%)
11/25 09:42:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 47.7360%
11/25 09:42:01午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:42:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.7360%
11/25 09:43:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][100/195]	Step 5588	lr 0.023	Loss 1.3674 (1.3361)	Arch Loss 1.7252 (1.9580)	Arch Hard Loss 1.7252 (1.9580)	Arch Beta Loss 318.4980 (318.8684)	Arch depth Loss 0.0592 (0.0550)	Prec@(1,5) (61.5%, 89.2%)	
11/25 09:45:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][195/195]	Step 5683	lr 0.023	Loss 1.5234 (1.3573)	Arch Loss 2.1514 (1.9615)	Arch Hard Loss 2.1514 (1.9615)	Arch Beta Loss 317.6053 (318.4698)	Arch depth Loss 0.0713 (0.0601)	Prec@(1,5) (60.7%, 88.8%)	
11/25 09:45:15午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 28/149] Final Prec@1 60.7200%
11/25 09:45:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/196]	Step 5684	Loss 1.9982	Prec@(1,5) (47.7%, 78.3%)
11/25 09:45:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][195/196]	Step 5684	Loss 1.9936	Prec@(1,5) (47.7%, 78.6%)
11/25 09:45:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 47.7560%
11/25 09:45:45午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:45:46午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.7560%
11/25 09:47:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][100/195]	Step 5784	lr 0.02285	Loss 1.2747 (1.3193)	Arch Loss 2.0365 (1.9660)	Arch Hard Loss 2.0365 (1.9660)	Arch Beta Loss 316.5517 (316.9872)	Arch depth Loss 0.0785 (0.0747)	Prec@(1,5) (61.8%, 89.6%)	
11/25 09:48:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][195/195]	Step 5879	lr 0.02285	Loss 1.4397 (1.3377)	Arch Loss 2.1398 (1.9659)	Arch Hard Loss 2.1398 (1.9659)	Arch Beta Loss 315.6340 (316.4957)	Arch depth Loss 0.0907 (0.0800)	Prec@(1,5) (61.2%, 89.3%)	
11/25 09:48:58午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 29/149] Final Prec@1 61.1640%
11/25 09:49:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/196]	Step 5880	Loss 2.0745	Prec@(1,5) (46.2%, 76.9%)
11/25 09:49:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][195/196]	Step 5880	Loss 2.0530	Prec@(1,5) (46.3%, 77.4%)
11/25 09:49:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 46.2800%
11/25 09:49:29午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 09:49:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.7560%
11/25 09:49:29午前 searchEvalStage_curriculum_trainer.py:146 [INFO] --> Curriculum part A finished. Part B begins!
11/25 09:51:08午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][100/195]	Step 5980	lr 0.02271	Loss 1.4787 (1.2928)	Arch Loss 2.1252 (2.2785)	Arch Hard Loss 1.8175 (1.9668)	Arch Beta Loss 307.7735 (311.6307)	Arch depth Loss 0.1035 (0.0976)	Prec@(1,5) (61.9%, 89.9%)	
11/25 09:52:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][195/195]	Step 6075	lr 0.02271	Loss 1.3121 (1.3204)	Arch Loss 2.0913 (2.2719)	Arch Hard Loss 1.7902 (1.9638)	Arch Beta Loss 301.1525 (308.1184)	Arch depth Loss 0.1096 (0.1021)	Prec@(1,5) (61.3%, 89.3%)	
11/25 09:52:42午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 30/149] Final Prec@1 61.2480%
11/25 09:52:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/196]	Step 6076	Loss 1.9731	Prec@(1,5) (47.9%, 78.5%)
11/25 09:53:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][195/196]	Step 6076	Loss 1.9619	Prec@(1,5) (48.3%, 78.6%)
11/25 09:53:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 48.2880%
11/25 09:53:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 09:53:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.2880%
11/25 09:54:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][100/195]	Step 6176	lr 0.02256	Loss 1.3863 (1.2452)	Arch Loss 2.0649 (2.2147)	Arch Hard Loss 1.7702 (1.9169)	Arch Beta Loss 294.6103 (297.7251)	Arch depth Loss 0.1215 (0.1161)	Prec@(1,5) (63.8%, 90.4%)	
11/25 09:56:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][195/195]	Step 6271	lr 0.02256	Loss 1.5382 (1.2808)	Arch Loss 2.5065 (2.2292)	Arch Hard Loss 2.2173 (1.9344)	Arch Beta Loss 289.1619 (294.8648)	Arch depth Loss 0.1295 (0.1203)	Prec@(1,5) (62.7%, 89.9%)	
11/25 09:56:27午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 31/149] Final Prec@1 62.7280%
11/25 09:56:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/196]	Step 6272	Loss 1.9816	Prec@(1,5) (47.4%, 78.7%)
11/25 09:56:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][195/196]	Step 6272	Loss 1.9788	Prec@(1,5) (47.4%, 78.9%)
11/25 09:56:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 47.4120%
11/25 09:56:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 09:56:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.2880%
11/25 09:58:37午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][100/195]	Step 6372	lr 0.0224	Loss 1.1227 (1.2141)	Arch Loss 2.4325 (2.2047)	Arch Hard Loss 2.1488 (1.9184)	Arch Beta Loss 283.6904 (286.3044)	Arch depth Loss 0.1414 (0.1350)	Prec@(1,5) (64.6%, 90.9%)	
11/25 10:00:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][195/195]	Step 6467	lr 0.0224	Loss 1.4258 (1.2495)	Arch Loss 2.2776 (2.2171)	Arch Hard Loss 1.9989 (1.9333)	Arch Beta Loss 278.6875 (283.7778)	Arch depth Loss 0.1523 (0.1410)	Prec@(1,5) (63.7%, 90.3%)	
11/25 10:00:11午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 32/149] Final Prec@1 63.7320%
11/25 10:00:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/196]	Step 6468	Loss 1.9703	Prec@(1,5) (48.1%, 79.0%)
11/25 10:00:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][195/196]	Step 6468	Loss 1.9620	Prec@(1,5) (48.5%, 79.2%)
11/25 10:00:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 48.4600%
11/25 10:00:41午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:00:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.4600%
11/25 10:02:21午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][100/195]	Step 6568	lr 0.02225	Loss 1.5153 (1.2036)	Arch Loss 2.3838 (2.1891)	Arch Hard Loss 2.1101 (1.9130)	Arch Beta Loss 273.7076 (276.1537)	Arch depth Loss 0.1623 (0.1583)	Prec@(1,5) (65.0%, 91.5%)	
11/25 10:03:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][195/195]	Step 6663	lr 0.02225	Loss 1.2863 (1.2261)	Arch Loss 2.2427 (2.1898)	Arch Hard Loss 1.9731 (1.9159)	Arch Beta Loss 269.5072 (273.9203)	Arch depth Loss 0.1749 (0.1637)	Prec@(1,5) (64.3%, 90.9%)	
11/25 10:03:55午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 33/149] Final Prec@1 64.3080%
11/25 10:04:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/196]	Step 6664	Loss 1.9467	Prec@(1,5) (49.0%, 79.1%)
11/25 10:04:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][195/196]	Step 6664	Loss 1.9359	Prec@(1,5) (49.1%, 79.2%)
11/25 10:04:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 49.1280%
11/25 10:04:26午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:04:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1280%
11/25 10:06:05午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][100/195]	Step 6764	lr 0.02208	Loss 1.1358 (1.1632)	Arch Loss 2.1907 (2.2048)	Arch Hard Loss 1.9255 (1.9375)	Arch Beta Loss 265.1420 (267.2982)	Arch depth Loss 0.1853 (0.1789)	Prec@(1,5) (66.0%, 91.6%)	
11/25 10:07:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][195/195]	Step 6859	lr 0.02208	Loss 1.1748 (1.1881)	Arch Loss 2.3238 (2.1771)	Arch Hard Loss 2.0628 (1.9119)	Arch Beta Loss 261.0168 (265.2585)	Arch depth Loss 0.1942 (0.1838)	Prec@(1,5) (65.2%, 91.2%)	
11/25 10:07:40午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 34/149] Final Prec@1 65.1960%
11/25 10:07:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/196]	Step 6860	Loss 1.9343	Prec@(1,5) (49.1%, 79.6%)
11/25 10:08:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][195/196]	Step 6860	Loss 1.9459	Prec@(1,5) (49.0%, 79.4%)
11/25 10:08:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 48.9560%
11/25 10:08:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:08:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1280%
11/25 10:09:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][100/195]	Step 6960	lr 0.02192	Loss 1.2878 (1.1656)	Arch Loss 2.0044 (2.1834)	Arch Hard Loss 1.7478 (1.9247)	Arch Beta Loss 256.5868 (258.7641)	Arch depth Loss 0.2071 (0.2017)	Prec@(1,5) (65.9%, 92.0%)	
11/25 10:11:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][195/195]	Step 7055	lr 0.02192	Loss 1.3847 (1.1802)	Arch Loss 2.3216 (2.1760)	Arch Hard Loss 2.0690 (1.9192)	Arch Beta Loss 252.5320 (256.7286)	Arch depth Loss 0.2174 (0.2067)	Prec@(1,5) (65.5%, 91.5%)	
11/25 10:11:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 35/149] Final Prec@1 65.4680%
11/25 10:11:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/196]	Step 7056	Loss 1.9816	Prec@(1,5) (48.5%, 79.2%)
11/25 10:11:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][195/196]	Step 7056	Loss 1.9764	Prec@(1,5) (49.0%, 79.0%)
11/25 10:11:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 48.9400%
11/25 10:11:53午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:11:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1280%
11/25 10:13:32午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][100/195]	Step 7156	lr 0.02175	Loss 1.1775 (1.1147)	Arch Loss 2.4225 (2.1781)	Arch Hard Loss 2.1740 (1.9275)	Arch Beta Loss 248.5455 (250.5125)	Arch depth Loss 0.2287 (0.2220)	Prec@(1,5) (66.5%, 92.2%)	
11/25 10:15:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][195/195]	Step 7251	lr 0.02175	Loss 1.1726 (1.1525)	Arch Loss 2.4661 (2.1590)	Arch Hard Loss 2.2212 (1.9104)	Arch Beta Loss 244.9181 (248.6732)	Arch depth Loss 0.2372 (0.2271)	Prec@(1,5) (65.8%, 91.6%)	
11/25 10:15:06午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 36/149] Final Prec@1 65.7880%
11/25 10:15:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/196]	Step 7252	Loss 1.9619	Prec@(1,5) (48.7%, 79.4%)
11/25 10:15:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][195/196]	Step 7252	Loss 1.9714	Prec@(1,5) (48.5%, 79.0%)
11/25 10:15:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 48.5000%
11/25 10:15:37午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:15:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1280%
11/25 10:17:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][100/195]	Step 7352	lr 0.02157	Loss 1.1212 (1.1049)	Arch Loss 2.0579 (2.1471)	Arch Hard Loss 1.8166 (1.9041)	Arch Beta Loss 241.2517 (243.0396)	Arch depth Loss 0.2505 (0.2443)	Prec@(1,5) (67.7%, 92.8%)	
11/25 10:18:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][195/195]	Step 7447	lr 0.02157	Loss 1.0682 (1.1305)	Arch Loss 2.0254 (2.1404)	Arch Hard Loss 1.7875 (1.8991)	Arch Beta Loss 237.8674 (241.3324)	Arch depth Loss 0.2626 (0.2498)	Prec@(1,5) (67.0%, 92.2%)	
11/25 10:18:50午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 37/149] Final Prec@1 67.0080%
11/25 10:19:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/196]	Step 7448	Loss 1.9436	Prec@(1,5) (48.7%, 79.6%)
11/25 10:19:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][195/196]	Step 7448	Loss 1.9342	Prec@(1,5) (49.1%, 79.6%)
11/25 10:19:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 49.0560%
11/25 10:19:21午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:19:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1280%
11/25 10:21:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][100/195]	Step 7548	lr 0.0214	Loss 0.8699 (1.0656)	Arch Loss 2.1105 (2.1269)	Arch Hard Loss 1.8759 (1.8907)	Arch Beta Loss 234.5739 (236.2222)	Arch depth Loss 0.2731 (0.2679)	Prec@(1,5) (68.7%, 92.8%)	
11/25 10:22:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][195/195]	Step 7643	lr 0.0214	Loss 1.4175 (1.0972)	Arch Loss 1.7297 (2.1098)	Arch Hard Loss 1.4984 (1.8752)	Arch Beta Loss 231.3339 (234.6282)	Arch depth Loss 0.2821 (0.2724)	Prec@(1,5) (67.7%, 92.5%)	
11/25 10:22:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 38/149] Final Prec@1 67.7240%
11/25 10:22:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/196]	Step 7644	Loss 1.9520	Prec@(1,5) (48.9%, 79.5%)
11/25 10:23:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][195/196]	Step 7644	Loss 1.9419	Prec@(1,5) (49.2%, 79.8%)
11/25 10:23:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 49.1560%
11/25 10:23:05午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:23:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1560%
11/25 10:24:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][100/195]	Step 7744	lr 0.02121	Loss 1.3437 (1.0627)	Arch Loss 1.9428 (2.1098)	Arch Hard Loss 1.7147 (1.8802)	Arch Beta Loss 228.1273 (229.6660)	Arch depth Loss 0.2935 (0.2880)	Prec@(1,5) (68.5%, 93.0%)	
11/25 10:26:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][195/195]	Step 7839	lr 0.02121	Loss 1.1803 (1.0796)	Arch Loss 2.3473 (2.1203)	Arch Hard Loss 2.1225 (1.8922)	Arch Beta Loss 224.7873 (228.1092)	Arch depth Loss 0.3082 (0.2937)	Prec@(1,5) (67.9%, 92.8%)	
11/25 10:26:19午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 39/149] Final Prec@1 67.8920%
11/25 10:26:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/196]	Step 7840	Loss 1.9970	Prec@(1,5) (48.2%, 78.7%)
11/25 10:26:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][195/196]	Step 7840	Loss 1.9873	Prec@(1,5) (48.5%, 79.0%)
11/25 10:26:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 48.4640%
11/25 10:26:49午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:26:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1560%
11/25 10:28:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][100/195]	Step 7940	lr 0.02103	Loss 0.9570 (1.0310)	Arch Loss 1.9394 (2.1240)	Arch Hard Loss 1.7177 (1.9007)	Arch Beta Loss 221.6842 (223.2649)	Arch depth Loss 0.3260 (0.3174)	Prec@(1,5) (69.6%, 93.8%)	
11/25 10:30:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][195/195]	Step 8035	lr 0.02103	Loss 1.0813 (1.0657)	Arch Loss 2.3502 (2.1044)	Arch Hard Loss 2.1313 (1.8827)	Arch Beta Loss 218.8633 (221.7874)	Arch depth Loss 0.3366 (0.3239)	Prec@(1,5) (68.5%, 93.2%)	
11/25 10:30:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 40/149] Final Prec@1 68.4760%
11/25 10:30:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/196]	Step 8036	Loss 2.0095	Prec@(1,5) (48.6%, 78.2%)
11/25 10:30:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][195/196]	Step 8036	Loss 1.9946	Prec@(1,5) (49.0%, 78.6%)
11/25 10:30:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 48.9880%
11/25 10:30:33午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:30:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1560%
11/25 10:32:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][100/195]	Step 8136	lr 0.02084	Loss 1.0113 (1.0217)	Arch Loss 2.0284 (2.1190)	Arch Hard Loss 1.8125 (1.9017)	Arch Beta Loss 215.9115 (217.3491)	Arch depth Loss 0.3501 (0.3441)	Prec@(1,5) (70.1%, 93.5%)	
11/25 10:33:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][195/195]	Step 8231	lr 0.02084	Loss 1.2965 (1.0576)	Arch Loss 1.9843 (2.1137)	Arch Hard Loss 1.7711 (1.8977)	Arch Beta Loss 213.1535 (215.9642)	Arch depth Loss 0.3598 (0.3494)	Prec@(1,5) (68.8%, 93.1%)	
11/25 10:33:47午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 41/149] Final Prec@1 68.8280%
11/25 10:34:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/196]	Step 8232	Loss 1.8938	Prec@(1,5) (50.9%, 80.2%)
11/25 10:34:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][195/196]	Step 8232	Loss 1.8920	Prec@(1,5) (50.4%, 80.4%)
11/25 10:34:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 50.3800%
11/25 10:34:17午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:34:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.3800%
11/25 10:35:57午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][100/195]	Step 8332	lr 0.02065	Loss 1.0147 (0.9878)	Arch Loss 2.0279 (2.1027)	Arch Hard Loss 1.8176 (1.8910)	Arch Beta Loss 210.2853 (211.6890)	Arch depth Loss 0.3744 (0.3669)	Prec@(1,5) (70.9%, 93.9%)	
11/25 10:37:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][195/195]	Step 8427	lr 0.02065	Loss 0.9414 (1.0271)	Arch Loss 2.1160 (2.0908)	Arch Hard Loss 1.9084 (1.8804)	Arch Beta Loss 207.5766 (210.3329)	Arch depth Loss 0.3846 (0.3732)	Prec@(1,5) (69.6%, 93.6%)	
11/25 10:37:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 42/149] Final Prec@1 69.5520%
11/25 10:37:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/196]	Step 8428	Loss 1.9443	Prec@(1,5) (49.5%, 79.9%)
11/25 10:38:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][195/196]	Step 8428	Loss 1.9326	Prec@(1,5) (49.7%, 80.0%)
11/25 10:38:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 49.6520%
11/25 10:38:01午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:38:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.3800%
11/25 10:39:41午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][100/195]	Step 8528	lr 0.02045	Loss 1.1532 (0.9835)	Arch Loss 1.8957 (2.0428)	Arch Hard Loss 1.6907 (1.8365)	Arch Beta Loss 205.0057 (206.2640)	Arch depth Loss 0.3963 (0.3913)	Prec@(1,5) (71.1%, 94.3%)	
11/25 10:41:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][195/195]	Step 8623	lr 0.02045	Loss 1.0885 (1.0130)	Arch Loss 2.2758 (2.0813)	Arch Hard Loss 2.0734 (1.8763)	Arch Beta Loss 202.4229 (205.0087)	Arch depth Loss 0.4073 (0.3963)	Prec@(1,5) (70.2%, 93.8%)	
11/25 10:41:14午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 43/149] Final Prec@1 70.1800%
11/25 10:41:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/196]	Step 8624	Loss 1.9060	Prec@(1,5) (50.3%, 80.3%)
11/25 10:41:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][195/196]	Step 8624	Loss 1.9097	Prec@(1,5) (50.2%, 80.1%)
11/25 10:41:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 50.1720%
11/25 10:41:45午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:41:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.3800%
11/25 10:43:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][100/195]	Step 8724	lr 0.02026	Loss 0.9712 (0.9763)	Arch Loss 2.1754 (2.0450)	Arch Hard Loss 1.9755 (1.8438)	Arch Beta Loss 199.8714 (201.1505)	Arch depth Loss 0.4148 (0.4110)	Prec@(1,5) (71.0%, 94.0%)	
11/25 10:44:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][195/195]	Step 8819	lr 0.02026	Loss 0.9806 (1.0002)	Arch Loss 1.8279 (2.0601)	Arch Hard Loss 1.6304 (1.8601)	Arch Beta Loss 197.4975 (199.9633)	Arch depth Loss 0.4214 (0.4146)	Prec@(1,5) (70.2%, 93.8%)	
11/25 10:44:58午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 44/149] Final Prec@1 70.1360%
11/25 10:45:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/196]	Step 8820	Loss 1.9511	Prec@(1,5) (49.9%, 79.9%)
11/25 10:45:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][195/196]	Step 8820	Loss 1.9316	Prec@(1,5) (50.2%, 80.1%)
11/25 10:45:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 50.1480%
11/25 10:45:29午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:45:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.3800%
11/25 10:47:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][100/195]	Step 8920	lr 0.02005	Loss 0.8307 (0.9559)	Arch Loss 2.1063 (2.0729)	Arch Hard Loss 1.9113 (1.8766)	Arch Beta Loss 195.0060 (196.2375)	Arch depth Loss 0.4310 (0.4258)	Prec@(1,5) (71.9%, 94.4%)	
11/25 10:48:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][195/195]	Step 9015	lr 0.02005	Loss 1.3230 (0.9736)	Arch Loss 2.0444 (2.0610)	Arch Hard Loss 1.8517 (1.8660)	Arch Beta Loss 192.7324 (195.0827)	Arch depth Loss 0.4405 (0.4304)	Prec@(1,5) (71.1%, 94.2%)	
11/25 10:48:43午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 45/149] Final Prec@1 71.0640%
11/25 10:48:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/196]	Step 9016	Loss 1.8626	Prec@(1,5) (51.4%, 81.3%)
11/25 10:49:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][195/196]	Step 9016	Loss 1.8836	Prec@(1,5) (51.0%, 80.9%)
11/25 10:49:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 50.9840%
11/25 10:49:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:49:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.9840%
11/25 10:50:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][100/195]	Step 9116	lr 0.01985	Loss 0.9008 (0.9216)	Arch Loss 2.0917 (2.0633)	Arch Hard Loss 1.9014 (1.8719)	Arch Beta Loss 190.3277 (191.4474)	Arch depth Loss 0.4486 (0.4442)	Prec@(1,5) (73.1%, 94.8%)	
11/25 10:52:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][195/195]	Step 9211	lr 0.01985	Loss 1.0264 (0.9551)	Arch Loss 1.8590 (2.0631)	Arch Hard Loss 1.6709 (1.8728)	Arch Beta Loss 188.1068 (190.3468)	Arch depth Loss 0.4561 (0.4484)	Prec@(1,5) (71.8%, 94.4%)	
11/25 10:52:26午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 46/149] Final Prec@1 71.8040%
11/25 10:52:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/196]	Step 9212	Loss 1.8865	Prec@(1,5) (51.4%, 80.4%)
11/25 10:52:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][195/196]	Step 9212	Loss 1.8780	Prec@(1,5) (51.4%, 80.8%)
11/25 10:52:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 51.4320%
11/25 10:52:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:52:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 10:54:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][100/195]	Step 9312	lr 0.01964	Loss 0.9983 (0.9086)	Arch Loss 1.8713 (2.0380)	Arch Hard Loss 1.6854 (1.8510)	Arch Beta Loss 185.9153 (186.9747)	Arch depth Loss 0.4616 (0.4578)	Prec@(1,5) (73.5%, 94.7%)	
11/25 10:56:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][195/195]	Step 9407	lr 0.01964	Loss 1.2203 (0.9508)	Arch Loss 1.9670 (2.0414)	Arch Hard Loss 1.7833 (1.8555)	Arch Beta Loss 183.7143 (185.9229)	Arch depth Loss 0.4699 (0.4617)	Prec@(1,5) (71.9%, 94.4%)	
11/25 10:56:10午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 47/149] Final Prec@1 71.9120%
11/25 10:56:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/196]	Step 9408	Loss 1.8864	Prec@(1,5) (51.2%, 80.2%)
11/25 10:56:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][195/196]	Step 9408	Loss 1.8961	Prec@(1,5) (51.0%, 80.2%)
11/25 10:56:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 51.0200%
11/25 10:56:40午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 10:56:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 10:58:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][100/195]	Step 9508	lr 0.01943	Loss 1.0207 (0.8968)	Arch Loss 2.1574 (2.0214)	Arch Hard Loss 1.9760 (1.8388)	Arch Beta Loss 181.4223 (182.5911)	Arch depth Loss 0.4801 (0.4751)	Prec@(1,5) (73.4%, 95.0%)	
11/25 10:59:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][195/195]	Step 9603	lr 0.01943	Loss 0.9610 (0.9282)	Arch Loss 2.5790 (2.0332)	Arch Hard Loss 2.3995 (1.8516)	Arch Beta Loss 179.4397 (181.5348)	Arch depth Loss 0.4865 (0.4796)	Prec@(1,5) (72.3%, 94.8%)	
11/25 10:59:53午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 48/149] Final Prec@1 72.2760%
11/25 11:00:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/196]	Step 9604	Loss 1.9225	Prec@(1,5) (51.4%, 80.1%)
11/25 11:00:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][195/196]	Step 9604	Loss 1.9245	Prec@(1,5) (50.9%, 80.2%)
11/25 11:00:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 50.9280%
11/25 11:00:24午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 11:00:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:02:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][100/195]	Step 9704	lr 0.01922	Loss 0.9268 (0.8636)	Arch Loss 2.3594 (2.0179)	Arch Hard Loss 2.1819 (1.8394)	Arch Beta Loss 177.4773 (178.4642)	Arch depth Loss 0.4959 (0.4912)	Prec@(1,5) (74.4%, 95.4%)	
11/25 11:03:36午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][195/195]	Step 9799	lr 0.01922	Loss 0.9881 (0.9078)	Arch Loss 1.9081 (2.0183)	Arch Hard Loss 1.7328 (1.8408)	Arch Beta Loss 175.3735 (177.4436)	Arch depth Loss 0.5021 (0.4951)	Prec@(1,5) (73.0%, 94.9%)	
11/25 11:03:36午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 49/149] Final Prec@1 73.0200%
11/25 11:03:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/196]	Step 9800	Loss 1.9033	Prec@(1,5) (51.0%, 80.7%)
11/25 11:04:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][195/196]	Step 9800	Loss 1.9022	Prec@(1,5) (51.0%, 80.6%)
11/25 11:04:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 50.9800%
11/25 11:04:07午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/25 11:04:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:04:08午前 searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
11/25 11:04:08午前 searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
11/25 11:04:49午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][100/351]	Step 9900	lr 0.025	Loss 2.4548 (2.7581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.3%, 62.5%)	
11/25 11:05:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][200/351]	Step 10000	lr 0.025	Loss 2.1327 (2.5056)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 67.9%)	
11/25 11:06:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][300/351]	Step 10100	lr 0.025	Loss 1.8724 (2.3797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 70.3%)	
11/25 11:06:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][351/351]	Step 10151	lr 0.025	Loss 2.1939 (2.3325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.3%)	
11/25 11:06:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 50/149] Final Prec@1 38.5489%
11/25 11:06:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][39/40]	Step 10152	Loss 2.4409	Prec@(1,5) (37.1%, 69.9%)
11/25 11:06:37午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 37.0600%
11/25 11:06:37午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:07:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][100/351]	Step 10252	lr 0.02499	Loss 2.0034 (1.9565)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 78.8%)	
11/25 11:07:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][200/351]	Step 10352	lr 0.02499	Loss 1.9891 (1.9477)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.1%)	
11/25 11:08:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][300/351]	Step 10452	lr 0.02499	Loss 1.8315 (1.9327)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.4%)	
11/25 11:08:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][351/351]	Step 10503	lr 0.02499	Loss 1.5020 (1.9244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.5%)	
11/25 11:08:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 51/149] Final Prec@1 47.8133%
11/25 11:09:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][39/40]	Step 10504	Loss 2.3091	Prec@(1,5) (40.0%, 72.7%)
11/25 11:09:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 40.0000%
11/25 11:09:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:09:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][100/351]	Step 10604	lr 0.02498	Loss 1.8736 (1.7745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.8%)	
11/25 11:10:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][200/351]	Step 10704	lr 0.02498	Loss 1.7982 (1.7928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 81.6%)	
11/25 11:11:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][300/351]	Step 10804	lr 0.02498	Loss 1.8402 (1.7984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.6%)	
11/25 11:11:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][351/351]	Step 10855	lr 0.02498	Loss 1.7428 (1.8024)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.5%)	
11/25 11:11:27午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 52/149] Final Prec@1 50.5933%
11/25 11:11:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][39/40]	Step 10856	Loss 2.0281	Prec@(1,5) (45.5%, 77.0%)
11/25 11:11:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 45.4600%
11/25 11:11:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:12:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][100/351]	Step 10956	lr 0.02495	Loss 1.7083 (1.6877)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.4%)	
11/25 11:12:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][200/351]	Step 11056	lr 0.02495	Loss 1.9045 (1.7134)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.0%)	
11/25 11:13:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][300/351]	Step 11156	lr 0.02495	Loss 1.7387 (1.7182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 82.8%)	
11/25 11:13:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][351/351]	Step 11207	lr 0.02495	Loss 1.5707 (1.7206)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 82.7%)	
11/25 11:13:55午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 53/149] Final Prec@1 52.4444%
11/25 11:14:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][39/40]	Step 11208	Loss 1.9580	Prec@(1,5) (47.0%, 78.5%)
11/25 11:14:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 47.0200%
11/25 11:14:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:14:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][100/351]	Step 11308	lr 0.02491	Loss 1.6672 (1.6653)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.3%, 84.3%)	
11/25 11:15:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][200/351]	Step 11408	lr 0.02491	Loss 1.5396 (1.6643)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 84.2%)	
11/25 11:16:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][300/351]	Step 11508	lr 0.02491	Loss 1.4830 (1.6643)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.1%)	
11/25 11:16:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][351/351]	Step 11559	lr 0.02491	Loss 1.7833 (1.6626)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.7%, 84.1%)	
11/25 11:16:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 54/149] Final Prec@1 53.7000%
11/25 11:16:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][39/40]	Step 11560	Loss 2.0177	Prec@(1,5) (46.4%, 77.8%)
11/25 11:16:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 46.3200%
11/25 11:16:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:17:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][100/351]	Step 11660	lr 0.02485	Loss 1.2504 (1.5837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 84.9%)	
11/25 11:17:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][200/351]	Step 11760	lr 0.02485	Loss 1.3951 (1.5816)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.0%)	
11/25 11:18:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][300/351]	Step 11860	lr 0.02485	Loss 1.6400 (1.5957)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.8%)	
11/25 11:18:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][351/351]	Step 11911	lr 0.02485	Loss 1.4470 (1.5959)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.7%)	
11/25 11:18:51午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 55/149] Final Prec@1 55.3911%
11/25 11:18:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][39/40]	Step 11912	Loss 1.8797	Prec@(1,5) (49.3%, 79.9%)
11/25 11:18:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 49.3200%
11/25 11:18:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:19:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][100/351]	Step 12012	lr 0.02479	Loss 1.5908 (1.5096)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.4%)	
11/25 11:20:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][200/351]	Step 12112	lr 0.02479	Loss 1.5111 (1.5389)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.8%)	
11/25 11:20:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][300/351]	Step 12212	lr 0.02479	Loss 1.6763 (1.5547)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.6%)	
11/25 11:21:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][351/351]	Step 12263	lr 0.02479	Loss 1.7081 (1.5501)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.7%)	
11/25 11:21:19午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 56/149] Final Prec@1 56.5622%
11/25 11:21:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][39/40]	Step 12264	Loss 1.9657	Prec@(1,5) (47.7%, 79.1%)
11/25 11:21:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 47.7200%
11/25 11:21:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:22:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][100/351]	Step 12364	lr 0.02471	Loss 1.3940 (1.4987)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.5%)	
11/25 11:22:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][200/351]	Step 12464	lr 0.02471	Loss 1.4307 (1.5032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.2%)	
11/25 11:23:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][300/351]	Step 12564	lr 0.02471	Loss 1.6468 (1.5175)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 85.9%)	
11/25 11:23:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][351/351]	Step 12615	lr 0.02471	Loss 1.4281 (1.5169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 85.9%)	
11/25 11:23:47午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 57/149] Final Prec@1 57.3044%
11/25 11:23:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][39/40]	Step 12616	Loss 1.8206	Prec@(1,5) (50.9%, 81.6%)
11/25 11:23:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 50.8600%
11/25 11:23:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:24:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][100/351]	Step 12716	lr 0.02462	Loss 1.7039 (1.4534)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 86.9%)	
11/25 11:25:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][200/351]	Step 12816	lr 0.02462	Loss 1.6663 (1.4685)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 86.5%)	
11/25 11:25:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][300/351]	Step 12916	lr 0.02462	Loss 1.3206 (1.4811)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.4%)	
11/25 11:26:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][351/351]	Step 12967	lr 0.02462	Loss 1.5954 (1.4824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.5%)	
11/25 11:26:15午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 58/149] Final Prec@1 58.1444%
11/25 11:26:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][39/40]	Step 12968	Loss 1.9569	Prec@(1,5) (47.7%, 79.1%)
11/25 11:26:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 47.6800%
11/25 11:26:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:27:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][100/351]	Step 13068	lr 0.02452	Loss 1.4144 (1.4198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.8%, 87.7%)	
11/25 11:27:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][200/351]	Step 13168	lr 0.02452	Loss 1.3910 (1.4362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.4%)	
11/25 11:28:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][300/351]	Step 13268	lr 0.02452	Loss 1.5546 (1.4412)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.2%)	
11/25 11:28:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][351/351]	Step 13319	lr 0.02452	Loss 1.2500 (1.4458)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.2%)	
11/25 11:28:43午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 59/149] Final Prec@1 58.7733%
11/25 11:28:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][39/40]	Step 13320	Loss 1.7591	Prec@(1,5) (51.2%, 83.0%)
11/25 11:28:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 51.2400%
11/25 11:28:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:29:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][100/351]	Step 13420	lr 0.02441	Loss 1.2886 (1.3984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.3%)	
11/25 11:30:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][200/351]	Step 13520	lr 0.02441	Loss 1.4545 (1.4139)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.9%)	
11/25 11:30:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][300/351]	Step 13620	lr 0.02441	Loss 1.4035 (1.4152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.8%)	
11/25 11:31:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][351/351]	Step 13671	lr 0.02441	Loss 1.4344 (1.4208)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.7%)	
11/25 11:31:11午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 60/149] Final Prec@1 59.4511%
11/25 11:31:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][39/40]	Step 13672	Loss 1.8673	Prec@(1,5) (48.9%, 81.0%)
11/25 11:31:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 48.9200%
11/25 11:31:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:31:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][100/351]	Step 13772	lr 0.02429	Loss 1.5065 (1.3260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 89.0%)	
11/25 11:32:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][200/351]	Step 13872	lr 0.02429	Loss 1.2634 (1.3741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.3%)	
11/25 11:33:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][300/351]	Step 13972	lr 0.02429	Loss 1.4509 (1.3885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.0%)	
11/25 11:33:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][351/351]	Step 14023	lr 0.02429	Loss 1.2986 (1.3942)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.9%)	
11/25 11:33:39午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 61/149] Final Prec@1 60.0622%
11/25 11:33:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][39/40]	Step 14024	Loss 1.9201	Prec@(1,5) (48.8%, 80.1%)
11/25 11:33:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 48.8800%
11/25 11:33:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
11/25 11:34:26午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][100/351]	Step 14124	lr 0.02416	Loss 1.4507 (1.3341)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.9%)	
11/25 11:35:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][200/351]	Step 14224	lr 0.02416	Loss 1.6420 (1.3469)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.6%)	
11/25 11:35:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][300/351]	Step 14324	lr 0.02416	Loss 1.5093 (1.3612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.4%)	
11/25 11:36:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][351/351]	Step 14375	lr 0.02416	Loss 1.2785 (1.3676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.4%)	
11/25 11:36:07午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 62/149] Final Prec@1 60.9089%
11/25 11:36:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][39/40]	Step 14376	Loss 1.7465	Prec@(1,5) (52.5%, 82.0%)
11/25 11:36:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 52.5200%
11/25 11:36:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.5200%
11/25 11:36:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][100/351]	Step 14476	lr 0.02401	Loss 1.1931 (1.2988)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.2%)	
11/25 11:37:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][200/351]	Step 14576	lr 0.02401	Loss 1.4316 (1.3238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 88.9%)	
11/25 11:38:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][300/351]	Step 14676	lr 0.02401	Loss 1.4361 (1.3352)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
11/25 11:38:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][351/351]	Step 14727	lr 0.02401	Loss 1.5376 (1.3451)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.6%)	
11/25 11:38:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 63/149] Final Prec@1 61.5733%
11/25 11:38:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][39/40]	Step 14728	Loss 2.0332	Prec@(1,5) (48.0%, 78.8%)
11/25 11:38:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 47.9800%
11/25 11:38:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.5200%
11/25 11:39:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][100/351]	Step 14828	lr 0.02386	Loss 1.4852 (1.3143)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 88.9%)	
11/25 11:40:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][200/351]	Step 14928	lr 0.02386	Loss 1.3721 (1.3238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.0%)	
11/25 11:40:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][300/351]	Step 15028	lr 0.02386	Loss 1.5369 (1.3306)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 88.9%)	
11/25 11:41:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][351/351]	Step 15079	lr 0.02386	Loss 1.1671 (1.3343)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
11/25 11:41:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 64/149] Final Prec@1 61.9156%
11/25 11:41:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][39/40]	Step 15080	Loss 1.7648	Prec@(1,5) (51.9%, 82.5%)
11/25 11:41:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 51.8800%
11/25 11:41:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.5200%
11/25 11:41:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][100/351]	Step 15180	lr 0.02369	Loss 1.1940 (1.2583)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.1%)	
11/25 11:42:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][200/351]	Step 15280	lr 0.02369	Loss 1.2647 (1.2837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.7%)	
11/25 11:43:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][300/351]	Step 15380	lr 0.02369	Loss 1.2800 (1.2992)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.4%)	
11/25 11:43:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][351/351]	Step 15431	lr 0.02369	Loss 1.2129 (1.3023)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.3%)	
11/25 11:43:31午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 65/149] Final Prec@1 62.4844%
11/25 11:43:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][39/40]	Step 15432	Loss 1.7848	Prec@(1,5) (51.8%, 82.2%)
11/25 11:43:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 51.8800%
11/25 11:43:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.5200%
11/25 11:44:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][100/351]	Step 15532	lr 0.02352	Loss 1.1990 (1.2492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.1%)	
11/25 11:44:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][200/351]	Step 15632	lr 0.02352	Loss 1.3150 (1.2720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.7%)	
11/25 11:45:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][300/351]	Step 15732	lr 0.02352	Loss 1.1649 (1.2831)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.7%)	
11/25 11:45:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][351/351]	Step 15783	lr 0.02352	Loss 1.4494 (1.2901)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.6%)	
11/25 11:45:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 66/149] Final Prec@1 62.9244%
11/25 11:46:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][39/40]	Step 15784	Loss 1.7947	Prec@(1,5) (52.3%, 82.4%)
11/25 11:46:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 52.2600%
11/25 11:46:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.5200%
11/25 11:46:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][100/351]	Step 15884	lr 0.02333	Loss 1.1805 (1.2311)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
11/25 11:47:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][200/351]	Step 15984	lr 0.02333	Loss 1.3469 (1.2469)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.2%)	
11/25 11:48:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][300/351]	Step 16084	lr 0.02333	Loss 1.0932 (1.2672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 89.8%)	
11/25 11:48:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][351/351]	Step 16135	lr 0.02333	Loss 1.1813 (1.2718)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.7%)	
11/25 11:48:27午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 67/149] Final Prec@1 63.3200%
11/25 11:48:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][39/40]	Step 16136	Loss 1.7079	Prec@(1,5) (54.2%, 83.8%)
11/25 11:48:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 54.1600%
11/25 11:48:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.1600%
11/25 11:49:15午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][100/351]	Step 16236	lr 0.02313	Loss 1.2386 (1.2020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.4%)	
11/25 11:49:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][200/351]	Step 16336	lr 0.02313	Loss 1.4743 (1.2283)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.2%)	
11/25 11:50:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][300/351]	Step 16436	lr 0.02313	Loss 1.2205 (1.2418)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 89.9%)	
11/25 11:50:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][351/351]	Step 16487	lr 0.02313	Loss 1.4788 (1.2501)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.8%)	
11/25 11:50:56午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 68/149] Final Prec@1 63.7156%
11/25 11:51:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][39/40]	Step 16488	Loss 1.7391	Prec@(1,5) (52.2%, 81.9%)
11/25 11:51:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 52.2200%
11/25 11:51:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.1600%
11/25 11:51:43午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][100/351]	Step 16588	lr 0.02292	Loss 1.3471 (1.2082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.8%)	
11/25 11:52:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][200/351]	Step 16688	lr 0.02292	Loss 1.0849 (1.2214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
11/25 11:53:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][300/351]	Step 16788	lr 0.02292	Loss 1.0735 (1.2271)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.3%)	
11/25 11:53:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][351/351]	Step 16839	lr 0.02292	Loss 1.3023 (1.2300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.2%)	
11/25 11:53:24午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 69/149] Final Prec@1 64.6756%
11/25 11:53:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][39/40]	Step 16840	Loss 1.7488	Prec@(1,5) (53.4%, 82.1%)
11/25 11:53:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 53.4200%
11/25 11:53:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.1600%
11/25 11:54:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][100/351]	Step 16940	lr 0.02271	Loss 1.3315 (1.1963)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 90.6%)	
11/25 11:54:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][200/351]	Step 17040	lr 0.02271	Loss 1.1504 (1.2040)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.6%)	
11/25 11:55:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][300/351]	Step 17140	lr 0.02271	Loss 1.0576 (1.2189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.3%)	
11/25 11:55:52午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][351/351]	Step 17191	lr 0.02271	Loss 1.3616 (1.2199)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.4%)	
11/25 11:55:52午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 70/149] Final Prec@1 64.4178%
11/25 11:55:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][39/40]	Step 17192	Loss 1.7883	Prec@(1,5) (51.9%, 82.1%)
11/25 11:55:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 51.8800%
11/25 11:55:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.1600%
11/25 11:56:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][100/351]	Step 17292	lr 0.02248	Loss 1.1914 (1.1628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.4%)	
11/25 11:57:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][200/351]	Step 17392	lr 0.02248	Loss 1.0192 (1.1945)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.8%)	
11/25 11:57:59午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][300/351]	Step 17492	lr 0.02248	Loss 1.3893 (1.2061)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.6%)	
11/25 11:58:20午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][351/351]	Step 17543	lr 0.02248	Loss 1.2504 (1.2111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.5%)	
11/25 11:58:20午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 71/149] Final Prec@1 65.0022%
11/25 11:58:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][39/40]	Step 17544	Loss 1.7958	Prec@(1,5) (52.5%, 82.3%)
11/25 11:58:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 52.4800%
11/25 11:58:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.1600%
11/25 11:59:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][100/351]	Step 17644	lr 0.02225	Loss 1.1281 (1.1532)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.3%)	
11/25 11:59:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][200/351]	Step 17744	lr 0.02225	Loss 1.1248 (1.1681)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.1%)	
11/25 12:00:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][300/351]	Step 17844	lr 0.02225	Loss 1.2717 (1.1854)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.8%)	
11/25 12:00:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][351/351]	Step 17895	lr 0.02225	Loss 1.0799 (1.1856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.9%)	
11/25 12:00:48午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 72/149] Final Prec@1 65.3689%
11/25 12:00:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][39/40]	Step 17896	Loss 1.6939	Prec@(1,5) (54.4%, 84.3%)
11/25 12:00:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 54.3800%
11/25 12:00:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.3800%
11/25 12:01:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][100/351]	Step 17996	lr 0.022	Loss 1.2406 (1.1371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.7%)	
11/25 12:02:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][200/351]	Step 18096	lr 0.022	Loss 1.0809 (1.1511)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.4%)	
11/25 12:02:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][300/351]	Step 18196	lr 0.022	Loss 1.1957 (1.1742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.0%)	
11/25 12:03:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][351/351]	Step 18247	lr 0.022	Loss 1.2643 (1.1820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.0%)	
11/25 12:03:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 73/149] Final Prec@1 65.5822%
11/25 12:03:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][39/40]	Step 18248	Loss 1.7388	Prec@(1,5) (52.6%, 83.6%)
11/25 12:03:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 52.5800%
11/25 12:03:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.3800%
11/25 12:04:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][100/351]	Step 18348	lr 0.02175	Loss 1.2045 (1.1261)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.7%)	
11/25 12:04:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][200/351]	Step 18448	lr 0.02175	Loss 1.2445 (1.1423)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.6%)	
11/25 12:05:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][300/351]	Step 18548	lr 0.02175	Loss 1.1691 (1.1555)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.3%)	
11/25 12:05:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][351/351]	Step 18599	lr 0.02175	Loss 1.1568 (1.1612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.2%)	
11/25 12:05:44午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 74/149] Final Prec@1 66.0756%
11/25 12:05:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][39/40]	Step 18600	Loss 1.7489	Prec@(1,5) (53.3%, 83.0%)
11/25 12:05:51午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 53.3200%
11/25 12:05:51午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.3800%
11/25 12:06:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][100/351]	Step 18700	lr 0.02149	Loss 1.3307 (1.1019)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.0%)	
11/25 12:07:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][200/351]	Step 18800	lr 0.02149	Loss 1.3818 (1.1304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.6%)	
11/25 12:07:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][300/351]	Step 18900	lr 0.02149	Loss 1.1136 (1.1392)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.5%)	
11/25 12:08:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][351/351]	Step 18951	lr 0.02149	Loss 1.3778 (1.1445)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.4%)	
11/25 12:08:12午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 75/149] Final Prec@1 66.5133%
11/25 12:08:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][39/40]	Step 18952	Loss 1.5933	Prec@(1,5) (56.2%, 85.5%)
11/25 12:08:19午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 56.2800%
11/25 12:08:19午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:09:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][100/351]	Step 19052	lr 0.02121	Loss 1.0876 (1.0993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.0%)	
11/25 12:09:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][200/351]	Step 19152	lr 0.02121	Loss 1.1086 (1.1160)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.9%)	
11/25 12:10:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][300/351]	Step 19252	lr 0.02121	Loss 1.2534 (1.1151)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.9%)	
11/25 12:10:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][351/351]	Step 19303	lr 0.02121	Loss 0.9630 (1.1234)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.7%)	
11/25 12:10:41午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 76/149] Final Prec@1 67.2533%
11/25 12:10:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][39/40]	Step 19304	Loss 1.6255	Prec@(1,5) (55.6%, 84.7%)
11/25 12:10:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 55.6000%
11/25 12:10:47午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:11:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][100/351]	Step 19404	lr 0.02094	Loss 1.0451 (1.0778)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.4%)	
11/25 12:12:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][200/351]	Step 19504	lr 0.02094	Loss 1.0609 (1.1027)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 91.8%)	
11/25 12:12:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][300/351]	Step 19604	lr 0.02094	Loss 1.2198 (1.1153)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.6%)	
11/25 12:13:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][351/351]	Step 19655	lr 0.02094	Loss 0.9851 (1.1193)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.7%)	
11/25 12:13:09午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 77/149] Final Prec@1 67.3600%
11/25 12:13:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][39/40]	Step 19656	Loss 1.6956	Prec@(1,5) (54.8%, 83.7%)
11/25 12:13:15午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 54.8000%
11/25 12:13:15午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:13:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][100/351]	Step 19756	lr 0.02065	Loss 1.1048 (1.0596)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.5%)	
11/25 12:14:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][200/351]	Step 19856	lr 0.02065	Loss 1.2150 (1.0808)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.3%)	
11/25 12:15:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][300/351]	Step 19956	lr 0.02065	Loss 0.8795 (1.0879)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.2%)	
11/25 12:15:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][351/351]	Step 20007	lr 0.02065	Loss 1.2267 (1.0944)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.1%)	
11/25 12:15:37午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 78/149] Final Prec@1 67.7844%
11/25 12:15:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][39/40]	Step 20008	Loss 1.6253	Prec@(1,5) (55.6%, 84.9%)
11/25 12:15:43午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 55.6200%
11/25 12:15:43午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:16:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][100/351]	Step 20108	lr 0.02035	Loss 1.1336 (1.0490)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.7%)	
11/25 12:17:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][200/351]	Step 20208	lr 0.02035	Loss 0.9398 (1.0705)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.3%)	
11/25 12:17:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][300/351]	Step 20308	lr 0.02035	Loss 1.0396 (1.0842)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.2%)	
11/25 12:18:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][351/351]	Step 20359	lr 0.02035	Loss 1.0500 (1.0891)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.2%)	
11/25 12:18:05午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 79/149] Final Prec@1 68.1311%
11/25 12:18:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][39/40]	Step 20360	Loss 1.6881	Prec@(1,5) (55.3%, 84.3%)
11/25 12:18:11午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 55.2800%
11/25 12:18:11午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:18:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][100/351]	Step 20460	lr 0.02005	Loss 0.9264 (1.0337)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 92.9%)	
11/25 12:19:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][200/351]	Step 20560	lr 0.02005	Loss 0.9811 (1.0590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.5%)	
11/25 12:20:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][300/351]	Step 20660	lr 0.02005	Loss 1.1826 (1.0645)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.4%)	
11/25 12:20:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][351/351]	Step 20711	lr 0.02005	Loss 1.0459 (1.0680)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.3%)	
11/25 12:20:33午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 80/149] Final Prec@1 68.5533%
11/25 12:20:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][39/40]	Step 20712	Loss 1.7003	Prec@(1,5) (54.8%, 84.0%)
11/25 12:20:39午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 54.7400%
11/25 12:20:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:21:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][100/351]	Step 20812	lr 0.01975	Loss 0.9177 (1.0313)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
11/25 12:22:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][200/351]	Step 20912	lr 0.01975	Loss 1.0999 (1.0466)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.7%)	
11/25 12:22:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][300/351]	Step 21012	lr 0.01975	Loss 1.2245 (1.0566)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.5%)	
11/25 12:23:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][351/351]	Step 21063	lr 0.01975	Loss 1.3884 (1.0650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.4%)	
11/25 12:23:01午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 81/149] Final Prec@1 68.6667%
11/25 12:23:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][39/40]	Step 21064	Loss 1.6252	Prec@(1,5) (55.7%, 85.2%)
11/25 12:23:07午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 55.7000%
11/25 12:23:07午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:23:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][100/351]	Step 21164	lr 0.01943	Loss 1.0724 (0.9978)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
11/25 12:24:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][200/351]	Step 21264	lr 0.01943	Loss 1.2843 (1.0297)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.1%)	
11/25 12:25:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][300/351]	Step 21364	lr 0.01943	Loss 1.2361 (1.0419)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.9%)	
11/25 12:25:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][351/351]	Step 21415	lr 0.01943	Loss 1.1213 (1.0460)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.8%)	
11/25 12:25:29午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 82/149] Final Prec@1 69.0222%
11/25 12:25:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][39/40]	Step 21416	Loss 1.6748	Prec@(1,5) (55.2%, 84.8%)
11/25 12:25:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 55.2200%
11/25 12:25:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:26:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][100/351]	Step 21516	lr 0.01911	Loss 0.8328 (0.9906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.5%)	
11/25 12:26:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][200/351]	Step 21616	lr 0.01911	Loss 0.9073 (1.0157)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.1%)	
11/25 12:27:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][300/351]	Step 21716	lr 0.01911	Loss 1.0920 (1.0251)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 92.9%)	
11/25 12:27:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][351/351]	Step 21767	lr 0.01911	Loss 1.0151 (1.0366)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.8%)	
11/25 12:27:57午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 83/149] Final Prec@1 69.3933%
11/25 12:28:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][39/40]	Step 21768	Loss 1.8900	Prec@(1,5) (52.1%, 81.3%)
11/25 12:28:03午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 52.1200%
11/25 12:28:03午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:28:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][100/351]	Step 21868	lr 0.01878	Loss 1.0181 (0.9643)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.7%)	
11/25 12:29:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][200/351]	Step 21968	lr 0.01878	Loss 0.9080 (0.9896)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
11/25 12:30:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][300/351]	Step 22068	lr 0.01878	Loss 0.9850 (1.0070)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.2%)	
11/25 12:30:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][351/351]	Step 22119	lr 0.01878	Loss 1.2274 (1.0207)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
11/25 12:30:25午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 84/149] Final Prec@1 69.6111%
11/25 12:30:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][39/40]	Step 22120	Loss 1.6474	Prec@(1,5) (56.3%, 84.5%)
11/25 12:30:31午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 56.2400%
11/25 12:30:31午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.2800%
11/25 12:31:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][100/351]	Step 22220	lr 0.01845	Loss 0.9440 (0.9687)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.4%)	
11/25 12:31:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][200/351]	Step 22320	lr 0.01845	Loss 1.0414 (0.9856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
11/25 12:32:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][300/351]	Step 22420	lr 0.01845	Loss 0.7987 (0.9947)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.2%)	
11/25 12:32:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][351/351]	Step 22471	lr 0.01845	Loss 1.2772 (1.0070)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.1%)	
11/25 12:32:53午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 85/149] Final Prec@1 69.9267%
11/25 12:32:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][39/40]	Step 22472	Loss 1.6250	Prec@(1,5) (56.5%, 85.8%)
11/25 12:32:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 56.4600%
11/25 12:32:59午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.4600%
11/25 12:33:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][100/351]	Step 22572	lr 0.01811	Loss 1.0030 (0.9679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.8%)	
11/25 12:34:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][200/351]	Step 22672	lr 0.01811	Loss 1.0525 (0.9734)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.7%)	
11/25 12:35:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][300/351]	Step 22772	lr 0.01811	Loss 0.8583 (0.9866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.5%)	
11/25 12:35:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][351/351]	Step 22823	lr 0.01811	Loss 1.2506 (0.9931)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.5%)	
11/25 12:35:21午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 86/149] Final Prec@1 70.7178%
11/25 12:35:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][39/40]	Step 22824	Loss 1.6641	Prec@(1,5) (57.2%, 85.1%)
11/25 12:35:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 57.2200%
11/25 12:35:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2200%
11/25 12:36:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][100/351]	Step 22924	lr 0.01777	Loss 0.9117 (0.9666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
11/25 12:36:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][200/351]	Step 23024	lr 0.01777	Loss 1.2138 (0.9723)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.7%)	
11/25 12:37:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][300/351]	Step 23124	lr 0.01777	Loss 0.8776 (0.9785)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.6%)	
11/25 12:37:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][351/351]	Step 23175	lr 0.01777	Loss 1.1677 (0.9841)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
11/25 12:37:49午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 87/149] Final Prec@1 70.4733%
11/25 12:37:56午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][39/40]	Step 23176	Loss 1.8953	Prec@(1,5) (52.9%, 81.8%)
11/25 12:37:56午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 52.9200%
11/25 12:37:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2200%
11/25 12:38:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][100/351]	Step 23276	lr 0.01742	Loss 1.2729 (0.9277)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.2%)	
11/25 12:39:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][200/351]	Step 23376	lr 0.01742	Loss 0.8748 (0.9539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.9%)	
11/25 12:39:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][300/351]	Step 23476	lr 0.01742	Loss 1.0463 (0.9660)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.7%)	
11/25 12:40:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][351/351]	Step 23527	lr 0.01742	Loss 0.8807 (0.9709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.6%)	
11/25 12:40:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 88/149] Final Prec@1 71.0578%
11/25 12:40:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][39/40]	Step 23528	Loss 1.6445	Prec@(1,5) (57.3%, 84.5%)
11/25 12:40:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 57.3000%
11/25 12:40:24午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.3000%
11/25 12:41:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][100/351]	Step 23628	lr 0.01706	Loss 0.7897 (0.9199)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
11/25 12:41:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][200/351]	Step 23728	lr 0.01706	Loss 0.8642 (0.9331)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.0%)	
11/25 12:42:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][300/351]	Step 23828	lr 0.01706	Loss 0.9438 (0.9463)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 93.9%)	
11/25 12:42:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][351/351]	Step 23879	lr 0.01706	Loss 1.1291 (0.9522)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.8%)	
11/25 12:42:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 89/149] Final Prec@1 71.5489%
11/25 12:42:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][39/40]	Step 23880	Loss 1.7360	Prec@(1,5) (55.3%, 83.9%)
11/25 12:42:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 55.3000%
11/25 12:42:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.3000%
11/25 12:43:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][100/351]	Step 23980	lr 0.01671	Loss 0.8771 (0.8991)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.6%)	
11/25 12:44:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][200/351]	Step 24080	lr 0.01671	Loss 0.9660 (0.9132)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.4%)	
11/25 12:44:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][300/351]	Step 24180	lr 0.01671	Loss 0.8026 (0.9322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.2%)	
11/25 12:45:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][351/351]	Step 24231	lr 0.01671	Loss 1.1583 (0.9379)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.2%)	
11/25 12:45:14午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 90/149] Final Prec@1 72.0578%
11/25 12:45:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][39/40]	Step 24232	Loss 1.5976	Prec@(1,5) (57.5%, 85.8%)
11/25 12:45:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 57.5800%
11/25 12:45:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.5800%
11/25 12:46:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][100/351]	Step 24332	lr 0.01635	Loss 0.9625 (0.8776)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.9%)	
11/25 12:46:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][200/351]	Step 24432	lr 0.01635	Loss 1.0328 (0.8941)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.5%)	
11/25 12:47:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][300/351]	Step 24532	lr 0.01635	Loss 0.8689 (0.9180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.2%)	
11/25 12:47:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][351/351]	Step 24583	lr 0.01635	Loss 0.9180 (0.9244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.2%)	
11/25 12:47:42午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 91/149] Final Prec@1 72.3822%
11/25 12:47:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][39/40]	Step 24584	Loss 1.6228	Prec@(1,5) (57.5%, 85.8%)
11/25 12:47:49午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 57.4800%
11/25 12:47:49午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.5800%
11/25 12:48:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][100/351]	Step 24684	lr 0.01598	Loss 1.2412 (0.8914)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.7%)	
11/25 12:49:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][200/351]	Step 24784	lr 0.01598	Loss 0.9774 (0.8970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.6%)	
11/25 12:49:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][300/351]	Step 24884	lr 0.01598	Loss 0.9040 (0.9080)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.4%)	
11/25 12:50:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][351/351]	Step 24935	lr 0.01598	Loss 0.8716 (0.9179)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.2%)	
11/25 12:50:10午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 92/149] Final Prec@1 72.4178%
11/25 12:50:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][39/40]	Step 24936	Loss 1.6906	Prec@(1,5) (56.4%, 84.2%)
11/25 12:50:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 56.4000%
11/25 12:50:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.5800%
11/25 12:50:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][100/351]	Step 25036	lr 0.01562	Loss 0.6988 (0.8449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.0%)	
11/25 12:51:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][200/351]	Step 25136	lr 0.01562	Loss 0.8981 (0.8742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
11/25 12:52:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][300/351]	Step 25236	lr 0.01562	Loss 0.8809 (0.8923)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.6%)	
11/25 12:52:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][351/351]	Step 25287	lr 0.01562	Loss 0.9739 (0.8989)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.5%)	
11/25 12:52:39午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 93/149] Final Prec@1 72.9200%
11/25 12:52:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][39/40]	Step 25288	Loss 1.6437	Prec@(1,5) (56.6%, 85.1%)
11/25 12:52:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 56.5400%
11/25 12:52:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.5800%
11/25 12:53:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][100/351]	Step 25388	lr 0.01525	Loss 0.9825 (0.8638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 94.8%)	
11/25 12:54:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][200/351]	Step 25488	lr 0.01525	Loss 0.9378 (0.8791)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.7%)	
11/25 12:54:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][300/351]	Step 25588	lr 0.01525	Loss 0.9783 (0.8876)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.7%)	
11/25 12:55:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][351/351]	Step 25639	lr 0.01525	Loss 0.9137 (0.8926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
11/25 12:55:07午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 94/149] Final Prec@1 73.2689%
11/25 12:55:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][39/40]	Step 25640	Loss 1.6035	Prec@(1,5) (57.9%, 86.0%)
11/25 12:55:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 57.9000%
11/25 12:55:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.9000%
11/25 12:55:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][100/351]	Step 25740	lr 0.01488	Loss 0.9455 (0.8416)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/25 12:56:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][200/351]	Step 25840	lr 0.01488	Loss 0.8170 (0.8540)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
11/25 12:57:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][300/351]	Step 25940	lr 0.01488	Loss 0.9028 (0.8710)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.7%)	
11/25 12:57:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][351/351]	Step 25991	lr 0.01488	Loss 0.7919 (0.8739)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/25 12:57:35午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 95/149] Final Prec@1 73.6244%
11/25 12:57:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][39/40]	Step 25992	Loss 1.5722	Prec@(1,5) (58.1%, 86.2%)
11/25 12:57:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 58.1400%
11/25 12:57:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1400%
11/25 12:58:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][100/351]	Step 26092	lr 0.0145	Loss 0.7778 (0.7934)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.7%)	
11/25 12:59:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][200/351]	Step 26192	lr 0.0145	Loss 0.9819 (0.8234)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.4%)	
11/25 12:59:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][300/351]	Step 26292	lr 0.0145	Loss 0.9878 (0.8464)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.0%)	
11/25 01:00:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][351/351]	Step 26343	lr 0.0145	Loss 0.7245 (0.8576)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.8%)	
11/25 01:00:03午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 96/149] Final Prec@1 74.1356%
11/25 01:00:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][39/40]	Step 26344	Loss 1.6219	Prec@(1,5) (57.9%, 86.2%)
11/25 01:00:10午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 57.8200%
11/25 01:00:10午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1400%
11/25 01:00:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][100/351]	Step 26444	lr 0.01413	Loss 1.0657 (0.7941)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.8%)	
11/25 01:01:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][200/351]	Step 26544	lr 0.01413	Loss 0.7242 (0.8090)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.6%)	
11/25 01:02:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][300/351]	Step 26644	lr 0.01413	Loss 0.9824 (0.8379)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.2%)	
11/25 01:02:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][351/351]	Step 26695	lr 0.01413	Loss 0.9329 (0.8440)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/25 01:02:32午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 97/149] Final Prec@1 74.4489%
11/25 01:02:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][39/40]	Step 26696	Loss 1.6930	Prec@(1,5) (56.8%, 84.1%)
11/25 01:02:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 56.7200%
11/25 01:02:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1400%
11/25 01:03:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][100/351]	Step 26796	lr 0.01375	Loss 0.9434 (0.7799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.4%)	
11/25 01:03:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][200/351]	Step 26896	lr 0.01375	Loss 0.7412 (0.7950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.5%)	
11/25 01:04:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][300/351]	Step 26996	lr 0.01375	Loss 0.8628 (0.8219)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.2%)	
11/25 01:04:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][351/351]	Step 27047	lr 0.01375	Loss 0.8837 (0.8298)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.1%)	
11/25 01:04:59午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 98/149] Final Prec@1 74.7644%
11/25 01:05:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][39/40]	Step 27048	Loss 1.5494	Prec@(1,5) (58.7%, 85.7%)
11/25 01:05:06午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 58.6600%
11/25 01:05:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6600%
11/25 01:05:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][100/351]	Step 27148	lr 0.01338	Loss 0.6740 (0.7870)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.6%)	
11/25 01:06:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][200/351]	Step 27248	lr 0.01338	Loss 0.9333 (0.8056)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.4%)	
11/25 01:07:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][300/351]	Step 27348	lr 0.01338	Loss 0.8374 (0.8174)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.3%)	
11/25 01:07:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][351/351]	Step 27399	lr 0.01338	Loss 1.1269 (0.8225)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.2%)	
11/25 01:07:28午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 99/149] Final Prec@1 75.2133%
11/25 01:07:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][39/40]	Step 27400	Loss 1.6561	Prec@(1,5) (57.9%, 85.4%)
11/25 01:07:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 57.8600%
11/25 01:07:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6600%
11/25 01:08:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][100/351]	Step 27500	lr 0.013	Loss 0.8823 (0.7712)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 96.0%)	
11/25 01:08:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][200/351]	Step 27600	lr 0.013	Loss 0.7818 (0.7916)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
11/25 01:09:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][300/351]	Step 27700	lr 0.013	Loss 0.7849 (0.8068)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.5%)	
11/25 01:09:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][351/351]	Step 27751	lr 0.013	Loss 0.8699 (0.8141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.4%)	
11/25 01:09:56午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [100/149] Final Prec@1 75.1089%
11/25 01:10:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][39/40]	Step 27752	Loss 1.5698	Prec@(1,5) (59.2%, 85.7%)
11/25 01:10:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 59.2000%
11/25 01:10:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2000%
11/25 01:10:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][100/351]	Step 27852	lr 0.01262	Loss 0.6421 (0.7559)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.1%)	
11/25 01:11:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][200/351]	Step 27952	lr 0.01262	Loss 0.7053 (0.7698)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 96.1%)	
11/25 01:12:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][300/351]	Step 28052	lr 0.01262	Loss 0.7735 (0.7824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.9%)	
11/25 01:12:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][351/351]	Step 28103	lr 0.01262	Loss 0.9454 (0.7897)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.8%)	
11/25 01:12:24午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [101/149] Final Prec@1 75.8022%
11/25 01:12:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][39/40]	Step 28104	Loss 1.5444	Prec@(1,5) (58.8%, 86.7%)
11/25 01:12:30午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 58.8000%
11/25 01:12:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2000%
11/25 01:13:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][100/351]	Step 28204	lr 0.01225	Loss 0.5457 (0.7431)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.2%)	
11/25 01:13:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][200/351]	Step 28304	lr 0.01225	Loss 1.0246 (0.7584)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.0%)	
11/25 01:14:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][300/351]	Step 28404	lr 0.01225	Loss 0.9802 (0.7772)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.7%)	
11/25 01:14:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][351/351]	Step 28455	lr 0.01225	Loss 0.7281 (0.7812)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.7%)	
11/25 01:14:52午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [102/149] Final Prec@1 76.2600%
11/25 01:14:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][39/40]	Step 28456	Loss 1.5496	Prec@(1,5) (59.3%, 86.6%)
11/25 01:14:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 59.2600%
11/25 01:14:59午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2600%
11/25 01:15:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][100/351]	Step 28556	lr 0.01187	Loss 0.6965 (0.7191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
11/25 01:16:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][200/351]	Step 28656	lr 0.01187	Loss 0.6687 (0.7466)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.0%)	
11/25 01:17:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][300/351]	Step 28756	lr 0.01187	Loss 1.0015 (0.7597)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.9%)	
11/25 01:17:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][351/351]	Step 28807	lr 0.01187	Loss 0.8612 (0.7636)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.9%)	
11/25 01:17:20午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [103/149] Final Prec@1 76.5978%
11/25 01:17:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][39/40]	Step 28808	Loss 1.5943	Prec@(1,5) (58.1%, 85.4%)
11/25 01:17:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 58.1200%
11/25 01:17:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2600%
11/25 01:18:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][100/351]	Step 28908	lr 0.0115	Loss 0.8195 (0.7136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.5%)	
11/25 01:18:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][200/351]	Step 29008	lr 0.0115	Loss 0.8026 (0.7188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.4%)	
11/25 01:19:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][300/351]	Step 29108	lr 0.0115	Loss 0.8613 (0.7389)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.2%)	
11/25 01:19:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][351/351]	Step 29159	lr 0.0115	Loss 0.7318 (0.7486)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
11/25 01:19:49午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [104/149] Final Prec@1 77.1556%
11/25 01:19:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][39/40]	Step 29160	Loss 1.6287	Prec@(1,5) (58.2%, 85.7%)
11/25 01:19:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 58.2200%
11/25 01:19:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.2600%
11/25 01:20:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][100/351]	Step 29260	lr 0.01112	Loss 0.8477 (0.6927)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.4%)	
11/25 01:21:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][200/351]	Step 29360	lr 0.01112	Loss 0.7789 (0.7093)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
11/25 01:21:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][300/351]	Step 29460	lr 0.01112	Loss 0.7189 (0.7252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.2%)	
11/25 01:22:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][351/351]	Step 29511	lr 0.01112	Loss 0.7264 (0.7328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.1%)	
11/25 01:22:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [105/149] Final Prec@1 77.6533%
11/25 01:22:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][39/40]	Step 29512	Loss 1.4974	Prec@(1,5) (60.1%, 87.2%)
11/25 01:22:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 60.0800%
11/25 01:22:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.0800%
11/25 01:23:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][100/351]	Step 29612	lr 0.01075	Loss 0.7730 (0.6800)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.6%)	
11/25 01:23:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][200/351]	Step 29712	lr 0.01075	Loss 0.6293 (0.6943)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.6%)	
11/25 01:24:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][300/351]	Step 29812	lr 0.01075	Loss 0.6884 (0.7069)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
11/25 01:24:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][351/351]	Step 29863	lr 0.01075	Loss 0.7008 (0.7149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.4%)	
11/25 01:24:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [106/149] Final Prec@1 78.1000%
11/25 01:24:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][39/40]	Step 29864	Loss 1.5059	Prec@(1,5) (60.3%, 87.0%)
11/25 01:24:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 60.3200%
11/25 01:24:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.3200%
11/25 01:25:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][100/351]	Step 29964	lr 0.01038	Loss 0.7626 (0.6730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.8%)	
11/25 01:26:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][200/351]	Step 30064	lr 0.01038	Loss 0.7613 (0.6825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.8%)	
11/25 01:26:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][300/351]	Step 30164	lr 0.01038	Loss 0.5342 (0.7037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
11/25 01:27:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][351/351]	Step 30215	lr 0.01038	Loss 0.7152 (0.7085)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.5%)	
11/25 01:27:14午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [107/149] Final Prec@1 78.2622%
11/25 01:27:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][39/40]	Step 30216	Loss 1.5801	Prec@(1,5) (59.5%, 86.3%)
11/25 01:27:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 59.5400%
11/25 01:27:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.3200%
11/25 01:28:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][100/351]	Step 30316	lr 0.01002	Loss 0.6764 (0.6639)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 97.1%)	
11/25 01:28:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][200/351]	Step 30416	lr 0.01002	Loss 0.5791 (0.6813)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.8%)	
11/25 01:29:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][300/351]	Step 30516	lr 0.01002	Loss 0.8523 (0.6908)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.7%)	
11/25 01:29:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][351/351]	Step 30567	lr 0.01002	Loss 0.8005 (0.6961)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.7%)	
11/25 01:29:42午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [108/149] Final Prec@1 78.5311%
11/25 01:29:48午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][39/40]	Step 30568	Loss 1.4799	Prec@(1,5) (61.4%, 87.9%)
11/25 01:29:48午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 61.4800%
11/25 01:29:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:30:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][100/351]	Step 30668	lr 0.00965	Loss 0.5843 (0.6352)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.1%)	
11/25 01:31:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][200/351]	Step 30768	lr 0.00965	Loss 0.9372 (0.6610)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 96.8%)	
11/25 01:31:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][300/351]	Step 30868	lr 0.00965	Loss 0.5967 (0.6721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.7%)	
11/25 01:32:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][351/351]	Step 30919	lr 0.00965	Loss 0.5921 (0.6797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.6%)	
11/25 01:32:10午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [109/149] Final Prec@1 79.3289%
11/25 01:32:16午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][39/40]	Step 30920	Loss 1.5578	Prec@(1,5) (59.4%, 86.8%)
11/25 01:32:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 59.4400%
11/25 01:32:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:32:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][100/351]	Step 31020	lr 0.00929	Loss 0.6565 (0.6149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.1%)	
11/25 01:33:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][200/351]	Step 31120	lr 0.00929	Loss 0.5670 (0.6375)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 96.9%)	
11/25 01:34:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][300/351]	Step 31220	lr 0.00929	Loss 0.6501 (0.6513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.8%)	
11/25 01:34:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][351/351]	Step 31271	lr 0.00929	Loss 0.6904 (0.6638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.8%)	
11/25 01:34:38午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [110/149] Final Prec@1 79.6644%
11/25 01:34:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][39/40]	Step 31272	Loss 1.5436	Prec@(1,5) (60.3%, 86.7%)
11/25 01:34:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 60.2200%
11/25 01:34:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:35:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][100/351]	Step 31372	lr 0.00894	Loss 0.5939 (0.6197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.0%)	
11/25 01:36:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][200/351]	Step 31472	lr 0.00894	Loss 0.5099 (0.6328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.0%)	
11/25 01:36:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][300/351]	Step 31572	lr 0.00894	Loss 0.6186 (0.6420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 96.9%)	
11/25 01:37:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][351/351]	Step 31623	lr 0.00894	Loss 0.9309 (0.6488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 96.9%)	
11/25 01:37:06午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [111/149] Final Prec@1 80.0667%
11/25 01:37:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][39/40]	Step 31624	Loss 1.5308	Prec@(1,5) (60.9%, 86.9%)
11/25 01:37:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 60.8200%
11/25 01:37:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:37:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][100/351]	Step 31724	lr 0.00858	Loss 0.4879 (0.6055)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.6%)	
11/25 01:38:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][200/351]	Step 31824	lr 0.00858	Loss 0.5776 (0.6182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.4%)	
11/25 01:39:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][300/351]	Step 31924	lr 0.00858	Loss 0.7114 (0.6336)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.1%)	
11/25 01:39:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][351/351]	Step 31975	lr 0.00858	Loss 0.7483 (0.6367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.1%)	
11/25 01:39:35午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [112/149] Final Prec@1 80.4978%
11/25 01:39:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][39/40]	Step 31976	Loss 1.5158	Prec@(1,5) (60.2%, 87.2%)
11/25 01:39:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 60.2600%
11/25 01:39:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:40:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][100/351]	Step 32076	lr 0.00823	Loss 0.6721 (0.5809)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.6%)	
11/25 01:41:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][200/351]	Step 32176	lr 0.00823	Loss 0.8402 (0.6022)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/25 01:41:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][300/351]	Step 32276	lr 0.00823	Loss 0.6415 (0.6165)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.2%)	
11/25 01:42:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][351/351]	Step 32327	lr 0.00823	Loss 0.6223 (0.6209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
11/25 01:42:03午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [113/149] Final Prec@1 80.8356%
11/25 01:42:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][39/40]	Step 32328	Loss 1.5474	Prec@(1,5) (59.3%, 86.2%)
11/25 01:42:09午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 59.2400%
11/25 01:42:09午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:42:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][100/351]	Step 32428	lr 0.00789	Loss 0.4360 (0.5713)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.6%)	
11/25 01:43:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][200/351]	Step 32528	lr 0.00789	Loss 0.5533 (0.5845)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/25 01:44:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][300/351]	Step 32628	lr 0.00789	Loss 0.6058 (0.6008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/25 01:44:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][351/351]	Step 32679	lr 0.00789	Loss 0.7114 (0.6050)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
11/25 01:44:31午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [114/149] Final Prec@1 81.1733%
11/25 01:44:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][39/40]	Step 32680	Loss 1.5175	Prec@(1,5) (61.3%, 86.9%)
11/25 01:44:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 61.3600%
11/25 01:44:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:45:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][100/351]	Step 32780	lr 0.00755	Loss 0.5008 (0.5794)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
11/25 01:45:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][200/351]	Step 32880	lr 0.00755	Loss 0.4982 (0.5838)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.5%)	
11/25 01:46:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][300/351]	Step 32980	lr 0.00755	Loss 0.7324 (0.5951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
11/25 01:46:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][351/351]	Step 33031	lr 0.00755	Loss 0.5053 (0.5950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
11/25 01:46:59午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [115/149] Final Prec@1 81.6356%
11/25 01:47:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][39/40]	Step 33032	Loss 1.4988	Prec@(1,5) (61.2%, 88.0%)
11/25 01:47:06午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 61.2000%
11/25 01:47:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:47:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][100/351]	Step 33132	lr 0.00722	Loss 0.6643 (0.5432)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
11/25 01:48:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][200/351]	Step 33232	lr 0.00722	Loss 0.5347 (0.5544)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.8%)	
11/25 01:49:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][300/351]	Step 33332	lr 0.00722	Loss 0.5540 (0.5673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
11/25 01:49:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][351/351]	Step 33383	lr 0.00722	Loss 0.6087 (0.5752)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.6%)	
11/25 01:49:28午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [116/149] Final Prec@1 82.3044%
11/25 01:49:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][39/40]	Step 33384	Loss 1.5001	Prec@(1,5) (61.0%, 87.3%)
11/25 01:49:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 60.9400%
11/25 01:49:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:50:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][100/351]	Step 33484	lr 0.00689	Loss 0.6333 (0.5395)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.0%)	
11/25 01:50:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][200/351]	Step 33584	lr 0.00689	Loss 0.5263 (0.5449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.9%)	
11/25 01:51:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][300/351]	Step 33684	lr 0.00689	Loss 0.6551 (0.5608)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.8%)	
11/25 01:51:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][351/351]	Step 33735	lr 0.00689	Loss 0.5540 (0.5656)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.8%)	
11/25 01:51:56午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [117/149] Final Prec@1 82.4467%
11/25 01:52:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][39/40]	Step 33736	Loss 1.4694	Prec@(1,5) (61.3%, 88.2%)
11/25 01:52:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 61.2600%
11/25 01:52:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:52:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][100/351]	Step 33836	lr 0.00657	Loss 0.5360 (0.5175)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.0%)	
11/25 01:53:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][200/351]	Step 33936	lr 0.00657	Loss 0.4753 (0.5275)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
11/25 01:54:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][300/351]	Step 34036	lr 0.00657	Loss 0.5126 (0.5389)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
11/25 01:54:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][351/351]	Step 34087	lr 0.00657	Loss 0.5049 (0.5435)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/25 01:54:24午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [118/149] Final Prec@1 83.3733%
11/25 01:54:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][39/40]	Step 34088	Loss 1.5030	Prec@(1,5) (61.4%, 87.9%)
11/25 01:54:30午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 61.4200%
11/25 01:54:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.4800%
11/25 01:55:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][100/351]	Step 34188	lr 0.00625	Loss 0.5097 (0.4974)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.3%)	
11/25 01:55:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][200/351]	Step 34288	lr 0.00625	Loss 0.4746 (0.5176)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.1%)	
11/25 01:56:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][300/351]	Step 34388	lr 0.00625	Loss 0.3876 (0.5244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
11/25 01:56:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][351/351]	Step 34439	lr 0.00625	Loss 0.5588 (0.5313)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/25 01:56:52午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [119/149] Final Prec@1 83.5044%
11/25 01:56:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][39/40]	Step 34440	Loss 1.4653	Prec@(1,5) (61.8%, 88.5%)
11/25 01:56:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 61.8400%
11/25 01:56:59午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.8400%
11/25 01:57:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][100/351]	Step 34540	lr 0.00595	Loss 0.4771 (0.4840)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/25 01:58:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][200/351]	Step 34640	lr 0.00595	Loss 0.5405 (0.5019)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.2%)	
11/25 01:59:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][300/351]	Step 34740	lr 0.00595	Loss 0.5597 (0.5154)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
11/25 01:59:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][351/351]	Step 34791	lr 0.00595	Loss 0.5041 (0.5209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.1%)	
11/25 01:59:21午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [120/149] Final Prec@1 83.9422%
11/25 01:59:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][39/40]	Step 34792	Loss 1.4447	Prec@(1,5) (62.6%, 88.8%)
11/25 01:59:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 62.5400%
11/25 01:59:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5400%
11/25 02:00:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][100/351]	Step 34892	lr 0.00565	Loss 0.4828 (0.4778)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.3%)	
11/25 02:00:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][200/351]	Step 34992	lr 0.00565	Loss 0.3377 (0.4870)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
11/25 02:01:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][300/351]	Step 35092	lr 0.00565	Loss 0.6017 (0.4944)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.2%)	
11/25 02:01:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][351/351]	Step 35143	lr 0.00565	Loss 0.6419 (0.5003)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
11/25 02:01:49午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [121/149] Final Prec@1 84.6067%
11/25 02:01:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][39/40]	Step 35144	Loss 1.4698	Prec@(1,5) (62.5%, 88.1%)
11/25 02:01:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 62.5800%
11/25 02:01:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5800%
11/25 02:02:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][100/351]	Step 35244	lr 0.00535	Loss 0.3944 (0.4753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.3%)	
11/25 02:03:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][200/351]	Step 35344	lr 0.00535	Loss 0.5729 (0.4821)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
11/25 02:03:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][300/351]	Step 35444	lr 0.00535	Loss 0.6567 (0.4871)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.3%)	
11/25 02:04:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][351/351]	Step 35495	lr 0.00535	Loss 0.5793 (0.4906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.3%)	
11/25 02:04:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [122/149] Final Prec@1 84.7356%
11/25 02:04:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][39/40]	Step 35496	Loss 1.4620	Prec@(1,5) (62.2%, 88.1%)
11/25 02:04:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 62.2400%
11/25 02:04:24午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5800%
11/25 02:05:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][100/351]	Step 35596	lr 0.00506	Loss 0.4499 (0.4427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.8%)	
11/25 02:05:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][200/351]	Step 35696	lr 0.00506	Loss 0.5772 (0.4649)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.5%)	
11/25 02:06:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][300/351]	Step 35796	lr 0.00506	Loss 0.4482 (0.4742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.4%)	
11/25 02:06:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][351/351]	Step 35847	lr 0.00506	Loss 0.5996 (0.4774)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.4%)	
11/25 02:06:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [123/149] Final Prec@1 85.2156%
11/25 02:06:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][39/40]	Step 35848	Loss 1.4716	Prec@(1,5) (62.0%, 88.3%)
11/25 02:06:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 61.9800%
11/25 02:06:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5800%
11/25 02:07:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][100/351]	Step 35948	lr 0.00479	Loss 0.4203 (0.4376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.6%)	
11/25 02:08:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][200/351]	Step 36048	lr 0.00479	Loss 0.6219 (0.4516)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
11/25 02:08:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][300/351]	Step 36148	lr 0.00479	Loss 0.4118 (0.4626)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
11/25 02:09:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][351/351]	Step 36199	lr 0.00479	Loss 0.4752 (0.4644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.5%)	
11/25 02:09:14午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [124/149] Final Prec@1 85.6644%
11/25 02:09:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][39/40]	Step 36200	Loss 1.4752	Prec@(1,5) (62.1%, 87.7%)
11/25 02:09:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 62.1200%
11/25 02:09:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5800%
11/25 02:10:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][100/351]	Step 36300	lr 0.00451	Loss 0.4998 (0.4197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/25 02:10:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][200/351]	Step 36400	lr 0.00451	Loss 0.4217 (0.4353)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
11/25 02:11:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][300/351]	Step 36500	lr 0.00451	Loss 0.5603 (0.4397)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.6%)	
11/25 02:11:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][351/351]	Step 36551	lr 0.00451	Loss 0.5234 (0.4446)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.6%)	
11/25 02:11:42午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [125/149] Final Prec@1 86.3222%
11/25 02:11:48午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][39/40]	Step 36552	Loss 1.4871	Prec@(1,5) (62.8%, 88.0%)
11/25 02:11:48午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 62.7600%
11/25 02:11:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.7600%
11/25 02:12:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][100/351]	Step 36652	lr 0.00425	Loss 0.3865 (0.4203)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
11/25 02:13:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][200/351]	Step 36752	lr 0.00425	Loss 0.4381 (0.4240)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
11/25 02:13:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][300/351]	Step 36852	lr 0.00425	Loss 0.3485 (0.4330)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
11/25 02:14:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][351/351]	Step 36903	lr 0.00425	Loss 0.5016 (0.4357)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
11/25 02:14:10午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [126/149] Final Prec@1 86.5444%
11/25 02:14:16午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][39/40]	Step 36904	Loss 1.4711	Prec@(1,5) (63.6%, 88.3%)
11/25 02:14:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 63.5800%
11/25 02:14:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5800%
11/25 02:14:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][100/351]	Step 37004	lr 0.004	Loss 0.4358 (0.4140)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.7%)	
11/25 02:15:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][200/351]	Step 37104	lr 0.004	Loss 0.4658 (0.4213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/25 02:16:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][300/351]	Step 37204	lr 0.004	Loss 0.4001 (0.4235)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.7%)	
11/25 02:16:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][351/351]	Step 37255	lr 0.004	Loss 0.4542 (0.4248)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.7%)	
11/25 02:16:39午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [127/149] Final Prec@1 86.9667%
11/25 02:16:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][39/40]	Step 37256	Loss 1.4761	Prec@(1,5) (63.3%, 88.1%)
11/25 02:16:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 63.3200%
11/25 02:16:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5800%
11/25 02:17:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][100/351]	Step 37356	lr 0.00375	Loss 0.3776 (0.3880)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 98.9%)	
11/25 02:18:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][200/351]	Step 37456	lr 0.00375	Loss 0.4289 (0.3991)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
11/25 02:18:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][300/351]	Step 37556	lr 0.00375	Loss 0.3757 (0.4065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 98.9%)	
11/25 02:19:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][351/351]	Step 37607	lr 0.00375	Loss 0.4434 (0.4086)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.9%)	
11/25 02:19:07午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [128/149] Final Prec@1 87.6044%
11/25 02:19:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][39/40]	Step 37608	Loss 1.4763	Prec@(1,5) (62.8%, 88.6%)
11/25 02:19:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 62.7600%
11/25 02:19:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5800%
11/25 02:19:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][100/351]	Step 37708	lr 0.00352	Loss 0.5044 (0.3724)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.1%)	
11/25 02:20:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][200/351]	Step 37808	lr 0.00352	Loss 0.4364 (0.3883)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
11/25 02:21:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][300/351]	Step 37908	lr 0.00352	Loss 0.3950 (0.3971)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.0%, 98.9%)	
11/25 02:21:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][351/351]	Step 37959	lr 0.00352	Loss 0.5884 (0.4012)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
11/25 02:21:35午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [129/149] Final Prec@1 87.8178%
11/25 02:21:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][39/40]	Step 37960	Loss 1.4717	Prec@(1,5) (62.9%, 88.7%)
11/25 02:21:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 62.8800%
11/25 02:21:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5800%
11/25 02:22:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][100/351]	Step 38060	lr 0.00329	Loss 0.3055 (0.3756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.0%)	
11/25 02:23:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][200/351]	Step 38160	lr 0.00329	Loss 0.3229 (0.3836)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
11/25 02:23:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][300/351]	Step 38260	lr 0.00329	Loss 0.3246 (0.3840)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
11/25 02:24:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][351/351]	Step 38311	lr 0.00329	Loss 0.4199 (0.3885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 98.9%)	
11/25 02:24:03午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [130/149] Final Prec@1 88.2222%
11/25 02:24:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][39/40]	Step 38312	Loss 1.4694	Prec@(1,5) (63.2%, 88.8%)
11/25 02:24:10午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 63.1800%
11/25 02:24:10午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5800%
11/25 02:24:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][100/351]	Step 38412	lr 0.00308	Loss 0.3565 (0.3757)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.0%)	
11/25 02:25:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][200/351]	Step 38512	lr 0.00308	Loss 0.4132 (0.3724)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.1%)	
11/25 02:26:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][300/351]	Step 38612	lr 0.00308	Loss 0.2256 (0.3776)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.0%)	
11/25 02:26:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][351/351]	Step 38663	lr 0.00308	Loss 0.3582 (0.3793)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.1%)	
11/25 02:26:32午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [131/149] Final Prec@1 88.5467%
11/25 02:26:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][39/40]	Step 38664	Loss 1.4831	Prec@(1,5) (62.6%, 88.6%)
11/25 02:26:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 62.6200%
11/25 02:26:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5800%
11/25 02:27:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][100/351]	Step 38764	lr 0.00287	Loss 0.3742 (0.3527)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
11/25 02:27:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][200/351]	Step 38864	lr 0.00287	Loss 0.3394 (0.3583)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.2%)	
11/25 02:28:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][300/351]	Step 38964	lr 0.00287	Loss 0.4412 (0.3634)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.1%)	
11/25 02:28:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][351/351]	Step 39015	lr 0.00287	Loss 0.3462 (0.3646)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.1%)	
11/25 02:29:00午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [132/149] Final Prec@1 89.1156%
11/25 02:29:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][39/40]	Step 39016	Loss 1.4539	Prec@(1,5) (64.3%, 88.8%)
11/25 02:29:06午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 64.3200%
11/25 02:29:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:29:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][100/351]	Step 39116	lr 0.00267	Loss 0.3438 (0.3347)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.2%)	
11/25 02:30:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][200/351]	Step 39216	lr 0.00267	Loss 0.3293 (0.3465)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
11/25 02:31:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][300/351]	Step 39316	lr 0.00267	Loss 0.3441 (0.3522)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
11/25 02:31:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][351/351]	Step 39367	lr 0.00267	Loss 0.4976 (0.3568)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.1%)	
11/25 02:31:28午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [133/149] Final Prec@1 89.3378%
11/25 02:31:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][39/40]	Step 39368	Loss 1.4589	Prec@(1,5) (64.2%, 88.8%)
11/25 02:31:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 64.1600%
11/25 02:31:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:32:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][100/351]	Step 39468	lr 0.00248	Loss 0.2373 (0.3277)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
11/25 02:32:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][200/351]	Step 39568	lr 0.00248	Loss 0.3711 (0.3409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.2%)	
11/25 02:33:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][300/351]	Step 39668	lr 0.00248	Loss 0.3587 (0.3440)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.2%)	
11/25 02:33:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][351/351]	Step 39719	lr 0.00248	Loss 0.3839 (0.3475)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
11/25 02:33:56午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [134/149] Final Prec@1 89.6933%
11/25 02:34:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][39/40]	Step 39720	Loss 1.4295	Prec@(1,5) (63.7%, 89.3%)
11/25 02:34:03午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 63.6200%
11/25 02:34:03午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:34:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][100/351]	Step 39820	lr 0.00231	Loss 0.2743 (0.3292)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
11/25 02:35:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][200/351]	Step 39920	lr 0.00231	Loss 0.3225 (0.3326)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.2%)	
11/25 02:36:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][300/351]	Step 40020	lr 0.00231	Loss 0.2617 (0.3375)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.2%)	
11/25 02:36:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][351/351]	Step 40071	lr 0.00231	Loss 0.4175 (0.3384)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.2%)	
11/25 02:36:25午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [135/149] Final Prec@1 89.9911%
11/25 02:36:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][39/40]	Step 40072	Loss 1.4545	Prec@(1,5) (63.3%, 88.8%)
11/25 02:36:31午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 63.3200%
11/25 02:36:31午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:37:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][100/351]	Step 40172	lr 0.00214	Loss 0.2778 (0.3165)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.3%)	
11/25 02:37:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][200/351]	Step 40272	lr 0.00214	Loss 0.2687 (0.3232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.3%)	
11/25 02:38:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][300/351]	Step 40372	lr 0.00214	Loss 0.2853 (0.3262)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.3%)	
11/25 02:38:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][351/351]	Step 40423	lr 0.00214	Loss 0.4425 (0.3291)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
11/25 02:38:54午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [136/149] Final Prec@1 90.5133%
11/25 02:39:00午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][39/40]	Step 40424	Loss 1.4601	Prec@(1,5) (63.8%, 89.4%)
11/25 02:39:01午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 63.8400%
11/25 02:39:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:39:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][100/351]	Step 40524	lr 0.00199	Loss 0.2290 (0.3173)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
11/25 02:40:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][200/351]	Step 40624	lr 0.00199	Loss 0.3895 (0.3212)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
11/25 02:41:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][300/351]	Step 40724	lr 0.00199	Loss 0.2758 (0.3194)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
11/25 02:41:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][351/351]	Step 40775	lr 0.00199	Loss 0.2965 (0.3202)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
11/25 02:41:23午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [137/149] Final Prec@1 90.5822%
11/25 02:41:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][39/40]	Step 40776	Loss 1.4460	Prec@(1,5) (63.9%, 89.2%)
11/25 02:41:29午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 63.9200%
11/25 02:41:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:42:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][100/351]	Step 40876	lr 0.00184	Loss 0.3107 (0.3030)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.4%)	
11/25 02:42:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][200/351]	Step 40976	lr 0.00184	Loss 0.3256 (0.3063)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
11/25 02:43:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][300/351]	Step 41076	lr 0.00184	Loss 0.4303 (0.3102)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
11/25 02:43:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][351/351]	Step 41127	lr 0.00184	Loss 0.2237 (0.3126)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
11/25 02:43:53午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [138/149] Final Prec@1 90.9400%
11/25 02:43:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][39/40]	Step 41128	Loss 1.4674	Prec@(1,5) (63.8%, 88.7%)
11/25 02:43:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 63.8000%
11/25 02:43:59午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:44:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][100/351]	Step 41228	lr 0.00171	Loss 0.3200 (0.3011)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
11/25 02:45:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][200/351]	Step 41328	lr 0.00171	Loss 0.3197 (0.3071)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.3%)	
11/25 02:46:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][300/351]	Step 41428	lr 0.00171	Loss 0.3555 (0.3053)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
11/25 02:46:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][351/351]	Step 41479	lr 0.00171	Loss 0.3407 (0.3085)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
11/25 02:46:22午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [139/149] Final Prec@1 91.0889%
11/25 02:46:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][39/40]	Step 41480	Loss 1.4745	Prec@(1,5) (63.6%, 88.8%)
11/25 02:46:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 63.6200%
11/25 02:46:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:47:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][100/351]	Step 41580	lr 0.00159	Loss 0.2731 (0.2929)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
11/25 02:47:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][200/351]	Step 41680	lr 0.00159	Loss 0.2954 (0.2930)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
11/25 02:48:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][300/351]	Step 41780	lr 0.00159	Loss 0.2552 (0.2977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
11/25 02:48:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][351/351]	Step 41831	lr 0.00159	Loss 0.3466 (0.2996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
11/25 02:48:51午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [140/149] Final Prec@1 91.2556%
11/25 02:48:57午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][39/40]	Step 41832	Loss 1.4670	Prec@(1,5) (63.3%, 89.0%)
11/25 02:48:57午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 63.3200%
11/25 02:48:57午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:49:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][100/351]	Step 41932	lr 0.00148	Loss 0.2280 (0.2867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
11/25 02:50:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][200/351]	Step 42032	lr 0.00148	Loss 0.3466 (0.2891)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
11/25 02:50:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][300/351]	Step 42132	lr 0.00148	Loss 0.3461 (0.2967)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
11/25 02:51:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][351/351]	Step 42183	lr 0.00148	Loss 0.2230 (0.2976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.4%)	
11/25 02:51:20午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [141/149] Final Prec@1 91.4356%
11/25 02:51:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][39/40]	Step 42184	Loss 1.4770	Prec@(1,5) (63.4%, 89.1%)
11/25 02:51:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 63.3800%
11/25 02:51:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3200%
11/25 02:52:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][100/351]	Step 42284	lr 0.00138	Loss 0.2228 (0.2799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
11/25 02:52:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][200/351]	Step 42384	lr 0.00138	Loss 0.3011 (0.2859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
11/25 02:53:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][300/351]	Step 42484	lr 0.00138	Loss 0.2139 (0.2851)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
11/25 02:53:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][351/351]	Step 42535	lr 0.00138	Loss 0.3060 (0.2864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
11/25 02:53:50午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [142/149] Final Prec@1 91.9178%
11/25 02:53:56午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][39/40]	Step 42536	Loss 1.4585	Prec@(1,5) (64.5%, 89.3%)
11/25 02:53:56午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 64.4400%
11/25 02:53:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 02:54:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][100/351]	Step 42636	lr 0.00129	Loss 0.2069 (0.2731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
11/25 02:55:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][200/351]	Step 42736	lr 0.00129	Loss 0.3052 (0.2773)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
11/25 02:55:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][300/351]	Step 42836	lr 0.00129	Loss 0.3711 (0.2828)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
11/25 02:56:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][351/351]	Step 42887	lr 0.00129	Loss 0.2600 (0.2853)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
11/25 02:56:18午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [143/149] Final Prec@1 91.7689%
11/25 02:56:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][39/40]	Step 42888	Loss 1.4716	Prec@(1,5) (63.8%, 88.8%)
11/25 02:56:25午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 63.8400%
11/25 02:56:25午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 02:57:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][100/351]	Step 42988	lr 0.00121	Loss 0.3018 (0.2702)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.5%)	
11/25 02:57:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][200/351]	Step 43088	lr 0.00121	Loss 0.2736 (0.2729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.5%)	
11/25 02:58:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][300/351]	Step 43188	lr 0.00121	Loss 0.3499 (0.2748)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.5%)	
11/25 02:58:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][351/351]	Step 43239	lr 0.00121	Loss 0.2244 (0.2771)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
11/25 02:58:47午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [144/149] Final Prec@1 92.3422%
11/25 02:58:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][39/40]	Step 43240	Loss 1.4880	Prec@(1,5) (63.5%, 88.7%)
11/25 02:58:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 63.5600%
11/25 02:58:54午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 02:59:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][100/351]	Step 43340	lr 0.00115	Loss 0.3097 (0.2740)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
11/25 03:00:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][200/351]	Step 43440	lr 0.00115	Loss 0.2469 (0.2709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
11/25 03:00:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][300/351]	Step 43540	lr 0.00115	Loss 0.2015 (0.2724)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
11/25 03:01:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][351/351]	Step 43591	lr 0.00115	Loss 0.2464 (0.2750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
11/25 03:01:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [145/149] Final Prec@1 92.2467%
11/25 03:01:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][39/40]	Step 43592	Loss 1.4499	Prec@(1,5) (64.4%, 88.9%)
11/25 03:01:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 64.3400%
11/25 03:01:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 03:02:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][100/351]	Step 43692	lr 0.00109	Loss 0.2746 (0.2686)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
11/25 03:02:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][200/351]	Step 43792	lr 0.00109	Loss 0.2181 (0.2699)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
11/25 03:03:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][300/351]	Step 43892	lr 0.00109	Loss 0.2401 (0.2737)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
11/25 03:03:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][351/351]	Step 43943	lr 0.00109	Loss 0.2164 (0.2753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
11/25 03:03:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [146/149] Final Prec@1 92.2711%
11/25 03:03:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][39/40]	Step 43944	Loss 1.4698	Prec@(1,5) (64.1%, 89.2%)
11/25 03:03:51午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 64.0800%
11/25 03:03:51午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 03:04:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][100/351]	Step 44044	lr 0.00105	Loss 0.2406 (0.2585)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.5%)	
11/25 03:05:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][200/351]	Step 44144	lr 0.00105	Loss 0.2594 (0.2623)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/25 03:05:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][300/351]	Step 44244	lr 0.00105	Loss 0.3624 (0.2674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
11/25 03:06:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][351/351]	Step 44295	lr 0.00105	Loss 0.2565 (0.2689)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
11/25 03:06:13午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [147/149] Final Prec@1 92.4244%
11/25 03:06:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][39/40]	Step 44296	Loss 1.4717	Prec@(1,5) (63.1%, 89.0%)
11/25 03:06:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 63.1600%
11/25 03:06:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 03:07:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][100/351]	Step 44396	lr 0.00102	Loss 0.3881 (0.2629)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/25 03:07:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][200/351]	Step 44496	lr 0.00102	Loss 0.2953 (0.2659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/25 03:08:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][300/351]	Step 44596	lr 0.00102	Loss 0.2529 (0.2671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.5%)	
11/25 03:08:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][351/351]	Step 44647	lr 0.00102	Loss 0.2874 (0.2688)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
11/25 03:08:42午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [148/149] Final Prec@1 92.4422%
11/25 03:08:48午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][39/40]	Step 44648	Loss 1.4636	Prec@(1,5) (64.4%, 88.8%)
11/25 03:08:48午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 64.3400%
11/25 03:08:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 03:09:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][100/351]	Step 44748	lr 0.00101	Loss 0.2841 (0.2572)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
11/25 03:10:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][200/351]	Step 44848	lr 0.00101	Loss 0.2426 (0.2616)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
11/25 03:10:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][300/351]	Step 44948	lr 0.00101	Loss 0.2890 (0.2638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/25 03:11:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][351/351]	Step 44999	lr 0.00101	Loss 0.2937 (0.2657)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/25 03:11:10午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [149/149] Final Prec@1 92.5978%
11/25 03:11:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][39/40]	Step 45000	Loss 1.4809	Prec@(1,5) (63.5%, 89.1%)
11/25 03:11:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 63.5000%
11/25 03:11:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4400%
11/25 03:11:17午後 searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 64.4400%
11/25 03:11:17午後 searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
