11/25 12:44:33AM parser.py:28 [INFO] 
11/25 12:44:33AM parser.py:29 [INFO] Parameters:
11/25 12:44:33AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s3--sw3-g_30-20/DAG
11/25 12:44:33AM parser.py:31 [INFO] T=10.0
11/25 12:44:33AM parser.py:31 [INFO] ADVANCED=1
11/25 12:44:33AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/25 12:44:33AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/25 12:44:33AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/25 12:44:33AM parser.py:31 [INFO] BATCH_SIZE=128
11/25 12:44:33AM parser.py:31 [INFO] CASCADE=0
11/25 12:44:33AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/25 12:44:33AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 20]
11/25 12:44:33AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/25 12:44:33AM parser.py:31 [INFO] DATA_PATH=../data/
11/25 12:44:33AM parser.py:31 [INFO] DATASET=cifar100
11/25 12:44:33AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/25 12:44:33AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3_
11/25 12:44:33AM parser.py:31 [INFO] DISCRETE=1
11/25 12:44:33AM parser.py:31 [INFO] EPOCHS=50
11/25 12:44:33AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/25 12:44:33AM parser.py:31 [INFO] EXP_NAME=s3--sw3-g_30-20
11/25 12:44:33AM parser.py:31 [INFO] FINAL_L=0.0
11/25 12:44:33AM parser.py:31 [INFO] G=0.001
11/25 12:44:33AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/25 12:44:33AM parser.py:31 [INFO] GPUS=[0]
11/25 12:44:33AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/25 12:44:33AM parser.py:31 [INFO] INIT_CHANNELS=16
11/25 12:44:33AM parser.py:31 [INFO] L=0.0
11/25 12:44:33AM parser.py:31 [INFO] LAYERS=32
11/25 12:44:33AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/25 12:44:33AM parser.py:31 [INFO] NAME=Curriculum
11/25 12:44:33AM parser.py:31 [INFO] NONKD=1
11/25 12:44:33AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s3--sw3-g_30-20
11/25 12:44:33AM parser.py:31 [INFO] PCDARTS=0
11/25 12:44:33AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s3--sw3-g_30-20/plots
11/25 12:44:33AM parser.py:31 [INFO] PRINT_FREQ=100
11/25 12:44:33AM parser.py:31 [INFO] RESET=0
11/25 12:44:33AM parser.py:31 [INFO] RESUME_PATH=None
11/25 12:44:33AM parser.py:31 [INFO] SAVE=s3--sw3-g_30-20
11/25 12:44:33AM parser.py:31 [INFO] SEED=3
11/25 12:44:33AM parser.py:31 [INFO] SHARE_STAGE=0
11/25 12:44:33AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/25 12:44:33AM parser.py:31 [INFO] SPEC_CELL=1
11/25 12:44:33AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/25 12:44:33AM parser.py:31 [INFO] TEACHER_NAME=none
11/25 12:44:33AM parser.py:31 [INFO] TEACHER_PATH=none
11/25 12:44:33AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/25 12:44:33AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
11/25 12:44:33AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/25 12:44:33AM parser.py:31 [INFO] W_LR=0.025
11/25 12:44:33AM parser.py:31 [INFO] W_LR_MIN=0.001
11/25 12:44:33AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/25 12:44:33AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/25 12:44:33AM parser.py:31 [INFO] WORKERS=4
11/25 12:44:33AM parser.py:32 [INFO] 
11/25 12:44:35AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/25 12:45:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][100/195]	Step 100	lr 0.025	Loss 4.0956 (4.3894)	Arch Loss 4.1319 (4.3814)	Arch Hard Loss 4.1319 (4.3814)	Arch Beta Loss 359.9607 (359.9973)	Arch depth Loss -0.0042 (-0.0028)	Prec@(1,5) (3.6%, 13.9%)	
11/25 12:46:57AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][195/195]	Step 195	lr 0.025	Loss 3.9861 (4.2257)	Arch Loss 4.0932 (4.2197)	Arch Hard Loss 4.0932 (4.2197)	Arch Beta Loss 359.0372 (359.7817)	Arch depth Loss -0.0075 (-0.0039)	Prec@(1,5) (5.2%, 18.9%)	
11/25 12:46:59AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  0/149] Final Prec@1 5.1880%
11/25 12:47:08AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/196]	Step 196	Loss 4.0165	Prec@(1,5) (6.5%, 25.6%)
11/25 12:47:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][195/196]	Step 196	Loss 4.0136	Prec@(1,5) (6.6%, 25.7%)
11/25 12:47:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 6.5600%
11/25 12:47:16AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 12:47:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 6.5600%
11/25 12:48:29AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][100/195]	Step 296	lr 0.025	Loss 4.0454 (3.8559)	Arch Loss 3.7448 (3.8524)	Arch Hard Loss 3.7448 (3.8524)	Arch Beta Loss 358.3889 (358.7178)	Arch depth Loss -0.0073 (-0.0077)	Prec@(1,5) (9.3%, 30.4%)	
11/25 12:49:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][195/195]	Step 391	lr 0.025	Loss 3.8323 (3.7900)	Arch Loss 3.8520 (3.7792)	Arch Hard Loss 3.8520 (3.7792)	Arch Beta Loss 357.3565 (358.2934)	Arch depth Loss -0.0082 (-0.0078)	Prec@(1,5) (10.6%, 32.6%)	
11/25 12:49:37AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  1/149] Final Prec@1 10.5600%
11/25 12:49:46AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/196]	Step 392	Loss 3.7662	Prec@(1,5) (11.1%, 34.2%)
11/25 12:49:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][195/196]	Step 392	Loss 3.7531	Prec@(1,5) (11.3%, 34.6%)
11/25 12:49:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 11.2640%
11/25 12:49:54AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 12:49:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 11.2640%
11/25 12:51:08AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][100/195]	Step 492	lr 0.02499	Loss 3.5549 (3.5966)	Arch Loss 3.5330 (3.6164)	Arch Hard Loss 3.5330 (3.6164)	Arch Beta Loss 356.8787 (357.1421)	Arch depth Loss -0.0096 (-0.0094)	Prec@(1,5) (13.5%, 38.5%)	
11/25 12:52:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][195/195]	Step 587	lr 0.02499	Loss 3.4858 (3.5515)	Arch Loss 3.7792 (3.5570)	Arch Hard Loss 3.7792 (3.5570)	Arch Beta Loss 355.3514 (356.6212)	Arch depth Loss -0.0104 (-0.0100)	Prec@(1,5) (14.4%, 40.1%)	
11/25 12:52:16AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  2/149] Final Prec@1 14.4200%
11/25 12:52:25AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/196]	Step 588	Loss 3.5456	Prec@(1,5) (14.6%, 40.9%)
11/25 12:52:33AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][195/196]	Step 588	Loss 3.5558	Prec@(1,5) (14.2%, 40.8%)
11/25 12:52:34AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 14.2360%
11/25 12:52:34AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 12:52:34AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 14.2360%
11/25 12:53:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][100/195]	Step 688	lr 0.02498	Loss 3.3640 (3.3530)	Arch Loss 3.3603 (3.4090)	Arch Hard Loss 3.3603 (3.4090)	Arch Beta Loss 354.0919 (354.6405)	Arch depth Loss -0.0109 (-0.0101)	Prec@(1,5) (17.7%, 45.5%)	
11/25 12:54:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][195/195]	Step 783	lr 0.02498	Loss 3.0596 (3.3335)	Arch Loss 3.1446 (3.3539)	Arch Hard Loss 3.1446 (3.3539)	Arch Beta Loss 353.2139 (354.1602)	Arch depth Loss -0.0090 (-0.0098)	Prec@(1,5) (18.4%, 46.4%)	
11/25 12:54:55AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  3/149] Final Prec@1 18.4400%
11/25 12:55:04AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/196]	Step 784	Loss 3.3970	Prec@(1,5) (17.2%, 45.6%)
11/25 12:55:12AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][195/196]	Step 784	Loss 3.3946	Prec@(1,5) (17.1%, 45.9%)
11/25 12:55:12AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 17.1120%
11/25 12:55:12AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 12:55:13AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 17.1120%
11/25 12:56:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][100/195]	Step 884	lr 0.02496	Loss 3.2433 (3.1694)	Arch Loss 3.3147 (3.2351)	Arch Hard Loss 3.3147 (3.2351)	Arch Beta Loss 351.8903 (352.6418)	Arch depth Loss -0.0134 (-0.0111)	Prec@(1,5) (20.9%, 50.8%)	
11/25 12:57:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][195/195]	Step 979	lr 0.02496	Loss 3.0627 (3.1409)	Arch Loss 3.0765 (3.1969)	Arch Hard Loss 3.0765 (3.1969)	Arch Beta Loss 351.5476 (352.1202)	Arch depth Loss -0.0118 (-0.0119)	Prec@(1,5) (21.7%, 51.6%)	
11/25 12:57:34AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  4/149] Final Prec@1 21.6760%
11/25 12:57:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/196]	Step 980	Loss 3.1988	Prec@(1,5) (20.3%, 50.7%)
11/25 12:57:51AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][195/196]	Step 980	Loss 3.1914	Prec@(1,5) (21.1%, 51.1%)
11/25 12:57:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 21.1240%
11/25 12:57:52AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/25 12:57:52AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 21.1240%
11/25 06:11:16AM parser.py:28 [INFO] 
11/25 06:11:16AM parser.py:29 [INFO] Parameters:
11/25 06:11:16AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s3--sw3-g_30-20/DAG
11/25 06:11:16AM parser.py:31 [INFO] T=10.0
11/25 06:11:16AM parser.py:31 [INFO] ADVANCED=1
11/25 06:11:16AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/25 06:11:16AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/25 06:11:16AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/25 06:11:16AM parser.py:31 [INFO] BATCH_SIZE=128
11/25 06:11:16AM parser.py:31 [INFO] CASCADE=0
11/25 06:11:16AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/25 06:11:16AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 20]
11/25 06:11:16AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/25 06:11:16AM parser.py:31 [INFO] DATA_PATH=../data/
11/25 06:11:16AM parser.py:31 [INFO] DATASET=cifar100
11/25 06:11:16AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/25 06:11:16AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3_
11/25 06:11:16AM parser.py:31 [INFO] DISCRETE=1
11/25 06:11:16AM parser.py:31 [INFO] EPOCHS=50
11/25 06:11:16AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/25 06:11:16AM parser.py:31 [INFO] EXP_NAME=s3--sw3-g_30-20
11/25 06:11:16AM parser.py:31 [INFO] FINAL_L=0.0
11/25 06:11:16AM parser.py:31 [INFO] G=0.001
11/25 06:11:16AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/25 06:11:16AM parser.py:31 [INFO] GPUS=[0]
11/25 06:11:16AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/25 06:11:16AM parser.py:31 [INFO] INIT_CHANNELS=16
11/25 06:11:16AM parser.py:31 [INFO] L=0.0
11/25 06:11:16AM parser.py:31 [INFO] LAYERS=32
11/25 06:11:16AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/25 06:11:16AM parser.py:31 [INFO] NAME=Curriculum
11/25 06:11:16AM parser.py:31 [INFO] NONKD=1
11/25 06:11:16AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s3--sw3-g_30-20
11/25 06:11:16AM parser.py:31 [INFO] PCDARTS=0
11/25 06:11:16AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s3--sw3-g_30-20/plots
11/25 06:11:16AM parser.py:31 [INFO] PRINT_FREQ=100
11/25 06:11:16AM parser.py:31 [INFO] RESET=0
11/25 06:11:16AM parser.py:31 [INFO] RESUME_PATH=None
11/25 06:11:16AM parser.py:31 [INFO] SAVE=s3--sw3-g_30-20
11/25 06:11:16AM parser.py:31 [INFO] SEED=3
11/25 06:11:16AM parser.py:31 [INFO] SHARE_STAGE=0
11/25 06:11:16AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/25 06:11:16AM parser.py:31 [INFO] SPEC_CELL=1
11/25 06:11:16AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/25 06:11:16AM parser.py:31 [INFO] TEACHER_NAME=none
11/25 06:11:16AM parser.py:31 [INFO] TEACHER_PATH=none
11/25 06:11:16AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/25 06:11:16AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
11/25 06:11:16AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/25 06:11:16AM parser.py:31 [INFO] W_LR=0.025
11/25 06:11:16AM parser.py:31 [INFO] W_LR_MIN=0.001
11/25 06:11:16AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/25 06:11:16AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/25 06:11:16AM parser.py:31 [INFO] WORKERS=4
11/25 06:11:16AM parser.py:32 [INFO] 
11/25 06:11:18AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/25 06:12:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][100/195]	Step 100	lr 0.025	Loss 4.2059 (4.4418)	Arch Loss 4.1952 (4.4227)	Arch Hard Loss 4.1952 (4.4227)	Arch Beta Loss 359.4200 (359.7911)	Arch depth Loss -0.0034 (-0.0022)	Prec@(1,5) (2.9%, 11.3%)	
11/25 06:13:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][195/195]	Step 195	lr 0.025	Loss 4.0213 (4.2984)	Arch Loss 4.0754 (4.2847)	Arch Hard Loss 4.0754 (4.2847)	Arch Beta Loss 358.6335 (359.4970)	Arch depth Loss -0.0062 (-0.0031)	Prec@(1,5) (4.3%, 15.9%)	
11/25 06:13:42AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  0/149] Final Prec@1 4.2680%
11/25 06:13:51AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/196]	Step 196	Loss 4.0583	Prec@(1,5) (5.8%, 23.7%)
11/25 06:13:59AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][195/196]	Step 196	Loss 4.0669	Prec@(1,5) (5.8%, 23.6%)
11/25 06:13:59AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 5.7760%
11/25 06:13:59AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 06:14:00AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 5.7760%
11/25 06:15:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][100/195]	Step 296	lr 0.025	Loss 4.0432 (3.9481)	Arch Loss 3.8410 (3.9461)	Arch Hard Loss 3.8410 (3.9461)	Arch Beta Loss 358.1142 (358.2763)	Arch depth Loss -0.0098 (-0.0079)	Prec@(1,5) (7.7%, 26.6%)	
11/25 06:16:20AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][195/195]	Step 391	lr 0.025	Loss 3.8773 (3.8792)	Arch Loss 3.8594 (3.8725)	Arch Hard Loss 3.8594 (3.8725)	Arch Beta Loss 357.1310 (357.9599)	Arch depth Loss -0.0074 (-0.0083)	Prec@(1,5) (9.0%, 29.3%)	
11/25 06:16:21AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  1/149] Final Prec@1 8.9520%
11/25 06:16:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/196]	Step 392	Loss 3.8124	Prec@(1,5) (10.5%, 31.9%)
11/25 06:16:38AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][195/196]	Step 392	Loss 3.8119	Prec@(1,5) (10.5%, 32.1%)
11/25 06:16:39AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 10.5200%
11/25 06:16:39AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 06:16:39AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 10.5200%
11/25 06:17:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][100/195]	Step 492	lr 0.02499	Loss 3.6471 (3.6642)	Arch Loss 3.7087 (3.6860)	Arch Hard Loss 3.7087 (3.6860)	Arch Beta Loss 356.2456 (356.5688)	Arch depth Loss -0.0083 (-0.0086)	Prec@(1,5) (12.1%, 36.6%)	
11/25 06:19:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][195/195]	Step 587	lr 0.02499	Loss 3.6921 (3.6186)	Arch Loss 3.6961 (3.6208)	Arch Hard Loss 3.6961 (3.6208)	Arch Beta Loss 355.1025 (356.1692)	Arch depth Loss -0.0083 (-0.0086)	Prec@(1,5) (12.9%, 38.0%)	
11/25 06:19:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  2/149] Final Prec@1 12.9240%
11/25 06:19:10AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/196]	Step 588	Loss 3.5503	Prec@(1,5) (14.2%, 40.7%)
11/25 06:19:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][195/196]	Step 588	Loss 3.5608	Prec@(1,5) (13.8%, 40.3%)
11/25 06:19:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 13.8480%
11/25 06:19:18AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/25 06:19:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 13.8480%
11/25 06:20:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][100/195]	Step 688	lr 0.02498	Loss 3.3546 (3.3999)	Arch Loss 3.5101 (3.4653)	Arch Hard Loss 3.5101 (3.4653)	Arch Beta Loss 354.2943 (354.7011)	Arch depth Loss -0.0114 (-0.0088)	Prec@(1,5) (17.6%, 44.7%)	
11/25 06:21:39AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][195/195]	Step 783	lr 0.02498	Loss 3.0946 (3.3784)	Arch Loss 3.2926 (3.4031)	Arch Hard Loss 3.2926 (3.4031)	Arch Beta Loss 353.4834 (354.2786)	Arch depth Loss -0.0112 (-0.0097)	Prec@(1,5) (17.8%, 45.3%)	
11/25 06:21:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  3/149] Final Prec@1 17.7680%
11/25 06:21:49AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/196]	Step 784	Loss 3.3285	Prec@(1,5) (18.6%, 46.8%)
11/25 06:21:57AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][195/196]	Step 784	Loss 3.3279	Prec@(1,5) (18.5%, 46.9%)
11/25 06:21:57AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 18.4840%
11/25 06:21:57AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:21:58AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 18.4840%
11/25 06:23:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][100/195]	Step 884	lr 0.02496	Loss 3.2825 (3.2266)	Arch Loss 3.2427 (3.2603)	Arch Hard Loss 3.2427 (3.2603)	Arch Beta Loss 352.5911 (353.0498)	Arch depth Loss -0.0101 (-0.0096)	Prec@(1,5) (20.1%, 49.2%)	
11/25 06:24:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][195/195]	Step 979	lr 0.02496	Loss 3.0727 (3.1882)	Arch Loss 3.0177 (3.2252)	Arch Hard Loss 3.0177 (3.2252)	Arch Beta Loss 351.8991 (352.6586)	Arch depth Loss -0.0091 (-0.0100)	Prec@(1,5) (20.8%, 50.4%)	
11/25 06:24:18AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  4/149] Final Prec@1 20.7720%
11/25 06:24:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/196]	Step 980	Loss 3.1886	Prec@(1,5) (20.5%, 51.1%)
11/25 06:24:36AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][195/196]	Step 980	Loss 3.1811	Prec@(1,5) (21.1%, 51.3%)
11/25 06:24:36AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 21.1120%
11/25 06:24:36AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:24:37AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 21.1120%
11/25 06:25:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][100/195]	Step 1080	lr 0.02493	Loss 2.6151 (3.0539)	Arch Loss 2.8615 (3.1245)	Arch Hard Loss 2.8615 (3.1245)	Arch Beta Loss 350.9547 (351.4768)	Arch depth Loss -0.0091 (-0.0090)	Prec@(1,5) (23.1%, 53.9%)	
11/25 06:26:57AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][195/195]	Step 1175	lr 0.02493	Loss 3.0033 (3.0305)	Arch Loss 3.0243 (3.0963)	Arch Hard Loss 3.0243 (3.0963)	Arch Beta Loss 350.1197 (351.0332)	Arch depth Loss -0.0087 (-0.0083)	Prec@(1,5) (23.5%, 54.5%)	
11/25 06:26:57AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  5/149] Final Prec@1 23.4640%
11/25 06:27:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/196]	Step 1176	Loss 3.0845	Prec@(1,5) (23.3%, 53.6%)
11/25 06:27:14AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][195/196]	Step 1176	Loss 3.0956	Prec@(1,5) (23.0%, 53.6%)
11/25 06:27:15AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 23.0160%
11/25 06:27:15AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:27:15AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 23.0160%
11/25 06:28:28AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][100/195]	Step 1276	lr 0.02491	Loss 3.0107 (2.9072)	Arch Loss 3.0067 (3.0234)	Arch Hard Loss 3.0067 (3.0234)	Arch Beta Loss 349.3152 (349.6976)	Arch depth Loss -0.0109 (-0.0102)	Prec@(1,5) (26.2%, 57.6%)	
11/25 06:29:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][195/195]	Step 1371	lr 0.02491	Loss 2.9002 (2.8901)	Arch Loss 2.8564 (2.9732)	Arch Hard Loss 2.8564 (2.9732)	Arch Beta Loss 348.5565 (349.3491)	Arch depth Loss -0.0142 (-0.0111)	Prec@(1,5) (26.4%, 57.9%)	
11/25 06:29:37AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  6/149] Final Prec@1 26.3880%
11/25 06:29:46AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/196]	Step 1372	Loss 2.9220	Prec@(1,5) (25.8%, 57.7%)
11/25 06:29:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][195/196]	Step 1372	Loss 2.9189	Prec@(1,5) (26.0%, 58.0%)
11/25 06:29:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 26.0320%
11/25 06:29:54AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:29:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 26.0320%
11/25 06:31:08AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][100/195]	Step 1472	lr 0.02487	Loss 2.9664 (2.7480)	Arch Loss 2.7785 (2.8672)	Arch Hard Loss 2.7785 (2.8672)	Arch Beta Loss 347.7128 (348.1487)	Arch depth Loss -0.0139 (-0.0139)	Prec@(1,5) (29.2%, 61.4%)	
11/25 06:32:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][195/195]	Step 1567	lr 0.02487	Loss 2.6807 (2.7420)	Arch Loss 2.8491 (2.8545)	Arch Hard Loss 2.8491 (2.8545)	Arch Beta Loss 346.7877 (347.7074)	Arch depth Loss -0.0162 (-0.0145)	Prec@(1,5) (29.6%, 61.4%)	
11/25 06:32:16AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  7/149] Final Prec@1 29.5680%
11/25 06:32:25AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/196]	Step 1568	Loss 2.8203	Prec@(1,5) (28.4%, 59.9%)
11/25 06:32:33AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][195/196]	Step 1568	Loss 2.8398	Prec@(1,5) (27.7%, 59.6%)
11/25 06:32:34AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 27.7000%
11/25 06:32:34AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:32:34AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 27.7000%
11/25 06:33:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][100/195]	Step 1668	lr 0.02483	Loss 2.6339 (2.6082)	Arch Loss 3.0666 (2.7780)	Arch Hard Loss 3.0666 (2.7780)	Arch Beta Loss 345.7628 (346.3357)	Arch depth Loss -0.0198 (-0.0185)	Prec@(1,5) (32.4%, 65.1%)	
11/25 06:34:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][195/195]	Step 1763	lr 0.02483	Loss 2.7118 (2.6150)	Arch Loss 2.7490 (2.7379)	Arch Hard Loss 2.7490 (2.7379)	Arch Beta Loss 345.0975 (345.8827)	Arch depth Loss -0.0193 (-0.0190)	Prec@(1,5) (32.4%, 64.8%)	
11/25 06:34:56AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  8/149] Final Prec@1 32.3880%
11/25 06:35:05AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/196]	Step 1764	Loss 2.7550	Prec@(1,5) (29.9%, 61.2%)
11/25 06:35:13AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][195/196]	Step 1764	Loss 2.7485	Prec@(1,5) (30.2%, 61.4%)
11/25 06:35:13AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 30.2160%
11/25 06:35:13AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:35:14AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 30.2160%
11/25 06:36:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][100/195]	Step 1864	lr 0.02479	Loss 2.6661 (2.4806)	Arch Loss 2.6606 (2.6636)	Arch Hard Loss 2.6606 (2.6636)	Arch Beta Loss 344.6053 (344.8071)	Arch depth Loss -0.0212 (-0.0209)	Prec@(1,5) (34.5%, 67.5%)	
11/25 06:37:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][195/195]	Step 1959	lr 0.02479	Loss 2.6032 (2.4843)	Arch Loss 2.5524 (2.6491)	Arch Hard Loss 2.5524 (2.6491)	Arch Beta Loss 344.0192 (344.5569)	Arch depth Loss -0.0246 (-0.0220)	Prec@(1,5) (34.8%, 67.6%)	
11/25 06:37:35AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  9/149] Final Prec@1 34.7920%
11/25 06:37:44AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/196]	Step 1960	Loss 2.5886	Prec@(1,5) (33.5%, 65.4%)
11/25 06:37:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][195/196]	Step 1960	Loss 2.5861	Prec@(1,5) (33.5%, 65.6%)
11/25 06:37:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 33.4840%
11/25 06:37:52AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:37:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.4840%
11/25 06:39:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][100/195]	Step 2060	lr 0.02474	Loss 2.2213 (2.3830)	Arch Loss 2.5986 (2.5871)	Arch Hard Loss 2.5986 (2.5871)	Arch Beta Loss 343.1776 (343.6252)	Arch depth Loss -0.0270 (-0.0261)	Prec@(1,5) (36.5%, 70.1%)	
11/25 06:40:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][195/195]	Step 2155	lr 0.02474	Loss 2.4596 (2.3910)	Arch Loss 2.2332 (2.5696)	Arch Hard Loss 2.2332 (2.5696)	Arch Beta Loss 342.4970 (343.3101)	Arch depth Loss -0.0291 (-0.0265)	Prec@(1,5) (36.2%, 69.9%)	
11/25 06:40:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 10/149] Final Prec@1 36.2440%
11/25 06:40:23AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/196]	Step 2156	Loss 2.5707	Prec@(1,5) (33.7%, 66.1%)
11/25 06:40:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][195/196]	Step 2156	Loss 2.5796	Prec@(1,5) (33.7%, 65.9%)
11/25 06:40:32AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 33.6720%
11/25 06:40:32AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:40:32AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.6720%
11/25 06:41:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][100/195]	Step 2256	lr 0.02468	Loss 2.3492 (2.3086)	Arch Loss 2.4120 (2.5155)	Arch Hard Loss 2.4120 (2.5155)	Arch Beta Loss 341.7998 (342.2221)	Arch depth Loss -0.0309 (-0.0303)	Prec@(1,5) (38.0%, 71.3%)	
11/25 06:42:53AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][195/195]	Step 2351	lr 0.02468	Loss 2.3161 (2.2889)	Arch Loss 2.4217 (2.4937)	Arch Hard Loss 2.4217 (2.4937)	Arch Beta Loss 340.9506 (341.7531)	Arch depth Loss -0.0314 (-0.0309)	Prec@(1,5) (38.5%, 71.9%)	
11/25 06:42:54AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 11/149] Final Prec@1 38.5280%
11/25 06:43:03AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/196]	Step 2352	Loss 2.5155	Prec@(1,5) (34.0%, 67.9%)
11/25 06:43:11AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][195/196]	Step 2352	Loss 2.5333	Prec@(1,5) (34.2%, 67.5%)
11/25 06:43:11AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 34.1720%
11/25 06:43:11AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:43:12AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 34.1720%
11/25 06:44:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][100/195]	Step 2452	lr 0.02462	Loss 2.0462 (2.1988)	Arch Loss 2.6248 (2.4337)	Arch Hard Loss 2.6248 (2.4337)	Arch Beta Loss 340.2264 (340.5934)	Arch depth Loss -0.0326 (-0.0325)	Prec@(1,5) (40.7%, 73.9%)	
11/25 06:45:32AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][195/195]	Step 2547	lr 0.02462	Loss 1.9457 (2.2066)	Arch Loss 2.3941 (2.4268)	Arch Hard Loss 2.3941 (2.4268)	Arch Beta Loss 339.3219 (340.2102)	Arch depth Loss -0.0321 (-0.0322)	Prec@(1,5) (40.9%, 73.8%)	
11/25 06:45:33AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 12/149] Final Prec@1 40.9040%
11/25 06:45:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/196]	Step 2548	Loss 2.4068	Prec@(1,5) (37.4%, 69.3%)
11/25 06:45:50AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][195/196]	Step 2548	Loss 2.3986	Prec@(1,5) (37.4%, 69.5%)
11/25 06:45:50AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 37.4480%
11/25 06:45:50AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/25 06:45:51AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.4480%
11/25 06:47:04AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][100/195]	Step 2648	lr 0.02456	Loss 2.0756 (2.1165)	Arch Loss 2.5378 (2.3912)	Arch Hard Loss 2.5378 (2.3912)	Arch Beta Loss 338.4420 (338.8877)	Arch depth Loss -0.0364 (-0.0339)	Prec@(1,5) (42.4%, 76.0%)	
11/25 06:48:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][195/195]	Step 2743	lr 0.02456	Loss 2.2108 (2.1135)	Arch Loss 2.5053 (2.3860)	Arch Hard Loss 2.5053 (2.3860)	Arch Beta Loss 337.4279 (338.4187)	Arch depth Loss -0.0370 (-0.0353)	Prec@(1,5) (42.7%, 75.8%)	
11/25 06:48:12AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 13/149] Final Prec@1 42.7120%
11/25 06:48:21AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/196]	Step 2744	Loss 2.4179	Prec@(1,5) (37.0%, 69.6%)
11/25 06:48:29AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][195/196]	Step 2744	Loss 2.4072	Prec@(1,5) (37.4%, 69.7%)
11/25 06:48:30AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 37.3720%
11/25 06:48:30AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 06:48:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.4480%
11/25 06:49:43AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][100/195]	Step 2844	lr 0.02449	Loss 1.9189 (2.0375)	Arch Loss 2.4389 (2.3283)	Arch Hard Loss 2.4389 (2.3283)	Arch Beta Loss 336.4377 (336.8954)	Arch depth Loss -0.0368 (-0.0366)	Prec@(1,5) (44.6%, 77.1%)	
11/25 06:50:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][195/195]	Step 2939	lr 0.02449	Loss 2.0721 (2.0509)	Arch Loss 2.2978 (2.3173)	Arch Hard Loss 2.2978 (2.3173)	Arch Beta Loss 336.2415 (336.6086)	Arch depth Loss -0.0358 (-0.0367)	Prec@(1,5) (44.3%, 76.6%)	
11/25 06:50:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 14/149] Final Prec@1 44.2600%
11/25 06:51:00AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/196]	Step 2940	Loss 2.3615	Prec@(1,5) (38.6%, 71.0%)
11/25 06:51:08AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][195/196]	Step 2940	Loss 2.3550	Prec@(1,5) (38.9%, 70.9%)
11/25 06:51:09AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 38.9200%
11/25 06:51:09AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 06:51:09AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 38.9200%
11/25 06:52:22AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][100/195]	Step 3040	lr 0.02441	Loss 1.7660 (1.9431)	Arch Loss 2.3666 (2.3185)	Arch Hard Loss 2.3666 (2.3185)	Arch Beta Loss 335.3607 (335.9502)	Arch depth Loss -0.0364 (-0.0359)	Prec@(1,5) (46.9%, 79.2%)	
11/25 06:53:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][195/195]	Step 3135	lr 0.02441	Loss 2.0352 (1.9811)	Arch Loss 2.0276 (2.2887)	Arch Hard Loss 2.0276 (2.2887)	Arch Beta Loss 334.7102 (335.4828)	Arch depth Loss -0.0369 (-0.0363)	Prec@(1,5) (45.8%, 78.2%)	
11/25 06:53:30AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 15/149] Final Prec@1 45.7960%
11/25 06:53:40AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/196]	Step 3136	Loss 2.3282	Prec@(1,5) (39.5%, 72.0%)
11/25 06:53:48AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][195/196]	Step 3136	Loss 2.3245	Prec@(1,5) (39.3%, 72.1%)
11/25 06:53:48AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 39.2800%
11/25 06:53:48AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 06:53:48AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.2800%
11/25 06:55:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][100/195]	Step 3236	lr 0.02433	Loss 1.7732 (1.9084)	Arch Loss 2.4945 (2.2295)	Arch Hard Loss 2.4945 (2.2295)	Arch Beta Loss 333.8526 (334.2477)	Arch depth Loss -0.0369 (-0.0368)	Prec@(1,5) (47.0%, 79.6%)	
11/25 06:56:09AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][195/195]	Step 3331	lr 0.02433	Loss 1.7929 (1.9096)	Arch Loss 2.0297 (2.2378)	Arch Hard Loss 2.0297 (2.2378)	Arch Beta Loss 333.0332 (333.8284)	Arch depth Loss -0.0343 (-0.0363)	Prec@(1,5) (47.0%, 79.5%)	
11/25 06:56:09AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 16/149] Final Prec@1 47.0000%
11/25 06:56:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/196]	Step 3332	Loss 2.2127	Prec@(1,5) (41.5%, 73.1%)
11/25 06:56:27AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][195/196]	Step 3332	Loss 2.2324	Prec@(1,5) (41.2%, 73.1%)
11/25 06:56:27AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 41.2120%
11/25 06:56:27AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 06:56:27AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.2120%
11/25 06:57:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][100/195]	Step 3432	lr 0.02425	Loss 1.8607 (1.8432)	Arch Loss 2.4661 (2.2194)	Arch Hard Loss 2.4661 (2.2194)	Arch Beta Loss 332.2607 (332.5620)	Arch depth Loss -0.0332 (-0.0338)	Prec@(1,5) (48.4%, 80.7%)	
11/25 06:58:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][195/195]	Step 3527	lr 0.02425	Loss 1.8010 (1.8600)	Arch Loss 2.4000 (2.2105)	Arch Hard Loss 2.4000 (2.2105)	Arch Beta Loss 331.4402 (332.2117)	Arch depth Loss -0.0325 (-0.0333)	Prec@(1,5) (48.1%, 80.5%)	
11/25 06:58:49AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 17/149] Final Prec@1 48.1360%
11/25 06:58:58AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/196]	Step 3528	Loss 2.1964	Prec@(1,5) (42.1%, 73.5%)
11/25 06:59:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][195/196]	Step 3528	Loss 2.2227	Prec@(1,5) (41.8%, 73.0%)
11/25 06:59:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 41.7760%
11/25 06:59:06AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 06:59:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.7760%
11/25 07:00:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][100/195]	Step 3628	lr 0.02416	Loss 1.8811 (1.7580)	Arch Loss 1.7660 (2.1655)	Arch Hard Loss 1.7660 (2.1655)	Arch Beta Loss 330.5760 (330.9924)	Arch depth Loss -0.0315 (-0.0321)	Prec@(1,5) (50.5%, 82.4%)	
11/25 07:01:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][195/195]	Step 3723	lr 0.02416	Loss 1.8980 (1.7910)	Arch Loss 2.0425 (2.1653)	Arch Hard Loss 2.0425 (2.1653)	Arch Beta Loss 329.6260 (330.5591)	Arch depth Loss -0.0293 (-0.0312)	Prec@(1,5) (50.1%, 81.5%)	
11/25 07:01:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 18/149] Final Prec@1 50.0920%
11/25 07:01:36AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/196]	Step 3724	Loss 2.2039	Prec@(1,5) (42.1%, 74.3%)
11/25 07:01:44AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][195/196]	Step 3724	Loss 2.1928	Prec@(1,5) (42.2%, 74.4%)
11/25 07:01:45AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 42.1520%
11/25 07:01:45AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:01:45AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.1520%
11/25 07:02:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][100/195]	Step 3824	lr 0.02406	Loss 1.8105 (1.7208)	Arch Loss 1.9352 (2.1508)	Arch Hard Loss 1.9352 (2.1508)	Arch Beta Loss 328.5916 (329.1461)	Arch depth Loss -0.0268 (-0.0278)	Prec@(1,5) (51.2%, 83.3%)	
11/25 07:04:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][195/195]	Step 3919	lr 0.02406	Loss 1.9490 (1.7495)	Arch Loss 2.0781 (2.1395)	Arch Hard Loss 2.0781 (2.1395)	Arch Beta Loss 327.9020 (328.7079)	Arch depth Loss -0.0247 (-0.0269)	Prec@(1,5) (50.6%, 82.6%)	
11/25 07:04:06AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 19/149] Final Prec@1 50.6200%
11/25 07:04:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/196]	Step 3920	Loss 2.1759	Prec@(1,5) (42.8%, 74.6%)
11/25 07:04:24AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][195/196]	Step 3920	Loss 2.1596	Prec@(1,5) (42.9%, 74.6%)
11/25 07:04:24AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 42.9320%
11/25 07:04:24AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:04:25AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.9320%
11/25 07:05:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][100/195]	Step 4020	lr 0.02396	Loss 1.7031 (1.6645)	Arch Loss 1.9999 (2.1214)	Arch Hard Loss 1.9999 (2.1214)	Arch Beta Loss 327.1099 (327.4352)	Arch depth Loss -0.0230 (-0.0234)	Prec@(1,5) (53.0%, 84.2%)	
11/25 07:06:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][195/195]	Step 4115	lr 0.02396	Loss 1.6533 (1.6911)	Arch Loss 2.4087 (2.1086)	Arch Hard Loss 2.4087 (2.1086)	Arch Beta Loss 326.0581 (326.9841)	Arch depth Loss -0.0210 (-0.0231)	Prec@(1,5) (52.5%, 83.7%)	
11/25 07:06:46AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 20/149] Final Prec@1 52.5200%
11/25 07:06:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/196]	Step 4116	Loss 2.1913	Prec@(1,5) (42.8%, 74.9%)
11/25 07:07:03AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][195/196]	Step 4116	Loss 2.1972	Prec@(1,5) (42.7%, 74.8%)
11/25 07:07:03AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 42.6600%
11/25 07:07:03AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:07:03AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.9320%
11/25 07:08:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][100/195]	Step 4216	lr 0.02386	Loss 1.6190 (1.6195)	Arch Loss 2.3530 (2.1133)	Arch Hard Loss 2.3530 (2.1133)	Arch Beta Loss 325.2664 (325.7296)	Arch depth Loss -0.0163 (-0.0180)	Prec@(1,5) (54.4%, 85.0%)	
11/25 07:09:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][195/195]	Step 4311	lr 0.02386	Loss 1.6247 (1.6523)	Arch Loss 2.1265 (2.1061)	Arch Hard Loss 2.1265 (2.1061)	Arch Beta Loss 324.3529 (325.3009)	Arch depth Loss -0.0142 (-0.0168)	Prec@(1,5) (53.5%, 84.2%)	
11/25 07:09:24AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 21/149] Final Prec@1 53.4800%
11/25 07:09:33AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/196]	Step 4312	Loss 2.1275	Prec@(1,5) (43.9%, 74.9%)
11/25 07:09:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][195/196]	Step 4312	Loss 2.1506	Prec@(1,5) (43.6%, 74.7%)
11/25 07:09:42AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 43.5440%
11/25 07:09:42AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:09:42AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.5440%
11/25 07:10:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][100/195]	Step 4412	lr 0.02375	Loss 1.5648 (1.5678)	Arch Loss 2.1001 (2.0795)	Arch Hard Loss 2.1001 (2.0795)	Arch Beta Loss 323.6158 (324.0482)	Arch depth Loss -0.0095 (-0.0120)	Prec@(1,5) (55.7%, 85.4%)	
11/25 07:12:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][195/195]	Step 4507	lr 0.02375	Loss 1.5234 (1.6021)	Arch Loss 2.0789 (2.0717)	Arch Hard Loss 2.0789 (2.0717)	Arch Beta Loss 322.6950 (323.5724)	Arch depth Loss -0.0043 (-0.0096)	Prec@(1,5) (54.5%, 84.9%)	
11/25 07:12:04AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 22/149] Final Prec@1 54.4880%
11/25 07:12:13AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/196]	Step 4508	Loss 2.0587	Prec@(1,5) (45.7%, 76.2%)
11/25 07:12:21AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][195/196]	Step 4508	Loss 2.0507	Prec@(1,5) (45.8%, 76.7%)
11/25 07:12:21AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 45.8280%
11/25 07:12:21AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:12:22AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8280%
11/25 07:13:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][100/195]	Step 4608	lr 0.02363	Loss 1.5209 (1.5419)	Arch Loss 2.2229 (2.0736)	Arch Hard Loss 2.2229 (2.0736)	Arch Beta Loss 321.9048 (322.3231)	Arch depth Loss 0.0021 (-0.0009)	Prec@(1,5) (56.0%, 85.9%)	
11/25 07:14:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][195/195]	Step 4703	lr 0.02363	Loss 1.6990 (1.5625)	Arch Loss 2.0414 (2.0659)	Arch Hard Loss 2.0414 (2.0659)	Arch Beta Loss 320.8724 (321.8689)	Arch depth Loss 0.0079 (0.0022)	Prec@(1,5) (55.3%, 85.8%)	
11/25 07:14:42AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 23/149] Final Prec@1 55.3040%
11/25 07:14:51AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/196]	Step 4704	Loss 2.1136	Prec@(1,5) (44.7%, 75.7%)
11/25 07:14:59AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][195/196]	Step 4704	Loss 2.1087	Prec@(1,5) (44.9%, 75.8%)
11/25 07:15:00AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 44.8720%
11/25 07:15:00AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:15:00AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8280%
11/25 07:16:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][100/195]	Step 4804	lr 0.02352	Loss 1.7979 (1.4803)	Arch Loss 1.8540 (2.0516)	Arch Hard Loss 1.8540 (2.0516)	Arch Beta Loss 319.8126 (320.3215)	Arch depth Loss 0.0135 (0.0098)	Prec@(1,5) (57.2%, 86.9%)	
11/25 07:17:20AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][195/195]	Step 4899	lr 0.02352	Loss 1.6062 (1.5187)	Arch Loss 2.2042 (2.0472)	Arch Hard Loss 2.2042 (2.0472)	Arch Beta Loss 318.7969 (319.8302)	Arch depth Loss 0.0199 (0.0134)	Prec@(1,5) (56.6%, 86.3%)	
11/25 07:17:21AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 24/149] Final Prec@1 56.6240%
11/25 07:17:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/196]	Step 4900	Loss 2.0777	Prec@(1,5) (45.4%, 76.5%)
11/25 07:17:38AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][195/196]	Step 4900	Loss 2.0825	Prec@(1,5) (45.2%, 76.8%)
11/25 07:17:38AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 45.2240%
11/25 07:17:38AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:17:38AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8280%
11/25 07:18:51AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][100/195]	Step 5000	lr 0.02339	Loss 1.2860 (1.4505)	Arch Loss 1.9220 (2.0539)	Arch Hard Loss 1.9220 (2.0539)	Arch Beta Loss 317.7349 (318.3188)	Arch depth Loss 0.0262 (0.0239)	Prec@(1,5) (58.7%, 87.7%)	
11/25 07:19:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][195/195]	Step 5095	lr 0.02339	Loss 1.9306 (1.4789)	Arch Loss 1.7272 (2.0349)	Arch Hard Loss 1.7272 (2.0349)	Arch Beta Loss 316.9515 (317.8500)	Arch depth Loss 0.0331 (0.0265)	Prec@(1,5) (57.9%, 87.0%)	
11/25 07:20:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 25/149] Final Prec@1 57.8640%
11/25 07:20:09AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/196]	Step 5096	Loss 2.0621	Prec@(1,5) (45.9%, 76.6%)
11/25 07:20:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][195/196]	Step 5096	Loss 2.0824	Prec@(1,5) (45.5%, 76.3%)
11/25 07:20:17AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 45.5000%
11/25 07:20:17AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:20:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8280%
11/25 07:21:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][100/195]	Step 5196	lr 0.02326	Loss 1.3809 (1.4339)	Arch Loss 1.9363 (2.0289)	Arch Hard Loss 1.9363 (2.0289)	Arch Beta Loss 316.0301 (316.5748)	Arch depth Loss 0.0421 (0.0373)	Prec@(1,5) (58.8%, 87.6%)	
11/25 07:22:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][195/195]	Step 5291	lr 0.02326	Loss 1.5281 (1.4536)	Arch Loss 2.0682 (2.0089)	Arch Hard Loss 2.0682 (2.0089)	Arch Beta Loss 315.1942 (316.0862)	Arch depth Loss 0.0508 (0.0414)	Prec@(1,5) (58.1%, 87.4%)	
11/25 07:22:38AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 26/149] Final Prec@1 58.0880%
11/25 07:22:47AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/196]	Step 5292	Loss 2.0788	Prec@(1,5) (45.5%, 77.0%)
11/25 07:22:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][195/196]	Step 5292	Loss 2.0636	Prec@(1,5) (45.6%, 77.1%)
11/25 07:22:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 45.6320%
11/25 07:22:55AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:22:56AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.8280%
11/25 07:24:08AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][100/195]	Step 5392	lr 0.02313	Loss 1.5991 (1.3569)	Arch Loss 1.8972 (1.9941)	Arch Hard Loss 1.8972 (1.9941)	Arch Beta Loss 314.5917 (314.8597)	Arch depth Loss 0.0612 (0.0557)	Prec@(1,5) (60.6%, 89.0%)	
11/25 07:25:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][195/195]	Step 5487	lr 0.02313	Loss 1.4404 (1.4085)	Arch Loss 2.3061 (1.9934)	Arch Hard Loss 2.3061 (1.9934)	Arch Beta Loss 313.7780 (314.5584)	Arch depth Loss 0.0686 (0.0602)	Prec@(1,5) (59.3%, 88.3%)	
11/25 07:25:17AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 27/149] Final Prec@1 59.3440%
11/25 07:25:26AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/196]	Step 5488	Loss 2.0285	Prec@(1,5) (46.5%, 77.8%)
11/25 07:25:34AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][195/196]	Step 5488	Loss 2.0343	Prec@(1,5) (46.2%, 77.8%)
11/25 07:25:34AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 46.2160%
11/25 07:25:34AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:25:35AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.2160%
11/25 07:26:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][100/195]	Step 5588	lr 0.023	Loss 1.2074 (1.3526)	Arch Loss 2.0205 (1.9905)	Arch Hard Loss 2.0205 (1.9905)	Arch Beta Loss 312.7888 (313.2234)	Arch depth Loss 0.0794 (0.0748)	Prec@(1,5) (61.1%, 88.8%)	
11/25 07:27:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][195/195]	Step 5683	lr 0.023	Loss 1.5105 (1.3750)	Arch Loss 1.9278 (1.9811)	Arch Hard Loss 1.9278 (1.9811)	Arch Beta Loss 312.2816 (312.8900)	Arch depth Loss 0.0889 (0.0794)	Prec@(1,5) (60.6%, 88.7%)	
11/25 07:27:56AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 28/149] Final Prec@1 60.6360%
11/25 07:28:05AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/196]	Step 5684	Loss 1.9826	Prec@(1,5) (47.1%, 78.3%)
11/25 07:28:13AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][195/196]	Step 5684	Loss 1.9806	Prec@(1,5) (47.4%, 78.4%)
11/25 07:28:13AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 47.4120%
11/25 07:28:13AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:28:14AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.4120%
11/25 07:29:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][100/195]	Step 5784	lr 0.02285	Loss 1.3685 (1.3182)	Arch Loss 1.7883 (1.9928)	Arch Hard Loss 1.7883 (1.9928)	Arch Beta Loss 311.2815 (311.7545)	Arch depth Loss 0.0987 (0.0933)	Prec@(1,5) (61.7%, 89.2%)	
11/25 07:30:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][195/195]	Step 5879	lr 0.02285	Loss 1.4410 (1.3498)	Arch Loss 1.9085 (1.9752)	Arch Hard Loss 1.9085 (1.9752)	Arch Beta Loss 310.6670 (311.3467)	Arch depth Loss 0.1061 (0.0973)	Prec@(1,5) (61.0%, 88.6%)	
11/25 07:30:35AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 29/149] Final Prec@1 61.0080%
11/25 07:30:44AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/196]	Step 5880	Loss 1.9931	Prec@(1,5) (47.5%, 78.2%)
11/25 07:30:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][195/196]	Step 5880	Loss 1.9916	Prec@(1,5) (47.4%, 78.3%)
11/25 07:30:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 47.3760%
11/25 07:30:52AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/25 07:30:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.4120%
11/25 07:30:53AM searchEvalStage_curriculum_trainer.py:146 [INFO] --> Curriculum part A finished. Part B begins!
11/25 07:32:05AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][100/195]	Step 5980	lr 0.02271	Loss 1.1911 (1.2571)	Arch Loss 2.4171 (2.2646)	Arch Hard Loss 2.1142 (1.9579)	Arch Beta Loss 302.8510 (306.6722)	Arch depth Loss 0.1141 (0.1095)	Prec@(1,5) (63.5%, 90.6%)	
11/25 07:33:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][195/195]	Step 6075	lr 0.02271	Loss 1.3954 (1.3027)	Arch Loss 2.1739 (2.2674)	Arch Hard Loss 1.8778 (1.9643)	Arch Beta Loss 296.1354 (303.1052)	Arch depth Loss 0.1242 (0.1143)	Prec@(1,5) (62.2%, 89.7%)	
11/25 07:33:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 30/149] Final Prec@1 62.1520%
11/25 07:33:23AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/196]	Step 6076	Loss 2.0440	Prec@(1,5) (46.8%, 77.5%)
11/25 07:33:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][195/196]	Step 6076	Loss 2.0331	Prec@(1,5) (47.2%, 77.6%)
11/25 07:33:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 47.1960%
11/25 07:33:31AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:33:32AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.4120%
11/25 07:34:44AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][100/195]	Step 6176	lr 0.02256	Loss 1.2620 (1.2494)	Arch Loss 2.1787 (2.2583)	Arch Hard Loss 1.8887 (1.9654)	Arch Beta Loss 289.9576 (292.9467)	Arch depth Loss 0.1361 (0.1307)	Prec@(1,5) (63.4%, 90.8%)	
11/25 07:35:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][195/195]	Step 6271	lr 0.02256	Loss 1.2748 (1.2690)	Arch Loss 2.1433 (2.2310)	Arch Hard Loss 1.8590 (1.9409)	Arch Beta Loss 284.2951 (290.0982)	Arch depth Loss 0.1446 (0.1352)	Prec@(1,5) (63.2%, 90.2%)	
11/25 07:35:53AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 31/149] Final Prec@1 63.1880%
11/25 07:36:02AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/196]	Step 6272	Loss 2.0135	Prec@(1,5) (47.7%, 78.2%)
11/25 07:36:10AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][195/196]	Step 6272	Loss 2.0082	Prec@(1,5) (47.9%, 78.1%)
11/25 07:36:10AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 47.8480%
11/25 07:36:10AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:36:11AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.8480%
11/25 07:37:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][100/195]	Step 6372	lr 0.0224	Loss 1.2152 (1.2280)	Arch Loss 2.4890 (2.2299)	Arch Hard Loss 2.2101 (1.9484)	Arch Beta Loss 278.8318 (281.4549)	Arch depth Loss 0.1564 (0.1510)	Prec@(1,5) (64.4%, 90.7%)	
11/25 07:38:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][195/195]	Step 6467	lr 0.0224	Loss 1.2979 (1.2543)	Arch Loss 2.1118 (2.2223)	Arch Hard Loss 1.8377 (1.9433)	Arch Beta Loss 274.0771 (279.0219)	Arch depth Loss 0.1680 (0.1568)	Prec@(1,5) (63.6%, 90.3%)	
11/25 07:38:32AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 32/149] Final Prec@1 63.5800%
11/25 07:38:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/196]	Step 6468	Loss 1.9168	Prec@(1,5) (49.2%, 79.4%)
11/25 07:38:49AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][195/196]	Step 6468	Loss 1.9332	Prec@(1,5) (48.8%, 79.4%)
11/25 07:38:49AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 48.8280%
11/25 07:38:49AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:38:50AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.8280%
11/25 07:40:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][100/195]	Step 6568	lr 0.02225	Loss 1.1850 (1.1870)	Arch Loss 1.9863 (2.2315)	Arch Hard Loss 1.7171 (1.9599)	Arch Beta Loss 269.2386 (271.5818)	Arch depth Loss 0.1810 (0.1746)	Prec@(1,5) (65.3%, 91.3%)	
11/25 07:41:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][195/195]	Step 6663	lr 0.02225	Loss 1.1681 (1.2128)	Arch Loss 2.1842 (2.1966)	Arch Hard Loss 1.9194 (1.9273)	Arch Beta Loss 264.8323 (269.3291)	Arch depth Loss 0.1935 (0.1804)	Prec@(1,5) (64.3%, 91.0%)	
11/25 07:41:10AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 33/149] Final Prec@1 64.3040%
11/25 07:41:20AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/196]	Step 6664	Loss 1.9569	Prec@(1,5) (48.5%, 79.1%)
11/25 07:41:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][195/196]	Step 6664	Loss 1.9818	Prec@(1,5) (47.9%, 78.9%)
11/25 07:41:28AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 47.8760%
11/25 07:41:28AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:41:28AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.8280%
11/25 07:42:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][100/195]	Step 6764	lr 0.02208	Loss 1.1224 (1.1578)	Arch Loss 2.2454 (2.1880)	Arch Hard Loss 1.9850 (1.9253)	Arch Beta Loss 260.4368 (262.6652)	Arch depth Loss 0.2066 (0.2001)	Prec@(1,5) (66.0%, 92.0%)	
11/25 07:43:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][195/195]	Step 6859	lr 0.02208	Loss 1.0973 (1.1965)	Arch Loss 2.3607 (2.1957)	Arch Hard Loss 2.1042 (1.9351)	Arch Beta Loss 256.5214 (260.5967)	Arch depth Loss 0.2187 (0.2059)	Prec@(1,5) (64.9%, 91.4%)	
11/25 07:43:48AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 34/149] Final Prec@1 64.9280%
11/25 07:43:58AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/196]	Step 6860	Loss 1.9211	Prec@(1,5) (49.1%, 79.6%)
11/25 07:44:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][195/196]	Step 6860	Loss 1.9345	Prec@(1,5) (48.9%, 79.4%)
11/25 07:44:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 48.9080%
11/25 07:44:06AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:44:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.9080%
11/25 07:45:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][100/195]	Step 6960	lr 0.02192	Loss 1.2579 (1.1305)	Arch Loss 1.9821 (2.1802)	Arch Hard Loss 1.7297 (1.9258)	Arch Beta Loss 252.3692 (254.3957)	Arch depth Loss 0.2313 (0.2254)	Prec@(1,5) (67.0%, 92.1%)	
11/25 07:46:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][195/195]	Step 7055	lr 0.02192	Loss 1.0904 (1.1599)	Arch Loss 2.3553 (2.1705)	Arch Hard Loss 2.1066 (1.9180)	Arch Beta Loss 248.6436 (252.4850)	Arch depth Loss 0.2449 (0.2317)	Prec@(1,5) (66.2%, 91.6%)	
11/25 07:46:28AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 35/149] Final Prec@1 66.1840%
11/25 07:46:37AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/196]	Step 7056	Loss 1.9311	Prec@(1,5) (48.9%, 79.9%)
11/25 07:46:45AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][195/196]	Step 7056	Loss 1.9327	Prec@(1,5) (49.2%, 79.7%)
11/25 07:46:45AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 49.1920%
11/25 07:46:45AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:46:46AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
11/25 07:47:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][100/195]	Step 7156	lr 0.02175	Loss 1.3458 (1.1166)	Arch Loss 2.0636 (2.1705)	Arch Hard Loss 1.8190 (1.9240)	Arch Beta Loss 244.6632 (246.5328)	Arch depth Loss 0.2600 (0.2529)	Prec@(1,5) (67.5%, 92.3%)	
11/25 07:49:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][195/195]	Step 7251	lr 0.02175	Loss 1.2221 (1.1489)	Arch Loss 2.1230 (2.1621)	Arch Hard Loss 1.8818 (1.9173)	Arch Beta Loss 241.1610 (244.7798)	Arch depth Loss 0.2716 (0.2588)	Prec@(1,5) (66.2%, 91.9%)	
11/25 07:49:07AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 36/149] Final Prec@1 66.1920%
11/25 07:49:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/196]	Step 7252	Loss 1.9342	Prec@(1,5) (49.4%, 79.7%)
11/25 07:49:24AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][195/196]	Step 7252	Loss 1.9544	Prec@(1,5) (48.8%, 79.3%)
11/25 07:49:24AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 48.8280%
11/25 07:49:24AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:49:24AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.1920%
11/25 07:50:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][100/195]	Step 7352	lr 0.02157	Loss 1.1344 (1.0771)	Arch Loss 2.2373 (2.1589)	Arch Hard Loss 1.9998 (1.9197)	Arch Beta Loss 237.4302 (239.2168)	Arch depth Loss 0.2878 (0.2799)	Prec@(1,5) (68.2%, 93.1%)	
11/25 07:51:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][195/195]	Step 7447	lr 0.02157	Loss 1.2348 (1.1102)	Arch Loss 2.1607 (2.1404)	Arch Hard Loss 1.9267 (1.9028)	Arch Beta Loss 234.0243 (237.5285)	Arch depth Loss 0.2985 (0.2866)	Prec@(1,5) (67.4%, 92.4%)	
11/25 07:51:45AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 37/149] Final Prec@1 67.4120%
11/25 07:51:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/196]	Step 7448	Loss 1.9733	Prec@(1,5) (49.7%, 79.0%)
11/25 07:52:02AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][195/196]	Step 7448	Loss 1.9708	Prec@(1,5) (49.3%, 79.1%)
11/25 07:52:03AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 49.2800%
11/25 07:52:03AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:52:03AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.2800%
11/25 07:53:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][100/195]	Step 7548	lr 0.0214	Loss 1.0828 (1.0738)	Arch Loss 2.0205 (2.1379)	Arch Hard Loss 1.7901 (1.9058)	Arch Beta Loss 230.3310 (232.1138)	Arch depth Loss 0.3126 (0.3063)	Prec@(1,5) (68.4%, 92.9%)	
11/25 07:54:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][195/195]	Step 7643	lr 0.0214	Loss 1.0216 (1.1049)	Arch Loss 1.8362 (2.1426)	Arch Hard Loss 1.6089 (1.9121)	Arch Beta Loss 227.3250 (230.5204)	Arch depth Loss 0.3246 (0.3124)	Prec@(1,5) (67.5%, 92.5%)	
11/25 07:54:24AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 38/149] Final Prec@1 67.4520%
11/25 07:54:33AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/196]	Step 7644	Loss 1.9260	Prec@(1,5) (49.7%, 79.7%)
11/25 07:54:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][195/196]	Step 7644	Loss 1.9589	Prec@(1,5) (49.1%, 79.3%)
11/25 07:54:41AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 49.0880%
11/25 07:54:41AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:54:42AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.2800%
11/25 07:55:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][100/195]	Step 7744	lr 0.02121	Loss 0.9717 (1.0384)	Arch Loss 1.8976 (2.1286)	Arch Hard Loss 1.6734 (1.9029)	Arch Beta Loss 224.2097 (225.7294)	Arch depth Loss 0.3355 (0.3296)	Prec@(1,5) (69.6%, 93.6%)	
11/25 07:57:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][195/195]	Step 7839	lr 0.02121	Loss 0.8742 (1.0625)	Arch Loss 2.4793 (2.1147)	Arch Hard Loss 2.2581 (1.8905)	Arch Beta Loss 221.2178 (224.2732)	Arch depth Loss 0.3501 (0.3361)	Prec@(1,5) (69.0%, 93.2%)	
11/25 07:57:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 39/149] Final Prec@1 68.9480%
11/25 07:57:12AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/196]	Step 7840	Loss 1.8821	Prec@(1,5) (50.7%, 80.6%)
11/25 07:57:20AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][195/196]	Step 7840	Loss 1.8885	Prec@(1,5) (50.5%, 80.5%)
11/25 07:57:20AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 50.4720%
11/25 07:57:20AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 07:57:21AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4720%
11/25 07:58:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][100/195]	Step 7940	lr 0.02103	Loss 1.1115 (1.0085)	Arch Loss 2.2447 (2.1229)	Arch Hard Loss 2.0266 (1.9033)	Arch Beta Loss 218.1359 (219.6179)	Arch depth Loss 0.3673 (0.3585)	Prec@(1,5) (70.1%, 93.8%)	
11/25 07:59:41AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][195/195]	Step 8035	lr 0.02103	Loss 1.0501 (1.0575)	Arch Loss 2.4797 (2.1065)	Arch Hard Loss 2.2645 (1.8883)	Arch Beta Loss 215.2063 (218.1525)	Arch depth Loss 0.3771 (0.3652)	Prec@(1,5) (68.8%, 93.1%)	
11/25 07:59:42AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 40/149] Final Prec@1 68.8080%
11/25 07:59:51AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/196]	Step 8036	Loss 1.9521	Prec@(1,5) (50.0%, 79.6%)
11/25 07:59:59AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][195/196]	Step 8036	Loss 1.9638	Prec@(1,5) (49.8%, 79.3%)
11/25 07:59:59AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 49.8120%
11/25 07:59:59AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 08:00:00AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4720%
11/25 08:01:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][100/195]	Step 8136	lr 0.02084	Loss 1.2075 (0.9989)	Arch Loss 2.1341 (2.1046)	Arch Hard Loss 1.9218 (1.8909)	Arch Beta Loss 212.3324 (213.7249)	Arch depth Loss 0.3908 (0.3858)	Prec@(1,5) (70.7%, 94.0%)	
11/25 08:02:20AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][195/195]	Step 8231	lr 0.02084	Loss 1.0382 (1.0339)	Arch Loss 2.1262 (2.0873)	Arch Hard Loss 1.9166 (1.8749)	Arch Beta Loss 209.5895 (212.3864)	Arch depth Loss 0.4022 (0.3906)	Prec@(1,5) (69.4%, 93.5%)	
11/25 08:02:21AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 41/149] Final Prec@1 69.4360%
11/25 08:02:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/196]	Step 8232	Loss 1.9369	Prec@(1,5) (49.8%, 79.8%)
11/25 08:02:38AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][195/196]	Step 8232	Loss 1.9627	Prec@(1,5) (49.4%, 79.4%)
11/25 08:02:38AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 49.3680%
11/25 08:02:38AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/25 08:02:39AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.4720%
11/25 08:03:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][100/195]	Step 8332	lr 0.02065	Loss 0.8573 (0.9860)	Arch Loss 2.2411 (2.0974)	Arch Hard Loss 2.0343 (1.8893)	Arch Beta Loss 206.8333 (208.1325)	Arch depth Loss 0.4175 (0.4104)	Prec@(1,5) (70.5%, 94.0%)	
11/25 08:04:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][195/195]	Step 8427	lr 0.02065	Loss 0.9573 (1.0023)	Arch Loss 2.4547 (2.0932)	Arch Hard Loss 2.2505 (1.8864)	Arch Beta Loss 204.2324 (206.8445)	Arch depth Loss 0.4284 (0.4162)	Prec@(1,5) (70.0%, 93.8%)	
11/25 08:05:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 42/149] Final Prec@1 70.0120%
11/25 08:05:09AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/196]	Step 8428	Loss 1.8871	Prec@(1,5) (51.1%, 80.6%)
11/25 08:05:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][195/196]	Step 8428	Loss 1.8871	Prec@(1,5) (51.1%, 80.5%)
11/25 08:05:17AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 51.0960%
11/25 08:05:17AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:05:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.0960%
11/25 08:06:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][100/195]	Step 8528	lr 0.02045	Loss 0.9619 (0.9439)	Arch Loss 1.8537 (2.0773)	Arch Hard Loss 1.6522 (1.8744)	Arch Beta Loss 201.5132 (202.8686)	Arch depth Loss 0.4405 (0.4355)	Prec@(1,5) (72.2%, 94.3%)	
11/25 08:07:39AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][195/195]	Step 8623	lr 0.02045	Loss 0.9404 (0.9853)	Arch Loss 2.1175 (2.0905)	Arch Hard Loss 1.9184 (1.8889)	Arch Beta Loss 199.1253 (201.6168)	Arch depth Loss 0.4552 (0.4416)	Prec@(1,5) (70.9%, 93.9%)	
11/25 08:07:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 43/149] Final Prec@1 70.8720%
11/25 08:07:48AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/196]	Step 8624	Loss 1.8834	Prec@(1,5) (51.7%, 80.2%)
11/25 08:07:57AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][195/196]	Step 8624	Loss 1.8864	Prec@(1,5) (51.3%, 80.2%)
11/25 08:07:57AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 51.2680%
11/25 08:07:57AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:07:57AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:09:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][100/195]	Step 8724	lr 0.02026	Loss 1.0579 (0.9497)	Arch Loss 2.2994 (2.1055)	Arch Hard Loss 2.1028 (1.9077)	Arch Beta Loss 196.5840 (197.7989)	Arch depth Loss 0.4695 (0.4628)	Prec@(1,5) (71.7%, 94.4%)	
11/25 08:10:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][195/195]	Step 8819	lr 0.02026	Loss 1.0012 (0.9766)	Arch Loss 2.3256 (2.0868)	Arch Hard Loss 2.1314 (1.8902)	Arch Beta Loss 194.1713 (196.5987)	Arch depth Loss 0.4807 (0.4693)	Prec@(1,5) (71.0%, 94.1%)	
11/25 08:10:18AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 44/149] Final Prec@1 71.0200%
11/25 08:10:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/196]	Step 8820	Loss 1.9322	Prec@(1,5) (50.8%, 79.7%)
11/25 08:10:36AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][195/196]	Step 8820	Loss 1.9283	Prec@(1,5) (50.7%, 79.9%)
11/25 08:10:36AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 50.7080%
11/25 08:10:36AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:10:36AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:11:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][100/195]	Step 8920	lr 0.02005	Loss 0.9584 (0.9413)	Arch Loss 2.1639 (2.0953)	Arch Hard Loss 1.9723 (1.9024)	Arch Beta Loss 191.6141 (192.8417)	Arch depth Loss 0.4969 (0.4887)	Prec@(1,5) (72.4%, 94.8%)	
11/25 08:12:56AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][195/195]	Step 9015	lr 0.02005	Loss 0.9943 (0.9604)	Arch Loss 1.7895 (2.0638)	Arch Hard Loss 1.6001 (1.8721)	Arch Beta Loss 189.4175 (191.6871)	Arch depth Loss 0.5061 (0.4947)	Prec@(1,5) (71.7%, 94.6%)	
11/25 08:12:57AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 45/149] Final Prec@1 71.7360%
11/25 08:13:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/196]	Step 9016	Loss 1.8939	Prec@(1,5) (50.9%, 80.5%)
11/25 08:13:14AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][195/196]	Step 9016	Loss 1.9069	Prec@(1,5) (50.4%, 80.6%)
11/25 08:13:14AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 50.3880%
11/25 08:13:14AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:13:15AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:14:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][100/195]	Step 9116	lr 0.01985	Loss 0.7301 (0.9057)	Arch Loss 2.0331 (2.0622)	Arch Hard Loss 1.8460 (1.8739)	Arch Beta Loss 187.0647 (188.2459)	Arch depth Loss 0.5229 (0.5145)	Prec@(1,5) (73.2%, 95.0%)	
11/25 08:15:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][195/195]	Step 9211	lr 0.01985	Loss 1.1288 (0.9434)	Arch Loss 2.2473 (2.0560)	Arch Hard Loss 2.0623 (1.8688)	Arch Beta Loss 185.0005 (187.1686)	Arch depth Loss 0.5362 (0.5221)	Prec@(1,5) (72.1%, 94.5%)	
11/25 08:15:35AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 46/149] Final Prec@1 72.0440%
11/25 08:15:44AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/196]	Step 9212	Loss 1.9505	Prec@(1,5) (50.1%, 79.7%)
11/25 08:15:53AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][195/196]	Step 9212	Loss 1.9370	Prec@(1,5) (50.2%, 79.9%)
11/25 08:15:53AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 50.1360%
11/25 08:15:53AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:15:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:17:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][100/195]	Step 9312	lr 0.01964	Loss 1.1066 (0.8873)	Arch Loss 1.5342 (2.0492)	Arch Hard Loss 1.3514 (1.8653)	Arch Beta Loss 182.7978 (183.8640)	Arch depth Loss 0.5472 (0.5403)	Prec@(1,5) (74.0%, 95.4%)	
11/25 08:18:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][195/195]	Step 9407	lr 0.01964	Loss 1.1612 (0.9260)	Arch Loss 1.9722 (2.0647)	Arch Hard Loss 1.7914 (1.8819)	Arch Beta Loss 180.7429 (182.8373)	Arch depth Loss 0.5613 (0.5477)	Prec@(1,5) (72.7%, 94.9%)	
11/25 08:18:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 47/149] Final Prec@1 72.6920%
11/25 08:18:23AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/196]	Step 9408	Loss 1.9451	Prec@(1,5) (50.4%, 79.6%)
11/25 08:18:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][195/196]	Step 9408	Loss 1.9351	Prec@(1,5) (50.5%, 79.8%)
11/25 08:18:32AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 50.4840%
11/25 08:18:32AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:18:32AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:19:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][100/195]	Step 9508	lr 0.01943	Loss 0.9067 (0.8725)	Arch Loss 1.9455 (2.0403)	Arch Hard Loss 1.7668 (1.8606)	Arch Beta Loss 178.6476 (179.6488)	Arch depth Loss 0.5712 (0.5657)	Prec@(1,5) (74.1%, 95.4%)	
11/25 08:20:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][195/195]	Step 9603	lr 0.01943	Loss 0.9814 (0.9052)	Arch Loss 1.9471 (2.0329)	Arch Hard Loss 1.7704 (1.8542)	Arch Beta Loss 176.7746 (178.6937)	Arch depth Loss 0.5817 (0.5714)	Prec@(1,5) (73.1%, 95.1%)	
11/25 08:20:53AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 48/149] Final Prec@1 73.1280%
11/25 08:21:02AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/196]	Step 9604	Loss 1.9199	Prec@(1,5) (49.9%, 80.2%)
11/25 08:21:10AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][195/196]	Step 9604	Loss 1.9163	Prec@(1,5) (50.5%, 80.3%)
11/25 08:21:10AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 50.5000%
11/25 08:21:10AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:21:11AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:22:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][100/195]	Step 9704	lr 0.01922	Loss 1.1658 (0.8595)	Arch Loss 2.4004 (2.0471)	Arch Hard Loss 2.2255 (1.8713)	Arch Beta Loss 174.8660 (175.7717)	Arch depth Loss 0.5942 (0.5891)	Prec@(1,5) (74.5%, 95.2%)	
11/25 08:23:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][195/195]	Step 9799	lr 0.01922	Loss 1.0040 (0.8949)	Arch Loss 2.2320 (2.0453)	Arch Hard Loss 2.0591 (1.8705)	Arch Beta Loss 172.8932 (174.8323)	Arch depth Loss 0.6051 (0.5945)	Prec@(1,5) (73.5%, 94.9%)	
11/25 08:23:32AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 49/149] Final Prec@1 73.4800%
11/25 08:23:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/196]	Step 9800	Loss 1.9261	Prec@(1,5) (50.5%, 79.9%)
11/25 08:23:49AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][195/196]	Step 9800	Loss 1.9279	Prec@(1,5) (50.6%, 79.9%)
11/25 08:23:49AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 50.6400%
11/25 08:23:49AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/25 08:23:49AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:23:51AM searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
11/25 08:23:51AM searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 1., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
11/25 08:24:21AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][100/351]	Step 9900	lr 0.025	Loss 2.0594 (2.6151)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.3%, 64.8%)	
11/25 08:24:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][200/351]	Step 10000	lr 0.025	Loss 1.9893 (2.3999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.2%, 69.4%)	
11/25 08:25:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][300/351]	Step 10100	lr 0.025	Loss 2.1268 (2.2860)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 71.8%)	
11/25 08:25:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][351/351]	Step 10151	lr 0.025	Loss 1.7983 (2.2372)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 72.9%)	
11/25 08:25:36AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 50/149] Final Prec@1 40.7311%
11/25 08:25:40AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][39/40]	Step 10152	Loss 2.1932	Prec@(1,5) (41.9%, 75.0%)
11/25 08:25:40AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 41.9800%
11/25 08:25:40AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:26:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][100/351]	Step 10252	lr 0.02499	Loss 1.9045 (1.8855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 79.9%)	
11/25 08:26:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][200/351]	Step 10352	lr 0.02499	Loss 1.8962 (1.8749)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.0%)	
11/25 08:27:09AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][300/351]	Step 10452	lr 0.02499	Loss 1.8410 (1.8525)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.4%)	
11/25 08:27:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][351/351]	Step 10503	lr 0.02499	Loss 1.8042 (1.8443)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.6%)	
11/25 08:27:24AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 51/149] Final Prec@1 49.5644%
11/25 08:27:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][39/40]	Step 10504	Loss 2.1238	Prec@(1,5) (44.1%, 75.1%)
11/25 08:27:28AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 44.1400%
11/25 08:27:28AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:27:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][100/351]	Step 10604	lr 0.02498	Loss 1.3866 (1.6998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.1%)	
11/25 08:28:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][200/351]	Step 10704	lr 0.02498	Loss 1.7896 (1.7111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 82.9%)	
11/25 08:28:57AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][300/351]	Step 10804	lr 0.02498	Loss 1.5886 (1.7157)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 82.9%)	
11/25 08:29:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][351/351]	Step 10855	lr 0.02498	Loss 1.5273 (1.7117)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 82.9%)	
11/25 08:29:12AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 52/149] Final Prec@1 52.4911%
11/25 08:29:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][39/40]	Step 10856	Loss 1.9635	Prec@(1,5) (47.6%, 78.6%)
11/25 08:29:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 47.6000%
11/25 08:29:16AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:29:46AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][100/351]	Step 10956	lr 0.02495	Loss 1.5406 (1.5964)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.1%)	
11/25 08:30:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][200/351]	Step 11056	lr 0.02495	Loss 1.7822 (1.6104)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.9%, 84.9%)	
11/25 08:30:44AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][300/351]	Step 11156	lr 0.02495	Loss 1.5853 (1.6099)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 84.8%)	
11/25 08:30:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][351/351]	Step 11207	lr 0.02495	Loss 1.6884 (1.6186)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.6%)	
11/25 08:31:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 53/149] Final Prec@1 54.8422%
11/25 08:31:04AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][39/40]	Step 11208	Loss 2.0576	Prec@(1,5) (45.4%, 77.0%)
11/25 08:31:04AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 45.3400%
11/25 08:31:04AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:31:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][100/351]	Step 11308	lr 0.02491	Loss 1.5346 (1.5079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.3%)	
11/25 08:32:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][200/351]	Step 11408	lr 0.02491	Loss 1.3775 (1.5305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 85.9%)	
11/25 08:32:32AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][300/351]	Step 11508	lr 0.02491	Loss 1.7704 (1.5469)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.5%)	
11/25 08:32:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][351/351]	Step 11559	lr 0.02491	Loss 1.4874 (1.5506)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.5%)	
11/25 08:32:47AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 54/149] Final Prec@1 56.4400%
11/25 08:32:51AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][39/40]	Step 11560	Loss 1.8734	Prec@(1,5) (49.9%, 80.0%)
11/25 08:32:51AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 49.8400%
11/25 08:32:51AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:33:22AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][100/351]	Step 11660	lr 0.02485	Loss 1.5337 (1.4599)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.3%, 86.8%)	
11/25 08:33:51AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][200/351]	Step 11760	lr 0.02485	Loss 1.6441 (1.4808)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 86.4%)	
11/25 08:34:20AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][300/351]	Step 11860	lr 0.02485	Loss 1.3827 (1.4993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.2%)	
11/25 08:34:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][351/351]	Step 11911	lr 0.02485	Loss 1.4368 (1.5056)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.1%)	
11/25 08:34:35AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 55/149] Final Prec@1 57.6311%
11/25 08:34:39AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][39/40]	Step 11912	Loss 1.8233	Prec@(1,5) (50.9%, 81.3%)
11/25 08:34:39AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 50.8800%
11/25 08:34:39AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:35:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][100/351]	Step 12012	lr 0.02479	Loss 1.5003 (1.4170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 87.4%)	
11/25 08:35:39AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][200/351]	Step 12112	lr 0.02479	Loss 1.4833 (1.4270)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.8%, 87.3%)	
11/25 08:36:08AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][300/351]	Step 12212	lr 0.02479	Loss 1.2337 (1.4426)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.1%)	
11/25 08:36:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][351/351]	Step 12263	lr 0.02479	Loss 1.5115 (1.4482)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.0%)	
11/25 08:36:23AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 56/149] Final Prec@1 59.1733%
11/25 08:36:27AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][39/40]	Step 12264	Loss 1.8849	Prec@(1,5) (49.7%, 80.0%)
11/25 08:36:27AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 49.7000%
11/25 08:36:27AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.2680%
11/25 08:36:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][100/351]	Step 12364	lr 0.02471	Loss 1.3820 (1.3798)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.2%)	
11/25 08:37:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][200/351]	Step 12464	lr 0.02471	Loss 1.3715 (1.3919)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 87.8%)	
11/25 08:37:56AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][300/351]	Step 12564	lr 0.02471	Loss 1.2147 (1.4017)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.7%)	
11/25 08:38:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][351/351]	Step 12615	lr 0.02471	Loss 1.5179 (1.4084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 87.6%)	
11/25 08:38:12AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 57/149] Final Prec@1 59.9000%
11/25 08:38:15AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][39/40]	Step 12616	Loss 1.7411	Prec@(1,5) (52.2%, 82.4%)
11/25 08:38:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 52.1600%
11/25 08:38:16AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.1600%
11/25 08:38:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][100/351]	Step 12716	lr 0.02462	Loss 1.1711 (1.3024)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.3%)	
11/25 08:39:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][200/351]	Step 12816	lr 0.02462	Loss 1.5692 (1.3386)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.7%)	
11/25 08:39:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][300/351]	Step 12916	lr 0.02462	Loss 1.5539 (1.3540)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.5%)	
11/25 08:40:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][351/351]	Step 12967	lr 0.02462	Loss 1.3235 (1.3636)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.4%)	
11/25 08:40:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 58/149] Final Prec@1 61.2756%
11/25 08:40:04AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][39/40]	Step 12968	Loss 1.8300	Prec@(1,5) (50.4%, 80.9%)
11/25 08:40:04AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 50.4400%
11/25 08:40:04AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.1600%
11/25 08:40:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][100/351]	Step 13068	lr 0.02452	Loss 1.2896 (1.2868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.4%)	
11/25 08:41:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][200/351]	Step 13168	lr 0.02452	Loss 1.6939 (1.3207)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 88.9%)	
11/25 08:41:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][300/351]	Step 13268	lr 0.02452	Loss 1.7017 (1.3441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.6%)	
11/25 08:41:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][351/351]	Step 13319	lr 0.02452	Loss 1.3839 (1.3435)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.5%)	
11/25 08:41:48AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 59/149] Final Prec@1 61.4978%
11/25 08:41:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][39/40]	Step 13320	Loss 1.7582	Prec@(1,5) (53.2%, 82.5%)
11/25 08:41:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 53.2600%
11/25 08:41:52AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.2600%
11/25 08:42:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][100/351]	Step 13420	lr 0.02441	Loss 1.1514 (1.2702)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.5%)	
11/25 08:42:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][200/351]	Step 13520	lr 0.02441	Loss 1.0867 (1.2797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.6%)	
11/25 08:43:21AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][300/351]	Step 13620	lr 0.02441	Loss 1.2309 (1.2950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.4%)	
11/25 08:43:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][351/351]	Step 13671	lr 0.02441	Loss 1.3987 (1.3074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.2%)	
11/25 08:43:36AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 60/149] Final Prec@1 62.4689%
11/25 08:43:40AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][39/40]	Step 13672	Loss 1.7362	Prec@(1,5) (52.6%, 82.6%)
11/25 08:43:40AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 52.6000%
11/25 08:43:40AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.2600%
11/25 08:44:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][100/351]	Step 13772	lr 0.02429	Loss 1.3421 (1.2470)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.1%)	
11/25 08:44:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][200/351]	Step 13872	lr 0.02429	Loss 1.5056 (1.2472)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
11/25 08:45:09AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][300/351]	Step 13972	lr 0.02429	Loss 1.4405 (1.2617)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.8%)	
11/25 08:45:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][351/351]	Step 14023	lr 0.02429	Loss 1.2593 (1.2708)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.7%)	
11/25 08:45:24AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 61/149] Final Prec@1 63.1422%
11/25 08:45:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][39/40]	Step 14024	Loss 1.8458	Prec@(1,5) (50.6%, 81.3%)
11/25 08:45:28AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 50.5600%
11/25 08:45:28AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.2600%
11/25 08:45:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][100/351]	Step 14124	lr 0.02416	Loss 1.4150 (1.2293)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.0%)	
11/25 08:46:28AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][200/351]	Step 14224	lr 0.02416	Loss 1.2872 (1.2407)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.0%)	
11/25 08:46:57AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][300/351]	Step 14324	lr 0.02416	Loss 1.3372 (1.2582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.6%, 89.7%)	
11/25 08:47:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][351/351]	Step 14375	lr 0.02416	Loss 0.9442 (1.2571)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.8%, 89.8%)	
11/25 08:47:12AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 62/149] Final Prec@1 63.7800%
11/25 08:47:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][39/40]	Step 14376	Loss 1.8575	Prec@(1,5) (50.7%, 81.2%)
11/25 08:47:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 50.6800%
11/25 08:47:16AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.2600%
11/25 08:47:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][100/351]	Step 14476	lr 0.02401	Loss 0.9013 (1.1753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.1%)	
11/25 08:48:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][200/351]	Step 14576	lr 0.02401	Loss 1.1181 (1.1988)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 90.8%)	
11/25 08:48:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][300/351]	Step 14676	lr 0.02401	Loss 1.2316 (1.2145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.5%)	
11/25 08:49:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][351/351]	Step 14727	lr 0.02401	Loss 1.3464 (1.2225)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
11/25 08:49:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 63/149] Final Prec@1 64.6422%
11/25 08:49:04AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][39/40]	Step 14728	Loss 1.6922	Prec@(1,5) (53.8%, 83.2%)
11/25 08:49:04AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 53.8200%
11/25 08:49:05AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.8200%
11/25 08:49:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][100/351]	Step 14828	lr 0.02386	Loss 1.2466 (1.1694)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.4%)	
11/25 08:50:04AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][200/351]	Step 14928	lr 0.02386	Loss 1.4801 (1.1962)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.8%)	
11/25 08:50:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][300/351]	Step 15028	lr 0.02386	Loss 1.2010 (1.2007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.7%)	
11/25 08:50:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][351/351]	Step 15079	lr 0.02386	Loss 1.2686 (1.2047)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.6%)	
11/25 08:50:48AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 64/149] Final Prec@1 65.0889%
11/25 08:50:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][39/40]	Step 15080	Loss 1.7073	Prec@(1,5) (54.0%, 82.9%)
11/25 08:50:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 54.0200%
11/25 08:50:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0200%
11/25 08:51:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][100/351]	Step 15180	lr 0.02369	Loss 1.1229 (1.1208)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.7%)	
11/25 08:51:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][200/351]	Step 15280	lr 0.02369	Loss 1.0741 (1.1536)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.3%)	
11/25 08:52:22AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][300/351]	Step 15380	lr 0.02369	Loss 1.1334 (1.1662)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.1%)	
11/25 08:52:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][351/351]	Step 15431	lr 0.02369	Loss 1.3154 (1.1696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.1%)	
11/25 08:52:37AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 65/149] Final Prec@1 65.9778%
11/25 08:52:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][39/40]	Step 15432	Loss 1.8495	Prec@(1,5) (52.1%, 81.5%)
11/25 08:52:41AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 52.0400%
11/25 08:52:41AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0200%
11/25 08:53:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][100/351]	Step 15532	lr 0.02352	Loss 1.1954 (1.1394)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.5%)	
11/25 08:53:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][200/351]	Step 15632	lr 0.02352	Loss 1.3542 (1.1409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.4%)	
11/25 08:54:09AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][300/351]	Step 15732	lr 0.02352	Loss 0.9451 (1.1570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.2%)	
11/25 08:54:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][351/351]	Step 15783	lr 0.02352	Loss 0.9285 (1.1579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.2%)	
11/25 08:54:25AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 66/149] Final Prec@1 66.2644%
11/25 08:54:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][39/40]	Step 15784	Loss 1.6556	Prec@(1,5) (55.3%, 83.8%)
11/25 08:54:29AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 55.3200%
11/25 08:54:29AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 08:55:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][100/351]	Step 15884	lr 0.02333	Loss 1.0626 (1.0901)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.1%)	
11/25 08:55:29AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][200/351]	Step 15984	lr 0.02333	Loss 1.0584 (1.1084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.9%)	
11/25 08:55:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][300/351]	Step 16084	lr 0.02333	Loss 1.1201 (1.1205)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.7%)	
11/25 08:56:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][351/351]	Step 16135	lr 0.02333	Loss 0.9408 (1.1295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.6%)	
11/25 08:56:13AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 67/149] Final Prec@1 66.9178%
11/25 08:56:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][39/40]	Step 16136	Loss 1.8048	Prec@(1,5) (52.6%, 83.3%)
11/25 08:56:17AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 52.6000%
11/25 08:56:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 08:56:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][100/351]	Step 16236	lr 0.02313	Loss 1.2868 (1.0502)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.7%)	
11/25 08:57:17AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][200/351]	Step 16336	lr 0.02313	Loss 1.2446 (1.0762)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.3%)	
11/25 08:57:46AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][300/351]	Step 16436	lr 0.02313	Loss 1.1553 (1.0957)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.1%)	
11/25 08:58:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][351/351]	Step 16487	lr 0.02313	Loss 1.0088 (1.1071)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.9%)	
11/25 08:58:01AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 68/149] Final Prec@1 67.5333%
11/25 08:58:05AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][39/40]	Step 16488	Loss 1.7145	Prec@(1,5) (54.2%, 83.7%)
11/25 08:58:05AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 54.2200%
11/25 08:58:05AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 08:58:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][100/351]	Step 16588	lr 0.02292	Loss 0.9931 (1.0661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.6%)	
11/25 08:59:05AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][200/351]	Step 16688	lr 0.02292	Loss 1.0856 (1.0673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.4%)	
11/25 08:59:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][300/351]	Step 16788	lr 0.02292	Loss 1.0739 (1.0759)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.3%)	
11/25 08:59:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][351/351]	Step 16839	lr 0.02292	Loss 1.0567 (1.0837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.2%)	
11/25 08:59:49AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 69/149] Final Prec@1 68.0956%
11/25 08:59:53AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][39/40]	Step 16840	Loss 1.6953	Prec@(1,5) (54.9%, 83.4%)
11/25 08:59:53AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 54.8800%
11/25 08:59:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 09:00:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][100/351]	Step 16940	lr 0.02271	Loss 1.1776 (1.0186)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.1%)	
11/25 09:00:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][200/351]	Step 17040	lr 0.02271	Loss 1.1216 (1.0431)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.8%)	
11/25 09:01:21AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][300/351]	Step 17140	lr 0.02271	Loss 1.2233 (1.0564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.6%)	
11/25 09:01:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][351/351]	Step 17191	lr 0.02271	Loss 1.2422 (1.0654)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.5%)	
11/25 09:01:37AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 70/149] Final Prec@1 68.3356%
11/25 09:01:40AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][39/40]	Step 17192	Loss 1.6726	Prec@(1,5) (55.3%, 84.7%)
11/25 09:01:41AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 55.2800%
11/25 09:01:41AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 09:02:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][100/351]	Step 17292	lr 0.02248	Loss 1.0229 (1.0029)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.3%)	
11/25 09:02:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][200/351]	Step 17392	lr 0.02248	Loss 1.1564 (1.0294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.0%)	
11/25 09:03:09AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][300/351]	Step 17492	lr 0.02248	Loss 1.0991 (1.0516)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 92.7%)	
11/25 09:03:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][351/351]	Step 17543	lr 0.02248	Loss 1.1487 (1.0577)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.7%)	
11/25 09:03:25AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 71/149] Final Prec@1 69.0156%
11/25 09:03:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][39/40]	Step 17544	Loss 1.7628	Prec@(1,5) (54.8%, 82.9%)
11/25 09:03:29AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 54.8400%
11/25 09:03:29AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 09:03:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][100/351]	Step 17644	lr 0.02225	Loss 1.2622 (0.9845)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.6%)	
11/25 09:04:28AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][200/351]	Step 17744	lr 0.02225	Loss 0.9896 (1.0002)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.3%)	
11/25 09:04:57AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][300/351]	Step 17844	lr 0.02225	Loss 1.1358 (1.0141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
11/25 09:05:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][351/351]	Step 17895	lr 0.02225	Loss 1.1281 (1.0244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
11/25 09:05:12AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 72/149] Final Prec@1 69.6089%
11/25 09:05:16AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][39/40]	Step 17896	Loss 1.7206	Prec@(1,5) (54.9%, 84.3%)
11/25 09:05:16AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 54.8600%
11/25 09:05:16AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 09:05:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][100/351]	Step 17996	lr 0.022	Loss 0.9461 (0.9969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.1%)	
11/25 09:06:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][200/351]	Step 18096	lr 0.022	Loss 1.1492 (1.0045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.1%)	
11/25 09:06:45AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][300/351]	Step 18196	lr 0.022	Loss 1.3271 (1.0182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.0%)	
11/25 09:07:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][351/351]	Step 18247	lr 0.022	Loss 1.0122 (1.0245)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 92.9%)	
11/25 09:07:00AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 73/149] Final Prec@1 69.6133%
11/25 09:07:04AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][39/40]	Step 18248	Loss 1.7759	Prec@(1,5) (53.6%, 83.6%)
11/25 09:07:04AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 53.5600%
11/25 09:07:04AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 09:07:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][100/351]	Step 18348	lr 0.02175	Loss 0.8346 (0.9532)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.0%)	
11/25 09:08:04AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][200/351]	Step 18448	lr 0.02175	Loss 0.9207 (0.9847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.6%)	
11/25 09:08:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][300/351]	Step 18548	lr 0.02175	Loss 1.0423 (0.9909)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.5%)	
11/25 09:08:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][351/351]	Step 18599	lr 0.02175	Loss 0.9294 (1.0054)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.3%)	
11/25 09:08:48AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 74/149] Final Prec@1 70.3289%
11/25 09:08:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][39/40]	Step 18600	Loss 1.7583	Prec@(1,5) (53.1%, 82.5%)
11/25 09:08:52AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 53.1200%
11/25 09:08:52AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.3200%
11/25 09:09:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][100/351]	Step 18700	lr 0.02149	Loss 1.0550 (0.9260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
11/25 09:09:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][200/351]	Step 18800	lr 0.02149	Loss 1.1071 (0.9618)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.8%)	
11/25 09:10:21AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][300/351]	Step 18900	lr 0.02149	Loss 1.0302 (0.9800)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.5%)	
11/25 09:10:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][351/351]	Step 18951	lr 0.02149	Loss 1.1437 (0.9850)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.5%)	
11/25 09:10:36AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 75/149] Final Prec@1 70.7267%
11/25 09:10:40AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][39/40]	Step 18952	Loss 1.6644	Prec@(1,5) (55.6%, 84.8%)
11/25 09:10:40AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 55.5800%
11/25 09:10:41AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.5800%
11/25 09:11:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][100/351]	Step 19052	lr 0.02121	Loss 1.0697 (0.9062)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.4%)	
11/25 09:11:40AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][200/351]	Step 19152	lr 0.02121	Loss 0.9567 (0.9249)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.3%)	
11/25 09:12:09AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][300/351]	Step 19252	lr 0.02121	Loss 0.8646 (0.9480)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.0%)	
11/25 09:12:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][351/351]	Step 19303	lr 0.02121	Loss 0.9922 (0.9547)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.9%)	
11/25 09:12:24AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 76/149] Final Prec@1 71.4600%
11/25 09:12:28AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][39/40]	Step 19304	Loss 1.6619	Prec@(1,5) (56.6%, 84.3%)
11/25 09:12:28AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 56.6200%
11/25 09:12:29AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6200%
11/25 09:12:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][100/351]	Step 19404	lr 0.02094	Loss 0.9160 (0.8810)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.7%)	
11/25 09:13:29AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][200/351]	Step 19504	lr 0.02094	Loss 0.8463 (0.9134)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.2%)	
11/25 09:13:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][300/351]	Step 19604	lr 0.02094	Loss 1.1581 (0.9353)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.1%)	
11/25 09:14:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][351/351]	Step 19655	lr 0.02094	Loss 1.0118 (0.9411)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.0%)	
11/25 09:14:13AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 77/149] Final Prec@1 71.8222%
11/25 09:14:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][39/40]	Step 19656	Loss 1.6482	Prec@(1,5) (56.4%, 84.8%)
11/25 09:14:17AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 56.4200%
11/25 09:14:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6200%
11/25 09:14:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][100/351]	Step 19756	lr 0.02065	Loss 0.7914 (0.8786)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 95.0%)	
11/25 09:15:16AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][200/351]	Step 19856	lr 0.02065	Loss 0.9285 (0.8930)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.8%)	
11/25 09:15:46AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][300/351]	Step 19956	lr 0.02065	Loss 0.8674 (0.9214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.5%)	
11/25 09:16:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][351/351]	Step 20007	lr 0.02065	Loss 1.0668 (0.9317)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.3%)	
11/25 09:16:01AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 78/149] Final Prec@1 72.0689%
11/25 09:16:05AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][39/40]	Step 20008	Loss 1.8033	Prec@(1,5) (53.9%, 83.6%)
11/25 09:16:05AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 53.9200%
11/25 09:16:05AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6200%
11/25 09:16:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][100/351]	Step 20108	lr 0.02035	Loss 1.0260 (0.8664)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.9%)	
11/25 09:17:04AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][200/351]	Step 20208	lr 0.02035	Loss 1.0788 (0.8808)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.8%)	
11/25 09:17:33AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][300/351]	Step 20308	lr 0.02035	Loss 1.0767 (0.9032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.6%)	
11/25 09:17:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][351/351]	Step 20359	lr 0.02035	Loss 0.9846 (0.9135)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.5%)	
11/25 09:17:49AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 79/149] Final Prec@1 72.3711%
11/25 09:17:52AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][39/40]	Step 20360	Loss 1.7587	Prec@(1,5) (54.9%, 84.1%)
11/25 09:17:53AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 54.8800%
11/25 09:17:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6200%
11/25 09:18:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][100/351]	Step 20460	lr 0.02005	Loss 1.1262 (0.8391)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.1%)	
11/25 09:18:52AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][200/351]	Step 20560	lr 0.02005	Loss 0.9050 (0.8674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.7%)	
11/25 09:19:22AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][300/351]	Step 20660	lr 0.02005	Loss 1.0844 (0.8847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
11/25 09:19:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][351/351]	Step 20711	lr 0.02005	Loss 0.9807 (0.8942)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.5%)	
11/25 09:19:37AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 80/149] Final Prec@1 72.9800%
11/25 09:19:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][39/40]	Step 20712	Loss 1.5923	Prec@(1,5) (58.2%, 85.7%)
11/25 09:19:41AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 58.1600%
11/25 09:19:41AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/25 09:20:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][100/351]	Step 20812	lr 0.01975	Loss 0.9450 (0.8299)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.4%)	
11/25 09:20:41AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][200/351]	Step 20912	lr 0.01975	Loss 0.7723 (0.8615)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
11/25 09:21:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][300/351]	Step 21012	lr 0.01975	Loss 0.9329 (0.8756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.7%)	
11/25 09:21:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][351/351]	Step 21063	lr 0.01975	Loss 0.9109 (0.8838)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.7%)	
11/25 09:21:25AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 81/149] Final Prec@1 73.5822%
11/25 09:21:29AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][39/40]	Step 21064	Loss 1.6297	Prec@(1,5) (56.9%, 84.8%)
11/25 09:21:29AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 56.9200%
11/25 09:21:29AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/25 09:22:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][100/351]	Step 21164	lr 0.01943	Loss 0.7928 (0.8162)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.3%)	
11/25 09:22:29AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][200/351]	Step 21264	lr 0.01943	Loss 0.8233 (0.8436)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.1%)	
11/25 09:22:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][300/351]	Step 21364	lr 0.01943	Loss 0.9313 (0.8612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.8%)	
11/25 09:23:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][351/351]	Step 21415	lr 0.01943	Loss 0.9844 (0.8691)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
11/25 09:23:13AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 82/149] Final Prec@1 73.8578%
11/25 09:23:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][39/40]	Step 21416	Loss 1.7178	Prec@(1,5) (56.0%, 84.5%)
11/25 09:23:17AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 56.0200%
11/25 09:23:17AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/25 09:23:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][100/351]	Step 21516	lr 0.01911	Loss 0.8595 (0.7900)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.8%)	
11/25 09:24:17AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][200/351]	Step 21616	lr 0.01911	Loss 0.7838 (0.8170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.5%)	
11/25 09:24:46AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][300/351]	Step 21716	lr 0.01911	Loss 0.8871 (0.8371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.3%)	
11/25 09:25:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][351/351]	Step 21767	lr 0.01911	Loss 0.8094 (0.8479)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.2%)	
11/25 09:25:01AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 83/149] Final Prec@1 74.1067%
11/25 09:25:05AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][39/40]	Step 21768	Loss 1.7427	Prec@(1,5) (55.6%, 84.4%)
11/25 09:25:05AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 55.6600%
11/25 09:25:05AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/25 09:25:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][100/351]	Step 21868	lr 0.01878	Loss 0.6971 (0.7816)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.9%)	
11/25 09:26:05AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][200/351]	Step 21968	lr 0.01878	Loss 0.8779 (0.8032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.5%)	
11/25 09:26:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][300/351]	Step 22068	lr 0.01878	Loss 0.9310 (0.8275)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
11/25 09:26:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][351/351]	Step 22119	lr 0.01878	Loss 0.7419 (0.8375)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.2%)	
11/25 09:26:49AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 84/149] Final Prec@1 74.6200%
11/25 09:26:53AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][39/40]	Step 22120	Loss 1.6227	Prec@(1,5) (56.2%, 85.3%)
11/25 09:26:53AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 56.2200%
11/25 09:26:53AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/25 09:27:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][100/351]	Step 22220	lr 0.01845	Loss 0.8343 (0.7808)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.7%)	
11/25 09:27:53AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][200/351]	Step 22320	lr 0.01845	Loss 0.8783 (0.7894)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.6%)	
11/25 09:28:22AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][300/351]	Step 22420	lr 0.01845	Loss 1.1424 (0.8114)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.4%)	
11/25 09:28:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][351/351]	Step 22471	lr 0.01845	Loss 0.8940 (0.8248)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.3%)	
11/25 09:28:37AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 85/149] Final Prec@1 74.8222%
11/25 09:28:41AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][39/40]	Step 22472	Loss 1.6281	Prec@(1,5) (57.6%, 85.0%)
11/25 09:28:41AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 57.6400%
11/25 09:28:41AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.1600%
11/25 09:29:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][100/351]	Step 22572	lr 0.01811	Loss 0.6854 (0.7512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.2%)	
11/25 09:29:41AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][200/351]	Step 22672	lr 0.01811	Loss 0.8217 (0.7757)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
11/25 09:30:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][300/351]	Step 22772	lr 0.01811	Loss 0.9079 (0.7906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.8%)	
11/25 09:30:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][351/351]	Step 22823	lr 0.01811	Loss 0.9622 (0.7998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.6%)	
11/25 09:30:25AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 86/149] Final Prec@1 75.6400%
11/25 09:30:29AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][39/40]	Step 22824	Loss 1.5904	Prec@(1,5) (58.6%, 85.6%)
11/25 09:30:29AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 58.6000%
11/25 09:30:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6000%
11/25 09:31:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][100/351]	Step 22924	lr 0.01777	Loss 0.7108 (0.7494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.4%)	
11/25 09:31:29AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][200/351]	Step 23024	lr 0.01777	Loss 0.7054 (0.7644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.1%)	
11/25 09:31:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][300/351]	Step 23124	lr 0.01777	Loss 0.6225 (0.7748)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.0%)	
11/25 09:32:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][351/351]	Step 23175	lr 0.01777	Loss 0.8238 (0.7811)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.8%)	
11/25 09:32:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 87/149] Final Prec@1 76.2200%
11/25 09:32:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][39/40]	Step 23176	Loss 1.7067	Prec@(1,5) (56.8%, 85.0%)
11/25 09:32:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 56.8000%
11/25 09:32:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6000%
11/25 09:32:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][100/351]	Step 23276	lr 0.01742	Loss 0.5885 (0.7063)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/25 09:33:17AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][200/351]	Step 23376	lr 0.01742	Loss 0.6969 (0.7358)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.4%)	
11/25 09:33:46AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][300/351]	Step 23476	lr 0.01742	Loss 0.8401 (0.7572)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
11/25 09:34:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][351/351]	Step 23527	lr 0.01742	Loss 0.7091 (0.7651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.1%)	
11/25 09:34:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 88/149] Final Prec@1 76.6333%
11/25 09:34:05AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][39/40]	Step 23528	Loss 1.6285	Prec@(1,5) (57.6%, 85.6%)
11/25 09:34:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 57.5600%
11/25 09:34:06AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6000%
11/25 09:34:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][100/351]	Step 23628	lr 0.01706	Loss 0.7710 (0.7155)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.7%)	
11/25 09:35:05AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][200/351]	Step 23728	lr 0.01706	Loss 0.8545 (0.7383)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.4%)	
11/25 09:35:34AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][300/351]	Step 23828	lr 0.01706	Loss 0.6346 (0.7581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.1%)	
11/25 09:35:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][351/351]	Step 23879	lr 0.01706	Loss 0.7155 (0.7659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 96.1%)	
11/25 09:35:50AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 89/149] Final Prec@1 76.4333%
11/25 09:35:53AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][39/40]	Step 23880	Loss 1.7109	Prec@(1,5) (56.0%, 84.7%)
11/25 09:35:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 56.0400%
11/25 09:35:54AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6000%
11/25 09:36:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][100/351]	Step 23980	lr 0.01671	Loss 0.6042 (0.6727)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
11/25 09:36:53AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][200/351]	Step 24080	lr 0.01671	Loss 0.6659 (0.7083)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.6%)	
11/25 09:37:22AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][300/351]	Step 24180	lr 0.01671	Loss 0.8528 (0.7325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.4%)	
11/25 09:37:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][351/351]	Step 24231	lr 0.01671	Loss 0.8184 (0.7452)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.2%)	
11/25 09:37:38AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 90/149] Final Prec@1 77.1511%
11/25 09:37:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][39/40]	Step 24232	Loss 1.6986	Prec@(1,5) (57.2%, 85.0%)
11/25 09:37:42AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 57.1600%
11/25 09:37:42AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6000%
11/25 09:38:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][100/351]	Step 24332	lr 0.01635	Loss 0.8963 (0.6776)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.9%)	
11/25 09:38:41AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][200/351]	Step 24432	lr 0.01635	Loss 0.7176 (0.7063)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
11/25 09:39:10AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][300/351]	Step 24532	lr 0.01635	Loss 0.7926 (0.7170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.6%)	
11/25 09:39:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][351/351]	Step 24583	lr 0.01635	Loss 0.7474 (0.7238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.4%)	
11/25 09:39:26AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 91/149] Final Prec@1 77.9556%
11/25 09:39:29AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][39/40]	Step 24584	Loss 1.6739	Prec@(1,5) (56.8%, 84.6%)
11/25 09:39:30AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 56.7800%
11/25 09:39:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6000%
11/25 09:40:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][100/351]	Step 24684	lr 0.01598	Loss 0.8278 (0.6620)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 97.1%)	
11/25 09:40:29AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][200/351]	Step 24784	lr 0.01598	Loss 0.7416 (0.6873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
11/25 09:40:58AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][300/351]	Step 24884	lr 0.01598	Loss 0.7114 (0.7044)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.6%)	
11/25 09:41:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][351/351]	Step 24935	lr 0.01598	Loss 0.8542 (0.7127)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.5%)	
11/25 09:41:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 92/149] Final Prec@1 78.0911%
11/25 09:41:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][39/40]	Step 24936	Loss 1.5130	Prec@(1,5) (60.2%, 87.1%)
11/25 09:41:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 60.1600%
11/25 09:41:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.1600%
11/25 09:41:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][100/351]	Step 25036	lr 0.01562	Loss 0.5499 (0.6483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
11/25 09:42:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][200/351]	Step 25136	lr 0.01562	Loss 0.6208 (0.6633)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.0%)	
11/25 09:42:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][300/351]	Step 25236	lr 0.01562	Loss 0.7599 (0.6823)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.8%)	
11/25 09:43:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][351/351]	Step 25287	lr 0.01562	Loss 0.9566 (0.6915)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.8%)	
11/25 09:43:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 93/149] Final Prec@1 78.7044%
11/25 09:43:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][39/40]	Step 25288	Loss 1.6344	Prec@(1,5) (58.9%, 86.1%)
11/25 09:43:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 58.9400%
11/25 09:43:06AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.1600%
11/25 09:43:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][100/351]	Step 25388	lr 0.01525	Loss 0.7081 (0.6248)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
11/25 09:44:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][200/351]	Step 25488	lr 0.01525	Loss 0.6206 (0.6511)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
11/25 09:44:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][300/351]	Step 25588	lr 0.01525	Loss 0.5001 (0.6630)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
11/25 09:44:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][351/351]	Step 25639	lr 0.01525	Loss 0.7283 (0.6730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
11/25 09:44:50AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 94/149] Final Prec@1 79.4200%
11/25 09:44:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][39/40]	Step 25640	Loss 1.6183	Prec@(1,5) (58.4%, 86.1%)
11/25 09:44:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 58.3800%
11/25 09:44:54AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.1600%
11/25 09:45:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][100/351]	Step 25740	lr 0.01488	Loss 0.5407 (0.6009)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.5%)	
11/25 09:45:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][200/351]	Step 25840	lr 0.01488	Loss 0.5909 (0.6279)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.3%)	
11/25 09:46:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][300/351]	Step 25940	lr 0.01488	Loss 0.7703 (0.6513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.1%)	
11/25 09:46:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][351/351]	Step 25991	lr 0.01488	Loss 0.6575 (0.6569)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
11/25 09:46:38AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 95/149] Final Prec@1 79.7311%
11/25 09:46:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][39/40]	Step 25992	Loss 1.6446	Prec@(1,5) (58.8%, 86.0%)
11/25 09:46:42AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 58.8200%
11/25 09:46:42AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.1600%
11/25 09:47:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][100/351]	Step 26092	lr 0.0145	Loss 0.7831 (0.6235)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
11/25 09:47:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][200/351]	Step 26192	lr 0.0145	Loss 0.6774 (0.6225)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
11/25 09:48:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][300/351]	Step 26292	lr 0.0145	Loss 0.7926 (0.6324)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.3%)	
11/25 09:48:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][351/351]	Step 26343	lr 0.0145	Loss 0.7331 (0.6392)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.2%)	
11/25 09:48:26AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 96/149] Final Prec@1 80.2711%
11/25 09:48:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][39/40]	Step 26344	Loss 1.6253	Prec@(1,5) (59.7%, 86.3%)
11/25 09:48:30AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 59.6800%
11/25 09:48:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.1600%
11/25 09:49:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][100/351]	Step 26444	lr 0.01413	Loss 0.5830 (0.5706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.9%)	
11/25 09:49:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][200/351]	Step 26544	lr 0.01413	Loss 0.8385 (0.6051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.6%)	
11/25 09:49:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][300/351]	Step 26644	lr 0.01413	Loss 0.6197 (0.6221)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.4%)	
11/25 09:50:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][351/351]	Step 26695	lr 0.01413	Loss 0.6704 (0.6279)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.3%)	
11/25 09:50:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 97/149] Final Prec@1 80.3156%
11/25 09:50:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][39/40]	Step 26696	Loss 1.6353	Prec@(1,5) (59.7%, 86.5%)
11/25 09:50:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 59.6200%
11/25 09:50:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.1600%
11/25 09:50:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][100/351]	Step 26796	lr 0.01375	Loss 0.5422 (0.5819)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.9%)	
11/25 09:51:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][200/351]	Step 26896	lr 0.01375	Loss 0.7576 (0.5893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.8%)	
11/25 09:51:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][300/351]	Step 26996	lr 0.01375	Loss 0.6292 (0.6023)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.6%)	
11/25 09:52:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][351/351]	Step 27047	lr 0.01375	Loss 0.7283 (0.6080)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.5%)	
11/25 09:52:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 98/149] Final Prec@1 81.0378%
11/25 09:52:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][39/40]	Step 27048	Loss 1.5619	Prec@(1,5) (60.8%, 87.1%)
11/25 09:52:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 60.7200%
11/25 09:52:06AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 09:52:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][100/351]	Step 27148	lr 0.01338	Loss 0.5042 (0.5300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.2%)	
11/25 09:53:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][200/351]	Step 27248	lr 0.01338	Loss 0.6621 (0.5507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 98.1%)	
11/25 09:53:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][300/351]	Step 27348	lr 0.01338	Loss 0.6931 (0.5737)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.8%)	
11/25 09:53:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][351/351]	Step 27399	lr 0.01338	Loss 0.6853 (0.5838)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.7%)	
11/25 09:53:50AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 99/149] Final Prec@1 81.8933%
11/25 09:53:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][39/40]	Step 27400	Loss 1.7078	Prec@(1,5) (57.2%, 85.8%)
11/25 09:53:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 57.2400%
11/25 09:53:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 09:54:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][100/351]	Step 27500	lr 0.013	Loss 0.5223 (0.5492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 98.1%)	
11/25 09:54:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][200/351]	Step 27600	lr 0.013	Loss 0.6194 (0.5562)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 98.0%)	
11/25 09:55:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][300/351]	Step 27700	lr 0.013	Loss 0.5774 (0.5686)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.9%)	
11/25 09:55:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][351/351]	Step 27751	lr 0.013	Loss 0.5056 (0.5751)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.8%)	
11/25 09:55:38AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [100/149] Final Prec@1 81.9800%
11/25 09:55:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][39/40]	Step 27752	Loss 1.6063	Prec@(1,5) (60.2%, 86.9%)
11/25 09:55:42AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 60.2000%
11/25 09:55:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 09:56:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][100/351]	Step 27852	lr 0.01262	Loss 0.5360 (0.5401)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 98.0%)	
11/25 09:56:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][200/351]	Step 27952	lr 0.01262	Loss 0.5398 (0.5503)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 98.0%)	
11/25 09:57:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][300/351]	Step 28052	lr 0.01262	Loss 0.5532 (0.5619)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.9%)	
11/25 09:57:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][351/351]	Step 28103	lr 0.01262	Loss 0.6615 (0.5679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.9%)	
11/25 09:57:26AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [101/149] Final Prec@1 82.0467%
11/25 09:57:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][39/40]	Step 28104	Loss 1.6189	Prec@(1,5) (59.9%, 86.1%)
11/25 09:57:30AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 59.8600%
11/25 09:57:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 09:58:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][100/351]	Step 28204	lr 0.01225	Loss 0.5119 (0.5128)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.3%)	
11/25 09:58:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][200/351]	Step 28304	lr 0.01225	Loss 0.7335 (0.5325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.2%)	
11/25 09:58:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][300/351]	Step 28404	lr 0.01225	Loss 0.5476 (0.5436)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 98.0%)	
11/25 09:59:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][351/351]	Step 28455	lr 0.01225	Loss 0.5620 (0.5483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.0%)	
11/25 09:59:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [102/149] Final Prec@1 82.8400%
11/25 09:59:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][39/40]	Step 28456	Loss 1.6402	Prec@(1,5) (60.1%, 86.8%)
11/25 09:59:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 60.1000%
11/25 09:59:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 09:59:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][100/351]	Step 28556	lr 0.01187	Loss 0.5126 (0.4902)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.5%)	
11/25 10:00:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][200/351]	Step 28656	lr 0.01187	Loss 0.5301 (0.5154)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.2%)	
11/25 10:00:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][300/351]	Step 28756	lr 0.01187	Loss 0.5412 (0.5307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.1%)	
11/25 10:01:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][351/351]	Step 28807	lr 0.01187	Loss 0.4481 (0.5369)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 98.0%)	
11/25 10:01:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [103/149] Final Prec@1 83.1933%
11/25 10:01:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][39/40]	Step 28808	Loss 1.6646	Prec@(1,5) (58.5%, 86.0%)
11/25 10:01:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 58.5200%
11/25 10:01:06AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 10:01:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][100/351]	Step 28908	lr 0.0115	Loss 0.4932 (0.4676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.4%)	
11/25 10:02:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][200/351]	Step 29008	lr 0.0115	Loss 0.5350 (0.4866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/25 10:02:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][300/351]	Step 29108	lr 0.0115	Loss 0.6527 (0.5008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
11/25 10:02:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][351/351]	Step 29159	lr 0.0115	Loss 0.4827 (0.5097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.3%)	
11/25 10:02:50AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [104/149] Final Prec@1 84.0800%
11/25 10:02:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][39/40]	Step 29160	Loss 1.6397	Prec@(1,5) (60.4%, 86.5%)
11/25 10:02:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 60.4200%
11/25 10:02:54AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 10:03:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][100/351]	Step 29260	lr 0.01112	Loss 0.5322 (0.4483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
11/25 10:03:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][200/351]	Step 29360	lr 0.01112	Loss 0.5747 (0.4637)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.5%)	
11/25 10:04:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][300/351]	Step 29460	lr 0.01112	Loss 0.5809 (0.4815)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/25 10:04:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][351/351]	Step 29511	lr 0.01112	Loss 0.5987 (0.4913)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.4%)	
11/25 10:04:38AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [105/149] Final Prec@1 84.5311%
11/25 10:04:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][39/40]	Step 29512	Loss 1.6214	Prec@(1,5) (60.3%, 86.8%)
11/25 10:04:42AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 60.2200%
11/25 10:04:42AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7200%
11/25 10:05:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][100/351]	Step 29612	lr 0.01075	Loss 0.4974 (0.4549)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.7%)	
11/25 10:05:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][200/351]	Step 29712	lr 0.01075	Loss 0.6551 (0.4678)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.7%)	
11/25 10:06:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][300/351]	Step 29812	lr 0.01075	Loss 0.5702 (0.4770)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.6%)	
11/25 10:06:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][351/351]	Step 29863	lr 0.01075	Loss 0.5707 (0.4834)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.5%)	
11/25 10:06:26AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [106/149] Final Prec@1 84.6911%
11/25 10:06:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][39/40]	Step 29864	Loss 1.6304	Prec@(1,5) (61.0%, 86.6%)
11/25 10:06:30AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 61.0200%
11/25 10:06:30AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0200%
11/25 10:07:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][100/351]	Step 29964	lr 0.01038	Loss 0.4394 (0.4434)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.7%)	
11/25 10:07:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][200/351]	Step 30064	lr 0.01038	Loss 0.3979 (0.4520)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
11/25 10:07:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][300/351]	Step 30164	lr 0.01038	Loss 0.4746 (0.4622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.6%)	
11/25 10:08:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][351/351]	Step 30215	lr 0.01038	Loss 0.3527 (0.4637)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.6%)	
11/25 10:08:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [107/149] Final Prec@1 85.5311%
11/25 10:08:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][39/40]	Step 30216	Loss 1.6472	Prec@(1,5) (60.1%, 86.2%)
11/25 10:08:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 60.1000%
11/25 10:08:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0200%
11/25 10:08:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][100/351]	Step 30316	lr 0.01002	Loss 0.5276 (0.4191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/25 10:09:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][200/351]	Step 30416	lr 0.01002	Loss 0.5869 (0.4285)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.8%)	
11/25 10:09:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][300/351]	Step 30516	lr 0.01002	Loss 0.5567 (0.4410)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.7%)	
11/25 10:10:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][351/351]	Step 30567	lr 0.01002	Loss 0.6814 (0.4461)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.7%)	
11/25 10:10:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [108/149] Final Prec@1 86.1000%
11/25 10:10:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][39/40]	Step 30568	Loss 1.5670	Prec@(1,5) (61.6%, 87.1%)
11/25 10:10:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 61.6400%
11/25 10:10:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/25 10:10:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][100/351]	Step 30668	lr 0.00965	Loss 0.4899 (0.4091)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.9%)	
11/25 10:11:07AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][200/351]	Step 30768	lr 0.00965	Loss 0.5076 (0.4230)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.9%)	
11/25 10:11:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][300/351]	Step 30868	lr 0.00965	Loss 0.4011 (0.4378)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.8%)	
11/25 10:11:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][351/351]	Step 30919	lr 0.00965	Loss 0.4489 (0.4382)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.8%)	
11/25 10:11:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [109/149] Final Prec@1 86.2178%
11/25 10:11:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][39/40]	Step 30920	Loss 1.6303	Prec@(1,5) (60.1%, 87.2%)
11/25 10:11:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 60.1400%
11/25 10:11:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/25 10:12:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][100/351]	Step 31020	lr 0.00929	Loss 0.4169 (0.3953)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 98.9%)	
11/25 10:12:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][200/351]	Step 31120	lr 0.00929	Loss 0.3156 (0.3999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.6%, 99.0%)	
11/25 10:13:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][300/351]	Step 31220	lr 0.00929	Loss 0.5136 (0.4107)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.9%)	
11/25 10:13:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][351/351]	Step 31271	lr 0.00929	Loss 0.4638 (0.4164)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.9%)	
11/25 10:13:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [110/149] Final Prec@1 86.9422%
11/25 10:13:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][39/40]	Step 31272	Loss 1.6135	Prec@(1,5) (61.5%, 86.7%)
11/25 10:13:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 61.5200%
11/25 10:13:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/25 10:14:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][100/351]	Step 31372	lr 0.00894	Loss 0.3664 (0.3721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.3%)	
11/25 10:14:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][200/351]	Step 31472	lr 0.00894	Loss 0.3747 (0.3894)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 99.2%)	
11/25 10:15:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][300/351]	Step 31572	lr 0.00894	Loss 0.4279 (0.4041)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 99.1%)	
11/25 10:15:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][351/351]	Step 31623	lr 0.00894	Loss 0.6217 (0.4112)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 99.0%)	
11/25 10:15:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [111/149] Final Prec@1 86.9978%
11/25 10:15:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][39/40]	Step 31624	Loss 1.5589	Prec@(1,5) (61.0%, 87.1%)
11/25 10:15:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 61.0000%
11/25 10:15:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/25 10:16:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][100/351]	Step 31724	lr 0.00858	Loss 0.3607 (0.3434)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.3%)	
11/25 10:16:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][200/351]	Step 31824	lr 0.00858	Loss 0.3800 (0.3595)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
11/25 10:16:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][300/351]	Step 31924	lr 0.00858	Loss 0.3377 (0.3708)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.2%)	
11/25 10:17:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][351/351]	Step 31975	lr 0.00858	Loss 0.4023 (0.3773)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.1%)	
11/25 10:17:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [112/149] Final Prec@1 88.3022%
11/25 10:17:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][39/40]	Step 31976	Loss 1.6104	Prec@(1,5) (61.1%, 87.7%)
11/25 10:17:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 61.1200%
11/25 10:17:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/25 10:17:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][100/351]	Step 32076	lr 0.00823	Loss 0.3389 (0.3483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
11/25 10:18:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][200/351]	Step 32176	lr 0.00823	Loss 0.4068 (0.3575)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.2%)	
11/25 10:18:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][300/351]	Step 32276	lr 0.00823	Loss 0.3931 (0.3644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.1%)	
11/25 10:19:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][351/351]	Step 32327	lr 0.00823	Loss 0.3539 (0.3699)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.1%)	
11/25 10:19:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [113/149] Final Prec@1 88.4822%
11/25 10:19:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][39/40]	Step 32328	Loss 1.6549	Prec@(1,5) (61.7%, 87.0%)
11/25 10:19:06AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 61.7400%
11/25 10:19:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.7400%
11/25 10:19:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][100/351]	Step 32428	lr 0.00789	Loss 0.3089 (0.3306)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
11/25 10:20:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][200/351]	Step 32528	lr 0.00789	Loss 0.2567 (0.3409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.3%)	
11/25 10:20:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][300/351]	Step 32628	lr 0.00789	Loss 0.4559 (0.3513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.3%)	
11/25 10:20:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][351/351]	Step 32679	lr 0.00789	Loss 0.3608 (0.3563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.3%)	
11/25 10:20:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [114/149] Final Prec@1 88.9089%
11/25 10:20:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][39/40]	Step 32680	Loss 1.6656	Prec@(1,5) (60.8%, 86.9%)
11/25 10:20:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 60.7200%
11/25 10:20:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.7400%
11/25 10:21:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][100/351]	Step 32780	lr 0.00755	Loss 0.2181 (0.3167)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
11/25 10:21:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][200/351]	Step 32880	lr 0.00755	Loss 0.3620 (0.3255)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.1%, 99.3%)	
11/25 10:22:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][300/351]	Step 32980	lr 0.00755	Loss 0.2812 (0.3376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.3%)	
11/25 10:22:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][351/351]	Step 33031	lr 0.00755	Loss 0.5562 (0.3434)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.3%)	
11/25 10:22:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [115/149] Final Prec@1 89.3422%
11/25 10:22:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][39/40]	Step 33032	Loss 1.5746	Prec@(1,5) (62.5%, 87.5%)
11/25 10:22:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 62.4800%
11/25 10:22:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.4800%
11/25 10:23:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][100/351]	Step 33132	lr 0.00722	Loss 0.2964 (0.3012)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
11/25 10:23:43AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][200/351]	Step 33232	lr 0.00722	Loss 0.5079 (0.3088)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
11/25 10:24:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][300/351]	Step 33332	lr 0.00722	Loss 0.3809 (0.3199)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
11/25 10:24:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][351/351]	Step 33383	lr 0.00722	Loss 0.3256 (0.3247)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.1%, 99.3%)	
11/25 10:24:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [116/149] Final Prec@1 90.0978%
11/25 10:24:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][39/40]	Step 33384	Loss 1.6201	Prec@(1,5) (62.6%, 87.8%)
11/25 10:24:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 62.5400%
11/25 10:24:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5400%
11/25 10:25:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][100/351]	Step 33484	lr 0.00689	Loss 0.2418 (0.2929)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
11/25 10:25:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][200/351]	Step 33584	lr 0.00689	Loss 0.1761 (0.2973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.5%)	
11/25 10:26:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][300/351]	Step 33684	lr 0.00689	Loss 0.2720 (0.3048)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.5%)	
11/25 10:26:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][351/351]	Step 33735	lr 0.00689	Loss 0.4430 (0.3093)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.5%)	
11/25 10:26:15AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [117/149] Final Prec@1 90.5467%
11/25 10:26:19AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][39/40]	Step 33736	Loss 1.6364	Prec@(1,5) (61.7%, 87.7%)
11/25 10:26:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 61.7200%
11/25 10:26:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5400%
11/25 10:26:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][100/351]	Step 33836	lr 0.00657	Loss 0.2450 (0.2727)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
11/25 10:27:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][200/351]	Step 33936	lr 0.00657	Loss 0.2633 (0.2798)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.6%)	
11/25 10:27:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][300/351]	Step 34036	lr 0.00657	Loss 0.3330 (0.2860)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.6%)	
11/25 10:28:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][351/351]	Step 34087	lr 0.00657	Loss 0.3564 (0.2882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.6%)	
11/25 10:28:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [118/149] Final Prec@1 91.2267%
11/25 10:28:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][39/40]	Step 34088	Loss 1.6622	Prec@(1,5) (61.9%, 87.3%)
11/25 10:28:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 61.9200%
11/25 10:28:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5400%
11/25 10:28:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][100/351]	Step 34188	lr 0.00625	Loss 0.2277 (0.2651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.7%)	
11/25 10:29:07AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][200/351]	Step 34288	lr 0.00625	Loss 0.2438 (0.2706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
11/25 10:29:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][300/351]	Step 34388	lr 0.00625	Loss 0.3897 (0.2760)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.6%)	
11/25 10:29:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][351/351]	Step 34439	lr 0.00625	Loss 0.3157 (0.2788)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.6%)	
11/25 10:29:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [119/149] Final Prec@1 91.6756%
11/25 10:29:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][39/40]	Step 34440	Loss 1.5973	Prec@(1,5) (63.3%, 87.9%)
11/25 10:29:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 63.3200%
11/25 10:29:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:30:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][100/351]	Step 34540	lr 0.00595	Loss 0.2280 (0.2496)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.7%)	
11/25 10:30:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][200/351]	Step 34640	lr 0.00595	Loss 0.2947 (0.2507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.7%)	
11/25 10:31:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][300/351]	Step 34740	lr 0.00595	Loss 0.3520 (0.2599)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
11/25 10:31:39AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][351/351]	Step 34791	lr 0.00595	Loss 0.2453 (0.2644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
11/25 10:31:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [120/149] Final Prec@1 92.1022%
11/25 10:31:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][39/40]	Step 34792	Loss 1.6140	Prec@(1,5) (62.7%, 87.6%)
11/25 10:31:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 62.7000%
11/25 10:31:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:32:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][100/351]	Step 34892	lr 0.00565	Loss 0.2579 (0.2398)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
11/25 10:32:43AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][200/351]	Step 34992	lr 0.00565	Loss 0.2172 (0.2445)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
11/25 10:33:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][300/351]	Step 35092	lr 0.00565	Loss 0.2498 (0.2509)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.7%)	
11/25 10:33:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][351/351]	Step 35143	lr 0.00565	Loss 0.2416 (0.2538)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.7%)	
11/25 10:33:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [121/149] Final Prec@1 92.4267%
11/25 10:33:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][39/40]	Step 35144	Loss 1.6126	Prec@(1,5) (63.2%, 88.0%)
11/25 10:33:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 63.2200%
11/25 10:33:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:34:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][100/351]	Step 35244	lr 0.00535	Loss 0.2796 (0.2315)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
11/25 10:34:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][200/351]	Step 35344	lr 0.00535	Loss 0.2732 (0.2374)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
11/25 10:35:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][300/351]	Step 35444	lr 0.00535	Loss 0.1855 (0.2412)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
11/25 10:35:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][351/351]	Step 35495	lr 0.00535	Loss 0.2697 (0.2451)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.7%)	
11/25 10:35:15AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [122/149] Final Prec@1 92.7311%
11/25 10:35:19AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][39/40]	Step 35496	Loss 1.5737	Prec@(1,5) (62.8%, 88.2%)
11/25 10:35:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 62.7600%
11/25 10:35:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:35:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][100/351]	Step 35596	lr 0.00506	Loss 0.2372 (0.2124)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
11/25 10:36:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][200/351]	Step 35696	lr 0.00506	Loss 0.2510 (0.2197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.8%)	
11/25 10:36:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][300/351]	Step 35796	lr 0.00506	Loss 0.2197 (0.2244)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.8%)	
11/25 10:37:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][351/351]	Step 35847	lr 0.00506	Loss 0.1749 (0.2277)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.8%)	
11/25 10:37:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [123/149] Final Prec@1 93.3711%
11/25 10:37:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][39/40]	Step 35848	Loss 1.6438	Prec@(1,5) (62.6%, 87.8%)
11/25 10:37:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 62.5800%
11/25 10:37:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:37:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][100/351]	Step 35948	lr 0.00479	Loss 0.2315 (0.2092)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.8%)	
11/25 10:38:07AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][200/351]	Step 36048	lr 0.00479	Loss 0.1804 (0.2166)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
11/25 10:38:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][300/351]	Step 36148	lr 0.00479	Loss 0.2015 (0.2214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/25 10:38:51AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][351/351]	Step 36199	lr 0.00479	Loss 0.1723 (0.2241)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
11/25 10:38:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [124/149] Final Prec@1 93.5356%
11/25 10:38:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][39/40]	Step 36200	Loss 1.6041	Prec@(1,5) (63.0%, 88.5%)
11/25 10:38:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 63.0000%
11/25 10:38:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:39:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][100/351]	Step 36300	lr 0.00451	Loss 0.1698 (0.2014)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.7%)	
11/25 10:39:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][200/351]	Step 36400	lr 0.00451	Loss 0.1962 (0.2037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
11/25 10:40:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][300/351]	Step 36500	lr 0.00451	Loss 0.2947 (0.2082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
11/25 10:40:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][351/351]	Step 36551	lr 0.00451	Loss 0.2237 (0.2116)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.8%)	
11/25 10:40:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [125/149] Final Prec@1 94.0578%
11/25 10:40:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][39/40]	Step 36552	Loss 1.6202	Prec@(1,5) (62.9%, 88.0%)
11/25 10:40:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 62.9000%
11/25 10:40:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:41:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][100/351]	Step 36652	lr 0.00425	Loss 0.2205 (0.1980)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
11/25 10:41:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][200/351]	Step 36752	lr 0.00425	Loss 0.1520 (0.1995)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
11/25 10:42:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][300/351]	Step 36852	lr 0.00425	Loss 0.2866 (0.1996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
11/25 10:42:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][351/351]	Step 36903	lr 0.00425	Loss 0.2745 (0.2005)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
11/25 10:42:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [126/149] Final Prec@1 94.3933%
11/25 10:42:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][39/40]	Step 36904	Loss 1.6246	Prec@(1,5) (63.1%, 88.2%)
11/25 10:42:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 63.1400%
11/25 10:42:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:43:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][100/351]	Step 37004	lr 0.004	Loss 0.1410 (0.1820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.9%)	
11/25 10:43:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][200/351]	Step 37104	lr 0.004	Loss 0.1636 (0.1865)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
11/25 10:43:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][300/351]	Step 37204	lr 0.004	Loss 0.1170 (0.1886)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
11/25 10:44:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][351/351]	Step 37255	lr 0.004	Loss 0.1455 (0.1887)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
11/25 10:44:14AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [127/149] Final Prec@1 94.7467%
11/25 10:44:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][39/40]	Step 37256	Loss 1.5989	Prec@(1,5) (63.3%, 88.2%)
11/25 10:44:18AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 63.2800%
11/25 10:44:18AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:44:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][100/351]	Step 37356	lr 0.00375	Loss 0.1451 (0.1683)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
11/25 10:45:18AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][200/351]	Step 37456	lr 0.00375	Loss 0.1963 (0.1752)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
11/25 10:45:47AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][300/351]	Step 37556	lr 0.00375	Loss 0.2433 (0.1797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.9%)	
11/25 10:46:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][351/351]	Step 37607	lr 0.00375	Loss 0.1865 (0.1806)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.9%)	
11/25 10:46:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [128/149] Final Prec@1 95.1844%
11/25 10:46:06AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][39/40]	Step 37608	Loss 1.6564	Prec@(1,5) (63.3%, 87.7%)
11/25 10:46:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 63.3000%
11/25 10:46:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3200%
11/25 10:46:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][100/351]	Step 37708	lr 0.00352	Loss 0.1117 (0.1675)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
11/25 10:47:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][200/351]	Step 37808	lr 0.00352	Loss 0.2049 (0.1709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.5%, 99.9%)	
11/25 10:47:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][300/351]	Step 37908	lr 0.00352	Loss 0.1832 (0.1719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
11/25 10:47:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][351/351]	Step 37959	lr 0.00352	Loss 0.1581 (0.1743)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.9%)	
11/25 10:47:50AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [129/149] Final Prec@1 95.3489%
11/25 10:47:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][39/40]	Step 37960	Loss 1.5901	Prec@(1,5) (63.8%, 88.4%)
11/25 10:47:54AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 63.8400%
11/25 10:47:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.8400%
11/25 10:48:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][100/351]	Step 38060	lr 0.00329	Loss 0.1050 (0.1536)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.3%, 99.9%)	
11/25 10:48:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][200/351]	Step 38160	lr 0.00329	Loss 0.1177 (0.1616)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
11/25 10:49:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][300/351]	Step 38260	lr 0.00329	Loss 0.1670 (0.1614)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
11/25 10:49:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][351/351]	Step 38311	lr 0.00329	Loss 0.2307 (0.1620)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
11/25 10:49:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [130/149] Final Prec@1 95.7844%
11/25 10:49:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][39/40]	Step 38312	Loss 1.6044	Prec@(1,5) (63.6%, 88.3%)
11/25 10:49:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 63.5800%
11/25 10:49:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.8400%
11/25 10:50:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][100/351]	Step 38412	lr 0.00308	Loss 0.1626 (0.1554)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.0%, 99.9%)	
11/25 10:50:43AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][200/351]	Step 38512	lr 0.00308	Loss 0.1215 (0.1536)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.0%, 99.9%)	
11/25 10:51:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][300/351]	Step 38612	lr 0.00308	Loss 0.1522 (0.1563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.9%, 99.9%)	
11/25 10:51:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][351/351]	Step 38663	lr 0.00308	Loss 0.2728 (0.1581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.9%, 99.9%)	
11/25 10:51:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [131/149] Final Prec@1 95.8778%
11/25 10:51:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][39/40]	Step 38664	Loss 1.6237	Prec@(1,5) (63.0%, 87.9%)
11/25 10:51:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 63.0600%
11/25 10:51:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.8400%
11/25 10:52:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][100/351]	Step 38764	lr 0.00287	Loss 0.1253 (0.1471)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.5%, 99.9%)	
11/25 10:52:30AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][200/351]	Step 38864	lr 0.00287	Loss 0.0821 (0.1493)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
11/25 10:52:59AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][300/351]	Step 38964	lr 0.00287	Loss 0.1447 (0.1502)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
11/25 10:53:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][351/351]	Step 39015	lr 0.00287	Loss 0.1064 (0.1507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
11/25 10:53:15AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [132/149] Final Prec@1 96.3622%
11/25 10:53:18AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][39/40]	Step 39016	Loss 1.6106	Prec@(1,5) (63.9%, 88.3%)
11/25 10:53:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 63.9200%
11/25 10:53:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.9200%
11/25 10:53:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][100/351]	Step 39116	lr 0.00267	Loss 0.1428 (0.1417)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.5%, 99.9%)	
11/25 10:54:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][200/351]	Step 39216	lr 0.00267	Loss 0.1567 (0.1419)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
11/25 10:54:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][300/351]	Step 39316	lr 0.00267	Loss 0.0980 (0.1433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
11/25 10:55:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][351/351]	Step 39367	lr 0.00267	Loss 0.1518 (0.1437)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
11/25 10:55:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [133/149] Final Prec@1 96.3889%
11/25 10:55:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][39/40]	Step 39368	Loss 1.6188	Prec@(1,5) (63.3%, 88.5%)
11/25 10:55:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 63.2800%
11/25 10:55:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.9200%
11/25 10:55:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][100/351]	Step 39468	lr 0.00248	Loss 0.1471 (0.1355)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.7%, 100.0%)	
11/25 10:56:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][200/351]	Step 39568	lr 0.00248	Loss 0.1138 (0.1335)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.8%, 99.9%)	
11/25 10:56:35AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][300/351]	Step 39668	lr 0.00248	Loss 0.1320 (0.1363)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.7%, 99.9%)	
11/25 10:56:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][351/351]	Step 39719	lr 0.00248	Loss 0.1941 (0.1379)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.6%, 99.9%)	
11/25 10:56:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [134/149] Final Prec@1 96.5956%
11/25 10:56:54AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][39/40]	Step 39720	Loss 1.6184	Prec@(1,5) (64.0%, 88.1%)
11/25 10:56:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 64.0600%
11/25 10:56:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.0600%
11/25 10:57:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][100/351]	Step 39820	lr 0.00231	Loss 0.0860 (0.1328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.6%, 99.9%)	
11/25 10:57:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][200/351]	Step 39920	lr 0.00231	Loss 0.1523 (0.1319)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.8%, 99.9%)	
11/25 10:58:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][300/351]	Step 40020	lr 0.00231	Loss 0.2242 (0.1348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.7%, 99.9%)	
11/25 10:58:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][351/351]	Step 40071	lr 0.00231	Loss 0.1496 (0.1350)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.7%, 99.9%)	
11/25 10:58:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [135/149] Final Prec@1 96.7400%
11/25 10:58:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][39/40]	Step 40072	Loss 1.5699	Prec@(1,5) (63.8%, 88.3%)
11/25 10:58:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 63.8200%
11/25 10:58:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.0600%
11/25 10:59:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][100/351]	Step 40172	lr 0.00214	Loss 0.0976 (0.1263)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.0%, 100.0%)	
11/25 10:59:42AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][200/351]	Step 40272	lr 0.00214	Loss 0.1377 (0.1272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.0%, 100.0%)	
11/25 11:00:11AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][300/351]	Step 40372	lr 0.00214	Loss 0.1453 (0.1294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.0%, 100.0%)	
11/25 11:00:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][351/351]	Step 40423	lr 0.00214	Loss 0.1254 (0.1300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.9%, 100.0%)	
11/25 11:00:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [136/149] Final Prec@1 96.9156%
11/25 11:00:30AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][39/40]	Step 40424	Loss 1.6054	Prec@(1,5) (64.4%, 88.5%)
11/25 11:00:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 64.4000%
11/25 11:00:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4000%
11/25 11:01:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][100/351]	Step 40524	lr 0.00199	Loss 0.1126 (0.1180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.5%, 100.0%)	
11/25 11:01:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][200/351]	Step 40624	lr 0.00199	Loss 0.0863 (0.1205)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.4%, 99.9%)	
11/25 11:02:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][300/351]	Step 40724	lr 0.00199	Loss 0.1179 (0.1239)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.2%, 99.9%)	
11/25 11:02:15AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][351/351]	Step 40775	lr 0.00199	Loss 0.1109 (0.1250)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.2%, 99.9%)	
11/25 11:02:15AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [137/149] Final Prec@1 97.1933%
11/25 11:02:19AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][39/40]	Step 40776	Loss 1.6025	Prec@(1,5) (64.1%, 88.7%)
11/25 11:02:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 64.1400%
11/25 11:02:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4000%
11/25 11:02:49AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][100/351]	Step 40876	lr 0.00184	Loss 0.1462 (0.1224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.2%, 99.9%)	
11/25 11:03:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][200/351]	Step 40976	lr 0.00184	Loss 0.1265 (0.1207)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.3%, 100.0%)	
11/25 11:03:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][300/351]	Step 41076	lr 0.00184	Loss 0.1057 (0.1222)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.3%, 100.0%)	
11/25 11:04:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][351/351]	Step 41127	lr 0.00184	Loss 0.1281 (0.1232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.2%, 100.0%)	
11/25 11:04:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [138/149] Final Prec@1 97.2289%
11/25 11:04:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][39/40]	Step 41128	Loss 1.5990	Prec@(1,5) (63.9%, 88.7%)
11/25 11:04:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 63.9000%
11/25 11:04:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4000%
11/25 11:04:37AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][100/351]	Step 41228	lr 0.00171	Loss 0.1154 (0.1113)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.7%, 100.0%)	
11/25 11:05:06AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][200/351]	Step 41328	lr 0.00171	Loss 0.0738 (0.1152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.5%, 100.0%)	
11/25 11:05:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][300/351]	Step 41428	lr 0.00171	Loss 0.1125 (0.1168)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.5%, 100.0%)	
11/25 11:05:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][351/351]	Step 41479	lr 0.00171	Loss 0.1698 (0.1185)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.4%, 100.0%)	
11/25 11:05:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [139/149] Final Prec@1 97.4333%
11/25 11:05:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][39/40]	Step 41480	Loss 1.6110	Prec@(1,5) (63.3%, 88.5%)
11/25 11:05:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 63.3000%
11/25 11:05:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4000%
11/25 11:06:25AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][100/351]	Step 41580	lr 0.00159	Loss 0.1252 (0.1098)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:06:54AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][200/351]	Step 41680	lr 0.00159	Loss 0.1259 (0.1121)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:07:23AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][300/351]	Step 41780	lr 0.00159	Loss 0.1266 (0.1154)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.6%, 100.0%)	
11/25 11:07:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][351/351]	Step 41831	lr 0.00159	Loss 0.1000 (0.1153)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.6%, 100.0%)	
11/25 11:07:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [140/149] Final Prec@1 97.5622%
11/25 11:07:42AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][39/40]	Step 41832	Loss 1.6148	Prec@(1,5) (64.9%, 88.5%)
11/25 11:07:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 64.9000%
11/25 11:07:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:08:13AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][100/351]	Step 41932	lr 0.00148	Loss 0.1395 (0.1051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:08:43AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][200/351]	Step 42032	lr 0.00148	Loss 0.1247 (0.1084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.7%, 100.0%)	
11/25 11:09:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][300/351]	Step 42132	lr 0.00148	Loss 0.1245 (0.1096)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.7%, 100.0%)	
11/25 11:09:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][351/351]	Step 42183	lr 0.00148	Loss 0.0946 (0.1105)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.6%, 100.0%)	
11/25 11:09:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [141/149] Final Prec@1 97.6111%
11/25 11:09:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][39/40]	Step 42184	Loss 1.6138	Prec@(1,5) (64.3%, 89.0%)
11/25 11:09:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 64.2600%
11/25 11:09:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:10:01AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][100/351]	Step 42284	lr 0.00138	Loss 0.0914 (0.1065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:10:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][200/351]	Step 42384	lr 0.00138	Loss 0.1139 (0.1073)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:11:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][300/351]	Step 42484	lr 0.00138	Loss 0.0720 (0.1084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:11:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][351/351]	Step 42535	lr 0.00138	Loss 0.1040 (0.1085)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.7%, 100.0%)	
11/25 11:11:15AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [142/149] Final Prec@1 97.7244%
11/25 11:11:19AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][39/40]	Step 42536	Loss 1.6208	Prec@(1,5) (64.4%, 88.5%)
11/25 11:11:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 64.4800%
11/25 11:11:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:11:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][100/351]	Step 42636	lr 0.00129	Loss 0.0838 (0.1002)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:12:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][200/351]	Step 42736	lr 0.00129	Loss 0.0738 (0.1031)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:12:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][300/351]	Step 42836	lr 0.00129	Loss 0.0686 (0.1046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:13:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][351/351]	Step 42887	lr 0.00129	Loss 0.0603 (0.1057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:13:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [143/149] Final Prec@1 97.8044%
11/25 11:13:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][39/40]	Step 42888	Loss 1.6410	Prec@(1,5) (63.9%, 88.3%)
11/25 11:13:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 63.8200%
11/25 11:13:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:13:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][100/351]	Step 42988	lr 0.00121	Loss 0.1141 (0.1001)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 99.9%)	
11/25 11:14:07AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][200/351]	Step 43088	lr 0.00121	Loss 0.1098 (0.1020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:14:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][300/351]	Step 43188	lr 0.00121	Loss 0.1487 (0.1032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:14:51AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][351/351]	Step 43239	lr 0.00121	Loss 0.0876 (0.1045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:14:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [144/149] Final Prec@1 97.8800%
11/25 11:14:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][39/40]	Step 43240	Loss 1.6330	Prec@(1,5) (63.8%, 88.6%)
11/25 11:14:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 63.8800%
11/25 11:14:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:15:26AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][100/351]	Step 43340	lr 0.00115	Loss 0.1029 (0.1025)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:15:55AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][200/351]	Step 43440	lr 0.00115	Loss 0.0957 (0.1027)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:16:24AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][300/351]	Step 43540	lr 0.00115	Loss 0.1399 (0.1036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:16:39AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][351/351]	Step 43591	lr 0.00115	Loss 0.0947 (0.1042)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:16:39AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [145/149] Final Prec@1 97.8756%
11/25 11:16:43AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][39/40]	Step 43592	Loss 1.6184	Prec@(1,5) (64.1%, 88.5%)
11/25 11:16:43AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 64.0400%
11/25 11:16:43AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:17:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][100/351]	Step 43692	lr 0.00109	Loss 0.0663 (0.0991)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:17:43AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][200/351]	Step 43792	lr 0.00109	Loss 0.1167 (0.1016)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:18:12AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][300/351]	Step 43892	lr 0.00109	Loss 0.0779 (0.1023)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.8%, 100.0%)	
11/25 11:18:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][351/351]	Step 43943	lr 0.00109	Loss 0.1018 (0.1018)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (97.9%, 100.0%)	
11/25 11:18:27AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [146/149] Final Prec@1 97.8556%
11/25 11:18:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][39/40]	Step 43944	Loss 1.6071	Prec@(1,5) (64.3%, 88.7%)
11/25 11:18:31AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 64.2600%
11/25 11:18:31AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:19:02AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][100/351]	Step 44044	lr 0.00105	Loss 0.0878 (0.0965)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.3%, 100.0%)	
11/25 11:19:31AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][200/351]	Step 44144	lr 0.00105	Loss 0.1066 (0.0989)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:20:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][300/351]	Step 44244	lr 0.00105	Loss 0.0851 (0.0992)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:20:14AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][351/351]	Step 44295	lr 0.00105	Loss 0.1144 (0.1000)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:20:15AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [147/149] Final Prec@1 98.0467%
11/25 11:20:19AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][39/40]	Step 44296	Loss 1.6322	Prec@(1,5) (63.9%, 88.6%)
11/25 11:20:19AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 63.9400%
11/25 11:20:19AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:20:50AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][100/351]	Step 44396	lr 0.00102	Loss 0.0901 (0.0962)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:21:19AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][200/351]	Step 44496	lr 0.00102	Loss 0.0652 (0.0976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:21:48AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][300/351]	Step 44596	lr 0.00102	Loss 0.1329 (0.0993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:22:03AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][351/351]	Step 44647	lr 0.00102	Loss 0.0786 (0.0997)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:22:03AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [148/149] Final Prec@1 98.0289%
11/25 11:22:07AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][39/40]	Step 44648	Loss 1.6194	Prec@(1,5) (64.1%, 88.8%)
11/25 11:22:07AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 64.0600%
11/25 11:22:07AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:22:38AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][100/351]	Step 44748	lr 0.00101	Loss 0.0969 (0.0975)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.0%, 100.0%)	
11/25 11:23:07AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][200/351]	Step 44848	lr 0.00101	Loss 0.1031 (0.0979)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:23:36AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][300/351]	Step 44948	lr 0.00101	Loss 0.1023 (0.0985)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:23:51AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][351/351]	Step 44999	lr 0.00101	Loss 0.1109 (0.0990)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (98.1%, 100.0%)	
11/25 11:23:51AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [149/149] Final Prec@1 98.0822%
11/25 11:23:55AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][39/40]	Step 45000	Loss 1.6305	Prec@(1,5) (64.3%, 88.6%)
11/25 11:23:55AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 64.3200%
11/25 11:23:55AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/25 11:23:55AM searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 64.9000%
11/25 11:23:55AM searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
