10/01 04:32:48AM parser.py:28 [INFO] 
10/01 04:32:48AM parser.py:29 [INFO] Parameters:
10/01 04:32:48AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.5-h_das_teacher/DAG
10/01 04:32:48AM parser.py:31 [INFO] T=10.0
10/01 04:32:48AM parser.py:31 [INFO] ADVANCED=True
10/01 04:32:48AM parser.py:31 [INFO] ALPHA_LR=0.0003
10/01 04:32:48AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
10/01 04:32:48AM parser.py:31 [INFO] BATCH_SIZE=64
10/01 04:32:48AM parser.py:31 [INFO] CASCADE=False
10/01 04:32:48AM parser.py:31 [INFO] CHECKPOINT_RESET=False
10/01 04:32:48AM parser.py:31 [INFO] CUTOUT_LENGTH=0
10/01 04:32:48AM parser.py:31 [INFO] DATA_PATH=../data/
10/01 04:32:48AM parser.py:31 [INFO] DATASET=cifar100
10/01 04:32:48AM parser.py:31 [INFO] DEPTH_COEF=0.0
10/01 04:32:48AM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
10/01 04:32:48AM parser.py:31 [INFO] EPOCHS=50
10/01 04:32:48AM parser.py:31 [INFO] EXP_NAME=l0.5-h_das_teacher
10/01 04:32:48AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
10/01 04:32:48AM parser.py:31 [INFO] GPUS=[0]
10/01 04:32:48AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
10/01 04:32:48AM parser.py:31 [INFO] INIT_CHANNELS=16
10/01 04:32:48AM parser.py:31 [INFO] L=0.5
10/01 04:32:48AM parser.py:31 [INFO] LAYERS=20
10/01 04:32:48AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
10/01 04:32:48AM parser.py:31 [INFO] NAME=ARCH-KD
10/01 04:32:48AM parser.py:31 [INFO] NONKD=False
10/01 04:32:48AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.5-h_das_teacher
10/01 04:32:48AM parser.py:31 [INFO] PCDARTS=False
10/01 04:32:48AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.5-h_das_teacher/plots
10/01 04:32:48AM parser.py:31 [INFO] PRINT_FREQ=100
10/01 04:32:48AM parser.py:31 [INFO] RESUME_PATH=None
10/01 04:32:48AM parser.py:31 [INFO] SAVE=l0.5-h_das_teacher
10/01 04:32:48AM parser.py:31 [INFO] SEED=0
10/01 04:32:48AM parser.py:31 [INFO] SHARE_STAGE=False
10/01 04:32:48AM parser.py:31 [INFO] SLIDE_WINDOW=8
10/01 04:32:48AM parser.py:31 [INFO] SPEC_CELL=True
10/01 04:32:48AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
10/01 04:32:48AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
10/01 04:32:48AM parser.py:31 [INFO] TRAIN_PORTION=0.5
10/01 04:32:48AM parser.py:31 [INFO] TYPE=ArchKD
10/01 04:32:48AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
10/01 04:32:48AM parser.py:31 [INFO] W_LR=0.025
10/01 04:32:48AM parser.py:31 [INFO] W_LR_MIN=0.001
10/01 04:32:48AM parser.py:31 [INFO] W_MOMENTUM=0.9
10/01 04:32:48AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
10/01 04:32:48AM parser.py:31 [INFO] WORKERS=4
10/01 04:32:48AM parser.py:32 [INFO] 
10/01 04:32:50AM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
10/01 04:32:50AM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
10/01 04:33:23AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.0980 (4.5248)	Arch Loss 22.8990 (23.3630)	Arch Hard Loss 4.3393 (4.5171)	Arch Alpha Loss 37.1194 (37.6918)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.4%, 11.8%)	
10/01 04:33:53AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0478 (4.3496)	Arch Loss 21.9315 (22.8778)	Arch Hard Loss 3.9649 (4.3242)	Arch Alpha Loss 35.9331 (37.1072)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.1%, 16.7%)	
10/01 04:34:22AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0157 (4.2328)	Arch Loss 21.2738 (22.4722)	Arch Hard Loss 3.9107 (4.2157)	Arch Alpha Loss 34.7262 (36.5131)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.0%, 19.7%)	
10/01 04:34:49AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.7751 (4.1605)	Arch Loss 20.5915 (22.1272)	Arch Hard Loss 3.7764 (4.1408)	Arch Alpha Loss 33.6301 (35.9729)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.9%, 21.7%)	
10/01 04:34:50AM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 5.8880%
10/01 04:34:55AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.8927	Prec@(1,5) (8.7%, 29.5%)
10/01 04:34:59AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9007	Prec@(1,5) (8.9%, 29.6%)
10/01 04:35:03AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.8921	Prec@(1,5) (9.0%, 29.9%)
10/01 04:35:07AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.8864	Prec@(1,5) (9.2%, 29.9%)
10/01 04:35:07AM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 9.2080%
10/01 04:35:07AM searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:35:08AM searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 9.2080%
10/01 04:35:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6196 (3.8161)	Arch Loss 19.9664 (20.3157)	Arch Hard Loss 3.7675 (3.8150)	Arch Alpha Loss 32.3979 (33.0014)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.7%, 32.3%)	
10/01 04:36:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.7327 (3.7632)	Arch Loss 19.0882 (19.9731)	Arch Hard Loss 3.4955 (3.7767)	Arch Alpha Loss 31.1853 (32.3928)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.3%, 33.7%)	
10/01 04:36:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8659 (3.7383)	Arch Loss 18.4713 (19.6285)	Arch Hard Loss 3.4768 (3.7343)	Arch Alpha Loss 29.9890 (31.7884)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.6%, 34.4%)	
10/01 04:37:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.3140 (3.6960)	Arch Loss 18.0048 (19.3233)	Arch Hard Loss 3.5380 (3.6985)	Arch Alpha Loss 28.9338 (31.2495)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.3%, 35.5%)	
10/01 04:37:07午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 12.2920%
10/01 04:37:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5388	Prec@(1,5) (15.1%, 40.4%)
10/01 04:37:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5479	Prec@(1,5) (14.9%, 40.2%)
10/01 04:37:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5387	Prec@(1,5) (15.2%, 40.6%)
10/01 04:37:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5379	Prec@(1,5) (15.2%, 40.7%)
10/01 04:37:24午前 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 15.2160%
10/01 04:37:24午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:37:25午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 15.2160%
10/01 04:37:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6898 (3.4977)	Arch Loss 17.5317 (17.6698)	Arch Hard Loss 3.6415 (3.4985)	Arch Alpha Loss 27.7804 (28.3426)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.7%)	
10/01 04:38:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.3548 (3.4547)	Arch Loss 16.9739 (17.3611)	Arch Hard Loss 3.6351 (3.4704)	Arch Alpha Loss 26.6776 (27.7814)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.8%, 42.8%)	
10/01 04:38:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.1587 (3.4100)	Arch Loss 16.0110 (17.0493)	Arch Hard Loss 3.2022 (3.4325)	Arch Alpha Loss 25.6175 (27.2337)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.8%, 44.1%)	
10/01 04:39:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.5642 (3.3850)	Arch Loss 15.6868 (16.7758)	Arch Hard Loss 3.3344 (3.3990)	Arch Alpha Loss 24.7048 (26.7535)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 44.8%)	
10/01 04:39:19午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 17.3280%
10/01 04:39:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2878	Prec@(1,5) (19.8%, 47.0%)
10/01 04:39:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.2748	Prec@(1,5) (20.1%, 47.1%)
10/01 04:39:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.2681	Prec@(1,5) (20.1%, 47.8%)
10/01 04:39:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.2794	Prec@(1,5) (19.8%, 47.6%)
10/01 04:39:37午前 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 19.7560%
10/01 04:39:37午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:39:37午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 19.7560%
10/01 04:40:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.0774 (3.1952)	Arch Loss 15.0264 (15.3414)	Arch Hard Loss 3.1626 (3.2403)	Arch Alpha Loss 23.7277 (24.2022)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 49.8%)	
10/01 04:40:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.3042 (3.1807)	Arch Loss 14.3483 (15.0830)	Arch Hard Loss 2.9414 (3.2170)	Arch Alpha Loss 22.8137 (23.7321)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.0%, 50.2%)	
10/01 04:41:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.0896 (3.1571)	Arch Loss 13.8797 (14.8314)	Arch Hard Loss 2.9033 (3.1916)	Arch Alpha Loss 21.9528 (23.2797)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.5%, 51.0%)	
10/01 04:41:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.2132 (3.1420)	Arch Loss 13.8956 (14.6233)	Arch Hard Loss 3.2840 (3.1796)	Arch Alpha Loss 21.2233 (22.8875)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.7%, 51.5%)	
10/01 04:41:36午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 21.6440%
10/01 04:41:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1042	Prec@(1,5) (22.8%, 53.7%)
10/01 04:41:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1108	Prec@(1,5) (22.5%, 53.1%)
10/01 04:41:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1145	Prec@(1,5) (22.7%, 53.0%)
10/01 04:41:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1201	Prec@(1,5) (22.8%, 52.7%)
10/01 04:41:54午前 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 22.7800%
10/01 04:41:54午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:41:55午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 22.7800%
10/01 04:42:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.5951 (2.9803)	Arch Loss 13.0343 (13.4754)	Arch Hard Loss 2.8067 (3.0618)	Arch Alpha Loss 20.4551 (20.8271)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.4%, 56.0%)	
10/01 04:42:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.8409 (2.9671)	Arch Loss 12.6609 (13.2683)	Arch Hard Loss 2.7879 (3.0382)	Arch Alpha Loss 19.7459 (20.4601)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.2%)	
10/01 04:43:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.1366 (2.9519)	Arch Loss 12.4900 (13.0782)	Arch Hard Loss 2.9468 (3.0234)	Arch Alpha Loss 19.0864 (20.1096)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.4%)	
10/01 04:43:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.1110 (2.9430)	Arch Loss 12.3501 (12.9089)	Arch Hard Loss 3.0830 (3.0048)	Arch Alpha Loss 18.5341 (19.8084)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 56.6%)	
10/01 04:43:56午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 25.9200%
10/01 04:44:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.9030	Prec@(1,5) (26.4%, 58.4%)
10/01 04:44:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.8975	Prec@(1,5) (26.9%, 58.4%)
10/01 04:44:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9090	Prec@(1,5) (26.7%, 57.9%)
10/01 04:44:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9138	Prec@(1,5) (26.7%, 57.9%)
10/01 04:44:14午前 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 26.7200%
10/01 04:44:14午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:44:14午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 26.7200%
10/01 04:44:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.5857 (2.7934)	Arch Loss 11.6955 (12.0026)	Arch Hard Loss 2.7167 (2.8845)	Arch Alpha Loss 17.9576 (18.2363)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.7%, 60.7%)	
10/01 04:45:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.9599 (2.7818)	Arch Loss 11.3974 (11.8632)	Arch Hard Loss 2.6821 (2.8822)	Arch Alpha Loss 17.4305 (17.9621)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.7%, 61.2%)	
10/01 04:45:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.5457 (2.7846)	Arch Loss 11.1377 (11.7204)	Arch Hard Loss 2.6660 (2.8695)	Arch Alpha Loss 16.9433 (17.7017)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 60.8%)	
10/01 04:46:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.7381 (2.7688)	Arch Loss 10.9307 (11.5880)	Arch Hard Loss 2.6625 (2.8487)	Arch Alpha Loss 16.5364 (17.4786)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 61.2%)	
10/01 04:46:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 29.1960%
10/01 04:46:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8774	Prec@(1,5) (27.5%, 58.4%)
10/01 04:46:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8833	Prec@(1,5) (27.4%, 58.9%)
10/01 04:46:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8821	Prec@(1,5) (27.2%, 59.0%)
10/01 04:46:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8835	Prec@(1,5) (27.3%, 59.1%)
10/01 04:46:29午前 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 27.2400%
10/01 04:46:29午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:46:30午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 27.2400%
10/01 04:47:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.7910 (2.6509)	Arch Loss 10.7962 (10.9270)	Arch Hard Loss 2.7384 (2.7675)	Arch Alpha Loss 16.1156 (16.3189)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 64.0%)	
10/01 04:47:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.5079 (2.6483)	Arch Loss 10.5994 (10.8410)	Arch Hard Loss 2.7337 (2.7816)	Arch Alpha Loss 15.7314 (16.1188)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.3%, 63.7%)	
10/01 04:48:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.7602 (2.6356)	Arch Loss 10.3054 (10.7111)	Arch Hard Loss 2.6162 (2.7464)	Arch Alpha Loss 15.3784 (15.9294)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.0%)	
10/01 04:48:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8373 (2.6325)	Arch Loss 10.1427 (10.6192)	Arch Hard Loss 2.6002 (2.7354)	Arch Alpha Loss 15.0851 (15.7676)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.0%)	
10/01 04:48:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 31.9600%
10/01 04:48:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7034	Prec@(1,5) (31.1%, 62.9%)
10/01 04:48:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6886	Prec@(1,5) (31.2%, 63.0%)
10/01 04:48:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6859	Prec@(1,5) (31.4%, 63.2%)
10/01 04:48:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6865	Prec@(1,5) (31.5%, 63.2%)
10/01 04:48:49午前 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 31.4920%
10/01 04:48:49午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:48:50午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 31.4920%
10/01 04:49:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.6496 (2.5060)	Arch Loss 10.1713 (10.1319)	Arch Hard Loss 2.7802 (2.6677)	Arch Alpha Loss 14.7821 (14.9284)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.8%, 67.1%)	
10/01 04:49:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4698 (2.4920)	Arch Loss 9.4522 (10.0436)	Arch Hard Loss 2.1995 (2.6514)	Arch Alpha Loss 14.5056 (14.7844)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.8%, 67.4%)	
10/01 04:50:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7730 (2.5004)	Arch Loss 9.9725 (9.9643)	Arch Hard Loss 2.8466 (2.6402)	Arch Alpha Loss 14.2518 (14.6482)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.8%, 67.2%)	
10/01 04:50:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.3269 (2.4972)	Arch Loss 9.3500 (9.8802)	Arch Hard Loss 2.3293 (2.6143)	Arch Alpha Loss 14.0414 (14.5318)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.7%, 67.3%)	
10/01 04:50:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 34.7520%
10/01 04:50:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5989	Prec@(1,5) (33.6%, 64.7%)
10/01 04:50:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5712	Prec@(1,5) (34.1%, 65.9%)
10/01 04:51:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5565	Prec@(1,5) (34.2%, 66.2%)
10/01 04:51:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5535	Prec@(1,5) (34.3%, 66.1%)
10/01 04:51:07午前 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 34.2600%
10/01 04:51:07午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:51:07午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 34.2600%
10/01 04:51:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.0674 (2.3671)	Arch Loss 9.4273 (9.5307)	Arch Hard Loss 2.5151 (2.5659)	Arch Alpha Loss 13.8244 (13.9295)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.4%, 70.3%)	
10/01 04:52:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.2505 (2.3720)	Arch Loss 9.2310 (9.4665)	Arch Hard Loss 2.4173 (2.5532)	Arch Alpha Loss 13.6274 (13.8266)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.1%, 70.2%)	
10/01 04:52:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2637 (2.3782)	Arch Loss 9.2062 (9.4056)	Arch Hard Loss 2.4831 (2.5410)	Arch Alpha Loss 13.4462 (13.7292)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 70.0%)	
10/01 04:53:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.4562 (2.3813)	Arch Loss 9.0173 (9.3447)	Arch Hard Loss 2.3696 (2.5217)	Arch Alpha Loss 13.2953 (13.6461)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.9%)	
10/01 04:53:06午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 36.9920%
10/01 04:53:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4447	Prec@(1,5) (36.7%, 68.8%)
10/01 04:53:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4468	Prec@(1,5) (36.6%, 68.4%)
10/01 04:53:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4562	Prec@(1,5) (36.3%, 68.2%)
10/01 04:53:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4606	Prec@(1,5) (36.2%, 68.1%)
10/01 04:53:23午前 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 36.2160%
10/01 04:53:23午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 04:53:24午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 36.2160%
10/01 04:53:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.6449 (2.2595)	Arch Loss 9.8793 (9.0801)	Arch Hard Loss 3.3089 (2.4723)	Arch Alpha Loss 13.1409 (13.2156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.5%, 72.9%)	
10/01 04:54:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.0604 (2.2658)	Arch Loss 8.9691 (9.0391)	Arch Hard Loss 2.4689 (2.4680)	Arch Alpha Loss 13.0004 (13.1423)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.4%, 72.6%)	
10/01 04:54:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 1.9410 (2.2742)	Arch Loss 8.8419 (8.9830)	Arch Hard Loss 2.4063 (2.4465)	Arch Alpha Loss 12.8712 (13.0730)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 72.4%)	
10/01 04:55:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 1.9389 (2.2704)	Arch Loss 8.8417 (8.9502)	Arch Hard Loss 2.4596 (2.4433)	Arch Alpha Loss 12.7641 (13.0139)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 72.4%)	
10/01 04:55:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 39.3200%
10/01 04:55:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4171	Prec@(1,5) (37.1%, 69.5%)
10/01 04:55:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3832	Prec@(1,5) (37.7%, 70.2%)
10/01 04:55:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3814	Prec@(1,5) (37.6%, 70.2%)
10/01 04:55:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3804	Prec@(1,5) (37.6%, 70.3%)
10/01 04:55:42午前 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 37.6200%
10/01 04:55:42午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 04:55:43午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 37.6200%
10/01 04:56:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.4979 (2.1317)	Arch Loss 8.2940 (8.7724)	Arch Hard Loss 1.9672 (2.4189)	Arch Alpha Loss 12.6537 (12.7071)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 75.3%)	
10/01 04:56:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.1064 (2.1541)	Arch Loss 8.8605 (8.7294)	Arch Hard Loss 2.5838 (2.4020)	Arch Alpha Loss 12.5534 (12.6547)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.8%, 74.8%)	
10/01 04:57:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.0671 (2.1669)	Arch Loss 8.3902 (8.6893)	Arch Hard Loss 2.1596 (2.3867)	Arch Alpha Loss 12.4612 (12.6052)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 74.4%)	
10/01 04:57:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1866 (2.1854)	Arch Loss 8.4482 (8.6580)	Arch Hard Loss 2.2559 (2.3766)	Arch Alpha Loss 12.3847 (12.5629)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.2%, 73.9%)	
10/01 04:57:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 41.2440%
10/01 04:57:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3631	Prec@(1,5) (38.3%, 70.0%)
10/01 04:57:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3606	Prec@(1,5) (38.5%, 70.5%)
10/01 04:57:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3351	Prec@(1,5) (38.8%, 71.1%)
10/01 04:58:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3343	Prec@(1,5) (38.9%, 71.1%)
10/01 04:58:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 38.8560%
10/01 04:58:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 04:58:01午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 38.8560%
10/01 04:58:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2608 (2.0694)	Arch Loss 8.3955 (8.5403)	Arch Hard Loss 2.2422 (2.3683)	Arch Alpha Loss 12.3067 (12.3441)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.3%)	
10/01 04:59:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.5974 (2.0818)	Arch Loss 8.3231 (8.4865)	Arch Hard Loss 2.2054 (2.3329)	Arch Alpha Loss 12.2353 (12.3071)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.5%, 75.9%)	
10/01 04:59:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2544 (2.0927)	Arch Loss 8.5484 (8.4585)	Arch Hard Loss 2.4638 (2.3226)	Arch Alpha Loss 12.1692 (12.2719)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 75.8%)	
10/01 05:00:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.7648 (2.0887)	Arch Loss 8.3385 (8.4373)	Arch Hard Loss 2.2809 (2.3164)	Arch Alpha Loss 12.1152 (12.2418)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 76.0%)	
10/01 05:00:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 43.3840%
10/01 05:00:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3849	Prec@(1,5) (38.6%, 70.8%)
10/01 05:00:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3815	Prec@(1,5) (38.6%, 70.7%)
10/01 05:00:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3760	Prec@(1,5) (38.8%, 70.7%)
10/01 05:00:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3609	Prec@(1,5) (39.0%, 71.0%)
10/01 05:00:19午前 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 38.9600%
10/01 05:00:19午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:00:20午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 38.9600%
10/01 05:00:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.7530 (1.9984)	Arch Loss 8.3842 (8.3484)	Arch Hard Loss 2.3545 (2.3052)	Arch Alpha Loss 12.0595 (12.0863)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.5%, 77.0%)	
10/01 05:01:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.9389 (2.0073)	Arch Loss 8.7609 (8.3278)	Arch Hard Loss 2.7565 (2.2978)	Arch Alpha Loss 12.0087 (12.0599)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.1%)	
10/01 05:01:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.1296 (2.0216)	Arch Loss 7.8444 (8.2938)	Arch Hard Loss 1.8628 (2.2762)	Arch Alpha Loss 11.9633 (12.0351)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.0%)	
10/01 05:02:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.1235 (2.0187)	Arch Loss 8.2523 (8.2759)	Arch Hard Loss 2.2895 (2.2689)	Arch Alpha Loss 11.9255 (12.0140)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 77.1%)	
10/01 05:02:19午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 45.1680%
10/01 05:02:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2261	Prec@(1,5) (41.5%, 72.9%)
10/01 05:02:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1888	Prec@(1,5) (42.2%, 73.6%)
10/01 05:02:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1917	Prec@(1,5) (42.0%, 73.7%)
10/01 05:02:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1910	Prec@(1,5) (42.1%, 73.8%)
10/01 05:02:36午前 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 42.1240%
10/01 05:02:36午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:02:36午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 42.1240%
10/01 05:03:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1166 (1.8995)	Arch Loss 8.2280 (8.1799)	Arch Hard Loss 2.2849 (2.2272)	Arch Alpha Loss 11.8862 (11.9052)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.5%)	
10/01 05:03:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.4589 (1.9073)	Arch Loss 7.8692 (8.1777)	Arch Hard Loss 1.9440 (2.2344)	Arch Alpha Loss 11.8504 (11.8865)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.4%, 79.5%)	
10/01 05:04:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.2388 (1.9231)	Arch Loss 7.5598 (8.1553)	Arch Hard Loss 1.6508 (2.2209)	Arch Alpha Loss 11.8179 (11.8689)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 79.2%)	
10/01 05:04:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.1698 (1.9368)	Arch Loss 7.9012 (8.1479)	Arch Hard Loss 2.0057 (2.2209)	Arch Alpha Loss 11.7910 (11.8540)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 79.0%)	
10/01 05:04:34午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 46.7400%
10/01 05:04:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2285	Prec@(1,5) (41.4%, 73.3%)
10/01 05:04:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2596	Prec@(1,5) (41.2%, 72.9%)
10/01 05:04:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2450	Prec@(1,5) (41.6%, 73.2%)
10/01 05:04:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2491	Prec@(1,5) (41.4%, 73.2%)
10/01 05:04:52午前 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 41.3920%
10/01 05:04:52午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:04:52午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 42.1240%
10/01 05:05:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.9352 (1.8501)	Arch Loss 7.9106 (8.0769)	Arch Hard Loss 2.0289 (2.1886)	Arch Alpha Loss 11.7634 (11.7766)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.5%)	
10/01 05:05:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.9086 (1.8540)	Arch Loss 7.7957 (8.0722)	Arch Hard Loss 1.9262 (2.1902)	Arch Alpha Loss 11.7390 (11.7639)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 80.1%)	
10/01 05:06:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.9730 (1.8562)	Arch Loss 8.2676 (8.0489)	Arch Hard Loss 2.4096 (2.1731)	Arch Alpha Loss 11.7161 (11.7517)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.2%)	
10/01 05:06:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.1928 (1.8688)	Arch Loss 8.1245 (8.0501)	Arch Hard Loss 2.2754 (2.1794)	Arch Alpha Loss 11.6984 (11.7414)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.0%)	
10/01 05:06:50午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 48.5280%
10/01 05:06:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1991	Prec@(1,5) (42.5%, 74.3%)
10/01 05:06:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1685	Prec@(1,5) (43.3%, 74.9%)
10/01 05:07:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1592	Prec@(1,5) (43.2%, 74.9%)
10/01 05:07:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1550	Prec@(1,5) (43.5%, 74.8%)
10/01 05:07:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 43.5280%
10/01 05:07:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:07:08午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.5280%
10/01 05:07:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.6820 (1.7690)	Arch Loss 7.7240 (7.9638)	Arch Hard Loss 1.8840 (2.1196)	Arch Alpha Loss 11.6799 (11.6884)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.7%)	
10/01 05:08:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.6264 (1.7624)	Arch Loss 7.8845 (7.9620)	Arch Hard Loss 2.0532 (2.1221)	Arch Alpha Loss 11.6625 (11.6797)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 82.0%)	
10/01 05:08:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9660 (1.7930)	Arch Loss 7.7799 (7.9578)	Arch Hard Loss 1.9562 (2.1221)	Arch Alpha Loss 11.6473 (11.6713)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.3%)	
10/01 05:09:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.8893 (1.8059)	Arch Loss 8.2316 (7.9565)	Arch Hard Loss 2.4143 (2.1244)	Arch Alpha Loss 11.6344 (11.6642)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.2%)	
10/01 05:09:08午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 49.6600%
10/01 05:09:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1292	Prec@(1,5) (44.0%, 75.7%)
10/01 05:09:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1125	Prec@(1,5) (44.2%, 75.9%)
10/01 05:09:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1234	Prec@(1,5) (43.9%, 75.7%)
10/01 05:09:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1242	Prec@(1,5) (43.8%, 75.7%)
10/01 05:09:26午前 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 43.8280%
10/01 05:09:26午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:09:26午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.8280%
10/01 05:09:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7691 (1.7178)	Arch Loss 7.9346 (7.8914)	Arch Hard Loss 2.1235 (2.0773)	Arch Alpha Loss 11.6222 (11.6281)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 83.2%)	
10/01 05:10:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.0990 (1.7251)	Arch Loss 7.7403 (7.9054)	Arch Hard Loss 1.9353 (2.0943)	Arch Alpha Loss 11.6101 (11.6221)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.0%, 83.0%)	
10/01 05:10:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9846 (1.7405)	Arch Loss 7.4576 (7.8990)	Arch Hard Loss 1.6575 (2.0909)	Arch Alpha Loss 11.6002 (11.6164)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.5%)	
10/01 05:11:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7458 (1.7502)	Arch Loss 8.4161 (7.9026)	Arch Hard Loss 2.6198 (2.0967)	Arch Alpha Loss 11.5926 (11.6118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.4%)	
10/01 05:11:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 51.1840%
10/01 05:11:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0719	Prec@(1,5) (45.5%, 76.3%)
10/01 05:11:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0749	Prec@(1,5) (45.0%, 76.5%)
10/01 05:11:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0752	Prec@(1,5) (44.9%, 76.6%)
10/01 05:11:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0793	Prec@(1,5) (44.8%, 76.4%)
10/01 05:11:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 44.8200%
10/01 05:11:43午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:11:44午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 44.8200%
10/01 05:12:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.0124 (1.6392)	Arch Loss 8.2422 (7.8853)	Arch Hard Loss 2.4501 (2.0911)	Arch Alpha Loss 11.5842 (11.5883)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.5%)	
10/01 05:12:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.4509 (1.6696)	Arch Loss 7.7167 (7.8798)	Arch Hard Loss 1.9285 (2.0876)	Arch Alpha Loss 11.5763 (11.5843)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.7%)	
10/01 05:13:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8592 (1.6770)	Arch Loss 7.9931 (7.8629)	Arch Hard Loss 2.2082 (2.0727)	Arch Alpha Loss 11.5699 (11.5805)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.7%)	
10/01 05:13:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.8054 (1.6824)	Arch Loss 7.2951 (7.8494)	Arch Hard Loss 1.5123 (2.0607)	Arch Alpha Loss 11.5654 (11.5775)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.4%)	
10/01 05:13:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 52.7200%
10/01 05:13:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0456	Prec@(1,5) (46.1%, 76.7%)
10/01 05:13:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0282	Prec@(1,5) (45.9%, 77.3%)
10/01 05:13:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0234	Prec@(1,5) (46.2%, 77.4%)
10/01 05:14:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0204	Prec@(1,5) (46.4%, 77.4%)
10/01 05:14:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 46.4320%
10/01 05:14:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:14:02午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.4320%
10/01 05:14:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.7264 (1.5512)	Arch Loss 7.6513 (7.8457)	Arch Hard Loss 1.8710 (2.0642)	Arch Alpha Loss 11.5606 (11.5630)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.8%)	
10/01 05:15:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.6481 (1.5990)	Arch Loss 7.7038 (7.8527)	Arch Hard Loss 1.9262 (2.0724)	Arch Alpha Loss 11.5552 (11.5606)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.1%)	
10/01 05:15:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6479 (1.6032)	Arch Loss 7.8423 (7.8450)	Arch Hard Loss 2.0671 (2.0660)	Arch Alpha Loss 11.5503 (11.5580)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.9%)	
10/01 05:15:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.5075 (1.6189)	Arch Loss 7.4620 (7.8309)	Arch Hard Loss 1.6884 (2.0529)	Arch Alpha Loss 11.5473 (11.5559)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.3%, 84.6%)	
10/01 05:15:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 54.2760%
10/01 05:16:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0166	Prec@(1,5) (46.9%, 77.2%)
10/01 05:16:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0146	Prec@(1,5) (47.0%, 77.4%)
10/01 05:16:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0252	Prec@(1,5) (46.6%, 77.3%)
10/01 05:16:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0140	Prec@(1,5) (46.8%, 77.4%)
10/01 05:16:16午前 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 46.7960%
10/01 05:16:16午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:16:17午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.7960%
10/01 05:16:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.4356 (1.5010)	Arch Loss 7.9119 (7.7787)	Arch Hard Loss 2.1400 (2.0059)	Arch Alpha Loss 11.5439 (11.5456)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.0%)	
10/01 05:17:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.4925 (1.5256)	Arch Loss 7.9874 (7.7965)	Arch Hard Loss 2.2173 (2.0246)	Arch Alpha Loss 11.5401 (11.5439)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 85.7%)	
10/01 05:17:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.4818 (1.5412)	Arch Loss 7.6075 (7.7935)	Arch Hard Loss 1.8385 (2.0224)	Arch Alpha Loss 11.5379 (11.5422)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.7%)	
10/01 05:18:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.2306 (1.5601)	Arch Loss 8.0698 (7.7832)	Arch Hard Loss 2.3019 (2.0127)	Arch Alpha Loss 11.5358 (11.5410)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.4%)	
10/01 05:18:17午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 56.0760%
10/01 05:18:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9840	Prec@(1,5) (48.0%, 78.2%)
10/01 05:18:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9914	Prec@(1,5) (47.9%, 77.9%)
10/01 05:18:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9972	Prec@(1,5) (47.5%, 77.9%)
10/01 05:18:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0016	Prec@(1,5) (47.6%, 77.9%)
10/01 05:18:35午前 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 47.5600%
10/01 05:18:35午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:18:36午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 47.5600%
10/01 05:19:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.5646 (1.4211)	Arch Loss 7.6416 (7.8012)	Arch Hard Loss 1.8749 (2.0341)	Arch Alpha Loss 11.5333 (11.5341)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.7%)	
10/01 05:19:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5908 (1.4656)	Arch Loss 8.0342 (7.7791)	Arch Hard Loss 2.2687 (2.0126)	Arch Alpha Loss 11.5311 (11.5331)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.1%)	
10/01 05:20:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.6029 (1.4816)	Arch Loss 7.9856 (7.7702)	Arch Hard Loss 2.2213 (2.0042)	Arch Alpha Loss 11.5287 (11.5320)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.6%)	
10/01 05:20:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.5043 (1.4968)	Arch Loss 7.8051 (7.7676)	Arch Hard Loss 2.0412 (2.0021)	Arch Alpha Loss 11.5277 (11.5311)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.4%)	
10/01 05:20:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 57.1040%
10/01 05:20:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9572	Prec@(1,5) (47.5%, 78.7%)
10/01 05:20:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9574	Prec@(1,5) (47.7%, 78.8%)
10/01 05:20:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9454	Prec@(1,5) (48.0%, 79.1%)
10/01 05:20:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9419	Prec@(1,5) (48.0%, 79.1%)
10/01 05:20:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 48.0320%
10/01 05:20:53午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:20:53午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 48.0320%
10/01 05:21:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.6992 (1.4071)	Arch Loss 7.1387 (7.7418)	Arch Hard Loss 1.3757 (1.9783)	Arch Alpha Loss 11.5261 (11.5270)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.4%)	
10/01 05:21:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3207 (1.4325)	Arch Loss 7.5398 (7.7594)	Arch Hard Loss 1.7773 (1.9963)	Arch Alpha Loss 11.5252 (11.5263)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.1%)	
10/01 05:22:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.2897 (1.4385)	Arch Loss 8.1487 (7.7435)	Arch Hard Loss 2.3873 (1.9808)	Arch Alpha Loss 11.5228 (11.5254)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.2%)	
10/01 05:22:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.4867 (1.4591)	Arch Loss 7.6002 (7.7414)	Arch Hard Loss 1.8395 (1.9791)	Arch Alpha Loss 11.5216 (11.5247)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 86.8%)	
10/01 05:22:54午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 58.2720%
10/01 05:22:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9339	Prec@(1,5) (49.4%, 78.8%)
10/01 05:23:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9042	Prec@(1,5) (49.9%, 79.7%)
10/01 05:23:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.8967	Prec@(1,5) (49.7%, 79.9%)
10/01 05:23:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9053	Prec@(1,5) (49.6%, 79.8%)
10/01 05:23:12午前 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 49.5960%
10/01 05:23:12午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:23:12午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.5960%
10/01 05:23:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3972 (1.3264)	Arch Loss 7.9217 (7.6687)	Arch Hard Loss 2.1619 (1.9085)	Arch Alpha Loss 11.5196 (11.5203)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.9%)	
10/01 05:24:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4656 (1.3807)	Arch Loss 7.7782 (7.7211)	Arch Hard Loss 2.0187 (1.9612)	Arch Alpha Loss 11.5189 (11.5198)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.0%)	
10/01 05:24:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3701 (1.3906)	Arch Loss 7.6264 (7.7218)	Arch Hard Loss 1.8675 (1.9622)	Arch Alpha Loss 11.5179 (11.5193)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.0%)	
10/01 05:25:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.0524 (1.3971)	Arch Loss 7.4187 (7.7186)	Arch Hard Loss 1.6601 (1.9592)	Arch Alpha Loss 11.5173 (11.5189)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.0%)	
10/01 05:25:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 59.5920%
10/01 05:25:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9399	Prec@(1,5) (49.4%, 79.5%)
10/01 05:25:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9433	Prec@(1,5) (49.3%, 79.3%)
10/01 05:25:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9279	Prec@(1,5) (49.2%, 79.4%)
10/01 05:25:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9358	Prec@(1,5) (49.1%, 79.4%)
10/01 05:25:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 49.1040%
10/01 05:25:32午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:25:32午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.5960%
10/01 05:26:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.2954 (1.2574)	Arch Loss 7.5928 (7.7019)	Arch Hard Loss 1.8344 (1.9432)	Arch Alpha Loss 11.5168 (11.5174)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.4%)	
10/01 05:26:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3588 (1.2908)	Arch Loss 7.8386 (7.6977)	Arch Hard Loss 2.0802 (1.9392)	Arch Alpha Loss 11.5169 (11.5171)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.5%)	
10/01 05:27:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.3343 (1.3196)	Arch Loss 7.7035 (7.7114)	Arch Hard Loss 1.9458 (1.9530)	Arch Alpha Loss 11.5155 (11.5168)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.1%)	
10/01 05:27:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3430 (1.3360)	Arch Loss 8.0659 (7.7061)	Arch Hard Loss 2.3088 (1.9479)	Arch Alpha Loss 11.5141 (11.5164)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.9%)	
10/01 05:27:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 61.0160%
10/01 05:27:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9010	Prec@(1,5) (49.1%, 80.7%)
10/01 05:27:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9236	Prec@(1,5) (49.0%, 80.0%)
10/01 05:27:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9318	Prec@(1,5) (49.1%, 79.7%)
10/01 05:27:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9202	Prec@(1,5) (49.5%, 79.9%)
10/01 05:27:50午前 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 49.5360%
10/01 05:27:50午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:27:50午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.5960%
10/01 05:28:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.2385 (1.2191)	Arch Loss 7.7877 (7.6802)	Arch Hard Loss 2.0309 (1.9233)	Arch Alpha Loss 11.5137 (11.5139)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.6%)	
10/01 05:28:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3281 (1.2450)	Arch Loss 8.3591 (7.6909)	Arch Hard Loss 2.6034 (1.9343)	Arch Alpha Loss 11.5115 (11.5132)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.3%)	
10/01 05:29:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.2942 (1.2736)	Arch Loss 7.9054 (7.6894)	Arch Hard Loss 2.1502 (1.9331)	Arch Alpha Loss 11.5105 (11.5125)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 90.0%)	
10/01 05:29:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.7397 (1.2906)	Arch Loss 7.7432 (7.6810)	Arch Hard Loss 1.9882 (1.9250)	Arch Alpha Loss 11.5099 (11.5120)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.7%)	
10/01 05:29:50午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 62.1160%
10/01 05:29:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9372	Prec@(1,5) (49.0%, 79.6%)
10/01 05:29:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9152	Prec@(1,5) (49.6%, 79.9%)
10/01 05:30:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9145	Prec@(1,5) (49.9%, 79.8%)
10/01 05:30:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9117	Prec@(1,5) (49.9%, 79.9%)
10/01 05:30:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 49.9440%
10/01 05:30:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:30:08午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.9440%
10/01 05:30:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.4055 (1.1935)	Arch Loss 7.5843 (7.6068)	Arch Hard Loss 1.8304 (1.8524)	Arch Alpha Loss 11.5077 (11.5087)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 91.0%)	
10/01 05:31:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3690 (1.2022)	Arch Loss 7.4581 (7.6504)	Arch Hard Loss 1.7044 (1.8963)	Arch Alpha Loss 11.5074 (11.5082)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.9%)	
10/01 05:31:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.4257 (1.2127)	Arch Loss 8.0841 (7.6621)	Arch Hard Loss 2.3305 (1.9081)	Arch Alpha Loss 11.5071 (11.5079)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.8%)	
10/01 05:32:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.4745 (1.2320)	Arch Loss 7.7603 (7.6675)	Arch Hard Loss 2.0071 (1.9137)	Arch Alpha Loss 11.5063 (11.5077)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.6%, 90.5%)	
10/01 05:32:07午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 63.6120%
10/01 05:32:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8691	Prec@(1,5) (51.2%, 80.2%)
10/01 05:32:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8881	Prec@(1,5) (50.5%, 80.4%)
10/01 05:32:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9157	Prec@(1,5) (50.3%, 80.0%)
10/01 05:32:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9233	Prec@(1,5) (50.1%, 79.9%)
10/01 05:32:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 50.0640%
10/01 05:32:24午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:32:25午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.0640%
10/01 05:32:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.0630 (1.1091)	Arch Loss 7.7824 (7.6917)	Arch Hard Loss 2.0296 (1.9389)	Arch Alpha Loss 11.5055 (11.5056)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 92.1%)	
10/01 05:33:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.3804 (1.1358)	Arch Loss 7.9572 (7.6698)	Arch Hard Loss 2.2042 (1.9170)	Arch Alpha Loss 11.5060 (11.5056)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.6%)	
10/01 05:33:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.4306 (1.1685)	Arch Loss 7.2987 (7.6577)	Arch Hard Loss 1.5459 (1.9049)	Arch Alpha Loss 11.5056 (11.5056)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.3%)	
10/01 05:34:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0855 (1.1821)	Arch Loss 7.9104 (7.6613)	Arch Hard Loss 2.1573 (1.9084)	Arch Alpha Loss 11.5063 (11.5058)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.2%)	
10/01 05:34:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 65.0800%
10/01 05:34:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8526	Prec@(1,5) (52.7%, 81.2%)
10/01 05:34:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8535	Prec@(1,5) (52.2%, 81.1%)
10/01 05:34:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8542	Prec@(1,5) (52.1%, 81.2%)
10/01 05:34:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8661	Prec@(1,5) (51.8%, 80.9%)
10/01 05:34:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 51.7320%
10/01 05:34:43午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:34:43午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.7320%
10/01 05:35:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0104 (1.0813)	Arch Loss 7.7964 (7.6292)	Arch Hard Loss 2.0431 (1.8761)	Arch Alpha Loss 11.5066 (11.5063)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.1%)	
10/01 05:35:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.3545 (1.0975)	Arch Loss 7.3664 (7.6498)	Arch Hard Loss 1.6132 (1.8966)	Arch Alpha Loss 11.5064 (11.5064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.0%)	
10/01 05:36:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1570 (1.1206)	Arch Loss 7.6250 (7.6670)	Arch Hard Loss 1.8720 (1.9138)	Arch Alpha Loss 11.5059 (11.5064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.9%)	
10/01 05:36:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.1424 (1.1299)	Arch Loss 7.3684 (7.6548)	Arch Hard Loss 1.6156 (1.9017)	Arch Alpha Loss 11.5055 (11.5062)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.8%)	
10/01 05:36:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 66.3040%
10/01 05:36:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8902	Prec@(1,5) (51.3%, 80.6%)
10/01 05:36:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8992	Prec@(1,5) (51.5%, 80.3%)
10/01 05:36:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8828	Prec@(1,5) (51.7%, 80.6%)
10/01 05:37:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8742	Prec@(1,5) (51.7%, 80.9%)
10/01 05:37:02午前 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 51.6960%
10/01 05:37:02午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:37:02午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.7320%
10/01 05:37:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9024 (1.0131)	Arch Loss 7.5164 (7.6521)	Arch Hard Loss 1.7635 (1.8993)	Arch Alpha Loss 11.5057 (11.5057)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.5%)	
10/01 05:38:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.0613 (1.0395)	Arch Loss 7.6351 (7.6287)	Arch Hard Loss 1.8824 (1.8759)	Arch Alpha Loss 11.5053 (11.5057)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.2%)	
10/01 05:38:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.2147 (1.0628)	Arch Loss 7.5330 (7.6644)	Arch Hard Loss 1.7807 (1.9117)	Arch Alpha Loss 11.5045 (11.5054)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.9%)	
10/01 05:39:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.2113 (1.0763)	Arch Loss 7.3846 (7.6698)	Arch Hard Loss 1.6317 (1.9171)	Arch Alpha Loss 11.5058 (11.5053)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.8%)	
10/01 05:39:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 67.8040%
10/01 05:39:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8447	Prec@(1,5) (52.8%, 81.5%)
10/01 05:39:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8682	Prec@(1,5) (51.9%, 81.2%)
10/01 05:39:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8552	Prec@(1,5) (52.4%, 81.4%)
10/01 05:39:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8513	Prec@(1,5) (52.6%, 81.5%)
10/01 05:39:18午前 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 52.5560%
10/01 05:39:18午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:39:19午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.5560%
10/01 05:39:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.9245 (0.9884)	Arch Loss 7.5711 (7.6371)	Arch Hard Loss 1.8190 (1.8847)	Arch Alpha Loss 11.5042 (11.5049)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.5%)	
10/01 05:40:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9629 (0.9974)	Arch Loss 7.6444 (7.6420)	Arch Hard Loss 1.8920 (1.8896)	Arch Alpha Loss 11.5049 (11.5048)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.5%)	
10/01 05:40:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 0.8725 (1.0166)	Arch Loss 8.4351 (7.6553)	Arch Hard Loss 2.6829 (1.9029)	Arch Alpha Loss 11.5046 (11.5048)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
10/01 05:41:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0614 (1.0294)	Arch Loss 7.9436 (7.6562)	Arch Hard Loss 2.1918 (1.9039)	Arch Alpha Loss 11.5036 (11.5046)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.0%)	
10/01 05:41:20午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 69.3200%
10/01 05:41:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8555	Prec@(1,5) (52.9%, 81.3%)
10/01 05:41:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8839	Prec@(1,5) (52.0%, 80.7%)
10/01 05:41:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8945	Prec@(1,5) (52.0%, 80.9%)
10/01 05:41:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8955	Prec@(1,5) (51.9%, 81.0%)
10/01 05:41:37午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 51.8920%
10/01 05:41:37午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:41:37午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.5560%
10/01 05:42:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.6600 (0.9399)	Arch Loss 7.4187 (7.6636)	Arch Hard Loss 1.6670 (1.9120)	Arch Alpha Loss 11.5033 (11.5031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.1%)	
10/01 05:42:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9281 (0.9672)	Arch Loss 7.8562 (7.6631)	Arch Hard Loss 2.1041 (1.9114)	Arch Alpha Loss 11.5041 (11.5035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.8%)	
10/01 05:43:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.2723 (0.9720)	Arch Loss 7.5905 (7.6675)	Arch Hard Loss 1.8387 (1.9156)	Arch Alpha Loss 11.5037 (11.5037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.7%)	
10/01 05:43:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0053 (0.9757)	Arch Loss 7.2695 (7.6641)	Arch Hard Loss 1.5183 (1.9123)	Arch Alpha Loss 11.5025 (11.5036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.6%)	
10/01 05:43:36午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 70.8000%
10/01 05:43:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9091	Prec@(1,5) (51.4%, 80.6%)
10/01 05:43:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9199	Prec@(1,5) (51.5%, 80.4%)
10/01 05:43:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9278	Prec@(1,5) (51.4%, 80.6%)
10/01 05:43:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9071	Prec@(1,5) (52.0%, 81.0%)
10/01 05:43:54午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 51.9720%
10/01 05:43:54午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:43:54午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.5560%
10/01 05:44:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9020 (0.8841)	Arch Loss 7.8804 (7.6604)	Arch Hard Loss 2.1298 (1.9095)	Arch Alpha Loss 11.5011 (11.5018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.6%)	
10/01 05:44:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9464 (0.8886)	Arch Loss 7.8819 (7.6378)	Arch Hard Loss 2.1311 (1.8870)	Arch Alpha Loss 11.5016 (11.5017)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.9%)	
10/01 05:45:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0101 (0.9067)	Arch Loss 8.0429 (7.6517)	Arch Hard Loss 2.2919 (1.9008)	Arch Alpha Loss 11.5021 (11.5018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.5%)	
10/01 05:45:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.8655 (0.9191)	Arch Loss 7.6363 (7.6518)	Arch Hard Loss 1.8854 (1.9009)	Arch Alpha Loss 11.5018 (11.5019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.5%)	
10/01 05:45:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 72.1360%
10/01 05:46:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8520	Prec@(1,5) (53.5%, 81.7%)
10/01 05:46:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8764	Prec@(1,5) (53.0%, 81.2%)
10/01 05:46:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8755	Prec@(1,5) (53.2%, 81.5%)
10/01 05:46:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8691	Prec@(1,5) (53.2%, 81.6%)
10/01 05:46:13午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 53.2000%
10/01 05:46:13午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:46:13午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.2000%
10/01 05:46:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8836 (0.8161)	Arch Loss 7.3629 (7.6669)	Arch Hard Loss 1.6120 (1.9159)	Arch Alpha Loss 11.5019 (11.5022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 96.1%)	
10/01 05:47:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.0675 (0.8172)	Arch Loss 7.8675 (7.6877)	Arch Hard Loss 2.1158 (1.9364)	Arch Alpha Loss 11.5032 (11.5026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.8%)	
10/01 05:47:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8569 (0.8436)	Arch Loss 7.7985 (7.6729)	Arch Hard Loss 2.0475 (1.9216)	Arch Alpha Loss 11.5021 (11.5026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.6%)	
10/01 05:48:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.8065 (0.8603)	Arch Loss 7.4289 (7.6637)	Arch Hard Loss 1.6775 (1.9124)	Arch Alpha Loss 11.5027 (11.5025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.3%)	
10/01 05:48:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 73.5320%
10/01 05:48:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8971	Prec@(1,5) (52.2%, 81.2%)
10/01 05:48:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8857	Prec@(1,5) (52.5%, 81.7%)
10/01 05:48:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8942	Prec@(1,5) (52.6%, 81.6%)
10/01 05:48:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8998	Prec@(1,5) (52.7%, 81.6%)
10/01 05:48:30午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 52.7200%
10/01 05:48:30午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:48:31午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.2000%
10/01 05:49:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8198 (0.7619)	Arch Loss 8.0934 (7.6201)	Arch Hard Loss 2.3418 (1.8685)	Arch Alpha Loss 11.5031 (11.5032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.0%)	
10/01 05:49:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8239 (0.7695)	Arch Loss 7.3722 (7.6427)	Arch Hard Loss 1.6204 (1.8912)	Arch Alpha Loss 11.5035 (11.5029)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 96.1%)	
10/01 05:50:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.7329 (0.7821)	Arch Loss 7.3276 (7.6611)	Arch Hard Loss 1.5754 (1.9095)	Arch Alpha Loss 11.5044 (11.5032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 96.0%)	
10/01 05:50:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.8237 (0.8027)	Arch Loss 7.5376 (7.6684)	Arch Hard Loss 1.7857 (1.9167)	Arch Alpha Loss 11.5037 (11.5034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.8%)	
10/01 05:50:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 75.4080%
10/01 05:50:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8755	Prec@(1,5) (54.0%, 82.5%)
10/01 05:50:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8927	Prec@(1,5) (53.6%, 82.1%)
10/01 05:50:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8881	Prec@(1,5) (53.7%, 82.2%)
10/01 05:50:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8915	Prec@(1,5) (53.5%, 82.2%)
10/01 05:50:44午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 53.4840%
10/01 05:50:44午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 05:50:45午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.4840%
10/01 05:51:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7186 (0.7020)	Arch Loss 7.3183 (7.6199)	Arch Hard Loss 1.5664 (1.8680)	Arch Alpha Loss 11.5038 (11.5039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.5%)	
10/01 05:51:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.4029 (0.7317)	Arch Loss 7.7767 (7.6479)	Arch Hard Loss 2.0250 (1.8960)	Arch Alpha Loss 11.5035 (11.5037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.4%)	
10/01 05:52:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.5940 (0.7399)	Arch Loss 7.4342 (7.6700)	Arch Hard Loss 1.6826 (1.9182)	Arch Alpha Loss 11.5032 (11.5037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.3%)	
10/01 05:52:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.4972 (0.7482)	Arch Loss 7.7279 (7.6820)	Arch Hard Loss 1.9761 (1.9301)	Arch Alpha Loss 11.5037 (11.5036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
10/01 05:52:42午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 77.0480%
10/01 05:52:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8914	Prec@(1,5) (53.8%, 82.3%)
10/01 05:52:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9150	Prec@(1,5) (53.5%, 82.4%)
10/01 05:52:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.8937	Prec@(1,5) (54.0%, 82.4%)
10/01 05:52:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.8943	Prec@(1,5) (54.0%, 82.4%)
10/01 05:52:59午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 54.0240%
10/01 05:52:59午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 05:53:00午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.0240%
10/01 05:53:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.6959 (0.6655)	Arch Loss 7.4986 (7.7720)	Arch Hard Loss 1.7461 (2.0197)	Arch Alpha Loss 11.5051 (11.5046)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.3%)	
10/01 05:54:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.7439 (0.6713)	Arch Loss 7.9667 (7.7290)	Arch Hard Loss 2.2146 (1.9767)	Arch Alpha Loss 11.5042 (11.5045)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 97.1%)	
10/01 05:54:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.8853 (0.6817)	Arch Loss 7.6294 (7.7175)	Arch Hard Loss 1.8772 (1.9653)	Arch Alpha Loss 11.5043 (11.5044)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.9%)	
10/01 05:54:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.6201 (0.6946)	Arch Loss 7.5131 (7.7110)	Arch Hard Loss 1.7614 (1.9589)	Arch Alpha Loss 11.5034 (11.5041)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.8%)	
10/01 05:54:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 78.3520%
10/01 05:55:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9275	Prec@(1,5) (54.3%, 82.1%)
10/01 05:55:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9149	Prec@(1,5) (54.0%, 82.3%)
10/01 05:55:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9184	Prec@(1,5) (54.1%, 82.1%)
10/01 05:55:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9117	Prec@(1,5) (54.1%, 82.2%)
10/01 05:55:16午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 54.1000%
10/01 05:55:16午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:55:16午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.1000%
10/01 05:55:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6521 (0.6085)	Arch Loss 7.7199 (7.7385)	Arch Hard Loss 1.9674 (1.9866)	Arch Alpha Loss 11.5050 (11.5039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.7%)	
10/01 05:56:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.6627 (0.6251)	Arch Loss 7.6328 (7.7132)	Arch Hard Loss 1.8806 (1.9611)	Arch Alpha Loss 11.5044 (11.5042)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.6%)	
10/01 05:56:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.6883 (0.6400)	Arch Loss 7.4637 (7.7171)	Arch Hard Loss 1.7113 (1.9649)	Arch Alpha Loss 11.5048 (11.5043)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.5%)	
10/01 05:57:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6922 (0.6516)	Arch Loss 7.8096 (7.7166)	Arch Hard Loss 2.0570 (1.9643)	Arch Alpha Loss 11.5053 (11.5045)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 97.4%)	
10/01 05:57:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 79.4480%
10/01 05:57:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.9206	Prec@(1,5) (54.0%, 82.6%)
10/01 05:57:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9374	Prec@(1,5) (54.4%, 82.5%)
10/01 05:57:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9212	Prec@(1,5) (54.8%, 82.7%)
10/01 05:57:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9236	Prec@(1,5) (54.8%, 82.5%)
10/01 05:57:34午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 54.7960%
10/01 05:57:34午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:57:34午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.7960%
10/01 05:58:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.4892 (0.5904)	Arch Loss 7.4296 (7.6701)	Arch Hard Loss 1.6764 (1.9173)	Arch Alpha Loss 11.5063 (11.5057)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.9%)	
10/01 05:58:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.5336 (0.5889)	Arch Loss 8.0433 (7.7045)	Arch Hard Loss 2.2903 (1.9515)	Arch Alpha Loss 11.5059 (11.5060)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.8%)	
10/01 05:59:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.6634 (0.5956)	Arch Loss 8.1822 (7.7059)	Arch Hard Loss 2.4290 (1.9528)	Arch Alpha Loss 11.5063 (11.5062)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.8%)	
10/01 05:59:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.3399 (0.5994)	Arch Loss 8.1610 (7.7223)	Arch Hard Loss 2.4070 (1.9691)	Arch Alpha Loss 11.5080 (11.5064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.7%)	
10/01 05:59:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 81.2640%
10/01 05:59:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.9031	Prec@(1,5) (55.2%, 83.0%)
10/01 05:59:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8940	Prec@(1,5) (55.3%, 82.9%)
10/01 05:59:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9173	Prec@(1,5) (55.0%, 82.7%)
10/01 05:59:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9299	Prec@(1,5) (54.8%, 82.5%)
10/01 05:59:49午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 54.8280%
10/01 05:59:49午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 05:59:49午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.8280%
10/01 06:00:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.4004 (0.5107)	Arch Loss 7.2187 (7.7108)	Arch Hard Loss 1.4645 (1.9567)	Arch Alpha Loss 11.5084 (11.5084)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.5%)	
10/01 06:00:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6267 (0.5278)	Arch Loss 7.4348 (7.7237)	Arch Hard Loss 1.6800 (1.9693)	Arch Alpha Loss 11.5095 (11.5088)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.3%)	
10/01 06:01:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.6816 (0.5412)	Arch Loss 7.9118 (7.7517)	Arch Hard Loss 2.1567 (1.9971)	Arch Alpha Loss 11.5102 (11.5092)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.1%)	
10/01 06:01:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.5687 (0.5522)	Arch Loss 7.8729 (7.7441)	Arch Hard Loss 2.1175 (1.9893)	Arch Alpha Loss 11.5109 (11.5096)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 98.0%)	
10/01 06:01:45午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 82.8760%
10/01 06:01:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9892	Prec@(1,5) (53.4%, 81.3%)
10/01 06:01:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9717	Prec@(1,5) (53.7%, 82.1%)
10/01 06:01:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9668	Prec@(1,5) (54.0%, 82.3%)
10/01 06:02:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9553	Prec@(1,5) (54.2%, 82.5%)
10/01 06:02:03午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 54.1480%
10/01 06:02:03午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:02:03午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.8280%
10/01 06:02:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.4629 (0.4789)	Arch Loss 7.8698 (7.7601)	Arch Hard Loss 2.1148 (2.0051)	Arch Alpha Loss 11.5100 (11.5099)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.5%)	
10/01 06:03:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.3200 (0.4828)	Arch Loss 8.1737 (7.7819)	Arch Hard Loss 2.4186 (2.0268)	Arch Alpha Loss 11.5101 (11.5101)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.5%)	
10/01 06:03:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.5386 (0.4946)	Arch Loss 7.2766 (7.7777)	Arch Hard Loss 1.5209 (2.0224)	Arch Alpha Loss 11.5115 (11.5104)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.4%)	
10/01 06:03:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.4104 (0.5005)	Arch Loss 8.1207 (7.7681)	Arch Hard Loss 2.3646 (2.0127)	Arch Alpha Loss 11.5121 (11.5107)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.3%)	
10/01 06:03:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 84.4640%
10/01 06:04:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9497	Prec@(1,5) (54.4%, 83.2%)
10/01 06:04:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.9393	Prec@(1,5) (54.9%, 83.2%)
10/01 06:04:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.9545	Prec@(1,5) (54.9%, 82.8%)
10/01 06:04:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.9538	Prec@(1,5) (54.9%, 82.7%)
10/01 06:04:16午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 54.9000%
10/01 06:04:16午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:04:16午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9000%
10/01 06:04:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6026 (0.4407)	Arch Loss 7.8521 (7.7007)	Arch Hard Loss 2.0960 (1.9444)	Arch Alpha Loss 11.5123 (11.5125)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
10/01 06:05:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.4626 (0.4512)	Arch Loss 7.6426 (7.7413)	Arch Hard Loss 1.8863 (1.9850)	Arch Alpha Loss 11.5125 (11.5126)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.5%)	
10/01 06:05:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4846 (0.4586)	Arch Loss 7.6131 (7.7641)	Arch Hard Loss 1.8559 (2.0077)	Arch Alpha Loss 11.5143 (11.5128)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.6%)	
10/01 06:06:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.2802 (0.4691)	Arch Loss 7.5667 (7.7613)	Arch Hard Loss 1.8101 (2.0048)	Arch Alpha Loss 11.5133 (11.5130)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
10/01 06:06:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 85.4680%
10/01 06:06:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9699	Prec@(1,5) (54.6%, 82.4%)
10/01 06:06:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9598	Prec@(1,5) (54.9%, 82.3%)
10/01 06:06:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.9717	Prec@(1,5) (55.0%, 82.5%)
10/01 06:06:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9583	Prec@(1,5) (55.3%, 82.8%)
10/01 06:06:31午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 55.3600%
10/01 06:06:31午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:06:32午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3600%
10/01 06:07:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.2148 (0.3993)	Arch Loss 7.8845 (7.8301)	Arch Hard Loss 2.1268 (2.0731)	Arch Alpha Loss 11.5155 (11.5140)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.7%, 99.1%)	
10/01 06:07:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4144 (0.4160)	Arch Loss 7.5517 (7.7822)	Arch Hard Loss 1.7945 (2.0250)	Arch Alpha Loss 11.5145 (11.5144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.9%)	
10/01 06:08:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5160 (0.4223)	Arch Loss 7.6185 (7.7910)	Arch Hard Loss 1.8619 (2.0339)	Arch Alpha Loss 11.5132 (11.5143)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.9%)	
10/01 06:08:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.4672 (0.4300)	Arch Loss 7.2529 (7.7764)	Arch Hard Loss 1.4963 (2.0194)	Arch Alpha Loss 11.5131 (11.5141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.8%)	
10/01 06:08:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 86.8280%
10/01 06:08:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.9683	Prec@(1,5) (54.9%, 82.7%)
10/01 06:08:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.9498	Prec@(1,5) (55.5%, 82.8%)
10/01 06:08:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.9790	Prec@(1,5) (54.9%, 82.5%)
10/01 06:08:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9697	Prec@(1,5) (55.1%, 82.7%)
10/01 06:08:49午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 55.1160%
10/01 06:08:49午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:08:49午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3600%
10/01 06:09:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.1912 (0.3815)	Arch Loss 7.5685 (7.7589)	Arch Hard Loss 1.8118 (2.0025)	Arch Alpha Loss 11.5135 (11.5129)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.3%)	
10/01 06:09:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.4264 (0.3850)	Arch Loss 7.6735 (7.7821)	Arch Hard Loss 1.9171 (2.0257)	Arch Alpha Loss 11.5128 (11.5130)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.2%)	
10/01 06:10:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.3721 (0.3936)	Arch Loss 7.9881 (7.7932)	Arch Hard Loss 2.2307 (2.0366)	Arch Alpha Loss 11.5148 (11.5133)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.1%)	
10/01 06:10:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.3278 (0.3962)	Arch Loss 7.5058 (7.8019)	Arch Hard Loss 1.7479 (2.0450)	Arch Alpha Loss 11.5157 (11.5138)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.9%, 99.0%)	
10/01 06:10:50午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 87.9360%
10/01 06:10:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.9992	Prec@(1,5) (54.8%, 82.8%)
10/01 06:10:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.9533	Prec@(1,5) (55.5%, 83.0%)
10/01 06:11:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9567	Prec@(1,5) (55.4%, 83.1%)
10/01 06:11:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.9646	Prec@(1,5) (55.3%, 83.0%)
10/01 06:11:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 55.3440%
10/01 06:11:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:11:08午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3600%
10/01 06:11:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.2647 (0.3556)	Arch Loss 7.8762 (7.7934)	Arch Hard Loss 2.1183 (2.0355)	Arch Alpha Loss 11.5158 (11.5158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.3%)	
10/01 06:12:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.3101 (0.3543)	Arch Loss 7.7747 (7.7832)	Arch Hard Loss 2.0168 (2.0253)	Arch Alpha Loss 11.5159 (11.5158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.2%)	
10/01 06:12:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5317 (0.3631)	Arch Loss 8.5612 (7.7805)	Arch Hard Loss 2.8033 (2.0225)	Arch Alpha Loss 11.5157 (11.5159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.2%)	
10/01 06:13:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.3606 (0.3682)	Arch Loss 7.5413 (7.7854)	Arch Hard Loss 1.7832 (2.0275)	Arch Alpha Loss 11.5161 (11.5158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.1%)	
10/01 06:13:08午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 89.1160%
10/01 06:13:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.0464	Prec@(1,5) (54.4%, 82.4%)
10/01 06:13:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.0057	Prec@(1,5) (55.2%, 82.6%)
10/01 06:13:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9965	Prec@(1,5) (55.3%, 82.6%)
10/01 06:13:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9920	Prec@(1,5) (55.3%, 82.8%)
10/01 06:13:26午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 55.2880%
10/01 06:13:26午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:13:26午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3600%
10/01 06:13:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.3237 (0.3238)	Arch Loss 8.2409 (7.7597)	Arch Hard Loss 2.4824 (2.0013)	Arch Alpha Loss 11.5169 (11.5166)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
10/01 06:14:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.3310 (0.3260)	Arch Loss 7.2031 (7.7806)	Arch Hard Loss 1.4443 (2.0221)	Arch Alpha Loss 11.5176 (11.5170)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
10/01 06:14:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.4837 (0.3294)	Arch Loss 7.4113 (7.8122)	Arch Hard Loss 1.6523 (2.0536)	Arch Alpha Loss 11.5180 (11.5173)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.1%, 99.4%)	
10/01 06:15:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.3056 (0.3372)	Arch Loss 7.9417 (7.8048)	Arch Hard Loss 2.1821 (2.0461)	Arch Alpha Loss 11.5192 (11.5176)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
10/01 06:15:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 89.8400%
10/01 06:15:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0401	Prec@(1,5) (55.7%, 82.7%)
10/01 06:15:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.0423	Prec@(1,5) (55.2%, 82.6%)
10/01 06:15:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.0180	Prec@(1,5) (55.4%, 82.7%)
10/01 06:15:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.0076	Prec@(1,5) (55.7%, 82.7%)
10/01 06:15:42午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 55.6880%
10/01 06:15:42午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:15:43午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.6880%
10/01 06:16:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.3604 (0.3109)	Arch Loss 7.0670 (7.8112)	Arch Hard Loss 1.3081 (2.0519)	Arch Alpha Loss 11.5178 (11.5186)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
10/01 06:16:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.2534 (0.3100)	Arch Loss 8.2698 (7.8064)	Arch Hard Loss 2.5113 (2.0473)	Arch Alpha Loss 11.5171 (11.5181)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.6%)	
10/01 06:17:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.2347 (0.3137)	Arch Loss 7.7592 (7.8146)	Arch Hard Loss 2.0000 (2.0557)	Arch Alpha Loss 11.5184 (11.5180)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.5%)	
10/01 06:17:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.3269 (0.3181)	Arch Loss 7.6430 (7.8160)	Arch Hard Loss 1.8832 (2.0569)	Arch Alpha Loss 11.5196 (11.5182)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
10/01 06:17:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 90.6440%
10/01 06:17:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.0377	Prec@(1,5) (55.5%, 82.0%)
10/01 06:17:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.0306	Prec@(1,5) (55.6%, 82.6%)
10/01 06:17:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.9948	Prec@(1,5) (56.0%, 83.0%)
10/01 06:18:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9971	Prec@(1,5) (55.8%, 83.0%)
10/01 06:18:00午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 55.8120%
10/01 06:18:00午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:18:00午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.8120%
10/01 06:18:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.2472 (0.2821)	Arch Loss 7.8493 (7.8006)	Arch Hard Loss 2.0890 (2.0404)	Arch Alpha Loss 11.5207 (11.5203)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.7%)	
10/01 06:19:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.2865 (0.2904)	Arch Loss 8.0296 (7.7961)	Arch Hard Loss 2.2695 (2.0360)	Arch Alpha Loss 11.5201 (11.5203)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.6%)	
10/01 06:19:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5095 (0.2946)	Arch Loss 8.2339 (7.8142)	Arch Hard Loss 2.4734 (2.0541)	Arch Alpha Loss 11.5209 (11.5203)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
10/01 06:20:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.2785 (0.3010)	Arch Loss 7.7883 (7.8273)	Arch Hard Loss 2.0275 (2.0671)	Arch Alpha Loss 11.5217 (11.5205)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
10/01 06:20:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 91.1800%
10/01 06:20:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.0460	Prec@(1,5) (54.7%, 82.3%)
10/01 06:20:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.0116	Prec@(1,5) (55.4%, 82.7%)
10/01 06:20:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.0006	Prec@(1,5) (55.8%, 82.9%)
10/01 06:20:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.0102	Prec@(1,5) (55.7%, 82.9%)
10/01 06:20:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 55.6880%
10/01 06:20:20午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:20:20午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.8120%
10/01 06:20:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.3054 (0.2821)	Arch Loss 7.5023 (7.8014)	Arch Hard Loss 1.7412 (2.0406)	Arch Alpha Loss 11.5223 (11.5216)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
10/01 06:21:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.2432 (0.2778)	Arch Loss 8.0763 (7.8072)	Arch Hard Loss 2.3152 (2.0462)	Arch Alpha Loss 11.5220 (11.5219)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
10/01 06:21:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.2671 (0.2836)	Arch Loss 8.9203 (7.8209)	Arch Hard Loss 3.1594 (2.0599)	Arch Alpha Loss 11.5218 (11.5220)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
10/01 06:22:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.1821 (0.2851)	Arch Loss 7.0197 (7.8413)	Arch Hard Loss 1.2582 (2.0802)	Arch Alpha Loss 11.5230 (11.5222)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
10/01 06:22:21午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 91.7320%
10/01 06:22:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.0201	Prec@(1,5) (55.4%, 83.2%)
10/01 06:22:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.0010	Prec@(1,5) (56.0%, 83.5%)
10/01 06:22:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.0140	Prec@(1,5) (55.8%, 83.2%)
10/01 06:22:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.0126	Prec@(1,5) (55.9%, 83.1%)
10/01 06:22:39午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 55.8280%
10/01 06:22:39午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:22:39午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.8280%
10/01 06:23:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.2172 (0.2701)	Arch Loss 7.2994 (7.8724)	Arch Hard Loss 1.5379 (2.1108)	Arch Alpha Loss 11.5230 (11.5233)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
10/01 06:23:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.2773 (0.2730)	Arch Loss 6.9436 (7.8623)	Arch Hard Loss 1.1813 (2.1006)	Arch Alpha Loss 11.5245 (11.5233)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
10/01 06:24:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3882 (0.2773)	Arch Loss 7.6703 (7.8425)	Arch Hard Loss 1.9085 (2.0807)	Arch Alpha Loss 11.5236 (11.5235)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
10/01 06:24:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.2487 (0.2778)	Arch Loss 7.1647 (7.8481)	Arch Hard Loss 1.4036 (2.0864)	Arch Alpha Loss 11.5223 (11.5234)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
10/01 06:24:37午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 92.0240%
10/01 06:24:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.0074	Prec@(1,5) (55.7%, 83.0%)
10/01 06:24:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.0309	Prec@(1,5) (55.6%, 82.8%)
10/01 06:24:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.0385	Prec@(1,5) (55.6%, 82.8%)
10/01 06:24:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.0277	Prec@(1,5) (55.7%, 83.0%)
10/01 06:24:55午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 55.6600%
10/01 06:24:55午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:24:55午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.8280%
10/01 06:25:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.2045 (0.2575)	Arch Loss 7.5828 (7.8745)	Arch Hard Loss 1.8208 (2.1127)	Arch Alpha Loss 11.5240 (11.5237)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
10/01 06:25:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.3017 (0.2597)	Arch Loss 7.3430 (7.8527)	Arch Hard Loss 1.5810 (2.0908)	Arch Alpha Loss 11.5239 (11.5238)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
10/01 06:26:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.1892 (0.2613)	Arch Loss 7.2999 (7.8447)	Arch Hard Loss 1.5383 (2.0828)	Arch Alpha Loss 11.5232 (11.5237)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.7%)	
10/01 06:26:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.3988 (0.2651)	Arch Loss 7.8940 (7.8495)	Arch Hard Loss 2.1326 (2.0878)	Arch Alpha Loss 11.5228 (11.5235)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
10/01 06:26:54午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 92.4480%
10/01 06:26:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.0258	Prec@(1,5) (56.1%, 83.4%)
10/01 06:27:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.9970	Prec@(1,5) (56.3%, 83.5%)
10/01 06:27:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.0174	Prec@(1,5) (55.9%, 83.2%)
10/01 06:27:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.0246	Prec@(1,5) (55.7%, 83.1%)
10/01 06:27:11午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 55.7200%
10/01 06:27:12午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:27:12午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.8280%
10/01 06:27:12午前 searchStage_KD_main.py:101 [INFO] Final best Prec@1 = 55.8280%
10/01 06:27:12午前 searchStage_KD_main.py:102 [INFO] Final Best Genotype = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
