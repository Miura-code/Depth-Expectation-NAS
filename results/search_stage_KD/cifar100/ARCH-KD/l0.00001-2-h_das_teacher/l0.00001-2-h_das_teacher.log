10/05 08:08:07AM parser.py:28 [INFO] 
10/05 08:08:07AM parser.py:29 [INFO] Parameters:
10/05 08:08:07AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.00001-2-h_das_teacher/DAG
10/05 08:08:07AM parser.py:31 [INFO] T=10.0
10/05 08:08:07AM parser.py:31 [INFO] ADVANCED=True
10/05 08:08:07AM parser.py:31 [INFO] ALPHA_LR=0.0003
10/05 08:08:07AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
10/05 08:08:07AM parser.py:31 [INFO] BATCH_SIZE=64
10/05 08:08:07AM parser.py:31 [INFO] CASCADE=False
10/05 08:08:07AM parser.py:31 [INFO] CHECKPOINT_RESET=False
10/05 08:08:07AM parser.py:31 [INFO] CUTOUT_LENGTH=0
10/05 08:08:07AM parser.py:31 [INFO] DATA_PATH=../data/
10/05 08:08:07AM parser.py:31 [INFO] DATASET=cifar100
10/05 08:08:07AM parser.py:31 [INFO] DEPTH_COEF=0.0
10/05 08:08:07AM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
10/05 08:08:07AM parser.py:31 [INFO] EPOCHS=50
10/05 08:08:07AM parser.py:31 [INFO] EXP_NAME=l0.00001-2-h_das_teacher
10/05 08:08:07AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
10/05 08:08:07AM parser.py:31 [INFO] GPUS=[0]
10/05 08:08:07AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
10/05 08:08:07AM parser.py:31 [INFO] INIT_CHANNELS=16
10/05 08:08:07AM parser.py:31 [INFO] L=1e-05
10/05 08:08:07AM parser.py:31 [INFO] LAYERS=20
10/05 08:08:07AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
10/05 08:08:07AM parser.py:31 [INFO] NAME=ARCH-KD
10/05 08:08:07AM parser.py:31 [INFO] NONKD=False
10/05 08:08:07AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.00001-2-h_das_teacher
10/05 08:08:07AM parser.py:31 [INFO] PCDARTS=False
10/05 08:08:07AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.00001-2-h_das_teacher/plots
10/05 08:08:07AM parser.py:31 [INFO] PRINT_FREQ=100
10/05 08:08:07AM parser.py:31 [INFO] RESUME_PATH=None
10/05 08:08:07AM parser.py:31 [INFO] SAVE=l0.00001-2-h_das_teacher
10/05 08:08:07AM parser.py:31 [INFO] SEED=0
10/05 08:08:07AM parser.py:31 [INFO] SHARE_STAGE=False
10/05 08:08:07AM parser.py:31 [INFO] SLIDE_WINDOW=8
10/05 08:08:07AM parser.py:31 [INFO] SPEC_CELL=True
10/05 08:08:07AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
10/05 08:08:07AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
10/05 08:08:07AM parser.py:31 [INFO] TRAIN_PORTION=0.5
10/05 08:08:07AM parser.py:31 [INFO] TYPE=ArchKD
10/05 08:08:07AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
10/05 08:08:07AM parser.py:31 [INFO] W_LR=0.025
10/05 08:08:07AM parser.py:31 [INFO] W_LR_MIN=0.001
10/05 08:08:07AM parser.py:31 [INFO] W_MOMENTUM=0.9
10/05 08:08:07AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
10/05 08:08:07AM parser.py:31 [INFO] WORKERS=4
10/05 08:08:07AM parser.py:32 [INFO] 
10/05 08:08:09AM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
10/05 08:08:09AM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
10/05 08:08:42AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.1121 (4.5336)	Arch Loss 4.3110 (4.5425)	Arch Hard Loss 4.3107 (4.5421)	Arch Alpha Loss 35.7315 (35.8830)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.5%, 11.4%)	
10/05 08:09:11AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1063 (4.3347)	Arch Loss 3.8599 (4.3197)	Arch Hard Loss 3.8596 (4.3193)	Arch Alpha Loss 35.6420 (35.7801)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (4.4%, 16.9%)	
10/05 08:09:41AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0917 (4.2123)	Arch Loss 3.8107 (4.2049)	Arch Hard Loss 3.8104 (4.2045)	Arch Alpha Loss 35.5545 (35.7126)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (5.4%, 20.4%)	
10/05 08:10:08AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.7643 (4.1400)	Arch Loss 3.7322 (4.1286)	Arch Hard Loss 3.7319 (4.1283)	Arch Alpha Loss 35.5515 (35.6781)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (6.2%, 22.1%)	
10/05 08:10:08AM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 6.1680%
10/05 08:10:13AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.8567	Prec@(1,5) (9.4%, 31.1%)
10/05 08:10:18AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.8638	Prec@(1,5) (9.4%, 31.0%)
10/05 08:10:22AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.8567	Prec@(1,5) (9.3%, 31.3%)
10/05 08:10:26AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.8468	Prec@(1,5) (9.3%, 31.4%)
10/05 08:10:27AM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 9.3280%
10/05 08:10:27AM searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 3)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 08:10:27AM searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 9.3280%
10/05 08:10:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6050 (3.8006)	Arch Loss 3.6881 (3.7856)	Arch Hard Loss 3.6877 (3.7853)	Arch Alpha Loss 35.6457 (35.6155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.0%, 32.7%)	
10/05 08:11:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.6195 (3.7452)	Arch Loss 3.7774 (3.7511)	Arch Hard Loss 3.7770 (3.7508)	Arch Alpha Loss 35.4280 (35.5702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.6%, 34.3%)	
10/05 08:11:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8766 (3.7237)	Arch Loss 3.5532 (3.7116)	Arch Hard Loss 3.5528 (3.7112)	Arch Alpha Loss 35.5874 (35.5371)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.9%, 34.9%)	
10/05 08:12:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.3780 (3.6803)	Arch Loss 3.4038 (3.6755)	Arch Hard Loss 3.4034 (3.6752)	Arch Alpha Loss 35.4667 (35.5457)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (12.5%, 36.1%)	
10/05 08:12:23午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 12.5120%
10/05 08:12:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6471	Prec@(1,5) (14.3%, 38.4%)
10/05 08:12:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6384	Prec@(1,5) (14.2%, 38.5%)
10/05 08:12:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6381	Prec@(1,5) (14.2%, 38.6%)
10/05 08:12:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6336	Prec@(1,5) (14.1%, 38.8%)
10/05 08:12:41午前 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 14.0920%
10/05 08:12:41午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 4)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 08:12:42午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 14.0920%
10/05 08:13:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.7956 (3.4830)	Arch Loss 3.6494 (3.5038)	Arch Hard Loss 3.6490 (3.5035)	Arch Alpha Loss 35.3284 (35.4148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (15.6%, 41.7%)	
10/05 08:13:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.3287 (3.4542)	Arch Loss 3.5631 (3.4697)	Arch Hard Loss 3.5627 (3.4694)	Arch Alpha Loss 35.2447 (35.3363)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (16.1%, 42.8%)	
10/05 08:14:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.1569 (3.4072)	Arch Loss 3.1445 (3.4206)	Arch Hard Loss 3.1442 (3.4203)	Arch Alpha Loss 35.1866 (35.3057)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (17.2%, 44.2%)	
10/05 08:14:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4525 (3.3790)	Arch Loss 3.3456 (3.3840)	Arch Hard Loss 3.3453 (3.3836)	Arch Alpha Loss 35.1968 (35.2770)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (17.7%, 45.2%)	
10/05 08:14:40午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 17.7160%
10/05 08:14:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3028	Prec@(1,5) (19.4%, 47.5%)
10/05 08:14:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3176	Prec@(1,5) (18.8%, 46.6%)
10/05 08:14:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3222	Prec@(1,5) (18.7%, 46.7%)
10/05 08:14:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3304	Prec@(1,5) (18.7%, 46.5%)
10/05 08:14:57午前 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 18.6920%
10/05 08:14:57午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 08:14:58午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 18.6920%
10/05 08:15:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.1615 (3.2068)	Arch Loss 3.0250 (3.2233)	Arch Hard Loss 3.0247 (3.2230)	Arch Alpha Loss 34.9662 (35.0605)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.5%)	
10/05 08:15:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.2005 (3.1872)	Arch Loss 3.1039 (3.2029)	Arch Hard Loss 3.1035 (3.2026)	Arch Alpha Loss 34.8745 (34.9882)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.2%)	
10/05 08:16:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1311 (3.1598)	Arch Loss 3.0309 (3.1811)	Arch Hard Loss 3.0306 (3.1807)	Arch Alpha Loss 34.7641 (34.9254)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (21.2%, 51.2%)	
10/05 08:16:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.1839 (3.1426)	Arch Loss 3.3781 (3.1646)	Arch Hard Loss 3.3777 (3.1642)	Arch Alpha Loss 34.5597 (34.8763)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (21.4%, 51.7%)	
10/05 08:16:56午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 21.4280%
10/05 08:17:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.0835	Prec@(1,5) (23.2%, 53.7%)
10/05 08:17:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.0867	Prec@(1,5) (23.2%, 53.7%)
10/05 08:17:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.0944	Prec@(1,5) (23.2%, 53.3%)
10/05 08:17:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.0956	Prec@(1,5) (23.1%, 53.2%)
10/05 08:17:14午前 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 23.0360%
10/05 08:17:14午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 08:17:14午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 23.0360%
10/05 08:17:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.6183 (2.9739)	Arch Loss 2.7586 (3.0578)	Arch Hard Loss 2.7582 (3.0575)	Arch Alpha Loss 34.3525 (34.4784)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (25.3%, 56.4%)	
10/05 08:18:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.6715 (2.9623)	Arch Loss 3.0299 (3.0295)	Arch Hard Loss 3.0295 (3.0292)	Arch Alpha Loss 34.1923 (34.3406)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (25.4%, 56.5%)	
10/05 08:18:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.0517 (2.9417)	Arch Loss 2.8603 (3.0120)	Arch Hard Loss 2.8600 (3.0117)	Arch Alpha Loss 33.9656 (34.2697)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.9%)	
10/05 08:19:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.7744 (2.9314)	Arch Loss 3.0607 (2.9847)	Arch Hard Loss 3.0604 (2.9844)	Arch Alpha Loss 34.0210 (34.2124)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (26.0%, 57.2%)	
10/05 08:19:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 25.9840%
10/05 08:19:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.9236	Prec@(1,5) (26.4%, 56.8%)
10/05 08:19:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9308	Prec@(1,5) (26.5%, 56.7%)
10/05 08:19:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9520	Prec@(1,5) (26.0%, 56.4%)
10/05 08:19:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9575	Prec@(1,5) (25.9%, 56.3%)
10/05 08:19:29午前 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 25.8560%
10/05 08:19:29午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 08:19:29午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 25.8560%
10/05 08:20:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.6260 (2.7631)	Arch Loss 2.6490 (2.8680)	Arch Hard Loss 2.6486 (2.8677)	Arch Alpha Loss 33.7425 (33.8863)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (29.4%, 61.1%)	
10/05 08:20:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0334 (2.7615)	Arch Loss 2.6033 (2.8547)	Arch Hard Loss 2.6030 (2.8544)	Arch Alpha Loss 33.6264 (33.7688)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (29.4%, 61.0%)	
10/05 08:20:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.4727 (2.7630)	Arch Loss 2.7481 (2.8385)	Arch Hard Loss 2.7478 (2.8381)	Arch Alpha Loss 33.6678 (33.7226)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 60.9%)	
10/05 08:21:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6697 (2.7472)	Arch Loss 2.5141 (2.8179)	Arch Hard Loss 2.5138 (2.8175)	Arch Alpha Loss 33.6407 (33.7063)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.4%, 61.4%)	
10/05 08:21:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 29.3680%
10/05 08:21:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.7513	Prec@(1,5) (29.7%, 61.5%)
10/05 08:21:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.7745	Prec@(1,5) (29.5%, 61.6%)
10/05 08:21:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.7801	Prec@(1,5) (29.1%, 61.4%)
10/05 08:21:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.7870	Prec@(1,5) (29.0%, 61.1%)
10/05 08:21:43午前 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 28.9520%
10/05 08:21:43午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 08:21:43午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 28.9520%
10/05 08:22:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8820 (2.6090)	Arch Loss 2.6948 (2.7235)	Arch Hard Loss 2.6944 (2.7231)	Arch Alpha Loss 33.5492 (33.6327)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.3%, 64.8%)	
10/05 08:22:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.3111 (2.6103)	Arch Loss 2.6868 (2.7315)	Arch Hard Loss 2.6865 (2.7312)	Arch Alpha Loss 33.4539 (33.5514)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.8%)	
10/05 08:23:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.8970 (2.5984)	Arch Loss 2.6786 (2.6977)	Arch Hard Loss 2.6783 (2.6974)	Arch Alpha Loss 33.5403 (33.5397)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.2%, 65.1%)	
10/05 08:23:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7335 (2.5893)	Arch Loss 2.3927 (2.6840)	Arch Hard Loss 2.3923 (2.6836)	Arch Alpha Loss 33.5806 (33.5427)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.6%, 65.1%)	
10/05 08:23:36午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 32.6200%
10/05 08:23:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6558	Prec@(1,5) (31.1%, 64.2%)
10/05 08:23:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6458	Prec@(1,5) (31.7%, 64.4%)
10/05 08:23:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6362	Prec@(1,5) (32.0%, 64.7%)
10/05 08:23:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6366	Prec@(1,5) (32.2%, 64.6%)
10/05 08:23:54午前 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 32.1760%
10/05 08:23:54午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 08:23:54午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 32.1760%
10/05 08:24:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.4387 (2.4616)	Arch Loss 2.4936 (2.6021)	Arch Hard Loss 2.4933 (2.6018)	Arch Alpha Loss 33.5726 (33.5447)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.7%, 68.3%)	
10/05 08:24:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4160 (2.4418)	Arch Loss 2.2612 (2.5825)	Arch Hard Loss 2.2608 (2.5822)	Arch Alpha Loss 33.4702 (33.5540)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 68.6%)	
10/05 08:25:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7070 (2.4460)	Arch Loss 2.8044 (2.5864)	Arch Hard Loss 2.8041 (2.5860)	Arch Alpha Loss 33.4860 (33.5274)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 68.5%)	
10/05 08:25:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.4404 (2.4440)	Arch Loss 2.2873 (2.5585)	Arch Hard Loss 2.2870 (2.5582)	Arch Alpha Loss 33.7315 (33.5470)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 68.4%)	
10/05 08:25:54午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 35.2520%
10/05 08:25:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5666	Prec@(1,5) (33.8%, 65.6%)
10/05 08:26:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5555	Prec@(1,5) (33.9%, 66.2%)
10/05 08:26:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5387	Prec@(1,5) (34.1%, 66.4%)
10/05 08:26:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5429	Prec@(1,5) (34.0%, 66.3%)
10/05 08:26:12午前 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 34.0040%
10/05 08:26:12午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:26:12午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 34.0040%
10/05 08:26:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 1.9772 (2.3210)	Arch Loss 2.3336 (2.5082)	Arch Hard Loss 2.3333 (2.5079)	Arch Alpha Loss 33.7713 (33.7466)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 71.3%)	
10/05 08:27:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.2464 (2.3269)	Arch Loss 2.4515 (2.4964)	Arch Hard Loss 2.4512 (2.4960)	Arch Alpha Loss 33.7839 (33.7935)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 71.2%)	
10/05 08:27:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2853 (2.3312)	Arch Loss 2.2586 (2.4816)	Arch Hard Loss 2.2583 (2.4813)	Arch Alpha Loss 33.8974 (33.8029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.1%, 71.2%)	
10/05 08:28:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.3132 (2.3288)	Arch Loss 2.2607 (2.4719)	Arch Hard Loss 2.2603 (2.4715)	Arch Alpha Loss 34.1386 (33.8519)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.1%)	
10/05 08:28:10午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 38.2640%
10/05 08:28:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4048	Prec@(1,5) (36.2%, 69.5%)
10/05 08:28:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4223	Prec@(1,5) (36.9%, 69.4%)
10/05 08:28:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4266	Prec@(1,5) (36.8%, 69.2%)
10/05 08:28:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4310	Prec@(1,5) (36.6%, 69.0%)
10/05 08:28:28午前 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 36.5960%
10/05 08:28:28午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:28:29午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 36.5960%
10/05 08:29:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.6157 (2.1859)	Arch Loss 2.9572 (2.3833)	Arch Hard Loss 2.9568 (2.3829)	Arch Alpha Loss 34.3335 (34.2684)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.2%, 73.8%)	
10/05 08:29:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 1.9093 (2.2052)	Arch Loss 2.3981 (2.3870)	Arch Hard Loss 2.3978 (2.3866)	Arch Alpha Loss 34.3877 (34.3163)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 73.4%)	
10/05 08:30:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 1.9332 (2.2138)	Arch Loss 2.4433 (2.3685)	Arch Hard Loss 2.4430 (2.3682)	Arch Alpha Loss 34.3776 (34.3364)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.2%, 73.3%)	
10/05 08:30:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.2029 (2.2100)	Arch Loss 2.4150 (2.3563)	Arch Hard Loss 2.4146 (2.3560)	Arch Alpha Loss 34.5202 (34.3584)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 73.6%)	
10/05 08:30:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 41.0960%
10/05 08:30:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4037	Prec@(1,5) (37.4%, 70.0%)
10/05 08:30:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3689	Prec@(1,5) (38.2%, 70.6%)
10/05 08:30:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3578	Prec@(1,5) (38.5%, 70.8%)
10/05 08:30:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3551	Prec@(1,5) (38.4%, 70.8%)
10/05 08:30:44午前 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 38.3920%
10/05 08:30:44午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:30:45午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 38.3920%
10/05 08:31:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.2829 (2.0499)	Arch Loss 1.9700 (2.3282)	Arch Hard Loss 1.9697 (2.3278)	Arch Alpha Loss 34.8162 (34.6906)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 76.8%)	
10/05 08:31:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 1.8508 (2.0840)	Arch Loss 2.4856 (2.3134)	Arch Hard Loss 2.4852 (2.3130)	Arch Alpha Loss 35.0096 (34.8024)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 76.0%)	
10/05 08:32:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.9267 (2.0979)	Arch Loss 2.0559 (2.2953)	Arch Hard Loss 2.0556 (2.2949)	Arch Alpha Loss 35.1700 (34.8922)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.8%)	
10/05 08:32:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.2551 (2.1148)	Arch Loss 2.3114 (2.2856)	Arch Hard Loss 2.3111 (2.2853)	Arch Alpha Loss 35.3362 (34.9713)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.3%)	
10/05 08:32:41午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 42.8920%
10/05 08:32:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.2833	Prec@(1,5) (39.8%, 71.7%)
10/05 08:32:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.2689	Prec@(1,5) (40.3%, 72.6%)
10/05 08:32:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.2487	Prec@(1,5) (40.6%, 72.9%)
10/05 08:32:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.2474	Prec@(1,5) (40.6%, 72.9%)
10/05 08:32:58午前 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 40.5680%
10/05 08:32:58午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:32:59午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 40.5680%
10/05 08:33:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2055 (2.0028)	Arch Loss 2.1465 (2.2813)	Arch Hard Loss 2.1462 (2.2809)	Arch Alpha Loss 35.4185 (35.3491)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 77.6%)	
10/05 08:34:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.2653 (2.0155)	Arch Loss 2.2100 (2.2457)	Arch Hard Loss 2.2097 (2.2453)	Arch Alpha Loss 35.6274 (35.4558)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.9%, 77.2%)	
10/05 08:34:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.3442 (2.0243)	Arch Loss 2.1949 (2.2284)	Arch Hard Loss 2.1946 (2.2281)	Arch Alpha Loss 35.8406 (35.5390)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.8%, 77.2%)	
10/05 08:34:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.8674 (2.0225)	Arch Loss 2.2140 (2.2292)	Arch Hard Loss 2.2137 (2.2288)	Arch Alpha Loss 35.9483 (35.6173)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.2%)	
10/05 08:34:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 44.9920%
10/05 08:35:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.2613	Prec@(1,5) (40.6%, 72.6%)
10/05 08:35:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2417	Prec@(1,5) (40.7%, 73.1%)
10/05 08:35:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2333	Prec@(1,5) (41.0%, 73.5%)
10/05 08:35:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2213	Prec@(1,5) (41.0%, 73.7%)
10/05 08:35:16午前 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 41.0160%
10/05 08:35:16午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:35:17午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 41.0160%
10/05 08:35:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.5816 (1.8993)	Arch Loss 2.4188 (2.2021)	Arch Hard Loss 2.4184 (2.2018)	Arch Alpha Loss 36.0848 (35.9897)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.1%)	
10/05 08:36:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.7606 (1.9191)	Arch Loss 2.6636 (2.1962)	Arch Hard Loss 2.6633 (2.1958)	Arch Alpha Loss 36.2439 (36.0740)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.0%)	
10/05 08:36:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.0648 (1.9285)	Arch Loss 1.8055 (2.1697)	Arch Hard Loss 1.8051 (2.1693)	Arch Alpha Loss 36.4258 (36.1506)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 78.9%)	
10/05 08:37:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.7897 (1.9327)	Arch Loss 2.1551 (2.1675)	Arch Hard Loss 2.1547 (2.1671)	Arch Alpha Loss 36.5530 (36.2318)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.8%)	
10/05 08:37:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 46.7360%
10/05 08:37:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.1761	Prec@(1,5) (42.2%, 74.7%)
10/05 08:37:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1388	Prec@(1,5) (43.2%, 75.4%)
10/05 08:37:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1481	Prec@(1,5) (43.3%, 75.0%)
10/05 08:37:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1484	Prec@(1,5) (43.0%, 75.2%)
10/05 08:37:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 43.0280%
10/05 08:37:32午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:37:33午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 43.0280%
10/05 08:38:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.0330 (1.8172)	Arch Loss 2.3102 (2.1482)	Arch Hard Loss 2.3099 (2.1479)	Arch Alpha Loss 36.5513 (36.5215)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.3%, 81.0%)	
10/05 08:38:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.3446 (1.8336)	Arch Loss 1.8937 (2.1555)	Arch Hard Loss 1.8934 (2.1551)	Arch Alpha Loss 36.6982 (36.5756)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.5%)	
10/05 08:39:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.1250 (1.8466)	Arch Loss 1.6977 (2.1321)	Arch Hard Loss 1.6973 (2.1317)	Arch Alpha Loss 36.8622 (36.6441)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.4%)	
10/05 08:39:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0210 (1.8602)	Arch Loss 1.9967 (2.1242)	Arch Hard Loss 1.9963 (2.1239)	Arch Alpha Loss 37.1180 (36.7300)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.2%)	
10/05 08:39:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 48.7640%
10/05 08:39:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1047	Prec@(1,5) (44.6%, 75.7%)
10/05 08:39:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1465	Prec@(1,5) (43.3%, 75.1%)
10/05 08:39:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1333	Prec@(1,5) (43.6%, 75.2%)
10/05 08:39:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1365	Prec@(1,5) (43.5%, 75.2%)
10/05 08:39:50午前 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 43.5360%
10/05 08:39:50午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:39:50午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 43.5360%
10/05 08:40:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.7828 (1.7859)	Arch Loss 1.7861 (2.0608)	Arch Hard Loss 1.7857 (2.0604)	Arch Alpha Loss 37.3779 (37.2669)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.8%)	
10/05 08:40:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.7001 (1.7833)	Arch Loss 1.9280 (2.0839)	Arch Hard Loss 1.9277 (2.0835)	Arch Alpha Loss 37.5749 (37.3614)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.6%)	
10/05 08:41:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.8113 (1.7777)	Arch Loss 2.3501 (2.0683)	Arch Hard Loss 2.3497 (2.0680)	Arch Alpha Loss 37.6611 (37.4544)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.7%)	
10/05 08:41:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.2890 (1.7882)	Arch Loss 1.9158 (2.0742)	Arch Hard Loss 1.9155 (2.0738)	Arch Alpha Loss 37.8442 (37.5197)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.5%)	
10/05 08:41:51午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 50.3880%
10/05 08:41:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.0708	Prec@(1,5) (45.3%, 76.7%)
10/05 08:42:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.0583	Prec@(1,5) (45.5%, 76.9%)
10/05 08:42:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0529	Prec@(1,5) (45.5%, 77.0%)
10/05 08:42:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0573	Prec@(1,5) (45.5%, 76.9%)
10/05 08:42:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 45.4720%
10/05 08:42:08午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:42:09午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 45.4720%
10/05 08:42:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.6333 (1.6913)	Arch Loss 1.7855 (2.0113)	Arch Hard Loss 1.7851 (2.0109)	Arch Alpha Loss 37.9714 (37.9190)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.3%)	
10/05 08:43:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.7942 (1.6902)	Arch Loss 1.8189 (2.0216)	Arch Hard Loss 1.8185 (2.0212)	Arch Alpha Loss 38.2611 (37.9667)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.3%)	
10/05 08:43:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.7848 (1.7068)	Arch Loss 1.9917 (2.0279)	Arch Hard Loss 1.9913 (2.0275)	Arch Alpha Loss 38.6468 (38.1487)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.1%, 83.1%)	
10/05 08:44:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.7842 (1.7191)	Arch Loss 2.3841 (2.0317)	Arch Hard Loss 2.3837 (2.0313)	Arch Alpha Loss 38.5845 (38.2555)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.9%)	
10/05 08:44:08午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 51.6600%
10/05 08:44:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0166	Prec@(1,5) (46.3%, 77.7%)
10/05 08:44:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0109	Prec@(1,5) (46.1%, 77.6%)
10/05 08:44:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0203	Prec@(1,5) (45.8%, 77.8%)
10/05 08:44:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0190	Prec@(1,5) (45.8%, 77.8%)
10/05 08:44:25午前 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 45.8400%
10/05 08:44:25午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:44:26午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 45.8400%
10/05 08:44:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.6871 (1.6476)	Arch Loss 2.0339 (2.0025)	Arch Hard Loss 2.0335 (2.0021)	Arch Alpha Loss 38.5854 (38.5405)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.6%)	
10/05 08:45:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9348 (1.6536)	Arch Loss 1.7225 (2.0042)	Arch Hard Loss 1.7221 (2.0038)	Arch Alpha Loss 38.8332 (38.6424)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.7%, 83.8%)	
10/05 08:45:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.8798 (1.6697)	Arch Loss 1.5434 (2.0094)	Arch Hard Loss 1.5430 (2.0090)	Arch Alpha Loss 39.1429 (38.7567)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.4%, 83.5%)	
10/05 08:46:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7872 (1.6696)	Arch Loss 2.5232 (2.0145)	Arch Hard Loss 2.5228 (2.0141)	Arch Alpha Loss 39.3516 (38.8705)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.5%)	
10/05 08:46:24午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 53.2280%
10/05 08:46:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 1.9636	Prec@(1,5) (47.4%, 78.8%)
10/05 08:46:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 1.9722	Prec@(1,5) (47.1%, 78.6%)
10/05 08:46:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 1.9701	Prec@(1,5) (47.2%, 78.7%)
10/05 08:46:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 1.9684	Prec@(1,5) (47.2%, 78.6%)
10/05 08:46:41午前 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 47.2400%
10/05 08:46:41午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:46:42午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 47.2400%
10/05 08:47:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.7201 (1.5846)	Arch Loss 2.5326 (1.9938)	Arch Hard Loss 2.5322 (1.9934)	Arch Alpha Loss 39.6596 (39.5251)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.5%, 85.3%)	
10/05 08:47:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.3821 (1.6010)	Arch Loss 1.8549 (1.9900)	Arch Hard Loss 1.8545 (1.9896)	Arch Alpha Loss 40.1662 (39.7277)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.9%)	
10/05 08:48:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.0031 (1.6107)	Arch Loss 1.9831 (1.9850)	Arch Hard Loss 1.9827 (1.9846)	Arch Alpha Loss 40.3057 (39.9206)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.7%)	
10/05 08:48:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.8704 (1.6161)	Arch Loss 1.6410 (1.9791)	Arch Hard Loss 1.6406 (1.9787)	Arch Alpha Loss 40.5697 (40.0395)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.5%)	
10/05 08:48:41午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 53.9160%
10/05 08:48:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0186	Prec@(1,5) (46.7%, 77.3%)
10/05 08:48:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0106	Prec@(1,5) (46.3%, 77.9%)
10/05 08:48:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9994	Prec@(1,5) (46.6%, 78.3%)
10/05 08:48:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9961	Prec@(1,5) (46.8%, 78.2%)
10/05 08:48:58午前 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 46.8080%
10/05 08:48:58午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:48:59午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 47.2400%
10/05 08:49:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.9391 (1.4921)	Arch Loss 1.9320 (1.9653)	Arch Hard Loss 1.9316 (1.9649)	Arch Alpha Loss 41.0059 (40.7806)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.8%)	
10/05 08:50:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.5620 (1.5294)	Arch Loss 1.7444 (1.9753)	Arch Hard Loss 1.7439 (1.9749)	Arch Alpha Loss 41.2514 (40.9845)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.1%)	
10/05 08:50:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.5775 (1.5329)	Arch Loss 2.1456 (1.9736)	Arch Hard Loss 2.1452 (1.9731)	Arch Alpha Loss 41.4340 (41.1144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.1%)	
10/05 08:50:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.6433 (1.5493)	Arch Loss 1.6120 (1.9628)	Arch Hard Loss 1.6116 (1.9624)	Arch Alpha Loss 41.5405 (41.2110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.7%)	
10/05 08:50:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 55.9480%
10/05 08:51:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9845	Prec@(1,5) (48.1%, 77.9%)
10/05 08:51:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9835	Prec@(1,5) (48.0%, 78.1%)
10/05 08:51:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9816	Prec@(1,5) (47.7%, 78.2%)
10/05 08:51:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9742	Prec@(1,5) (47.8%, 78.2%)
10/05 08:51:15午前 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 47.7480%
10/05 08:51:15午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:51:15午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 47.7480%
10/05 08:51:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.5455 (1.4393)	Arch Loss 2.1854 (1.9209)	Arch Hard Loss 2.1850 (1.9204)	Arch Alpha Loss 41.6193 (41.6214)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.2%)	
10/05 08:52:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.5928 (1.4615)	Arch Loss 2.0287 (1.9367)	Arch Hard Loss 2.0283 (1.9363)	Arch Alpha Loss 42.0015 (41.7052)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.8%, 87.0%)	
10/05 08:52:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.3183 (1.4786)	Arch Loss 1.8025 (1.9340)	Arch Hard Loss 1.8020 (1.9336)	Arch Alpha Loss 42.2240 (41.8386)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.7%)	
10/05 08:53:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.1244 (1.4926)	Arch Loss 2.2606 (1.9304)	Arch Hard Loss 2.2602 (1.9300)	Arch Alpha Loss 42.4743 (41.9547)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.5%)	
10/05 08:53:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 57.1360%
10/05 08:53:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.8912	Prec@(1,5) (49.6%, 79.3%)
10/05 08:53:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.8909	Prec@(1,5) (49.7%, 79.5%)
10/05 08:53:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.8812	Prec@(1,5) (50.0%, 79.9%)
10/05 08:53:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.8746	Prec@(1,5) (50.1%, 80.0%)
10/05 08:53:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 50.1320%
10/05 08:53:32午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:53:32午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.1320%
10/05 08:54:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.3607 (1.3530)	Arch Loss 2.0160 (1.9353)	Arch Hard Loss 2.0156 (1.9349)	Arch Alpha Loss 42.7953 (42.6670)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.6%)	
10/05 08:54:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.6573 (1.4016)	Arch Loss 2.1483 (1.9144)	Arch Hard Loss 2.1479 (1.9140)	Arch Alpha Loss 43.0217 (42.7798)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.1%)	
10/05 08:55:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.7681 (1.4179)	Arch Loss 2.2754 (1.9056)	Arch Hard Loss 2.2750 (1.9051)	Arch Alpha Loss 43.1343 (42.8731)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.7%)	
10/05 08:55:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4417 (1.4264)	Arch Loss 1.8699 (1.9073)	Arch Hard Loss 1.8694 (1.9068)	Arch Alpha Loss 43.3432 (42.9459)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.5%)	
10/05 08:55:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 59.2760%
10/05 08:55:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9340	Prec@(1,5) (48.9%, 79.6%)
10/05 08:55:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9310	Prec@(1,5) (48.7%, 79.6%)
10/05 08:55:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9270	Prec@(1,5) (48.7%, 79.7%)
10/05 08:55:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9203	Prec@(1,5) (48.8%, 79.8%)
10/05 08:55:49午前 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 48.7800%
10/05 08:55:49午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 08:55:49午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.1320%
10/05 08:56:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.6155 (1.3591)	Arch Loss 1.6330 (1.9092)	Arch Hard Loss 1.6326 (1.9088)	Arch Alpha Loss 43.5623 (43.4240)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.4%)	
10/05 08:56:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4162 (1.3738)	Arch Loss 1.7649 (1.9163)	Arch Hard Loss 1.7645 (1.9159)	Arch Alpha Loss 43.9088 (43.5764)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.1%)	
10/05 08:57:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.2471 (1.3789)	Arch Loss 2.0548 (1.8945)	Arch Hard Loss 2.0544 (1.8941)	Arch Alpha Loss 44.2406 (43.7495)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.0%)	
10/05 08:57:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.4046 (1.3954)	Arch Loss 1.7037 (1.8892)	Arch Hard Loss 1.7032 (1.8888)	Arch Alpha Loss 44.6853 (43.9156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.8%)	
10/05 08:57:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 59.9480%
10/05 08:57:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.8852	Prec@(1,5) (49.9%, 79.7%)
10/05 08:57:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.8530	Prec@(1,5) (50.5%, 80.2%)
10/05 08:58:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.8357	Prec@(1,5) (50.7%, 80.7%)
10/05 08:58:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.8419	Prec@(1,5) (50.8%, 80.7%)
10/05 08:58:06午前 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 50.7520%
10/05 08:58:06午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 08:58:06午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.7520%
10/05 08:58:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.2466 (1.2586)	Arch Loss 2.2238 (1.8675)	Arch Hard Loss 2.2233 (1.8670)	Arch Alpha Loss 45.2184 (44.8809)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.2%)	
10/05 08:59:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4352 (1.3125)	Arch Loss 2.0760 (1.8773)	Arch Hard Loss 2.0756 (1.8768)	Arch Alpha Loss 45.6194 (45.1368)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.1%)	
10/05 08:59:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4147 (1.3230)	Arch Loss 1.8934 (1.8750)	Arch Hard Loss 1.8930 (1.8745)	Arch Alpha Loss 46.0329 (45.3702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.9%)	
10/05 09:00:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.0933 (1.3331)	Arch Loss 1.5011 (1.8714)	Arch Hard Loss 1.5006 (1.8710)	Arch Alpha Loss 46.2678 (45.5517)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.7%)	
10/05 09:00:06午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 61.4560%
10/05 09:00:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9184	Prec@(1,5) (49.2%, 79.7%)
10/05 09:00:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9128	Prec@(1,5) (49.7%, 79.9%)
10/05 09:00:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8898	Prec@(1,5) (50.1%, 80.2%)
10/05 09:00:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8909	Prec@(1,5) (50.1%, 80.3%)
10/05 09:00:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 50.1240%
10/05 09:00:24午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 09:00:24午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.7520%
10/05 09:00:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.1639 (1.2140)	Arch Loss 1.7034 (1.8356)	Arch Hard Loss 1.7030 (1.8351)	Arch Alpha Loss 46.7876 (46.5438)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.7%)	
10/05 09:01:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.1563 (1.2527)	Arch Loss 1.9502 (1.8448)	Arch Hard Loss 1.9497 (1.8443)	Arch Alpha Loss 47.2583 (46.7675)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.6%, 90.2%)	
10/05 09:01:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2425 (1.2697)	Arch Loss 1.8303 (1.8531)	Arch Hard Loss 1.8298 (1.8526)	Arch Alpha Loss 47.6182 (46.9817)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.9%)	
10/05 09:02:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4819 (1.2795)	Arch Loss 2.1091 (1.8559)	Arch Hard Loss 2.1086 (1.8555)	Arch Alpha Loss 48.0030 (47.1814)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.5%)	
10/05 09:02:24午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 63.0400%
10/05 09:02:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8255	Prec@(1,5) (51.4%, 81.9%)
10/05 09:02:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8570	Prec@(1,5) (50.8%, 81.3%)
10/05 09:02:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8663	Prec@(1,5) (50.8%, 81.1%)
10/05 09:02:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8533	Prec@(1,5) (51.2%, 81.4%)
10/05 09:02:41午前 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 51.1920%
10/05 09:02:41午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 09:02:42午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 51.1920%
10/05 09:03:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.2891 (1.1790)	Arch Loss 1.8079 (1.8242)	Arch Hard Loss 1.8075 (1.8237)	Arch Alpha Loss 48.5766 (48.2842)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.8%, 91.0%)	
10/05 09:03:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3049 (1.1930)	Arch Loss 2.7143 (1.8351)	Arch Hard Loss 2.7138 (1.8346)	Arch Alpha Loss 48.9721 (48.5330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.8%)	
10/05 09:04:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3615 (1.2199)	Arch Loss 1.9536 (1.8372)	Arch Hard Loss 1.9531 (1.8367)	Arch Alpha Loss 49.2654 (48.7361)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
10/05 09:04:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.5888 (1.2362)	Arch Loss 1.8580 (1.8349)	Arch Hard Loss 1.8575 (1.8345)	Arch Alpha Loss 49.5919 (48.8866)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.2%)	
10/05 09:04:41午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 63.8680%
10/05 09:04:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8907	Prec@(1,5) (50.6%, 80.3%)
10/05 09:04:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8782	Prec@(1,5) (50.9%, 80.6%)
10/05 09:04:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8686	Prec@(1,5) (50.9%, 80.8%)
10/05 09:04:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8678	Prec@(1,5) (50.9%, 80.9%)
10/05 09:04:59午前 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 50.8880%
10/05 09:04:59午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 09:04:59午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 51.1920%
10/05 09:05:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.2565 (1.1447)	Arch Loss 1.9149 (1.7484)	Arch Hard Loss 1.9144 (1.7479)	Arch Alpha Loss 50.2481 (49.9580)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.5%)	
10/05 09:06:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.1939 (1.1530)	Arch Loss 1.7501 (1.8003)	Arch Hard Loss 1.7496 (1.7998)	Arch Alpha Loss 50.8365 (50.2693)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.4%)	
10/05 09:06:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.2568 (1.1773)	Arch Loss 2.0232 (1.8129)	Arch Hard Loss 2.0227 (1.8124)	Arch Alpha Loss 51.3469 (50.5592)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.1%)	
10/05 09:06:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.8328 (1.1900)	Arch Loss 1.5576 (1.8130)	Arch Hard Loss 1.5570 (1.8125)	Arch Alpha Loss 51.7507 (50.7760)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.8%)	
10/05 09:06:59午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 65.1440%
10/05 09:07:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.7841	Prec@(1,5) (53.3%, 82.2%)
10/05 09:07:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8102	Prec@(1,5) (52.2%, 81.7%)
10/05 09:07:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8349	Prec@(1,5) (51.8%, 81.4%)
10/05 09:07:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8366	Prec@(1,5) (51.7%, 81.4%)
10/05 09:07:16午前 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 51.7000%
10/05 09:07:16午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 09:07:16午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 51.7000%
10/05 09:07:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.8573 (1.0745)	Arch Loss 1.9176 (1.8461)	Arch Hard Loss 1.9170 (1.8456)	Arch Alpha Loss 52.4056 (52.0906)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.4%)	
10/05 09:08:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.5067 (1.1067)	Arch Loss 2.0568 (1.8243)	Arch Hard Loss 2.0563 (1.8238)	Arch Alpha Loss 52.9634 (52.3821)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.9%)	
10/05 09:08:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.1285 (1.1382)	Arch Loss 1.4978 (1.8156)	Arch Hard Loss 1.4973 (1.8150)	Arch Alpha Loss 53.5392 (52.6835)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.5%)	
10/05 09:09:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 0.9959 (1.1486)	Arch Loss 1.8467 (1.8210)	Arch Hard Loss 1.8461 (1.8204)	Arch Alpha Loss 54.0692 (52.9341)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.5%)	
10/05 09:09:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 66.1640%
10/05 09:09:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.7628	Prec@(1,5) (54.0%, 82.5%)
10/05 09:09:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.7668	Prec@(1,5) (53.8%, 82.5%)
10/05 09:09:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.7722	Prec@(1,5) (53.6%, 82.3%)
10/05 09:09:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.7829	Prec@(1,5) (53.4%, 82.0%)
10/05 09:09:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 53.3760%
10/05 09:09:33午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:09:34午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 53.3760%
10/05 09:10:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.1319 (1.0542)	Arch Loss 1.9110 (1.7501)	Arch Hard Loss 1.9105 (1.7495)	Arch Alpha Loss 54.3522 (54.1848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.5%)	
10/05 09:10:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.2151 (1.0594)	Arch Loss 1.4190 (1.7725)	Arch Hard Loss 1.4185 (1.7719)	Arch Alpha Loss 54.7960 (54.3820)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.5%)	
10/05 09:11:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1032 (1.0840)	Arch Loss 1.7644 (1.7996)	Arch Hard Loss 1.7638 (1.7991)	Arch Alpha Loss 55.5076 (54.6536)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.2%)	
10/05 09:11:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.1820 (1.0975)	Arch Loss 1.4438 (1.7910)	Arch Hard Loss 1.4433 (1.7905)	Arch Alpha Loss 56.0682 (54.9138)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.1%)	
10/05 09:11:33午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 67.6760%
10/05 09:11:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.7895	Prec@(1,5) (52.8%, 82.0%)
10/05 09:11:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.7952	Prec@(1,5) (52.7%, 81.8%)
10/05 09:11:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.7860	Prec@(1,5) (53.1%, 82.2%)
10/05 09:11:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.7802	Prec@(1,5) (53.2%, 82.2%)
10/05 09:11:51午前 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 53.1880%
10/05 09:11:51午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:11:51午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 53.3760%
10/05 09:12:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9204 (1.0003)	Arch Loss 1.7548 (1.7874)	Arch Hard Loss 1.7542 (1.7868)	Arch Alpha Loss 56.7184 (56.3168)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.8%)	
10/05 09:12:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1814 (1.0340)	Arch Loss 1.9718 (1.7710)	Arch Hard Loss 1.9712 (1.7705)	Arch Alpha Loss 57.1889 (56.6133)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.1%)	
10/05 09:13:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.2323 (1.0474)	Arch Loss 1.6635 (1.8054)	Arch Hard Loss 1.6629 (1.8048)	Arch Alpha Loss 57.8367 (56.9128)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.0%)	
10/05 09:13:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.4569 (1.0571)	Arch Loss 1.8084 (1.8026)	Arch Hard Loss 1.8078 (1.8021)	Arch Alpha Loss 58.4800 (57.2096)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.8%)	
10/05 09:13:50午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 68.4880%
10/05 09:13:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.7453	Prec@(1,5) (54.3%, 82.5%)
10/05 09:13:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.7824	Prec@(1,5) (53.8%, 82.2%)
10/05 09:14:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.7773	Prec@(1,5) (54.0%, 82.4%)
10/05 09:14:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7775	Prec@(1,5) (54.0%, 82.5%)
10/05 09:14:07午前 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 53.9880%
10/05 09:14:07午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:14:07午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 53.9880%
10/05 09:14:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.0268 (0.9520)	Arch Loss 1.8700 (1.7907)	Arch Hard Loss 1.8694 (1.7901)	Arch Alpha Loss 59.1971 (58.7647)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.3%)	
10/05 09:15:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9208 (0.9694)	Arch Loss 1.7350 (1.7940)	Arch Hard Loss 1.7344 (1.7934)	Arch Alpha Loss 59.9800 (59.1458)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.9%)	
10/05 09:15:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 0.9829 (0.9882)	Arch Loss 2.2620 (1.8055)	Arch Hard Loss 2.2613 (1.8049)	Arch Alpha Loss 60.6982 (59.5624)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.6%)	
10/05 09:16:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9563 (1.0005)	Arch Loss 2.3286 (1.8059)	Arch Hard Loss 2.3280 (1.8053)	Arch Alpha Loss 61.2862 (59.8765)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.4%)	
10/05 09:16:07午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 70.1400%
10/05 09:16:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7523	Prec@(1,5) (54.7%, 83.1%)
10/05 09:16:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7725	Prec@(1,5) (54.2%, 82.7%)
10/05 09:16:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7839	Prec@(1,5) (54.1%, 82.7%)
10/05 09:16:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7756	Prec@(1,5) (54.3%, 82.9%)
10/05 09:16:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 54.2600%
10/05 09:16:24午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:16:25午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 54.2600%
10/05 09:16:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.6133 (0.9322)	Arch Loss 1.8168 (1.8185)	Arch Hard Loss 1.8162 (1.8178)	Arch Alpha Loss 62.1000 (61.7075)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.6%)	
10/05 09:17:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.1319 (0.9478)	Arch Loss 1.9002 (1.7867)	Arch Hard Loss 1.8996 (1.7860)	Arch Alpha Loss 62.8082 (62.0760)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.2%)	
10/05 09:17:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1429 (0.9584)	Arch Loss 1.7050 (1.7892)	Arch Hard Loss 1.7043 (1.7886)	Arch Alpha Loss 63.6087 (62.4530)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.0%)	
10/05 09:18:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0407 (0.9703)	Arch Loss 1.5172 (1.7935)	Arch Hard Loss 1.5166 (1.7929)	Arch Alpha Loss 64.2500 (62.7994)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.9%)	
10/05 09:18:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 70.8880%
10/05 09:18:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7603	Prec@(1,5) (54.1%, 82.6%)
10/05 09:18:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7822	Prec@(1,5) (53.8%, 82.4%)
10/05 09:18:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7957	Prec@(1,5) (53.6%, 82.5%)
10/05 09:18:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7775	Prec@(1,5) (54.3%, 82.9%)
10/05 09:18:42午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 54.2760%
10/05 09:18:42午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:18:43午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 54.2760%
10/05 09:19:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9262 (0.8818)	Arch Loss 2.0440 (1.8472)	Arch Hard Loss 2.0434 (1.8466)	Arch Alpha Loss 65.1543 (64.6585)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 94.7%)	
10/05 09:19:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9629 (0.8851)	Arch Loss 1.8676 (1.8087)	Arch Hard Loss 1.8670 (1.8080)	Arch Alpha Loss 65.8843 (65.1437)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
10/05 09:20:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0536 (0.8964)	Arch Loss 2.1194 (1.8065)	Arch Hard Loss 2.1187 (1.8058)	Arch Alpha Loss 66.7681 (65.5487)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.7%)	
10/05 09:20:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.8773 (0.9127)	Arch Loss 1.9860 (1.7997)	Arch Hard Loss 1.9854 (1.7991)	Arch Alpha Loss 67.5779 (65.9313)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.5%)	
10/05 09:20:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 72.6520%
10/05 09:20:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7086	Prec@(1,5) (56.0%, 83.7%)
10/05 09:20:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7433	Prec@(1,5) (55.1%, 83.4%)
10/05 09:20:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7423	Prec@(1,5) (55.2%, 83.4%)
10/05 09:21:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7404	Prec@(1,5) (55.2%, 83.4%)
10/05 09:21:00午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 55.2320%
10/05 09:21:00午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:21:00午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 55.2320%
10/05 09:21:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.7333 (0.8105)	Arch Loss 1.4336 (1.7985)	Arch Hard Loss 1.4329 (1.7978)	Arch Alpha Loss 68.4460 (68.0447)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.6%)	
10/05 09:22:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9278 (0.8177)	Arch Loss 1.9530 (1.7969)	Arch Hard Loss 1.9523 (1.7962)	Arch Alpha Loss 69.3517 (68.4704)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.6%)	
10/05 09:22:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8267 (0.8446)	Arch Loss 1.9959 (1.7874)	Arch Hard Loss 1.9952 (1.7867)	Arch Alpha Loss 70.2802 (68.9173)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.2%)	
10/05 09:22:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.9653 (0.8566)	Arch Loss 1.6806 (1.7831)	Arch Hard Loss 1.6799 (1.7824)	Arch Alpha Loss 71.0880 (69.3226)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.1%)	
10/05 09:22:56午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 74.1560%
10/05 09:23:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8077	Prec@(1,5) (54.0%, 82.8%)
10/05 09:23:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7793	Prec@(1,5) (54.8%, 83.1%)
10/05 09:23:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7820	Prec@(1,5) (54.4%, 83.2%)
10/05 09:23:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7849	Prec@(1,5) (54.4%, 83.2%)
10/05 09:23:13午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 54.4480%
10/05 09:23:13午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:23:13午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 55.2320%
10/05 09:23:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7515 (0.7737)	Arch Loss 2.2099 (1.7589)	Arch Hard Loss 2.2092 (1.7582)	Arch Alpha Loss 71.8510 (71.5162)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.3%)	
10/05 09:24:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.6968 (0.7931)	Arch Loss 1.7059 (1.7779)	Arch Hard Loss 1.7051 (1.7771)	Arch Alpha Loss 72.8918 (71.9484)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 96.2%)	
10/05 09:24:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.8687 (0.8027)	Arch Loss 1.5599 (1.7983)	Arch Hard Loss 1.5591 (1.7976)	Arch Alpha Loss 73.8180 (72.4276)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.9%)	
10/05 09:25:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.8694 (0.8154)	Arch Loss 1.7031 (1.7963)	Arch Hard Loss 1.7023 (1.7956)	Arch Alpha Loss 74.5806 (72.8171)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.7%)	
10/05 09:25:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 75.1520%
10/05 09:25:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7645	Prec@(1,5) (54.6%, 83.6%)
10/05 09:25:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7847	Prec@(1,5) (54.8%, 83.2%)
10/05 09:25:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7869	Prec@(1,5) (54.9%, 83.3%)
10/05 09:25:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7880	Prec@(1,5) (54.9%, 83.3%)
10/05 09:25:29午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 54.8880%
10/05 09:25:29午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:25:30午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 55.2320%
10/05 09:26:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.6583 (0.7263)	Arch Loss 1.4749 (1.7271)	Arch Hard Loss 1.4742 (1.7264)	Arch Alpha Loss 75.7552 (75.2079)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.2%)	
10/05 09:26:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.6770 (0.7418)	Arch Loss 1.8964 (1.7598)	Arch Hard Loss 1.8956 (1.7590)	Arch Alpha Loss 76.9833 (75.8086)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.2%)	
10/05 09:27:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.6764 (0.7628)	Arch Loss 1.7962 (1.7756)	Arch Hard Loss 1.7954 (1.7748)	Arch Alpha Loss 77.9077 (76.3506)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.1%)	
10/05 09:27:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.6326 (0.7738)	Arch Loss 1.8094 (1.7900)	Arch Hard Loss 1.8086 (1.7892)	Arch Alpha Loss 78.9064 (76.8292)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
10/05 09:27:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 76.5400%
10/05 09:27:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7040	Prec@(1,5) (56.6%, 84.2%)
10/05 09:27:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7339	Prec@(1,5) (56.3%, 84.0%)
10/05 09:27:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7310	Prec@(1,5) (56.4%, 83.9%)
10/05 09:27:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7296	Prec@(1,5) (56.3%, 83.9%)
10/05 09:27:47午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 56.2680%
10/05 09:27:47午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:27:47午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.2680%
10/05 09:28:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.8345 (0.6781)	Arch Loss 1.6494 (1.8034)	Arch Hard Loss 1.6486 (1.8026)	Arch Alpha Loss 80.1597 (79.5695)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.8%, 97.1%)	
10/05 09:28:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9108 (0.6950)	Arch Loss 2.0580 (1.7926)	Arch Hard Loss 2.0572 (1.7918)	Arch Alpha Loss 81.3403 (80.1368)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.9%)	
10/05 09:29:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.6651 (0.7122)	Arch Loss 1.6318 (1.7988)	Arch Hard Loss 1.6310 (1.7980)	Arch Alpha Loss 82.3638 (80.7232)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.7%)	
10/05 09:29:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.5750 (0.7271)	Arch Loss 1.4991 (1.7921)	Arch Hard Loss 1.4982 (1.7913)	Arch Alpha Loss 83.3970 (81.2330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.5%)	
10/05 09:29:45午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 78.0040%
10/05 09:29:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7822	Prec@(1,5) (56.1%, 83.8%)
10/05 09:29:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7635	Prec@(1,5) (56.1%, 83.9%)
10/05 09:29:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7672	Prec@(1,5) (55.9%, 83.9%)
10/05 09:30:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7580	Prec@(1,5) (55.9%, 83.9%)
10/05 09:30:02午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 55.9240%
10/05 09:30:02午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:30:02午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.2680%
10/05 09:30:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8013 (0.6444)	Arch Loss 1.9020 (1.7738)	Arch Hard Loss 1.9011 (1.7729)	Arch Alpha Loss 84.5996 (83.9231)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.4%)	
10/05 09:31:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8963 (0.6595)	Arch Loss 1.6188 (1.7587)	Arch Hard Loss 1.6179 (1.7578)	Arch Alpha Loss 85.5021 (84.4496)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.3%)	
10/05 09:31:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8189 (0.6752)	Arch Loss 1.2457 (1.7773)	Arch Hard Loss 1.2449 (1.7765)	Arch Alpha Loss 86.9150 (85.0434)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 97.1%)	
10/05 09:32:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8662 (0.6894)	Arch Loss 2.0438 (1.7755)	Arch Hard Loss 2.0429 (1.7746)	Arch Alpha Loss 87.6839 (85.5578)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.9%)	
10/05 09:32:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 78.8560%
10/05 09:32:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7864	Prec@(1,5) (56.0%, 83.4%)
10/05 09:32:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7844	Prec@(1,5) (55.9%, 83.6%)
10/05 09:32:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7745	Prec@(1,5) (55.8%, 83.9%)
10/05 09:32:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7737	Prec@(1,5) (55.8%, 83.7%)
10/05 09:32:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 55.8440%
10/05 09:32:20午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:32:21午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.2680%
10/05 09:32:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.4720 (0.6444)	Arch Loss 1.5739 (1.7650)	Arch Hard Loss 1.5730 (1.7641)	Arch Alpha Loss 89.0437 (88.3994)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
10/05 09:33:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.5852 (0.6339)	Arch Loss 2.0951 (1.7848)	Arch Hard Loss 2.0942 (1.7839)	Arch Alpha Loss 90.2289 (89.0076)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
10/05 09:33:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.6757 (0.6471)	Arch Loss 2.0958 (1.7831)	Arch Hard Loss 2.0949 (1.7822)	Arch Alpha Loss 91.5077 (89.6292)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
10/05 09:34:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.5603 (0.6533)	Arch Loss 2.2106 (1.7985)	Arch Hard Loss 2.2097 (1.7976)	Arch Alpha Loss 92.6873 (90.1947)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
10/05 09:34:19午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 79.9960%
10/05 09:34:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7091	Prec@(1,5) (57.3%, 84.7%)
10/05 09:34:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7229	Prec@(1,5) (57.0%, 84.5%)
10/05 09:34:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7415	Prec@(1,5) (56.5%, 84.5%)
10/05 09:34:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7436	Prec@(1,5) (56.5%, 84.3%)
10/05 09:34:36午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 56.4800%
10/05 09:34:36午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:34:37午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.4800%
10/05 09:35:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.5673 (0.5581)	Arch Loss 1.4479 (1.7855)	Arch Hard Loss 1.4469 (1.7846)	Arch Alpha Loss 93.9175 (93.2623)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.1%)	
10/05 09:35:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7602 (0.5863)	Arch Loss 1.8468 (1.7729)	Arch Hard Loss 1.8459 (1.7719)	Arch Alpha Loss 95.3915 (93.9489)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.7%)	
10/05 09:36:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8197 (0.6001)	Arch Loss 2.0271 (1.7991)	Arch Hard Loss 2.0262 (1.7982)	Arch Alpha Loss 96.9444 (94.7008)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.6%)	
10/05 09:36:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.7529 (0.6106)	Arch Loss 1.9794 (1.7947)	Arch Hard Loss 1.9784 (1.7938)	Arch Alpha Loss 97.8772 (95.3284)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.6%)	
10/05 09:36:37午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 81.4320%
10/05 09:36:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7481	Prec@(1,5) (57.0%, 84.3%)
10/05 09:36:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7558	Prec@(1,5) (56.8%, 84.0%)
10/05 09:36:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7624	Prec@(1,5) (56.4%, 84.2%)
10/05 09:36:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7506	Prec@(1,5) (56.5%, 84.4%)
10/05 09:36:54午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 56.4960%
10/05 09:36:54午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:36:54午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.4960%
10/05 09:37:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.4994 (0.5548)	Arch Loss 1.8486 (1.7784)	Arch Hard Loss 1.8476 (1.7774)	Arch Alpha Loss 99.0536 (98.4123)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.1%)	
10/05 09:37:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.4955 (0.5607)	Arch Loss 2.2448 (1.8160)	Arch Hard Loss 2.2438 (1.8151)	Arch Alpha Loss 100.2858 (99.0445)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
10/05 09:38:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.6028 (0.5703)	Arch Loss 1.1914 (1.8073)	Arch Hard Loss 1.1904 (1.8063)	Arch Alpha Loss 101.6018 (99.6915)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
10/05 09:38:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.6846 (0.5780)	Arch Loss 2.0587 (1.8018)	Arch Hard Loss 2.0576 (1.8007)	Arch Alpha Loss 102.6971 (100.2431)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.8%)	
10/05 09:38:51午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 82.0920%
10/05 09:38:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7240	Prec@(1,5) (57.9%, 84.8%)
10/05 09:39:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7431	Prec@(1,5) (57.4%, 84.8%)
10/05 09:39:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7736	Prec@(1,5) (56.8%, 84.3%)
10/05 09:39:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7678	Prec@(1,5) (56.6%, 84.4%)
10/05 09:39:09午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 56.6560%
10/05 09:39:09午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:39:09午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.6560%
10/05 09:39:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.7968 (0.5229)	Arch Loss 2.0355 (1.7564)	Arch Hard Loss 2.0344 (1.7554)	Arch Alpha Loss 104.0050 (103.4386)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.0%)	
10/05 09:40:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.7089 (0.5354)	Arch Loss 1.8567 (1.7917)	Arch Hard Loss 1.8557 (1.7906)	Arch Alpha Loss 105.1243 (104.0414)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.0%)	
10/05 09:40:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.5651 (0.5463)	Arch Loss 1.5153 (1.7890)	Arch Hard Loss 1.5142 (1.7879)	Arch Alpha Loss 106.4429 (104.6598)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
10/05 09:41:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.3853 (0.5524)	Arch Loss 1.9151 (1.7917)	Arch Hard Loss 1.9140 (1.7906)	Arch Alpha Loss 107.5921 (105.2088)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
10/05 09:41:08午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 83.5560%
10/05 09:41:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7368	Prec@(1,5) (56.3%, 84.9%)
10/05 09:41:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7446	Prec@(1,5) (56.5%, 84.6%)
10/05 09:41:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7433	Prec@(1,5) (56.5%, 84.7%)
10/05 09:41:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7329	Prec@(1,5) (56.8%, 84.9%)
10/05 09:41:25午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 56.7960%
10/05 09:41:25午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:41:26午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.7960%
10/05 09:41:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.3898 (0.4807)	Arch Loss 1.7395 (1.8090)	Arch Hard Loss 1.7384 (1.8079)	Arch Alpha Loss 109.1186 (108.3300)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.6%)	
10/05 09:42:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6214 (0.5067)	Arch Loss 1.4638 (1.7825)	Arch Hard Loss 1.4627 (1.7814)	Arch Alpha Loss 110.4013 (109.0794)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.2%)	
10/05 09:42:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.4921 (0.5144)	Arch Loss 1.7376 (1.7910)	Arch Hard Loss 1.7365 (1.7899)	Arch Alpha Loss 111.5794 (109.7289)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
10/05 09:43:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.3574 (0.5216)	Arch Loss 1.6999 (1.7922)	Arch Hard Loss 1.6988 (1.7911)	Arch Alpha Loss 112.8358 (110.3221)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.2%)	
10/05 09:43:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 84.2680%
10/05 09:43:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7364	Prec@(1,5) (56.6%, 85.0%)
10/05 09:43:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7208	Prec@(1,5) (57.2%, 85.2%)
10/05 09:43:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7434	Prec@(1,5) (56.7%, 84.7%)
10/05 09:43:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7433	Prec@(1,5) (56.9%, 84.6%)
10/05 09:43:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 56.9600%
10/05 09:43:43午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:43:44午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.9600%
10/05 09:44:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.3443 (0.4598)	Arch Loss 1.4660 (1.7637)	Arch Hard Loss 1.4649 (1.7625)	Arch Alpha Loss 114.2209 (113.5234)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.8%)	
10/05 09:44:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.5538 (0.4763)	Arch Loss 1.5905 (1.7810)	Arch Hard Loss 1.5894 (1.7798)	Arch Alpha Loss 115.5691 (114.1809)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.6%)	
10/05 09:45:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.5349 (0.4860)	Arch Loss 1.7104 (1.8006)	Arch Hard Loss 1.7092 (1.7995)	Arch Alpha Loss 117.1318 (114.8904)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
10/05 09:45:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5479 (0.4939)	Arch Loss 1.8831 (1.8010)	Arch Hard Loss 1.8819 (1.7998)	Arch Alpha Loss 118.3432 (115.5406)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
10/05 09:45:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 85.1440%
10/05 09:45:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7771	Prec@(1,5) (57.2%, 84.2%)
10/05 09:45:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7445	Prec@(1,5) (57.1%, 84.6%)
10/05 09:45:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7442	Prec@(1,5) (57.0%, 84.7%)
10/05 09:46:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7450	Prec@(1,5) (57.2%, 84.7%)
10/05 09:46:00午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 57.2280%
10/05 09:46:00午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:46:01午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.2280%
10/05 09:46:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.4189 (0.4481)	Arch Loss 2.0459 (1.8091)	Arch Hard Loss 2.0447 (1.8079)	Arch Alpha Loss 119.5300 (119.0005)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.7%)	
10/05 09:47:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.3645 (0.4541)	Arch Loss 1.5036 (1.7835)	Arch Hard Loss 1.5024 (1.7823)	Arch Alpha Loss 120.5027 (119.5408)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.6%)	
10/05 09:47:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6832 (0.4634)	Arch Loss 2.1229 (1.7860)	Arch Hard Loss 2.1217 (1.7848)	Arch Alpha Loss 121.8853 (120.1027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.5%)	
10/05 09:48:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.3555 (0.4680)	Arch Loss 1.4043 (1.7942)	Arch Hard Loss 1.4031 (1.7930)	Arch Alpha Loss 123.3005 (120.6794)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.5%)	
10/05 09:48:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 86.1440%
10/05 09:48:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7658	Prec@(1,5) (58.1%, 84.5%)
10/05 09:48:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7490	Prec@(1,5) (57.8%, 84.6%)
10/05 09:48:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7484	Prec@(1,5) (57.5%, 84.7%)
10/05 09:48:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7507	Prec@(1,5) (57.3%, 84.7%)
10/05 09:48:19午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 57.3280%
10/05 09:48:19午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:48:19午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.3280%
10/05 09:48:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.4139 (0.4219)	Arch Loss 1.8079 (1.7595)	Arch Hard Loss 1.8066 (1.7583)	Arch Alpha Loss 125.0424 (124.1546)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 99.0%)	
10/05 09:49:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.4677 (0.4269)	Arch Loss 1.6116 (1.7761)	Arch Hard Loss 1.6103 (1.7749)	Arch Alpha Loss 126.2425 (124.9402)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.9%)	
10/05 09:49:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.3854 (0.4355)	Arch Loss 1.5284 (1.7936)	Arch Hard Loss 1.5271 (1.7924)	Arch Alpha Loss 127.5226 (125.6105)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.9%)	
10/05 09:50:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.4380 (0.4464)	Arch Loss 2.0169 (1.7895)	Arch Hard Loss 2.0156 (1.7882)	Arch Alpha Loss 128.6423 (126.1760)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
10/05 09:50:18午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 86.8880%
10/05 09:50:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.7600	Prec@(1,5) (57.0%, 84.7%)
10/05 09:50:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7527	Prec@(1,5) (56.9%, 84.8%)
10/05 09:50:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7415	Prec@(1,5) (57.2%, 84.8%)
10/05 09:50:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7442	Prec@(1,5) (57.2%, 84.8%)
10/05 09:50:35午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 57.2600%
10/05 09:50:35午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:50:36午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.3280%
10/05 09:51:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4780 (0.4183)	Arch Loss 1.3005 (1.8254)	Arch Hard Loss 1.2992 (1.8241)	Arch Alpha Loss 129.9828 (129.2588)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.0%)	
10/05 09:51:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.4741 (0.4245)	Arch Loss 2.3424 (1.8011)	Arch Hard Loss 2.3411 (1.7998)	Arch Alpha Loss 131.1498 (129.9318)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.0%)	
10/05 09:52:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.4005 (0.4290)	Arch Loss 1.5501 (1.7969)	Arch Hard Loss 1.5488 (1.7956)	Arch Alpha Loss 132.3981 (130.5541)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.7%, 98.9%)	
10/05 09:52:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4920 (0.4404)	Arch Loss 1.7116 (1.7904)	Arch Hard Loss 1.7102 (1.7891)	Arch Alpha Loss 133.6191 (131.1341)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.8%)	
10/05 09:52:36午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 87.2920%
10/05 09:52:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7767	Prec@(1,5) (57.0%, 84.5%)
10/05 09:52:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7788	Prec@(1,5) (57.0%, 84.7%)
10/05 09:52:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7558	Prec@(1,5) (57.2%, 85.0%)
10/05 09:52:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7527	Prec@(1,5) (57.3%, 84.9%)
10/05 09:52:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 57.3440%
10/05 09:52:53午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:52:53午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.3440%
10/05 09:53:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.3346 (0.4042)	Arch Loss 1.8529 (1.7987)	Arch Hard Loss 1.8515 (1.7974)	Arch Alpha Loss 135.2279 (134.3969)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.6%, 98.9%)	
10/05 09:53:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.3791 (0.4137)	Arch Loss 2.2535 (1.7973)	Arch Hard Loss 2.2522 (1.7960)	Arch Alpha Loss 136.5650 (135.1276)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 98.9%)	
10/05 09:54:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5623 (0.4156)	Arch Loss 1.9976 (1.7941)	Arch Hard Loss 1.9963 (1.7928)	Arch Alpha Loss 137.4008 (135.7717)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.9%, 98.8%)	
10/05 09:54:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.3748 (0.4187)	Arch Loss 1.8962 (1.8032)	Arch Hard Loss 1.8948 (1.8018)	Arch Alpha Loss 138.6245 (136.2633)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.9%, 98.8%)	
10/05 09:54:48午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 87.9000%
10/05 09:54:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7650	Prec@(1,5) (56.6%, 84.6%)
10/05 09:54:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7414	Prec@(1,5) (57.2%, 84.8%)
10/05 09:55:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7449	Prec@(1,5) (57.3%, 84.8%)
10/05 09:55:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7557	Prec@(1,5) (57.1%, 84.6%)
10/05 09:55:06午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 57.0920%
10/05 09:55:06午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:55:06午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.3440%
10/05 09:55:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.3808 (0.4056)	Arch Loss 1.4388 (1.7850)	Arch Hard Loss 1.4374 (1.7836)	Arch Alpha Loss 140.1069 (139.3581)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.9%, 99.3%)	
10/05 09:56:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.4617 (0.4133)	Arch Loss 1.9737 (1.7859)	Arch Hard Loss 1.9722 (1.7845)	Arch Alpha Loss 141.3354 (140.0095)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 99.2%)	
10/05 09:56:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.3123 (0.4234)	Arch Loss 2.4565 (1.7906)	Arch Hard Loss 2.4550 (1.7892)	Arch Alpha Loss 142.3093 (140.6229)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.5%, 99.0%)	
10/05 09:57:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.3163 (0.4233)	Arch Loss 1.2216 (1.7974)	Arch Hard Loss 1.2202 (1.7960)	Arch Alpha Loss 143.1164 (141.1014)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.9%)	
10/05 09:57:06午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 87.5480%
10/05 09:57:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7456	Prec@(1,5) (57.3%, 84.5%)
10/05 09:57:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7298	Prec@(1,5) (57.5%, 84.9%)
10/05 09:57:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7418	Prec@(1,5) (57.5%, 84.6%)
10/05 09:57:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7407	Prec@(1,5) (57.5%, 84.7%)
10/05 09:57:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 57.4480%
10/05 09:57:24午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:57:24午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.4480%
10/05 09:57:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.4180 (0.3989)	Arch Loss 1.7329 (1.8173)	Arch Hard Loss 1.7315 (1.8158)	Arch Alpha Loss 144.6304 (143.9410)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.0%)	
10/05 09:58:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.3864 (0.4071)	Arch Loss 1.4666 (1.8076)	Arch Hard Loss 1.4651 (1.8062)	Arch Alpha Loss 145.8836 (144.6736)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.4%, 98.9%)	
10/05 09:58:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5480 (0.4069)	Arch Loss 1.9621 (1.8030)	Arch Hard Loss 1.9606 (1.8015)	Arch Alpha Loss 146.8503 (145.2494)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
10/05 09:59:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.2702 (0.4129)	Arch Loss 1.2679 (1.8072)	Arch Hard Loss 1.2664 (1.8057)	Arch Alpha Loss 147.8948 (145.7380)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.1%, 99.0%)	
10/05 09:59:22午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 88.1040%
10/05 09:59:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7353	Prec@(1,5) (57.5%, 84.6%)
10/05 09:59:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7241	Prec@(1,5) (57.6%, 84.8%)
10/05 09:59:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7365	Prec@(1,5) (57.4%, 84.7%)
10/05 09:59:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7398	Prec@(1,5) (57.5%, 84.7%)
10/05 09:59:39午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 57.4880%
10/05 09:59:39午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 09:59:39午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.4880%
10/05 10:00:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.3130 (0.4022)	Arch Loss 1.5455 (1.7694)	Arch Hard Loss 1.5440 (1.7680)	Arch Alpha Loss 149.1316 (148.4033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.0%)	
10/05 10:00:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.3746 (0.4063)	Arch Loss 1.3600 (1.7700)	Arch Hard Loss 1.3585 (1.7685)	Arch Alpha Loss 150.0826 (149.0074)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.6%, 98.9%)	
10/05 10:01:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.2444 (0.4045)	Arch Loss 1.7269 (1.7816)	Arch Hard Loss 1.7254 (1.7801)	Arch Alpha Loss 151.4344 (149.5825)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.8%, 98.9%)	
10/05 10:01:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6375 (0.4074)	Arch Loss 1.6992 (1.7949)	Arch Hard Loss 1.6976 (1.7934)	Arch Alpha Loss 152.6275 (150.1833)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.7%, 98.9%)	
10/05 10:01:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 88.6960%
10/05 10:01:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7644	Prec@(1,5) (57.3%, 84.6%)
10/05 10:01:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7276	Prec@(1,5) (58.0%, 85.2%)
10/05 10:01:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7406	Prec@(1,5) (57.8%, 85.2%)
10/05 10:01:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7517	Prec@(1,5) (57.6%, 85.0%)
10/05 10:01:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 57.6440%
10/05 10:01:53午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 10:01:54午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.6440%
10/05 10:01:54午前 searchStage_KD_main.py:107 [INFO] Final best Prec@1 = 57.6440%
10/05 10:01:54午前 searchStage_KD_main.py:108 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
