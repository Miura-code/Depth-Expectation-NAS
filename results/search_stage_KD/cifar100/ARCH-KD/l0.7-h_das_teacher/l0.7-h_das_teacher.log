10/01 08:21:49AM parser.py:28 [INFO] 
10/01 08:21:49AM parser.py:29 [INFO] Parameters:
10/01 08:21:49AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.7-h_das_teacher/DAG
10/01 08:21:49AM parser.py:31 [INFO] T=10.0
10/01 08:21:49AM parser.py:31 [INFO] ADVANCED=True
10/01 08:21:49AM parser.py:31 [INFO] ALPHA_LR=0.0003
10/01 08:21:49AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
10/01 08:21:49AM parser.py:31 [INFO] BATCH_SIZE=64
10/01 08:21:49AM parser.py:31 [INFO] CASCADE=False
10/01 08:21:49AM parser.py:31 [INFO] CHECKPOINT_RESET=False
10/01 08:21:49AM parser.py:31 [INFO] CUTOUT_LENGTH=0
10/01 08:21:49AM parser.py:31 [INFO] DATA_PATH=../data/
10/01 08:21:49AM parser.py:31 [INFO] DATASET=cifar100
10/01 08:21:49AM parser.py:31 [INFO] DEPTH_COEF=0.0
10/01 08:21:49AM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
10/01 08:21:49AM parser.py:31 [INFO] EPOCHS=50
10/01 08:21:49AM parser.py:31 [INFO] EXP_NAME=l0.7-h_das_teacher
10/01 08:21:49AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
10/01 08:21:49AM parser.py:31 [INFO] GPUS=[0]
10/01 08:21:49AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
10/01 08:21:49AM parser.py:31 [INFO] INIT_CHANNELS=16
10/01 08:21:49AM parser.py:31 [INFO] L=0.7
10/01 08:21:49AM parser.py:31 [INFO] LAYERS=20
10/01 08:21:49AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
10/01 08:21:49AM parser.py:31 [INFO] NAME=ARCH-KD
10/01 08:21:49AM parser.py:31 [INFO] NONKD=False
10/01 08:21:49AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.7-h_das_teacher
10/01 08:21:49AM parser.py:31 [INFO] PCDARTS=False
10/01 08:21:49AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.7-h_das_teacher/plots
10/01 08:21:49AM parser.py:31 [INFO] PRINT_FREQ=100
10/01 08:21:49AM parser.py:31 [INFO] RESUME_PATH=None
10/01 08:21:49AM parser.py:31 [INFO] SAVE=l0.7-h_das_teacher
10/01 08:21:49AM parser.py:31 [INFO] SEED=0
10/01 08:21:49AM parser.py:31 [INFO] SHARE_STAGE=False
10/01 08:21:49AM parser.py:31 [INFO] SLIDE_WINDOW=8
10/01 08:21:49AM parser.py:31 [INFO] SPEC_CELL=True
10/01 08:21:49AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
10/01 08:21:49AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
10/01 08:21:49AM parser.py:31 [INFO] TRAIN_PORTION=0.5
10/01 08:21:49AM parser.py:31 [INFO] TYPE=ArchKD
10/01 08:21:49AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
10/01 08:21:49AM parser.py:31 [INFO] W_LR=0.025
10/01 08:21:49AM parser.py:31 [INFO] W_LR_MIN=0.001
10/01 08:21:49AM parser.py:31 [INFO] W_MOMENTUM=0.9
10/01 08:21:49AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
10/01 08:21:49AM parser.py:31 [INFO] WORKERS=4
10/01 08:21:49AM parser.py:32 [INFO] 
10/01 08:21:50AM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
10/01 08:21:51AM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
10/01 08:22:22AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.0653 (4.5433)	Arch Loss 30.1922 (30.9078)	Arch Hard Loss 4.2131 (4.5261)	Arch Alpha Loss 37.1131 (37.6882)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 11.3%)	
10/01 08:22:51AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1283 (4.3496)	Arch Loss 29.0531 (30.2865)	Arch Hard Loss 3.9061 (4.3154)	Arch Alpha Loss 35.9243 (37.1015)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.0%, 16.3%)	
10/01 08:23:19AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8898 (4.2208)	Arch Loss 28.1587 (29.7513)	Arch Hard Loss 3.8582 (4.1970)	Arch Alpha Loss 34.7150 (36.5060)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.3%, 20.0%)	
10/01 08:23:44AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8878 (4.1445)	Arch Loss 27.3355 (29.2955)	Arch Hard Loss 3.8030 (4.1201)	Arch Alpha Loss 33.6179 (35.9648)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.1%, 22.3%)	
10/01 08:23:45AM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 6.1680%
10/01 08:23:50AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.7999	Prec@(1,5) (10.9%, 32.5%)
10/01 08:23:55AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.7986	Prec@(1,5) (10.9%, 32.6%)
10/01 08:23:59AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.7976	Prec@(1,5) (10.7%, 32.8%)
10/01 08:24:03AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.7902	Prec@(1,5) (10.7%, 32.9%)
10/01 08:24:03AM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 10.7200%
10/01 08:24:03AM searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:24:04AM searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 10.7200%
10/01 08:24:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6745 (3.7813)	Arch Loss 26.4070 (26.8549)	Arch Hard Loss 3.7381 (3.7629)	Arch Alpha Loss 32.3841 (32.9885)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.5%, 33.4%)	
10/01 08:25:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.5625 (3.7323)	Arch Loss 25.4310 (26.4049)	Arch Hard Loss 3.6118 (3.7394)	Arch Alpha Loss 31.1703 (32.3793)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.4%, 34.8%)	
10/01 08:25:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9400 (3.7139)	Arch Loss 24.3881 (25.9427)	Arch Hard Loss 3.4073 (3.7008)	Arch Alpha Loss 29.9725 (31.7741)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.8%, 35.2%)	
10/01 08:25:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.3712 (3.6777)	Arch Loss 23.7067 (25.5325)	Arch Hard Loss 3.4655 (3.6683)	Arch Alpha Loss 28.9160 (31.2346)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.4%, 36.3%)	
10/01 08:25:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 12.3640%
10/01 08:26:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5087	Prec@(1,5) (15.7%, 41.8%)
10/01 08:26:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5136	Prec@(1,5) (15.6%, 41.5%)
10/01 08:26:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5123	Prec@(1,5) (15.6%, 41.5%)
10/01 08:26:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5110	Prec@(1,5) (15.7%, 41.6%)
10/01 08:26:15午前 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 15.7120%
10/01 08:26:15午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:26:16午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 15.7120%
10/01 08:26:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6067 (3.4774)	Arch Loss 23.1041 (23.3320)	Arch Hard Loss 3.6711 (3.5050)	Arch Alpha Loss 27.7615 (28.3243)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.5%, 41.8%)	
10/01 08:27:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4083 (3.4585)	Arch Loss 22.1670 (22.9153)	Arch Hard Loss 3.5072 (3.4818)	Arch Alpha Loss 26.6568 (27.7622)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.0%, 42.5%)	
10/01 08:27:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.2506 (3.4161)	Arch Loss 21.2018 (22.4918)	Arch Hard Loss 3.2851 (3.4422)	Arch Alpha Loss 25.5953 (27.2138)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.7%, 43.9%)	
10/01 08:28:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4522 (3.3920)	Arch Loss 20.7286 (22.1242)	Arch Hard Loss 3.4517 (3.4112)	Arch Alpha Loss 24.6813 (26.7329)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.2%, 44.7%)	
10/01 08:28:13午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 17.1960%
10/01 08:28:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3339	Prec@(1,5) (19.2%, 47.1%)
10/01 08:28:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3349	Prec@(1,5) (18.9%, 46.6%)
10/01 08:28:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3411	Prec@(1,5) (18.9%, 46.6%)
10/01 08:28:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3511	Prec@(1,5) (18.8%, 46.3%)
10/01 08:28:31午前 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 18.7880%
10/01 08:28:31午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:28:31午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 18.7880%
10/01 08:29:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.0382 (3.2282)	Arch Loss 19.7182 (20.1761)	Arch Hard Loss 3.1254 (3.2512)	Arch Alpha Loss 23.7039 (24.1785)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.5%, 49.2%)	
10/01 08:29:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.3534 (3.2121)	Arch Loss 19.1953 (19.8284)	Arch Hard Loss 3.2436 (3.2329)	Arch Alpha Loss 22.7882 (23.7078)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.5%)	
10/01 08:30:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1506 (3.1911)	Arch Loss 18.2624 (19.4893)	Arch Hard Loss 2.9144 (3.2111)	Arch Alpha Loss 21.9257 (23.2546)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.1%, 50.1%)	
10/01 08:30:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.3744 (3.1789)	Arch Loss 18.2869 (19.1970)	Arch Hard Loss 3.4505 (3.1937)	Arch Alpha Loss 21.1950 (22.8618)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.1%, 50.6%)	
10/01 08:30:30午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 21.0960%
10/01 08:30:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1798	Prec@(1,5) (21.5%, 50.7%)
10/01 08:30:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1791	Prec@(1,5) (21.8%, 51.4%)
10/01 08:30:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1818	Prec@(1,5) (21.8%, 51.2%)
10/01 08:30:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1820	Prec@(1,5) (21.8%, 51.3%)
10/01 08:30:47午前 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 21.7760%
10/01 08:30:47午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:30:47午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 21.7760%
10/01 08:31:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.8907 (3.0158)	Arch Loss 16.9731 (17.6478)	Arch Hard Loss 2.6746 (3.0890)	Arch Alpha Loss 20.4264 (20.7984)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.5%, 54.2%)	
10/01 08:31:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.7858 (3.0057)	Arch Loss 16.7354 (17.3580)	Arch Hard Loss 2.9339 (3.0563)	Arch Alpha Loss 19.7164 (20.4311)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.5%, 54.8%)	
10/01 08:32:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.3872 (2.9909)	Arch Loss 16.2948 (17.0978)	Arch Hard Loss 2.9558 (3.0417)	Arch Alpha Loss 19.0558 (20.0802)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.6%, 55.3%)	
10/01 08:32:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.9142 (2.9825)	Arch Loss 16.0139 (16.8650)	Arch Hard Loss 3.0624 (3.0201)	Arch Alpha Loss 18.5020 (19.7785)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.9%, 55.6%)	
10/01 08:32:46午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 24.8800%
10/01 08:32:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.8964	Prec@(1,5) (27.2%, 57.6%)
10/01 08:32:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.8985	Prec@(1,5) (27.2%, 57.6%)
10/01 08:32:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9166	Prec@(1,5) (26.6%, 57.3%)
10/01 08:33:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9189	Prec@(1,5) (26.6%, 57.3%)
10/01 08:33:03午前 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 26.5680%
10/01 08:33:03午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:33:03午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 26.5680%
10/01 08:33:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.8040 (2.8262)	Arch Loss 15.3618 (15.6691)	Arch Hard Loss 2.8149 (2.9266)	Arch Alpha Loss 17.9242 (18.2036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 60.1%)	
10/01 08:34:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.9300 (2.8184)	Arch Loss 14.9115 (15.4461)	Arch Hard Loss 2.7343 (2.8959)	Arch Alpha Loss 17.3960 (17.9288)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.9%, 60.0%)	
10/01 08:34:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.7027 (2.8284)	Arch Loss 14.8222 (15.2552)	Arch Hard Loss 2.9867 (2.8877)	Arch Alpha Loss 16.9079 (17.6680)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.1%, 59.6%)	
10/01 08:34:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.7342 (2.8169)	Arch Loss 14.3633 (15.0791)	Arch Hard Loss 2.8123 (2.8679)	Arch Alpha Loss 16.5014 (17.4445)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.3%, 59.8%)	
10/01 08:35:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 28.3360%
10/01 08:35:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.7798	Prec@(1,5) (29.0%, 60.6%)
10/01 08:35:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8008	Prec@(1,5) (28.2%, 60.6%)
10/01 08:35:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.7964	Prec@(1,5) (28.3%, 60.6%)
10/01 08:35:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.7974	Prec@(1,5) (28.2%, 60.5%)
10/01 08:35:18午前 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 28.1480%
10/01 08:35:18午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:35:18午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 28.1480%
10/01 08:35:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.9678 (2.6586)	Arch Loss 14.0155 (14.1617)	Arch Hard Loss 2.7598 (2.7634)	Arch Alpha Loss 16.0795 (16.2833)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 63.7%)	
10/01 08:36:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.5345 (2.6706)	Arch Loss 13.7933 (14.0362)	Arch Hard Loss 2.8069 (2.7781)	Arch Alpha Loss 15.6948 (16.0829)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.4%)	
10/01 08:36:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.8111 (2.6563)	Arch Loss 13.3682 (13.8795)	Arch Hard Loss 2.6294 (2.7543)	Arch Alpha Loss 15.3412 (15.8932)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 63.9%)	
10/01 08:37:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7939 (2.6511)	Arch Loss 12.9237 (13.7481)	Arch Hard Loss 2.3907 (2.7364)	Arch Alpha Loss 15.0471 (15.7311)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.5%, 63.9%)	
10/01 08:37:17午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 31.4960%
10/01 08:37:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6927	Prec@(1,5) (31.4%, 63.3%)
10/01 08:37:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6866	Prec@(1,5) (31.5%, 63.1%)
10/01 08:37:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6785	Prec@(1,5) (31.5%, 63.4%)
10/01 08:37:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6796	Prec@(1,5) (31.5%, 63.5%)
10/01 08:37:35午前 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 31.4560%
10/01 08:37:35午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:37:36午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 31.4560%
10/01 08:38:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.6747 (2.5289)	Arch Loss 12.9447 (13.0902)	Arch Hard Loss 2.6243 (2.6671)	Arch Alpha Loss 14.7434 (14.8900)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.6%, 66.5%)	
10/01 08:38:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4071 (2.5172)	Arch Loss 12.3480 (12.9808)	Arch Hard Loss 2.2211 (2.6586)	Arch Alpha Loss 14.4670 (14.7460)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 66.8%)	
10/01 08:39:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.8876 (2.5219)	Arch Loss 12.8694 (12.8801)	Arch Hard Loss 2.9198 (2.6533)	Arch Alpha Loss 14.2137 (14.6097)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 66.5%)	
10/01 08:39:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.3455 (2.5149)	Arch Loss 12.0959 (12.7694)	Arch Hard Loss 2.2940 (2.6240)	Arch Alpha Loss 14.0026 (14.4934)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.3%, 66.8%)	
10/01 08:39:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 34.2720%
10/01 08:39:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6642	Prec@(1,5) (31.5%, 63.9%)
10/01 08:39:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6464	Prec@(1,5) (32.1%, 64.1%)
10/01 08:39:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6342	Prec@(1,5) (32.2%, 64.3%)
10/01 08:39:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6369	Prec@(1,5) (32.4%, 64.2%)
10/01 08:39:48午前 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 32.3600%
10/01 08:39:48午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:39:49午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 32.3600%
10/01 08:40:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 1.9410 (2.3916)	Arch Loss 12.0226 (12.2843)	Arch Hard Loss 2.3731 (2.5613)	Arch Alpha Loss 13.7850 (13.8901)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 69.9%)	
10/01 08:40:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.2835 (2.3952)	Arch Loss 12.0983 (12.2058)	Arch Hard Loss 2.5872 (2.5549)	Arch Alpha Loss 13.5873 (13.7869)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.8%)	
10/01 08:41:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2946 (2.3998)	Arch Loss 11.9439 (12.1291)	Arch Hard Loss 2.5595 (2.5465)	Arch Alpha Loss 13.4062 (13.6895)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.6%, 69.6%)	
10/01 08:41:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.4432 (2.3950)	Arch Loss 11.8342 (12.0527)	Arch Hard Loss 2.5551 (2.5283)	Arch Alpha Loss 13.2558 (13.6063)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.6%, 69.6%)	
10/01 08:41:42午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 36.5960%
10/01 08:41:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5085	Prec@(1,5) (35.3%, 68.1%)
10/01 08:41:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5189	Prec@(1,5) (35.5%, 67.5%)
10/01 08:41:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5329	Prec@(1,5) (34.9%, 67.0%)
10/01 08:41:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5377	Prec@(1,5) (34.9%, 67.0%)
10/01 08:41:59午前 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 34.8640%
10/01 08:41:59午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:41:59午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 34.8640%
10/01 08:42:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.8603 (2.2391)	Arch Loss 12.3105 (11.7181)	Arch Hard Loss 3.1402 (2.4954)	Arch Alpha Loss 13.1004 (13.1753)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.0%)	
10/01 08:43:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.1286 (2.2609)	Arch Loss 11.7581 (11.6535)	Arch Hard Loss 2.6866 (2.4823)	Arch Alpha Loss 12.9594 (13.1018)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 72.4%)	
10/01 08:43:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.1622 (2.2830)	Arch Loss 11.2860 (11.5836)	Arch Hard Loss 2.3052 (2.4610)	Arch Alpha Loss 12.8296 (13.0322)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 72.0%)	
10/01 08:43:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.0596 (2.2788)	Arch Loss 11.2059 (11.5236)	Arch Hard Loss 2.3005 (2.4426)	Arch Alpha Loss 12.7221 (12.9728)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 72.2%)	
10/01 08:44:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 39.1920%
10/01 08:44:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4683	Prec@(1,5) (36.4%, 68.4%)
10/01 08:44:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4290	Prec@(1,5) (36.9%, 69.2%)
10/01 08:44:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4138	Prec@(1,5) (37.0%, 69.4%)
10/01 08:44:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4109	Prec@(1,5) (37.0%, 69.5%)
10/01 08:44:17午前 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 37.0320%
10/01 08:44:17午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:44:18午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 37.0320%
10/01 08:44:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.3289 (2.1192)	Arch Loss 10.9408 (11.2745)	Arch Hard Loss 2.1127 (2.4091)	Arch Alpha Loss 12.6116 (12.6648)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 75.5%)	
10/01 08:45:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 1.9936 (2.1480)	Arch Loss 11.2962 (11.2043)	Arch Hard Loss 2.5385 (2.3756)	Arch Alpha Loss 12.5110 (12.6124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 74.7%)	
10/01 08:45:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.9000 (2.1689)	Arch Loss 10.7177 (11.1559)	Arch Hard Loss 2.0247 (2.3619)	Arch Alpha Loss 12.4186 (12.5629)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.8%, 74.4%)	
10/01 08:46:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1910 (2.1841)	Arch Loss 11.0316 (11.1186)	Arch Hard Loss 2.3922 (2.3542)	Arch Alpha Loss 12.3419 (12.5205)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 73.9%)	
10/01 08:46:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 41.5520%
10/01 08:46:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3093	Prec@(1,5) (39.5%, 71.6%)
10/01 08:46:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3171	Prec@(1,5) (39.2%, 71.4%)
10/01 08:46:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3001	Prec@(1,5) (39.4%, 72.0%)
10/01 08:46:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.2970	Prec@(1,5) (39.5%, 71.9%)
10/01 08:46:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 39.4960%
10/01 08:46:33午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:46:34午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 39.4960%
10/01 08:47:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.4881 (2.0691)	Arch Loss 11.0402 (10.9652)	Arch Hard Loss 2.4558 (2.3542)	Arch Alpha Loss 12.2634 (12.3013)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 76.8%)	
10/01 08:47:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.3850 (2.0862)	Arch Loss 10.7033 (10.8964)	Arch Hard Loss 2.1693 (2.3117)	Arch Alpha Loss 12.1914 (12.2639)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 76.2%)	
10/01 08:48:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.3590 (2.0914)	Arch Loss 11.0974 (10.8629)	Arch Hard Loss 2.6098 (2.3030)	Arch Alpha Loss 12.1251 (12.2284)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.7%)	
10/01 08:48:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.0185 (2.0938)	Arch Loss 10.6065 (10.8372)	Arch Hard Loss 2.1574 (2.2985)	Arch Alpha Loss 12.0701 (12.1981)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.7%)	
10/01 08:48:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 43.2720%
10/01 08:48:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3322	Prec@(1,5) (39.4%, 71.7%)
10/01 08:48:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3170	Prec@(1,5) (39.1%, 71.6%)
10/01 08:48:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3142	Prec@(1,5) (39.2%, 71.7%)
10/01 08:48:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3012	Prec@(1,5) (39.4%, 72.1%)
10/01 08:48:50午前 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 39.3920%
10/01 08:48:50午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:48:50午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 39.4960%
10/01 08:49:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.7814 (1.9841)	Arch Loss 10.7863 (10.7292)	Arch Hard Loss 2.3768 (2.3006)	Arch Alpha Loss 12.0137 (12.0409)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.8%)	
10/01 08:49:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.0071 (1.9902)	Arch Loss 11.2353 (10.6920)	Arch Hard Loss 2.8619 (2.2822)	Arch Alpha Loss 11.9621 (12.0141)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 77.8%)	
10/01 08:50:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9890 (2.0006)	Arch Loss 10.3807 (10.6487)	Arch Hard Loss 2.0403 (2.2566)	Arch Alpha Loss 11.9148 (11.9887)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 77.5%)	
10/01 08:50:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.1627 (2.0028)	Arch Loss 10.5647 (10.6229)	Arch Hard Loss 2.2516 (2.2459)	Arch Alpha Loss 11.8759 (11.9670)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.6%)	
10/01 08:50:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 44.9480%
10/01 08:50:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.1949	Prec@(1,5) (41.4%, 73.7%)
10/01 08:50:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1704	Prec@(1,5) (42.2%, 74.4%)
10/01 08:51:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1739	Prec@(1,5) (42.2%, 74.3%)
10/01 08:51:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1784	Prec@(1,5) (42.0%, 74.2%)
10/01 08:51:07午前 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 41.9840%
10/01 08:51:07午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 08:51:07午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 41.9840%
10/01 08:51:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1352 (1.8807)	Arch Loss 10.5722 (10.4906)	Arch Hard Loss 2.2873 (2.1921)	Arch Alpha Loss 11.8357 (11.8550)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.3%, 79.9%)	
10/01 08:52:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.5640 (1.8988)	Arch Loss 9.9799 (10.5033)	Arch Hard Loss 1.7204 (2.2180)	Arch Alpha Loss 11.7993 (11.8361)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.6%)	
10/01 08:52:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.0477 (1.9146)	Arch Loss 9.9740 (10.4769)	Arch Hard Loss 1.7379 (2.2042)	Arch Alpha Loss 11.7659 (11.8181)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.4%)	
10/01 08:53:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.2012 (1.9306)	Arch Loss 10.1396 (10.4570)	Arch Hard Loss 1.9229 (2.1951)	Arch Alpha Loss 11.7382 (11.8028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.1%)	
10/01 08:53:04午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 46.9000%
10/01 08:53:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1751	Prec@(1,5) (43.0%, 74.7%)
10/01 08:53:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2046	Prec@(1,5) (42.6%, 74.1%)
10/01 08:53:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2033	Prec@(1,5) (42.7%, 73.9%)
10/01 08:53:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2040	Prec@(1,5) (42.5%, 73.9%)
10/01 08:53:21午前 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 42.5240%
10/01 08:53:21午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:53:22午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 42.5240%
10/01 08:53:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.1464 (1.8461)	Arch Loss 10.2989 (10.3512)	Arch Hard Loss 2.1020 (2.1448)	Arch Alpha Loss 11.7098 (11.7234)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.4%, 80.8%)	
10/01 08:54:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.9000 (1.8389)	Arch Loss 10.1054 (10.3500)	Arch Hard Loss 1.9265 (2.1530)	Arch Alpha Loss 11.6842 (11.7100)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.2%, 80.9%)	
10/01 08:54:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.7834 (1.8419)	Arch Loss 10.4145 (10.3333)	Arch Hard Loss 2.2520 (2.1451)	Arch Alpha Loss 11.6608 (11.6974)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 80.7%)	
10/01 08:55:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.2448 (1.8588)	Arch Loss 10.2392 (10.3317)	Arch Hard Loss 2.0901 (2.1510)	Arch Alpha Loss 11.6415 (11.6867)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.3%)	
10/01 08:55:20午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 48.6080%
10/01 08:55:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1559	Prec@(1,5) (42.8%, 74.9%)
10/01 08:55:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1198	Prec@(1,5) (43.5%, 76.0%)
10/01 08:55:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1147	Prec@(1,5) (43.5%, 76.2%)
10/01 08:55:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1140	Prec@(1,5) (43.7%, 76.0%)
10/01 08:55:37午前 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 43.6480%
10/01 08:55:37午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 08:55:37午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.6480%
10/01 08:56:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.7338 (1.7513)	Arch Loss 9.9120 (10.2539)	Arch Hard Loss 1.7768 (2.1121)	Arch Alpha Loss 11.6217 (11.6311)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 83.1%)	
10/01 08:56:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.8656 (1.7595)	Arch Loss 9.8082 (10.2545)	Arch Hard Loss 1.6856 (2.1192)	Arch Alpha Loss 11.6036 (11.6218)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 82.9%)	
10/01 08:57:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9193 (1.7788)	Arch Loss 10.0380 (10.2438)	Arch Hard Loss 1.9272 (2.1148)	Arch Alpha Loss 11.5869 (11.6129)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 82.4%)	
10/01 08:57:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.0044 (1.7901)	Arch Loss 10.4800 (10.2405)	Arch Hard Loss 2.3785 (2.1168)	Arch Alpha Loss 11.5735 (11.6052)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 82.1%)	
10/01 08:57:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 50.1000%
10/01 08:57:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0730	Prec@(1,5) (45.4%, 76.8%)
10/01 08:57:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0639	Prec@(1,5) (45.2%, 76.7%)
10/01 08:57:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0732	Prec@(1,5) (44.9%, 76.6%)
10/01 08:57:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0777	Prec@(1,5) (44.8%, 76.5%)
10/01 08:57:52午前 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 44.7760%
10/01 08:57:52午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 08:57:52午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 44.7760%
10/01 08:58:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.6050 (1.7101)	Arch Loss 10.1579 (10.1429)	Arch Hard Loss 2.0660 (2.0463)	Arch Alpha Loss 11.5598 (11.5666)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 83.3%)	
10/01 08:58:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.8880 (1.7063)	Arch Loss 10.1411 (10.1560)	Arch Hard Loss 2.0575 (2.0639)	Arch Alpha Loss 11.5479 (11.5602)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 83.4%)	
10/01 08:59:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9242 (1.7261)	Arch Loss 9.6770 (10.1585)	Arch Hard Loss 1.6014 (2.0706)	Arch Alpha Loss 11.5367 (11.5542)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.8%)	
10/01 08:59:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.5949 (1.7291)	Arch Loss 10.7956 (10.1587)	Arch Hard Loss 2.7262 (2.0743)	Arch Alpha Loss 11.5278 (11.5492)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.7%)	
10/01 08:59:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 51.6120%
10/01 08:59:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0884	Prec@(1,5) (44.2%, 76.5%)
10/01 08:59:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1066	Prec@(1,5) (44.1%, 76.3%)
10/01 09:00:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1059	Prec@(1,5) (44.0%, 76.3%)
10/01 09:00:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1051	Prec@(1,5) (44.1%, 76.3%)
10/01 09:00:06午前 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 44.1200%
10/01 09:00:06午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:00:06午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 44.7760%
10/01 09:00:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.8600 (1.6301)	Arch Loss 10.5735 (10.1541)	Arch Hard Loss 2.5104 (2.0880)	Arch Alpha Loss 11.5187 (11.5231)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.6%)	
10/01 09:01:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.3960 (1.6455)	Arch Loss 9.9384 (10.1408)	Arch Hard Loss 1.8807 (2.0776)	Arch Alpha Loss 11.5110 (11.5189)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.4%, 84.3%)	
10/01 09:01:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8636 (1.6590)	Arch Loss 10.1214 (10.1241)	Arch Hard Loss 2.0690 (2.0637)	Arch Alpha Loss 11.5034 (11.5150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 84.0%)	
10/01 09:02:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.7206 (1.6650)	Arch Loss 10.0428 (10.1139)	Arch Hard Loss 1.9942 (2.0558)	Arch Alpha Loss 11.4979 (11.5116)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.8%)	
10/01 09:02:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 52.7320%
10/01 09:02:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0502	Prec@(1,5) (46.1%, 76.8%)
10/01 09:02:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0405	Prec@(1,5) (45.7%, 77.3%)
10/01 09:02:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0347	Prec@(1,5) (45.8%, 77.5%)
10/01 09:02:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0375	Prec@(1,5) (46.0%, 77.4%)
10/01 09:02:17午前 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 45.9560%
10/01 09:02:17午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:02:18午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 45.9560%
10/01 09:02:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.8166 (1.5446)	Arch Loss 10.0409 (10.0959)	Arch Hard Loss 1.9963 (2.0494)	Arch Alpha Loss 11.4924 (11.4950)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.6%)	
10/01 09:03:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.6106 (1.5819)	Arch Loss 9.8779 (10.1052)	Arch Hard Loss 1.8370 (2.0605)	Arch Alpha Loss 11.4870 (11.4923)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.0%)	
10/01 09:03:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6549 (1.5856)	Arch Loss 10.1964 (10.0942)	Arch Hard Loss 2.1590 (2.0514)	Arch Alpha Loss 11.4820 (11.4897)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.1%)	
10/01 09:04:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.7445 (1.5983)	Arch Loss 9.7621 (10.0800)	Arch Hard Loss 1.7277 (2.0389)	Arch Alpha Loss 11.4777 (11.4874)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.9%)	
10/01 09:04:18午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 54.6680%
10/01 09:04:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0066	Prec@(1,5) (46.4%, 77.5%)
10/01 09:04:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9962	Prec@(1,5) (47.1%, 77.8%)
10/01 09:04:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9937	Prec@(1,5) (46.8%, 77.9%)
10/01 09:04:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9904	Prec@(1,5) (46.9%, 78.0%)
10/01 09:04:35午前 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 46.8440%
10/01 09:04:35午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:04:35午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.8440%
10/01 09:05:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.5625 (1.4824)	Arch Loss 10.0784 (10.0627)	Arch Hard Loss 2.0463 (2.0294)	Arch Alpha Loss 11.4744 (11.4761)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 87.0%)	
10/01 09:05:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6723 (1.5045)	Arch Loss 10.2302 (10.0551)	Arch Hard Loss 2.2005 (2.0230)	Arch Alpha Loss 11.4710 (11.4744)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.6%)	
10/01 09:06:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.3271 (1.5246)	Arch Loss 9.8511 (10.0560)	Arch Hard Loss 1.8232 (2.0250)	Arch Alpha Loss 11.4685 (11.4728)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.3%)	
10/01 09:06:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.2694 (1.5457)	Arch Loss 10.2732 (10.0486)	Arch Hard Loss 2.2476 (2.0186)	Arch Alpha Loss 11.4652 (11.4714)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.8%)	
10/01 09:06:34午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 56.0760%
10/01 09:06:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9773	Prec@(1,5) (48.4%, 78.3%)
10/01 09:06:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9698	Prec@(1,5) (48.0%, 78.6%)
10/01 09:06:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9771	Prec@(1,5) (47.8%, 78.5%)
10/01 09:06:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9755	Prec@(1,5) (48.0%, 78.4%)
10/01 09:06:52午前 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 48.0200%
10/01 09:06:52午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:06:52午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 48.0200%
10/01 09:07:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.4647 (1.4019)	Arch Loss 9.9678 (10.0528)	Arch Hard Loss 1.9436 (2.0279)	Arch Alpha Loss 11.4631 (11.4641)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.1%)	
10/01 09:07:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5588 (1.4515)	Arch Loss 10.3823 (10.0305)	Arch Hard Loss 2.3598 (2.0064)	Arch Alpha Loss 11.4607 (11.4629)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.2%)	
10/01 09:08:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.4593 (1.4682)	Arch Loss 10.4012 (10.0269)	Arch Hard Loss 2.3800 (2.0036)	Arch Alpha Loss 11.4588 (11.4619)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.7%, 87.0%)	
10/01 09:08:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.5227 (1.4831)	Arch Loss 9.7731 (10.0223)	Arch Hard Loss 1.7533 (1.9997)	Arch Alpha Loss 11.4569 (11.4609)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.8%)	
10/01 09:08:51午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 57.2800%
10/01 09:08:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9560	Prec@(1,5) (47.7%, 78.9%)
10/01 09:09:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9498	Prec@(1,5) (48.2%, 78.8%)
10/01 09:09:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9369	Prec@(1,5) (48.7%, 79.0%)
10/01 09:09:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9304	Prec@(1,5) (48.7%, 79.1%)
10/01 09:09:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 48.7000%
10/01 09:09:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:09:09午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 48.7000%
10/01 09:09:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.6760 (1.3765)	Arch Loss 9.7536 (9.9766)	Arch Hard Loss 1.7350 (1.9572)	Arch Alpha Loss 11.4553 (11.4562)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.7%)	
10/01 09:10:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.1717 (1.4013)	Arch Loss 9.9392 (9.9934)	Arch Hard Loss 1.9212 (1.9745)	Arch Alpha Loss 11.4542 (11.4555)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.9%)	
10/01 09:10:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.0807 (1.4204)	Arch Loss 10.2807 (9.9872)	Arch Hard Loss 2.2637 (1.9688)	Arch Alpha Loss 11.4528 (11.4549)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.7%)	
10/01 09:11:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.4387 (1.4338)	Arch Loss 9.7915 (9.9770)	Arch Hard Loss 1.7761 (1.9591)	Arch Alpha Loss 11.4505 (11.4541)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.5%)	
10/01 09:11:03午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 58.5120%
10/01 09:11:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9585	Prec@(1,5) (48.9%, 78.6%)
10/01 09:11:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9455	Prec@(1,5) (49.0%, 79.2%)
10/01 09:11:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9302	Prec@(1,5) (49.3%, 79.4%)
10/01 09:11:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9328	Prec@(1,5) (49.3%, 79.5%)
10/01 09:11:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 49.3080%
10/01 09:11:20午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:11:21午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.3080%
10/01 09:11:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.1250 (1.3267)	Arch Loss 10.2330 (9.9431)	Arch Hard Loss 2.2184 (1.9283)	Arch Alpha Loss 11.4493 (11.4498)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.5%)	
10/01 09:12:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.3018 (1.3606)	Arch Loss 10.1528 (9.9710)	Arch Hard Loss 2.1390 (1.9565)	Arch Alpha Loss 11.4482 (11.4492)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.7%)	
10/01 09:12:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3152 (1.3641)	Arch Loss 9.9482 (9.9679)	Arch Hard Loss 1.9354 (1.9538)	Arch Alpha Loss 11.4469 (11.4486)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.6%)	
10/01 09:13:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.2308 (1.3757)	Arch Loss 9.6455 (9.9628)	Arch Hard Loss 1.6333 (1.9491)	Arch Alpha Loss 11.4460 (11.4481)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.5%)	
10/01 09:13:20午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 60.3800%
10/01 09:13:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8931	Prec@(1,5) (49.9%, 80.5%)
10/01 09:13:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8981	Prec@(1,5) (50.2%, 80.2%)
10/01 09:13:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8780	Prec@(1,5) (50.4%, 80.5%)
10/01 09:13:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8802	Prec@(1,5) (50.6%, 80.5%)
10/01 09:13:38午前 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 50.5640%
10/01 09:13:38午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:13:38午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.5640%
10/01 09:14:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.2034 (1.2163)	Arch Loss 9.8566 (9.9390)	Arch Hard Loss 1.8447 (1.9270)	Arch Alpha Loss 11.4455 (11.4457)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.5%)	
10/01 09:14:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.2284 (1.2663)	Arch Loss 10.1435 (9.9414)	Arch Hard Loss 2.1321 (1.9296)	Arch Alpha Loss 11.4449 (11.4455)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.0%)	
10/01 09:15:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2401 (1.2963)	Arch Loss 10.0977 (9.9580)	Arch Hard Loss 2.0866 (1.9464)	Arch Alpha Loss 11.4445 (11.4452)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.4%)	
10/01 09:15:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3715 (1.3088)	Arch Loss 10.3673 (9.9515)	Arch Hard Loss 2.3570 (1.9401)	Arch Alpha Loss 11.4432 (11.4449)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.3%)	
10/01 09:15:38午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 62.1800%
10/01 09:15:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8813	Prec@(1,5) (50.0%, 81.6%)
10/01 09:15:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9039	Prec@(1,5) (49.7%, 80.9%)
10/01 09:15:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9084	Prec@(1,5) (49.8%, 80.5%)
10/01 09:15:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8916	Prec@(1,5) (50.3%, 80.9%)
10/01 09:15:55午前 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 50.2840%
10/01 09:15:55午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:15:55午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.5640%
10/01 09:16:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0770 (1.1917)	Arch Loss 9.9695 (9.9398)	Arch Hard Loss 1.9597 (1.9297)	Arch Alpha Loss 11.4426 (11.4430)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.9%)	
10/01 09:16:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2924 (1.2165)	Arch Loss 10.5785 (9.9575)	Arch Hard Loss 2.5691 (1.9477)	Arch Alpha Loss 11.4420 (11.4426)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.9%)	
10/01 09:17:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3853 (1.2440)	Arch Loss 9.8406 (9.9618)	Arch Hard Loss 1.8314 (1.9521)	Arch Alpha Loss 11.4418 (11.4423)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.5%)	
10/01 09:17:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.6890 (1.2635)	Arch Loss 9.9178 (9.9482)	Arch Hard Loss 1.9092 (1.9388)	Arch Alpha Loss 11.4410 (11.4421)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.7%, 90.3%)	
10/01 09:17:56午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 62.6640%
10/01 09:18:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9511	Prec@(1,5) (49.9%, 80.5%)
10/01 09:18:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9366	Prec@(1,5) (50.0%, 80.3%)
10/01 09:18:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9323	Prec@(1,5) (50.0%, 80.3%)
10/01 09:18:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9338	Prec@(1,5) (50.0%, 80.2%)
10/01 09:18:14午前 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 49.9880%
10/01 09:18:14午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:18:14午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.5640%
10/01 09:18:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.1536 (1.1830)	Arch Loss 10.1036 (9.8569)	Arch Hard Loss 2.0953 (1.8486)	Arch Alpha Loss 11.4404 (11.4405)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.8%, 91.3%)	
10/01 09:19:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3696 (1.1930)	Arch Loss 9.7150 (9.8905)	Arch Hard Loss 1.7074 (1.8824)	Arch Alpha Loss 11.4395 (11.4403)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 91.2%)	
10/01 09:19:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.1806 (1.2027)	Arch Loss 10.2693 (9.9116)	Arch Hard Loss 2.2624 (1.9037)	Arch Alpha Loss 11.4384 (11.4398)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 91.0%)	
10/01 09:20:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.4277 (1.2152)	Arch Loss 9.8956 (9.9253)	Arch Hard Loss 1.8890 (1.9177)	Arch Alpha Loss 11.4380 (11.4394)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.8%)	
10/01 09:20:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 64.0680%
10/01 09:20:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8476	Prec@(1,5) (51.5%, 81.5%)
10/01 09:20:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8648	Prec@(1,5) (51.2%, 81.1%)
10/01 09:20:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8993	Prec@(1,5) (50.6%, 80.6%)
10/01 09:20:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9115	Prec@(1,5) (50.5%, 80.4%)
10/01 09:20:30午前 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 50.5000%
10/01 09:20:30午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:20:30午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.5640%
10/01 09:21:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.7668 (1.0858)	Arch Loss 10.1865 (9.9463)	Arch Hard Loss 2.1804 (1.9401)	Arch Alpha Loss 11.4372 (11.4374)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.5%)	
10/01 09:21:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.4180 (1.1293)	Arch Loss 10.3562 (9.9385)	Arch Hard Loss 2.3503 (1.9324)	Arch Alpha Loss 11.4371 (11.4373)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.9%)	
10/01 09:22:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2762 (1.1563)	Arch Loss 9.5186 (9.9318)	Arch Hard Loss 1.5133 (1.9258)	Arch Alpha Loss 11.4362 (11.4370)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.6%)	
10/01 09:22:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0452 (1.1673)	Arch Loss 9.9942 (9.9291)	Arch Hard Loss 1.9891 (1.9233)	Arch Alpha Loss 11.4359 (11.4369)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.5%)	
10/01 09:22:30午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 65.3480%
10/01 09:22:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8539	Prec@(1,5) (51.7%, 81.6%)
10/01 09:22:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8402	Prec@(1,5) (52.0%, 81.8%)
10/01 09:22:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8468	Prec@(1,5) (52.0%, 81.6%)
10/01 09:22:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8587	Prec@(1,5) (51.6%, 81.2%)
10/01 09:22:47午前 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 51.6120%
10/01 09:22:47午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:22:48午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.6120%
10/01 09:23:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0412 (1.0618)	Arch Loss 10.0627 (9.8898)	Arch Hard Loss 2.0576 (1.8845)	Arch Alpha Loss 11.4359 (11.4361)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 93.0%)	
10/01 09:23:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.4764 (1.0743)	Arch Loss 10.0335 (9.9095)	Arch Hard Loss 2.0289 (1.9044)	Arch Alpha Loss 11.4351 (11.4358)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.8%)	
10/01 09:24:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.2116 (1.0967)	Arch Loss 9.6524 (9.9298)	Arch Hard Loss 1.6479 (1.9249)	Arch Alpha Loss 11.4351 (11.4357)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.6%)	
10/01 09:24:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.0246 (1.1139)	Arch Loss 9.6123 (9.9259)	Arch Hard Loss 1.6080 (1.9211)	Arch Alpha Loss 11.4348 (11.4355)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 92.2%)	
10/01 09:24:42午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 66.8600%
10/01 09:24:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8636	Prec@(1,5) (51.4%, 81.5%)
10/01 09:24:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8838	Prec@(1,5) (51.3%, 81.1%)
10/01 09:24:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8728	Prec@(1,5) (51.6%, 81.3%)
10/01 09:25:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8646	Prec@(1,5) (51.8%, 81.3%)
10/01 09:25:00午前 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 51.7880%
10/01 09:25:00午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:25:00午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.7880%
10/01 09:25:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9581 (0.9968)	Arch Loss 9.8588 (9.8699)	Arch Hard Loss 1.8544 (1.8657)	Arch Alpha Loss 11.4348 (11.4345)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.6%)	
10/01 09:26:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1783 (1.0266)	Arch Loss 10.0952 (9.8713)	Arch Hard Loss 2.0910 (1.8671)	Arch Alpha Loss 11.4346 (11.4345)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.3%)	
10/01 09:26:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.1661 (1.0437)	Arch Loss 9.8822 (9.9140)	Arch Hard Loss 1.8786 (1.9099)	Arch Alpha Loss 11.4338 (11.4344)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.0%)	
10/01 09:26:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.3832 (1.0514)	Arch Loss 10.0174 (9.9141)	Arch Hard Loss 2.0138 (1.9102)	Arch Alpha Loss 11.4337 (11.4342)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.8%)	
10/01 09:26:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 68.4920%
10/01 09:27:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8466	Prec@(1,5) (53.0%, 81.2%)
10/01 09:27:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8616	Prec@(1,5) (52.6%, 81.4%)
10/01 09:27:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8595	Prec@(1,5) (52.4%, 81.5%)
10/01 09:27:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8620	Prec@(1,5) (52.5%, 81.5%)
10/01 09:27:15午前 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 52.4680%
10/01 09:27:15午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:27:15午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.4680%
10/01 09:27:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.9032 (0.9577)	Arch Loss 9.8376 (9.9019)	Arch Hard Loss 1.8346 (1.8988)	Arch Alpha Loss 11.4329 (11.4330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.2%)	
10/01 09:28:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.0124 (0.9648)	Arch Loss 9.6768 (9.9114)	Arch Hard Loss 1.6736 (1.9083)	Arch Alpha Loss 11.4331 (11.4330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 94.0%)	
10/01 09:28:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 0.9373 (0.9885)	Arch Loss 10.4780 (9.9274)	Arch Hard Loss 2.4751 (1.9243)	Arch Alpha Loss 11.4327 (11.4330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.7%)	
10/01 09:29:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0261 (1.0041)	Arch Loss 10.2630 (9.9246)	Arch Hard Loss 2.2599 (1.9215)	Arch Alpha Loss 11.4329 (11.4330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.5%)	
10/01 09:29:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 69.6640%
10/01 09:29:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8800	Prec@(1,5) (52.5%, 81.8%)
10/01 09:29:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8827	Prec@(1,5) (52.4%, 81.5%)
10/01 09:29:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8911	Prec@(1,5) (52.6%, 81.5%)
10/01 09:29:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8916	Prec@(1,5) (52.3%, 81.5%)
10/01 09:29:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 52.3440%
10/01 09:29:33午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:29:34午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.4680%
10/01 09:30:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.5865 (0.9066)	Arch Loss 9.9063 (9.9353)	Arch Hard Loss 1.9033 (1.9323)	Arch Alpha Loss 11.4328 (11.4329)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.8%)	
10/01 09:30:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.0274 (0.9322)	Arch Loss 10.0624 (9.9253)	Arch Hard Loss 2.0591 (1.9222)	Arch Alpha Loss 11.4333 (11.4330)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.4%)	
10/01 09:31:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1120 (0.9422)	Arch Loss 9.9211 (9.9227)	Arch Hard Loss 1.9178 (1.9195)	Arch Alpha Loss 11.4332 (11.4331)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.2%)	
10/01 09:31:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.1979 (0.9504)	Arch Loss 9.7335 (9.9267)	Arch Hard Loss 1.7305 (1.9236)	Arch Alpha Loss 11.4329 (11.4331)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.1%)	
10/01 09:31:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 71.4160%
10/01 09:31:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9125	Prec@(1,5) (52.2%, 81.3%)
10/01 09:31:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9258	Prec@(1,5) (52.1%, 81.0%)
10/01 09:31:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9278	Prec@(1,5) (51.8%, 81.0%)
10/01 09:31:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9024	Prec@(1,5) (52.5%, 81.3%)
10/01 09:31:50午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 52.4560%
10/01 09:31:50午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:31:50午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.4680%
10/01 09:32:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8049 (0.8494)	Arch Loss 9.9696 (9.9708)	Arch Hard Loss 1.9670 (1.9680)	Arch Alpha Loss 11.4322 (11.4327)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.5%)	
10/01 09:32:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.8806 (0.8582)	Arch Loss 10.1984 (9.9292)	Arch Hard Loss 2.1960 (1.9265)	Arch Alpha Loss 11.4321 (11.4324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 95.6%)	
10/01 09:33:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1082 (0.8770)	Arch Loss 10.4240 (9.9434)	Arch Hard Loss 2.4214 (1.9407)	Arch Alpha Loss 11.4322 (11.4323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.0%, 95.3%)	
10/01 09:33:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.9637 (0.8978)	Arch Loss 10.2881 (9.9446)	Arch Hard Loss 2.2858 (1.9420)	Arch Alpha Loss 11.4318 (11.4323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.4%, 95.0%)	
10/01 09:33:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 72.4200%
10/01 09:33:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8907	Prec@(1,5) (52.6%, 82.1%)
10/01 09:33:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9072	Prec@(1,5) (52.5%, 81.9%)
10/01 09:34:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9147	Prec@(1,5) (52.5%, 81.8%)
10/01 09:34:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9097	Prec@(1,5) (52.5%, 81.9%)
10/01 09:34:07午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 52.4760%
10/01 09:34:07午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:34:07午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.4760%
10/01 09:34:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8858 (0.7671)	Arch Loss 9.4923 (9.9416)	Arch Hard Loss 1.4905 (1.9394)	Arch Alpha Loss 11.4312 (11.4317)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 96.2%)	
10/01 09:35:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.8780 (0.7912)	Arch Loss 9.9980 (9.9560)	Arch Hard Loss 1.9962 (1.9539)	Arch Alpha Loss 11.4312 (11.4316)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.8%)	
10/01 09:35:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.6659 (0.8178)	Arch Loss 10.3063 (9.9467)	Arch Hard Loss 2.3044 (1.9447)	Arch Alpha Loss 11.4313 (11.4315)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.6%)	
10/01 09:36:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.8914 (0.8392)	Arch Loss 9.9234 (9.9488)	Arch Hard Loss 1.9210 (1.9467)	Arch Alpha Loss 11.4320 (11.4315)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.4%)	
10/01 09:36:08午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 74.2600%
10/01 09:36:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.9237	Prec@(1,5) (53.0%, 81.3%)
10/01 09:36:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.9061	Prec@(1,5) (53.1%, 81.6%)
10/01 09:36:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.9052	Prec@(1,5) (52.9%, 81.7%)
10/01 09:36:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.9140	Prec@(1,5) (52.7%, 81.6%)
10/01 09:36:25午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 52.7120%
10/01 09:36:25午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:36:25午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.7120%
10/01 09:36:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.9531 (0.7406)	Arch Loss 10.3243 (9.9138)	Arch Hard Loss 2.3221 (1.9112)	Arch Alpha Loss 11.4318 (11.4323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.5%)	
10/01 09:37:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.7018 (0.7578)	Arch Loss 9.4510 (9.9413)	Arch Hard Loss 1.4484 (1.9388)	Arch Alpha Loss 11.4323 (11.4322)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.3%)	
10/01 09:37:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.6834 (0.7674)	Arch Loss 9.7000 (9.9578)	Arch Hard Loss 1.6968 (1.9551)	Arch Alpha Loss 11.4331 (11.4324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.2%)	
10/01 09:38:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9090 (0.7831)	Arch Loss 9.9721 (9.9561)	Arch Hard Loss 1.9694 (1.9533)	Arch Alpha Loss 11.4325 (11.4325)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.7%, 96.0%)	
10/01 09:38:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 75.7240%
10/01 09:38:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.9040	Prec@(1,5) (53.0%, 81.6%)
10/01 09:38:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.9178	Prec@(1,5) (53.0%, 81.9%)
10/01 09:38:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.9209	Prec@(1,5) (53.2%, 81.8%)
10/01 09:38:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.9103	Prec@(1,5) (53.2%, 81.8%)
10/01 09:38:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 53.1680%
10/01 09:38:43午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:38:44午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.1680%
10/01 09:39:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8494 (0.6758)	Arch Loss 9.7082 (9.8738)	Arch Hard Loss 1.7057 (1.8713)	Arch Alpha Loss 11.4321 (11.4321)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.6%)	
10/01 09:39:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.5619 (0.7053)	Arch Loss 10.0757 (9.9312)	Arch Hard Loss 2.0730 (1.9286)	Arch Alpha Loss 11.4324 (11.4324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.5%)	
10/01 09:40:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.6502 (0.7232)	Arch Loss 9.8234 (9.9458)	Arch Hard Loss 1.8209 (1.9431)	Arch Alpha Loss 11.4321 (11.4324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.3%)	
10/01 09:40:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.5142 (0.7337)	Arch Loss 10.2419 (9.9661)	Arch Hard Loss 2.2394 (1.9635)	Arch Alpha Loss 11.4322 (11.4323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.3%)	
10/01 09:40:39午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 77.3720%
10/01 09:40:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.9326	Prec@(1,5) (54.0%, 81.7%)
10/01 09:40:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9524	Prec@(1,5) (53.5%, 81.7%)
10/01 09:40:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9288	Prec@(1,5) (53.7%, 82.2%)
10/01 09:40:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9276	Prec@(1,5) (53.5%, 82.2%)
10/01 09:40:57午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 53.5240%
10/01 09:40:57午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:40:57午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.5240%
10/01 09:41:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.6255 (0.6454)	Arch Loss 9.8509 (10.0018)	Arch Hard Loss 1.8484 (1.9992)	Arch Alpha Loss 11.4322 (11.4323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.2%)	
10/01 09:41:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.7559 (0.6574)	Arch Loss 10.2598 (9.9945)	Arch Hard Loss 2.2578 (1.9921)	Arch Alpha Loss 11.4315 (11.4320)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 97.2%)	
10/01 09:42:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.5688 (0.6670)	Arch Loss 9.5387 (9.9860)	Arch Hard Loss 1.5358 (1.9836)	Arch Alpha Loss 11.4326 (11.4320)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 97.1%)	
10/01 09:42:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.6040 (0.6755)	Arch Loss 9.5266 (9.9826)	Arch Hard Loss 1.5238 (1.9801)	Arch Alpha Loss 11.4326 (11.4321)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 97.0%)	
10/01 09:42:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 78.9280%
10/01 09:42:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9335	Prec@(1,5) (53.7%, 82.4%)
10/01 09:43:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9095	Prec@(1,5) (53.8%, 82.5%)
10/01 09:43:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9045	Prec@(1,5) (53.8%, 82.5%)
10/01 09:43:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8952	Prec@(1,5) (53.9%, 82.6%)
10/01 09:43:12午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 53.9040%
10/01 09:43:12午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:43:12午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.9040%
10/01 09:43:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6153 (0.5801)	Arch Loss 9.8667 (9.9918)	Arch Hard Loss 1.8639 (1.9892)	Arch Alpha Loss 11.4327 (11.4323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 98.0%)	
10/01 09:44:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.7367 (0.6016)	Arch Loss 9.8772 (9.9868)	Arch Hard Loss 1.8739 (1.9840)	Arch Alpha Loss 11.4333 (11.4325)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.7%)	
10/01 09:44:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7107 (0.6098)	Arch Loss 9.4863 (9.9980)	Arch Hard Loss 1.4835 (1.9952)	Arch Alpha Loss 11.4325 (11.4326)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.6%)	
10/01 09:45:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6532 (0.6211)	Arch Loss 10.2316 (9.9929)	Arch Hard Loss 2.2294 (1.9902)	Arch Alpha Loss 11.4317 (11.4325)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.5%)	
10/01 09:45:09午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 80.5840%
10/01 09:45:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.9842	Prec@(1,5) (54.0%, 81.7%)
10/01 09:45:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9801	Prec@(1,5) (54.0%, 81.8%)
10/01 09:45:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9570	Prec@(1,5) (54.1%, 82.3%)
10/01 09:45:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9543	Prec@(1,5) (54.1%, 82.1%)
10/01 09:45:27午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 54.1480%
10/01 09:45:27午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:45:28午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.1480%
10/01 09:45:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.4037 (0.5591)	Arch Loss 9.7248 (9.9667)	Arch Hard Loss 1.7224 (1.9643)	Arch Alpha Loss 11.4320 (11.4320)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.8%)	
10/01 09:46:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.6013 (0.5606)	Arch Loss 10.5312 (10.0050)	Arch Hard Loss 2.5283 (2.0024)	Arch Alpha Loss 11.4328 (11.4322)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
10/01 09:46:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.6265 (0.5661)	Arch Loss 10.3823 (10.0060)	Arch Hard Loss 2.3794 (2.0033)	Arch Alpha Loss 11.4328 (11.4325)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
10/01 09:47:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.6156 (0.5774)	Arch Loss 10.2759 (10.0076)	Arch Hard Loss 2.2728 (2.0047)	Arch Alpha Loss 11.4329 (11.4326)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.8%)	
10/01 09:47:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 82.4280%
10/01 09:47:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.9426	Prec@(1,5) (54.4%, 82.7%)
10/01 09:47:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.9253	Prec@(1,5) (54.9%, 82.9%)
10/01 09:47:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9529	Prec@(1,5) (54.3%, 82.7%)
10/01 09:47:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9532	Prec@(1,5) (54.4%, 82.7%)
10/01 09:47:44午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 54.3800%
10/01 09:47:44午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:47:44午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.3800%
10/01 09:48:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.5252 (0.4981)	Arch Loss 9.5022 (10.0086)	Arch Hard Loss 1.4991 (2.0056)	Arch Alpha Loss 11.4330 (11.4329)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.4%)	
10/01 09:48:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6650 (0.5107)	Arch Loss 10.2597 (10.0094)	Arch Hard Loss 2.2564 (2.0063)	Arch Alpha Loss 11.4333 (11.4331)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
10/01 09:49:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.4966 (0.5218)	Arch Loss 10.2087 (10.0387)	Arch Hard Loss 2.2051 (2.0354)	Arch Alpha Loss 11.4336 (11.4333)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.3%)	
10/01 09:49:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.5823 (0.5298)	Arch Loss 10.1031 (10.0433)	Arch Hard Loss 2.0994 (2.0400)	Arch Alpha Loss 11.4339 (11.4334)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.3%)	
10/01 09:49:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 83.4480%
10/01 09:49:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9907	Prec@(1,5) (54.2%, 82.3%)
10/01 09:49:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9883	Prec@(1,5) (54.3%, 82.4%)
10/01 09:49:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9977	Prec@(1,5) (54.1%, 82.4%)
10/01 09:50:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9802	Prec@(1,5) (54.2%, 82.5%)
10/01 09:50:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 54.1920%
10/01 09:50:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:50:01午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.3800%
10/01 09:50:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.5047 (0.4588)	Arch Loss 9.9793 (10.0382)	Arch Hard Loss 1.9753 (2.0342)	Arch Alpha Loss 11.4343 (11.4343)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.7%)	
10/01 09:51:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6518 (0.4676)	Arch Loss 10.4605 (10.0558)	Arch Hard Loss 2.4568 (2.0518)	Arch Alpha Loss 11.4340 (11.4342)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.7%)	
10/01 09:51:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.5265 (0.4764)	Arch Loss 9.6948 (10.0538)	Arch Hard Loss 1.6909 (2.0499)	Arch Alpha Loss 11.4340 (11.4342)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.6%)	
10/01 09:52:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.5961 (0.4849)	Arch Loss 10.0652 (10.0453)	Arch Hard Loss 2.0614 (2.0414)	Arch Alpha Loss 11.4341 (11.4342)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.5%)	
10/01 09:52:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 84.9000%
10/01 09:52:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9677	Prec@(1,5) (53.7%, 82.6%)
10/01 09:52:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.9954	Prec@(1,5) (54.2%, 82.7%)
10/01 09:52:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.0077	Prec@(1,5) (54.3%, 82.6%)
10/01 09:52:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.0075	Prec@(1,5) (54.3%, 82.5%)
10/01 09:52:19午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 54.2920%
10/01 09:52:19午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:52:19午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.3800%
10/01 09:52:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.4638 (0.4162)	Arch Loss 10.3217 (9.9638)	Arch Hard Loss 2.3178 (1.9599)	Arch Alpha Loss 11.4342 (11.4342)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.7%)	
10/01 09:53:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5130 (0.4308)	Arch Loss 9.8040 (10.0037)	Arch Hard Loss 1.7999 (1.9997)	Arch Alpha Loss 11.4344 (11.4343)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
10/01 09:53:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4755 (0.4417)	Arch Loss 9.9847 (10.0389)	Arch Hard Loss 1.9797 (2.0347)	Arch Alpha Loss 11.4356 (11.4345)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
10/01 09:54:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.3132 (0.4457)	Arch Loss 10.2334 (10.0490)	Arch Hard Loss 2.2281 (2.0446)	Arch Alpha Loss 11.4361 (11.4349)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.7%)	
10/01 09:54:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 86.3760%
10/01 09:54:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9943	Prec@(1,5) (55.0%, 82.5%)
10/01 09:54:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9925	Prec@(1,5) (54.8%, 82.4%)
10/01 09:54:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.0027	Prec@(1,5) (54.6%, 82.5%)
10/01 09:54:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9966	Prec@(1,5) (54.8%, 82.5%)
10/01 09:54:34午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 54.7640%
10/01 09:54:34午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 09:54:34午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.7640%
10/01 09:55:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.2078 (0.3942)	Arch Loss 9.8843 (10.1037)	Arch Hard Loss 1.8785 (2.0981)	Arch Alpha Loss 11.4368 (11.4366)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.0%)	
10/01 09:55:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5393 (0.3931)	Arch Loss 9.7502 (10.0587)	Arch Hard Loss 1.7444 (2.0530)	Arch Alpha Loss 11.4368 (11.4366)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.1%, 99.0%)	
10/01 09:56:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.4436 (0.3993)	Arch Loss 9.6392 (10.0670)	Arch Hard Loss 1.6339 (2.0615)	Arch Alpha Loss 11.4360 (11.4365)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.0%)	
10/01 09:56:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.3766 (0.4064)	Arch Loss 9.6446 (10.0601)	Arch Hard Loss 1.6392 (2.0545)	Arch Alpha Loss 11.4363 (11.4364)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
10/01 09:56:33午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 87.7760%
10/01 09:56:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.9970	Prec@(1,5) (54.5%, 82.9%)
10/01 09:56:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.9797	Prec@(1,5) (55.1%, 83.3%)
10/01 09:56:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.0026	Prec@(1,5) (54.7%, 82.8%)
10/01 09:56:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9972	Prec@(1,5) (54.8%, 82.8%)
10/01 09:56:50午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 54.7920%
10/01 09:56:50午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:56:50午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.7920%
10/01 09:57:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.1643 (0.3565)	Arch Loss 9.8991 (10.0244)	Arch Hard Loss 1.8939 (2.0193)	Arch Alpha Loss 11.4360 (11.4359)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.3%)	
10/01 09:57:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.3995 (0.3634)	Arch Loss 9.8147 (10.0543)	Arch Hard Loss 1.8096 (2.0493)	Arch Alpha Loss 11.4359 (11.4358)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.2%)	
10/01 09:58:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.3604 (0.3706)	Arch Loss 10.3451 (10.0702)	Arch Hard Loss 2.3399 (2.0652)	Arch Alpha Loss 11.4360 (11.4359)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.2%)	
10/01 09:58:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.3412 (0.3736)	Arch Loss 9.8468 (10.0680)	Arch Hard Loss 1.8415 (2.0628)	Arch Alpha Loss 11.4362 (11.4360)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.1%)	
10/01 09:58:48午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 88.7800%
10/01 09:58:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.0342	Prec@(1,5) (53.8%, 82.9%)
10/01 09:58:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.0103	Prec@(1,5) (54.6%, 82.9%)
10/01 09:59:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.0066	Prec@(1,5) (54.9%, 82.8%)
10/01 09:59:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.0247	Prec@(1,5) (55.0%, 82.7%)
10/01 09:59:06午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 54.9560%
10/01 09:59:06午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 09:59:06午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9560%
10/01 09:59:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.2738 (0.3270)	Arch Loss 9.6818 (10.0642)	Arch Hard Loss 1.6757 (2.0583)	Arch Alpha Loss 11.4373 (11.4369)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.6%)	
10/01 10:00:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.1789 (0.3242)	Arch Loss 10.0244 (10.0755)	Arch Hard Loss 2.0177 (2.0692)	Arch Alpha Loss 11.4381 (11.4375)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.6%)	
10/01 10:00:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.4156 (0.3403)	Arch Loss 10.2966 (10.0801)	Arch Hard Loss 2.2899 (2.0737)	Arch Alpha Loss 11.4381 (11.4377)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.4%)	
10/01 10:01:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.2832 (0.3487)	Arch Loss 10.1001 (10.0865)	Arch Hard Loss 2.0932 (2.0800)	Arch Alpha Loss 11.4384 (11.4379)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.3%)	
10/01 10:01:04午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 89.6760%
10/01 10:01:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.0475	Prec@(1,5) (55.1%, 83.0%)
10/01 10:01:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.0312	Prec@(1,5) (54.9%, 82.7%)
10/01 10:01:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.0359	Prec@(1,5) (54.9%, 82.4%)
10/01 10:01:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.0334	Prec@(1,5) (55.0%, 82.6%)
10/01 10:01:21午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 55.0160%
10/01 10:01:21午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:01:22午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.0160%
10/01 10:01:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.2881 (0.3200)	Arch Loss 10.2270 (10.0863)	Arch Hard Loss 2.2200 (2.0791)	Arch Alpha Loss 11.4385 (11.4389)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.3%)	
10/01 10:02:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.2941 (0.3169)	Arch Loss 9.6678 (10.0683)	Arch Hard Loss 1.6616 (2.0613)	Arch Alpha Loss 11.4375 (11.4385)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
10/01 10:02:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.2491 (0.3181)	Arch Loss 10.2334 (10.0955)	Arch Hard Loss 2.2270 (2.0887)	Arch Alpha Loss 11.4378 (11.4382)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
10/01 10:03:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.3468 (0.3229)	Arch Loss 10.6277 (10.0955)	Arch Hard Loss 2.6211 (2.0888)	Arch Alpha Loss 11.4380 (11.4382)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.3%)	
10/01 10:03:21午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 90.2680%
10/01 10:03:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0520	Prec@(1,5) (55.3%, 82.5%)
10/01 10:03:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.0637	Prec@(1,5) (54.7%, 82.3%)
10/01 10:03:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.0505	Prec@(1,5) (55.0%, 82.5%)
10/01 10:03:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.0408	Prec@(1,5) (55.3%, 82.6%)
10/01 10:03:39午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 55.3360%
10/01 10:03:39午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:03:39午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3360%
10/01 10:04:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.2651 (0.2982)	Arch Loss 9.6085 (10.1406)	Arch Hard Loss 1.6017 (2.1338)	Arch Alpha Loss 11.4382 (11.4383)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.6%)	
10/01 10:04:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.3705 (0.2958)	Arch Loss 10.6717 (10.1276)	Arch Hard Loss 2.6650 (2.1208)	Arch Alpha Loss 11.4382 (11.4383)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.6%)	
10/01 10:05:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.3110 (0.2990)	Arch Loss 9.7423 (10.1245)	Arch Hard Loss 1.7360 (2.1177)	Arch Alpha Loss 11.4377 (11.4382)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.6%)	
10/01 10:05:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4805 (0.3055)	Arch Loss 9.9058 (10.1162)	Arch Hard Loss 1.8992 (2.1095)	Arch Alpha Loss 11.4380 (11.4381)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.5%)	
10/01 10:05:37午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 91.0280%
10/01 10:05:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.1006	Prec@(1,5) (54.3%, 82.3%)
10/01 10:05:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.0809	Prec@(1,5) (54.7%, 82.4%)
10/01 10:05:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.0487	Prec@(1,5) (55.2%, 82.7%)
10/01 10:05:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.0608	Prec@(1,5) (55.1%, 82.6%)
10/01 10:05:54午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 55.0640%
10/01 10:05:54午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:05:55午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3360%
10/01 10:06:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.1849 (0.2849)	Arch Loss 10.3661 (10.0753)	Arch Hard Loss 2.3589 (2.0683)	Arch Alpha Loss 11.4389 (11.4386)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.6%)	
10/01 10:06:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.3606 (0.2913)	Arch Loss 10.6464 (10.0781)	Arch Hard Loss 2.6403 (2.0712)	Arch Alpha Loss 11.4373 (11.4385)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
10/01 10:07:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5504 (0.2938)	Arch Loss 10.2649 (10.0966)	Arch Hard Loss 2.2585 (2.0899)	Arch Alpha Loss 11.4376 (11.4381)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
10/01 10:07:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.1891 (0.2964)	Arch Loss 9.6159 (10.1145)	Arch Hard Loss 1.6085 (2.1078)	Arch Alpha Loss 11.4392 (11.4381)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
10/01 10:07:54午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 91.1640%
10/01 10:07:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.0589	Prec@(1,5) (55.1%, 82.6%)
10/01 10:08:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.0396	Prec@(1,5) (55.5%, 82.9%)
10/01 10:08:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.0417	Prec@(1,5) (55.5%, 82.9%)
10/01 10:08:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.0578	Prec@(1,5) (55.3%, 82.7%)
10/01 10:08:12午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 55.2680%
10/01 10:08:12午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:08:12午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3360%
10/01 10:08:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.2120 (0.2695)	Arch Loss 9.7699 (10.0866)	Arch Hard Loss 1.7625 (2.0795)	Arch Alpha Loss 11.4392 (11.4387)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
10/01 10:09:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.3702 (0.2672)	Arch Loss 10.3414 (10.1121)	Arch Hard Loss 2.3336 (2.1047)	Arch Alpha Loss 11.4397 (11.4391)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.5%)	
10/01 10:09:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.2234 (0.2723)	Arch Loss 11.1588 (10.1148)	Arch Hard Loss 3.1514 (2.1074)	Arch Alpha Loss 11.4391 (11.4392)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
10/01 10:10:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.2421 (0.2738)	Arch Loss 9.3202 (10.1228)	Arch Hard Loss 1.3122 (2.1153)	Arch Alpha Loss 11.4400 (11.4393)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
10/01 10:10:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 92.2160%
10/01 10:10:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.0349	Prec@(1,5) (55.5%, 83.2%)
10/01 10:10:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.0223	Prec@(1,5) (55.9%, 83.4%)
10/01 10:10:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.0388	Prec@(1,5) (55.6%, 83.0%)
10/01 10:10:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.0484	Prec@(1,5) (55.4%, 82.9%)
10/01 10:10:29午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 55.3960%
10/01 10:10:29午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:10:30午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3960%
10/01 10:11:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.2092 (0.2706)	Arch Loss 9.6629 (10.1364)	Arch Hard Loss 1.6546 (2.1281)	Arch Alpha Loss 11.4404 (11.4404)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
10/01 10:11:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.3309 (0.2657)	Arch Loss 10.1127 (10.1416)	Arch Hard Loss 2.1034 (2.1330)	Arch Alpha Loss 11.4417 (11.4409)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
10/01 10:12:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3271 (0.2678)	Arch Loss 10.0799 (10.1353)	Arch Hard Loss 2.0717 (2.1266)	Arch Alpha Loss 11.4403 (11.4410)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
10/01 10:12:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.3069 (0.2669)	Arch Loss 9.6181 (10.1358)	Arch Hard Loss 1.6095 (2.1272)	Arch Alpha Loss 11.4408 (11.4409)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
10/01 10:12:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 92.3400%
10/01 10:12:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.0316	Prec@(1,5) (55.5%, 82.8%)
10/01 10:12:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.0464	Prec@(1,5) (55.3%, 82.6%)
10/01 10:12:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.0595	Prec@(1,5) (55.3%, 82.6%)
10/01 10:12:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.0586	Prec@(1,5) (55.5%, 82.7%)
10/01 10:12:46午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 55.5160%
10/01 10:12:46午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:12:47午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.5160%
10/01 10:13:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.2768 (0.2480)	Arch Loss 10.0246 (10.1411)	Arch Hard Loss 2.0158 (2.1324)	Arch Alpha Loss 11.4412 (11.4410)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.6%)	
10/01 10:13:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.3244 (0.2516)	Arch Loss 9.7390 (10.1515)	Arch Hard Loss 1.7300 (2.1425)	Arch Alpha Loss 11.4414 (11.4414)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
10/01 10:14:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.2039 (0.2518)	Arch Loss 10.1936 (10.1470)	Arch Hard Loss 2.1849 (2.1380)	Arch Alpha Loss 11.4410 (11.4415)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
10/01 10:14:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.3189 (0.2535)	Arch Loss 10.0899 (10.1563)	Arch Hard Loss 2.0811 (2.1474)	Arch Alpha Loss 11.4411 (11.4413)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
10/01 10:14:45午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 92.9160%
10/01 10:14:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.0748	Prec@(1,5) (55.7%, 82.9%)
10/01 10:14:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.0483	Prec@(1,5) (55.8%, 83.3%)
10/01 10:14:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.0833	Prec@(1,5) (55.5%, 82.9%)
10/01 10:15:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.0782	Prec@(1,5) (55.4%, 82.9%)
10/01 10:15:02午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 55.3800%
10/01 10:15:02午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 10:15:02午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.5160%
10/01 10:15:02午前 searchStage_KD_main.py:101 [INFO] Final best Prec@1 = 55.5160%
10/01 10:15:02午前 searchStage_KD_main.py:102 [INFO] Final Best Genotype = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
