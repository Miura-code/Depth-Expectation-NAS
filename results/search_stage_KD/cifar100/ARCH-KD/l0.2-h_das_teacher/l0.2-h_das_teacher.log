10/01 12:45:24AM parser.py:28 [INFO] 
10/01 12:45:24AM parser.py:29 [INFO] Parameters:
10/01 12:45:24AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.2-h_das_teacher/DAG
10/01 12:45:24AM parser.py:31 [INFO] T=10.0
10/01 12:45:24AM parser.py:31 [INFO] ADVANCED=True
10/01 12:45:24AM parser.py:31 [INFO] ALPHA_LR=0.0003
10/01 12:45:24AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
10/01 12:45:24AM parser.py:31 [INFO] BATCH_SIZE=64
10/01 12:45:24AM parser.py:31 [INFO] CASCADE=False
10/01 12:45:24AM parser.py:31 [INFO] CHECKPOINT_RESET=False
10/01 12:45:24AM parser.py:31 [INFO] CUTOUT_LENGTH=0
10/01 12:45:24AM parser.py:31 [INFO] DATA_PATH=../data/
10/01 12:45:24AM parser.py:31 [INFO] DATASET=cifar100
10/01 12:45:24AM parser.py:31 [INFO] DEPTH_COEF=0.0
10/01 12:45:24AM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
10/01 12:45:24AM parser.py:31 [INFO] EPOCHS=50
10/01 12:45:24AM parser.py:31 [INFO] EXP_NAME=l0.2-h_das_teacher
10/01 12:45:24AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
10/01 12:45:24AM parser.py:31 [INFO] GPUS=[0]
10/01 12:45:24AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
10/01 12:45:24AM parser.py:31 [INFO] INIT_CHANNELS=16
10/01 12:45:24AM parser.py:31 [INFO] L=0.2
10/01 12:45:24AM parser.py:31 [INFO] LAYERS=20
10/01 12:45:24AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
10/01 12:45:24AM parser.py:31 [INFO] NAME=ARCH-KD
10/01 12:45:24AM parser.py:31 [INFO] NONKD=False
10/01 12:45:24AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.2-h_das_teacher
10/01 12:45:24AM parser.py:31 [INFO] PCDARTS=False
10/01 12:45:24AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.2-h_das_teacher/plots
10/01 12:45:24AM parser.py:31 [INFO] PRINT_FREQ=100
10/01 12:45:24AM parser.py:31 [INFO] RESUME_PATH=None
10/01 12:45:24AM parser.py:31 [INFO] SAVE=l0.2-h_das_teacher
10/01 12:45:24AM parser.py:31 [INFO] SEED=0
10/01 12:45:24AM parser.py:31 [INFO] SHARE_STAGE=False
10/01 12:45:24AM parser.py:31 [INFO] SLIDE_WINDOW=8
10/01 12:45:24AM parser.py:31 [INFO] SPEC_CELL=True
10/01 12:45:24AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
10/01 12:45:24AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
10/01 12:45:24AM parser.py:31 [INFO] TRAIN_PORTION=0.5
10/01 12:45:24AM parser.py:31 [INFO] TYPE=ArchKD
10/01 12:45:24AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
10/01 12:45:24AM parser.py:31 [INFO] W_LR=0.025
10/01 12:45:24AM parser.py:31 [INFO] W_LR_MIN=0.001
10/01 12:45:24AM parser.py:31 [INFO] W_MOMENTUM=0.9
10/01 12:45:24AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
10/01 12:45:24AM parser.py:31 [INFO] WORKERS=4
10/01 12:45:24AM parser.py:32 [INFO] 
10/01 12:45:26AM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
10/01 12:45:26AM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
10/01 12:45:58AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.2057 (4.5697)	Arch Loss 11.9063 (12.0856)	Arch Hard Loss 4.4769 (4.5439)	Arch Alpha Loss 37.1470 (37.7088)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.7%, 11.1%)	
10/01 12:46:28AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0833 (4.3748)	Arch Loss 11.0212 (11.7617)	Arch Hard Loss 3.8269 (4.3352)	Arch Alpha Loss 35.9715 (37.1325)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.3%, 15.8%)	
10/01 12:46:56AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8894 (4.2437)	Arch Loss 10.8778 (11.5263)	Arch Hard Loss 3.9232 (4.2174)	Arch Alpha Loss 34.7729 (36.5443)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.4%, 19.8%)	
10/01 12:47:23AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9086 (4.1664)	Arch Loss 10.2586 (11.3393)	Arch Hard Loss 3.5221 (4.1376)	Arch Alpha Loss 33.6822 (36.0084)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.2%, 21.8%)	
10/01 12:47:24AM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 6.1880%
10/01 12:47:28AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9403	Prec@(1,5) (8.5%, 29.0%)
10/01 12:47:33AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9579	Prec@(1,5) (8.4%, 28.7%)
10/01 12:47:37AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9526	Prec@(1,5) (8.3%, 28.7%)
10/01 12:47:41AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9483	Prec@(1,5) (8.3%, 28.7%)
10/01 12:47:41AM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 8.3160%
10/01 12:47:41AM searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:47:42AM searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 8.3160%
10/01 12:48:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6456 (3.8046)	Arch Loss 10.2735 (10.4008)	Arch Hard Loss 3.7817 (3.7892)	Arch Alpha Loss 32.4590 (33.0579)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.7%, 33.2%)	
10/01 12:48:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.5866 (3.7433)	Arch Loss 9.7479 (10.2473)	Arch Hard Loss 3.4974 (3.7566)	Arch Alpha Loss 31.2525 (32.4533)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.5%, 35.0%)	
10/01 12:49:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7492 (3.7130)	Arch Loss 9.6278 (10.0797)	Arch Hard Loss 3.6150 (3.7091)	Arch Alpha Loss 30.0641 (31.8526)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.0%, 35.8%)	
10/01 12:49:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.4384 (3.6719)	Arch Loss 9.3304 (9.9327)	Arch Hard Loss 3.5273 (3.6693)	Arch Alpha Loss 29.0153 (31.3171)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.5%, 36.8%)	
10/01 12:49:40午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 12.5440%
10/01 12:49:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6341	Prec@(1,5) (13.3%, 38.2%)
10/01 12:49:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6313	Prec@(1,5) (13.2%, 38.3%)
10/01 12:49:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6338	Prec@(1,5) (13.3%, 38.2%)
10/01 12:49:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6286	Prec@(1,5) (13.2%, 38.5%)
10/01 12:49:57午前 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 13.2480%
10/01 12:49:57午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:49:58午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 13.2480%
10/01 12:50:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6075 (3.4563)	Arch Loss 9.0463 (9.1749)	Arch Hard Loss 3.4721 (3.4891)	Arch Alpha Loss 27.8710 (28.4293)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.5%, 42.5%)	
10/01 12:50:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.2861 (3.4240)	Arch Loss 8.9764 (9.0297)	Arch Hard Loss 3.6212 (3.4553)	Arch Alpha Loss 26.7760 (27.8717)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.3%, 43.2%)	
10/01 12:51:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.0697 (3.3863)	Arch Loss 8.2649 (8.8807)	Arch Hard Loss 3.1198 (3.4151)	Arch Alpha Loss 25.7255 (27.3282)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.2%, 44.5%)	
10/01 12:51:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.2971 (3.3680)	Arch Loss 8.2618 (8.7523)	Arch Hard Loss 3.2985 (3.3819)	Arch Alpha Loss 24.8166 (26.8516)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.4%, 45.2%)	
10/01 12:51:56午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 17.4360%
10/01 12:52:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2906	Prec@(1,5) (20.3%, 47.9%)
10/01 12:52:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.2920	Prec@(1,5) (19.8%, 47.5%)
10/01 12:52:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.2882	Prec@(1,5) (19.6%, 47.9%)
10/01 12:52:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.2946	Prec@(1,5) (19.6%, 47.6%)
10/01 12:52:13午前 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 19.6320%
10/01 12:52:13午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:52:13午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 19.6320%
10/01 12:52:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 2.8764 (3.1820)	Arch Loss 7.9832 (8.0933)	Arch Hard Loss 3.2134 (3.2295)	Arch Alpha Loss 23.8490 (24.3188)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.4%, 50.4%)	
10/01 12:53:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1336 (3.1711)	Arch Loss 7.5760 (7.9740)	Arch Hard Loss 2.9879 (3.2035)	Arch Alpha Loss 22.9407 (23.8525)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.2%, 50.8%)	
10/01 12:53:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1719 (3.1503)	Arch Loss 7.3508 (7.8572)	Arch Hard Loss 2.9336 (3.1765)	Arch Alpha Loss 22.0862 (23.4033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.6%, 51.3%)	
10/01 12:54:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.2155 (3.1351)	Arch Loss 7.6513 (7.7626)	Arch Hard Loss 3.3784 (3.1598)	Arch Alpha Loss 21.3644 (23.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.7%, 51.8%)	
10/01 12:54:11午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 21.7000%
10/01 12:54:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1474	Prec@(1,5) (22.1%, 51.9%)
10/01 12:54:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1456	Prec@(1,5) (21.6%, 52.6%)
10/01 12:54:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1494	Prec@(1,5) (21.7%, 52.1%)
10/01 12:54:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1497	Prec@(1,5) (21.8%, 52.0%)
10/01 12:54:28午前 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 21.7480%
10/01 12:54:28午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:54:29午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 21.7480%
10/01 12:54:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.7625 (2.9834)	Arch Loss 6.9583 (7.2522)	Arch Hard Loss 2.8379 (3.0579)	Arch Alpha Loss 20.6019 (20.9715)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.9%)	
10/01 12:55:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.7018 (2.9727)	Arch Loss 6.9505 (7.1514)	Arch Hard Loss 2.9711 (3.0301)	Arch Alpha Loss 19.8969 (20.6067)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.2%, 56.0%)	
10/01 12:55:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.1179 (2.9572)	Arch Loss 6.7124 (7.0686)	Arch Hard Loss 2.8639 (3.0169)	Arch Alpha Loss 19.2424 (20.2586)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.3%, 56.4%)	
10/01 12:56:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8473 (2.9489)	Arch Loss 6.9016 (6.9828)	Arch Hard Loss 3.1628 (2.9909)	Arch Alpha Loss 18.6937 (19.9595)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.4%, 56.6%)	
10/01 12:56:24午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 25.4360%
10/01 12:56:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.9345	Prec@(1,5) (26.4%, 57.3%)
10/01 12:56:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9334	Prec@(1,5) (26.4%, 57.3%)
10/01 12:56:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9512	Prec@(1,5) (26.1%, 56.8%)
10/01 12:56:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9537	Prec@(1,5) (26.2%, 56.8%)
10/01 12:56:41午前 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 26.2000%
10/01 12:56:41午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:56:41午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 26.2000%
10/01 12:57:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.7259 (2.7946)	Arch Loss 6.4780 (6.5725)	Arch Hard Loss 2.8536 (2.8928)	Arch Alpha Loss 18.1220 (18.3982)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.4%, 60.5%)	
10/01 12:57:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0912 (2.7900)	Arch Loss 6.2791 (6.4936)	Arch Hard Loss 2.7589 (2.8683)	Arch Alpha Loss 17.6010 (18.1265)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.4%, 60.4%)	
10/01 12:58:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.5633 (2.7925)	Arch Loss 6.1649 (6.4364)	Arch Hard Loss 2.7416 (2.8627)	Arch Alpha Loss 17.1166 (17.8687)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.6%, 60.4%)	
10/01 12:58:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.4928 (2.7764)	Arch Loss 6.0490 (6.3709)	Arch Hard Loss 2.7064 (2.8414)	Arch Alpha Loss 16.7132 (17.6475)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.0%, 60.8%)	
10/01 12:58:40午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 28.9720%
10/01 12:58:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8328	Prec@(1,5) (27.8%, 59.5%)
10/01 12:58:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8329	Prec@(1,5) (27.8%, 59.9%)
10/01 12:58:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8326	Prec@(1,5) (27.6%, 60.0%)
10/01 12:58:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8335	Prec@(1,5) (27.5%, 59.8%)
10/01 12:58:58午前 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 27.5160%
10/01 12:58:58午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:58:59午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 27.5160%
10/01 12:59:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.7172 (2.6366)	Arch Loss 5.9434 (6.0517)	Arch Hard Loss 2.6844 (2.7523)	Arch Alpha Loss 16.2954 (16.4972)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 64.1%)	
10/01 01:00:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.4913 (2.6512)	Arch Loss 5.6852 (6.0379)	Arch Hard Loss 2.5021 (2.7781)	Arch Alpha Loss 15.9150 (16.2993)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.6%, 64.0%)	
10/01 01:00:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.8442 (2.6415)	Arch Loss 5.7918 (5.9765)	Arch Hard Loss 2.6789 (2.7543)	Arch Alpha Loss 15.5642 (16.1113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.4%)	
10/01 01:00:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8664 (2.6364)	Arch Loss 5.5556 (5.9261)	Arch Hard Loss 2.5011 (2.7360)	Arch Alpha Loss 15.2721 (15.9505)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.3%)	
10/01 01:00:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 31.8320%
10/01 01:01:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6581	Prec@(1,5) (32.0%, 63.2%)
10/01 01:01:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6513	Prec@(1,5) (32.0%, 63.7%)
10/01 01:01:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6424	Prec@(1,5) (32.2%, 64.0%)
10/01 01:01:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6468	Prec@(1,5) (32.3%, 63.8%)
10/01 01:01:13午前 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 32.2640%
10/01 01:01:13午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:01:13午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 32.2640%
10/01 01:01:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.5988 (2.5007)	Arch Loss 5.6353 (5.6926)	Arch Hard Loss 2.6407 (2.6691)	Arch Alpha Loss 14.9734 (15.1175)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.8%, 67.0%)	
10/01 01:02:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4859 (2.4901)	Arch Loss 5.1349 (5.6570)	Arch Hard Loss 2.1946 (2.6618)	Arch Alpha Loss 14.7017 (14.9761)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.6%, 67.5%)	
10/01 01:02:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.8056 (2.5001)	Arch Loss 5.7625 (5.6247)	Arch Hard Loss 2.8722 (2.6563)	Arch Alpha Loss 14.4514 (14.8419)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 67.4%)	
10/01 01:03:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.2708 (2.4984)	Arch Loss 5.3166 (5.5802)	Arch Hard Loss 2.4683 (2.6348)	Arch Alpha Loss 14.2415 (14.7270)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 67.5%)	
10/01 01:03:10午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 34.5120%
10/01 01:03:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6247	Prec@(1,5) (32.9%, 64.2%)
10/01 01:03:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5999	Prec@(1,5) (33.4%, 64.8%)
10/01 01:03:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5876	Prec@(1,5) (33.7%, 65.3%)
10/01 01:03:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5867	Prec@(1,5) (33.7%, 65.3%)
10/01 01:03:28午前 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 33.6760%
10/01 01:03:28午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:03:28午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 33.6760%
10/01 01:04:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.0350 (2.3636)	Arch Loss 5.4365 (5.4247)	Arch Hard Loss 2.6309 (2.5984)	Arch Alpha Loss 14.0283 (14.1313)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.1%)	
10/01 01:04:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.2172 (2.3748)	Arch Loss 5.2789 (5.3824)	Arch Hard Loss 2.5119 (2.5763)	Arch Alpha Loss 13.8347 (14.0303)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 70.4%)	
10/01 01:05:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.1536 (2.3886)	Arch Loss 5.2490 (5.3567)	Arch Hard Loss 2.5177 (2.5698)	Arch Alpha Loss 13.6565 (13.9347)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.2%, 70.2%)	
10/01 01:05:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.3851 (2.3904)	Arch Loss 5.1244 (5.3238)	Arch Hard Loss 2.4227 (2.5532)	Arch Alpha Loss 13.5082 (13.8530)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 70.0%)	
10/01 01:05:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 37.2840%
10/01 01:05:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4214	Prec@(1,5) (36.3%, 69.4%)
10/01 01:05:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4480	Prec@(1,5) (35.8%, 68.8%)
10/01 01:05:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4653	Prec@(1,5) (35.6%, 68.3%)
10/01 01:05:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4756	Prec@(1,5) (35.4%, 68.1%)
10/01 01:05:45午前 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 35.4440%
10/01 01:05:45午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:05:45午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 35.4440%
10/01 01:06:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.7930 (2.2725)	Arch Loss 5.6919 (5.1911)	Arch Hard Loss 3.0204 (2.5051)	Arch Alpha Loss 13.3574 (13.4299)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 71.9%)	
10/01 01:06:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.1711 (2.2781)	Arch Loss 5.2187 (5.1485)	Arch Hard Loss 2.5751 (2.4769)	Arch Alpha Loss 13.2182 (13.3580)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 71.6%)	
10/01 01:07:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.0114 (2.2909)	Arch Loss 5.0057 (5.1168)	Arch Hard Loss 2.3873 (2.4588)	Arch Alpha Loss 13.0921 (13.2898)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 71.6%)	
10/01 01:07:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1567 (2.2889)	Arch Loss 5.0186 (5.1004)	Arch Hard Loss 2.4211 (2.4541)	Arch Alpha Loss 12.9872 (13.2318)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 71.7%)	
10/01 01:07:45午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 39.5640%
10/01 01:07:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4308	Prec@(1,5) (36.2%, 68.3%)
10/01 01:07:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3947	Prec@(1,5) (37.0%, 69.0%)
10/01 01:07:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3925	Prec@(1,5) (37.0%, 69.3%)
10/01 01:08:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3948	Prec@(1,5) (37.2%, 69.2%)
10/01 01:08:02午前 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 37.1560%
10/01 01:08:02午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:08:03午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 37.1560%
10/01 01:08:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.5485 (2.1290)	Arch Loss 4.9301 (4.9841)	Arch Hard Loss 2.3541 (2.3979)	Arch Alpha Loss 12.8803 (12.9307)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 74.9%)	
10/01 01:09:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.0777 (2.1668)	Arch Loss 5.1235 (4.9714)	Arch Hard Loss 2.5667 (2.3952)	Arch Alpha Loss 12.7843 (12.8809)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 74.5%)	
10/01 01:09:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.8970 (2.1762)	Arch Loss 4.5973 (4.9575)	Arch Hard Loss 2.0581 (2.3908)	Arch Alpha Loss 12.6958 (12.8336)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.4%)	
10/01 01:09:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.4151 (2.1924)	Arch Loss 4.9247 (4.9348)	Arch Hard Loss 2.4004 (2.3762)	Arch Alpha Loss 12.6211 (12.7929)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 73.9%)	
10/01 01:09:57午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 41.4200%
10/01 01:10:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3419	Prec@(1,5) (39.0%, 71.0%)
10/01 01:10:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3413	Prec@(1,5) (39.0%, 71.2%)
10/01 01:10:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3208	Prec@(1,5) (39.2%, 71.7%)
10/01 01:10:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3132	Prec@(1,5) (39.2%, 71.8%)
10/01 01:10:15午前 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 39.1880%
10/01 01:10:15午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:10:16午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 39.1880%
10/01 01:10:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2898 (2.0744)	Arch Loss 4.7865 (4.8732)	Arch Hard Loss 2.2769 (2.3566)	Arch Alpha Loss 12.5480 (12.5831)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 76.5%)	
10/01 01:11:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.3515 (2.0910)	Arch Loss 4.6935 (4.8308)	Arch Hard Loss 2.1971 (2.3211)	Arch Alpha Loss 12.4816 (12.5489)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.5%, 75.8%)	
10/01 01:11:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2429 (2.0976)	Arch Loss 5.0588 (4.8176)	Arch Hard Loss 2.5744 (2.3144)	Arch Alpha Loss 12.4220 (12.5163)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.8%)	
10/01 01:12:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.8832 (2.1029)	Arch Loss 4.8614 (4.8119)	Arch Hard Loss 2.3876 (2.3143)	Arch Alpha Loss 12.3690 (12.4882)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.7%)	
10/01 01:12:10午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 43.3280%
10/01 01:12:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3593	Prec@(1,5) (39.0%, 70.8%)
10/01 01:12:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3488	Prec@(1,5) (39.0%, 70.6%)
10/01 01:12:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3377	Prec@(1,5) (38.9%, 70.9%)
10/01 01:12:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3236	Prec@(1,5) (39.2%, 71.5%)
10/01 01:12:27午前 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 39.1960%
10/01 01:12:27午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:12:28午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 39.1960%
10/01 01:12:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.6749 (1.9810)	Arch Loss 4.7225 (4.7792)	Arch Hard Loss 2.2585 (2.3106)	Arch Alpha Loss 12.3199 (12.3429)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.8%)	
10/01 01:13:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.0268 (1.9990)	Arch Loss 5.1981 (4.7668)	Arch Hard Loss 2.7433 (2.3028)	Arch Alpha Loss 12.2738 (12.3198)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 77.6%)	
10/01 01:14:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9833 (2.0085)	Arch Loss 4.3488 (4.7298)	Arch Hard Loss 1.9025 (2.2703)	Arch Alpha Loss 12.2314 (12.2974)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.3%, 77.5%)	
10/01 01:14:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.9231 (2.0112)	Arch Loss 4.8847 (4.7155)	Arch Hard Loss 2.4452 (2.2598)	Arch Alpha Loss 12.1974 (12.2781)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.3%, 77.4%)	
10/01 01:14:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 45.2720%
10/01 01:14:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2645	Prec@(1,5) (40.9%, 72.5%)
10/01 01:14:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2349	Prec@(1,5) (41.6%, 73.4%)
10/01 01:14:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2371	Prec@(1,5) (41.4%, 73.3%)
10/01 01:14:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2401	Prec@(1,5) (41.5%, 73.3%)
10/01 01:14:44午前 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 41.4720%
10/01 01:14:44午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:14:45午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 41.4720%
10/01 01:15:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.0517 (1.8852)	Arch Loss 4.6882 (4.6637)	Arch Hard Loss 2.2561 (2.2281)	Arch Alpha Loss 12.1603 (12.1780)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 79.5%)	
10/01 01:15:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.0565 (1.9190)	Arch Loss 4.3987 (4.6774)	Arch Hard Loss 1.9731 (2.2451)	Arch Alpha Loss 12.1280 (12.1613)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.7%, 79.0%)	
10/01 01:16:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.2593 (1.9309)	Arch Loss 4.4805 (4.6584)	Arch Hard Loss 2.0604 (2.2293)	Arch Alpha Loss 12.1003 (12.1455)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.1%)	
10/01 01:16:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0158 (1.9446)	Arch Loss 4.3860 (4.6488)	Arch Hard Loss 1.9704 (2.2223)	Arch Alpha Loss 12.0781 (12.1324)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 78.7%)	
10/01 01:16:44午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 46.8800%
10/01 01:16:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2259	Prec@(1,5) (42.3%, 74.3%)
10/01 01:16:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2533	Prec@(1,5) (41.4%, 73.5%)
10/01 01:16:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2407	Prec@(1,5) (41.5%, 73.5%)
10/01 01:17:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2434	Prec@(1,5) (41.2%, 73.4%)
10/01 01:17:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 41.2400%
10/01 01:17:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:17:01午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 41.4720%
10/01 01:17:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8870 (1.8390)	Arch Loss 4.5337 (4.5832)	Arch Hard Loss 2.1226 (2.1700)	Arch Alpha Loss 12.0552 (12.0660)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 80.5%)	
10/01 01:18:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8576 (1.8355)	Arch Loss 4.3672 (4.5983)	Arch Hard Loss 1.9601 (2.1873)	Arch Alpha Loss 12.0355 (12.0554)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.4%)	
10/01 01:18:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.8044 (1.8482)	Arch Loss 4.9095 (4.5815)	Arch Hard Loss 2.5060 (2.1724)	Arch Alpha Loss 12.0172 (12.0455)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.2%)	
10/01 01:18:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.1942 (1.8617)	Arch Loss 4.3967 (4.5867)	Arch Hard Loss 1.9958 (2.1792)	Arch Alpha Loss 12.0043 (12.0375)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.2%)	
10/01 01:18:57午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 48.7840%
10/01 01:19:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1331	Prec@(1,5) (44.4%, 75.0%)
10/01 01:19:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1036	Prec@(1,5) (44.1%, 75.8%)
10/01 01:19:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1026	Prec@(1,5) (44.1%, 75.9%)
10/01 01:19:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1047	Prec@(1,5) (44.3%, 75.8%)
10/01 01:19:15午前 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 44.2880%
10/01 01:19:15午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:19:16午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 44.2880%
10/01 01:19:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.5716 (1.7610)	Arch Loss 4.0294 (4.5432)	Arch Hard Loss 1.6313 (2.1439)	Arch Alpha Loss 11.9906 (11.9966)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.0%)	
10/01 01:20:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.5355 (1.7709)	Arch Loss 4.2169 (4.5442)	Arch Hard Loss 1.8211 (2.1461)	Arch Alpha Loss 11.9793 (11.9906)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.8%)	
10/01 01:20:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.8288 (1.7889)	Arch Loss 4.3350 (4.5371)	Arch Hard Loss 1.9418 (2.1403)	Arch Alpha Loss 11.9661 (11.9842)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.5%)	
10/01 01:21:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.9761 (1.8030)	Arch Loss 4.7477 (4.5384)	Arch Hard Loss 2.3565 (2.1427)	Arch Alpha Loss 11.9562 (11.9788)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.2%)	
10/01 01:21:13午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 50.1560%
10/01 01:21:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1054	Prec@(1,5) (44.2%, 76.3%)
10/01 01:21:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1080	Prec@(1,5) (43.9%, 76.1%)
10/01 01:21:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1187	Prec@(1,5) (43.6%, 76.1%)
10/01 01:21:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1163	Prec@(1,5) (43.7%, 76.0%)
10/01 01:21:30午前 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 43.7160%
10/01 01:21:30午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:21:30午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 44.2880%
10/01 01:22:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.9194 (1.7073)	Arch Loss 4.6268 (4.4456)	Arch Hard Loss 2.2376 (2.0553)	Arch Alpha Loss 11.9460 (11.9513)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.8%)	
10/01 01:22:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.0531 (1.7136)	Arch Loss 4.3497 (4.4760)	Arch Hard Loss 1.9623 (2.0867)	Arch Alpha Loss 11.9372 (11.9464)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.8%)	
10/01 01:23:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.0429 (1.7282)	Arch Loss 4.0648 (4.4765)	Arch Hard Loss 1.6789 (2.0880)	Arch Alpha Loss 11.9296 (11.9421)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.5%)	
10/01 01:23:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.8208 (1.7359)	Arch Loss 5.0782 (4.4812)	Arch Hard Loss 2.6939 (2.0936)	Arch Alpha Loss 11.9214 (11.9382)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.4%, 82.4%)	
10/01 01:23:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 51.4360%
10/01 01:23:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0806	Prec@(1,5) (45.6%, 76.9%)
10/01 01:23:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0871	Prec@(1,5) (45.5%, 76.8%)
10/01 01:23:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0722	Prec@(1,5) (45.5%, 77.0%)
10/01 01:23:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0685	Prec@(1,5) (45.5%, 77.0%)
10/01 01:23:48午前 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 45.4480%
10/01 01:23:48午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:23:48午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 45.4480%
10/01 01:24:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.9501 (1.6278)	Arch Loss 4.7515 (4.4888)	Arch Hard Loss 2.3680 (2.1049)	Arch Alpha Loss 11.9174 (11.9197)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 84.7%)	
10/01 01:24:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.3585 (1.6565)	Arch Loss 4.1606 (4.4783)	Arch Hard Loss 1.7785 (2.0950)	Arch Alpha Loss 11.9106 (11.9169)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.0%)	
10/01 01:25:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.7503 (1.6709)	Arch Loss 4.3859 (4.4687)	Arch Hard Loss 2.0052 (2.0860)	Arch Alpha Loss 11.9037 (11.9137)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.8%)	
10/01 01:25:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.6787 (1.6730)	Arch Loss 4.0769 (4.4587)	Arch Hard Loss 1.6969 (2.0765)	Arch Alpha Loss 11.9002 (11.9110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.7%)	
10/01 01:25:47午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 53.0600%
10/01 01:25:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0298	Prec@(1,5) (46.5%, 77.0%)
10/01 01:25:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0153	Prec@(1,5) (46.5%, 77.2%)
10/01 01:26:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0115	Prec@(1,5) (46.7%, 77.6%)
10/01 01:26:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0133	Prec@(1,5) (46.8%, 77.5%)
10/01 01:26:04午前 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 46.8360%
10/01 01:26:04午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:26:05午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.8360%
10/01 01:26:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.7707 (1.5404)	Arch Loss 4.2770 (4.4460)	Arch Hard Loss 1.8973 (2.0661)	Arch Alpha Loss 11.8984 (11.8993)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.6%)	
10/01 01:27:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4448 (1.5763)	Arch Loss 4.2559 (4.4527)	Arch Hard Loss 1.8769 (2.0731)	Arch Alpha Loss 11.8949 (11.8980)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.1%)	
10/01 01:27:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.7644 (1.5927)	Arch Loss 4.2919 (4.4566)	Arch Hard Loss 1.9139 (2.0773)	Arch Alpha Loss 11.8901 (11.8963)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.2%, 84.9%)	
10/01 01:28:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.6190 (1.6075)	Arch Loss 4.1448 (4.4440)	Arch Hard Loss 1.7676 (2.0651)	Arch Alpha Loss 11.8864 (11.8944)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.7%)	
10/01 01:28:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 54.7760%
10/01 01:28:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0094	Prec@(1,5) (47.7%, 77.5%)
10/01 01:28:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0069	Prec@(1,5) (47.4%, 77.6%)
10/01 01:28:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0176	Prec@(1,5) (46.8%, 77.4%)
10/01 01:28:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0115	Prec@(1,5) (46.9%, 77.6%)
10/01 01:28:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 46.8760%
10/01 01:28:20午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:28:20午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.8760%
10/01 01:28:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.6486 (1.4851)	Arch Loss 4.3367 (4.3926)	Arch Hard Loss 1.9599 (2.0156)	Arch Alpha Loss 11.8841 (11.8853)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.8%)	
10/01 01:29:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6054 (1.5089)	Arch Loss 4.2789 (4.3982)	Arch Hard Loss 1.9027 (2.0214)	Arch Alpha Loss 11.8810 (11.8839)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.3%)	
10/01 01:29:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.4497 (1.5384)	Arch Loss 3.9157 (4.3970)	Arch Hard Loss 1.5403 (2.0205)	Arch Alpha Loss 11.8769 (11.8823)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.8%)	
10/01 01:30:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.1815 (1.5527)	Arch Loss 4.6908 (4.3877)	Arch Hard Loss 2.3166 (2.0116)	Arch Alpha Loss 11.8713 (11.8804)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.5%)	
10/01 01:30:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 56.0040%
10/01 01:30:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0208	Prec@(1,5) (47.7%, 77.4%)
10/01 01:30:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0163	Prec@(1,5) (47.3%, 77.6%)
10/01 01:30:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0219	Prec@(1,5) (47.0%, 77.5%)
10/01 01:30:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0157	Prec@(1,5) (47.0%, 77.5%)
10/01 01:30:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 47.0400%
10/01 01:30:32午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:30:32午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 47.0400%
10/01 01:31:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.5171 (1.4069)	Arch Loss 4.3096 (4.4110)	Arch Hard Loss 1.9356 (2.0368)	Arch Alpha Loss 11.8701 (11.8707)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 87.7%)	
10/01 01:31:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.7546 (1.4545)	Arch Loss 4.4233 (4.3924)	Arch Hard Loss 2.0501 (2.0185)	Arch Alpha Loss 11.8662 (11.8693)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.1%)	
10/01 01:32:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.6560 (1.4699)	Arch Loss 4.5953 (4.3825)	Arch Hard Loss 2.2225 (2.0089)	Arch Alpha Loss 11.8640 (11.8679)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.9%)	
10/01 01:32:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6388 (1.4840)	Arch Loss 4.2631 (4.3751)	Arch Hard Loss 1.8908 (2.0017)	Arch Alpha Loss 11.8615 (11.8668)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.6%)	
10/01 01:32:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 57.6840%
10/01 01:32:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9836	Prec@(1,5) (47.5%, 78.2%)
10/01 01:32:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9799	Prec@(1,5) (47.2%, 78.3%)
10/01 01:32:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9721	Prec@(1,5) (47.5%, 78.5%)
10/01 01:32:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9664	Prec@(1,5) (47.7%, 78.5%)
10/01 01:32:46午前 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 47.7080%
10/01 01:32:46午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:32:47午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 47.7080%
10/01 01:33:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.6518 (1.3819)	Arch Loss 3.9090 (4.3721)	Arch Hard Loss 1.5372 (2.0002)	Arch Alpha Loss 11.8590 (11.8597)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.0%)	
10/01 01:33:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.5238 (1.4172)	Arch Loss 4.2356 (4.3911)	Arch Hard Loss 1.8639 (2.0193)	Arch Alpha Loss 11.8581 (11.8592)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.6%)	
10/01 01:34:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.2446 (1.4293)	Arch Loss 4.8668 (4.3680)	Arch Hard Loss 2.4954 (1.9963)	Arch Alpha Loss 11.8567 (11.8585)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.4%)	
10/01 01:34:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.5272 (1.4470)	Arch Loss 4.1504 (4.3603)	Arch Hard Loss 1.7794 (1.9887)	Arch Alpha Loss 11.8550 (11.8578)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.1%)	
10/01 01:34:45午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 58.5040%
10/01 01:34:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9565	Prec@(1,5) (48.5%, 78.8%)
10/01 01:34:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9380	Prec@(1,5) (49.1%, 79.1%)
10/01 01:34:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9227	Prec@(1,5) (49.3%, 79.5%)
10/01 01:35:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9267	Prec@(1,5) (49.1%, 79.4%)
10/01 01:35:03午前 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 49.1480%
10/01 01:35:03午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:35:03午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.1480%
10/01 01:35:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.2437 (1.3065)	Arch Loss 4.8357 (4.3418)	Arch Hard Loss 2.4650 (1.9711)	Arch Alpha Loss 11.8535 (11.8534)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.2%)	
10/01 01:36:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.3890 (1.3593)	Arch Loss 4.4935 (4.3643)	Arch Hard Loss 2.1228 (1.9935)	Arch Alpha Loss 11.8538 (11.8538)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.3%)	
10/01 01:36:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3095 (1.3701)	Arch Loss 4.1334 (4.3616)	Arch Hard Loss 1.7627 (1.9908)	Arch Alpha Loss 11.8536 (11.8538)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.1%)	
10/01 01:37:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.1748 (1.3828)	Arch Loss 3.9077 (4.3548)	Arch Hard Loss 1.5371 (1.9841)	Arch Alpha Loss 11.8530 (11.8538)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.9%)	
10/01 01:37:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 60.1320%
10/01 01:37:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9610	Prec@(1,5) (49.2%, 78.7%)
10/01 01:37:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9735	Prec@(1,5) (49.0%, 78.9%)
10/01 01:37:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9458	Prec@(1,5) (49.4%, 79.4%)
10/01 01:37:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9532	Prec@(1,5) (49.2%, 79.3%)
10/01 01:37:19午前 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 49.1880%
10/01 01:37:19午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:37:19午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.1880%
10/01 01:37:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.1713 (1.2255)	Arch Loss 4.3735 (4.3217)	Arch Hard Loss 2.0027 (1.9511)	Arch Alpha Loss 11.8542 (11.8532)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 91.1%)	
10/01 01:38:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3194 (1.2715)	Arch Loss 4.4079 (4.3213)	Arch Hard Loss 2.0370 (1.9506)	Arch Alpha Loss 11.8544 (11.8539)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 90.0%)	
10/01 01:38:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2545 (1.3070)	Arch Loss 4.6804 (4.3386)	Arch Hard Loss 2.3099 (1.9679)	Arch Alpha Loss 11.8529 (11.8537)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.6%)	
10/01 01:39:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4315 (1.3182)	Arch Loss 4.5165 (4.3325)	Arch Hard Loss 2.1462 (1.9619)	Arch Alpha Loss 11.8513 (11.8532)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.4%)	
10/01 01:39:17午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 61.6760%
10/01 01:39:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9454	Prec@(1,5) (49.3%, 79.6%)
10/01 01:39:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9604	Prec@(1,5) (49.2%, 79.4%)
10/01 01:39:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9664	Prec@(1,5) (49.1%, 79.3%)
10/01 01:39:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9528	Prec@(1,5) (49.5%, 79.4%)
10/01 01:39:34午前 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 49.5120%
10/01 01:39:34午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:39:34午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.5120%
10/01 01:40:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.1739 (1.2081)	Arch Loss 4.3493 (4.3089)	Arch Hard Loss 1.9795 (1.9388)	Arch Alpha Loss 11.8490 (11.8506)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.9%)	
10/01 01:40:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.4409 (1.2226)	Arch Loss 4.7411 (4.3344)	Arch Hard Loss 2.3712 (1.9645)	Arch Alpha Loss 11.8493 (11.8497)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.5%)	
10/01 01:41:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3100 (1.2485)	Arch Loss 4.4592 (4.3259)	Arch Hard Loss 2.0894 (1.9559)	Arch Alpha Loss 11.8488 (11.8496)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.2%)	
10/01 01:41:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.5582 (1.2696)	Arch Loss 4.3529 (4.3223)	Arch Hard Loss 1.9831 (1.9524)	Arch Alpha Loss 11.8490 (11.8495)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.8%)	
10/01 01:41:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 63.0080%
10/01 01:41:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9396	Prec@(1,5) (48.7%, 79.3%)
10/01 01:41:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9335	Prec@(1,5) (49.1%, 79.6%)
10/01 01:41:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9372	Prec@(1,5) (49.3%, 79.6%)
10/01 01:41:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9376	Prec@(1,5) (49.3%, 79.5%)
10/01 01:41:49午前 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 49.2600%
10/01 01:41:49午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:41:50午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.5120%
10/01 01:42:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.2936 (1.1602)	Arch Loss 4.4871 (4.2373)	Arch Hard Loss 2.1175 (1.8676)	Arch Alpha Loss 11.8479 (11.8483)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.4%)	
10/01 01:42:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3888 (1.1847)	Arch Loss 4.3213 (4.2845)	Arch Hard Loss 1.9515 (1.9148)	Arch Alpha Loss 11.8492 (11.8488)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.1%)	
10/01 01:43:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.2484 (1.1994)	Arch Loss 4.4799 (4.2961)	Arch Hard Loss 2.1101 (1.9263)	Arch Alpha Loss 11.8491 (11.8490)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.8%)	
10/01 01:43:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.4240 (1.2118)	Arch Loss 4.3089 (4.3064)	Arch Hard Loss 1.9392 (1.9366)	Arch Alpha Loss 11.8483 (11.8488)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.6%)	
10/01 01:43:48午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 64.3120%
10/01 01:43:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8945	Prec@(1,5) (51.2%, 80.0%)
10/01 01:43:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9219	Prec@(1,5) (50.8%, 79.9%)
10/01 01:44:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9497	Prec@(1,5) (50.2%, 79.5%)
10/01 01:44:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9568	Prec@(1,5) (50.2%, 79.6%)
10/01 01:44:05午前 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 50.1520%
10/01 01:44:05午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:44:06午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.1520%
10/01 01:44:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.9552 (1.1090)	Arch Loss 4.5159 (4.3586)	Arch Hard Loss 2.1464 (1.9890)	Arch Alpha Loss 11.8477 (11.8479)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.1%)	
10/01 01:45:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.3765 (1.1385)	Arch Loss 4.6867 (4.3299)	Arch Hard Loss 2.3169 (1.9603)	Arch Alpha Loss 11.8489 (11.8482)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.8%)	
10/01 01:45:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.3788 (1.1641)	Arch Loss 4.0401 (4.3213)	Arch Hard Loss 1.6702 (1.9516)	Arch Alpha Loss 11.8496 (11.8483)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.4%)	
10/01 01:46:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.1160 (1.1721)	Arch Loss 4.4077 (4.3151)	Arch Hard Loss 2.0380 (1.9454)	Arch Alpha Loss 11.8485 (11.8486)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.2%, 91.3%)	
10/01 01:46:04午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 65.2320%
10/01 01:46:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.9074	Prec@(1,5) (50.9%, 80.2%)
10/01 01:46:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8937	Prec@(1,5) (51.5%, 80.7%)
10/01 01:46:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8929	Prec@(1,5) (51.4%, 80.7%)
10/01 01:46:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9028	Prec@(1,5) (51.2%, 80.6%)
10/01 01:46:22午前 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 51.1280%
10/01 01:46:22午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:46:23午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.1280%
10/01 01:46:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 0.8946 (1.0593)	Arch Loss 4.1727 (4.2492)	Arch Hard Loss 1.8029 (1.8796)	Arch Alpha Loss 11.8491 (11.8481)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.8%)	
10/01 01:47:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.2070 (1.0677)	Arch Loss 4.1073 (4.2708)	Arch Hard Loss 1.7371 (1.9009)	Arch Alpha Loss 11.8508 (11.8492)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.8%)	
10/01 01:47:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.0903 (1.0983)	Arch Loss 4.1691 (4.2983)	Arch Hard Loss 1.7984 (1.9282)	Arch Alpha Loss 11.8535 (11.8504)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.4%)	
10/01 01:48:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 0.9348 (1.1103)	Arch Loss 3.7736 (4.2930)	Arch Hard Loss 1.4031 (1.9228)	Arch Alpha Loss 11.8524 (11.8511)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.1%)	
10/01 01:48:21午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 67.1920%
10/01 01:48:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9279	Prec@(1,5) (50.3%, 80.6%)
10/01 01:48:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.9320	Prec@(1,5) (50.4%, 80.8%)
10/01 01:48:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.9215	Prec@(1,5) (50.6%, 81.0%)
10/01 01:48:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.9185	Prec@(1,5) (50.8%, 80.9%)
10/01 01:48:38午前 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 50.7400%
10/01 01:48:38午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:48:38午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.1280%
10/01 01:49:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.0610 (0.9914)	Arch Loss 4.3703 (4.2927)	Arch Hard Loss 2.0001 (1.9224)	Arch Alpha Loss 11.8511 (11.8512)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.9%)	
10/01 01:49:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.2211 (1.0173)	Arch Loss 4.5210 (4.2757)	Arch Hard Loss 2.1506 (1.9054)	Arch Alpha Loss 11.8523 (11.8514)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.5%)	
10/01 01:50:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.1682 (1.0331)	Arch Loss 4.1291 (4.3196)	Arch Hard Loss 1.7582 (1.9492)	Arch Alpha Loss 11.8544 (11.8520)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.2%)	
10/01 01:50:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.2413 (1.0509)	Arch Loss 4.4662 (4.3149)	Arch Hard Loss 2.0946 (1.9443)	Arch Alpha Loss 11.8582 (11.8530)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.9%)	
10/01 01:50:36午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 68.7160%
10/01 01:50:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9264	Prec@(1,5) (51.5%, 80.6%)
10/01 01:50:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.9380	Prec@(1,5) (51.1%, 80.3%)
10/01 01:50:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.9237	Prec@(1,5) (51.3%, 80.7%)
10/01 01:50:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.9211	Prec@(1,5) (51.5%, 80.7%)
10/01 01:50:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 51.5240%
10/01 01:50:53午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:50:54午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.5240%
10/01 01:51:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.0293 (0.9450)	Arch Loss 4.3911 (4.2944)	Arch Hard Loss 2.0197 (1.9228)	Arch Alpha Loss 11.8569 (11.8581)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.3%)	
10/01 01:51:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.0489 (0.9633)	Arch Loss 4.0753 (4.3095)	Arch Hard Loss 1.7030 (1.9378)	Arch Alpha Loss 11.8613 (11.8587)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.2%, 94.0%)	
10/01 01:52:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 0.8720 (0.9866)	Arch Loss 4.8518 (4.3210)	Arch Hard Loss 2.4793 (1.9490)	Arch Alpha Loss 11.8627 (11.8601)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.6%)	
10/01 01:52:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9686 (1.0006)	Arch Loss 4.7340 (4.3215)	Arch Hard Loss 2.3616 (1.9494)	Arch Alpha Loss 11.8623 (11.8607)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.5%)	
10/01 01:52:52午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 70.1720%
10/01 01:52:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8341	Prec@(1,5) (53.2%, 82.0%)
10/01 01:53:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8644	Prec@(1,5) (52.7%, 81.5%)
10/01 01:53:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8823	Prec@(1,5) (52.4%, 81.3%)
10/01 01:53:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8826	Prec@(1,5) (52.2%, 81.4%)
10/01 01:53:09午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 52.2520%
10/01 01:53:09午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:53:09午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.2520%
10/01 01:53:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.7218 (0.9002)	Arch Loss 4.1988 (4.3324)	Arch Hard Loss 1.8259 (1.9598)	Arch Alpha Loss 11.8646 (11.8631)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.7%)	
10/01 01:54:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9919 (0.9332)	Arch Loss 4.7557 (4.3227)	Arch Hard Loss 2.3821 (1.9498)	Arch Alpha Loss 11.8677 (11.8648)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.3%)	
10/01 01:54:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.2732 (0.9420)	Arch Loss 4.1193 (4.3208)	Arch Hard Loss 1.7451 (1.9475)	Arch Alpha Loss 11.8711 (11.8665)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.0%)	
10/01 01:55:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0471 (0.9528)	Arch Loss 4.0176 (4.3221)	Arch Hard Loss 1.6434 (1.9486)	Arch Alpha Loss 11.8709 (11.8676)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
10/01 01:55:07午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 71.2760%
10/01 01:55:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9072	Prec@(1,5) (52.1%, 81.2%)
10/01 01:55:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9137	Prec@(1,5) (51.6%, 80.9%)
10/01 01:55:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9213	Prec@(1,5) (51.7%, 81.0%)
10/01 01:55:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9070	Prec@(1,5) (52.1%, 81.3%)
10/01 01:55:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 52.1160%
10/01 01:55:24午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 01:55:24午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.2520%
10/01 01:55:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.6184 (0.8465)	Arch Loss 4.2703 (4.3411)	Arch Hard Loss 1.8967 (1.9671)	Arch Alpha Loss 11.8682 (11.8697)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.4%)	
10/01 01:56:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.7705 (0.8594)	Arch Loss 5.0365 (4.3175)	Arch Hard Loss 2.6624 (1.9436)	Arch Alpha Loss 11.8704 (11.8695)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.8%, 95.3%)	
10/01 01:56:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0639 (0.8703)	Arch Loss 4.8495 (4.3170)	Arch Hard Loss 2.4758 (1.9430)	Arch Alpha Loss 11.8684 (11.8698)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.1%)	
10/01 01:57:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.7024 (0.8853)	Arch Loss 4.3171 (4.3220)	Arch Hard Loss 1.9428 (1.9481)	Arch Alpha Loss 11.8715 (11.8698)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.0%, 95.0%)	
10/01 01:57:22午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 72.9600%
10/01 01:57:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8830	Prec@(1,5) (53.1%, 81.6%)
10/01 01:57:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9212	Prec@(1,5) (52.9%, 81.6%)
10/01 01:57:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9194	Prec@(1,5) (52.7%, 81.4%)
10/01 01:57:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9101	Prec@(1,5) (52.7%, 81.7%)
10/01 01:57:40午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 52.6920%
10/01 01:57:40午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:57:41午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.6920%
10/01 01:58:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8744 (0.7817)	Arch Loss 3.8608 (4.3527)	Arch Hard Loss 1.4859 (1.9781)	Arch Alpha Loss 11.8744 (11.8726)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.9%)	
10/01 01:58:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9329 (0.7893)	Arch Loss 4.2191 (4.3665)	Arch Hard Loss 1.8436 (1.9916)	Arch Alpha Loss 11.8775 (11.8741)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.7%)	
10/01 01:59:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.7708 (0.8195)	Arch Loss 4.7638 (4.3548)	Arch Hard Loss 2.3881 (1.9798)	Arch Alpha Loss 11.8783 (11.8752)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.4%)	
10/01 01:59:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.7076 (0.8321)	Arch Loss 3.9522 (4.3397)	Arch Hard Loss 1.5765 (1.9646)	Arch Alpha Loss 11.8785 (11.8757)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.4%)	
10/01 01:59:39午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 74.4720%
10/01 01:59:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.9424	Prec@(1,5) (51.8%, 81.1%)
10/01 01:59:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.9374	Prec@(1,5) (52.2%, 81.3%)
10/01 01:59:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.9480	Prec@(1,5) (51.9%, 81.4%)
10/01 01:59:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.9531	Prec@(1,5) (52.0%, 81.3%)
10/01 01:59:57午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 52.0440%
10/01 01:59:57午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 01:59:57午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.6920%
10/01 02:00:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7508 (0.7193)	Arch Loss 4.7926 (4.3177)	Arch Hard Loss 2.4167 (1.9419)	Arch Alpha Loss 11.8794 (11.8788)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.8%)	
10/01 02:00:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.5910 (0.7423)	Arch Loss 4.2438 (4.3362)	Arch Hard Loss 1.8671 (1.9601)	Arch Alpha Loss 11.8838 (11.8802)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.4%)	
10/01 02:01:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.7183 (0.7558)	Arch Loss 4.2879 (4.3554)	Arch Hard Loss 1.9103 (1.9790)	Arch Alpha Loss 11.8878 (11.8820)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.2%)	
10/01 02:01:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.8905 (0.7723)	Arch Loss 4.3147 (4.3473)	Arch Hard Loss 1.9374 (1.9707)	Arch Alpha Loss 11.8863 (11.8830)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.1%)	
10/01 02:01:56午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 76.2800%
10/01 02:02:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.9248	Prec@(1,5) (52.5%, 81.9%)
10/01 02:02:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.9457	Prec@(1,5) (52.5%, 81.3%)
10/01 02:02:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.9497	Prec@(1,5) (52.5%, 81.6%)
10/01 02:02:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.9589	Prec@(1,5) (52.5%, 81.5%)
10/01 02:02:13午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 52.4760%
10/01 02:02:13午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:02:14午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.6920%
10/01 02:02:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.6846 (0.6807)	Arch Loss 3.7813 (4.3268)	Arch Hard Loss 1.4033 (1.9493)	Arch Alpha Loss 11.8902 (11.8874)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 97.0%)	
10/01 02:03:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.4409 (0.6920)	Arch Loss 4.6880 (4.3474)	Arch Hard Loss 2.3092 (1.9694)	Arch Alpha Loss 11.8940 (11.8898)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.9%)	
10/01 02:03:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.4982 (0.7118)	Arch Loss 4.1099 (4.3516)	Arch Hard Loss 1.7305 (1.9733)	Arch Alpha Loss 11.8969 (11.8919)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.6%)	
10/01 02:04:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.6203 (0.7223)	Arch Loss 4.6631 (4.3655)	Arch Hard Loss 2.2836 (1.9868)	Arch Alpha Loss 11.8977 (11.8931)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.6%)	
10/01 02:04:13午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 77.7160%
10/01 02:04:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.9867	Prec@(1,5) (53.2%, 81.4%)
10/01 02:04:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.0092	Prec@(1,5) (52.6%, 81.2%)
10/01 02:04:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9808	Prec@(1,5) (52.7%, 81.5%)
10/01 02:04:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9764	Prec@(1,5) (52.8%, 81.6%)
10/01 02:04:30午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 52.7920%
10/01 02:04:30午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:04:31午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.7920%
10/01 02:05:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.6276 (0.6339)	Arch Loss 4.2030 (4.4241)	Arch Hard Loss 1.8236 (2.0445)	Arch Alpha Loss 11.8972 (11.8979)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
10/01 02:05:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.6002 (0.6451)	Arch Loss 4.3554 (4.4087)	Arch Hard Loss 1.9760 (2.0293)	Arch Alpha Loss 11.8969 (11.8972)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.1%)	
10/01 02:05:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.5053 (0.6603)	Arch Loss 4.5128 (4.3935)	Arch Hard Loss 2.1323 (2.0139)	Arch Alpha Loss 11.9022 (11.8978)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.1%)	
10/01 02:06:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.6085 (0.6759)	Arch Loss 4.1335 (4.3912)	Arch Hard Loss 1.7526 (2.0113)	Arch Alpha Loss 11.9047 (11.8992)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.9%)	
10/01 02:06:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 79.2120%
10/01 02:06:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9902	Prec@(1,5) (54.3%, 81.7%)
10/01 02:06:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9946	Prec@(1,5) (53.8%, 81.7%)
10/01 02:06:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9955	Prec@(1,5) (53.6%, 81.7%)
10/01 02:06:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9930	Prec@(1,5) (53.4%, 81.6%)
10/01 02:06:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 53.3640%
10/01 02:06:43午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:06:44午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.3640%
10/01 02:07:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.7174 (0.5769)	Arch Loss 4.4615 (4.4191)	Arch Hard Loss 2.0797 (2.0377)	Arch Alpha Loss 11.9091 (11.9071)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.6%)	
10/01 02:07:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.7754 (0.5947)	Arch Loss 4.0956 (4.3875)	Arch Hard Loss 1.7137 (2.0059)	Arch Alpha Loss 11.9097 (11.9079)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.5%)	
10/01 02:08:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.6640 (0.6017)	Arch Loss 4.2152 (4.3999)	Arch Hard Loss 1.8329 (2.0182)	Arch Alpha Loss 11.9116 (11.9088)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
10/01 02:08:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6362 (0.6144)	Arch Loss 4.6066 (4.4013)	Arch Hard Loss 2.2240 (2.0194)	Arch Alpha Loss 11.9127 (11.9097)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.4%)	
10/01 02:08:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 81.0000%
10/01 02:08:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.9981	Prec@(1,5) (53.2%, 81.5%)
10/01 02:08:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9957	Prec@(1,5) (53.6%, 81.6%)
10/01 02:08:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9801	Prec@(1,5) (53.6%, 81.9%)
10/01 02:09:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9821	Prec@(1,5) (53.5%, 81.9%)
10/01 02:09:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 53.5240%
10/01 02:09:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:09:01午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.5240%
10/01 02:09:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.3348 (0.5407)	Arch Loss 4.1985 (4.3744)	Arch Hard Loss 1.8154 (1.9915)	Arch Alpha Loss 11.9157 (11.9141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.3%)	
10/01 02:10:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.8556 (0.5461)	Arch Loss 4.7356 (4.3777)	Arch Hard Loss 2.3522 (1.9946)	Arch Alpha Loss 11.9172 (11.9155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 98.3%)	
10/01 02:10:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.6090 (0.5586)	Arch Loss 5.1293 (4.3902)	Arch Hard Loss 2.7458 (2.0069)	Arch Alpha Loss 11.9176 (11.9162)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 98.0%)	
10/01 02:11:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.4077 (0.5695)	Arch Loss 4.4134 (4.4047)	Arch Hard Loss 2.0293 (2.0214)	Arch Alpha Loss 11.9207 (11.9168)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 98.0%)	
10/01 02:11:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 82.3440%
10/01 02:11:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.9847	Prec@(1,5) (54.5%, 82.0%)
10/01 02:11:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.9653	Prec@(1,5) (54.5%, 82.4%)
10/01 02:11:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9849	Prec@(1,5) (54.1%, 82.4%)
10/01 02:11:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9881	Prec@(1,5) (54.0%, 82.4%)
10/01 02:11:17午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 54.0360%
10/01 02:11:17午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:11:18午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.0360%
10/01 02:11:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.4453 (0.4817)	Arch Loss 4.2871 (4.4070)	Arch Hard Loss 1.9017 (2.0223)	Arch Alpha Loss 11.9271 (11.9238)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.6%)	
10/01 02:12:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.3954 (0.4913)	Arch Loss 4.1113 (4.4046)	Arch Hard Loss 1.7253 (2.0193)	Arch Alpha Loss 11.9300 (11.9262)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.4%)	
10/01 02:12:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.6006 (0.5074)	Arch Loss 4.7540 (4.4305)	Arch Hard Loss 2.3677 (2.0449)	Arch Alpha Loss 11.9317 (11.9280)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.4%)	
10/01 02:13:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.5172 (0.5212)	Arch Loss 4.5441 (4.4258)	Arch Hard Loss 2.1571 (2.0399)	Arch Alpha Loss 11.9350 (11.9295)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.2%)	
10/01 02:13:15午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 83.7320%
10/01 02:13:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9870	Prec@(1,5) (54.0%, 82.5%)
10/01 02:13:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9980	Prec@(1,5) (54.1%, 82.6%)
10/01 02:13:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9989	Prec@(1,5) (53.8%, 82.6%)
10/01 02:13:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9830	Prec@(1,5) (54.1%, 82.7%)
10/01 02:13:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 54.1000%
10/01 02:13:32午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:13:33午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.1000%
10/01 02:14:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.5228 (0.4586)	Arch Loss 4.6642 (4.4213)	Arch Hard Loss 2.2770 (2.0344)	Arch Alpha Loss 11.9361 (11.9344)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
10/01 02:14:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.4242 (0.4615)	Arch Loss 4.6738 (4.4557)	Arch Hard Loss 2.2860 (2.0685)	Arch Alpha Loss 11.9392 (11.9362)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
10/01 02:15:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.3716 (0.4738)	Arch Loss 4.2337 (4.4456)	Arch Hard Loss 1.8458 (2.0581)	Arch Alpha Loss 11.9396 (11.9373)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.4%)	
10/01 02:15:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.4380 (0.4794)	Arch Loss 4.7488 (4.4381)	Arch Hard Loss 2.3604 (2.0504)	Arch Alpha Loss 11.9423 (11.9382)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
10/01 02:15:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 85.0680%
10/01 02:15:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9874	Prec@(1,5) (54.4%, 82.6%)
10/01 02:15:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.9837	Prec@(1,5) (54.6%, 82.8%)
10/01 02:15:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.0003	Prec@(1,5) (54.4%, 82.5%)
10/01 02:15:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.0004	Prec@(1,5) (54.3%, 82.5%)
10/01 02:15:47午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 54.3320%
10/01 02:15:47午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:15:47午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.3320%
10/01 02:16:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.5497 (0.4020)	Arch Loss 4.9140 (4.3885)	Arch Hard Loss 2.5253 (2.0000)	Arch Alpha Loss 11.9436 (11.9429)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.7%, 98.7%)	
10/01 02:16:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.4128 (0.4199)	Arch Loss 4.2251 (4.4206)	Arch Hard Loss 1.8356 (2.0318)	Arch Alpha Loss 11.9475 (11.9442)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.8%)	
10/01 02:17:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.3932 (0.4345)	Arch Loss 4.6910 (4.4444)	Arch Hard Loss 2.3006 (2.0552)	Arch Alpha Loss 11.9520 (11.9461)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.7%)	
10/01 02:17:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.3235 (0.4415)	Arch Loss 4.3689 (4.4477)	Arch Hard Loss 1.9782 (2.0582)	Arch Alpha Loss 11.9533 (11.9476)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
10/01 02:17:44午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 86.6040%
10/01 02:17:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.0141	Prec@(1,5) (54.6%, 82.7%)
10/01 02:17:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9995	Prec@(1,5) (54.6%, 82.7%)
10/01 02:17:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.0257	Prec@(1,5) (54.2%, 82.5%)
10/01 02:18:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.0197	Prec@(1,5) (54.3%, 82.7%)
10/01 02:18:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 54.2720%
10/01 02:18:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:18:02午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.3320%
10/01 02:18:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.2666 (0.3809)	Arch Loss 4.3647 (4.5142)	Arch Hard Loss 1.9728 (2.1229)	Arch Alpha Loss 11.9599 (11.9565)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.2%)	
10/01 02:19:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5814 (0.3915)	Arch Loss 4.1644 (4.4757)	Arch Hard Loss 1.7726 (2.0840)	Arch Alpha Loss 11.9591 (11.9585)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
10/01 02:19:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.4086 (0.3970)	Arch Loss 4.0377 (4.4843)	Arch Hard Loss 1.6451 (2.0924)	Arch Alpha Loss 11.9630 (11.9594)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.1%, 98.9%)	
10/01 02:19:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.3087 (0.4028)	Arch Loss 3.9222 (4.4679)	Arch Hard Loss 1.5296 (2.0758)	Arch Alpha Loss 11.9628 (11.9604)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
10/01 02:20:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 87.8040%
10/01 02:20:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.0502	Prec@(1,5) (53.9%, 82.1%)
10/01 02:20:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.0257	Prec@(1,5) (54.6%, 82.7%)
10/01 02:20:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.0548	Prec@(1,5) (54.3%, 82.1%)
10/01 02:20:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.0316	Prec@(1,5) (54.5%, 82.3%)
10/01 02:20:17午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 54.5040%
10/01 02:20:17午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:20:17午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.5040%
10/01 02:20:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.1918 (0.3436)	Arch Loss 4.1093 (4.4456)	Arch Hard Loss 1.7169 (2.0532)	Arch Alpha Loss 11.9620 (11.9622)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.4%)	
10/01 02:21:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.3845 (0.3554)	Arch Loss 4.2874 (4.4596)	Arch Hard Loss 1.8948 (2.0671)	Arch Alpha Loss 11.9631 (11.9624)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.3%)	
10/01 02:21:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.2668 (0.3641)	Arch Loss 4.8816 (4.4770)	Arch Hard Loss 2.4885 (2.0844)	Arch Alpha Loss 11.9652 (11.9630)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
10/01 02:22:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.3912 (0.3691)	Arch Loss 4.0590 (4.4831)	Arch Hard Loss 1.6653 (2.0903)	Arch Alpha Loss 11.9684 (11.9641)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.1%)	
10/01 02:22:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 88.8240%
10/01 02:22:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.0810	Prec@(1,5) (53.4%, 81.7%)
10/01 02:22:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.0174	Prec@(1,5) (54.9%, 82.7%)
10/01 02:22:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.0341	Prec@(1,5) (54.7%, 82.6%)
10/01 02:22:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.0423	Prec@(1,5) (54.8%, 82.5%)
10/01 02:22:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 54.8080%
10/01 02:22:32午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:22:33午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.8080%
10/01 02:23:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.2357 (0.3148)	Arch Loss 4.1080 (4.4719)	Arch Hard Loss 1.7140 (2.0781)	Arch Alpha Loss 11.9700 (11.9687)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
10/01 02:23:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.2068 (0.3236)	Arch Loss 4.1276 (4.4823)	Arch Hard Loss 1.7329 (2.0884)	Arch Alpha Loss 11.9734 (11.9699)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
10/01 02:24:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.4093 (0.3319)	Arch Loss 4.7835 (4.4866)	Arch Hard Loss 2.3886 (2.0923)	Arch Alpha Loss 11.9744 (11.9712)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.3%)	
10/01 02:24:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.3746 (0.3382)	Arch Loss 4.0785 (4.4903)	Arch Hard Loss 1.6836 (2.0958)	Arch Alpha Loss 11.9744 (11.9723)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.2%)	
10/01 02:24:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 89.9160%
10/01 02:24:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.0639	Prec@(1,5) (55.1%, 82.4%)
10/01 02:24:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.0645	Prec@(1,5) (54.9%, 82.3%)
10/01 02:24:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.0608	Prec@(1,5) (54.9%, 82.4%)
10/01 02:24:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.0640	Prec@(1,5) (54.6%, 82.5%)
10/01 02:24:48午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 54.5520%
10/01 02:24:48午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:24:48午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.8080%
10/01 02:25:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.2549 (0.2976)	Arch Loss 4.5311 (4.4621)	Arch Hard Loss 2.1359 (2.0669)	Arch Alpha Loss 11.9764 (11.9757)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.6%)	
10/01 02:25:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.3370 (0.3042)	Arch Loss 4.2286 (4.5051)	Arch Hard Loss 1.8326 (2.1098)	Arch Alpha Loss 11.9800 (11.9768)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.5%)	
10/01 02:26:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.1445 (0.3113)	Arch Loss 4.3709 (4.5223)	Arch Hard Loss 1.9743 (2.1267)	Arch Alpha Loss 11.9830 (11.9780)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.5%)	
10/01 02:26:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.3584 (0.3163)	Arch Loss 4.5862 (4.5161)	Arch Hard Loss 2.1893 (2.1202)	Arch Alpha Loss 11.9846 (11.9796)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
10/01 02:26:46午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 90.8280%
10/01 02:26:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0970	Prec@(1,5) (54.2%, 82.1%)
10/01 02:26:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.0786	Prec@(1,5) (54.5%, 82.3%)
10/01 02:27:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.0715	Prec@(1,5) (54.5%, 82.4%)
10/01 02:27:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.0683	Prec@(1,5) (54.6%, 82.3%)
10/01 02:27:03午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 54.6040%
10/01 02:27:03午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:27:04午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.8080%
10/01 02:27:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4060 (0.2990)	Arch Loss 3.6354 (4.5165)	Arch Hard Loss 1.2385 (2.1198)	Arch Alpha Loss 11.9843 (11.9837)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.5%)	
10/01 02:28:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.2798 (0.2942)	Arch Loss 5.4838 (4.5005)	Arch Hard Loss 3.0865 (2.1036)	Arch Alpha Loss 11.9861 (11.9843)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
10/01 02:28:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.2893 (0.2967)	Arch Loss 4.1460 (4.5157)	Arch Hard Loss 1.7484 (2.1186)	Arch Alpha Loss 11.9882 (11.9853)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
10/01 02:29:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.2703 (0.3006)	Arch Loss 4.0591 (4.5114)	Arch Hard Loss 1.6614 (2.1143)	Arch Alpha Loss 11.9883 (11.9859)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
10/01 02:29:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 91.1560%
10/01 02:29:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.0886	Prec@(1,5) (54.8%, 82.3%)
10/01 02:29:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.0880	Prec@(1,5) (55.1%, 82.4%)
10/01 02:29:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.0708	Prec@(1,5) (55.4%, 82.5%)
10/01 02:29:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.0811	Prec@(1,5) (55.0%, 82.5%)
10/01 02:29:18午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 54.9840%
10/01 02:29:18午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:29:19午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9840%
10/01 02:29:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.2025 (0.2728)	Arch Loss 4.6377 (4.5059)	Arch Hard Loss 2.2398 (2.1082)	Arch Alpha Loss 11.9895 (11.9887)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.7%)	
10/01 02:30:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.3258 (0.2752)	Arch Loss 4.6912 (4.4968)	Arch Hard Loss 2.2936 (2.0990)	Arch Alpha Loss 11.9880 (11.9887)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
10/01 02:30:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.3431 (0.2760)	Arch Loss 4.6713 (4.5117)	Arch Hard Loss 2.2730 (2.1138)	Arch Alpha Loss 11.9913 (11.9893)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
10/01 02:31:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.2998 (0.2802)	Arch Loss 4.3780 (4.5236)	Arch Hard Loss 1.9792 (2.1256)	Arch Alpha Loss 11.9942 (11.9901)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.6%)	
10/01 02:31:15午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 92.0200%
10/01 02:31:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.1269	Prec@(1,5) (54.7%, 82.0%)
10/01 02:31:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.1013	Prec@(1,5) (54.5%, 82.4%)
10/01 02:31:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.0831	Prec@(1,5) (54.9%, 82.6%)
10/01 02:31:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.0989	Prec@(1,5) (54.7%, 82.5%)
10/01 02:31:32午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 54.7400%
10/01 02:31:32午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:31:32午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9840%
10/01 02:32:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.2036 (0.2498)	Arch Loss 4.6571 (4.5063)	Arch Hard Loss 2.2582 (2.1075)	Arch Alpha Loss 11.9943 (11.9940)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
10/01 02:32:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.2494 (0.2554)	Arch Loss 4.5586 (4.5196)	Arch Hard Loss 2.1593 (2.1207)	Arch Alpha Loss 11.9964 (11.9945)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
10/01 02:33:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.1658 (0.2638)	Arch Loss 5.3641 (4.5285)	Arch Hard Loss 2.9647 (2.1294)	Arch Alpha Loss 11.9970 (11.9954)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
10/01 02:33:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.0775 (0.2649)	Arch Loss 4.1662 (4.5380)	Arch Hard Loss 1.7659 (2.1388)	Arch Alpha Loss 12.0016 (11.9963)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.5%)	
10/01 02:33:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 92.4760%
10/01 02:33:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.0942	Prec@(1,5) (55.3%, 82.4%)
10/01 02:33:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.0580	Prec@(1,5) (55.6%, 82.9%)
10/01 02:33:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.0727	Prec@(1,5) (55.4%, 82.6%)
10/01 02:33:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.0747	Prec@(1,5) (55.3%, 82.6%)
10/01 02:33:44午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 55.3000%
10/01 02:33:44午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:33:45午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3000%
10/01 02:34:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.2900 (0.2520)	Arch Loss 4.4052 (4.5727)	Arch Hard Loss 2.0041 (2.1719)	Arch Alpha Loss 12.0051 (12.0040)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
10/01 02:34:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.2203 (0.2582)	Arch Loss 3.8753 (4.5658)	Arch Hard Loss 1.4743 (2.1648)	Arch Alpha Loss 12.0052 (12.0049)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
10/01 02:35:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3120 (0.2562)	Arch Loss 4.6772 (4.5579)	Arch Hard Loss 2.2760 (2.1570)	Arch Alpha Loss 12.0064 (12.0049)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
10/01 02:35:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.2457 (0.2561)	Arch Loss 3.9394 (4.5653)	Arch Hard Loss 1.5383 (2.1643)	Arch Alpha Loss 12.0056 (12.0053)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
10/01 02:35:41午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 92.6960%
10/01 02:35:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.0442	Prec@(1,5) (55.6%, 83.6%)
10/01 02:35:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.0671	Prec@(1,5) (55.1%, 83.0%)
10/01 02:35:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.0757	Prec@(1,5) (55.2%, 82.7%)
10/01 02:35:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.0715	Prec@(1,5) (55.2%, 82.8%)
10/01 02:35:59午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 55.1400%
10/01 02:35:59午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:35:59午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3000%
10/01 02:36:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.1979 (0.2425)	Arch Loss 4.2014 (4.5577)	Arch Hard Loss 1.7995 (2.1562)	Arch Alpha Loss 12.0092 (12.0077)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
10/01 02:36:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.2339 (0.2439)	Arch Loss 4.2731 (4.5524)	Arch Hard Loss 1.8708 (2.1506)	Arch Alpha Loss 12.0112 (12.0090)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
10/01 02:37:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.0985 (0.2422)	Arch Loss 4.8098 (4.5478)	Arch Hard Loss 2.4076 (2.1459)	Arch Alpha Loss 12.0109 (12.0097)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
10/01 02:37:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.3371 (0.2438)	Arch Loss 4.2002 (4.5540)	Arch Hard Loss 1.7983 (2.1521)	Arch Alpha Loss 12.0092 (12.0094)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
10/01 02:37:53午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 93.2160%
10/01 02:37:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.1133	Prec@(1,5) (55.9%, 82.3%)
10/01 02:38:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.0701	Prec@(1,5) (55.9%, 83.2%)
10/01 02:38:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.0890	Prec@(1,5) (55.5%, 83.0%)
10/01 02:38:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.1030	Prec@(1,5) (55.2%, 82.8%)
10/01 02:38:10午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 55.2480%
10/01 02:38:10午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 02:38:10午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.3000%
10/01 02:38:10午前 searchStage_KD_main.py:101 [INFO] Final best Prec@1 = 55.3000%
10/01 02:38:10午前 searchStage_KD_main.py:102 [INFO] Final Best Genotype = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
