10/01 06:27:21AM parser.py:28 [INFO] 
10/01 06:27:21AM parser.py:29 [INFO] Parameters:
10/01 06:27:21AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.6-h_das_teacher/DAG
10/01 06:27:21AM parser.py:31 [INFO] T=10.0
10/01 06:27:21AM parser.py:31 [INFO] ADVANCED=True
10/01 06:27:21AM parser.py:31 [INFO] ALPHA_LR=0.0003
10/01 06:27:21AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
10/01 06:27:21AM parser.py:31 [INFO] BATCH_SIZE=64
10/01 06:27:21AM parser.py:31 [INFO] CASCADE=False
10/01 06:27:21AM parser.py:31 [INFO] CHECKPOINT_RESET=False
10/01 06:27:21AM parser.py:31 [INFO] CUTOUT_LENGTH=0
10/01 06:27:21AM parser.py:31 [INFO] DATA_PATH=../data/
10/01 06:27:21AM parser.py:31 [INFO] DATASET=cifar100
10/01 06:27:21AM parser.py:31 [INFO] DEPTH_COEF=0.0
10/01 06:27:21AM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
10/01 06:27:21AM parser.py:31 [INFO] EPOCHS=50
10/01 06:27:21AM parser.py:31 [INFO] EXP_NAME=l0.6-h_das_teacher
10/01 06:27:21AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
10/01 06:27:21AM parser.py:31 [INFO] GPUS=[0]
10/01 06:27:21AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
10/01 06:27:21AM parser.py:31 [INFO] INIT_CHANNELS=16
10/01 06:27:21AM parser.py:31 [INFO] L=0.6
10/01 06:27:21AM parser.py:31 [INFO] LAYERS=20
10/01 06:27:21AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
10/01 06:27:21AM parser.py:31 [INFO] NAME=ARCH-KD
10/01 06:27:21AM parser.py:31 [INFO] NONKD=False
10/01 06:27:21AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.6-h_das_teacher
10/01 06:27:21AM parser.py:31 [INFO] PCDARTS=False
10/01 06:27:21AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.6-h_das_teacher/plots
10/01 06:27:21AM parser.py:31 [INFO] PRINT_FREQ=100
10/01 06:27:21AM parser.py:31 [INFO] RESUME_PATH=None
10/01 06:27:21AM parser.py:31 [INFO] SAVE=l0.6-h_das_teacher
10/01 06:27:21AM parser.py:31 [INFO] SEED=0
10/01 06:27:21AM parser.py:31 [INFO] SHARE_STAGE=False
10/01 06:27:21AM parser.py:31 [INFO] SLIDE_WINDOW=8
10/01 06:27:21AM parser.py:31 [INFO] SPEC_CELL=True
10/01 06:27:21AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
10/01 06:27:21AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
10/01 06:27:21AM parser.py:31 [INFO] TRAIN_PORTION=0.5
10/01 06:27:21AM parser.py:31 [INFO] TYPE=ArchKD
10/01 06:27:21AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
10/01 06:27:21AM parser.py:31 [INFO] W_LR=0.025
10/01 06:27:21AM parser.py:31 [INFO] W_LR_MIN=0.001
10/01 06:27:21AM parser.py:31 [INFO] W_MOMENTUM=0.9
10/01 06:27:21AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
10/01 06:27:21AM parser.py:31 [INFO] WORKERS=4
10/01 06:27:21AM parser.py:32 [INFO] 
10/01 06:27:23AM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
10/01 06:27:23AM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
10/01 06:27:55AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.0284 (4.5540)	Arch Loss 26.4945 (27.1524)	Arch Hard Loss 4.2253 (4.5389)	Arch Alpha Loss 37.1153 (37.6891)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.7%, 11.1%)	
10/01 06:28:25AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1091 (4.3591)	Arch Loss 25.4674 (26.5965)	Arch Hard Loss 3.9106 (4.3344)	Arch Alpha Loss 35.9279 (37.1034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 15.5%)	
10/01 06:28:54AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8903 (4.2434)	Arch Loss 24.7075 (26.1276)	Arch Hard Loss 3.8759 (4.2225)	Arch Alpha Loss 34.7193 (36.5086)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.0%, 19.0%)	
10/01 06:29:20AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8746 (4.1757)	Arch Loss 23.9066 (25.7361)	Arch Hard Loss 3.7331 (4.1554)	Arch Alpha Loss 33.6225 (35.9678)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.7%, 20.8%)	
10/01 06:29:21AM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 5.7200%
10/01 06:29:26AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9069	Prec@(1,5) (8.4%, 28.7%)
10/01 06:29:31AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9160	Prec@(1,5) (8.3%, 28.7%)
10/01 06:29:35AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9118	Prec@(1,5) (8.1%, 28.9%)
10/01 06:29:39AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9071	Prec@(1,5) (8.2%, 29.1%)
10/01 06:29:40AM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 8.2280%
10/01 06:29:40AM searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:29:40AM searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 8.2280%
10/01 06:30:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6197 (3.8253)	Arch Loss 23.0866 (23.6089)	Arch Hard Loss 3.6527 (3.8126)	Arch Alpha Loss 32.3898 (32.9938)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.2%, 32.3%)	
10/01 06:30:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.6284 (3.7881)	Arch Loss 22.4753 (23.2276)	Arch Hard Loss 3.7697 (3.7968)	Arch Alpha Loss 31.1760 (32.3847)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.7%, 33.7%)	
10/01 06:31:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9751 (3.7680)	Arch Loss 21.6010 (22.8228)	Arch Hard Loss 3.6139 (3.7549)	Arch Alpha Loss 29.9785 (31.7797)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.9%, 33.9%)	
10/01 06:31:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.5820 (3.7258)	Arch Loss 20.9394 (22.4647)	Arch Hard Loss 3.5860 (3.7205)	Arch Alpha Loss 28.9223 (31.2404)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.6%, 35.1%)	
10/01 06:31:38午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 11.5960%
10/01 06:31:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6168	Prec@(1,5) (14.0%, 37.6%)
10/01 06:31:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6193	Prec@(1,5) (14.0%, 37.6%)
10/01 06:31:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6173	Prec@(1,5) (13.8%, 37.7%)
10/01 06:31:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6154	Prec@(1,5) (13.8%, 37.7%)
10/01 06:31:56午前 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 13.7920%
10/01 06:31:56午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:31:57午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 13.7920%
10/01 06:32:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.7789 (3.5413)	Arch Loss 20.3340 (20.5717)	Arch Hard Loss 3.6730 (3.5731)	Arch Alpha Loss 27.7682 (28.3309)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.4%, 40.2%)	
10/01 06:32:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.3982 (3.5098)	Arch Loss 19.4691 (20.1963)	Arch Hard Loss 3.4709 (3.5350)	Arch Alpha Loss 26.6636 (27.7689)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 40.9%)	
10/01 06:33:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.2798 (3.4691)	Arch Loss 18.5554 (19.8247)	Arch Hard Loss 3.1938 (3.4923)	Arch Alpha Loss 25.6028 (27.2206)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.0%, 42.2%)	
10/01 06:33:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4742 (3.4457)	Arch Loss 18.3046 (19.5055)	Arch Hard Loss 3.4911 (3.4616)	Arch Alpha Loss 24.6892 (26.7399)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.5%, 43.2%)	
10/01 06:33:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 16.5160%
10/01 06:34:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3763	Prec@(1,5) (18.0%, 45.2%)
10/01 06:34:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3704	Prec@(1,5) (18.2%, 45.2%)
10/01 06:34:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3670	Prec@(1,5) (18.1%, 45.4%)
10/01 06:34:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3711	Prec@(1,5) (18.2%, 45.3%)
10/01 06:34:13午前 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 18.2040%
10/01 06:34:13午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:34:13午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 18.2040%
10/01 06:34:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.2023 (3.2912)	Arch Loss 17.3498 (17.8197)	Arch Hard Loss 3.1226 (3.3078)	Arch Alpha Loss 23.7120 (24.1865)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.3%, 46.9%)	
10/01 06:35:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.2760 (3.2633)	Arch Loss 16.9178 (17.5109)	Arch Hard Loss 3.2392 (3.2812)	Arch Alpha Loss 22.7976 (23.7162)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 47.9%)	
10/01 06:35:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.2143 (3.2471)	Arch Loss 16.3120 (17.2186)	Arch Hard Loss 3.1505 (3.2606)	Arch Alpha Loss 21.9358 (23.2634)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.0%, 48.4%)	
10/01 06:36:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.3271 (3.2281)	Arch Loss 16.1115 (16.9671)	Arch Hard Loss 3.3880 (3.2445)	Arch Alpha Loss 21.2058 (22.8711)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.4%, 49.0%)	
10/01 06:36:11午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 20.4080%
10/01 06:36:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2017	Prec@(1,5) (21.1%, 50.4%)
10/01 06:36:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1995	Prec@(1,5) (20.8%, 50.4%)
10/01 06:36:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2016	Prec@(1,5) (20.9%, 50.2%)
10/01 06:36:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2007	Prec@(1,5) (21.1%, 50.1%)
10/01 06:36:29午前 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 21.0400%
10/01 06:36:29午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:36:29午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 21.0400%
10/01 06:37:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.7881 (3.0612)	Arch Loss 15.1918 (15.6350)	Arch Hard Loss 2.9294 (3.1494)	Arch Alpha Loss 20.4374 (20.8094)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.2%, 53.3%)	
10/01 06:37:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.7416 (3.0452)	Arch Loss 14.9999 (15.3788)	Arch Hard Loss 3.1632 (3.1135)	Arch Alpha Loss 19.7278 (20.4421)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.9%, 54.1%)	
10/01 06:38:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.3239 (3.0330)	Arch Loss 14.2483 (15.1522)	Arch Hard Loss 2.8080 (3.0973)	Arch Alpha Loss 19.0671 (20.0914)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.7%, 54.4%)	
10/01 06:38:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.1405 (3.0222)	Arch Loss 14.3385 (14.9440)	Arch Hard Loss 3.2303 (3.0701)	Arch Alpha Loss 18.5137 (19.7898)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.1%, 54.8%)	
10/01 06:38:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 24.0720%
10/01 06:38:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0041	Prec@(1,5) (24.5%, 54.8%)
10/01 06:38:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0059	Prec@(1,5) (24.8%, 55.1%)
10/01 06:38:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0246	Prec@(1,5) (24.3%, 54.6%)
10/01 06:38:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0247	Prec@(1,5) (24.3%, 54.7%)
10/01 06:38:47午前 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 24.2640%
10/01 06:38:47午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:38:47午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 24.2640%
10/01 06:39:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.7483 (2.8657)	Arch Loss 13.6570 (13.8930)	Arch Hard Loss 2.8950 (2.9636)	Arch Alpha Loss 17.9366 (18.2157)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.8%, 59.3%)	
10/01 06:39:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0192 (2.8633)	Arch Loss 13.0478 (13.7036)	Arch Hard Loss 2.6025 (2.9389)	Arch Alpha Loss 17.4089 (17.9412)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 58.9%)	
10/01 06:40:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.6551 (2.8642)	Arch Loss 12.9373 (13.5377)	Arch Hard Loss 2.7845 (2.9294)	Arch Alpha Loss 16.9214 (17.6805)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 58.7%)	
10/01 06:40:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.7674 (2.8513)	Arch Loss 12.6496 (13.3828)	Arch Hard Loss 2.7409 (2.9084)	Arch Alpha Loss 16.5145 (17.4573)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.2%, 59.1%)	
10/01 06:40:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 27.2560%
10/01 06:40:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8422	Prec@(1,5) (28.3%, 59.3%)
10/01 06:40:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8588	Prec@(1,5) (27.9%, 59.2%)
10/01 06:41:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8564	Prec@(1,5) (27.6%, 59.2%)
10/01 06:41:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8596	Prec@(1,5) (27.4%, 59.1%)
10/01 06:41:06午前 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 27.4360%
10/01 06:41:06午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:41:07午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 27.4360%
10/01 06:41:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.7979 (2.6964)	Arch Loss 12.3026 (12.5797)	Arch Hard Loss 2.6466 (2.8017)	Arch Alpha Loss 16.0933 (16.2967)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.5%, 63.4%)	
10/01 06:42:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.4648 (2.7087)	Arch Loss 12.1603 (12.4722)	Arch Hard Loss 2.7350 (2.8143)	Arch Alpha Loss 15.7088 (16.0965)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 62.9%)	
10/01 06:42:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.7891 (2.6985)	Arch Loss 11.7898 (12.3269)	Arch Hard Loss 2.5765 (2.7828)	Arch Alpha Loss 15.3554 (15.9070)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.2%, 63.0%)	
10/01 06:43:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.9363 (2.6903)	Arch Loss 11.4762 (12.2203)	Arch Hard Loss 2.4391 (2.7733)	Arch Alpha Loss 15.0618 (15.7450)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.4%, 63.1%)	
10/01 06:43:06午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 30.3720%
10/01 06:43:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6978	Prec@(1,5) (30.9%, 62.5%)
10/01 06:43:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6807	Prec@(1,5) (31.2%, 63.2%)
10/01 06:43:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6697	Prec@(1,5) (31.5%, 63.6%)
10/01 06:43:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6696	Prec@(1,5) (31.5%, 63.7%)
10/01 06:43:25午前 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 31.4360%
10/01 06:43:25午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:43:25午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 31.4360%
10/01 06:43:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.7153 (2.5433)	Arch Loss 11.6023 (11.6292)	Arch Hard Loss 2.7475 (2.6863)	Arch Alpha Loss 14.7580 (14.9047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.1%, 66.0%)	
10/01 06:44:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4761 (2.5407)	Arch Loss 10.9713 (11.5332)	Arch Hard Loss 2.2821 (2.6767)	Arch Alpha Loss 14.4821 (14.7608)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.4%, 66.1%)	
10/01 06:44:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.8177 (2.5479)	Arch Loss 11.3200 (11.4520)	Arch Hard Loss 2.7830 (2.6773)	Arch Alpha Loss 14.2284 (14.6246)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.3%, 66.0%)	
10/01 06:45:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.2535 (2.5430)	Arch Loss 10.8224 (11.3554)	Arch Hard Loss 2.4118 (2.6505)	Arch Alpha Loss 14.0177 (14.5083)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.4%, 66.3%)	
10/01 06:45:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 33.4200%
10/01 06:45:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.7086	Prec@(1,5) (31.0%, 63.0%)
10/01 06:45:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6976	Prec@(1,5) (31.7%, 63.1%)
10/01 06:45:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6878	Prec@(1,5) (31.7%, 63.5%)
10/01 06:45:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6883	Prec@(1,5) (31.7%, 63.4%)
10/01 06:45:44午前 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 31.6960%
10/01 06:45:44午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:45:44午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 31.6960%
10/01 06:46:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.2112 (2.4290)	Arch Loss 10.6425 (10.9384)	Arch Hard Loss 2.3626 (2.5952)	Arch Alpha Loss 13.7998 (13.9053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.0%)	
10/01 06:46:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.3168 (2.4237)	Arch Loss 10.6639 (10.8704)	Arch Hard Loss 2.5020 (2.5891)	Arch Alpha Loss 13.6031 (13.8022)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 69.1%)	
10/01 06:47:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.3000 (2.4280)	Arch Loss 10.5642 (10.7977)	Arch Hard Loss 2.5111 (2.5748)	Arch Alpha Loss 13.4219 (13.7049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 69.2%)	
10/01 06:47:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.2270 (2.4233)	Arch Loss 10.2523 (10.7354)	Arch Hard Loss 2.2893 (2.5623)	Arch Alpha Loss 13.2716 (13.6218)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.0%, 69.2%)	
10/01 06:47:40午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 36.0520%
10/01 06:47:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4532	Prec@(1,5) (35.1%, 68.7%)
10/01 06:47:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4814	Prec@(1,5) (35.4%, 67.9%)
10/01 06:47:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4868	Prec@(1,5) (35.6%, 67.7%)
10/01 06:47:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4927	Prec@(1,5) (35.4%, 67.5%)
10/01 06:47:58午前 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 35.3640%
10/01 06:47:58午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:47:58午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 35.3640%
10/01 06:48:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.6907 (2.2897)	Arch Loss 10.8423 (10.4445)	Arch Hard Loss 2.9725 (2.5297)	Arch Alpha Loss 13.1163 (13.1913)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.4%, 71.9%)	
10/01 06:49:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.0307 (2.3045)	Arch Loss 10.3418 (10.3786)	Arch Hard Loss 2.5568 (2.5080)	Arch Alpha Loss 12.9750 (13.1176)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.5%)	
10/01 06:49:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 1.9812 (2.3246)	Arch Loss 10.0280 (10.3115)	Arch Hard Loss 2.3206 (2.4827)	Arch Alpha Loss 12.8458 (13.0481)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 71.1%)	
10/01 06:49:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1808 (2.3197)	Arch Loss 10.2691 (10.2686)	Arch Hard Loss 2.6257 (2.4753)	Arch Alpha Loss 12.7390 (12.9888)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.5%)	
10/01 06:49:59午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 38.2560%
10/01 06:50:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4859	Prec@(1,5) (35.3%, 67.7%)
10/01 06:50:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4588	Prec@(1,5) (35.6%, 68.4%)
10/01 06:50:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4546	Prec@(1,5) (35.6%, 68.5%)
10/01 06:50:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4518	Prec@(1,5) (35.7%, 68.6%)
10/01 06:50:16午前 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 35.7000%
10/01 06:50:16午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:50:17午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 35.7000%
10/01 06:50:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.6478 (2.1672)	Arch Loss 9.8010 (10.0485)	Arch Hard Loss 2.2238 (2.4393)	Arch Alpha Loss 12.6287 (12.6819)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.1%)	
10/01 06:51:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.0437 (2.1868)	Arch Loss 10.0819 (9.9990)	Arch Hard Loss 2.5648 (2.4212)	Arch Alpha Loss 12.5285 (12.6296)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.3%, 73.6%)	
10/01 06:51:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.9601 (2.1975)	Arch Loss 9.6983 (9.9549)	Arch Hard Loss 2.2365 (2.4068)	Arch Alpha Loss 12.4363 (12.5801)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.0%, 73.8%)	
10/01 06:52:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1901 (2.2137)	Arch Loss 9.8134 (9.9211)	Arch Hard Loss 2.3969 (2.3983)	Arch Alpha Loss 12.3608 (12.5380)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.6%, 73.4%)	
10/01 06:52:18午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 40.5600%
10/01 06:52:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3975	Prec@(1,5) (37.4%, 69.1%)
10/01 06:52:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3992	Prec@(1,5) (37.3%, 69.6%)
10/01 06:52:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3813	Prec@(1,5) (37.6%, 70.0%)
10/01 06:52:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3768	Prec@(1,5) (37.8%, 70.1%)
10/01 06:52:36午前 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 37.7960%
10/01 06:52:36午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:52:37午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 37.7960%
10/01 06:53:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2316 (2.0848)	Arch Loss 9.7685 (9.7741)	Arch Hard Loss 2.3992 (2.3820)	Arch Alpha Loss 12.2823 (12.3201)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.5%)	
10/01 06:53:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4744 (2.1043)	Arch Loss 9.6786 (9.7206)	Arch Hard Loss 2.3517 (2.3507)	Arch Alpha Loss 12.2116 (12.2831)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.7%)	
10/01 06:54:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.4133 (2.1181)	Arch Loss 9.7811 (9.6825)	Arch Hard Loss 2.4945 (2.3338)	Arch Alpha Loss 12.1443 (12.2478)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.4%)	
10/01 06:54:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.0481 (2.1193)	Arch Loss 9.4687 (9.6635)	Arch Hard Loss 2.2150 (2.3331)	Arch Alpha Loss 12.0894 (12.2174)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.4%)	
10/01 06:54:37午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 42.7600%
10/01 06:54:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3730	Prec@(1,5) (38.2%, 70.5%)
10/01 06:54:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3740	Prec@(1,5) (38.0%, 70.3%)
10/01 06:54:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3640	Prec@(1,5) (38.0%, 70.7%)
10/01 06:54:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3536	Prec@(1,5) (38.3%, 71.0%)
10/01 06:54:55午前 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 38.2840%
10/01 06:54:55午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:54:55午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 38.2840%
10/01 06:55:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.7283 (1.9875)	Arch Loss 9.6434 (9.5462)	Arch Hard Loss 2.4233 (2.3100)	Arch Alpha Loss 12.0336 (12.0604)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 77.5%)	
10/01 06:55:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.0597 (2.0207)	Arch Loss 9.9310 (9.5264)	Arch Hard Loss 2.7416 (2.3060)	Arch Alpha Loss 11.9823 (12.0340)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.1%)	
10/01 06:56:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.2901 (2.0279)	Arch Loss 9.1580 (9.4845)	Arch Hard Loss 1.9970 (2.2793)	Arch Alpha Loss 11.9350 (12.0087)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 76.9%)	
10/01 06:56:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.0577 (2.0316)	Arch Loss 9.4272 (9.4659)	Arch Hard Loss 2.2896 (2.2737)	Arch Alpha Loss 11.8960 (11.9871)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.1%, 77.0%)	
10/01 06:56:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 44.1480%
10/01 06:57:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2303	Prec@(1,5) (40.5%, 73.9%)
10/01 06:57:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2065	Prec@(1,5) (41.1%, 74.1%)
10/01 06:57:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2076	Prec@(1,5) (41.1%, 73.8%)
10/01 06:57:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2093	Prec@(1,5) (41.2%, 73.8%)
10/01 06:57:13午前 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 41.1720%
10/01 06:57:13午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:57:13午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 41.1720%
10/01 06:57:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1536 (1.9145)	Arch Loss 9.5240 (9.3269)	Arch Hard Loss 2.4102 (2.2017)	Arch Alpha Loss 11.8562 (11.8753)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 79.4%)	
10/01 06:58:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.7305 (1.9229)	Arch Loss 8.9798 (9.3524)	Arch Hard Loss 1.8879 (2.2385)	Arch Alpha Loss 11.8198 (11.8565)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.1%)	
10/01 06:58:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.3814 (1.9326)	Arch Loss 8.9204 (9.3325)	Arch Hard Loss 1.8484 (2.2293)	Arch Alpha Loss 11.7868 (11.8386)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.6%, 79.2%)	
10/01 06:59:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.1281 (1.9473)	Arch Loss 9.0925 (9.3135)	Arch Hard Loss 2.0365 (2.2194)	Arch Alpha Loss 11.7600 (11.8235)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.9%)	
10/01 06:59:15午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 46.3400%
10/01 06:59:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1829	Prec@(1,5) (42.1%, 74.0%)
10/01 06:59:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2087	Prec@(1,5) (41.6%, 73.8%)
10/01 06:59:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2020	Prec@(1,5) (41.7%, 74.0%)
10/01 06:59:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2031	Prec@(1,5) (41.7%, 74.2%)
10/01 06:59:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 41.6600%
10/01 06:59:33午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 06:59:33午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 41.6600%
10/01 07:00:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8973 (1.8700)	Arch Loss 8.8312 (9.2267)	Arch Hard Loss 1.7919 (2.1794)	Arch Alpha Loss 11.7323 (11.7456)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.0%)	
10/01 07:00:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.9534 (1.8640)	Arch Loss 8.9289 (9.2242)	Arch Hard Loss 1.9048 (2.1847)	Arch Alpha Loss 11.7067 (11.7324)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 80.2%)	
10/01 07:01:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.8866 (1.8654)	Arch Loss 9.2290 (9.2017)	Arch Hard Loss 2.2190 (2.1698)	Arch Alpha Loss 11.6833 (11.7198)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 80.3%)	
10/01 07:01:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.3625 (1.8759)	Arch Loss 8.9969 (9.1972)	Arch Hard Loss 1.9983 (2.1717)	Arch Alpha Loss 11.6644 (11.7092)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 80.2%)	
10/01 07:01:33午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 47.5760%
10/01 07:01:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1840	Prec@(1,5) (43.0%, 74.8%)
10/01 07:01:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1608	Prec@(1,5) (43.0%, 75.2%)
10/01 07:01:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1566	Prec@(1,5) (42.8%, 75.6%)
10/01 07:01:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1604	Prec@(1,5) (42.9%, 75.4%)
10/01 07:01:51午前 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 42.8640%
10/01 07:01:51午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:01:52午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 42.8640%
10/01 07:02:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.8415 (1.7458)	Arch Loss 8.7165 (9.1229)	Arch Hard Loss 1.7294 (2.1303)	Arch Alpha Loss 11.6452 (11.6543)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.5%)	
10/01 07:02:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.6370 (1.7554)	Arch Loss 9.1489 (9.1355)	Arch Hard Loss 2.1721 (2.1483)	Arch Alpha Loss 11.6280 (11.6453)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 82.1%)	
10/01 07:03:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.7860 (1.7830)	Arch Loss 8.9330 (9.1224)	Arch Hard Loss 1.9657 (2.1403)	Arch Alpha Loss 11.6121 (11.6368)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.6%)	
10/01 07:03:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.9099 (1.7957)	Arch Loss 9.3743 (9.1182)	Arch Hard Loss 2.4150 (2.1405)	Arch Alpha Loss 11.5988 (11.6295)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.4%)	
10/01 07:03:50午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 49.7720%
10/01 07:03:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1321	Prec@(1,5) (43.4%, 76.1%)
10/01 07:03:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1190	Prec@(1,5) (43.6%, 75.9%)
10/01 07:04:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1243	Prec@(1,5) (43.5%, 76.0%)
10/01 07:04:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1253	Prec@(1,5) (43.4%, 76.0%)
10/01 07:04:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 43.3480%
10/01 07:04:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:04:08午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.3480%
10/01 07:04:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7768 (1.7215)	Arch Loss 9.1535 (9.0446)	Arch Hard Loss 2.2017 (2.0891)	Arch Alpha Loss 11.5864 (11.5926)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.5%)	
10/01 07:05:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.1284 (1.7205)	Arch Loss 9.0073 (9.0551)	Arch Hard Loss 2.0626 (2.1032)	Arch Alpha Loss 11.5746 (11.5865)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.5%)	
10/01 07:05:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9542 (1.7352)	Arch Loss 8.5503 (9.0514)	Arch Hard Loss 1.6116 (2.1030)	Arch Alpha Loss 11.5645 (11.5808)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.4%)	
10/01 07:06:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7329 (1.7467)	Arch Loss 9.7531 (9.0476)	Arch Hard Loss 2.8200 (2.1020)	Arch Alpha Loss 11.5552 (11.5759)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
10/01 07:06:03午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 51.1080%
10/01 07:06:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1036	Prec@(1,5) (44.1%, 75.8%)
10/01 07:06:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1104	Prec@(1,5) (44.2%, 75.7%)
10/01 07:06:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1116	Prec@(1,5) (43.9%, 75.6%)
10/01 07:06:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1077	Prec@(1,5) (43.9%, 75.7%)
10/01 07:06:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 43.8520%
10/01 07:06:20午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:06:21午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.8520%
10/01 07:06:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.0427 (1.6360)	Arch Loss 9.4281 (9.0157)	Arch Hard Loss 2.5001 (2.0853)	Arch Alpha Loss 11.5467 (11.5507)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.4%, 84.7%)	
10/01 07:07:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.4248 (1.6640)	Arch Loss 8.8183 (9.0139)	Arch Hard Loss 1.8950 (2.0859)	Arch Alpha Loss 11.5389 (11.5468)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.7%)	
10/01 07:07:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.9091 (1.6726)	Arch Loss 8.9463 (9.0059)	Arch Hard Loss 2.0273 (2.0802)	Arch Alpha Loss 11.5317 (11.5430)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.6%)	
10/01 07:08:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.7309 (1.6807)	Arch Loss 8.6247 (8.9946)	Arch Hard Loss 1.7087 (2.0708)	Arch Alpha Loss 11.5266 (11.5398)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.4%)	
10/01 07:08:20午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 52.4600%
10/01 07:08:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0010	Prec@(1,5) (46.6%, 77.3%)
10/01 07:08:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9991	Prec@(1,5) (46.0%, 77.7%)
10/01 07:08:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9988	Prec@(1,5) (46.3%, 77.8%)
10/01 07:08:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0008	Prec@(1,5) (46.2%, 77.8%)
10/01 07:08:37午前 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 46.1760%
10/01 07:08:37午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:08:38午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.1760%
10/01 07:09:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.7111 (1.5382)	Arch Loss 8.7098 (8.9668)	Arch Hard Loss 1.7967 (2.0525)	Arch Alpha Loss 11.5219 (11.5239)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.0%)	
10/01 07:09:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.8154 (1.5954)	Arch Loss 8.9122 (8.9803)	Arch Hard Loss 2.0018 (2.0672)	Arch Alpha Loss 11.5173 (11.5217)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.9%)	
10/01 07:10:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6528 (1.5988)	Arch Loss 9.0048 (8.9794)	Arch Hard Loss 2.0972 (2.0678)	Arch Alpha Loss 11.5125 (11.5194)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.9%)	
10/01 07:10:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.6067 (1.6145)	Arch Loss 8.8201 (8.9631)	Arch Hard Loss 1.9150 (2.0527)	Arch Alpha Loss 11.5085 (11.5173)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.3%, 84.7%)	
10/01 07:10:37午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 54.2640%
10/01 07:10:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0067	Prec@(1,5) (46.8%, 77.6%)
10/01 07:10:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0065	Prec@(1,5) (47.0%, 77.7%)
10/01 07:10:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0102	Prec@(1,5) (46.4%, 77.8%)
10/01 07:10:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0018	Prec@(1,5) (46.4%, 77.9%)
10/01 07:10:55午前 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 46.3920%
10/01 07:10:55午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:10:55午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.3920%
10/01 07:11:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.5551 (1.4942)	Arch Loss 9.0671 (8.9174)	Arch Hard Loss 2.1642 (2.0135)	Arch Alpha Loss 11.5049 (11.5066)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.8%, 86.6%)	
10/01 07:11:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6812 (1.5093)	Arch Loss 8.9343 (8.9328)	Arch Hard Loss 2.0335 (2.0299)	Arch Alpha Loss 11.5014 (11.5048)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.4%)	
10/01 07:12:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.2535 (1.5342)	Arch Loss 8.8771 (8.9331)	Arch Hard Loss 1.9778 (2.0312)	Arch Alpha Loss 11.4988 (11.5033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.0%)	
10/01 07:12:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.2625 (1.5510)	Arch Loss 9.0488 (8.9241)	Arch Hard Loss 2.1514 (2.0230)	Arch Alpha Loss 11.4957 (11.5018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.7%)	
10/01 07:12:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 56.1480%
10/01 07:13:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9530	Prec@(1,5) (48.7%, 78.4%)
10/01 07:13:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9638	Prec@(1,5) (48.5%, 78.4%)
10/01 07:13:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9721	Prec@(1,5) (48.3%, 78.2%)
10/01 07:13:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9700	Prec@(1,5) (48.3%, 78.3%)
10/01 07:13:12午前 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 48.3160%
10/01 07:13:12午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:13:13午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 48.3160%
10/01 07:13:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6096 (1.4013)	Arch Loss 8.8497 (8.9482)	Arch Hard Loss 1.9535 (2.0515)	Arch Alpha Loss 11.4937 (11.4944)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 88.5%)	
10/01 07:14:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5533 (1.4509)	Arch Loss 9.2630 (8.9220)	Arch Hard Loss 2.3678 (2.0258)	Arch Alpha Loss 11.4919 (11.4936)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.8%, 87.5%)	
10/01 07:14:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.6650 (1.4663)	Arch Loss 9.1776 (8.9127)	Arch Hard Loss 2.2838 (2.0171)	Arch Alpha Loss 11.4896 (11.4927)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 87.3%)	
10/01 07:15:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6623 (1.4834)	Arch Loss 8.9125 (8.9038)	Arch Hard Loss 2.0202 (2.0088)	Arch Alpha Loss 11.4872 (11.4917)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 87.0%)	
10/01 07:15:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 57.0840%
10/01 07:15:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9850	Prec@(1,5) (47.4%, 78.4%)
10/01 07:15:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9842	Prec@(1,5) (47.5%, 78.3%)
10/01 07:15:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9757	Prec@(1,5) (47.4%, 78.6%)
10/01 07:15:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9741	Prec@(1,5) (47.5%, 78.5%)
10/01 07:15:29午前 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 47.4960%
10/01 07:15:29午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:15:29午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 48.3160%
10/01 07:16:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5215 (1.3774)	Arch Loss 8.3591 (8.8533)	Arch Hard Loss 1.4678 (1.9614)	Arch Alpha Loss 11.4856 (11.4864)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.4%)	
10/01 07:16:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3715 (1.4104)	Arch Loss 8.8912 (8.8759)	Arch Hard Loss 2.0008 (1.9845)	Arch Alpha Loss 11.4840 (11.4857)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.8%)	
10/01 07:17:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.1435 (1.4189)	Arch Loss 9.4529 (8.8724)	Arch Hard Loss 2.5630 (1.9814)	Arch Alpha Loss 11.4832 (11.4850)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.8%)	
10/01 07:17:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.5688 (1.4387)	Arch Loss 8.8675 (8.8631)	Arch Hard Loss 1.9786 (1.9724)	Arch Alpha Loss 11.4815 (11.4844)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.7%)	
10/01 07:17:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 58.3400%
10/01 07:17:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9310	Prec@(1,5) (48.9%, 79.1%)
10/01 07:17:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9096	Prec@(1,5) (49.4%, 79.8%)
10/01 07:17:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9026	Prec@(1,5) (49.4%, 80.1%)
10/01 07:17:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9065	Prec@(1,5) (49.5%, 80.0%)
10/01 07:17:44午前 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 49.4800%
10/01 07:17:44午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:17:44午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.4800%
10/01 07:18:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3212 (1.3065)	Arch Loss 9.2054 (8.8449)	Arch Hard Loss 2.3176 (1.9568)	Arch Alpha Loss 11.4797 (11.4803)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.4%)	
10/01 07:18:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4422 (1.3613)	Arch Loss 9.0409 (8.8534)	Arch Hard Loss 2.1539 (1.9656)	Arch Alpha Loss 11.4785 (11.4797)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.5%)	
10/01 07:19:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4415 (1.3631)	Arch Loss 8.7399 (8.8537)	Arch Hard Loss 1.8533 (1.9661)	Arch Alpha Loss 11.4776 (11.4793)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.6%)	
10/01 07:19:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.1345 (1.3747)	Arch Loss 8.6344 (8.8552)	Arch Hard Loss 1.7483 (1.9679)	Arch Alpha Loss 11.4768 (11.4788)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.5%)	
10/01 07:19:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 60.3120%
10/01 07:19:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9306	Prec@(1,5) (48.5%, 79.7%)
10/01 07:19:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9272	Prec@(1,5) (48.8%, 79.9%)
10/01 07:19:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9066	Prec@(1,5) (49.3%, 80.2%)
10/01 07:20:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9116	Prec@(1,5) (49.3%, 80.0%)
10/01 07:20:01午前 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 49.3160%
10/01 07:20:01午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:20:01午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.4800%
10/01 07:20:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.2849 (1.2221)	Arch Loss 8.7881 (8.8367)	Arch Hard Loss 1.9026 (1.9506)	Arch Alpha Loss 11.4760 (11.4768)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.7%)	
10/01 07:21:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3897 (1.2622)	Arch Loss 9.1031 (8.8481)	Arch Hard Loss 2.2175 (1.9623)	Arch Alpha Loss 11.4759 (11.4764)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.1%)	
10/01 07:21:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.3222 (1.2902)	Arch Loss 8.8369 (8.8524)	Arch Hard Loss 1.9518 (1.9669)	Arch Alpha Loss 11.4751 (11.4759)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.7%)	
10/01 07:22:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4322 (1.3060)	Arch Loss 9.5109 (8.8488)	Arch Hard Loss 2.6268 (1.9635)	Arch Alpha Loss 11.4736 (11.4755)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.4%)	
10/01 07:22:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 61.9200%
10/01 07:22:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9034	Prec@(1,5) (50.6%, 81.0%)
10/01 07:22:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9101	Prec@(1,5) (49.9%, 80.5%)
10/01 07:22:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9201	Prec@(1,5) (49.7%, 80.1%)
10/01 07:22:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9098	Prec@(1,5) (49.8%, 80.3%)
10/01 07:22:18午前 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 49.8360%
10/01 07:22:18午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:22:19午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.8360%
10/01 07:22:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.2619 (1.1880)	Arch Loss 8.6322 (8.8096)	Arch Hard Loss 1.7481 (1.9255)	Arch Alpha Loss 11.4734 (11.4734)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.3%)	
10/01 07:23:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2913 (1.2202)	Arch Loss 9.4537 (8.8394)	Arch Hard Loss 2.5697 (1.9554)	Arch Alpha Loss 11.4733 (11.4734)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.7%)	
10/01 07:23:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3080 (1.2425)	Arch Loss 8.8741 (8.8386)	Arch Hard Loss 1.9904 (1.9546)	Arch Alpha Loss 11.4730 (11.4733)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.3%)	
10/01 07:24:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.5082 (1.2567)	Arch Loss 8.9279 (8.8323)	Arch Hard Loss 2.0454 (1.9485)	Arch Alpha Loss 11.4708 (11.4730)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.1%)	
10/01 07:24:18午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 63.0160%
10/01 07:24:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9752	Prec@(1,5) (49.1%, 79.4%)
10/01 07:24:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9517	Prec@(1,5) (49.1%, 79.6%)
10/01 07:24:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9546	Prec@(1,5) (49.4%, 79.5%)
10/01 07:24:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9496	Prec@(1,5) (49.4%, 79.5%)
10/01 07:24:35午前 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 49.4160%
10/01 07:24:35午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:24:35午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.8360%
10/01 07:25:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.2318 (1.1599)	Arch Loss 8.9430 (8.7803)	Arch Hard Loss 2.0606 (1.8979)	Arch Alpha Loss 11.4707 (11.4707)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.3%)	
10/01 07:25:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3105 (1.1844)	Arch Loss 8.6132 (8.8096)	Arch Hard Loss 1.7312 (1.9273)	Arch Alpha Loss 11.4699 (11.4706)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.1%)	
10/01 07:26:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.2391 (1.2048)	Arch Loss 8.8908 (8.8214)	Arch Hard Loss 2.0084 (1.9392)	Arch Alpha Loss 11.4707 (11.4704)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.7%)	
10/01 07:26:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.4841 (1.2134)	Arch Loss 8.6059 (8.8258)	Arch Hard Loss 1.7242 (1.9437)	Arch Alpha Loss 11.4695 (11.4702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
10/01 07:26:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 64.1720%
10/01 07:26:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8450	Prec@(1,5) (51.5%, 81.2%)
10/01 07:26:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8719	Prec@(1,5) (51.1%, 80.9%)
10/01 07:26:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9012	Prec@(1,5) (50.4%, 80.4%)
10/01 07:26:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9064	Prec@(1,5) (50.2%, 80.4%)
10/01 07:26:49午前 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 50.2040%
10/01 07:26:49午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:26:49午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.2040%
10/01 07:27:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.9306 (1.0960)	Arch Loss 8.8646 (8.8373)	Arch Hard Loss 1.9838 (1.9561)	Arch Alpha Loss 11.4681 (11.4687)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.4%)	
10/01 07:27:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.6307 (1.1273)	Arch Loss 9.0226 (8.8137)	Arch Hard Loss 2.1421 (1.9328)	Arch Alpha Loss 11.4676 (11.4683)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.2%)	
10/01 07:28:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.4773 (1.1538)	Arch Loss 8.5009 (8.8158)	Arch Hard Loss 1.6206 (1.9351)	Arch Alpha Loss 11.4672 (11.4679)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.7%)	
10/01 07:28:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.2490 (1.1634)	Arch Loss 8.8447 (8.8069)	Arch Hard Loss 1.9649 (1.9263)	Arch Alpha Loss 11.4663 (11.4677)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.6%)	
10/01 07:28:46午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 65.8680%
10/01 07:28:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.9159	Prec@(1,5) (50.8%, 80.6%)
10/01 07:28:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8929	Prec@(1,5) (51.1%, 81.2%)
10/01 07:29:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8929	Prec@(1,5) (51.1%, 81.0%)
10/01 07:29:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9012	Prec@(1,5) (50.8%, 80.8%)
10/01 07:29:04午前 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 50.7760%
10/01 07:29:04午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:29:04午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.7760%
10/01 07:29:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 0.7497 (1.0444)	Arch Loss 9.0466 (8.7881)	Arch Hard Loss 2.1667 (1.9084)	Arch Alpha Loss 11.4665 (11.4663)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.4%)	
10/01 07:30:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.0701 (1.0540)	Arch Loss 8.5685 (8.7780)	Arch Hard Loss 1.6884 (1.8981)	Arch Alpha Loss 11.4669 (11.4666)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
10/01 07:30:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1588 (1.0864)	Arch Loss 8.5685 (8.8150)	Arch Hard Loss 1.6884 (1.9350)	Arch Alpha Loss 11.4669 (11.4667)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.4%)	
10/01 07:31:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 0.9254 (1.0983)	Arch Loss 8.4607 (8.8105)	Arch Hard Loss 1.5809 (1.9304)	Arch Alpha Loss 11.4664 (11.4667)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.3%)	
10/01 07:31:05午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 67.3720%
10/01 07:31:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9299	Prec@(1,5) (50.2%, 80.4%)
10/01 07:31:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.9311	Prec@(1,5) (51.0%, 80.2%)
10/01 07:31:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.9177	Prec@(1,5) (51.3%, 80.4%)
10/01 07:31:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.9145	Prec@(1,5) (51.4%, 80.6%)
10/01 07:31:22午前 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 51.3440%
10/01 07:31:22午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:31:23午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 51.3440%
10/01 07:31:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9839 (0.9755)	Arch Loss 8.5954 (8.7842)	Arch Hard Loss 1.7158 (1.9045)	Arch Alpha Loss 11.4659 (11.4661)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.9%)	
10/01 07:32:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1358 (1.0123)	Arch Loss 9.0061 (8.7813)	Arch Hard Loss 2.1269 (1.9019)	Arch Alpha Loss 11.4654 (11.4657)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.4%)	
10/01 07:32:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.1458 (1.0323)	Arch Loss 8.5026 (8.8119)	Arch Hard Loss 1.6238 (1.9327)	Arch Alpha Loss 11.4646 (11.4654)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.1%)	
10/01 07:33:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.1693 (1.0421)	Arch Loss 8.7386 (8.8105)	Arch Hard Loss 1.8593 (1.9313)	Arch Alpha Loss 11.4655 (11.4653)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.9%)	
10/01 07:33:23午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 68.4760%
10/01 07:33:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8297	Prec@(1,5) (53.3%, 82.2%)
10/01 07:33:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8634	Prec@(1,5) (52.7%, 81.7%)
10/01 07:33:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8643	Prec@(1,5) (52.6%, 81.9%)
10/01 07:33:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8700	Prec@(1,5) (52.7%, 81.6%)
10/01 07:33:40午前 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 52.6600%
10/01 07:33:40午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:33:40午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.6600%
10/01 07:34:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.8504 (0.9375)	Arch Loss 8.8850 (8.8273)	Arch Hard Loss 2.0064 (1.9485)	Arch Alpha Loss 11.4644 (11.4647)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.4%)	
10/01 07:34:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.1349 (0.9614)	Arch Loss 8.5399 (8.8218)	Arch Hard Loss 1.6611 (1.9431)	Arch Alpha Loss 11.4647 (11.4646)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.8%, 94.1%)	
10/01 07:35:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.0383 (0.9748)	Arch Loss 9.7012 (8.8291)	Arch Hard Loss 2.8223 (1.9503)	Arch Alpha Loss 11.4649 (11.4647)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.8%)	
10/01 07:35:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9603 (0.9884)	Arch Loss 9.1043 (8.8256)	Arch Hard Loss 2.2258 (1.9468)	Arch Alpha Loss 11.4641 (11.4647)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.7%)	
10/01 07:35:34午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 70.1880%
10/01 07:35:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8809	Prec@(1,5) (53.0%, 81.7%)
10/01 07:35:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8867	Prec@(1,5) (52.9%, 81.3%)
10/01 07:35:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.9006	Prec@(1,5) (52.3%, 81.4%)
10/01 07:35:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8930	Prec@(1,5) (52.3%, 81.4%)
10/01 07:35:51午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 52.3640%
10/01 07:35:51午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 07:35:52午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.6600%
10/01 07:36:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.5596 (0.8941)	Arch Loss 8.9035 (8.8266)	Arch Hard Loss 2.0252 (1.9483)	Arch Alpha Loss 11.4639 (11.4639)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.5%)	
10/01 07:36:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9137 (0.9244)	Arch Loss 9.1662 (8.8186)	Arch Hard Loss 2.2877 (1.9402)	Arch Alpha Loss 11.4641 (11.4640)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.3%)	
10/01 07:37:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.0632 (0.9386)	Arch Loss 8.7103 (8.8315)	Arch Hard Loss 1.8315 (1.9529)	Arch Alpha Loss 11.4647 (11.4642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.2%)	
10/01 07:37:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0419 (0.9475)	Arch Loss 8.7347 (8.8264)	Arch Hard Loss 1.8566 (1.9479)	Arch Alpha Loss 11.4636 (11.4642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 94.1%)	
10/01 07:37:51午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 71.1320%
10/01 07:37:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9471	Prec@(1,5) (51.2%, 81.0%)
10/01 07:38:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9592	Prec@(1,5) (50.9%, 80.9%)
10/01 07:38:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9628	Prec@(1,5) (50.9%, 80.7%)
10/01 07:38:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9396	Prec@(1,5) (51.4%, 81.1%)
10/01 07:38:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 51.4120%
10/01 07:38:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 07:38:08午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.6600%
10/01 07:38:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9768 (0.8427)	Arch Loss 8.7957 (8.8659)	Arch Hard Loss 1.9180 (1.9878)	Arch Alpha Loss 11.4629 (11.4635)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.1%)	
10/01 07:39:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.0052 (0.8594)	Arch Loss 8.8231 (8.8179)	Arch Hard Loss 1.9457 (1.9401)	Arch Alpha Loss 11.4624 (11.4630)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.9%)	
10/01 07:39:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0308 (0.8711)	Arch Loss 9.1381 (8.8165)	Arch Hard Loss 2.2604 (1.9388)	Arch Alpha Loss 11.4628 (11.4629)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
10/01 07:40:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.8290 (0.8838)	Arch Loss 8.9067 (8.8171)	Arch Hard Loss 2.0293 (1.9394)	Arch Alpha Loss 11.4623 (11.4628)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.7%)	
10/01 07:40:09午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 73.1720%
10/01 07:40:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8699	Prec@(1,5) (53.5%, 82.1%)
10/01 07:40:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9052	Prec@(1,5) (53.0%, 81.6%)
10/01 07:40:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9099	Prec@(1,5) (52.9%, 81.6%)
10/01 07:40:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9056	Prec@(1,5) (52.8%, 81.7%)
10/01 07:40:27午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 52.8280%
10/01 07:40:27午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 07:40:27午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.8280%
10/01 07:40:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8512 (0.7557)	Arch Loss 8.3306 (8.8242)	Arch Hard Loss 1.4537 (1.9469)	Arch Alpha Loss 11.4616 (11.4620)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.4%)	
10/01 07:41:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.0072 (0.7715)	Arch Loss 8.6710 (8.8351)	Arch Hard Loss 1.7942 (1.9580)	Arch Alpha Loss 11.4614 (11.4619)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 96.1%)	
10/01 07:41:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.7360 (0.8001)	Arch Loss 9.1984 (8.8337)	Arch Hard Loss 2.3213 (1.9567)	Arch Alpha Loss 11.4618 (11.4617)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.8%)	
10/01 07:42:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.7156 (0.8159)	Arch Loss 8.8271 (8.8350)	Arch Hard Loss 1.9495 (1.9579)	Arch Alpha Loss 11.4625 (11.4618)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.6%)	
10/01 07:42:23午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 75.1040%
10/01 07:42:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.9411	Prec@(1,5) (51.8%, 81.6%)
10/01 07:42:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.9232	Prec@(1,5) (53.0%, 81.7%)
10/01 07:42:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.9277	Prec@(1,5) (52.9%, 81.5%)
10/01 07:42:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.9314	Prec@(1,5) (52.7%, 81.5%)
10/01 07:42:40午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 52.6240%
10/01 07:42:40午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:42:41午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.8280%
10/01 07:43:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8942 (0.7260)	Arch Loss 9.5596 (8.8079)	Arch Hard Loss 2.6825 (1.9304)	Arch Alpha Loss 11.4618 (11.4625)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.6%)	
10/01 07:43:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.6324 (0.7501)	Arch Loss 8.5579 (8.8306)	Arch Hard Loss 1.6801 (1.9530)	Arch Alpha Loss 11.4629 (11.4626)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.3%)	
10/01 07:44:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.6702 (0.7550)	Arch Loss 8.5230 (8.8500)	Arch Hard Loss 1.6445 (1.9722)	Arch Alpha Loss 11.4641 (11.4629)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.3%)	
10/01 07:44:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9372 (0.7733)	Arch Loss 8.9232 (8.8435)	Arch Hard Loss 2.0456 (1.9657)	Arch Alpha Loss 11.4628 (11.4630)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.2%, 96.1%)	
10/01 07:44:41午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 76.1840%
10/01 07:44:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8949	Prec@(1,5) (53.4%, 81.7%)
10/01 07:44:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.9244	Prec@(1,5) (52.8%, 81.7%)
10/01 07:44:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.9363	Prec@(1,5) (52.7%, 81.8%)
10/01 07:44:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.9341	Prec@(1,5) (52.8%, 81.8%)
10/01 07:44:59午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 52.7920%
10/01 07:44:59午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:44:59午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.8280%
10/01 07:45:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.6870 (0.6739)	Arch Loss 8.3726 (8.7902)	Arch Hard Loss 1.4946 (1.9123)	Arch Alpha Loss 11.4635 (11.4633)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
10/01 07:46:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.7468 (0.6886)	Arch Loss 8.8833 (8.8201)	Arch Hard Loss 2.0054 (1.9420)	Arch Alpha Loss 11.4632 (11.4634)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.9%)	
10/01 07:46:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.8000 (0.7078)	Arch Loss 8.5800 (8.8351)	Arch Hard Loss 1.7020 (1.9571)	Arch Alpha Loss 11.4634 (11.4633)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.6%)	
10/01 07:47:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.6742 (0.7155)	Arch Loss 8.8799 (8.8493)	Arch Hard Loss 2.0015 (1.9713)	Arch Alpha Loss 11.4640 (11.4633)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.6%)	
10/01 07:47:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 77.9040%
10/01 07:47:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.9051	Prec@(1,5) (54.3%, 82.2%)
10/01 07:47:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9428	Prec@(1,5) (53.4%, 82.1%)
10/01 07:47:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9406	Prec@(1,5) (53.3%, 82.0%)
10/01 07:47:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9404	Prec@(1,5) (53.2%, 82.0%)
10/01 07:47:18午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 53.2640%
10/01 07:47:18午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:47:19午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.2640%
10/01 07:47:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.5638 (0.6134)	Arch Loss 8.6795 (8.8700)	Arch Hard Loss 1.8012 (1.9918)	Arch Alpha Loss 11.4638 (11.4637)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.6%)	
10/01 07:48:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.8140 (0.6355)	Arch Loss 9.1305 (8.8683)	Arch Hard Loss 2.2517 (1.9901)	Arch Alpha Loss 11.4646 (11.4637)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.5%)	
10/01 07:48:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.5783 (0.6425)	Arch Loss 8.6993 (8.8649)	Arch Hard Loss 1.8202 (1.9864)	Arch Alpha Loss 11.4653 (11.4641)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.3%)	
10/01 07:49:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.5862 (0.6540)	Arch Loss 8.4081 (8.8656)	Arch Hard Loss 1.5286 (1.9870)	Arch Alpha Loss 11.4658 (11.4644)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.2%)	
10/01 07:49:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 79.6720%
10/01 07:49:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9805	Prec@(1,5) (53.2%, 81.5%)
10/01 07:49:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9640	Prec@(1,5) (53.4%, 81.8%)
10/01 07:49:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9613	Prec@(1,5) (53.3%, 81.8%)
10/01 07:49:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9540	Prec@(1,5) (53.5%, 81.9%)
10/01 07:49:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 53.4720%
10/01 07:49:33午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:49:34午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.4720%
10/01 07:50:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6353 (0.5709)	Arch Loss 9.2191 (8.8657)	Arch Hard Loss 2.3389 (1.9860)	Arch Alpha Loss 11.4669 (11.4661)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.9%)	
10/01 07:50:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.7764 (0.5853)	Arch Loss 8.8624 (8.8468)	Arch Hard Loss 1.9824 (1.9669)	Arch Alpha Loss 11.4668 (11.4665)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.8%)	
10/01 07:51:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8859 (0.5956)	Arch Loss 8.3939 (8.8649)	Arch Hard Loss 1.5140 (1.9850)	Arch Alpha Loss 11.4665 (11.4665)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.7%)	
10/01 07:51:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.7761 (0.6103)	Arch Loss 9.0712 (8.8703)	Arch Hard Loss 2.1917 (1.9904)	Arch Alpha Loss 11.4659 (11.4664)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.6%)	
10/01 07:51:30午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 81.0920%
10/01 07:51:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.0151	Prec@(1,5) (53.5%, 82.2%)
10/01 07:51:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9979	Prec@(1,5) (53.7%, 82.0%)
10/01 07:51:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9825	Prec@(1,5) (53.6%, 82.0%)
10/01 07:51:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9893	Prec@(1,5) (53.5%, 81.9%)
10/01 07:51:48午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 53.5440%
10/01 07:51:48午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:51:48午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.5440%
10/01 07:52:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.4293 (0.5540)	Arch Loss 8.5300 (8.8395)	Arch Hard Loss 1.6503 (1.9600)	Arch Alpha Loss 11.4662 (11.4659)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 98.3%)	
10/01 07:52:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.5599 (0.5571)	Arch Loss 9.1772 (8.8642)	Arch Hard Loss 2.2975 (1.9848)	Arch Alpha Loss 11.4662 (11.4657)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.1%)	
10/01 07:53:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.5850 (0.5672)	Arch Loss 9.2902 (8.8786)	Arch Hard Loss 2.4101 (1.9990)	Arch Alpha Loss 11.4667 (11.4660)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 98.0%)	
10/01 07:53:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.5676 (0.5705)	Arch Loss 9.3188 (8.8970)	Arch Hard Loss 2.4383 (2.0174)	Arch Alpha Loss 11.4676 (11.4661)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.9%)	
10/01 07:53:47午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 82.4160%
10/01 07:53:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.9624	Prec@(1,5) (54.8%, 82.2%)
10/01 07:53:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.9601	Prec@(1,5) (54.9%, 82.4%)
10/01 07:54:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9763	Prec@(1,5) (54.7%, 82.3%)
10/01 07:54:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9857	Prec@(1,5) (54.6%, 82.2%)
10/01 07:54:05午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 54.5760%
10/01 07:54:05午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:54:05午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.5760%
10/01 07:54:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.4135 (0.4646)	Arch Loss 8.5168 (8.8913)	Arch Hard Loss 1.6364 (2.0108)	Arch Alpha Loss 11.4672 (11.4674)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.7%)	
10/01 07:55:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6738 (0.4852)	Arch Loss 8.9795 (8.9071)	Arch Hard Loss 2.0984 (2.0265)	Arch Alpha Loss 11.4684 (11.4676)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.3%)	
10/01 07:55:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.5132 (0.5004)	Arch Loss 9.2996 (8.9287)	Arch Hard Loss 2.4183 (2.0479)	Arch Alpha Loss 11.4688 (11.4680)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
10/01 07:56:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.4553 (0.5092)	Arch Loss 9.1497 (8.9287)	Arch Hard Loss 2.2677 (2.0477)	Arch Alpha Loss 11.4701 (11.4684)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
10/01 07:56:05午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 84.0640%
10/01 07:56:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.0045	Prec@(1,5) (53.9%, 82.4%)
10/01 07:56:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.0109	Prec@(1,5) (53.6%, 82.6%)
10/01 07:56:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.0148	Prec@(1,5) (53.8%, 82.4%)
10/01 07:56:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9992	Prec@(1,5) (54.0%, 82.5%)
10/01 07:56:22午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 54.0080%
10/01 07:56:22午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:56:23午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.5760%
10/01 07:56:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.5940 (0.4356)	Arch Loss 8.7762 (8.9227)	Arch Hard Loss 1.8935 (2.0404)	Arch Alpha Loss 11.4710 (11.4706)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.7%)	
10/01 07:57:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.3492 (0.4455)	Arch Loss 9.6902 (8.9298)	Arch Hard Loss 2.8085 (2.0477)	Arch Alpha Loss 11.4695 (11.4702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
10/01 07:57:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.3848 (0.4606)	Arch Loss 8.5252 (8.9388)	Arch Hard Loss 1.6428 (2.0567)	Arch Alpha Loss 11.4707 (11.4702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.6%)	
10/01 07:58:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.5475 (0.4671)	Arch Loss 9.2573 (8.9338)	Arch Hard Loss 2.3746 (2.0516)	Arch Alpha Loss 11.4712 (11.4704)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.5%)	
10/01 07:58:24午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 85.6760%
10/01 07:58:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.0143	Prec@(1,5) (54.2%, 82.2%)
10/01 07:58:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.0100	Prec@(1,5) (54.4%, 82.5%)
10/01 07:58:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.0261	Prec@(1,5) (54.4%, 82.3%)
10/01 07:58:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.0255	Prec@(1,5) (54.2%, 82.2%)
10/01 07:58:41午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 54.1880%
10/01 07:58:41午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 07:58:41午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.5760%
10/01 07:59:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.5381 (0.3976)	Arch Loss 9.2175 (8.8603)	Arch Hard Loss 2.3345 (1.9770)	Arch Alpha Loss 11.4717 (11.4720)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.1%, 98.8%)	
10/01 07:59:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.3923 (0.4123)	Arch Loss 9.0598 (8.9149)	Arch Hard Loss 2.1761 (2.0315)	Arch Alpha Loss 11.4729 (11.4723)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.9%)	
10/01 08:00:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4724 (0.4191)	Arch Loss 9.1049 (8.9338)	Arch Hard Loss 2.2208 (2.0503)	Arch Alpha Loss 11.4734 (11.4726)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
10/01 08:00:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.5036 (0.4289)	Arch Loss 8.8803 (8.9393)	Arch Hard Loss 1.9972 (2.0558)	Arch Alpha Loss 11.4717 (11.4726)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.7%)	
10/01 08:00:42午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 86.8080%
10/01 08:00:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9800	Prec@(1,5) (55.4%, 83.1%)
10/01 08:00:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9978	Prec@(1,5) (54.7%, 82.7%)
10/01 08:00:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.0165	Prec@(1,5) (54.3%, 82.6%)
10/01 08:00:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9998	Prec@(1,5) (54.6%, 82.7%)
10/01 08:00:59午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 54.5520%
10/01 08:00:59午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:00:59午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.5760%
10/01 08:01:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.3108 (0.3757)	Arch Loss 8.6976 (8.9830)	Arch Hard Loss 1.8143 (2.0998)	Arch Alpha Loss 11.4721 (11.4719)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.1%)	
10/01 08:02:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4586 (0.3847)	Arch Loss 8.8578 (8.9358)	Arch Hard Loss 1.9748 (2.0526)	Arch Alpha Loss 11.4717 (11.4720)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
10/01 08:02:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.4071 (0.3895)	Arch Loss 8.7585 (8.9490)	Arch Hard Loss 1.8757 (2.0659)	Arch Alpha Loss 11.4714 (11.4719)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.0%)	
10/01 08:02:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.3129 (0.3971)	Arch Loss 8.5083 (8.9427)	Arch Hard Loss 1.6253 (2.0596)	Arch Alpha Loss 11.4717 (11.4719)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.0%, 98.9%)	
10/01 08:03:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 87.9840%
10/01 08:03:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.0304	Prec@(1,5) (54.0%, 82.3%)
10/01 08:03:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.0033	Prec@(1,5) (54.8%, 82.8%)
10/01 08:03:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.0350	Prec@(1,5) (54.4%, 82.5%)
10/01 08:03:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.0228	Prec@(1,5) (54.6%, 82.6%)
10/01 08:03:18午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 54.6480%
10/01 08:03:18午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:03:18午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.6480%
10/01 08:03:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.2734 (0.3391)	Arch Loss 8.7202 (8.9430)	Arch Hard Loss 1.8370 (2.0598)	Arch Alpha Loss 11.4719 (11.4720)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
10/01 08:04:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.4385 (0.3532)	Arch Loss 8.6800 (8.9661)	Arch Hard Loss 1.7968 (2.0830)	Arch Alpha Loss 11.4720 (11.4718)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.2%)	
10/01 08:04:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.4072 (0.3607)	Arch Loss 9.3812 (8.9741)	Arch Hard Loss 2.4976 (2.0910)	Arch Alpha Loss 11.4727 (11.4719)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
10/01 08:05:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.3557 (0.3636)	Arch Loss 8.6776 (8.9689)	Arch Hard Loss 1.7942 (2.0856)	Arch Alpha Loss 11.4723 (11.4721)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.1%)	
10/01 08:05:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 88.9560%
10/01 08:05:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.0511	Prec@(1,5) (54.1%, 82.6%)
10/01 08:05:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.0297	Prec@(1,5) (54.7%, 82.8%)
10/01 08:05:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.0325	Prec@(1,5) (54.9%, 82.8%)
10/01 08:05:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.0443	Prec@(1,5) (54.9%, 82.8%)
10/01 08:05:31午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 54.9160%
10/01 08:05:31午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 08:05:32午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9160%
10/01 08:06:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.2472 (0.3247)	Arch Loss 9.3552 (8.9679)	Arch Hard Loss 2.4716 (2.0844)	Arch Alpha Loss 11.4727 (11.4725)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.3%)	
10/01 08:06:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.1989 (0.3263)	Arch Loss 8.7792 (8.9813)	Arch Hard Loss 1.8953 (2.0975)	Arch Alpha Loss 11.4732 (11.4730)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
10/01 08:07:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.3249 (0.3325)	Arch Loss 9.6514 (8.9832)	Arch Hard Loss 2.7672 (2.0993)	Arch Alpha Loss 11.4736 (11.4731)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.4%)	
10/01 08:07:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.1793 (0.3363)	Arch Loss 8.8735 (8.9778)	Arch Hard Loss 1.9891 (2.0939)	Arch Alpha Loss 11.4741 (11.4733)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
10/01 08:07:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 89.9200%
10/01 08:07:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.0699	Prec@(1,5) (54.9%, 82.5%)
10/01 08:07:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.0604	Prec@(1,5) (54.9%, 82.5%)
10/01 08:07:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.0573	Prec@(1,5) (55.2%, 82.4%)
10/01 08:07:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.0542	Prec@(1,5) (55.0%, 82.5%)
10/01 08:07:49午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 54.9960%
10/01 08:07:49午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:07:49午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9960%
10/01 08:08:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.2259 (0.2917)	Arch Loss 9.3017 (8.9494)	Arch Hard Loss 2.4174 (2.0651)	Arch Alpha Loss 11.4738 (11.4738)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
10/01 08:08:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.2867 (0.2998)	Arch Loss 8.6517 (8.9822)	Arch Hard Loss 1.7673 (2.0979)	Arch Alpha Loss 11.4740 (11.4739)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.4%)	
10/01 08:09:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.3925 (0.3023)	Arch Loss 8.8056 (8.9989)	Arch Hard Loss 1.9206 (2.1145)	Arch Alpha Loss 11.4750 (11.4740)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
10/01 08:09:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.2409 (0.3069)	Arch Loss 9.0924 (8.9900)	Arch Hard Loss 2.2064 (2.1053)	Arch Alpha Loss 11.4767 (11.4745)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
10/01 08:09:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 91.0360%
10/01 08:09:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0875	Prec@(1,5) (54.1%, 82.7%)
10/01 08:09:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.0925	Prec@(1,5) (53.9%, 82.4%)
10/01 08:10:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.0709	Prec@(1,5) (54.3%, 82.6%)
10/01 08:10:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.0589	Prec@(1,5) (54.6%, 82.6%)
10/01 08:10:06午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 54.6000%
10/01 08:10:07午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:10:07午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.9960%
10/01 08:10:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.3322 (0.2914)	Arch Loss 8.2326 (9.0374)	Arch Hard Loss 1.3460 (2.1511)	Arch Alpha Loss 11.4775 (11.4772)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.6%)	
10/01 08:11:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.4006 (0.2931)	Arch Loss 9.7159 (9.0341)	Arch Hard Loss 2.8293 (2.1476)	Arch Alpha Loss 11.4777 (11.4775)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
10/01 08:11:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.3207 (0.2935)	Arch Loss 8.7272 (9.0256)	Arch Hard Loss 1.8400 (2.1390)	Arch Alpha Loss 11.4786 (11.4777)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
10/01 08:12:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4004 (0.2972)	Arch Loss 8.5727 (9.0118)	Arch Hard Loss 1.6863 (2.1251)	Arch Alpha Loss 11.4774 (11.4778)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
10/01 08:12:06午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 91.2960%
10/01 08:12:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.1119	Prec@(1,5) (54.9%, 82.2%)
10/01 08:12:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.1024	Prec@(1,5) (54.9%, 82.5%)
10/01 08:12:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.0736	Prec@(1,5) (55.1%, 82.8%)
10/01 08:12:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.0694	Prec@(1,5) (55.1%, 82.7%)
10/01 08:12:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 55.0760%
10/01 08:12:24午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:12:25午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.0760%
10/01 08:12:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.1233 (0.2653)	Arch Loss 9.1078 (8.9822)	Arch Hard Loss 2.2208 (2.0955)	Arch Alpha Loss 11.4782 (11.4778)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.7%)	
10/01 08:13:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.3278 (0.2739)	Arch Loss 9.4117 (8.9959)	Arch Hard Loss 2.5249 (2.1091)	Arch Alpha Loss 11.4779 (11.4780)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
10/01 08:13:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.3590 (0.2762)	Arch Loss 9.1243 (8.9987)	Arch Hard Loss 2.2377 (2.1120)	Arch Alpha Loss 11.4775 (11.4780)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
10/01 08:14:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.2702 (0.2804)	Arch Loss 9.2429 (9.0172)	Arch Hard Loss 2.3555 (2.1304)	Arch Alpha Loss 11.4790 (11.4780)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
10/01 08:14:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 91.9880%
10/01 08:14:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.1165	Prec@(1,5) (54.9%, 82.2%)
10/01 08:14:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.0738	Prec@(1,5) (54.9%, 82.7%)
10/01 08:14:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.0751	Prec@(1,5) (55.1%, 82.7%)
10/01 08:14:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.0772	Prec@(1,5) (55.1%, 82.8%)
10/01 08:14:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 55.0920%
10/01 08:14:43午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:14:43午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.0920%
10/01 08:15:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.3034 (0.2563)	Arch Loss 8.8905 (9.0103)	Arch Hard Loss 2.0024 (2.1225)	Arch Alpha Loss 11.4801 (11.4797)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
10/01 08:15:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.2785 (0.2566)	Arch Loss 9.0582 (9.0190)	Arch Hard Loss 2.1704 (2.1312)	Arch Alpha Loss 11.4796 (11.4797)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
10/01 08:16:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.2872 (0.2595)	Arch Loss 10.0655 (9.0315)	Arch Hard Loss 3.1783 (2.1439)	Arch Alpha Loss 11.4787 (11.4794)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
10/01 08:16:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.2373 (0.2591)	Arch Loss 8.3186 (9.0270)	Arch Hard Loss 1.4321 (2.1395)	Arch Alpha Loss 11.4776 (11.4791)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
10/01 08:16:44午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 92.7880%
10/01 08:16:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.0829	Prec@(1,5) (55.3%, 82.5%)
10/01 08:16:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.0580	Prec@(1,5) (55.3%, 82.9%)
10/01 08:16:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.0652	Prec@(1,5) (55.3%, 82.8%)
10/01 08:17:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.0669	Prec@(1,5) (55.2%, 82.7%)
10/01 08:17:02午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 55.1760%
10/01 08:17:02午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:17:02午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.1760%
10/01 08:17:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.2636 (0.2446)	Arch Loss 8.6099 (9.0182)	Arch Hard Loss 1.7233 (2.1317)	Arch Alpha Loss 11.4776 (11.4775)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.6%)	
10/01 08:18:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.2367 (0.2433)	Arch Loss 8.3279 (9.0129)	Arch Hard Loss 1.4412 (2.1262)	Arch Alpha Loss 11.4779 (11.4777)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
10/01 08:18:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.2484 (0.2461)	Arch Loss 9.1161 (9.0178)	Arch Hard Loss 2.2296 (2.1312)	Arch Alpha Loss 11.4775 (11.4777)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
10/01 08:19:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.1984 (0.2488)	Arch Loss 8.6493 (9.0272)	Arch Hard Loss 1.7627 (2.1406)	Arch Alpha Loss 11.4776 (11.4777)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
10/01 08:19:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 93.1120%
10/01 08:19:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.0858	Prec@(1,5) (54.9%, 82.8%)
10/01 08:19:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.0872	Prec@(1,5) (55.2%, 83.1%)
10/01 08:19:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.0962	Prec@(1,5) (55.2%, 82.9%)
10/01 08:19:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.0918	Prec@(1,5) (55.2%, 83.1%)
10/01 08:19:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 55.1520%
10/01 08:19:20午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 08:19:20午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.1760%
10/01 08:19:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.2588 (0.2343)	Arch Loss 9.2302 (9.0515)	Arch Hard Loss 2.3430 (2.1646)	Arch Alpha Loss 11.4785 (11.4781)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.9%, 99.6%)	
10/01 08:20:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.1877 (0.2304)	Arch Loss 8.7215 (9.0463)	Arch Hard Loss 1.8345 (2.1593)	Arch Alpha Loss 11.4784 (11.4783)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.7%)	
10/01 08:20:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.1530 (0.2359)	Arch Loss 9.3108 (9.0395)	Arch Hard Loss 2.4237 (2.1525)	Arch Alpha Loss 11.4785 (11.4784)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
10/01 08:21:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5783 (0.2411)	Arch Loss 9.3490 (9.0500)	Arch Hard Loss 2.4619 (2.1630)	Arch Alpha Loss 11.4785 (11.4783)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
10/01 08:21:22午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 93.5200%
10/01 08:21:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.1316	Prec@(1,5) (55.1%, 82.5%)
10/01 08:21:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.0774	Prec@(1,5) (55.8%, 83.1%)
10/01 08:21:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.0935	Prec@(1,5) (55.5%, 83.0%)
10/01 08:21:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.0948	Prec@(1,5) (55.3%, 83.0%)
10/01 08:21:39午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 55.2920%
10/01 08:21:39午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 08:21:39午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.2920%
10/01 08:21:39午前 searchStage_KD_main.py:101 [INFO] Final best Prec@1 = 55.2920%
10/01 08:21:39午前 searchStage_KD_main.py:102 [INFO] Final Best Genotype = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
