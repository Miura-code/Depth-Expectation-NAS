09/30 10:52:34PM parser.py:28 [INFO] 
09/30 10:52:34PM parser.py:29 [INFO] Parameters:
09/30 10:52:34PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.1-h_das_teacher/DAG
09/30 10:52:34PM parser.py:31 [INFO] T=10.0
09/30 10:52:34PM parser.py:31 [INFO] ADVANCED=True
09/30 10:52:34PM parser.py:31 [INFO] ALPHA_LR=0.0003
09/30 10:52:34PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
09/30 10:52:34PM parser.py:31 [INFO] BATCH_SIZE=64
09/30 10:52:34PM parser.py:31 [INFO] CASCADE=False
09/30 10:52:34PM parser.py:31 [INFO] CHECKPOINT_RESET=False
09/30 10:52:34PM parser.py:31 [INFO] CUTOUT_LENGTH=0
09/30 10:52:34PM parser.py:31 [INFO] DATA_PATH=../data/
09/30 10:52:34PM parser.py:31 [INFO] DATASET=cifar100
09/30 10:52:34PM parser.py:31 [INFO] DEPTH_COEF=0.0
09/30 10:52:34PM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
09/30 10:52:34PM parser.py:31 [INFO] EPOCHS=50
09/30 10:52:34PM parser.py:31 [INFO] EXP_NAME=l0.1-h_das_teacher
09/30 10:52:34PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
09/30 10:52:34PM parser.py:31 [INFO] GPUS=[0]
09/30 10:52:34PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
09/30 10:52:34PM parser.py:31 [INFO] INIT_CHANNELS=16
09/30 10:52:34PM parser.py:31 [INFO] L=0.1
09/30 10:52:34PM parser.py:31 [INFO] LAYERS=20
09/30 10:52:34PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
09/30 10:52:34PM parser.py:31 [INFO] NAME=ARCH-KD
09/30 10:52:34PM parser.py:31 [INFO] NONKD=False
09/30 10:52:34PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.1-h_das_teacher
09/30 10:52:34PM parser.py:31 [INFO] PCDARTS=False
09/30 10:52:34PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.1-h_das_teacher/plots
09/30 10:52:34PM parser.py:31 [INFO] PRINT_FREQ=100
09/30 10:52:34PM parser.py:31 [INFO] RESUME_PATH=None
09/30 10:52:34PM parser.py:31 [INFO] SAVE=l0.1-h_das_teacher
09/30 10:52:34PM parser.py:31 [INFO] SEED=0
09/30 10:52:34PM parser.py:31 [INFO] SHARE_STAGE=False
09/30 10:52:34PM parser.py:31 [INFO] SLIDE_WINDOW=8
09/30 10:52:34PM parser.py:31 [INFO] SPEC_CELL=True
09/30 10:52:34PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
09/30 10:52:34PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
09/30 10:52:34PM parser.py:31 [INFO] TRAIN_PORTION=0.5
09/30 10:52:34PM parser.py:31 [INFO] TYPE=ArchKD
09/30 10:52:34PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
09/30 10:52:34PM parser.py:31 [INFO] W_LR=0.025
09/30 10:52:34PM parser.py:31 [INFO] W_LR_MIN=0.001
09/30 10:52:34PM parser.py:31 [INFO] W_MOMENTUM=0.9
09/30 10:52:34PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
09/30 10:52:34PM parser.py:31 [INFO] WORKERS=4
09/30 10:52:34PM parser.py:32 [INFO] 
09/30 10:52:36PM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
09/30 10:52:36PM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
09/30 10:53:08PM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.1732 (4.5493)	Arch Loss 8.0421 (8.3100)	Arch Hard Loss 4.3227 (4.5365)	Arch Alpha Loss 37.1937 (37.7350)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 11.5%)	
09/30 10:53:38PM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2360 (4.3616)	Arch Loss 7.5790 (8.0563)	Arch Hard Loss 3.9745 (4.3387)	Arch Alpha Loss 36.0452 (37.1761)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.0%, 16.2%)	
09/30 10:54:07PM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9672 (4.2336)	Arch Loss 7.3305 (7.8780)	Arch Hard Loss 3.8437 (4.2178)	Arch Alpha Loss 34.8685 (36.6015)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.3%, 19.9%)	
09/30 10:54:33PM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.7144 (4.1549)	Arch Loss 7.1514 (7.7498)	Arch Hard Loss 3.7717 (4.1421)	Arch Alpha Loss 33.7971 (36.0766)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.3%, 22.0%)	
09/30 10:54:34PM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 6.2840%
09/30 10:54:39PM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9209	Prec@(1,5) (9.3%, 29.1%)
09/30 10:54:44PM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9264	Prec@(1,5) (9.2%, 29.1%)
09/30 10:54:48PM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9211	Prec@(1,5) (9.2%, 29.2%)
09/30 10:54:52PM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9168	Prec@(1,5) (9.2%, 29.2%)
09/30 10:54:53PM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 9.1440%
09/30 10:54:53PM searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
09/30 10:54:53PM searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 9.1440%
09/30 10:55:24午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.5092 (3.7740)	Arch Loss 7.1197 (7.0906)	Arch Hard Loss 3.8603 (3.7722)	Arch Alpha Loss 32.5942 (33.1838)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.8%, 33.5%)	
09/30 10:55:54午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.7918 (3.7269)	Arch Loss 6.6522 (6.9973)	Arch Hard Loss 3.5120 (3.7385)	Arch Alpha Loss 31.4025 (32.5871)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.2%, 35.0%)	
09/30 10:56:24午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7496 (3.7012)	Arch Loss 6.6538 (6.8972)	Arch Hard Loss 3.6306 (3.6977)	Arch Alpha Loss 30.2320 (31.9948)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.5%, 35.6%)	
09/30 10:56:49午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.2920 (3.6632)	Arch Loss 6.3236 (6.8201)	Arch Hard Loss 3.4034 (3.6733)	Arch Alpha Loss 29.2021 (31.4673)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.1%, 36.8%)	
09/30 10:56:50午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 13.0640%
09/30 10:56:55午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5643	Prec@(1,5) (14.5%, 39.3%)
09/30 10:56:59午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5685	Prec@(1,5) (14.4%, 39.5%)
09/30 10:57:03午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5639	Prec@(1,5) (14.6%, 39.5%)
09/30 10:57:07午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5625	Prec@(1,5) (14.7%, 39.8%)
09/30 10:57:07午後 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 14.6560%
09/30 10:57:07午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
09/30 10:57:07午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 14.6560%
09/30 10:57:39午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8695 (3.4712)	Arch Loss 6.5414 (6.3638)	Arch Hard Loss 3.7339 (3.5013)	Arch Alpha Loss 28.0754 (28.6253)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.5%, 41.6%)	
09/30 10:58:09午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.2000 (3.4387)	Arch Loss 6.2066 (6.2806)	Arch Hard Loss 3.5072 (3.4731)	Arch Alpha Loss 26.9938 (28.0751)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.0%, 43.0%)	
09/30 10:58:38午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.1021 (3.3972)	Arch Loss 5.7656 (6.1782)	Arch Hard Loss 3.1704 (3.4244)	Arch Alpha Loss 25.9522 (27.5379)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.6%, 44.3%)	
09/30 10:59:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.2251 (3.3702)	Arch Loss 5.7606 (6.0990)	Arch Hard Loss 3.2549 (3.3924)	Arch Alpha Loss 25.0576 (27.0668)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.0%, 45.2%)	
09/30 10:59:05午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 17.9840%
09/30 10:59:09午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2982	Prec@(1,5) (19.5%, 46.9%)
09/30 10:59:14午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3011	Prec@(1,5) (19.3%, 47.0%)
09/30 10:59:19午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3016	Prec@(1,5) (19.1%, 47.1%)
09/30 10:59:23午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3073	Prec@(1,5) (19.1%, 46.8%)
09/30 10:59:23午後 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 19.0640%
09/30 10:59:23午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
09/30 10:59:23午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 19.0640%
09/30 10:59:53午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 2.9758 (3.1844)	Arch Loss 5.5747 (5.6833)	Arch Hard Loss 3.1641 (3.2265)	Arch Alpha Loss 24.1057 (24.5683)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.5%, 49.9%)	
09/30 11:00:22午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.4608 (3.1674)	Arch Loss 5.4236 (5.6073)	Arch Hard Loss 3.1026 (3.1965)	Arch Alpha Loss 23.2100 (24.1085)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.8%, 50.6%)	
09/30 11:00:51午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1039 (3.1481)	Arch Loss 5.1011 (5.5407)	Arch Hard Loss 2.8645 (3.1741)	Arch Alpha Loss 22.3657 (23.6657)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.4%, 51.3%)	
09/30 11:01:17午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.2376 (3.1309)	Arch Loss 5.6983 (5.4881)	Arch Hard Loss 3.5337 (3.1600)	Arch Alpha Loss 21.6466 (23.2811)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.6%, 51.8%)	
09/30 11:01:18午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 21.5880%
09/30 11:01:22午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1777	Prec@(1,5) (21.6%, 51.3%)
09/30 11:01:27午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1817	Prec@(1,5) (21.6%, 51.5%)
09/30 11:01:31午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1896	Prec@(1,5) (21.7%, 51.2%)
09/30 11:01:35午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1900	Prec@(1,5) (21.7%, 51.2%)
09/30 11:01:35午後 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 21.7160%
09/30 11:01:35午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
09/30 11:01:36午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 21.7160%
09/30 11:02:05午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.7286 (2.9534)	Arch Loss 5.0127 (5.1733)	Arch Hard Loss 2.9233 (3.0474)	Arch Alpha Loss 20.8937 (21.2592)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 56.8%)	
09/30 11:02:34午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.5393 (2.9414)	Arch Loss 4.9174 (5.1063)	Arch Hard Loss 2.8975 (3.0164)	Arch Alpha Loss 20.1991 (20.8997)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 57.0%)	
09/30 11:03:03午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.0330 (2.9269)	Arch Loss 4.9248 (5.0572)	Arch Hard Loss 2.9696 (3.0016)	Arch Alpha Loss 19.5525 (20.5559)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.4%, 57.5%)	
09/30 11:03:29午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8110 (2.9161)	Arch Loss 4.9659 (5.0026)	Arch Hard Loss 3.0650 (2.9766)	Arch Alpha Loss 19.0097 (20.2607)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 57.7%)	
09/30 11:03:29午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 25.6760%
09/30 11:03:34午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.9837	Prec@(1,5) (24.8%, 56.3%)
09/30 11:03:38午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9856	Prec@(1,5) (25.2%, 56.6%)
09/30 11:03:42午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9987	Prec@(1,5) (25.2%, 56.3%)
09/30 11:03:46午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0020	Prec@(1,5) (25.1%, 56.4%)
09/30 11:03:46午後 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 25.1560%
09/30 11:03:46午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
09/30 11:03:47午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 25.1560%
09/30 11:04:18午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.7354 (2.7692)	Arch Loss 4.7253 (4.7558)	Arch Hard Loss 2.8805 (2.8839)	Arch Alpha Loss 18.4482 (18.7194)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.4%, 61.3%)	
09/30 11:04:48午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0428 (2.7553)	Arch Loss 4.4441 (4.6919)	Arch Hard Loss 2.6511 (2.8468)	Arch Alpha Loss 17.9294 (18.4512)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 61.4%)	
09/30 11:05:18午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.5101 (2.7568)	Arch Loss 4.4624 (4.6517)	Arch Hard Loss 2.7171 (2.8321)	Arch Alpha Loss 17.4528 (18.1959)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.4%, 61.4%)	
09/30 11:05:45午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.5869 (2.7396)	Arch Loss 4.1830 (4.6114)	Arch Hard Loss 2.4778 (2.8137)	Arch Alpha Loss 17.0518 (17.9768)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.5%, 61.9%)	
09/30 11:05:45午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 29.5120%
09/30 11:05:50午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8626	Prec@(1,5) (27.7%, 58.8%)
09/30 11:05:55午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8674	Prec@(1,5) (27.3%, 59.6%)
09/30 11:05:59午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8549	Prec@(1,5) (27.3%, 59.6%)
09/30 11:06:03午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8650	Prec@(1,5) (27.3%, 59.2%)
09/30 11:06:03午後 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 27.3120%
09/30 11:06:03午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
09/30 11:06:03午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 27.3120%
09/30 11:06:35午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8052 (2.6032)	Arch Loss 4.4564 (4.4249)	Arch Hard Loss 2.7923 (2.7410)	Arch Alpha Loss 16.6414 (16.8394)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.2%, 65.0%)	
09/30 11:07:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.4844 (2.6083)	Arch Loss 4.2627 (4.4086)	Arch Hard Loss 2.6362 (2.7442)	Arch Alpha Loss 16.2645 (16.6438)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 65.2%)	
09/30 11:07:33午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.7265 (2.5986)	Arch Loss 4.2204 (4.3616)	Arch Hard Loss 2.6283 (2.7157)	Arch Alpha Loss 15.9215 (16.4586)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.1%)	
09/30 11:08:00午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8082 (2.5934)	Arch Loss 4.1060 (4.3350)	Arch Hard Loss 2.5423 (2.7049)	Arch Alpha Loss 15.6376 (16.3011)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.1%)	
09/30 11:08:01午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 32.8680%
09/30 11:08:05午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6903	Prec@(1,5) (31.7%, 63.4%)
09/30 11:08:10午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6845	Prec@(1,5) (31.7%, 63.4%)
09/30 11:08:14午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6792	Prec@(1,5) (31.8%, 63.7%)
09/30 11:08:18午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6772	Prec@(1,5) (31.8%, 63.7%)
09/30 11:08:19午後 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 31.8240%
09/30 11:08:19午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:08:19午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 31.8240%
09/30 11:08:50午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.6977 (2.4541)	Arch Loss 3.9492 (4.1546)	Arch Hard Loss 2.4148 (2.6061)	Arch Alpha Loss 15.3441 (15.4843)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 68.6%)	
09/30 11:09:21午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.3495 (2.4497)	Arch Loss 3.6866 (4.1401)	Arch Hard Loss 2.1789 (2.6054)	Arch Alpha Loss 15.0777 (15.3461)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 68.7%)	
09/30 11:09:51午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.6285 (2.4541)	Arch Loss 4.3072 (4.1255)	Arch Hard Loss 2.8241 (2.6040)	Arch Alpha Loss 14.8308 (15.2148)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.6%)	
09/30 11:10:19午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.1000 (2.4488)	Arch Loss 3.8683 (4.0818)	Arch Hard Loss 2.4062 (2.5717)	Arch Alpha Loss 14.6209 (15.1014)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.6%)	
09/30 11:10:19午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 35.5200%
09/30 11:10:24午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5813	Prec@(1,5) (32.9%, 66.2%)
09/30 11:10:28午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5688	Prec@(1,5) (33.4%, 66.4%)
09/30 11:10:32午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5527	Prec@(1,5) (33.7%, 66.5%)
09/30 11:10:36午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5538	Prec@(1,5) (33.8%, 66.3%)
09/30 11:10:36午後 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 33.8240%
09/30 11:10:36午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:10:37午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 33.8240%
09/30 11:11:07午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 1.9037 (2.3348)	Arch Loss 3.7478 (3.9626)	Arch Hard Loss 2.3066 (2.5111)	Arch Alpha Loss 14.4125 (14.5150)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 71.0%)	
09/30 11:11:36午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.2616 (2.3432)	Arch Loss 4.0208 (3.9511)	Arch Hard Loss 2.5981 (2.5094)	Arch Alpha Loss 14.2266 (14.4165)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 70.7%)	
09/30 11:12:05午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2858 (2.3386)	Arch Loss 3.9257 (3.9254)	Arch Hard Loss 2.5202 (2.4929)	Arch Alpha Loss 14.0546 (14.3243)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.7%)	
09/30 11:12:31午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.3232 (2.3378)	Arch Loss 3.6688 (3.9034)	Arch Hard Loss 2.2780 (2.4789)	Arch Alpha Loss 13.9083 (14.2448)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 70.5%)	
09/30 11:12:31午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 37.7320%
09/30 11:12:36午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.3756	Prec@(1,5) (38.1%, 70.0%)
09/30 11:12:40午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.3873	Prec@(1,5) (37.8%, 69.8%)
09/30 11:12:45午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.3942	Prec@(1,5) (37.6%, 69.8%)
09/30 11:12:49午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.3998	Prec@(1,5) (37.4%, 69.7%)
09/30 11:12:49午後 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 37.3800%
09/30 11:12:49午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:12:49午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 37.3800%
09/30 11:13:20午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.7384 (2.1982)	Arch Loss 4.4822 (3.8302)	Arch Hard Loss 3.1061 (2.4470)	Arch Alpha Loss 13.7605 (13.8311)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 73.5%)	
09/30 11:13:49午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.1190 (2.2143)	Arch Loss 3.8796 (3.7947)	Arch Hard Loss 2.5168 (2.4186)	Arch Alpha Loss 13.6277 (13.7615)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.3%)	
09/30 11:14:19午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.0429 (2.2296)	Arch Loss 3.5452 (3.7647)	Arch Hard Loss 2.1943 (2.3950)	Arch Alpha Loss 13.5092 (13.6969)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.6%, 73.1%)	
09/30 11:14:46午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.0163 (2.2293)	Arch Loss 3.8779 (3.7456)	Arch Hard Loss 2.5369 (2.3814)	Arch Alpha Loss 13.4098 (13.6420)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 73.2%)	
09/30 11:14:46午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 40.4080%
09/30 11:14:51午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.3799	Prec@(1,5) (38.5%, 70.1%)
09/30 11:14:55午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3468	Prec@(1,5) (38.4%, 70.8%)
09/30 11:14:59午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3461	Prec@(1,5) (38.5%, 70.7%)
09/30 11:15:03午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3419	Prec@(1,5) (38.6%, 70.7%)
09/30 11:15:03午後 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 38.5800%
09/30 11:15:03午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:15:04午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 38.5800%
09/30 11:15:35午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.2771 (2.0844)	Arch Loss 3.5263 (3.7023)	Arch Hard Loss 2.1956 (2.3667)	Arch Alpha Loss 13.3075 (13.3551)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.9%)	
09/30 11:16:05午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.0153 (2.1064)	Arch Loss 3.8135 (3.6717)	Arch Hard Loss 2.4917 (2.3409)	Arch Alpha Loss 13.2172 (13.3082)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 75.6%)	
09/30 11:16:36午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.8859 (2.1081)	Arch Loss 3.5430 (3.6471)	Arch Hard Loss 2.2296 (2.3207)	Arch Alpha Loss 13.1344 (13.2635)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 75.4%)	
09/30 11:17:03午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1364 (2.1264)	Arch Loss 3.6003 (3.6270)	Arch Hard Loss 2.2936 (2.3044)	Arch Alpha Loss 13.0669 (13.2256)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 75.0%)	
09/30 11:17:03午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 42.3000%
09/30 11:17:08午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3433	Prec@(1,5) (39.0%, 71.0%)
09/30 11:17:13午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3459	Prec@(1,5) (38.4%, 70.7%)
09/30 11:17:17午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3204	Prec@(1,5) (38.7%, 71.3%)
09/30 11:17:21午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3218	Prec@(1,5) (38.9%, 71.3%)
09/30 11:17:21午後 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 38.8640%
09/30 11:17:21午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:17:22午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 38.8640%
09/30 11:17:53午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.0945 (2.0055)	Arch Loss 3.3037 (3.5930)	Arch Hard Loss 2.0036 (2.2898)	Arch Alpha Loss 13.0014 (13.0321)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 77.9%)	
09/30 11:18:24午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4096 (2.0182)	Arch Loss 3.5824 (3.5435)	Arch Hard Loss 2.2885 (2.2434)	Arch Alpha Loss 12.9392 (13.0007)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.6%)	
09/30 11:18:54午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.5181 (2.0350)	Arch Loss 3.6793 (3.5398)	Arch Hard Loss 2.3911 (2.2427)	Arch Alpha Loss 12.8824 (12.9706)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.2%)	
09/30 11:19:22午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.7372 (2.0319)	Arch Loss 3.6525 (3.5312)	Arch Hard Loss 2.3690 (2.2367)	Arch Alpha Loss 12.8350 (12.9448)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.3%)	
09/30 11:19:22午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 44.6440%
09/30 11:19:27午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.2468	Prec@(1,5) (40.8%, 73.1%)
09/30 11:19:32午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2443	Prec@(1,5) (40.5%, 72.9%)
09/30 11:19:36午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2454	Prec@(1,5) (40.6%, 73.0%)
09/30 11:19:40午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2330	Prec@(1,5) (40.8%, 73.3%)
09/30 11:19:40午後 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 40.7840%
09/30 11:19:40午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:19:41午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 40.7840%
09/30 11:20:12午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.6557 (1.9280)	Arch Loss 3.5321 (3.5116)	Arch Hard Loss 2.2528 (2.2305)	Arch Alpha Loss 12.7925 (12.8118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 79.1%)	
09/30 11:20:41午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.9780 (1.9443)	Arch Loss 4.0278 (3.5036)	Arch Hard Loss 2.7527 (2.2245)	Arch Alpha Loss 12.7507 (12.7910)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 78.6%)	
09/30 11:21:11午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.3202 (1.9547)	Arch Loss 3.1177 (3.4737)	Arch Hard Loss 1.8462 (2.1966)	Arch Alpha Loss 12.7144 (12.7713)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.5%, 78.4%)	
09/30 11:21:38午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.8108 (1.9560)	Arch Loss 3.3272 (3.4628)	Arch Hard Loss 2.0590 (2.1874)	Arch Alpha Loss 12.6824 (12.7543)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.5%, 78.3%)	
09/30 11:21:38午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 46.4960%
09/30 11:21:43午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.1334	Prec@(1,5) (43.6%, 75.2%)
09/30 11:21:47午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1160	Prec@(1,5) (43.8%, 75.6%)
09/30 11:21:51午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1257	Prec@(1,5) (43.6%, 75.3%)
09/30 11:21:55午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1265	Prec@(1,5) (43.7%, 75.4%)
09/30 11:21:55午後 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 43.6560%
09/30 11:21:55午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:21:56午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.6560%
09/30 11:22:27午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.8309 (1.8102)	Arch Loss 3.6175 (3.4176)	Arch Hard Loss 2.3517 (2.1506)	Arch Alpha Loss 12.6586 (12.6703)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 81.2%)	
09/30 11:22:58午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.7247 (1.8433)	Arch Loss 3.3429 (3.4354)	Arch Hard Loss 2.0796 (2.1696)	Arch Alpha Loss 12.6327 (12.6578)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.5%)	
09/30 11:23:28午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.0538 (1.8581)	Arch Loss 2.8847 (3.4236)	Arch Hard Loss 1.6239 (2.1591)	Arch Alpha Loss 12.6077 (12.6451)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.2%)	
09/30 11:23:56午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0147 (1.8700)	Arch Loss 3.2342 (3.4124)	Arch Hard Loss 1.9755 (2.1490)	Arch Alpha Loss 12.5868 (12.6342)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 80.1%)	
09/30 11:23:56午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 47.9840%
09/30 11:24:01午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1744	Prec@(1,5) (43.0%, 74.2%)
09/30 11:24:05午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2092	Prec@(1,5) (42.4%, 73.7%)
09/30 11:24:10午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2002	Prec@(1,5) (42.4%, 73.9%)
09/30 11:24:14午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1994	Prec@(1,5) (42.4%, 74.1%)
09/30 11:24:14午後 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 42.3640%
09/30 11:24:14午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:24:14午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 43.6560%
09/30 11:24:46午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.9421 (1.7833)	Arch Loss 3.1982 (3.3763)	Arch Hard Loss 1.9414 (2.1187)	Arch Alpha Loss 12.5682 (12.5762)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.6%)	
09/30 11:25:17午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.9054 (1.7835)	Arch Loss 3.2309 (3.3747)	Arch Hard Loss 1.9756 (2.1178)	Arch Alpha Loss 12.5537 (12.5692)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.4%)	
09/30 11:25:47午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.6017 (1.7916)	Arch Loss 3.5397 (3.3518)	Arch Hard Loss 2.2862 (2.0957)	Arch Alpha Loss 12.5350 (12.5609)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.4%)	
09/30 11:26:14午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.1527 (1.8031)	Arch Loss 3.0680 (3.3573)	Arch Hard Loss 1.8160 (2.1020)	Arch Alpha Loss 12.5196 (12.5531)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.3%)	
09/30 11:26:15午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 50.0720%
09/30 11:26:19午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.0507	Prec@(1,5) (45.6%, 76.8%)
09/30 11:26:24午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.0284	Prec@(1,5) (45.7%, 77.2%)
09/30 11:26:28午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0285	Prec@(1,5) (45.5%, 77.2%)
09/30 11:26:32午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0330	Prec@(1,5) (45.6%, 77.1%)
09/30 11:26:33午後 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 45.5920%
09/30 11:26:33午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:26:33午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 45.5920%
09/30 11:27:05午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.4404 (1.7015)	Arch Loss 2.9802 (3.2932)	Arch Hard Loss 1.7295 (2.0419)	Arch Alpha Loss 12.5077 (12.5127)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.7%, 82.6%)	
09/30 11:27:35午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.5372 (1.7051)	Arch Loss 3.2555 (3.2980)	Arch Hard Loss 2.0060 (2.0473)	Arch Alpha Loss 12.4947 (12.5071)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.8%)	
09/30 11:28:05午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.6585 (1.7150)	Arch Loss 3.1762 (3.2941)	Arch Hard Loss 1.9281 (2.0441)	Arch Alpha Loss 12.4815 (12.5006)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.0%, 82.7%)	
09/30 11:28:33午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.9646 (1.7335)	Arch Loss 3.5965 (3.3027)	Arch Hard Loss 2.3492 (2.0532)	Arch Alpha Loss 12.4724 (12.4949)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.4%, 82.5%)	
09/30 11:28:33午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 51.4160%
09/30 11:28:38午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0183	Prec@(1,5) (47.1%, 78.1%)
09/30 11:28:42午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0383	Prec@(1,5) (46.4%, 77.6%)
09/30 11:28:47午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0519	Prec@(1,5) (45.9%, 77.3%)
09/30 11:28:51午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0505	Prec@(1,5) (45.7%, 77.3%)
09/30 11:28:51午後 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 45.6800%
09/30 11:28:51午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:28:51午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 45.6800%
09/30 11:29:23午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.8333 (1.6414)	Arch Loss 3.3847 (3.2532)	Arch Hard Loss 2.1381 (2.0064)	Arch Alpha Loss 12.4657 (12.4682)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.0%)	
09/30 11:29:53午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9368 (1.6477)	Arch Loss 2.9994 (3.2684)	Arch Hard Loss 1.7539 (2.0219)	Arch Alpha Loss 12.4555 (12.4644)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.5%, 84.0%)	
09/30 11:30:23午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9066 (1.6594)	Arch Loss 2.7608 (3.2704)	Arch Hard Loss 1.5160 (2.0244)	Arch Alpha Loss 12.4479 (12.4604)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.3%, 83.7%)	
09/30 11:30:50午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.5952 (1.6658)	Arch Loss 3.9231 (3.2681)	Arch Hard Loss 2.6790 (2.0224)	Arch Alpha Loss 12.4413 (12.4568)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.7%)	
09/30 11:30:50午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 53.2360%
09/30 11:30:55午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 1.9964	Prec@(1,5) (47.0%, 78.5%)
09/30 11:30:59午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0132	Prec@(1,5) (46.5%, 78.2%)
09/30 11:31:04午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0126	Prec@(1,5) (46.3%, 78.4%)
09/30 11:31:08午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0169	Prec@(1,5) (46.3%, 78.2%)
09/30 11:31:08午後 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 46.2600%
09/30 11:31:08午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:31:08午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.2600%
09/30 11:31:39午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.6507 (1.5565)	Arch Loss 3.7188 (3.2423)	Arch Hard Loss 2.4750 (1.9983)	Arch Alpha Loss 12.4376 (12.4395)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.8%)	
09/30 11:32:09午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.2299 (1.5845)	Arch Loss 3.0239 (3.2589)	Arch Hard Loss 1.7809 (2.0153)	Arch Alpha Loss 12.4306 (12.4364)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.2%)	
09/30 11:32:38午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.7752 (1.6008)	Arch Loss 3.3311 (3.2489)	Arch Hard Loss 2.0890 (2.0056)	Arch Alpha Loss 12.4215 (12.4329)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.9%)	
09/30 11:33:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.6802 (1.6099)	Arch Loss 2.7817 (3.2434)	Arch Hard Loss 1.5397 (2.0004)	Arch Alpha Loss 12.4201 (12.4302)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.7%)	
09/30 11:33:05午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 54.6120%
09/30 11:33:10午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 1.9925	Prec@(1,5) (46.6%, 78.1%)
09/30 11:33:14午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9841	Prec@(1,5) (46.7%, 78.0%)
09/30 11:33:19午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9860	Prec@(1,5) (46.8%, 78.1%)
09/30 11:33:23午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9875	Prec@(1,5) (47.0%, 78.1%)
09/30 11:33:23午後 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 46.9840%
09/30 11:33:23午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:33:23午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 46.9840%
09/30 11:33:55午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.8055 (1.4639)	Arch Loss 3.1213 (3.2179)	Arch Hard Loss 1.8794 (1.9760)	Arch Alpha Loss 12.4182 (12.4188)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.1%)	
09/30 11:34:24午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.6402 (1.5076)	Arch Loss 3.2132 (3.2379)	Arch Hard Loss 1.9720 (1.9962)	Arch Alpha Loss 12.4123 (12.4178)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.3%)	
09/30 11:34:53午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.5830 (1.5227)	Arch Loss 3.4089 (3.2308)	Arch Hard Loss 2.1678 (1.9893)	Arch Alpha Loss 12.4100 (12.4154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.2%)	
09/30 11:35:19午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.5137 (1.5441)	Arch Loss 2.9347 (3.2240)	Arch Hard Loss 1.6942 (1.9827)	Arch Alpha Loss 12.4050 (12.4133)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.8%)	
09/30 11:35:19午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 56.0280%
09/30 11:35:24午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9281	Prec@(1,5) (49.3%, 79.0%)
09/30 11:35:28午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9276	Prec@(1,5) (48.7%, 79.3%)
09/30 11:35:33午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9330	Prec@(1,5) (48.4%, 79.3%)
09/30 11:35:36午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9289	Prec@(1,5) (48.6%, 79.4%)
09/30 11:35:37午後 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 48.5800%
09/30 11:35:37午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:35:37午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 48.5800%
09/30 11:36:07午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.5942 (1.4335)	Arch Loss 3.1912 (3.1646)	Arch Hard Loss 1.9509 (1.9243)	Arch Alpha Loss 12.4033 (12.4030)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.5%)	
09/30 11:36:35午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6511 (1.4440)	Arch Loss 3.1626 (3.1838)	Arch Hard Loss 1.9228 (1.9437)	Arch Alpha Loss 12.3980 (12.4017)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.3%)	
09/30 11:37:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.3256 (1.4663)	Arch Loss 2.8880 (3.1985)	Arch Hard Loss 1.6487 (1.9586)	Arch Alpha Loss 12.3932 (12.3990)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 86.9%)	
09/30 11:37:29午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.1669 (1.4843)	Arch Loss 3.5828 (3.1937)	Arch Hard Loss 2.3435 (1.9540)	Arch Alpha Loss 12.3932 (12.3976)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.8%)	
09/30 11:37:30午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 57.7720%
09/30 11:37:35午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9325	Prec@(1,5) (49.3%, 79.8%)
09/30 11:37:39午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9400	Prec@(1,5) (49.2%, 79.4%)
09/30 11:37:43午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9434	Prec@(1,5) (49.1%, 79.4%)
09/30 11:37:47午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9464	Prec@(1,5) (49.2%, 79.3%)
09/30 11:37:47午後 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 49.1600%
09/30 11:37:47午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:37:47午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.1600%
09/30 11:38:18午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.2711 (1.3519)	Arch Loss 3.4137 (3.2073)	Arch Hard Loss 2.1747 (1.9680)	Arch Alpha Loss 12.3901 (12.3929)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.0%)	
09/30 11:38:48午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5728 (1.4015)	Arch Loss 3.6740 (3.1906)	Arch Hard Loss 2.4354 (1.9516)	Arch Alpha Loss 12.3859 (12.3905)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.7%)	
09/30 11:39:18午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.5808 (1.4153)	Arch Loss 3.3787 (3.1800)	Arch Hard Loss 2.1402 (1.9411)	Arch Alpha Loss 12.3849 (12.3891)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.7%)	
09/30 11:39:45午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4691 (1.4243)	Arch Loss 3.0359 (3.1740)	Arch Hard Loss 1.7976 (1.9352)	Arch Alpha Loss 12.3836 (12.3881)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.6%)	
09/30 11:39:45午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 59.3640%
09/30 11:39:50午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9622	Prec@(1,5) (48.3%, 79.0%)
09/30 11:39:54午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9638	Prec@(1,5) (48.0%, 79.2%)
09/30 11:39:58午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9627	Prec@(1,5) (48.5%, 79.2%)
09/30 11:40:02午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9580	Prec@(1,5) (48.4%, 79.2%)
09/30 11:40:02午後 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 48.4560%
09/30 11:40:02午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:40:03午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.1600%
09/30 11:40:34午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5947 (1.3331)	Arch Loss 2.7103 (3.1595)	Arch Hard Loss 1.4720 (1.9213)	Arch Alpha Loss 12.3830 (12.3819)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.6%)	
09/30 11:41:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3015 (1.3629)	Arch Loss 2.9678 (3.1698)	Arch Hard Loss 1.7295 (1.9315)	Arch Alpha Loss 12.3830 (12.3826)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.4%)	
09/30 11:41:34午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.1863 (1.3682)	Arch Loss 3.5600 (3.1496)	Arch Hard Loss 2.3218 (1.9114)	Arch Alpha Loss 12.3820 (12.3824)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.1%)	
09/30 11:42:00午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.2994 (1.3867)	Arch Loss 3.0988 (3.1468)	Arch Hard Loss 1.8602 (1.9085)	Arch Alpha Loss 12.3862 (12.3831)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 87.9%)	
09/30 11:42:01午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 59.7920%
09/30 11:42:06午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9480	Prec@(1,5) (49.1%, 79.7%)
09/30 11:42:10午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9220	Prec@(1,5) (49.5%, 80.2%)
09/30 11:42:14午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9067	Prec@(1,5) (49.5%, 80.3%)
09/30 11:42:18午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9100	Prec@(1,5) (49.5%, 80.3%)
09/30 11:42:18午後 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 49.4640%
09/30 11:42:18午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:42:19午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.4640%
09/30 11:42:50午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3568 (1.2622)	Arch Loss 3.5770 (3.1217)	Arch Hard Loss 2.3385 (1.8833)	Arch Alpha Loss 12.3845 (12.3840)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.2%)	
09/30 11:43:20午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.5340 (1.3039)	Arch Loss 3.1231 (3.1535)	Arch Hard Loss 1.8847 (1.9150)	Arch Alpha Loss 12.3843 (12.3848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.5%)	
09/30 11:43:51午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.2730 (1.3180)	Arch Loss 3.0380 (3.1471)	Arch Hard Loss 1.7995 (1.9087)	Arch Alpha Loss 12.3848 (12.3848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.2%)	
09/30 11:44:18午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 0.9340 (1.3294)	Arch Loss 2.9052 (3.1470)	Arch Hard Loss 1.6665 (1.9085)	Arch Alpha Loss 12.3873 (12.3849)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.1%)	
09/30 11:44:18午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 61.2840%
09/30 11:44:23午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9725	Prec@(1,5) (49.6%, 78.5%)
09/30 11:44:27午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9615	Prec@(1,5) (49.6%, 79.1%)
09/30 11:44:31午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9392	Prec@(1,5) (49.8%, 79.5%)
09/30 11:44:35午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9399	Prec@(1,5) (49.8%, 79.5%)
09/30 11:44:35午後 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 49.7520%
09/30 11:44:35午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:44:36午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.7520%
09/30 11:45:06午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.1264 (1.1752)	Arch Loss 2.8953 (3.1057)	Arch Hard Loss 1.6565 (1.8669)	Arch Alpha Loss 12.3877 (12.3871)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.5%)	
09/30 11:45:35午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.0775 (1.2182)	Arch Loss 3.3831 (3.1090)	Arch Hard Loss 2.1441 (1.8703)	Arch Alpha Loss 12.3903 (12.3874)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.4%, 91.1%)	
09/30 11:46:03午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.0915 (1.2432)	Arch Loss 3.2862 (3.1257)	Arch Hard Loss 2.0471 (1.8868)	Arch Alpha Loss 12.3913 (12.3885)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.6%)	
09/30 11:46:30午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3410 (1.2633)	Arch Loss 3.3788 (3.1243)	Arch Hard Loss 2.1401 (1.8855)	Arch Alpha Loss 12.3869 (12.3889)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.3%)	
09/30 11:46:30午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 62.9520%
09/30 11:46:35午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9305	Prec@(1,5) (49.8%, 80.2%)
09/30 11:46:40午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9464	Prec@(1,5) (49.4%, 79.7%)
09/30 11:46:44午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9577	Prec@(1,5) (49.3%, 79.6%)
09/30 11:46:48午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9462	Prec@(1,5) (49.6%, 79.9%)
09/30 11:46:48午後 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 49.5760%
09/30 11:46:48午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:46:49午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 49.7520%
09/30 11:47:20午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.2243 (1.1534)	Arch Loss 3.2446 (3.0947)	Arch Hard Loss 2.0057 (1.8559)	Arch Alpha Loss 12.3889 (12.3873)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.7%)	
09/30 11:47:50午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2848 (1.1703)	Arch Loss 3.6953 (3.1199)	Arch Hard Loss 2.4563 (1.8811)	Arch Alpha Loss 12.3893 (12.3872)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.6%)	
09/30 11:48:20午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.0763 (1.1973)	Arch Loss 3.5330 (3.1216)	Arch Hard Loss 2.2938 (1.8828)	Arch Alpha Loss 12.3919 (12.3883)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 91.1%)	
09/30 11:48:47午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.3192 (1.2162)	Arch Loss 3.3323 (3.1165)	Arch Hard Loss 2.0933 (1.8776)	Arch Alpha Loss 12.3904 (12.3890)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.8%)	
09/30 11:48:48午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 64.3080%
09/30 11:48:53午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8754	Prec@(1,5) (51.4%, 80.5%)
09/30 11:48:57午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8720	Prec@(1,5) (51.2%, 81.0%)
09/30 11:49:02午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8745	Prec@(1,5) (50.9%, 80.8%)
09/30 11:49:06午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8747	Prec@(1,5) (50.9%, 80.9%)
09/30 11:49:06午後 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 50.8600%
09/30 11:49:06午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:49:07午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.8600%
09/30 11:49:37午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3425 (1.1256)	Arch Loss 3.1573 (3.0535)	Arch Hard Loss 1.9184 (1.8146)	Arch Alpha Loss 12.3893 (12.3881)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.9%)	
09/30 11:50:08午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.2690 (1.1294)	Arch Loss 2.9078 (3.0887)	Arch Hard Loss 1.6686 (1.8497)	Arch Alpha Loss 12.3921 (12.3899)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 92.0%)	
09/30 11:50:38午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.0832 (1.1465)	Arch Loss 3.4119 (3.1038)	Arch Hard Loss 2.1725 (1.8646)	Arch Alpha Loss 12.3944 (12.3914)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.8%)	
09/30 11:51:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.3701 (1.1587)	Arch Loss 2.7771 (3.1160)	Arch Hard Loss 1.5369 (1.8767)	Arch Alpha Loss 12.4021 (12.3928)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.6%)	
09/30 11:51:05午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 65.3160%
09/30 11:51:10午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8946	Prec@(1,5) (51.9%, 80.8%)
09/30 11:51:14午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9044	Prec@(1,5) (51.4%, 80.6%)
09/30 11:51:18午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9207	Prec@(1,5) (50.9%, 80.4%)
09/30 11:51:22午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9254	Prec@(1,5) (50.7%, 80.4%)
09/30 11:51:22午後 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 50.6520%
09/30 11:51:22午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:51:22午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 50.8600%
09/30 11:51:52午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.7828 (1.0364)	Arch Loss 3.3039 (3.1452)	Arch Hard Loss 2.0640 (1.9053)	Arch Alpha Loss 12.3990 (12.3984)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 93.2%)	
09/30 11:52:21午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.5437 (1.0770)	Arch Loss 3.2669 (3.1296)	Arch Hard Loss 2.0268 (1.8895)	Arch Alpha Loss 12.4011 (12.4001)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.6%)	
09/30 11:52:50午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.0687 (1.1102)	Arch Loss 2.7830 (3.1290)	Arch Hard Loss 1.5424 (1.8889)	Arch Alpha Loss 12.4061 (12.4011)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 92.2%)	
09/30 11:53:16午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.1180 (1.1220)	Arch Loss 3.2457 (3.1226)	Arch Hard Loss 2.0050 (1.8824)	Arch Alpha Loss 12.4072 (12.4024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 92.0%)	
09/30 11:53:16午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 66.8800%
09/30 11:53:21午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8408	Prec@(1,5) (52.6%, 81.6%)
09/30 11:53:25午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8440	Prec@(1,5) (52.6%, 81.6%)
09/30 11:53:30午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8490	Prec@(1,5) (52.5%, 81.7%)
09/30 11:53:34午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8573	Prec@(1,5) (52.3%, 81.6%)
09/30 11:53:34午後 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 52.2440%
09/30 11:53:34午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:53:34午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.2440%
09/30 11:54:04午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0419 (1.0038)	Arch Loss 3.3321 (3.0961)	Arch Hard Loss 2.0912 (1.8553)	Arch Alpha Loss 12.4090 (12.4086)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.8%)	
09/30 11:54:33午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.3194 (1.0174)	Arch Loss 3.0302 (3.0853)	Arch Hard Loss 1.7893 (1.8444)	Arch Alpha Loss 12.4096 (12.4086)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.4%)	
09/30 11:55:02午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 0.9802 (1.0490)	Arch Loss 3.0717 (3.1127)	Arch Hard Loss 1.8302 (1.8716)	Arch Alpha Loss 12.4150 (12.4104)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.1%)	
09/30 11:55:27午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.0493 (1.0595)	Arch Loss 2.9790 (3.0999)	Arch Hard Loss 1.7378 (1.8588)	Arch Alpha Loss 12.4127 (12.4112)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.9%)	
09/30 11:55:28午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 68.4640%
09/30 11:55:33午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8162	Prec@(1,5) (52.5%, 81.5%)
09/30 11:55:37午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8228	Prec@(1,5) (53.0%, 81.6%)
09/30 11:55:41午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8257	Prec@(1,5) (53.0%, 81.6%)
09/30 11:55:45午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8170	Prec@(1,5) (52.9%, 81.8%)
09/30 11:55:45午後 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 52.9160%
09/30 11:55:45午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:55:46午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 52.9160%
09/30 11:56:17午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.0596 (0.9494)	Arch Loss 3.0117 (3.0687)	Arch Hard Loss 1.7703 (1.8273)	Arch Alpha Loss 12.4143 (12.4140)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.2%)	
09/30 11:56:47午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 0.9712 (0.9812)	Arch Loss 3.3530 (3.0610)	Arch Hard Loss 2.1116 (1.8195)	Arch Alpha Loss 12.4138 (12.4145)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
09/30 11:57:16午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.1267 (0.9945)	Arch Loss 2.6790 (3.1067)	Arch Hard Loss 1.4369 (1.8651)	Arch Alpha Loss 12.4208 (12.4156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.6%)	
09/30 11:57:42午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.2433 (1.0060)	Arch Loss 3.2892 (3.1053)	Arch Hard Loss 2.0470 (1.8636)	Arch Alpha Loss 12.4213 (12.4168)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.5%)	
09/30 11:57:42午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 70.0000%
09/30 11:57:47午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8310	Prec@(1,5) (54.1%, 82.2%)
09/30 11:57:51午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8587	Prec@(1,5) (53.0%, 81.8%)
09/30 11:57:55午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8515	Prec@(1,5) (53.2%, 81.8%)
09/30 11:57:59午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8535	Prec@(1,5) (53.1%, 81.8%)
09/30 11:57:59午後 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 53.0760%
09/30 11:57:59午後 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
09/30 11:57:59午後 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.0760%
09/30 11:58:29午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.7024 (0.9139)	Arch Loss 3.3232 (3.1144)	Arch Hard Loss 2.0812 (1.8723)	Arch Alpha Loss 12.4205 (12.4214)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.7%)	
09/30 11:58:58午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.1122 (0.9329)	Arch Loss 2.9386 (3.1136)	Arch Hard Loss 1.6959 (1.8714)	Arch Alpha Loss 12.4267 (12.4222)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.5%)	
09/30 11:59:27午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 0.9083 (0.9544)	Arch Loss 3.8154 (3.1268)	Arch Hard Loss 2.5720 (1.8843)	Arch Alpha Loss 12.4333 (12.4250)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.0%, 94.2%)	
09/30 11:59:52午後 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9909 (0.9625)	Arch Loss 3.3305 (3.1278)	Arch Hard Loss 2.0867 (1.8850)	Arch Alpha Loss 12.4377 (12.4277)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 94.2%)	
09/30 11:59:53午後 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 70.6680%
09/30 11:59:58午後 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8120	Prec@(1,5) (54.2%, 82.9%)
10/01 12:00:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8341	Prec@(1,5) (53.6%, 82.5%)
10/01 12:00:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8467	Prec@(1,5) (53.3%, 82.2%)
10/01 12:00:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8400	Prec@(1,5) (53.4%, 82.4%)
10/01 12:00:11午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 53.4080%
10/01 12:00:11午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:00:11午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.4080%
10/01 12:00:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.6106 (0.8618)	Arch Loss 3.1076 (3.1368)	Arch Hard Loss 1.8635 (1.8930)	Arch Alpha Loss 12.4412 (12.4383)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.4%, 95.1%)	
10/01 12:01:14午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9830 (0.8939)	Arch Loss 3.0806 (3.1208)	Arch Hard Loss 1.8362 (1.8768)	Arch Alpha Loss 12.4438 (12.4399)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.7%)	
10/01 12:01:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1425 (0.9000)	Arch Loss 3.1000 (3.1144)	Arch Hard Loss 1.8551 (1.8702)	Arch Alpha Loss 12.4493 (12.4419)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.5%)	
10/01 12:02:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2729 (0.9123)	Arch Loss 3.0030 (3.1218)	Arch Hard Loss 1.7576 (1.8774)	Arch Alpha Loss 12.4540 (12.4441)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.4%)	
10/01 12:02:12午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 72.3600%
10/01 12:02:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8479	Prec@(1,5) (53.4%, 81.9%)
10/01 12:02:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8655	Prec@(1,5) (53.2%, 81.8%)
10/01 12:02:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8777	Prec@(1,5) (52.9%, 81.7%)
10/01 12:02:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8598	Prec@(1,5) (53.3%, 81.9%)
10/01 12:02:30午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 53.3040%
10/01 12:02:30午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:02:30午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.4080%
10/01 12:03:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.6782 (0.7977)	Arch Loss 3.4247 (3.1185)	Arch Hard Loss 2.1798 (1.8733)	Arch Alpha Loss 12.4493 (12.4514)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.7%)	
10/01 12:03:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.8093 (0.8097)	Arch Loss 3.2708 (3.1055)	Arch Hard Loss 2.0249 (1.8602)	Arch Alpha Loss 12.4588 (12.4532)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.6%)	
10/01 12:03:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0326 (0.8334)	Arch Loss 3.4900 (3.1227)	Arch Hard Loss 2.2436 (1.8771)	Arch Alpha Loss 12.4637 (12.4561)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.4%)	
10/01 12:04:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.8116 (0.8500)	Arch Loss 3.5602 (3.1223)	Arch Hard Loss 2.3134 (1.8765)	Arch Alpha Loss 12.4680 (12.4582)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.3%)	
10/01 12:04:25午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 74.0920%
10/01 12:04:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8128	Prec@(1,5) (54.3%, 82.9%)
10/01 12:04:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8565	Prec@(1,5) (53.5%, 82.6%)
10/01 12:04:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8564	Prec@(1,5) (53.4%, 82.5%)
10/01 12:04:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8571	Prec@(1,5) (53.5%, 82.5%)
10/01 12:04:42午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 53.5080%
10/01 12:04:42午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:04:43午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.5080%
10/01 12:05:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.7767 (0.7488)	Arch Loss 2.6499 (3.1145)	Arch Hard Loss 1.4026 (1.8673)	Arch Alpha Loss 12.4730 (12.4715)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
10/01 12:05:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.8860 (0.7622)	Arch Loss 2.8734 (3.1338)	Arch Hard Loss 1.6256 (1.8863)	Arch Alpha Loss 12.4785 (12.4748)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.0%)	
10/01 12:06:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.7117 (0.7819)	Arch Loss 3.1474 (3.1252)	Arch Hard Loss 1.8991 (1.8775)	Arch Alpha Loss 12.4824 (12.4768)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.9%)	
10/01 12:06:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.8253 (0.7990)	Arch Loss 2.7641 (3.1245)	Arch Hard Loss 1.5151 (1.8766)	Arch Alpha Loss 12.4898 (12.4788)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.7%)	
10/01 12:06:37午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 75.4560%
10/01 12:06:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8756	Prec@(1,5) (53.8%, 82.5%)
10/01 12:06:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8649	Prec@(1,5) (54.1%, 82.4%)
10/01 12:06:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8625	Prec@(1,5) (53.9%, 82.5%)
10/01 12:06:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8839	Prec@(1,5) (53.8%, 82.2%)
10/01 12:06:56午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 53.7640%
10/01 12:06:56午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:06:56午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 53.7640%
10/01 12:07:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7549 (0.7076)	Arch Loss 3.6070 (3.0890)	Arch Hard Loss 2.3578 (1.8397)	Arch Alpha Loss 12.4919 (12.4927)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.7%)	
10/01 12:07:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8016 (0.7302)	Arch Loss 2.9322 (3.1152)	Arch Hard Loss 1.6821 (1.8658)	Arch Alpha Loss 12.5008 (12.4943)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.4%)	
10/01 12:08:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.6120 (0.7312)	Arch Loss 2.8870 (3.1339)	Arch Hard Loss 1.6358 (1.8841)	Arch Alpha Loss 12.5122 (12.4981)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.4%)	
10/01 12:08:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9277 (0.7499)	Arch Loss 2.6981 (3.1435)	Arch Hard Loss 1.4473 (1.8934)	Arch Alpha Loss 12.5082 (12.5012)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
10/01 12:08:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 77.0160%
10/01 12:08:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8588	Prec@(1,5) (54.3%, 82.9%)
10/01 12:08:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8806	Prec@(1,5) (54.1%, 82.8%)
10/01 12:09:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8864	Prec@(1,5) (53.8%, 82.8%)
10/01 12:09:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8869	Prec@(1,5) (54.0%, 82.6%)
10/01 12:09:07午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 54.0320%
10/01 12:09:08午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:09:08午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.0320%
10/01 12:09:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8677 (0.6557)	Arch Loss 2.4929 (3.0921)	Arch Hard Loss 1.2421 (1.8412)	Arch Alpha Loss 12.5086 (12.5085)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
10/01 12:10:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.5291 (0.6753)	Arch Loss 3.2850 (3.1309)	Arch Hard Loss 2.0338 (1.8800)	Arch Alpha Loss 12.5121 (12.5091)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.9%)	
10/01 12:10:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.5644 (0.6909)	Arch Loss 2.8292 (3.1376)	Arch Hard Loss 1.5774 (1.8864)	Arch Alpha Loss 12.5187 (12.5112)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
10/01 12:11:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.5528 (0.6984)	Arch Loss 3.0280 (3.1484)	Arch Hard Loss 1.7754 (1.8970)	Arch Alpha Loss 12.5267 (12.5137)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.6%)	
10/01 12:11:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 78.4840%
10/01 12:11:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8864	Prec@(1,5) (54.6%, 82.6%)
10/01 12:11:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9032	Prec@(1,5) (54.5%, 82.5%)
10/01 12:11:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.8849	Prec@(1,5) (54.7%, 82.7%)
10/01 12:11:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.8853	Prec@(1,5) (54.6%, 82.8%)
10/01 12:11:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 54.6400%
10/01 12:11:20午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:11:20午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.6400%
10/01 12:11:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.5370 (0.6054)	Arch Loss 3.2164 (3.1958)	Arch Hard Loss 1.9624 (1.9426)	Arch Alpha Loss 12.5404 (12.5317)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
10/01 12:12:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.5966 (0.6153)	Arch Loss 3.0662 (3.1725)	Arch Hard Loss 1.8121 (1.9189)	Arch Alpha Loss 12.5412 (12.5357)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
10/01 12:12:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.4996 (0.6258)	Arch Loss 3.2467 (3.1583)	Arch Hard Loss 1.9920 (1.9044)	Arch Alpha Loss 12.5476 (12.5386)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.3%)	
10/01 12:13:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.4696 (0.6403)	Arch Loss 2.9666 (3.1615)	Arch Hard Loss 1.7109 (1.9073)	Arch Alpha Loss 12.5566 (12.5419)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.3%)	
10/01 12:13:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 80.3360%
10/01 12:13:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9013	Prec@(1,5) (54.7%, 82.7%)
10/01 12:13:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.8787	Prec@(1,5) (55.0%, 83.0%)
10/01 12:13:30午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.8835	Prec@(1,5) (54.7%, 82.9%)
10/01 12:13:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8812	Prec@(1,5) (54.7%, 82.9%)
10/01 12:13:34午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 54.7200%
10/01 12:13:34午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:13:35午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 54.7200%
10/01 12:14:06午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8910 (0.5394)	Arch Loss 2.8916 (3.2020)	Arch Hard Loss 1.6347 (1.9457)	Arch Alpha Loss 12.5690 (12.5630)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
10/01 12:14:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.7939 (0.5661)	Arch Loss 3.2759 (3.1700)	Arch Hard Loss 2.0188 (1.9134)	Arch Alpha Loss 12.5710 (12.5661)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.9%)	
10/01 12:15:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.6427 (0.5841)	Arch Loss 2.8571 (3.1847)	Arch Hard Loss 1.5994 (1.9278)	Arch Alpha Loss 12.5770 (12.5686)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.7%)	
10/01 12:15:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.5926 (0.5952)	Arch Loss 3.2022 (3.1877)	Arch Hard Loss 1.9444 (1.9306)	Arch Alpha Loss 12.5780 (12.5709)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.7%)	
10/01 12:15:33午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 81.7600%
10/01 12:15:38午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.9072	Prec@(1,5) (54.4%, 83.0%)
10/01 12:15:42午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9107	Prec@(1,5) (54.9%, 82.9%)
10/01 12:15:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9001	Prec@(1,5) (55.1%, 83.1%)
10/01 12:15:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9025	Prec@(1,5) (55.1%, 83.0%)
10/01 12:15:51午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 55.1000%
10/01 12:15:51午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:15:51午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.1000%
10/01 12:16:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.3456 (0.5386)	Arch Loss 2.9252 (3.1704)	Arch Hard Loss 1.6663 (1.9117)	Arch Alpha Loss 12.5897 (12.5869)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
10/01 12:16:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.5684 (0.5322)	Arch Loss 3.6203 (3.1904)	Arch Hard Loss 2.3613 (1.9316)	Arch Alpha Loss 12.5902 (12.5883)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
10/01 12:17:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.5750 (0.5453)	Arch Loss 3.8990 (3.1957)	Arch Hard Loss 2.6393 (1.9366)	Arch Alpha Loss 12.5970 (12.5909)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
10/01 12:17:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.4727 (0.5569)	Arch Loss 3.6258 (3.2025)	Arch Hard Loss 2.3651 (1.9432)	Arch Alpha Loss 12.6071 (12.5930)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.9%)	
10/01 12:17:49午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 82.9240%
10/01 12:17:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8783	Prec@(1,5) (56.3%, 83.3%)
10/01 12:17:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8641	Prec@(1,5) (56.3%, 83.5%)
10/01 12:18:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.8892	Prec@(1,5) (55.8%, 83.4%)
10/01 12:18:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.8938	Prec@(1,5) (55.6%, 83.4%)
10/01 12:18:06午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 55.5760%
10/01 12:18:06午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:18:07午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.5760%
10/01 12:18:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.3996 (0.4837)	Arch Loss 2.6651 (3.1663)	Arch Hard Loss 1.4038 (1.9053)	Arch Alpha Loss 12.6129 (12.6103)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.3%)	
10/01 12:19:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.5864 (0.4922)	Arch Loss 3.0438 (3.1760)	Arch Hard Loss 1.7824 (1.9148)	Arch Alpha Loss 12.6145 (12.6119)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.4%)	
10/01 12:19:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.4580 (0.5062)	Arch Loss 3.6165 (3.2099)	Arch Hard Loss 2.3544 (1.9485)	Arch Alpha Loss 12.6207 (12.6139)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.2%)	
10/01 12:20:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6070 (0.5136)	Arch Loss 3.1462 (3.2044)	Arch Hard Loss 1.8835 (1.9428)	Arch Alpha Loss 12.6277 (12.6162)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.2%)	
10/01 12:20:04午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 83.8440%
10/01 12:20:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9269	Prec@(1,5) (54.4%, 83.5%)
10/01 12:20:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9144	Prec@(1,5) (55.0%, 83.3%)
10/01 12:20:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9114	Prec@(1,5) (55.1%, 83.4%)
10/01 12:20:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.8984	Prec@(1,5) (55.3%, 83.5%)
10/01 12:20:21午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 55.2360%
10/01 12:20:21午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:20:22午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.5760%
10/01 12:20:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.4879 (0.4477)	Arch Loss 3.3017 (3.2232)	Arch Hard Loss 2.0385 (1.9602)	Arch Alpha Loss 12.6319 (12.6297)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.6%)	
10/01 12:21:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.4463 (0.4619)	Arch Loss 3.6510 (3.2370)	Arch Hard Loss 2.3870 (1.9737)	Arch Alpha Loss 12.6403 (12.6323)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
10/01 12:21:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.4506 (0.4659)	Arch Loss 2.8644 (3.2345)	Arch Hard Loss 1.5995 (1.9708)	Arch Alpha Loss 12.6489 (12.6369)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
10/01 12:22:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.5554 (0.4715)	Arch Loss 3.5628 (3.2308)	Arch Hard Loss 2.2975 (1.9668)	Arch Alpha Loss 12.6529 (12.6399)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
10/01 12:22:20午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 85.4960%
10/01 12:22:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9235	Prec@(1,5) (55.4%, 83.5%)
10/01 12:22:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.9166	Prec@(1,5) (55.7%, 83.4%)
10/01 12:22:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.9269	Prec@(1,5) (55.5%, 83.3%)
10/01 12:22:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.9168	Prec@(1,5) (55.5%, 83.4%)
10/01 12:22:37午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 55.5360%
10/01 12:22:37午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:22:38午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 55.5760%
10/01 12:23:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.4995 (0.3934)	Arch Loss 3.6214 (3.1799)	Arch Hard Loss 2.3560 (1.9144)	Arch Alpha Loss 12.6546 (12.6548)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.4%, 98.8%)	
10/01 12:23:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5110 (0.4130)	Arch Loss 3.0187 (3.2082)	Arch Hard Loss 1.7526 (1.9425)	Arch Alpha Loss 12.6608 (12.6565)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.7%, 98.8%)	
10/01 12:24:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4496 (0.4239)	Arch Loss 2.9488 (3.2317)	Arch Hard Loss 1.6816 (1.9658)	Arch Alpha Loss 12.6717 (12.6596)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.7%)	
10/01 12:24:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.3867 (0.4288)	Arch Loss 3.2742 (3.2342)	Arch Hard Loss 2.0062 (1.9678)	Arch Alpha Loss 12.6800 (12.6632)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.7%)	
10/01 12:24:36午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 86.7960%
10/01 12:24:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9471	Prec@(1,5) (56.0%, 82.9%)
10/01 12:24:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9204	Prec@(1,5) (55.8%, 82.9%)
10/01 12:24:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.9318	Prec@(1,5) (55.8%, 83.0%)
10/01 12:24:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9182	Prec@(1,5) (56.1%, 83.3%)
10/01 12:24:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 56.0800%
10/01 12:24:53午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:24:54午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.0800%
10/01 12:25:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.2559 (0.3589)	Arch Loss 3.3559 (3.2487)	Arch Hard Loss 2.0874 (1.9803)	Arch Alpha Loss 12.6850 (12.6847)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.2%)	
10/01 12:25:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4223 (0.3778)	Arch Loss 3.0483 (3.2431)	Arch Hard Loss 1.7793 (1.9744)	Arch Alpha Loss 12.6900 (12.6867)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.0%)	
10/01 12:26:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.2994 (0.3856)	Arch Loss 2.8167 (3.2626)	Arch Hard Loss 1.5469 (1.9937)	Arch Alpha Loss 12.6983 (12.6893)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
10/01 12:26:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.4596 (0.3901)	Arch Loss 2.8563 (3.2517)	Arch Hard Loss 1.5861 (1.9825)	Arch Alpha Loss 12.7025 (12.6915)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
10/01 12:26:53午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 88.2800%
10/01 12:26:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.9440	Prec@(1,5) (54.9%, 83.0%)
10/01 12:27:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.9361	Prec@(1,5) (55.5%, 83.4%)
10/01 12:27:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.9643	Prec@(1,5) (55.3%, 83.0%)
10/01 12:27:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9559	Prec@(1,5) (55.4%, 83.2%)
10/01 12:27:10午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 55.4440%
10/01 12:27:10午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:27:10午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.0800%
10/01 12:27:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.2073 (0.3569)	Arch Loss 2.9659 (3.1967)	Arch Hard Loss 1.6954 (1.9260)	Arch Alpha Loss 12.7054 (12.7064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.2%)	
10/01 12:28:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.4814 (0.3567)	Arch Loss 3.0881 (3.2501)	Arch Hard Loss 1.8164 (1.9792)	Arch Alpha Loss 12.7175 (12.7093)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.3%)	
10/01 12:28:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.3388 (0.3630)	Arch Loss 3.1548 (3.2703)	Arch Hard Loss 1.8820 (1.9990)	Arch Alpha Loss 12.7276 (12.7128)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.2%)	
10/01 12:29:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.4025 (0.3638)	Arch Loss 3.0967 (3.2730)	Arch Hard Loss 1.8238 (2.0013)	Arch Alpha Loss 12.7297 (12.7167)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.2%)	
10/01 12:29:10午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 89.0960%
10/01 12:29:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.9560	Prec@(1,5) (55.7%, 83.5%)
10/01 12:29:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.9297	Prec@(1,5) (56.0%, 83.4%)
10/01 12:29:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9278	Prec@(1,5) (56.0%, 83.3%)
10/01 12:29:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.9361	Prec@(1,5) (56.1%, 83.3%)
10/01 12:29:27午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 56.1120%
10/01 12:29:27午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:29:28午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.1120%
10/01 12:29:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.2619 (0.3252)	Arch Loss 3.4020 (3.2736)	Arch Hard Loss 2.1282 (2.0003)	Arch Alpha Loss 12.7372 (12.7324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.3%)	
10/01 12:30:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.3334 (0.3260)	Arch Loss 3.2881 (3.2727)	Arch Hard Loss 2.0134 (1.9990)	Arch Alpha Loss 12.7474 (12.7379)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
10/01 12:30:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5540 (0.3308)	Arch Loss 3.7113 (3.2819)	Arch Hard Loss 2.4358 (2.0077)	Arch Alpha Loss 12.7553 (12.7422)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.1%, 99.4%)	
10/01 12:31:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.2438 (0.3381)	Arch Loss 3.0209 (3.2759)	Arch Hard Loss 1.7457 (2.0014)	Arch Alpha Loss 12.7516 (12.7451)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.4%)	
10/01 12:31:26午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 89.9840%
10/01 12:31:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.9960	Prec@(1,5) (55.8%, 83.5%)
10/01 12:31:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.9749	Prec@(1,5) (56.1%, 83.5%)
10/01 12:31:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9608	Prec@(1,5) (56.1%, 83.5%)
10/01 12:31:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9651	Prec@(1,5) (55.9%, 83.6%)
10/01 12:31:43午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 55.9520%
10/01 12:31:43午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:31:43午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.1120%
10/01 12:32:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.3313 (0.2999)	Arch Loss 3.3469 (3.2836)	Arch Hard Loss 2.0704 (2.0075)	Arch Alpha Loss 12.7656 (12.7605)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
10/01 12:32:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.3628 (0.3088)	Arch Loss 2.9509 (3.2796)	Arch Hard Loss 1.6740 (2.0032)	Arch Alpha Loss 12.7690 (12.7637)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
10/01 12:33:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.3318 (0.3107)	Arch Loss 3.0496 (3.3057)	Arch Hard Loss 1.7718 (2.0289)	Arch Alpha Loss 12.7782 (12.7678)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
10/01 12:33:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.2897 (0.3139)	Arch Loss 3.6799 (3.2982)	Arch Hard Loss 2.4019 (2.0211)	Arch Alpha Loss 12.7801 (12.7705)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
10/01 12:33:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 90.7160%
10/01 12:33:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0019	Prec@(1,5) (56.0%, 83.1%)
10/01 12:33:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.9886	Prec@(1,5) (56.1%, 83.7%)
10/01 12:33:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.9699	Prec@(1,5) (56.4%, 83.8%)
10/01 12:34:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.9584	Prec@(1,5) (56.4%, 83.7%)
10/01 12:34:00午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 56.4680%
10/01 12:34:00午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:34:01午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.4680%
10/01 12:34:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.2492 (0.2790)	Arch Loss 2.3741 (3.3247)	Arch Hard Loss 1.0951 (2.0462)	Arch Alpha Loss 12.7908 (12.7852)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
10/01 12:35:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.3000 (0.2851)	Arch Loss 3.9767 (3.2965)	Arch Hard Loss 2.6975 (2.0178)	Arch Alpha Loss 12.7920 (12.7872)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
10/01 12:35:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.2835 (0.2933)	Arch Loss 3.2139 (3.3057)	Arch Hard Loss 1.9339 (2.0266)	Arch Alpha Loss 12.7997 (12.7905)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
10/01 12:35:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.3100 (0.2976)	Arch Loss 3.2939 (3.3056)	Arch Hard Loss 2.0138 (2.0263)	Arch Alpha Loss 12.8015 (12.7927)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.5%)	
10/01 12:35:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 91.0800%
10/01 12:36:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.0277	Prec@(1,5) (55.1%, 82.9%)
10/01 12:36:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.9944	Prec@(1,5) (55.6%, 83.6%)
10/01 12:36:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.9610	Prec@(1,5) (56.2%, 83.7%)
10/01 12:36:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9588	Prec@(1,5) (56.3%, 83.7%)
10/01 12:36:15午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 56.3040%
10/01 12:36:15午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:36:16午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.4680%
10/01 12:36:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.2018 (0.2672)	Arch Loss 3.2783 (3.2768)	Arch Hard Loss 1.9976 (1.9963)	Arch Alpha Loss 12.8075 (12.8043)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
10/01 12:37:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.2660 (0.2732)	Arch Loss 3.8500 (3.2963)	Arch Hard Loss 2.5686 (2.0155)	Arch Alpha Loss 12.8136 (12.8076)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
10/01 12:37:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.4265 (0.2740)	Arch Loss 3.2208 (3.3066)	Arch Hard Loss 1.9391 (2.0255)	Arch Alpha Loss 12.8171 (12.8110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
10/01 12:38:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.2696 (0.2779)	Arch Loss 3.1976 (3.3194)	Arch Hard Loss 1.9154 (2.0381)	Arch Alpha Loss 12.8225 (12.8127)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
10/01 12:38:14午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 92.0280%
10/01 12:38:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.0155	Prec@(1,5) (55.5%, 83.3%)
10/01 12:38:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.9926	Prec@(1,5) (55.6%, 83.2%)
10/01 12:38:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.9907	Prec@(1,5) (55.9%, 83.2%)
10/01 12:38:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.9868	Prec@(1,5) (55.9%, 83.4%)
10/01 12:38:31午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 55.9080%
10/01 12:38:31午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
10/01 12:38:31午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.4680%
10/01 12:39:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.2981 (0.2566)	Arch Loss 2.7745 (3.3199)	Arch Hard Loss 1.4915 (2.0372)	Arch Alpha Loss 12.8306 (12.8276)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
10/01 12:39:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.2269 (0.2591)	Arch Loss 3.5212 (3.3147)	Arch Hard Loss 2.2369 (2.0315)	Arch Alpha Loss 12.8422 (12.8320)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
10/01 12:40:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.2058 (0.2668)	Arch Loss 4.2282 (3.3209)	Arch Hard Loss 2.9439 (2.0373)	Arch Alpha Loss 12.8424 (12.8361)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
10/01 12:40:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.1778 (0.2671)	Arch Loss 2.4114 (3.3285)	Arch Hard Loss 1.1262 (2.0446)	Arch Alpha Loss 12.8525 (12.8388)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
10/01 12:40:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 92.3560%
10/01 12:40:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.9801	Prec@(1,5) (56.2%, 83.6%)
10/01 12:40:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.9560	Prec@(1,5) (56.8%, 84.0%)
10/01 12:40:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.9704	Prec@(1,5) (56.5%, 83.9%)
10/01 12:40:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.9762	Prec@(1,5) (56.3%, 83.8%)
10/01 12:40:48午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 56.2920%
10/01 12:40:48午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:40:48午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.4680%
10/01 12:41:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.1349 (0.2485)	Arch Loss 3.1976 (3.3521)	Arch Hard Loss 1.9113 (2.0663)	Arch Alpha Loss 12.8635 (12.8585)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.6%)	
10/01 12:41:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.3294 (0.2501)	Arch Loss 3.1913 (3.3448)	Arch Hard Loss 1.9042 (2.0584)	Arch Alpha Loss 12.8708 (12.8637)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
10/01 12:42:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3006 (0.2521)	Arch Loss 3.3385 (3.3253)	Arch Hard Loss 2.0516 (2.0387)	Arch Alpha Loss 12.8688 (12.8658)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
10/01 12:42:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.1900 (0.2552)	Arch Loss 2.8116 (3.3226)	Arch Hard Loss 1.5242 (2.0359)	Arch Alpha Loss 12.8749 (12.8672)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
10/01 12:42:46午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 92.9280%
10/01 12:42:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.9710	Prec@(1,5) (56.0%, 83.7%)
10/01 12:42:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.9738	Prec@(1,5) (56.3%, 83.7%)
10/01 12:42:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.9813	Prec@(1,5) (56.3%, 83.6%)
10/01 12:43:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.9843	Prec@(1,5) (56.3%, 83.6%)
10/01 12:43:03午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 56.3440%
10/01 12:43:03午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:43:04午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.4680%
10/01 12:43:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.2331 (0.2432)	Arch Loss 3.5003 (3.3426)	Arch Hard Loss 2.2122 (2.0547)	Arch Alpha Loss 12.8809 (12.8793)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
10/01 12:44:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.1722 (0.2494)	Arch Loss 3.1812 (3.3536)	Arch Hard Loss 1.8923 (2.0653)	Arch Alpha Loss 12.8892 (12.8820)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
10/01 12:44:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.1972 (0.2478)	Arch Loss 3.2343 (3.3444)	Arch Hard Loss 1.9451 (2.0559)	Arch Alpha Loss 12.8925 (12.8845)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
10/01 12:44:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.3744 (0.2490)	Arch Loss 2.8790 (3.3436)	Arch Hard Loss 1.5897 (2.0549)	Arch Alpha Loss 12.8926 (12.8863)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.7%)	
10/01 12:44:58午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 92.9280%
10/01 12:45:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.0052	Prec@(1,5) (55.9%, 83.0%)
10/01 12:45:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.9736	Prec@(1,5) (56.7%, 83.7%)
10/01 12:45:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.9937	Prec@(1,5) (56.5%, 83.6%)
10/01 12:45:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.0023	Prec@(1,5) (56.3%, 83.5%)
10/01 12:45:15午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 56.2600%
10/01 12:45:15午前 searchStage_KD_main.py:65 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
10/01 12:45:15午前 searchStage_KD_main.py:96 [INFO] Until now, best Prec@1 = 56.4680%
10/01 12:45:15午前 searchStage_KD_main.py:101 [INFO] Final best Prec@1 = 56.4680%
10/01 12:45:15午前 searchStage_KD_main.py:102 [INFO] Final Best Genotype = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG2_concat=range(6, 8), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
