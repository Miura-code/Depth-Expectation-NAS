10/05 06:15:02AM parser.py:28 [INFO] 
10/05 06:15:02AM parser.py:29 [INFO] Parameters:
10/05 06:15:02AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.00004-2-h_das_teacher/DAG
10/05 06:15:02AM parser.py:31 [INFO] T=10.0
10/05 06:15:02AM parser.py:31 [INFO] ADVANCED=True
10/05 06:15:02AM parser.py:31 [INFO] ALPHA_LR=0.0003
10/05 06:15:02AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
10/05 06:15:02AM parser.py:31 [INFO] BATCH_SIZE=64
10/05 06:15:02AM parser.py:31 [INFO] CASCADE=False
10/05 06:15:02AM parser.py:31 [INFO] CHECKPOINT_RESET=False
10/05 06:15:02AM parser.py:31 [INFO] CUTOUT_LENGTH=0
10/05 06:15:02AM parser.py:31 [INFO] DATA_PATH=../data/
10/05 06:15:02AM parser.py:31 [INFO] DATASET=cifar100
10/05 06:15:02AM parser.py:31 [INFO] DEPTH_COEF=0.0
10/05 06:15:02AM parser.py:31 [INFO] DESCRIPTION=ArchHint_KD_mimic_only_teacher_archtecture
10/05 06:15:02AM parser.py:31 [INFO] EPOCHS=50
10/05 06:15:02AM parser.py:31 [INFO] EXP_NAME=l0.00004-2-h_das_teacher
10/05 06:15:02AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
10/05 06:15:02AM parser.py:31 [INFO] GPUS=[0]
10/05 06:15:02AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
10/05 06:15:02AM parser.py:31 [INFO] INIT_CHANNELS=16
10/05 06:15:02AM parser.py:31 [INFO] L=4e-05
10/05 06:15:02AM parser.py:31 [INFO] LAYERS=20
10/05 06:15:02AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
10/05 06:15:02AM parser.py:31 [INFO] NAME=ARCH-KD
10/05 06:15:02AM parser.py:31 [INFO] NONKD=False
10/05 06:15:02AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.00004-2-h_das_teacher
10/05 06:15:02AM parser.py:31 [INFO] PCDARTS=False
10/05 06:15:02AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/ARCH-KD/l0.00004-2-h_das_teacher/plots
10/05 06:15:02AM parser.py:31 [INFO] PRINT_FREQ=100
10/05 06:15:02AM parser.py:31 [INFO] RESUME_PATH=None
10/05 06:15:02AM parser.py:31 [INFO] SAVE=l0.00004-2-h_das_teacher
10/05 06:15:02AM parser.py:31 [INFO] SEED=0
10/05 06:15:02AM parser.py:31 [INFO] SHARE_STAGE=False
10/05 06:15:02AM parser.py:31 [INFO] SLIDE_WINDOW=8
10/05 06:15:02AM parser.py:31 [INFO] SPEC_CELL=True
10/05 06:15:02AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
10/05 06:15:02AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
10/05 06:15:02AM parser.py:31 [INFO] TRAIN_PORTION=0.5
10/05 06:15:02AM parser.py:31 [INFO] TYPE=ArchKD
10/05 06:15:02AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
10/05 06:15:02AM parser.py:31 [INFO] W_LR=0.025
10/05 06:15:02AM parser.py:31 [INFO] W_LR_MIN=0.001
10/05 06:15:02AM parser.py:31 [INFO] W_MOMENTUM=0.9
10/05 06:15:02AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
10/05 06:15:02AM parser.py:31 [INFO] WORKERS=4
10/05 06:15:02AM parser.py:32 [INFO] 
10/05 06:15:04AM searchStage_ArchKD_trainer.py:91 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
10/05 06:15:04AM searchStage_trainer.py:136 [INFO] --> No loaded checkpoint!
10/05 06:15:37AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3452 (4.5665)	Arch Loss 4.3951 (4.5621)	Arch Hard Loss 4.3936 (4.5606)	Arch Alpha Loss 35.6157 (35.8065)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (2.7%, 11.5%)	
10/05 06:16:06AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2383 (4.3570)	Arch Loss 3.9953 (4.3336)	Arch Hard Loss 3.9938 (4.3322)	Arch Alpha Loss 35.5465 (35.6846)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (4.0%, 16.4%)	
10/05 06:16:35AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8560 (4.2316)	Arch Loss 3.9150 (4.2129)	Arch Hard Loss 3.9136 (4.2115)	Arch Alpha Loss 35.4254 (35.6020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (5.0%, 19.8%)	
10/05 06:17:01AM searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.7689 (4.1537)	Arch Loss 3.8331 (4.1367)	Arch Hard Loss 3.8317 (4.1353)	Arch Alpha Loss 35.1938 (35.5359)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (5.8%, 22.0%)	
10/05 06:17:02AM searchStage_ArchKD_trainer.py:179 [INFO] Train: [  0/49] Final Prec@1 5.8360%
10/05 06:17:07AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.8285	Prec@(1,5) (9.9%, 31.2%)
10/05 06:17:12AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.8343	Prec@(1,5) (9.9%, 31.4%)
10/05 06:17:17AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.8346	Prec@(1,5) (9.6%, 31.2%)
10/05 06:17:21AM searchStage_trainer.py:311 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.8266	Prec@(1,5) (9.6%, 31.6%)
10/05 06:17:21AM searchStage_trainer.py:322 [INFO] Valid: [  0/49] Final Prec@1 9.6360%
10/05 06:17:21AM searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 3)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 06:17:21AM searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 9.6360%
10/05 06:17:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6025 (3.7892)	Arch Loss 3.7074 (3.7736)	Arch Hard Loss 3.7060 (3.7722)	Arch Alpha Loss 35.1942 (35.2081)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.2%, 33.0%)	
10/05 06:18:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.5990 (3.7281)	Arch Loss 3.6486 (3.7378)	Arch Hard Loss 3.6472 (3.7364)	Arch Alpha Loss 34.9651 (35.1371)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (12.3%, 34.9%)	
10/05 06:18:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9319 (3.7084)	Arch Loss 3.4285 (3.6940)	Arch Hard Loss 3.4271 (3.6926)	Arch Alpha Loss 35.0778 (35.0848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (12.5%, 35.3%)	
10/05 06:19:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.2775 (3.6678)	Arch Loss 3.4523 (3.6647)	Arch Hard Loss 3.4509 (3.6633)	Arch Alpha Loss 34.9294 (35.0857)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (12.9%, 36.6%)	
10/05 06:19:20午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  1/49] Final Prec@1 12.8760%
10/05 06:19:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6886	Prec@(1,5) (13.2%, 37.8%)
10/05 06:19:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6885	Prec@(1,5) (13.2%, 38.2%)
10/05 06:19:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6920	Prec@(1,5) (13.3%, 38.2%)
10/05 06:19:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6921	Prec@(1,5) (13.2%, 38.3%)
10/05 06:19:37午前 searchStage_trainer.py:322 [INFO] Valid: [  1/49] Final Prec@1 13.2360%
10/05 06:19:37午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:19:37午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 13.2360%
10/05 06:20:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6829 (3.4768)	Arch Loss 3.4802 (3.4981)	Arch Hard Loss 3.4788 (3.4967)	Arch Alpha Loss 34.6796 (34.7856)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (15.4%, 41.8%)	
10/05 06:20:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.3290 (3.4437)	Arch Loss 3.5635 (3.4689)	Arch Hard Loss 3.5621 (3.4675)	Arch Alpha Loss 34.6027 (34.7118)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (16.4%, 42.8%)	
10/05 06:21:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.1874 (3.4031)	Arch Loss 3.0217 (3.4228)	Arch Hard Loss 3.0204 (3.4214)	Arch Alpha Loss 34.4101 (34.6602)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (17.3%, 44.0%)	
10/05 06:21:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.2642 (3.3821)	Arch Loss 3.2775 (3.3929)	Arch Hard Loss 3.2761 (3.3915)	Arch Alpha Loss 34.5005 (34.6120)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (17.7%, 44.8%)	
10/05 06:21:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  2/49] Final Prec@1 17.6880%
10/05 06:21:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2466	Prec@(1,5) (20.1%, 49.1%)
10/05 06:21:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.2463	Prec@(1,5) (20.2%, 48.5%)
10/05 06:21:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.2455	Prec@(1,5) (20.2%, 48.8%)
10/05 06:21:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.2527	Prec@(1,5) (20.1%, 48.7%)
10/05 06:21:53午前 searchStage_trainer.py:322 [INFO] Valid: [  2/49] Final Prec@1 20.1240%
10/05 06:21:53午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:21:53午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 20.1240%
10/05 06:22:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 2.9766 (3.1962)	Arch Loss 3.1095 (3.2397)	Arch Hard Loss 3.1081 (3.2383)	Arch Alpha Loss 34.2163 (34.3459)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.0%)	
10/05 06:22:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.2437 (3.1827)	Arch Loss 3.0794 (3.2160)	Arch Hard Loss 3.0780 (3.2146)	Arch Alpha Loss 34.1866 (34.2568)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (20.7%, 50.7%)	
10/05 06:23:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1295 (3.1659)	Arch Loss 3.0929 (3.1951)	Arch Hard Loss 3.0916 (3.1937)	Arch Alpha Loss 33.9375 (34.1876)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (21.1%, 51.2%)	
10/05 06:23:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.3322 (3.1520)	Arch Loss 3.5086 (3.1761)	Arch Hard Loss 3.5072 (3.1747)	Arch Alpha Loss 33.7806 (34.1124)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (21.5%, 51.5%)	
10/05 06:23:51午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  3/49] Final Prec@1 21.4680%
10/05 06:23:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1851	Prec@(1,5) (20.7%, 51.5%)
10/05 06:24:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1897	Prec@(1,5) (20.7%, 51.4%)
10/05 06:24:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1964	Prec@(1,5) (20.7%, 50.9%)
10/05 06:24:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1951	Prec@(1,5) (20.9%, 51.0%)
10/05 06:24:08午前 searchStage_trainer.py:322 [INFO] Valid: [  3/49] Final Prec@1 20.8600%
10/05 06:24:08午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:24:09午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 20.8600%
10/05 06:24:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.7061 (2.9839)	Arch Loss 2.7834 (3.0558)	Arch Hard Loss 2.7820 (3.0544)	Arch Alpha Loss 33.7244 (33.7672)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.5%)	
10/05 06:25:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.8762 (2.9734)	Arch Loss 2.9040 (3.0303)	Arch Hard Loss 2.9027 (3.0290)	Arch Alpha Loss 33.4385 (33.6281)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (25.1%, 55.8%)	
10/05 06:25:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.1258 (2.9527)	Arch Loss 2.8584 (3.0133)	Arch Hard Loss 2.8570 (3.0119)	Arch Alpha Loss 33.2208 (33.5394)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (25.2%, 56.2%)	
10/05 06:26:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.7890 (2.9471)	Arch Loss 3.1345 (2.9889)	Arch Hard Loss 3.1332 (2.9876)	Arch Alpha Loss 33.2062 (33.4612)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (25.2%, 56.5%)	
10/05 06:26:04午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  4/49] Final Prec@1 25.1640%
10/05 06:26:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.9663	Prec@(1,5) (25.8%, 56.4%)
10/05 06:26:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9665	Prec@(1,5) (26.1%, 56.2%)
10/05 06:26:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9769	Prec@(1,5) (25.8%, 56.0%)
10/05 06:26:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9780	Prec@(1,5) (25.8%, 55.9%)
10/05 06:26:21午前 searchStage_trainer.py:322 [INFO] Valid: [  4/49] Final Prec@1 25.8600%
10/05 06:26:21午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:26:22午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 25.8600%
10/05 06:26:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.6074 (2.7975)	Arch Loss 2.8262 (2.8942)	Arch Hard Loss 2.8249 (2.8929)	Arch Alpha Loss 33.0079 (33.0785)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (29.0%, 60.3%)	
10/05 06:27:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0897 (2.7824)	Arch Loss 2.5301 (2.8693)	Arch Hard Loss 2.5288 (2.8680)	Arch Alpha Loss 32.6849 (32.9519)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (28.8%, 60.6%)	
10/05 06:27:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.5349 (2.7828)	Arch Loss 2.8922 (2.8533)	Arch Hard Loss 2.8909 (2.8520)	Arch Alpha Loss 32.6960 (32.8721)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (29.0%, 60.5%)	
10/05 06:28:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6491 (2.7659)	Arch Loss 2.6078 (2.8317)	Arch Hard Loss 2.6065 (2.8304)	Arch Alpha Loss 32.6962 (32.8370)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (29.3%, 61.0%)	
10/05 06:28:19午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  5/49] Final Prec@1 29.3120%
10/05 06:28:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8230	Prec@(1,5) (28.5%, 60.3%)
10/05 06:28:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8421	Prec@(1,5) (28.1%, 60.1%)
10/05 06:28:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8449	Prec@(1,5) (27.9%, 59.9%)
10/05 06:28:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8491	Prec@(1,5) (27.8%, 59.7%)
10/05 06:28:37午前 searchStage_trainer.py:322 [INFO] Valid: [  5/49] Final Prec@1 27.8000%
10/05 06:28:37午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:28:37午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 27.8000%
10/05 06:29:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.0512 (2.6360)	Arch Loss 2.8083 (2.7128)	Arch Hard Loss 2.8070 (2.7115)	Arch Alpha Loss 32.5378 (32.6434)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.7%)	
10/05 06:29:36午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.3396 (2.6326)	Arch Loss 2.5622 (2.7300)	Arch Hard Loss 2.5609 (2.7287)	Arch Alpha Loss 32.4092 (32.5280)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (31.7%, 64.6%)	
10/05 06:30:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.8549 (2.6294)	Arch Loss 2.6589 (2.7000)	Arch Hard Loss 2.6576 (2.6987)	Arch Alpha Loss 32.4654 (32.4922)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.7%)	
10/05 06:30:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7952 (2.6185)	Arch Loss 2.3527 (2.6882)	Arch Hard Loss 2.3514 (2.6869)	Arch Alpha Loss 32.3539 (32.4737)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.7%)	
10/05 06:30:31午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  6/49] Final Prec@1 32.0080%
10/05 06:30:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6837	Prec@(1,5) (31.3%, 63.2%)
10/05 06:30:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6671	Prec@(1,5) (31.7%, 63.8%)
10/05 06:30:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6606	Prec@(1,5) (31.7%, 64.0%)
10/05 06:30:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6635	Prec@(1,5) (31.7%, 63.8%)
10/05 06:30:49午前 searchStage_trainer.py:322 [INFO] Valid: [  6/49] Final Prec@1 31.7200%
10/05 06:30:49午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:30:49午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 31.7200%
10/05 06:31:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.6086 (2.4869)	Arch Loss 2.5738 (2.6141)	Arch Hard Loss 2.5725 (2.6128)	Arch Alpha Loss 32.1100 (32.2076)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.8%)	
10/05 06:31:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4875 (2.4745)	Arch Loss 2.1875 (2.5954)	Arch Hard Loss 2.1862 (2.5941)	Arch Alpha Loss 32.0844 (32.1530)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (34.8%, 67.9%)	
10/05 06:32:17午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7473 (2.4818)	Arch Loss 2.9379 (2.5972)	Arch Hard Loss 2.9366 (2.5959)	Arch Alpha Loss 32.0989 (32.1315)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (34.8%, 67.7%)	
10/05 06:32:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.2906 (2.4749)	Arch Loss 2.3923 (2.5722)	Arch Hard Loss 2.3910 (2.5710)	Arch Alpha Loss 32.3066 (32.1409)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (34.9%, 67.8%)	
10/05 06:32:43午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  7/49] Final Prec@1 34.9160%
10/05 06:32:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5942	Prec@(1,5) (33.1%, 65.8%)
10/05 06:32:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5757	Prec@(1,5) (33.5%, 66.2%)
10/05 06:32:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5621	Prec@(1,5) (33.5%, 66.2%)
10/05 06:33:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5633	Prec@(1,5) (33.6%, 66.3%)
10/05 06:33:01午前 searchStage_trainer.py:322 [INFO] Valid: [  7/49] Final Prec@1 33.5800%
10/05 06:33:01午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:33:01午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 33.5800%
10/05 06:33:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.0517 (2.3470)	Arch Loss 2.3879 (2.5110)	Arch Hard Loss 2.3866 (2.5097)	Arch Alpha Loss 32.1412 (32.2010)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (38.0%, 71.8%)	
10/05 06:34:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.3537 (2.3579)	Arch Loss 2.4913 (2.5023)	Arch Hard Loss 2.4900 (2.5010)	Arch Alpha Loss 32.0380 (32.1553)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.8%)	
10/05 06:34:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2321 (2.3642)	Arch Loss 2.3149 (2.4871)	Arch Hard Loss 2.3136 (2.4859)	Arch Alpha Loss 32.0805 (32.1032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.6%)	
10/05 06:35:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.3622 (2.3643)	Arch Loss 2.2716 (2.4741)	Arch Hard Loss 2.2703 (2.4728)	Arch Alpha Loss 32.2849 (32.1242)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.4%)	
10/05 06:35:01午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  8/49] Final Prec@1 37.5400%
10/05 06:35:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4168	Prec@(1,5) (36.8%, 69.2%)
10/05 06:35:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4344	Prec@(1,5) (37.0%, 69.0%)
10/05 06:35:15午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4457	Prec@(1,5) (36.6%, 68.7%)
10/05 06:35:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4529	Prec@(1,5) (36.5%, 68.4%)
10/05 06:35:19午前 searchStage_trainer.py:322 [INFO] Valid: [  8/49] Final Prec@1 36.4360%
10/05 06:35:19午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:35:20午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 36.4360%
10/05 06:35:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 1.8139 (2.2513)	Arch Loss 3.0892 (2.4402)	Arch Hard Loss 3.0879 (2.4389)	Arch Alpha Loss 32.1744 (32.2083)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (40.2%, 73.0%)	
10/05 06:36:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.1168 (2.2423)	Arch Loss 2.5514 (2.4284)	Arch Hard Loss 2.5502 (2.4271)	Arch Alpha Loss 32.1787 (32.1883)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (40.3%, 72.9%)	
10/05 06:36:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 1.9258 (2.2559)	Arch Loss 2.2246 (2.4105)	Arch Hard Loss 2.2233 (2.4092)	Arch Alpha Loss 32.3793 (32.2248)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.7%)	
10/05 06:37:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1083 (2.2505)	Arch Loss 2.3152 (2.3968)	Arch Hard Loss 2.3139 (2.3955)	Arch Alpha Loss 32.4968 (32.2755)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.7%)	
10/05 06:37:15午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [  9/49] Final Prec@1 40.0440%
10/05 06:37:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.3770	Prec@(1,5) (38.1%, 69.4%)
10/05 06:37:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3502	Prec@(1,5) (38.5%, 70.8%)
10/05 06:37:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3418	Prec@(1,5) (38.5%, 70.9%)
10/05 06:37:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3373	Prec@(1,5) (38.5%, 71.0%)
10/05 06:37:33午前 searchStage_trainer.py:322 [INFO] Valid: [  9/49] Final Prec@1 38.5080%
10/05 06:37:33午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:37:34午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 38.5080%
10/05 06:38:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.1895 (2.1133)	Arch Loss 2.0750 (2.3564)	Arch Hard Loss 2.0737 (2.3551)	Arch Alpha Loss 32.6185 (32.5382)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (42.4%, 75.6%)	
10/05 06:38:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.0812 (2.1320)	Arch Loss 2.4212 (2.3444)	Arch Hard Loss 2.4199 (2.3431)	Arch Alpha Loss 32.7158 (32.5869)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (42.3%, 75.2%)	
10/05 06:39:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.1219 (2.1479)	Arch Loss 2.0686 (2.3348)	Arch Hard Loss 2.0673 (2.3335)	Arch Alpha Loss 32.7305 (32.6252)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (41.8%, 74.9%)	
10/05 06:39:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.2494 (2.1600)	Arch Loss 2.1213 (2.3186)	Arch Hard Loss 2.1200 (2.3172)	Arch Alpha Loss 32.9818 (32.6702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.5%)	
10/05 06:39:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 10/49] Final Prec@1 41.7200%
10/05 06:39:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.2905	Prec@(1,5) (39.2%, 71.7%)
10/05 06:39:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.2899	Prec@(1,5) (39.3%, 71.8%)
10/05 06:39:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.2676	Prec@(1,5) (39.9%, 72.6%)
10/05 06:39:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.2631	Prec@(1,5) (39.9%, 72.9%)
10/05 06:39:47午前 searchStage_trainer.py:322 [INFO] Valid: [ 10/49] Final Prec@1 39.9440%
10/05 06:39:47午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:39:48午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 39.9440%
10/05 06:40:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2741 (2.0471)	Arch Loss 2.4970 (2.2863)	Arch Hard Loss 2.4957 (2.2849)	Arch Alpha Loss 33.0290 (32.9906)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (43.7%, 77.0%)	
10/05 06:40:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.5169 (2.0593)	Arch Loss 2.1195 (2.2582)	Arch Hard Loss 2.1182 (2.2569)	Arch Alpha Loss 33.2150 (33.0796)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.5%)	
10/05 06:41:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2722 (2.0681)	Arch Loss 2.4336 (2.2515)	Arch Hard Loss 2.4323 (2.2502)	Arch Alpha Loss 33.3774 (33.1523)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (43.6%, 76.4%)	
10/05 06:41:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.6849 (2.0617)	Arch Loss 2.2573 (2.2488)	Arch Hard Loss 2.2560 (2.2475)	Arch Alpha Loss 33.5600 (33.2283)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.5%)	
10/05 06:41:46午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 11/49] Final Prec@1 43.8960%
10/05 06:41:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3304	Prec@(1,5) (39.5%, 71.6%)
10/05 06:41:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3306	Prec@(1,5) (39.2%, 71.2%)
10/05 06:41:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3253	Prec@(1,5) (39.2%, 71.5%)
10/05 06:42:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3144	Prec@(1,5) (39.5%, 71.7%)
10/05 06:42:03午前 searchStage_trainer.py:322 [INFO] Valid: [ 11/49] Final Prec@1 39.4560%
10/05 06:42:03午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:42:03午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 39.9440%
10/05 06:42:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.7428 (1.9514)	Arch Loss 2.3157 (2.2332)	Arch Hard Loss 2.3144 (2.2318)	Arch Alpha Loss 33.4679 (33.5295)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.8%)	
10/05 06:43:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.0312 (1.9757)	Arch Loss 2.6297 (2.2329)	Arch Hard Loss 2.6284 (2.2316)	Arch Alpha Loss 33.6117 (33.5240)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.2%, 78.4%)	
10/05 06:43:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.0568 (1.9824)	Arch Loss 1.9256 (2.2031)	Arch Hard Loss 1.9243 (2.2018)	Arch Alpha Loss 33.8407 (33.5858)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (45.9%, 78.2%)	
10/05 06:44:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.0208 (1.9833)	Arch Loss 2.2279 (2.2019)	Arch Hard Loss 2.2265 (2.2005)	Arch Alpha Loss 33.9242 (33.6557)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.2%)	
10/05 06:44:02午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 12/49] Final Prec@1 45.8360%
10/05 06:44:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2195	Prec@(1,5) (41.7%, 73.5%)
10/05 06:44:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1872	Prec@(1,5) (42.6%, 74.3%)
10/05 06:44:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1964	Prec@(1,5) (42.2%, 74.2%)
10/05 06:44:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1977	Prec@(1,5) (41.9%, 74.4%)
10/05 06:44:20午前 searchStage_trainer.py:322 [INFO] Valid: [ 12/49] Final Prec@1 41.9400%
10/05 06:44:20午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:44:21午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 41.9400%
10/05 06:44:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1877 (1.8691)	Arch Loss 2.1552 (2.1670)	Arch Hard Loss 2.1539 (2.1656)	Arch Alpha Loss 34.0741 (34.0296)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.0%)	
10/05 06:45:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.3359 (1.8924)	Arch Loss 1.9623 (2.1801)	Arch Hard Loss 1.9610 (2.1788)	Arch Alpha Loss 34.2280 (34.1074)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.3%, 80.0%)	
10/05 06:45:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.3806 (1.9003)	Arch Loss 1.7129 (2.1681)	Arch Hard Loss 1.7115 (2.1667)	Arch Alpha Loss 34.3533 (34.1708)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.8%)	
10/05 06:46:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.9828 (1.9111)	Arch Loss 2.1499 (2.1576)	Arch Hard Loss 2.1485 (2.1563)	Arch Alpha Loss 34.5802 (34.2453)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.6%)	
10/05 06:46:19午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 13/49] Final Prec@1 47.5120%
10/05 06:46:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1584	Prec@(1,5) (42.5%, 74.6%)
10/05 06:46:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1989	Prec@(1,5) (42.0%, 73.8%)
10/05 06:46:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1889	Prec@(1,5) (42.5%, 74.0%)
10/05 06:46:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1874	Prec@(1,5) (42.4%, 74.1%)
10/05 06:46:37午前 searchStage_trainer.py:322 [INFO] Valid: [ 13/49] Final Prec@1 42.3840%
10/05 06:46:37午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=range(6, 8))
10/05 06:46:37午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 42.3840%
10/05 06:47:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.9374 (1.8338)	Arch Loss 1.8627 (2.0977)	Arch Hard Loss 1.8613 (2.0963)	Arch Alpha Loss 34.8708 (34.7497)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.4%, 80.8%)	
10/05 06:47:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8880 (1.8297)	Arch Loss 2.0594 (2.1173)	Arch Hard Loss 2.0580 (2.1159)	Arch Alpha Loss 35.0410 (34.8446)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.2%, 80.9%)	
10/05 06:48:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.8817 (1.8319)	Arch Loss 2.3177 (2.1045)	Arch Hard Loss 2.3163 (2.1031)	Arch Alpha Loss 35.2388 (34.9400)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.2%, 80.8%)	
10/05 06:48:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.4474 (1.8419)	Arch Loss 2.2042 (2.1085)	Arch Hard Loss 2.2028 (2.1071)	Arch Alpha Loss 35.3939 (35.0247)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.1%, 80.5%)	
10/05 06:48:39午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 14/49] Final Prec@1 49.1320%
10/05 06:48:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1514	Prec@(1,5) (43.2%, 74.6%)
10/05 06:48:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1227	Prec@(1,5) (43.5%, 75.5%)
10/05 06:48:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1205	Prec@(1,5) (43.6%, 75.5%)
10/05 06:48:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1203	Prec@(1,5) (43.8%, 75.4%)
10/05 06:48:56午前 searchStage_trainer.py:322 [INFO] Valid: [ 14/49] Final Prec@1 43.7360%
10/05 06:48:56午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 2)]], DAG3_concat=range(6, 8))
10/05 06:48:57午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 43.7360%
10/05 06:49:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.6054 (1.7274)	Arch Loss 1.8161 (2.0652)	Arch Hard Loss 1.8147 (2.0638)	Arch Alpha Loss 35.7197 (35.5347)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.8%)	
10/05 06:49:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.5804 (1.7315)	Arch Loss 2.0829 (2.0702)	Arch Hard Loss 2.0814 (2.0688)	Arch Alpha Loss 35.8875 (35.6717)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.5%)	
10/05 06:50:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9069 (1.7538)	Arch Loss 2.0780 (2.0640)	Arch Hard Loss 2.0765 (2.0626)	Arch Alpha Loss 36.1198 (35.7952)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.3%)	
10/05 06:50:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.0092 (1.7633)	Arch Loss 2.2438 (2.0658)	Arch Hard Loss 2.2424 (2.0643)	Arch Alpha Loss 36.2846 (35.8726)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
10/05 06:50:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 15/49] Final Prec@1 51.1120%
10/05 06:51:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0646	Prec@(1,5) (45.3%, 76.8%)
10/05 06:51:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0647	Prec@(1,5) (45.2%, 76.8%)
10/05 06:51:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0737	Prec@(1,5) (44.9%, 76.5%)
10/05 06:51:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0720	Prec@(1,5) (44.8%, 76.5%)
10/05 06:51:13午前 searchStage_trainer.py:322 [INFO] Valid: [ 15/49] Final Prec@1 44.8280%
10/05 06:51:13午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 06:51:13午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 44.8280%
10/05 06:51:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.8064 (1.6838)	Arch Loss 2.0676 (2.0042)	Arch Hard Loss 2.0662 (2.0027)	Arch Alpha Loss 36.4209 (36.3594)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.4%)	
10/05 06:52:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.0764 (1.6918)	Arch Loss 1.7943 (2.0315)	Arch Hard Loss 1.7929 (2.0300)	Arch Alpha Loss 36.6551 (36.4523)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.1%)	
10/05 06:52:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.8799 (1.7109)	Arch Loss 1.6183 (2.0341)	Arch Hard Loss 1.6168 (2.0327)	Arch Alpha Loss 36.9411 (36.5616)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.7%)	
10/05 06:53:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.5756 (1.7144)	Arch Loss 2.6566 (2.0348)	Arch Hard Loss 2.6551 (2.0334)	Arch Alpha Loss 37.0522 (36.6729)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.7%)	
10/05 06:53:08午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 16/49] Final Prec@1 52.1920%
10/05 06:53:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0350	Prec@(1,5) (45.6%, 77.0%)
10/05 06:53:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0458	Prec@(1,5) (45.5%, 77.1%)
10/05 06:53:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0495	Prec@(1,5) (45.4%, 77.1%)
10/05 06:53:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0496	Prec@(1,5) (45.3%, 76.9%)
10/05 06:53:26午前 searchStage_trainer.py:322 [INFO] Valid: [ 16/49] Final Prec@1 45.2600%
10/05 06:53:26午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)]], DAG3_concat=range(6, 8))
10/05 06:53:26午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 45.2600%
10/05 06:53:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.8770 (1.6304)	Arch Loss 2.4145 (2.0314)	Arch Hard Loss 2.4130 (2.0299)	Arch Alpha Loss 37.2341 (37.1721)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 84.4%)	
10/05 06:54:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.2980 (1.6468)	Arch Loss 1.8520 (2.0203)	Arch Hard Loss 1.8505 (2.0188)	Arch Alpha Loss 37.3869 (37.2673)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.3%, 83.9%)	
10/05 06:54:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.9833 (1.6518)	Arch Loss 2.1295 (2.0194)	Arch Hard Loss 2.1280 (2.0179)	Arch Alpha Loss 37.5621 (37.3449)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 84.0%)	
10/05 06:55:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.6340 (1.6557)	Arch Loss 1.5476 (2.0107)	Arch Hard Loss 1.5461 (2.0092)	Arch Alpha Loss 37.8039 (37.4089)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.7%)	
10/05 06:55:23午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 17/49] Final Prec@1 53.1560%
10/05 06:55:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0016	Prec@(1,5) (46.5%, 77.8%)
10/05 06:55:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9935	Prec@(1,5) (46.4%, 78.0%)
10/05 06:55:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9916	Prec@(1,5) (46.8%, 78.1%)
10/05 06:55:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9906	Prec@(1,5) (46.8%, 78.1%)
10/05 06:55:41午前 searchStage_trainer.py:322 [INFO] Valid: [ 17/49] Final Prec@1 46.8440%
10/05 06:55:41午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 06:55:41午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 46.8440%
10/05 06:56:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.5954 (1.5347)	Arch Loss 2.1585 (2.0229)	Arch Hard Loss 2.1569 (2.0214)	Arch Alpha Loss 38.2208 (37.9830)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.7%)	
10/05 06:56:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4820 (1.5803)	Arch Loss 1.7570 (2.0089)	Arch Hard Loss 1.7555 (2.0073)	Arch Alpha Loss 38.2878 (38.1538)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.1%)	
10/05 06:57:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6780 (1.5822)	Arch Loss 2.0740 (2.0091)	Arch Hard Loss 2.0725 (2.0076)	Arch Alpha Loss 38.4766 (38.2267)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.2%)	
10/05 06:57:39午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.6538 (1.5980)	Arch Loss 1.6437 (1.9916)	Arch Hard Loss 1.6422 (1.9901)	Arch Alpha Loss 38.7515 (38.3162)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.7%)	
10/05 06:57:40午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 18/49] Final Prec@1 54.6760%
10/05 06:57:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9572	Prec@(1,5) (48.2%, 78.5%)
10/05 06:57:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9599	Prec@(1,5) (47.8%, 78.6%)
10/05 06:57:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9616	Prec@(1,5) (47.4%, 78.5%)
10/05 06:57:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9582	Prec@(1,5) (47.6%, 78.5%)
10/05 06:57:57午前 searchStage_trainer.py:322 [INFO] Valid: [ 18/49] Final Prec@1 47.5400%
10/05 06:57:57午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)]], DAG3_concat=range(6, 8))
10/05 06:57:58午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 47.5400%
10/05 06:58:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.4854 (1.4987)	Arch Loss 1.8141 (1.9514)	Arch Hard Loss 1.8125 (1.9499)	Arch Alpha Loss 39.0270 (38.9173)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.5%)	
10/05 06:58:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.7010 (1.5119)	Arch Loss 1.9523 (1.9582)	Arch Hard Loss 1.9507 (1.9567)	Arch Alpha Loss 39.2865 (39.0720)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.3%)	
10/05 06:59:27午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.4251 (1.5331)	Arch Loss 1.7052 (1.9606)	Arch Hard Loss 1.7036 (1.9591)	Arch Alpha Loss 39.7726 (39.2061)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.1%)	
10/05 06:59:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.2163 (1.5499)	Arch Loss 2.2224 (1.9573)	Arch Hard Loss 2.2208 (1.9558)	Arch Alpha Loss 40.0032 (39.3779)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.8%)	
10/05 06:59:55午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 19/49] Final Prec@1 56.0600%
10/05 07:00:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9408	Prec@(1,5) (48.8%, 78.6%)
10/05 07:00:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9445	Prec@(1,5) (48.6%, 78.8%)
10/05 07:00:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9309	Prec@(1,5) (48.6%, 79.1%)
10/05 07:00:13午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9266	Prec@(1,5) (48.7%, 79.1%)
10/05 07:00:13午前 searchStage_trainer.py:322 [INFO] Valid: [ 19/49] Final Prec@1 48.7120%
10/05 07:00:13午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)]], DAG3_concat=range(6, 8))
10/05 07:00:14午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 48.7120%
10/05 07:00:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.4513 (1.4045)	Arch Loss 2.0042 (1.9382)	Arch Hard Loss 2.0026 (1.9366)	Arch Alpha Loss 40.3835 (40.1799)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.8%)	
10/05 07:01:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5115 (1.4521)	Arch Loss 2.0270 (1.9354)	Arch Hard Loss 2.0254 (1.9337)	Arch Alpha Loss 40.6331 (40.3505)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.2%, 87.3%)	
10/05 07:01:45午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.5550 (1.4661)	Arch Loss 1.9623 (1.9345)	Arch Hard Loss 1.9607 (1.9329)	Arch Alpha Loss 40.8235 (40.4823)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.8%)	
10/05 07:02:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4651 (1.4740)	Arch Loss 1.8729 (1.9298)	Arch Hard Loss 1.8713 (1.9282)	Arch Alpha Loss 40.9363 (40.5761)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.8%)	
10/05 07:02:13午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 20/49] Final Prec@1 57.5480%
10/05 07:02:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9425	Prec@(1,5) (48.3%, 78.9%)
10/05 07:02:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9411	Prec@(1,5) (47.8%, 79.2%)
10/05 07:02:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9329	Prec@(1,5) (48.0%, 79.2%)
10/05 07:02:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9243	Prec@(1,5) (48.3%, 79.3%)
10/05 07:02:31午前 searchStage_trainer.py:322 [INFO] Valid: [ 20/49] Final Prec@1 48.3160%
10/05 07:02:31午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:02:31午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 48.7120%
10/05 07:03:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5450 (1.3977)	Arch Loss 1.3653 (1.9372)	Arch Hard Loss 1.3637 (1.9356)	Arch Alpha Loss 41.2913 (41.0763)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.8%)	
10/05 07:03:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4102 (1.4279)	Arch Loss 1.6175 (1.9397)	Arch Hard Loss 1.6158 (1.9381)	Arch Alpha Loss 41.5675 (41.2602)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.3%)	
10/05 07:04:02午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.3612 (1.4268)	Arch Loss 2.1164 (1.9190)	Arch Hard Loss 2.1147 (1.9173)	Arch Alpha Loss 41.9285 (41.4227)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.4%)	
10/05 07:04:29午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.5774 (1.4430)	Arch Loss 1.8936 (1.9138)	Arch Hard Loss 1.8919 (1.9121)	Arch Alpha Loss 42.1457 (41.5709)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.2%)	
10/05 07:04:29午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 21/49] Final Prec@1 58.2920%
10/05 07:04:34午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9075	Prec@(1,5) (48.6%, 80.2%)
10/05 07:04:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.8762	Prec@(1,5) (49.7%, 80.6%)
10/05 07:04:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.8626	Prec@(1,5) (49.8%, 80.7%)
10/05 07:04:47午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.8668	Prec@(1,5) (49.9%, 80.7%)
10/05 07:04:47午前 searchStage_trainer.py:322 [INFO] Valid: [ 21/49] Final Prec@1 49.8920%
10/05 07:04:47午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:04:47午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 49.8920%
10/05 07:05:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3599 (1.3204)	Arch Loss 2.2643 (1.8611)	Arch Hard Loss 2.2626 (1.8594)	Arch Alpha Loss 42.4118 (42.2987)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 89.4%)	
10/05 07:05:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.2269 (1.3657)	Arch Loss 1.8544 (1.8770)	Arch Hard Loss 1.8527 (1.8753)	Arch Alpha Loss 42.7199 (42.4306)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.6%)	
10/05 07:06:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4295 (1.3712)	Arch Loss 1.9761 (1.8793)	Arch Hard Loss 1.9744 (1.8776)	Arch Alpha Loss 43.2542 (42.6205)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.4%)	
10/05 07:06:47午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.0209 (1.3759)	Arch Loss 1.5010 (1.8769)	Arch Hard Loss 1.4992 (1.8752)	Arch Alpha Loss 43.6645 (42.8053)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.4%)	
10/05 07:06:48午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 22/49] Final Prec@1 60.1640%
10/05 07:06:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8902	Prec@(1,5) (50.3%, 80.5%)
10/05 07:06:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8744	Prec@(1,5) (50.4%, 80.8%)
10/05 07:07:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8495	Prec@(1,5) (50.8%, 81.3%)
10/05 07:07:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8565	Prec@(1,5) (50.8%, 81.1%)
10/05 07:07:05午前 searchStage_trainer.py:322 [INFO] Valid: [ 22/49] Final Prec@1 50.7640%
10/05 07:07:05午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:07:05午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.7640%
10/05 07:07:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.1747 (1.2508)	Arch Loss 1.4830 (1.8464)	Arch Hard Loss 1.4813 (1.8447)	Arch Alpha Loss 43.8794 (43.8234)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.5%)	
10/05 07:08:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.4334 (1.2877)	Arch Loss 1.7805 (1.8464)	Arch Hard Loss 1.7787 (1.8446)	Arch Alpha Loss 44.5433 (43.9881)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.8%)	
10/05 07:08:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2606 (1.3145)	Arch Loss 2.0608 (1.8575)	Arch Hard Loss 2.0590 (1.8557)	Arch Alpha Loss 44.8417 (44.2263)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.1%)	
10/05 07:09:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3605 (1.3273)	Arch Loss 2.1565 (1.8599)	Arch Hard Loss 2.1547 (1.8582)	Arch Alpha Loss 45.1758 (44.4063)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.9%)	
10/05 07:09:05午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 23/49] Final Prec@1 61.6640%
10/05 07:09:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9162	Prec@(1,5) (49.7%, 80.3%)
10/05 07:09:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9317	Prec@(1,5) (49.7%, 79.9%)
10/05 07:09:19午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9400	Prec@(1,5) (49.6%, 79.7%)
10/05 07:09:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9240	Prec@(1,5) (50.1%, 80.1%)
10/05 07:09:23午前 searchStage_trainer.py:322 [INFO] Valid: [ 23/49] Final Prec@1 50.1000%
10/05 07:09:23午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:09:23午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.7640%
10/05 07:09:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.4360 (1.2364)	Arch Loss 1.9851 (1.8299)	Arch Hard Loss 1.9832 (1.8281)	Arch Alpha Loss 45.5683 (45.3723)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.2%)	
10/05 07:10:24午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2623 (1.2565)	Arch Loss 2.7007 (1.8549)	Arch Hard Loss 2.6989 (1.8531)	Arch Alpha Loss 45.7906 (45.5276)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.1%)	
10/05 07:10:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.2933 (1.2705)	Arch Loss 2.0696 (1.8572)	Arch Hard Loss 2.0678 (1.8554)	Arch Alpha Loss 46.2926 (45.7011)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.9%)	
10/05 07:11:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.4877 (1.2820)	Arch Loss 1.8873 (1.8541)	Arch Hard Loss 1.8855 (1.8522)	Arch Alpha Loss 46.5568 (45.8631)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.8%)	
10/05 07:11:22午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 24/49] Final Prec@1 62.7560%
10/05 07:11:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8843	Prec@(1,5) (50.6%, 80.4%)
10/05 07:11:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8711	Prec@(1,5) (50.6%, 80.7%)
10/05 07:11:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8665	Prec@(1,5) (50.5%, 80.8%)
10/05 07:11:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8675	Prec@(1,5) (50.4%, 80.9%)
10/05 07:11:40午前 searchStage_trainer.py:322 [INFO] Valid: [ 24/49] Final Prec@1 50.4120%
10/05 07:11:40午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:11:40午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 50.7640%
10/05 07:12:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.2839 (1.1861)	Arch Loss 1.9182 (1.7960)	Arch Hard Loss 1.9164 (1.7941)	Arch Alpha Loss 47.0292 (46.8234)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 90.8%)	
10/05 07:12:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.4697 (1.2124)	Arch Loss 1.6362 (1.8236)	Arch Hard Loss 1.6343 (1.8218)	Arch Alpha Loss 47.4011 (47.0452)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.6%)	
10/05 07:13:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.3942 (1.2254)	Arch Loss 1.9053 (1.8304)	Arch Hard Loss 1.9034 (1.8285)	Arch Alpha Loss 47.8034 (47.2116)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
10/05 07:13:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.4144 (1.2369)	Arch Loss 1.8872 (1.8381)	Arch Hard Loss 1.8853 (1.8362)	Arch Alpha Loss 48.4627 (47.4195)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.3%)	
10/05 07:13:40午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 25/49] Final Prec@1 63.9080%
10/05 07:13:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.7536	Prec@(1,5) (53.8%, 82.3%)
10/05 07:13:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.7745	Prec@(1,5) (53.1%, 81.7%)
10/05 07:13:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8036	Prec@(1,5) (52.3%, 81.4%)
10/05 07:13:59午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8124	Prec@(1,5) (52.2%, 81.3%)
10/05 07:13:59午前 searchStage_trainer.py:322 [INFO] Valid: [ 25/49] Final Prec@1 52.1640%
10/05 07:13:59午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:13:59午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 52.1640%
10/05 07:14:30午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.0770 (1.1187)	Arch Loss 1.9554 (1.8650)	Arch Hard Loss 1.9535 (1.8630)	Arch Alpha Loss 48.7765 (48.6722)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 92.3%)	
10/05 07:15:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.4005 (1.1481)	Arch Loss 2.0283 (1.8449)	Arch Hard Loss 2.0264 (1.8429)	Arch Alpha Loss 49.3829 (48.8787)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.6%)	
10/05 07:15:31午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.3903 (1.1784)	Arch Loss 1.4683 (1.8338)	Arch Hard Loss 1.4663 (1.8318)	Arch Alpha Loss 50.1461 (49.1791)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.2%)	
10/05 07:15:58午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.1342 (1.1881)	Arch Loss 2.0520 (1.8335)	Arch Hard Loss 2.0499 (1.8316)	Arch Alpha Loss 50.5066 (49.4428)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.1%)	
10/05 07:15:59午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 26/49] Final Prec@1 65.0720%
10/05 07:16:03午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8203	Prec@(1,5) (52.4%, 81.3%)
10/05 07:16:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.7894	Prec@(1,5) (52.9%, 81.9%)
10/05 07:16:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.7970	Prec@(1,5) (52.6%, 81.9%)
10/05 07:16:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8032	Prec@(1,5) (52.6%, 81.7%)
10/05 07:16:16午前 searchStage_trainer.py:322 [INFO] Valid: [ 26/49] Final Prec@1 52.5600%
10/05 07:16:16午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:16:17午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 52.5600%
10/05 07:16:48午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0846 (1.0828)	Arch Loss 2.0165 (1.7952)	Arch Hard Loss 2.0145 (1.7932)	Arch Alpha Loss 51.1563 (50.8254)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.4%)	
10/05 07:17:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.3296 (1.0999)	Arch Loss 1.6664 (1.7971)	Arch Hard Loss 1.6643 (1.7951)	Arch Alpha Loss 51.7425 (51.1445)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.2%)	
10/05 07:17:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.0979 (1.1320)	Arch Loss 1.5982 (1.8245)	Arch Hard Loss 1.5961 (1.8225)	Arch Alpha Loss 52.6507 (51.5060)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.8%)	
10/05 07:18:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.0456 (1.1433)	Arch Loss 1.4502 (1.8110)	Arch Hard Loss 1.4481 (1.8089)	Arch Alpha Loss 52.9611 (51.8084)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.7%)	
10/05 07:18:15午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 27/49] Final Prec@1 66.1480%
10/05 07:18:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8061	Prec@(1,5) (52.8%, 81.6%)
10/05 07:18:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8009	Prec@(1,5) (52.7%, 81.8%)
10/05 07:18:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.7867	Prec@(1,5) (52.9%, 82.2%)
10/05 07:18:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.7875	Prec@(1,5) (52.9%, 82.1%)
10/05 07:18:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 27/49] Final Prec@1 52.9320%
10/05 07:18:33午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 3)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:18:33午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 52.9320%
10/05 07:19:03午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.1207 (1.0453)	Arch Loss 1.8472 (1.8126)	Arch Hard Loss 1.8451 (1.8105)	Arch Alpha Loss 53.6535 (53.3678)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.9%)	
10/05 07:19:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1358 (1.0791)	Arch Loss 1.6881 (1.7803)	Arch Hard Loss 1.6859 (1.7781)	Arch Alpha Loss 54.0400 (53.6071)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.5%)	
10/05 07:20:01午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.2426 (1.0881)	Arch Loss 1.6874 (1.8116)	Arch Hard Loss 1.6852 (1.8094)	Arch Alpha Loss 54.7599 (53.8618)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.4%)	
10/05 07:20:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.1506 (1.0965)	Arch Loss 1.7422 (1.8026)	Arch Hard Loss 1.7400 (1.8005)	Arch Alpha Loss 55.3768 (54.1376)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.2%)	
10/05 07:20:27午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 28/49] Final Prec@1 67.5000%
10/05 07:20:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.7693	Prec@(1,5) (53.7%, 82.4%)
10/05 07:20:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.7983	Prec@(1,5) (53.2%, 82.1%)
10/05 07:20:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.7931	Prec@(1,5) (53.2%, 82.4%)
10/05 07:20:45午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7932	Prec@(1,5) (53.3%, 82.3%)
10/05 07:20:45午前 searchStage_trainer.py:322 [INFO] Valid: [ 28/49] Final Prec@1 53.3240%
10/05 07:20:45午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:20:45午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 53.3240%
10/05 07:21:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.0695 (1.0256)	Arch Loss 1.9016 (1.8001)	Arch Hard Loss 1.8994 (1.7979)	Arch Alpha Loss 56.1729 (55.7162)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.3%)	
10/05 07:21:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9870 (1.0356)	Arch Loss 1.7113 (1.8029)	Arch Hard Loss 1.7090 (1.8006)	Arch Alpha Loss 56.9403 (56.1596)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.1%)	
10/05 07:22:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1282 (1.0495)	Arch Loss 2.4342 (1.8090)	Arch Hard Loss 2.4319 (1.8068)	Arch Alpha Loss 57.5247 (56.5347)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.9%)	
10/05 07:22:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.1718 (1.0562)	Arch Loss 2.1592 (1.8064)	Arch Hard Loss 2.1568 (1.8042)	Arch Alpha Loss 58.1619 (56.8366)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.8%)	
10/05 07:22:39午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 29/49] Final Prec@1 68.4800%
10/05 07:22:43午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7737	Prec@(1,5) (53.7%, 82.5%)
10/05 07:22:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7862	Prec@(1,5) (53.5%, 82.1%)
10/05 07:22:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7894	Prec@(1,5) (53.3%, 82.4%)
10/05 07:22:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7842	Prec@(1,5) (53.5%, 82.5%)
10/05 07:22:56午前 searchStage_trainer.py:322 [INFO] Valid: [ 29/49] Final Prec@1 53.4680%
10/05 07:22:56午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:22:56午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 53.4680%
10/05 07:23:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.7772 (0.9830)	Arch Loss 1.5554 (1.7981)	Arch Hard Loss 1.5531 (1.7957)	Arch Alpha Loss 58.9212 (58.5717)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
10/05 07:23:56午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9582 (0.9989)	Arch Loss 1.8497 (1.7994)	Arch Hard Loss 1.8473 (1.7971)	Arch Alpha Loss 59.7020 (58.9349)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.5%)	
10/05 07:24:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 0.9419 (1.0021)	Arch Loss 1.6824 (1.7933)	Arch Hard Loss 1.6800 (1.7909)	Arch Alpha Loss 60.4921 (59.3335)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.5%)	
10/05 07:24:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2628 (1.0122)	Arch Loss 1.6724 (1.7962)	Arch Hard Loss 1.6699 (1.7938)	Arch Alpha Loss 61.3718 (59.7008)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.4%)	
10/05 07:24:53午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 30/49] Final Prec@1 69.6760%
10/05 07:24:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7915	Prec@(1,5) (52.8%, 82.6%)
10/05 07:25:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8040	Prec@(1,5) (52.8%, 82.1%)
10/05 07:25:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8133	Prec@(1,5) (52.8%, 82.0%)
10/05 07:25:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7898	Prec@(1,5) (53.4%, 82.4%)
10/05 07:25:10午前 searchStage_trainer.py:322 [INFO] Valid: [ 30/49] Final Prec@1 53.3960%
10/05 07:25:10午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:25:10午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 53.4680%
10/05 07:25:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8684 (0.9328)	Arch Loss 1.7136 (1.8290)	Arch Hard Loss 1.7111 (1.8265)	Arch Alpha Loss 62.0747 (61.7971)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.1%)	
10/05 07:26:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.8632 (0.9446)	Arch Loss 2.3396 (1.7912)	Arch Hard Loss 2.3371 (1.7887)	Arch Alpha Loss 62.9201 (62.1882)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.1%)	
10/05 07:26:38午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0431 (0.9498)	Arch Loss 2.1767 (1.7919)	Arch Hard Loss 2.1742 (1.7894)	Arch Alpha Loss 63.8660 (62.5763)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.1%)	
10/05 07:27:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.8334 (0.9619)	Arch Loss 1.8493 (1.7878)	Arch Hard Loss 1.8467 (1.7853)	Arch Alpha Loss 64.6142 (62.9581)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 94.0%)	
10/05 07:27:05午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 31/49] Final Prec@1 70.9560%
10/05 07:27:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7167	Prec@(1,5) (55.7%, 83.6%)
10/05 07:27:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7485	Prec@(1,5) (54.5%, 83.0%)
10/05 07:27:18午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7544	Prec@(1,5) (54.5%, 83.1%)
10/05 07:27:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7511	Prec@(1,5) (54.5%, 83.3%)
10/05 07:27:22午前 searchStage_trainer.py:322 [INFO] Valid: [ 31/49] Final Prec@1 54.5280%
10/05 07:27:22午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:27:23午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 54.5280%
10/05 07:27:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.9919 (0.8641)	Arch Loss 1.5750 (1.7783)	Arch Hard Loss 1.5724 (1.7757)	Arch Alpha Loss 65.5556 (65.0613)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.4%)	
10/05 07:28:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.1523 (0.8756)	Arch Loss 1.6455 (1.8013)	Arch Hard Loss 1.6428 (1.7987)	Arch Alpha Loss 66.7524 (65.6106)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 95.1%)	
10/05 07:28:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8412 (0.8944)	Arch Loss 1.9332 (1.7910)	Arch Hard Loss 1.9305 (1.7884)	Arch Alpha Loss 67.7431 (66.1665)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.7%)	
10/05 07:29:15午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.8857 (0.9058)	Arch Loss 1.5530 (1.7874)	Arch Hard Loss 1.5502 (1.7847)	Arch Alpha Loss 68.5442 (66.6179)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.6%)	
10/05 07:29:16午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 32/49] Final Prec@1 72.8280%
10/05 07:29:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7858	Prec@(1,5) (53.8%, 83.1%)
10/05 07:29:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7655	Prec@(1,5) (54.5%, 83.4%)
10/05 07:29:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7725	Prec@(1,5) (54.2%, 83.5%)
10/05 07:29:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7730	Prec@(1,5) (54.2%, 83.4%)
10/05 07:29:33午前 searchStage_trainer.py:322 [INFO] Valid: [ 32/49] Final Prec@1 54.1920%
10/05 07:29:33午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:29:33午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 54.5280%
10/05 07:30:05午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7707 (0.8149)	Arch Loss 2.1220 (1.7690)	Arch Hard Loss 2.1192 (1.7663)	Arch Alpha Loss 69.4858 (69.1048)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.6%)	
10/05 07:30:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.7892 (0.8314)	Arch Loss 1.6871 (1.7804)	Arch Hard Loss 1.6843 (1.7777)	Arch Alpha Loss 70.3967 (69.5268)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.5%)	
10/05 07:31:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.7705 (0.8391)	Arch Loss 1.8636 (1.7899)	Arch Hard Loss 1.8608 (1.7871)	Arch Alpha Loss 71.4441 (69.9851)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
10/05 07:31:32午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9571 (0.8579)	Arch Loss 1.6947 (1.7902)	Arch Hard Loss 1.6918 (1.7874)	Arch Alpha Loss 72.6565 (70.4572)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.1%)	
10/05 07:31:32午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 33/49] Final Prec@1 74.2040%
10/05 07:31:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7576	Prec@(1,5) (54.6%, 83.5%)
10/05 07:31:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7646	Prec@(1,5) (54.2%, 83.5%)
10/05 07:31:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7621	Prec@(1,5) (54.3%, 83.5%)
10/05 07:31:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7616	Prec@(1,5) (54.5%, 83.4%)
10/05 07:31:50午前 searchStage_trainer.py:322 [INFO] Valid: [ 33/49] Final Prec@1 54.4880%
10/05 07:31:50午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:31:50午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 54.5280%
10/05 07:32:21午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8066 (0.7772)	Arch Loss 1.4159 (1.7269)	Arch Hard Loss 1.4130 (1.7239)	Arch Alpha Loss 73.8150 (73.3614)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.8%)	
10/05 07:32:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.5710 (0.7962)	Arch Loss 1.9034 (1.7604)	Arch Hard Loss 1.9004 (1.7574)	Arch Alpha Loss 75.0666 (73.9324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.8%)	
10/05 07:33:20午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.7990 (0.8151)	Arch Loss 1.4451 (1.7723)	Arch Hard Loss 1.4420 (1.7693)	Arch Alpha Loss 76.2524 (74.4978)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.6%)	
10/05 07:33:46午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.6351 (0.8268)	Arch Loss 1.8428 (1.7888)	Arch Hard Loss 1.8397 (1.7858)	Arch Alpha Loss 77.0411 (74.9998)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.4%)	
10/05 07:33:46午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 34/49] Final Prec@1 74.8480%
10/05 07:33:51午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7342	Prec@(1,5) (55.7%, 83.8%)
10/05 07:33:55午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7730	Prec@(1,5) (54.7%, 83.4%)
10/05 07:34:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7595	Prec@(1,5) (55.0%, 83.7%)
10/05 07:34:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7619	Prec@(1,5) (54.9%, 83.6%)
10/05 07:34:04午前 searchStage_trainer.py:322 [INFO] Valid: [ 34/49] Final Prec@1 54.9360%
10/05 07:34:04午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:34:04午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 54.9360%
10/05 07:34:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.9516 (0.7437)	Arch Loss 1.8843 (1.8022)	Arch Hard Loss 1.8812 (1.7991)	Arch Alpha Loss 78.2602 (77.6290)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.4%)	
10/05 07:35:04午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.7212 (0.7471)	Arch Loss 1.8793 (1.8009)	Arch Hard Loss 1.8761 (1.7978)	Arch Alpha Loss 79.3874 (78.2283)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.4%)	
10/05 07:35:33午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.7884 (0.7570)	Arch Loss 1.7800 (1.8049)	Arch Hard Loss 1.7768 (1.8017)	Arch Alpha Loss 80.8967 (78.8676)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.2%)	
10/05 07:36:00午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.6578 (0.7740)	Arch Loss 1.5064 (1.7990)	Arch Hard Loss 1.5031 (1.7958)	Arch Alpha Loss 81.8118 (79.4423)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.0%)	
10/05 07:36:00午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 35/49] Final Prec@1 76.2880%
10/05 07:36:05午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7891	Prec@(1,5) (55.6%, 83.1%)
10/05 07:36:09午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7677	Prec@(1,5) (55.7%, 83.2%)
10/05 07:36:14午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7688	Prec@(1,5) (55.7%, 83.2%)
10/05 07:36:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7593	Prec@(1,5) (55.5%, 83.4%)
10/05 07:36:18午前 searchStage_trainer.py:322 [INFO] Valid: [ 35/49] Final Prec@1 55.5480%
10/05 07:36:18午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:36:18午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 55.5480%
10/05 07:36:49午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6384 (0.6660)	Arch Loss 1.9613 (1.8002)	Arch Hard Loss 1.9580 (1.7969)	Arch Alpha Loss 83.2547 (82.4910)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.0%)	
10/05 07:37:19午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8754 (0.6952)	Arch Loss 2.1113 (1.7688)	Arch Hard Loss 2.1079 (1.7655)	Arch Alpha Loss 84.5475 (83.1674)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.6%)	
10/05 07:37:50午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8077 (0.7187)	Arch Loss 1.6193 (1.7873)	Arch Hard Loss 1.6158 (1.7839)	Arch Alpha Loss 85.7976 (83.8301)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.4%)	
10/05 07:38:16午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8433 (0.7376)	Arch Loss 2.1328 (1.7982)	Arch Hard Loss 2.1293 (1.7948)	Arch Alpha Loss 86.9850 (84.4240)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
10/05 07:38:17午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 36/49] Final Prec@1 77.6200%
10/05 07:38:22午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7653	Prec@(1,5) (55.7%, 83.5%)
10/05 07:38:26午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7678	Prec@(1,5) (55.6%, 83.6%)
10/05 07:38:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7614	Prec@(1,5) (55.7%, 83.5%)
10/05 07:38:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7691	Prec@(1,5) (55.5%, 83.5%)
10/05 07:38:35午前 searchStage_trainer.py:322 [INFO] Valid: [ 36/49] Final Prec@1 55.5440%
10/05 07:38:35午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:38:36午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 55.5480%
10/05 07:39:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.5621 (0.6757)	Arch Loss 1.6814 (1.7413)	Arch Hard Loss 1.6779 (1.7378)	Arch Alpha Loss 88.2807 (87.7006)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
10/05 07:39:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.7429 (0.6771)	Arch Loss 1.9144 (1.7637)	Arch Hard Loss 1.9108 (1.7601)	Arch Alpha Loss 89.6190 (88.2984)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
10/05 07:40:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.6596 (0.6931)	Arch Loss 2.3116 (1.7724)	Arch Hard Loss 2.3079 (1.7688)	Arch Alpha Loss 90.7397 (88.8977)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.8%)	
10/05 07:40:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.4370 (0.6974)	Arch Loss 2.1558 (1.7821)	Arch Hard Loss 2.1521 (1.7785)	Arch Alpha Loss 91.9221 (89.4711)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.8%)	
10/05 07:40:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 37/49] Final Prec@1 78.5840%
10/05 07:40:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.6993	Prec@(1,5) (56.7%, 84.4%)
10/05 07:40:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7001	Prec@(1,5) (56.6%, 84.3%)
10/05 07:40:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7272	Prec@(1,5) (56.3%, 84.3%)
10/05 07:40:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7326	Prec@(1,5) (56.3%, 84.3%)
10/05 07:40:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 37/49] Final Prec@1 56.3200%
10/05 07:40:53午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:40:53午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.3200%
10/05 07:41:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.5545 (0.6133)	Arch Loss 1.2155 (1.7603)	Arch Hard Loss 1.2118 (1.7566)	Arch Alpha Loss 93.1365 (92.5667)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.5%)	
10/05 07:41:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6851 (0.6342)	Arch Loss 1.7239 (1.7683)	Arch Hard Loss 1.7202 (1.7645)	Arch Alpha Loss 94.5716 (93.2118)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.3%)	
10/05 07:42:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.7940 (0.6473)	Arch Loss 1.8682 (1.7861)	Arch Hard Loss 1.8644 (1.7824)	Arch Alpha Loss 95.8804 (93.9087)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
10/05 07:42:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6758 (0.6535)	Arch Loss 2.2310 (1.7815)	Arch Hard Loss 2.2272 (1.7778)	Arch Alpha Loss 96.7693 (94.4586)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.8%, 97.0%)	
10/05 07:42:52午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 38/49] Final Prec@1 79.8280%
10/05 07:42:57午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7703	Prec@(1,5) (55.9%, 83.7%)
10/05 07:43:01午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7682	Prec@(1,5) (55.7%, 83.7%)
10/05 07:43:06午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7690	Prec@(1,5) (55.8%, 83.9%)
10/05 07:43:10午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7570	Prec@(1,5) (56.0%, 84.0%)
10/05 07:43:10午前 searchStage_trainer.py:322 [INFO] Valid: [ 38/49] Final Prec@1 56.0400%
10/05 07:43:10午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:43:10午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.3200%
10/05 07:43:42午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.6312 (0.5924)	Arch Loss 1.7489 (1.7754)	Arch Hard Loss 1.7449 (1.7715)	Arch Alpha Loss 98.1172 (97.4741)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.4%)	
10/05 07:44:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.5773 (0.5995)	Arch Loss 2.2043 (1.8042)	Arch Hard Loss 2.2003 (1.8003)	Arch Alpha Loss 99.7514 (98.2045)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.4%)	
10/05 07:44:41午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.6583 (0.6079)	Arch Loss 1.3675 (1.7993)	Arch Hard Loss 1.3634 (1.7954)	Arch Alpha Loss 101.1222 (98.9220)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.4%)	
10/05 07:45:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.6570 (0.6180)	Arch Loss 1.7967 (1.7931)	Arch Hard Loss 1.7926 (1.7891)	Arch Alpha Loss 102.2267 (99.5597)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.3%)	
10/05 07:45:07午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 39/49] Final Prec@1 81.2280%
10/05 07:45:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7406	Prec@(1,5) (55.9%, 84.3%)
10/05 07:45:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7579	Prec@(1,5) (56.3%, 84.3%)
10/05 07:45:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7636	Prec@(1,5) (56.3%, 84.0%)
10/05 07:45:24午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7580	Prec@(1,5) (56.3%, 84.0%)
10/05 07:45:24午前 searchStage_trainer.py:322 [INFO] Valid: [ 39/49] Final Prec@1 56.3280%
10/05 07:45:24午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:45:25午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.3280%
10/05 07:45:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6545 (0.5582)	Arch Loss 2.1170 (1.7453)	Arch Hard Loss 2.1128 (1.7412)	Arch Alpha Loss 103.4566 (102.8813)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.8%)	
10/05 07:46:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5268 (0.5686)	Arch Loss 1.5957 (1.7822)	Arch Hard Loss 1.5915 (1.7780)	Arch Alpha Loss 104.6539 (103.4663)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.6%)	
10/05 07:46:52午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.7323 (0.5766)	Arch Loss 1.7526 (1.7998)	Arch Hard Loss 1.7483 (1.7956)	Arch Alpha Loss 106.3967 (104.1690)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
10/05 07:47:18午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.4692 (0.5851)	Arch Loss 1.8564 (1.8034)	Arch Hard Loss 1.8521 (1.7992)	Arch Alpha Loss 107.7204 (104.8322)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.6%)	
10/05 07:47:18午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 40/49] Final Prec@1 82.1080%
10/05 07:47:23午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7385	Prec@(1,5) (56.5%, 84.3%)
10/05 07:47:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7540	Prec@(1,5) (56.4%, 83.9%)
10/05 07:47:31午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7594	Prec@(1,5) (56.2%, 84.0%)
10/05 07:47:35午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7490	Prec@(1,5) (56.6%, 84.1%)
10/05 07:47:35午前 searchStage_trainer.py:322 [INFO] Valid: [ 40/49] Final Prec@1 56.6080%
10/05 07:47:35午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:47:36午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.6080%
10/05 07:48:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.4053 (0.5273)	Arch Loss 1.7334 (1.8214)	Arch Hard Loss 1.7290 (1.8171)	Arch Alpha Loss 109.2940 (108.4627)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
10/05 07:48:37午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5571 (0.5398)	Arch Loss 1.7151 (1.7963)	Arch Hard Loss 1.7107 (1.7920)	Arch Alpha Loss 110.6247 (109.2113)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
10/05 07:49:08午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5163 (0.5480)	Arch Loss 1.4416 (1.8051)	Arch Hard Loss 1.4371 (1.8007)	Arch Alpha Loss 112.0401 (109.9285)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.9%)	
10/05 07:49:35午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.4520 (0.5566)	Arch Loss 1.4152 (1.7965)	Arch Hard Loss 1.4107 (1.7920)	Arch Alpha Loss 113.1060 (110.5638)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.8%)	
10/05 07:49:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 41/49] Final Prec@1 83.3320%
10/05 07:49:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7377	Prec@(1,5) (56.6%, 84.6%)
10/05 07:49:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7354	Prec@(1,5) (56.8%, 84.8%)
10/05 07:49:49午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7597	Prec@(1,5) (56.4%, 84.3%)
10/05 07:49:53午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7475	Prec@(1,5) (56.6%, 84.4%)
10/05 07:49:53午前 searchStage_trainer.py:322 [INFO] Valid: [ 41/49] Final Prec@1 56.5960%
10/05 07:49:53午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:49:53午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 56.6080%
10/05 07:50:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.3481 (0.4966)	Arch Loss 1.3989 (1.7444)	Arch Hard Loss 1.3943 (1.7398)	Arch Alpha Loss 114.2839 (113.6272)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.4%)	
10/05 07:50:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6266 (0.5035)	Arch Loss 1.4469 (1.7772)	Arch Hard Loss 1.4423 (1.7726)	Arch Alpha Loss 115.9131 (114.3407)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
10/05 07:51:25午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.4798 (0.5169)	Arch Loss 1.7439 (1.8011)	Arch Hard Loss 1.7392 (1.7965)	Arch Alpha Loss 117.6343 (115.1544)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.3%)	
10/05 07:51:53午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.4875 (0.5248)	Arch Loss 1.5802 (1.8009)	Arch Hard Loss 1.5754 (1.7963)	Arch Alpha Loss 118.8721 (115.8531)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
10/05 07:51:53午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 42/49] Final Prec@1 84.2240%
10/05 07:51:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7373	Prec@(1,5) (56.9%, 84.6%)
10/05 07:52:02午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7263	Prec@(1,5) (57.3%, 84.8%)
10/05 07:52:07午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7358	Prec@(1,5) (57.0%, 84.5%)
10/05 07:52:11午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7433	Prec@(1,5) (57.2%, 84.6%)
10/05 07:52:11午前 searchStage_trainer.py:322 [INFO] Valid: [ 42/49] Final Prec@1 57.1920%
10/05 07:52:11午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:52:11午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.1920%
10/05 07:52:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.3749 (0.4821)	Arch Loss 1.9783 (1.8027)	Arch Hard Loss 1.9734 (1.7979)	Arch Alpha Loss 120.4580 (119.8090)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.4%)	
10/05 07:53:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.3251 (0.4871)	Arch Loss 1.7052 (1.7822)	Arch Hard Loss 1.7003 (1.7774)	Arch Alpha Loss 121.7696 (120.4867)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.4%)	
10/05 07:53:44午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6881 (0.4953)	Arch Loss 2.0632 (1.7985)	Arch Hard Loss 2.0583 (1.7937)	Arch Alpha Loss 123.2578 (121.1515)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.3%)	
10/05 07:54:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.4862 (0.5020)	Arch Loss 1.6094 (1.7928)	Arch Hard Loss 1.6044 (1.7879)	Arch Alpha Loss 123.9925 (121.7232)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
10/05 07:54:11午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 43/49] Final Prec@1 85.0840%
10/05 07:54:16午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7690	Prec@(1,5) (57.0%, 84.4%)
10/05 07:54:20午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7542	Prec@(1,5) (57.4%, 84.5%)
10/05 07:54:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7591	Prec@(1,5) (57.1%, 84.2%)
10/05 07:54:29午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7561	Prec@(1,5) (57.0%, 84.3%)
10/05 07:54:29午前 searchStage_trainer.py:322 [INFO] Valid: [ 43/49] Final Prec@1 57.0240%
10/05 07:54:29午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:54:29午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.1920%
10/05 07:54:59午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.4267 (0.4538)	Arch Loss 1.6760 (1.7992)	Arch Hard Loss 1.6710 (1.7942)	Arch Alpha Loss 125.7534 (124.8766)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
10/05 07:55:28午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.3813 (0.4632)	Arch Loss 1.3654 (1.8061)	Arch Hard Loss 1.3604 (1.8011)	Arch Alpha Loss 126.7094 (125.5659)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.6%)	
10/05 07:55:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.4725 (0.4678)	Arch Loss 1.8038 (1.8169)	Arch Hard Loss 1.7987 (1.8118)	Arch Alpha Loss 127.9753 (126.1494)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
10/05 07:56:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5022 (0.4794)	Arch Loss 1.8127 (1.8077)	Arch Hard Loss 1.8075 (1.8026)	Arch Alpha Loss 129.2997 (126.7098)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
10/05 07:56:24午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 44/49] Final Prec@1 85.7800%
10/05 07:56:28午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.7810	Prec@(1,5) (56.6%, 83.9%)
10/05 07:56:33午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7880	Prec@(1,5) (56.0%, 84.2%)
10/05 07:56:37午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7760	Prec@(1,5) (56.1%, 84.3%)
10/05 07:56:41午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7636	Prec@(1,5) (56.5%, 84.4%)
10/05 07:56:41午前 searchStage_trainer.py:322 [INFO] Valid: [ 44/49] Final Prec@1 56.5000%
10/05 07:56:41午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:56:42午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.1920%
10/05 07:57:11午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5105 (0.4522)	Arch Loss 1.3296 (1.8304)	Arch Hard Loss 1.3244 (1.8252)	Arch Alpha Loss 130.9020 (130.0872)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.5%)	
10/05 07:57:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.4903 (0.4629)	Arch Loss 2.2026 (1.8104)	Arch Hard Loss 2.1974 (1.8052)	Arch Alpha Loss 132.1487 (130.8418)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.5%)	
10/05 07:58:09午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.5301 (0.4689)	Arch Loss 1.6301 (1.8175)	Arch Hard Loss 1.6248 (1.8122)	Arch Alpha Loss 133.7308 (131.5683)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
10/05 07:58:34午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4789 (0.4749)	Arch Loss 1.6959 (1.8085)	Arch Hard Loss 1.6906 (1.8033)	Arch Alpha Loss 134.4759 (132.1564)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
10/05 07:58:35午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 45/49] Final Prec@1 85.8520%
10/05 07:58:39午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7678	Prec@(1,5) (56.8%, 84.2%)
10/05 07:58:44午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7553	Prec@(1,5) (57.2%, 84.3%)
10/05 07:58:48午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7370	Prec@(1,5) (57.2%, 84.6%)
10/05 07:58:52午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7430	Prec@(1,5) (57.2%, 84.6%)
10/05 07:58:52午前 searchStage_trainer.py:322 [INFO] Valid: [ 45/49] Final Prec@1 57.1520%
10/05 07:58:52午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 07:58:52午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.1920%
10/05 07:59:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.4355 (0.4427)	Arch Loss 1.6687 (1.7809)	Arch Hard Loss 1.6632 (1.7755)	Arch Alpha Loss 135.8136 (135.1569)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.9%)	
10/05 07:59:54午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.4600 (0.4553)	Arch Loss 2.3392 (1.7858)	Arch Hard Loss 2.3337 (1.7804)	Arch Alpha Loss 137.1128 (135.7737)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.8%)	
10/05 08:00:23午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.6825 (0.4535)	Arch Loss 1.7407 (1.7904)	Arch Hard Loss 1.7352 (1.7850)	Arch Alpha Loss 137.9291 (136.3393)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
10/05 08:00:51午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.3807 (0.4578)	Arch Loss 1.9077 (1.8109)	Arch Hard Loss 1.9022 (1.8054)	Arch Alpha Loss 139.3304 (136.8637)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
10/05 08:00:51午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 46/49] Final Prec@1 86.5640%
10/05 08:00:56午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7885	Prec@(1,5) (56.6%, 84.0%)
10/05 08:01:00午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7519	Prec@(1,5) (57.0%, 84.8%)
10/05 08:01:04午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7472	Prec@(1,5) (57.1%, 84.8%)
10/05 08:01:08午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7471	Prec@(1,5) (57.1%, 84.8%)
10/05 08:01:08午前 searchStage_trainer.py:322 [INFO] Valid: [ 46/49] Final Prec@1 57.1080%
10/05 08:01:08午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 08:01:09午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.1920%
10/05 08:01:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.4563 (0.4294)	Arch Loss 1.7513 (1.7910)	Arch Hard Loss 1.7457 (1.7854)	Arch Alpha Loss 140.4149 (139.9575)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.7%, 98.9%)	
10/05 08:02:10午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5318 (0.4401)	Arch Loss 2.1801 (1.7954)	Arch Hard Loss 2.1744 (1.7898)	Arch Alpha Loss 141.4081 (140.4445)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.8%)	
10/05 08:02:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.3767 (0.4509)	Arch Loss 2.4088 (1.8034)	Arch Hard Loss 2.4031 (1.7977)	Arch Alpha Loss 142.2958 (140.9425)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.7%)	
10/05 08:03:07午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.4549 (0.4522)	Arch Loss 1.3101 (1.8078)	Arch Hard Loss 1.3044 (1.8021)	Arch Alpha Loss 143.8181 (141.4185)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.6%)	
10/05 08:03:07午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 47/49] Final Prec@1 86.9520%
10/05 08:03:12午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7669	Prec@(1,5) (57.2%, 83.9%)
10/05 08:03:17午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7370	Prec@(1,5) (57.3%, 84.8%)
10/05 08:03:21午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7399	Prec@(1,5) (57.2%, 84.6%)
10/05 08:03:25午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7401	Prec@(1,5) (57.3%, 84.8%)
10/05 08:03:25午前 searchStage_trainer.py:322 [INFO] Valid: [ 47/49] Final Prec@1 57.2880%
10/05 08:03:25午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 08:03:26午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.2880%
10/05 08:03:57午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.3561 (0.4288)	Arch Loss 1.5643 (1.8181)	Arch Hard Loss 1.5585 (1.8124)	Arch Alpha Loss 145.3364 (144.6891)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.7%)	
10/05 08:04:26午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.3696 (0.4351)	Arch Loss 1.3788 (1.8063)	Arch Hard Loss 1.3730 (1.8005)	Arch Alpha Loss 146.2086 (145.2358)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.7%)	
10/05 08:04:55午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3899 (0.4369)	Arch Loss 1.6024 (1.8018)	Arch Hard Loss 1.5966 (1.7960)	Arch Alpha Loss 147.1974 (145.7295)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.7%)	
10/05 08:05:22午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.3769 (0.4407)	Arch Loss 1.2841 (1.8048)	Arch Hard Loss 1.2781 (1.7990)	Arch Alpha Loss 148.1025 (146.1667)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.7%)	
10/05 08:05:22午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 48/49] Final Prec@1 87.1360%
10/05 08:05:27午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7061	Prec@(1,5) (57.9%, 84.4%)
10/05 08:05:32午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7339	Prec@(1,5) (57.1%, 84.6%)
10/05 08:05:36午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7508	Prec@(1,5) (57.1%, 84.5%)
10/05 08:05:40午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7479	Prec@(1,5) (57.1%, 84.5%)
10/05 08:05:40午前 searchStage_trainer.py:322 [INFO] Valid: [ 48/49] Final Prec@1 57.1360%
10/05 08:05:40午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 08:05:41午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.2880%
10/05 08:06:12午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.3951 (0.4331)	Arch Loss 1.4951 (1.7960)	Arch Hard Loss 1.4891 (1.7900)	Arch Alpha Loss 149.6988 (148.9542)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.2%, 99.0%)	
10/05 08:06:43午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5362 (0.4309)	Arch Loss 1.5860 (1.8002)	Arch Hard Loss 1.5800 (1.7943)	Arch Alpha Loss 150.5958 (149.5632)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.9%)	
10/05 08:07:13午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.3984 (0.4302)	Arch Loss 1.5066 (1.7989)	Arch Hard Loss 1.5006 (1.7929)	Arch Alpha Loss 151.6065 (150.0299)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.9%)	
10/05 08:07:40午前 searchStage_ArchKD_trainer.py:165 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.7863 (0.4362)	Arch Loss 1.7254 (1.7977)	Arch Hard Loss 1.7193 (1.7917)	Arch Alpha Loss 152.4080 (150.4793)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.9%)	
10/05 08:07:41午前 searchStage_ArchKD_trainer.py:179 [INFO] Train: [ 49/49] Final Prec@1 87.3120%
10/05 08:07:46午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7507	Prec@(1,5) (56.7%, 84.5%)
10/05 08:07:50午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7228	Prec@(1,5) (57.4%, 84.9%)
10/05 08:07:54午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7525	Prec@(1,5) (57.1%, 84.6%)
10/05 08:07:58午前 searchStage_trainer.py:311 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7602	Prec@(1,5) (57.0%, 84.5%)
10/05 08:07:58午前 searchStage_trainer.py:322 [INFO] Valid: [ 49/49] Final Prec@1 57.0440%
10/05 08:07:58午前 searchStage_KD_main.py:71 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
10/05 08:07:58午前 searchStage_KD_main.py:102 [INFO] Until now, best Prec@1 = 57.2880%
10/05 08:07:59午前 searchStage_KD_main.py:107 [INFO] Final best Prec@1 = 57.2880%
10/05 08:07:59午前 searchStage_KD_main.py:108 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG3_concat=range(6, 8))
