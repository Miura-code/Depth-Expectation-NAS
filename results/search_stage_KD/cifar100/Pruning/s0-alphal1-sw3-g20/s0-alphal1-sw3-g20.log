11/18 01:53:24PM parser.py:28 [INFO] 
11/18 01:53:24PM parser.py:29 [INFO] Parameters:
11/18 01:53:24PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g20/DAG
11/18 01:53:24PM parser.py:31 [INFO] T=10.0
11/18 01:53:24PM parser.py:31 [INFO] ADVANCED=1
11/18 01:53:24PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/18 01:53:24PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/18 01:53:24PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/18 01:53:24PM parser.py:31 [INFO] BATCH_SIZE=64
11/18 01:53:24PM parser.py:31 [INFO] CASCADE=0
11/18 01:53:24PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/18 01:53:24PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/18 01:53:24PM parser.py:31 [INFO] DATA_PATH=../data/
11/18 01:53:24PM parser.py:31 [INFO] DATASET=cifar100
11/18 01:53:24PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/18 01:53:24PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/18 01:53:24PM parser.py:31 [INFO] DISCRETE=0
11/18 01:53:24PM parser.py:31 [INFO] EPOCHS=50
11/18 01:53:24PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/18 01:53:24PM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g20
11/18 01:53:24PM parser.py:31 [INFO] FINAL_L=20.0
11/18 01:53:24PM parser.py:31 [INFO] G=20.0
11/18 01:53:24PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/18 01:53:24PM parser.py:31 [INFO] GPUS=[0]
11/18 01:53:24PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/18 01:53:24PM parser.py:31 [INFO] INIT_CHANNELS=16
11/18 01:53:24PM parser.py:31 [INFO] L=20.0
11/18 01:53:24PM parser.py:31 [INFO] LAYERS=32
11/18 01:53:24PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/18 01:53:24PM parser.py:31 [INFO] NAME=Pruning
11/18 01:53:24PM parser.py:31 [INFO] NONKD=1
11/18 01:53:24PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g20
11/18 01:53:24PM parser.py:31 [INFO] PCDARTS=0
11/18 01:53:24PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g20/plots
11/18 01:53:24PM parser.py:31 [INFO] PRINT_FREQ=100
11/18 01:53:24PM parser.py:31 [INFO] RESET=0
11/18 01:53:24PM parser.py:31 [INFO] RESUME_PATH=None
11/18 01:53:24PM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g20
11/18 01:53:24PM parser.py:31 [INFO] SEED=0
11/18 01:53:24PM parser.py:31 [INFO] SHARE_STAGE=0
11/18 01:53:24PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/18 01:53:24PM parser.py:31 [INFO] SPEC_CELL=1
11/18 01:53:24PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/18 01:53:24PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/18 01:53:24PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/18 01:53:24PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/18 01:53:24PM parser.py:31 [INFO] TYPE=ArchKD
11/18 01:53:24PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/18 01:53:24PM parser.py:31 [INFO] W_LR=0.025
11/18 01:53:24PM parser.py:31 [INFO] W_LR_MIN=0.001
11/18 01:53:24PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/18 01:53:24PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/18 01:53:24PM parser.py:31 [INFO] WORKERS=4
11/18 01:53:24PM parser.py:32 [INFO] 
11/18 01:53:29PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/18 01:53:36PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/18 01:55:15PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6392 (4.7109)	Arch Loss 4.6631 (4.9571)	Arch Hard Loss 4.4456 (4.7189)	Arch Alpha Loss 0.0109 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.5%, 6.4%)	
11/18 01:56:49PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.3318 (4.5702)	Arch Loss 4.5281 (4.8110)	Arch Hard Loss 4.3131 (4.5835)	Arch Alpha Loss 0.0107 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 9.7%)	
11/18 01:58:22PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2565 (4.4817)	Arch Loss 4.5830 (4.7155)	Arch Hard Loss 4.3681 (4.4915)	Arch Alpha Loss 0.0107 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 11.6%)	
11/18 01:59:46PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2228 (4.4148)	Arch Loss 4.2008 (4.6442)	Arch Hard Loss 3.9848 (4.4218)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.2%, 13.4%)	
11/18 01:59:49PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 3.1880%
11/18 02:00:04PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.1286	Prec@(1,5) (5.2%, 19.9%)
11/18 02:00:19PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.1251	Prec@(1,5) (5.2%, 20.2%)
11/18 02:00:34PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.1363	Prec@(1,5) (5.2%, 20.0%)
11/18 02:00:47PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.1301	Prec@(1,5) (5.3%, 20.2%)
11/18 02:00:47PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 5.2840%
11/18 02:00:47PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/18 02:00:48PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 5.2840%
11/18 02:02:22PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.2995 (4.1283)	Arch Loss 4.4995 (4.3233)	Arch Hard Loss 4.2770 (4.1060)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.3%, 20.5%)	
11/18 02:03:56PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.2016 (4.0994)	Arch Loss 4.1641 (4.3147)	Arch Hard Loss 3.9460 (4.0974)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 21.6%)	
11/18 02:05:30PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8424 (4.0765)	Arch Loss 3.9915 (4.2839)	Arch Hard Loss 3.7740 (4.0666)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.8%, 22.2%)	
11/18 02:06:54PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8390 (4.0572)	Arch Loss 4.1293 (4.2596)	Arch Hard Loss 3.9152 (4.0423)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (6.2%, 23.0%)	
11/18 02:06:54PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 6.1720%
11/18 02:07:09PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.8972	Prec@(1,5) (8.5%, 28.4%)
11/18 02:07:24PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.9270	Prec@(1,5) (8.4%, 27.6%)
11/18 02:07:39PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.9219	Prec@(1,5) (8.5%, 27.7%)
11/18 02:07:52PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.9239	Prec@(1,5) (8.5%, 27.6%)
11/18 02:07:52PM searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 8.4800%
11/18 02:07:52PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/18 02:07:52PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.4800%
11/18 02:09:27PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.9663 (3.9253)	Arch Loss 4.2101 (4.1565)	Arch Hard Loss 3.9935 (3.9391)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.3%, 28.0%)	
11/18 02:11:01PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8295 (3.9199)	Arch Loss 3.9076 (4.1257)	Arch Hard Loss 3.6899 (3.9086)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.6%, 27.8%)	
11/18 02:12:35PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 4.1588 (3.9072)	Arch Loss 4.1295 (4.1099)	Arch Hard Loss 3.9149 (3.8928)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.7%, 28.1%)	
11/18 02:13:58PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.8395 (3.8860)	Arch Loss 3.8187 (4.0870)	Arch Hard Loss 3.6041 (3.8699)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (9.2%, 28.9%)	
11/18 02:13:59PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 9.1840%
11/18 02:14:14PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.8387	Prec@(1,5) (9.4%, 32.0%)
11/18 02:14:29PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.8341	Prec@(1,5) (9.5%, 32.0%)
11/18 02:14:43PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.8314	Prec@(1,5) (9.7%, 32.2%)
11/18 02:14:57PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.8280	Prec@(1,5) (9.6%, 32.1%)
11/18 02:14:57PM searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.6280%
11/18 02:14:57PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/18 02:14:57PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.6280%
11/18 02:16:32PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.7079 (3.7841)	Arch Loss 3.7017 (3.9984)	Arch Hard Loss 3.4883 (3.7811)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.0%, 32.7%)	
11/18 02:18:06PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7439 (3.7657)	Arch Loss 3.8894 (3.9716)	Arch Hard Loss 3.6698 (3.7543)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.4%, 33.3%)	
11/18 02:19:40PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.8024 (3.7485)	Arch Loss 4.1360 (3.9571)	Arch Hard Loss 3.9194 (3.7397)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.2%, 33.5%)	
11/18 02:21:04PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6166 (3.7370)	Arch Loss 3.8104 (3.9441)	Arch Hard Loss 3.5927 (3.7267)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.5%, 34.0%)	
11/18 02:21:05PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 11.4680%
11/18 02:21:20PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.6595	Prec@(1,5) (13.3%, 35.9%)
11/18 02:21:34PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.6699	Prec@(1,5) (13.0%, 35.8%)
11/18 02:21:49PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.6606	Prec@(1,5) (12.9%, 36.3%)
11/18 02:22:02PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.6588	Prec@(1,5) (13.1%, 36.5%)
11/18 02:22:02PM searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 13.0760%
11/18 02:22:02PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/18 02:22:03PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.0760%
11/18 02:23:38PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.5711 (3.6004)	Arch Loss 4.0962 (3.8620)	Arch Hard Loss 3.8823 (3.6447)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.7%, 37.6%)	
11/18 02:25:12PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.5723 (3.6114)	Arch Loss 3.7956 (3.8303)	Arch Hard Loss 3.5791 (3.6131)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.5%, 37.3%)	
