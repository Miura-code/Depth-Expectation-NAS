11/17 01:12:26AM parser.py:28 [INFO] 
11/17 01:12:26AM parser.py:29 [INFO] Parameters:
11/17 01:12:26AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-l1-sw3-g15/DAG
11/17 01:12:26AM parser.py:31 [INFO] T=10.0
11/17 01:12:26AM parser.py:31 [INFO] ADVANCED=1
11/17 01:12:26AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/17 01:12:26AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/17 01:12:26AM parser.py:31 [INFO] ARCH_CRITERION=l1
11/17 01:12:26AM parser.py:31 [INFO] BATCH_SIZE=64
11/17 01:12:26AM parser.py:31 [INFO] CASCADE=0
11/17 01:12:26AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/17 01:12:26AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/17 01:12:26AM parser.py:31 [INFO] DATA_PATH=../data/
11/17 01:12:26AM parser.py:31 [INFO] DATASET=cifar100
11/17 01:12:26AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/17 01:12:26AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/17 01:12:26AM parser.py:31 [INFO] DISCRETE=0
11/17 01:12:26AM parser.py:31 [INFO] EPOCHS=50
11/17 01:12:26AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/17 01:12:26AM parser.py:31 [INFO] EXP_NAME=s0-l1-sw3-g15
11/17 01:12:26AM parser.py:31 [INFO] FINAL_L=0.0
11/17 01:12:26AM parser.py:31 [INFO] G=15.0
11/17 01:12:26AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/17 01:12:26AM parser.py:31 [INFO] GPUS=[0]
11/17 01:12:26AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/17 01:12:26AM parser.py:31 [INFO] INIT_CHANNELS=16
11/17 01:12:26AM parser.py:31 [INFO] L=0.0
11/17 01:12:26AM parser.py:31 [INFO] LAYERS=32
11/17 01:12:26AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/17 01:12:26AM parser.py:31 [INFO] NAME=Pruning
11/17 01:12:26AM parser.py:31 [INFO] NONKD=1
11/17 01:12:26AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-l1-sw3-g15
11/17 01:12:26AM parser.py:31 [INFO] PCDARTS=0
11/17 01:12:26AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-l1-sw3-g15/plots
11/17 01:12:26AM parser.py:31 [INFO] PRINT_FREQ=100
11/17 01:12:26AM parser.py:31 [INFO] RESET=0
11/17 01:12:26AM parser.py:31 [INFO] RESUME_PATH=None
11/17 01:12:26AM parser.py:31 [INFO] SAVE=s0-l1-sw3-g15
11/17 01:12:26AM parser.py:31 [INFO] SEED=0
11/17 01:12:26AM parser.py:31 [INFO] SHARE_STAGE=0
11/17 01:12:26AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/17 01:12:26AM parser.py:31 [INFO] SPEC_CELL=1
11/17 01:12:26AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/17 01:12:26AM parser.py:31 [INFO] TEACHER_NAME=none
11/17 01:12:26AM parser.py:31 [INFO] TEACHER_PATH=none
11/17 01:12:26AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/17 01:12:26AM parser.py:31 [INFO] TYPE=Pruning
11/17 01:12:26AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/17 01:12:26AM parser.py:31 [INFO] W_LR=0.025
11/17 01:12:26AM parser.py:31 [INFO] W_LR_MIN=0.001
11/17 01:12:26AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/17 01:12:26AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/17 01:12:26AM parser.py:31 [INFO] WORKERS=4
11/17 01:12:26AM parser.py:32 [INFO] 
11/17 01:12:33AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/17 01:14:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.4194 (4.5274)	Arch Loss 4.4220 (4.5996)	Arch Hard Loss 4.3652 (4.5317)	Arch Beta Loss 0.0038 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 10.1%)	
11/17 01:16:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2048 (4.3997)	Arch Loss 4.1941 (4.4634)	Arch Hard Loss 4.1409 (4.4023)	Arch Beta Loss 0.0035 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.3%, 14.0%)	
11/17 01:18:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.1288 (4.2932)	Arch Loss 4.1298 (4.3558)	Arch Hard Loss 4.0717 (4.2971)	Arch Beta Loss 0.0039 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.5%, 17.0%)	
11/17 01:20:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9720 (4.2261)	Arch Loss 3.9461 (4.2812)	Arch Hard Loss 3.8941 (4.2237)	Arch Beta Loss 0.0035 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.1%, 19.1%)	
11/17 01:20:28AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  0/49] Final Prec@1 5.1440%
11/17 01:20:49AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9732	Prec@(1,5) (8.5%, 26.8%)
11/17 01:21:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9577	Prec@(1,5) (8.5%, 27.2%)
11/17 01:21:30AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9646	Prec@(1,5) (8.3%, 27.3%)
11/17 01:21:48AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9627	Prec@(1,5) (8.3%, 27.5%)
11/17 01:21:48AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 8.2800%
11/17 01:21:48AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[5, 10])
11/17 01:21:49AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.2800%
11/17 01:23:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8906 (3.9015)	Arch Loss 4.0424 (3.9474)	Arch Hard Loss 3.9897 (3.8936)	Arch Beta Loss 0.0035 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.4%, 28.9%)	
11/17 01:25:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.8348 (3.8680)	Arch Loss 3.9127 (3.9092)	Arch Hard Loss 3.8594 (3.8555)	Arch Beta Loss 0.0035 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.0%, 30.3%)	
11/17 01:27:49AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7381 (3.8375)	Arch Loss 3.6490 (3.8761)	Arch Hard Loss 3.5962 (3.8224)	Arch Beta Loss 0.0035 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.6%, 31.3%)	
11/17 01:29:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8234 (3.7991)	Arch Loss 4.1852 (3.8475)	Arch Hard Loss 4.1297 (3.7939)	Arch Beta Loss 0.0037 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.2%, 32.6%)	
11/17 01:29:38AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  1/49] Final Prec@1 10.2280%
11/17 01:29:59AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.7146	Prec@(1,5) (12.2%, 36.1%)
11/17 01:30:19AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.7070	Prec@(1,5) (12.4%, 35.9%)
11/17 01:30:39AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.7042	Prec@(1,5) (12.3%, 35.9%)
11/17 01:30:58AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.7014	Prec@(1,5) (12.3%, 36.1%)
11/17 01:30:58AM searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 12.2520%
11/17 01:30:58AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[7, 10], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[6, 8])
11/17 01:30:59AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.2520%
11/17 01:32:59AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.7177 (3.6305)	Arch Loss 3.6332 (3.6867)	Arch Hard Loss 3.5791 (3.6330)	Arch Beta Loss 0.0036 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.3%, 37.3%)	
11/17 01:34:58AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5844 (3.5981)	Arch Loss 3.5110 (3.6576)	Arch Hard Loss 3.4602 (3.6038)	Arch Beta Loss 0.0034 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.9%, 38.7%)	
11/17 01:36:59AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.4260 (3.5680)	Arch Loss 3.4056 (3.6225)	Arch Hard Loss 3.3561 (3.5688)	Arch Beta Loss 0.0033 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.5%, 39.7%)	
11/17 01:38:47AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.5063 (3.5448)	Arch Loss 3.3389 (3.5991)	Arch Hard Loss 3.2792 (3.5454)	Arch Beta Loss 0.0040 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 40.2%)	
11/17 01:38:48AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  2/49] Final Prec@1 14.9400%
11/17 01:39:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.5564	Prec@(1,5) (15.1%, 41.7%)
11/17 01:39:29AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.5679	Prec@(1,5) (15.0%, 41.2%)
11/17 01:39:49AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.5654	Prec@(1,5) (15.0%, 41.3%)
11/17 01:40:07AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.5666	Prec@(1,5) (15.2%, 41.4%)
11/17 01:40:07AM searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 15.2040%
11/17 01:40:08AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[6, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[5, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 4])
11/17 01:40:08AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 15.2040%
11/17 01:42:08AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.6656 (3.4062)	Arch Loss 3.3745 (3.4559)	Arch Hard Loss 3.3232 (3.4026)	Arch Beta Loss 0.0034 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.0%, 44.6%)	
11/17 01:44:08AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1027 (3.3658)	Arch Loss 3.7782 (3.4247)	Arch Hard Loss 3.7282 (3.3715)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.8%, 45.9%)	
11/17 01:46:08AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1885 (3.3333)	Arch Loss 3.4489 (3.3981)	Arch Hard Loss 3.3971 (3.3449)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.5%, 46.6%)	
11/17 01:47:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.0162 (3.3097)	Arch Loss 3.1738 (3.3769)	Arch Hard Loss 3.1179 (3.3237)	Arch Beta Loss 0.0037 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.9%, 47.2%)	
11/17 01:47:56AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  3/49] Final Prec@1 18.9320%
11/17 01:48:17AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2539	Prec@(1,5) (20.9%, 48.7%)
11/17 01:48:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2495	Prec@(1,5) (20.5%, 48.9%)
11/17 01:48:58AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2524	Prec@(1,5) (20.5%, 49.1%)
11/17 01:49:16AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2545	Prec@(1,5) (20.5%, 49.1%)
11/17 01:49:16AM searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 20.4640%
11/17 01:49:16AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[9, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[5, 8])
11/17 01:49:17AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.4640%
11/17 01:51:18AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.2184 (3.1514)	Arch Loss 3.1032 (3.2804)	Arch Hard Loss 3.0481 (3.2279)	Arch Beta Loss 0.0037 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 51.8%)	
11/17 01:53:18AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.0997 (3.1357)	Arch Loss 3.0468 (3.2460)	Arch Hard Loss 2.9954 (3.1938)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 51.9%)	
11/17 01:55:17AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.7184 (3.1249)	Arch Loss 3.1703 (3.2237)	Arch Hard Loss 3.1184 (3.1715)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.5%, 52.1%)	
11/17 01:57:05AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.0522 (3.1179)	Arch Loss 2.9008 (3.1989)	Arch Hard Loss 2.8501 (3.1468)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 52.3%)	
11/17 01:57:06AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  4/49] Final Prec@1 22.6120%
11/17 01:57:27AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1163	Prec@(1,5) (22.3%, 53.6%)
11/17 01:57:47AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0754	Prec@(1,5) (23.1%, 54.5%)
11/17 01:58:07AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0727	Prec@(1,5) (23.2%, 54.7%)
11/17 01:58:25AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0742	Prec@(1,5) (23.4%, 54.6%)
11/17 01:58:26AM searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 23.3800%
11/17 01:58:26AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[6, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 8])
11/17 01:58:26AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.3800%
11/17 02:00:27AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.1639 (2.9517)	Arch Loss 3.0768 (3.0679)	Arch Hard Loss 3.0247 (3.0158)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.4%, 55.9%)	
11/17 02:02:26AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.1580 (2.9500)	Arch Loss 3.4040 (3.0762)	Arch Hard Loss 3.3531 (3.0241)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.0%)	
11/17 02:04:26AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8362 (2.9483)	Arch Loss 2.7959 (3.0624)	Arch Hard Loss 2.7410 (3.0103)	Arch Beta Loss 0.0037 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.6%, 56.2%)	
11/17 02:06:15AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.7386 (2.9377)	Arch Loss 2.9806 (3.0441)	Arch Hard Loss 2.9277 (2.9919)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.6%)	
11/17 02:06:16AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  5/49] Final Prec@1 25.6600%
11/17 02:06:36AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.9640	Prec@(1,5) (25.0%, 57.3%)
11/17 02:06:56AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.9623	Prec@(1,5) (25.1%, 57.3%)
11/17 02:07:17AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.9629	Prec@(1,5) (25.2%, 57.3%)
11/17 02:07:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.9544	Prec@(1,5) (25.4%, 57.4%)
11/17 02:07:35AM searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 25.3480%
11/17 02:07:36AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[7, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 10])
11/17 02:07:36AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.3480%
11/17 02:09:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.7379 (2.7912)	Arch Loss 2.9526 (2.9465)	Arch Hard Loss 2.9047 (2.8944)	Arch Beta Loss 0.0032 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.8%, 60.2%)	
11/17 02:11:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.9886 (2.8047)	Arch Loss 3.0685 (2.9373)	Arch Hard Loss 3.0202 (2.8851)	Arch Beta Loss 0.0032 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.2%, 60.2%)	
11/17 02:13:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.9362 (2.7954)	Arch Loss 2.8341 (2.9160)	Arch Hard Loss 2.7841 (2.8638)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.3%, 60.3%)	
11/17 02:15:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.9453 (2.7908)	Arch Loss 2.9287 (2.9183)	Arch Hard Loss 2.8689 (2.8661)	Arch Beta Loss 0.0040 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.7%, 60.5%)	
11/17 02:15:26AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  6/49] Final Prec@1 28.7000%
11/17 02:15:46AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.8069	Prec@(1,5) (29.6%, 60.2%)
11/17 02:16:05AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7961	Prec@(1,5) (29.7%, 60.6%)
11/17 02:16:25AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7964	Prec@(1,5) (29.6%, 60.8%)
11/17 02:16:44AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.8094	Prec@(1,5) (29.2%, 60.4%)
11/17 02:16:44AM searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 29.2360%
11/17 02:16:44AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[8, 9], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[6, 10])
11/17 02:16:45AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.2360%
11/17 02:18:46AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.8890 (2.6390)	Arch Loss 2.7197 (2.8397)	Arch Hard Loss 2.6664 (2.7881)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 64.7%)	
11/17 02:20:46AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.6708 (2.6506)	Arch Loss 2.7345 (2.8238)	Arch Hard Loss 2.6815 (2.7724)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 64.2%)	
11/17 02:22:46AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.9265 (2.6501)	Arch Loss 3.1199 (2.8216)	Arch Hard Loss 3.0685 (2.7704)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.3%, 64.1%)	
11/17 02:24:33AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.6674 (2.6417)	Arch Loss 2.8505 (2.7977)	Arch Hard Loss 2.8008 (2.7466)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 64.2%)	
11/17 02:24:34AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  7/49] Final Prec@1 31.4000%
11/17 02:24:55AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6994	Prec@(1,5) (30.2%, 62.3%)
11/17 02:25:15AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6765	Prec@(1,5) (30.8%, 63.1%)
11/17 02:25:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6744	Prec@(1,5) (31.1%, 63.3%)
11/17 02:25:54AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6849	Prec@(1,5) (31.0%, 63.0%)
11/17 02:25:54AM searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 31.0160%
11/17 02:25:54AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[9, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 10])
11/17 02:25:54AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.0160%
11/17 02:27:56AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.3885 (2.5354)	Arch Loss 2.8721 (2.7194)	Arch Hard Loss 2.8181 (2.6690)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.4%, 66.0%)	
11/17 02:29:56AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.1798 (2.5265)	Arch Loss 3.0036 (2.7082)	Arch Hard Loss 2.9537 (2.6577)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.6%, 66.6%)	
11/17 02:31:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.4741 (2.5277)	Arch Loss 2.7743 (2.7059)	Arch Hard Loss 2.7197 (2.6556)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.7%, 66.8%)	
11/17 02:33:43AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.2621 (2.5202)	Arch Loss 2.9290 (2.6926)	Arch Hard Loss 2.8835 (2.6424)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 67.0%)	
11/17 02:33:44AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  8/49] Final Prec@1 33.8480%
11/17 02:34:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5779	Prec@(1,5) (33.5%, 65.5%)
11/17 02:34:25AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5846	Prec@(1,5) (33.2%, 65.6%)
11/17 02:34:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5980	Prec@(1,5) (33.2%, 65.1%)
11/17 02:35:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5956	Prec@(1,5) (33.1%, 65.0%)
11/17 02:35:04AM searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 33.1560%
11/17 02:35:04AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[7, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
11/17 02:35:04AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.1560%
11/17 02:37:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.4519 (2.4180)	Arch Loss 2.9348 (2.6563)	Arch Hard Loss 2.8865 (2.6068)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.8%, 69.0%)	
11/17 02:39:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.5236 (2.4326)	Arch Loss 2.7097 (2.6346)	Arch Hard Loss 2.6588 (2.5849)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 69.1%)	
11/17 02:41:05AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.3595 (2.4205)	Arch Loss 2.5586 (2.6220)	Arch Hard Loss 2.5100 (2.5723)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 69.1%)	
11/17 02:42:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.2181 (2.4114)	Arch Loss 2.6234 (2.6152)	Arch Hard Loss 2.5703 (2.5655)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.4%)	
11/17 02:42:54AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  9/49] Final Prec@1 36.3680%
11/17 02:43:14AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.5798	Prec@(1,5) (33.3%, 66.5%)
11/17 02:43:34AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.5698	Prec@(1,5) (33.3%, 66.5%)
11/17 02:43:55AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.5828	Prec@(1,5) (33.1%, 66.2%)
11/17 02:44:12AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.5817	Prec@(1,5) (33.2%, 66.1%)
11/17 02:44:12AM searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 33.1720%
11/17 02:44:12AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 7])
11/17 02:44:12AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.1720%
11/17 02:46:14AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.7074 (2.2930)	Arch Loss 2.7257 (2.5745)	Arch Hard Loss 2.6716 (2.5248)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 71.8%)	
11/17 02:48:14AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4950 (2.3141)	Arch Loss 2.4055 (2.5508)	Arch Hard Loss 2.3539 (2.5010)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 71.6%)	
11/17 02:50:14AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.4469 (2.3219)	Arch Loss 2.3398 (2.5419)	Arch Hard Loss 2.2901 (2.4921)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 71.4%)	
11/17 02:52:01AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.4993 (2.3165)	Arch Loss 2.4607 (2.5279)	Arch Hard Loss 2.4130 (2.4781)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.6%)	
11/17 02:52:02AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 10/49] Final Prec@1 38.4680%
11/17 02:52:23AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4504	Prec@(1,5) (36.3%, 68.7%)
11/17 02:52:43AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.4243	Prec@(1,5) (36.1%, 69.1%)
11/17 02:53:03AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.4356	Prec@(1,5) (36.0%, 68.9%)
11/17 02:53:22AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.4313	Prec@(1,5) (36.2%, 69.0%)
11/17 02:53:22AM searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 36.2200%
11/17 02:53:22AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[6, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 11])
11/17 02:53:23AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.2200%
11/17 02:55:24AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.1277 (2.1957)	Arch Loss 2.8916 (2.4681)	Arch Hard Loss 2.8416 (2.4182)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 74.5%)	
11/17 02:57:24AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.6689 (2.2011)	Arch Loss 2.8266 (2.4646)	Arch Hard Loss 2.7817 (2.4147)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 73.9%)	
11/17 02:59:23AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.1487 (2.2034)	Arch Loss 2.2206 (2.4571)	Arch Hard Loss 2.1686 (2.4072)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.3%, 73.6%)	
11/17 03:01:11AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.0773 (2.2119)	Arch Loss 2.5887 (2.4530)	Arch Hard Loss 2.5343 (2.4030)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 73.5%)	
11/17 03:01:12AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 11/49] Final Prec@1 40.1640%
11/17 03:01:33AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3807	Prec@(1,5) (38.1%, 70.6%)
11/17 03:01:53AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3664	Prec@(1,5) (38.1%, 70.6%)
11/17 03:02:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3580	Prec@(1,5) (38.0%, 70.7%)
11/17 03:02:32AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3561	Prec@(1,5) (38.2%, 70.8%)
11/17 03:02:32AM searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 38.1920%
11/17 03:02:32AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[4, 8], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 11])
11/17 03:02:32AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.1920%
11/17 03:04:33AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.9667 (2.0910)	Arch Loss 2.1544 (2.4008)	Arch Hard Loss 2.1060 (2.3506)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.5%, 75.9%)	
11/17 03:06:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.2458 (2.1201)	Arch Loss 2.1722 (2.4072)	Arch Hard Loss 2.1170 (2.3567)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.5%)	
11/17 03:08:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.1892 (2.1250)	Arch Loss 2.5232 (2.4018)	Arch Hard Loss 2.4730 (2.3512)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.5%)	
11/17 03:10:21AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.7683 (2.1293)	Arch Loss 2.2264 (2.3879)	Arch Hard Loss 2.1724 (2.3372)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 75.4%)	
11/17 03:10:22AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 12/49] Final Prec@1 42.5560%
11/17 03:10:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2864	Prec@(1,5) (40.2%, 72.1%)
11/17 03:11:03AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2850	Prec@(1,5) (39.8%, 72.1%)
11/17 03:11:23AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2831	Prec@(1,5) (40.0%, 72.0%)
11/17 03:11:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2898	Prec@(1,5) (39.9%, 71.8%)
11/17 03:11:41AM searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 39.9000%
11/17 03:11:41AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 10], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 11])
11/17 03:11:42AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.9000%
11/17 03:13:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.2010 (2.0020)	Arch Loss 2.3531 (2.3500)	Arch Hard Loss 2.3016 (2.2996)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 78.4%)	
11/17 03:15:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.7448 (2.0542)	Arch Loss 2.4089 (2.3453)	Arch Hard Loss 2.3597 (2.2949)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 77.3%)	
11/17 03:17:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.9021 (2.0491)	Arch Loss 2.3007 (2.3449)	Arch Hard Loss 2.2543 (2.2945)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.1%, 77.2%)	
11/17 03:19:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.8802 (2.0556)	Arch Loss 2.2172 (2.3342)	Arch Hard Loss 2.1712 (2.2838)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.9%)	
11/17 03:19:30AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 13/49] Final Prec@1 43.9320%
11/17 03:19:51AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2404	Prec@(1,5) (41.5%, 72.5%)
11/17 03:20:11AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2590	Prec@(1,5) (40.5%, 72.4%)
11/17 03:20:32AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2428	Prec@(1,5) (40.8%, 72.8%)
11/17 03:20:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2455	Prec@(1,5) (40.6%, 73.0%)
11/17 03:20:50AM searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 40.5800%
11/17 03:20:50AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[9, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[5, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 10])
11/17 03:20:51AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.5800%
11/17 03:22:52AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8934 (1.9293)	Arch Loss 2.3409 (2.3152)	Arch Hard Loss 2.2842 (2.2646)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 79.4%)	
11/17 03:24:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.0333 (1.9656)	Arch Loss 2.3648 (2.3156)	Arch Hard Loss 2.3154 (2.2651)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 78.5%)	
11/17 03:26:51AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.1416 (1.9697)	Arch Loss 2.3510 (2.3048)	Arch Hard Loss 2.2992 (2.2542)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.4%)	
11/17 03:28:40AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.9365 (1.9738)	Arch Loss 2.3387 (2.2996)	Arch Hard Loss 2.2878 (2.2489)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.4%)	
11/17 03:28:40AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 14/49] Final Prec@1 45.7920%
11/17 03:29:01AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1751	Prec@(1,5) (42.1%, 74.2%)
11/17 03:29:21AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.2010	Prec@(1,5) (42.0%, 73.7%)
11/17 03:29:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.2020	Prec@(1,5) (41.8%, 73.6%)
11/17 03:30:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.2001	Prec@(1,5) (41.6%, 73.7%)
11/17 03:30:00AM searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 41.6560%
11/17 03:30:00AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[6, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 11])
11/17 03:30:01AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.6560%
11/17 03:32:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.3204 (1.8625)	Arch Loss 2.0957 (2.2688)	Arch Hard Loss 2.0479 (2.2181)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.4%)	
11/17 03:34:01AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.7591 (1.8846)	Arch Loss 2.1366 (2.2796)	Arch Hard Loss 2.0850 (2.2289)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.3%, 79.9%)	
11/17 03:36:01AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0381 (1.8869)	Arch Loss 2.1973 (2.2675)	Arch Hard Loss 2.1455 (2.2169)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 80.0%)	
11/17 03:37:49AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.6675 (1.8959)	Arch Loss 2.1207 (2.2578)	Arch Hard Loss 2.0719 (2.2072)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.8%)	
11/17 03:37:50AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 15/49] Final Prec@1 47.8440%
11/17 03:38:11AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1937	Prec@(1,5) (41.6%, 75.1%)
11/17 03:38:31AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1731	Prec@(1,5) (42.1%, 74.8%)
11/17 03:38:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1820	Prec@(1,5) (42.0%, 74.5%)
11/17 03:39:10AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1771	Prec@(1,5) (42.1%, 74.7%)
11/17 03:39:10AM searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 42.0960%
11/17 03:39:10AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 9])
11/17 03:39:11AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.0960%
11/17 03:41:10AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7919 (1.8022)	Arch Loss 1.9408 (2.2132)	Arch Hard Loss 1.8915 (2.1629)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.0%, 81.6%)	
11/17 03:43:11AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.0177 (1.8273)	Arch Loss 2.4151 (2.2169)	Arch Hard Loss 2.3592 (2.1664)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.4%, 81.1%)	
11/17 03:45:11AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.8783 (1.8379)	Arch Loss 2.3120 (2.2277)	Arch Hard Loss 2.2632 (2.1771)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 81.2%)	
11/17 03:46:59AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7871 (1.8412)	Arch Loss 2.1828 (2.2155)	Arch Hard Loss 2.1316 (2.1649)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 81.1%)	
11/17 03:47:00AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 16/49] Final Prec@1 48.7360%
11/17 03:47:21AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1687	Prec@(1,5) (43.2%, 75.2%)
11/17 03:47:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1451	Prec@(1,5) (43.2%, 75.3%)
11/17 03:48:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1437	Prec@(1,5) (43.2%, 75.4%)
11/17 03:48:19AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1379	Prec@(1,5) (43.3%, 75.3%)
11/17 03:48:19AM searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 43.3400%
11/17 03:48:19AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 10])
11/17 03:48:20AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3400%
11/17 03:50:21AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.6710 (1.7077)	Arch Loss 2.4085 (2.1751)	Arch Hard Loss 2.3567 (2.1243)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.1%)	
11/17 03:52:21AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.6889 (1.7395)	Arch Loss 2.1514 (2.1729)	Arch Hard Loss 2.1035 (2.1219)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.5%)	
11/17 03:54:21AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.9848 (1.7603)	Arch Loss 1.9978 (2.1818)	Arch Hard Loss 1.9454 (2.1307)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.9%, 82.2%)	
11/17 03:56:09AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.5553 (1.7757)	Arch Loss 2.1647 (2.1817)	Arch Hard Loss 2.1133 (2.1306)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.4%, 82.0%)	
11/17 03:56:09AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 17/49] Final Prec@1 50.3680%
11/17 03:56:30AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0693	Prec@(1,5) (44.5%, 76.3%)
11/17 03:56:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0567	Prec@(1,5) (45.3%, 76.6%)
11/17 03:57:11AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0732	Prec@(1,5) (44.9%, 76.2%)
11/17 03:57:29AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0690	Prec@(1,5) (44.9%, 76.1%)
11/17 03:57:29AM searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 44.9280%
11/17 03:57:29AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[8, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/17 03:57:30AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.9280%
11/17 03:59:31AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.5954 (1.6533)	Arch Loss 2.1443 (2.1375)	Arch Hard Loss 2.0921 (2.0867)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.7%, 83.5%)	
11/17 04:01:31AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.3813 (1.6955)	Arch Loss 1.9500 (2.1530)	Arch Hard Loss 1.8986 (2.1023)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.6%, 82.9%)	
11/17 04:03:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6497 (1.7073)	Arch Loss 2.2683 (2.1638)	Arch Hard Loss 2.2164 (2.1131)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.3%, 83.0%)	
11/17 04:05:19AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.8686 (1.7161)	Arch Loss 1.4322 (2.1518)	Arch Hard Loss 1.3842 (2.1011)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.0%, 82.9%)	
11/17 04:05:20AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 18/49] Final Prec@1 51.9880%
11/17 04:05:40AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0933	Prec@(1,5) (44.3%, 75.8%)
11/17 04:06:01AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0852	Prec@(1,5) (44.5%, 76.2%)
11/17 04:06:21AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0770	Prec@(1,5) (45.0%, 76.4%)
11/17 04:06:39AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0806	Prec@(1,5) (44.7%, 76.4%)
11/17 04:06:39AM searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 44.7400%
11/17 04:06:40AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 11])
11/17 04:06:40AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.9280%
11/17 04:08:41AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.2302 (1.6061)	Arch Loss 2.3441 (2.1487)	Arch Hard Loss 2.2940 (2.0983)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.1%)	
11/17 04:10:40AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.8328 (1.6357)	Arch Loss 2.3890 (2.1365)	Arch Hard Loss 2.3408 (2.0863)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.8%, 84.5%)	
11/17 04:12:40AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.8680 (1.6446)	Arch Loss 1.8248 (2.1211)	Arch Hard Loss 1.7753 (2.0709)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.4%)	
11/17 04:14:28AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.6481 (1.6571)	Arch Loss 2.0694 (2.1165)	Arch Hard Loss 2.0237 (2.0664)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.4%, 84.1%)	
11/17 04:14:29AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 19/49] Final Prec@1 53.3960%
11/17 04:14:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.1290	Prec@(1,5) (43.6%, 75.2%)
11/17 04:15:10AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.1248	Prec@(1,5) (44.1%, 75.4%)
11/17 04:15:30AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.1051	Prec@(1,5) (44.8%, 75.7%)
11/17 04:15:49AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0958	Prec@(1,5) (44.8%, 76.0%)
11/17 04:15:49AM searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 44.8280%
11/17 04:15:49AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[9, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[8, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 9])
11/17 04:15:49AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.9280%
11/17 04:17:31AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.7313 (1.5569)	Arch Loss 2.0832 (2.1110)	Arch Hard Loss 2.0305 (2.0609)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 86.0%)	
11/17 04:19:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.6636 (1.5726)	Arch Loss 2.7716 (2.1042)	Arch Hard Loss 2.7201 (2.0539)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.8%)	
11/17 04:21:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.2262 (1.5869)	Arch Loss 1.7490 (2.0956)	Arch Hard Loss 1.7003 (2.0452)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.5%)	
11/17 04:23:20AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6728 (1.6116)	Arch Loss 1.8355 (2.0921)	Arch Hard Loss 1.7830 (2.0416)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.9%)	
11/17 04:23:21AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 20/49] Final Prec@1 54.5280%
11/17 04:23:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0148	Prec@(1,5) (46.4%, 77.8%)
11/17 04:24:02AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0020	Prec@(1,5) (46.5%, 77.9%)
11/17 04:24:20AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0031	Prec@(1,5) (46.6%, 77.8%)
11/17 04:24:38AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0079	Prec@(1,5) (46.5%, 77.6%)
11/17 04:24:38AM searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 46.4880%
11/17 04:24:38AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[7, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[4, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 10])
11/17 04:24:39AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.4880%
11/17 04:26:38AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.7780 (1.4803)	Arch Loss 2.4309 (2.0951)	Arch Hard Loss 2.3794 (2.0436)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.5%)	
11/17 04:28:39AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3544 (1.5091)	Arch Loss 2.2124 (2.0858)	Arch Hard Loss 2.1610 (2.0343)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.5%)	
11/17 04:30:39AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.6876 (1.5337)	Arch Loss 1.8893 (2.0741)	Arch Hard Loss 1.8421 (2.0225)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.0%)	
11/17 04:32:27AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.5513 (1.5483)	Arch Loss 1.8792 (2.0766)	Arch Hard Loss 1.8271 (2.0248)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.6%)	
11/17 04:32:28AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 21/49] Final Prec@1 55.9920%
11/17 04:32:49AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9968	Prec@(1,5) (47.0%, 77.5%)
11/17 04:33:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9922	Prec@(1,5) (46.9%, 77.9%)
11/17 04:33:29AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9945	Prec@(1,5) (46.9%, 77.7%)
11/17 04:33:47AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9927	Prec@(1,5) (47.0%, 77.7%)
11/17 04:33:48AM searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 47.0520%
11/17 04:33:48AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[5, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[8, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 8])
11/17 04:33:48AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0520%
11/17 04:35:48AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.4516 (1.4218)	Arch Loss 2.2392 (2.0788)	Arch Hard Loss 2.1846 (2.0264)	Arch Beta Loss 0.0036 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.9%)	
11/17 04:37:48AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.5786 (1.4580)	Arch Loss 2.0250 (2.0475)	Arch Hard Loss 1.9738 (1.9951)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.2%, 87.4%)	
11/17 04:39:49AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.2756 (1.4818)	Arch Loss 2.4791 (2.0474)	Arch Hard Loss 2.4269 (1.9952)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.9%)	
11/17 04:41:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7547 (1.4983)	Arch Loss 1.9652 (2.0530)	Arch Hard Loss 1.9128 (2.0009)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.6%)	
11/17 04:41:38AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 22/49] Final Prec@1 57.3240%
11/17 04:41:58AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9991	Prec@(1,5) (46.9%, 77.8%)
11/17 04:42:19AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9937	Prec@(1,5) (46.7%, 78.0%)
11/17 04:42:39AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9895	Prec@(1,5) (46.8%, 78.1%)
11/17 04:42:57AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9976	Prec@(1,5) (46.7%, 78.0%)
11/17 04:42:57AM searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 46.7000%
11/17 04:42:57AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[6, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 04:42:58AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0520%
11/17 04:44:57AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4338 (1.3532)	Arch Loss 1.7513 (2.0352)	Arch Hard Loss 1.7033 (1.9830)	Arch Beta Loss 0.0032 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 89.2%)	
11/17 04:46:57AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.2311 (1.4026)	Arch Loss 2.3617 (2.0282)	Arch Hard Loss 2.3091 (1.9759)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.3%, 88.3%)	
11/17 04:48:58AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.5742 (1.4231)	Arch Loss 1.8611 (2.0429)	Arch Hard Loss 1.8119 (1.9905)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.9%)	
11/17 04:50:46AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3360 (1.4383)	Arch Loss 2.2349 (2.0367)	Arch Hard Loss 2.1804 (1.9843)	Arch Beta Loss 0.0036 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.7%)	
11/17 04:50:47AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 23/49] Final Prec@1 58.6440%
11/17 04:51:07AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9162	Prec@(1,5) (49.6%, 78.9%)
11/17 04:51:28AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9201	Prec@(1,5) (49.0%, 79.4%)
11/17 04:51:48AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9320	Prec@(1,5) (48.9%, 79.2%)
11/17 04:52:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9366	Prec@(1,5) (48.8%, 79.3%)
11/17 04:52:06AM searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 48.7880%
11/17 04:52:06AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[9, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/17 04:52:07AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.7880%
11/17 04:54:06AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0821 (1.3497)	Arch Loss 2.1588 (2.0260)	Arch Hard Loss 2.1060 (1.9738)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.5%)	
11/17 04:56:07AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3529 (1.3655)	Arch Loss 2.2921 (2.0300)	Arch Hard Loss 2.2357 (1.9778)	Arch Beta Loss 0.0038 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.5%)	
11/17 04:58:07AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6293 (1.3795)	Arch Loss 1.9313 (2.0287)	Arch Hard Loss 1.8726 (1.9765)	Arch Beta Loss 0.0039 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.3%)	
11/17 04:59:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2707 (1.3927)	Arch Loss 1.8018 (2.0307)	Arch Hard Loss 1.7503 (1.9786)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.1%)	
11/17 04:59:56AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 24/49] Final Prec@1 59.8160%
11/17 05:00:17AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9662	Prec@(1,5) (48.4%, 79.1%)
11/17 05:00:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9592	Prec@(1,5) (48.9%, 79.2%)
11/17 05:00:57AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9693	Prec@(1,5) (48.4%, 78.9%)
11/17 05:01:15AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9593	Prec@(1,5) (48.4%, 79.1%)
11/17 05:01:15AM searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 48.3800%
11/17 05:01:15AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[6, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 8])
11/17 05:01:16AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.7880%
11/17 05:03:15AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.4252 (1.3069)	Arch Loss 2.0075 (1.9806)	Arch Hard Loss 1.9531 (1.9290)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.4%)	
11/17 05:05:16AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3907 (1.3144)	Arch Loss 2.3286 (1.9902)	Arch Hard Loss 2.2831 (1.9387)	Arch Beta Loss 0.0030 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.3%)	
11/17 05:07:16AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.1710 (1.3268)	Arch Loss 1.3259 (2.0008)	Arch Hard Loss 1.2742 (1.9494)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.1%)	
11/17 05:09:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.1509 (1.3404)	Arch Loss 1.8494 (1.9979)	Arch Hard Loss 1.7988 (1.9466)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.0%)	
11/17 05:09:05AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 25/49] Final Prec@1 61.3520%
11/17 05:09:26AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9069	Prec@(1,5) (49.6%, 80.0%)
11/17 05:09:46AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9117	Prec@(1,5) (49.5%, 79.8%)
11/17 05:10:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9027	Prec@(1,5) (49.6%, 79.8%)
11/17 05:10:25AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9064	Prec@(1,5) (49.4%, 79.7%)
11/17 05:10:25AM searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 49.4160%
11/17 05:10:25AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[8, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[6, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/17 05:10:26AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.4160%
11/17 05:12:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5679 (1.2474)	Arch Loss 1.7015 (1.9397)	Arch Hard Loss 1.6481 (1.8884)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.3%)	
11/17 05:14:26AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.8804 (1.2766)	Arch Loss 1.9680 (1.9691)	Arch Hard Loss 1.9177 (1.9177)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.0%)	
11/17 05:16:26AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2268 (1.2815)	Arch Loss 1.7071 (1.9797)	Arch Hard Loss 1.6567 (1.9282)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 90.1%)	
11/17 05:18:14AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.1539 (1.2995)	Arch Loss 2.2656 (1.9878)	Arch Hard Loss 2.2132 (1.9364)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.7%)	
11/17 05:18:15AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 26/49] Final Prec@1 62.1000%
11/17 05:18:36AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8999	Prec@(1,5) (50.0%, 80.3%)
11/17 05:18:56AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8903	Prec@(1,5) (50.2%, 80.3%)
11/17 05:19:16AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8943	Prec@(1,5) (49.8%, 80.3%)
11/17 05:19:34AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8958	Prec@(1,5) (49.7%, 80.1%)
11/17 05:19:35AM searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 49.6480%
11/17 05:19:35AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[6, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 8])
11/17 05:19:35AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6480%
11/17 05:21:35AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0717 (1.1691)	Arch Loss 2.3886 (1.9880)	Arch Hard Loss 2.3346 (1.9370)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.4%)	
11/17 05:23:35AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.4805 (1.2024)	Arch Loss 1.6015 (1.9689)	Arch Hard Loss 1.5505 (1.9178)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.9%)	
11/17 05:25:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 0.9066 (1.2090)	Arch Loss 2.2778 (1.9712)	Arch Hard Loss 2.2238 (1.9202)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.8%)	
11/17 05:27:24AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.0616 (1.2292)	Arch Loss 1.7864 (1.9734)	Arch Hard Loss 1.7383 (1.9223)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.6%)	
11/17 05:27:25AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 27/49] Final Prec@1 64.1640%
11/17 05:27:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9067	Prec@(1,5) (50.4%, 79.9%)
11/17 05:28:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8936	Prec@(1,5) (50.5%, 80.2%)
11/17 05:28:26AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.9030	Prec@(1,5) (50.2%, 79.8%)
11/17 05:28:44AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8982	Prec@(1,5) (50.2%, 80.0%)
11/17 05:28:44AM searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 50.2240%
11/17 05:28:44AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[6, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[6, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 8])
11/17 05:28:45AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.2240%
11/17 05:30:45AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.3726 (1.1409)	Arch Loss 1.8495 (1.9235)	Arch Hard Loss 1.8018 (1.8729)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.9%)	
11/17 05:32:45AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 0.9453 (1.1625)	Arch Loss 1.6123 (1.9402)	Arch Hard Loss 1.5600 (1.8895)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.8%)	
11/17 05:34:45AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.1971 (1.1686)	Arch Loss 1.8434 (1.9581)	Arch Hard Loss 1.7918 (1.9073)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.7%)	
11/17 05:36:34AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 0.9883 (1.1930)	Arch Loss 1.5050 (1.9693)	Arch Hard Loss 1.4546 (1.9185)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.2%, 91.3%)	
11/17 05:36:34AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 28/49] Final Prec@1 65.1480%
11/17 05:36:55AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9040	Prec@(1,5) (49.5%, 80.4%)
11/17 05:37:15AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.9309	Prec@(1,5) (49.2%, 80.1%)
11/17 05:37:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8971	Prec@(1,5) (50.1%, 80.4%)
11/17 05:37:54AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8917	Prec@(1,5) (50.3%, 80.4%)
11/17 05:37:54AM searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 50.2960%
11/17 05:37:54AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 11])
11/17 05:37:55AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.2960%
11/17 05:39:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1851 (1.1038)	Arch Loss 1.5844 (1.9743)	Arch Hard Loss 1.5388 (1.9242)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 92.5%)	
11/17 05:41:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9171 (1.1097)	Arch Loss 1.8708 (1.9760)	Arch Hard Loss 1.8241 (1.9261)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 92.3%)	
11/17 05:43:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1125 (1.1303)	Arch Loss 1.9594 (1.9665)	Arch Hard Loss 1.9111 (1.9167)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.1%)	
11/17 05:45:43AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9781 (1.1474)	Arch Loss 1.9216 (1.9654)	Arch Hard Loss 1.8703 (1.9157)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.9%)	
11/17 05:45:44AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 29/49] Final Prec@1 66.2240%
11/17 05:46:05AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8899	Prec@(1,5) (51.0%, 80.4%)
11/17 05:46:25AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8751	Prec@(1,5) (51.1%, 80.6%)
11/17 05:46:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8732	Prec@(1,5) (51.1%, 80.4%)
11/17 05:47:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8627	Prec@(1,5) (51.3%, 80.7%)
11/17 05:47:04AM searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 51.3280%
11/17 05:47:04AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[9, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 10])
11/17 05:47:04AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.3280%
11/17 05:49:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.1311 (1.0570)	Arch Loss 1.3967 (1.9202)	Arch Hard Loss 1.3465 (1.8709)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.3%)	
11/17 05:51:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.2212 (1.0509)	Arch Loss 2.2043 (1.9416)	Arch Hard Loss 2.1575 (1.8921)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.3%)	
11/17 05:53:05AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.2921 (1.0771)	Arch Loss 1.6175 (1.9409)	Arch Hard Loss 1.5704 (1.8914)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.8%)	
11/17 05:54:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.1809 (1.0985)	Arch Loss 2.2189 (1.9481)	Arch Hard Loss 2.1669 (1.8985)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.5%)	
11/17 05:54:54AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 30/49] Final Prec@1 67.4840%
11/17 05:55:14AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9129	Prec@(1,5) (50.1%, 80.1%)
11/17 05:55:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8958	Prec@(1,5) (50.2%, 80.3%)
11/17 05:55:54AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9161	Prec@(1,5) (50.0%, 79.8%)
11/17 05:56:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9156	Prec@(1,5) (49.9%, 79.9%)
11/17 05:56:13AM searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 49.9400%
11/17 05:56:13AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
11/17 05:56:13AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.3280%
11/17 05:58:13AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8931 (1.0140)	Arch Loss 2.2691 (1.9190)	Arch Hard Loss 2.2229 (1.8687)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.6%)	
11/17 06:00:13AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9053 (1.0200)	Arch Loss 1.7512 (1.9359)	Arch Hard Loss 1.6985 (1.8852)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.5%)	
11/17 06:02:13AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1887 (1.0465)	Arch Loss 2.2531 (1.9435)	Arch Hard Loss 2.2022 (1.8929)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.1%)	
11/17 06:04:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.4024 (1.0609)	Arch Loss 1.8872 (1.9375)	Arch Hard Loss 1.8328 (1.8871)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
11/17 06:04:02AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 31/49] Final Prec@1 68.6520%
11/17 06:04:23AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8289	Prec@(1,5) (51.0%, 81.8%)
11/17 06:04:43AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8269	Prec@(1,5) (51.8%, 81.8%)
11/17 06:05:03AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8404	Prec@(1,5) (51.7%, 81.5%)
11/17 06:05:22AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8524	Prec@(1,5) (51.5%, 81.3%)
11/17 06:05:22AM searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 51.5120%
11/17 06:05:22AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 10])
11/17 06:05:23AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.5120%
11/17 06:07:22AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.1240 (0.9684)	Arch Loss 1.7348 (1.9299)	Arch Hard Loss 1.6807 (1.8796)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
11/17 06:09:23AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9236 (0.9809)	Arch Loss 2.2651 (1.9325)	Arch Hard Loss 2.2138 (1.8822)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
11/17 06:11:23AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.9658 (0.9887)	Arch Loss 1.7831 (1.9471)	Arch Hard Loss 1.7346 (1.8970)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.8%)	
11/17 06:13:11AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.9606 (1.0005)	Arch Loss 1.7806 (1.9434)	Arch Hard Loss 1.7317 (1.8934)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.7%)	
11/17 06:13:12AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 32/49] Final Prec@1 70.3160%
11/17 06:13:33AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8541	Prec@(1,5) (52.1%, 81.4%)
11/17 06:13:53AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8500	Prec@(1,5) (52.2%, 81.3%)
11/17 06:14:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8541	Prec@(1,5) (51.8%, 81.3%)
11/17 06:14:31AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8503	Prec@(1,5) (51.9%, 81.3%)
11/17 06:14:31AM searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 51.9560%
11/17 06:14:32AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[4, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 10])
11/17 06:14:32AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9560%
11/17 06:16:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8176 (0.8911)	Arch Loss 1.7996 (1.9259)	Arch Hard Loss 1.7462 (1.8759)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.9%, 95.0%)	
11/17 06:18:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8679 (0.9308)	Arch Loss 1.6635 (1.8962)	Arch Hard Loss 1.6130 (1.8463)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.5%)	
11/17 06:20:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.1569 (0.9508)	Arch Loss 2.2738 (1.9260)	Arch Hard Loss 2.2165 (1.8763)	Arch Beta Loss 0.0038 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.3%)	
11/17 06:22:21AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9952 (0.9617)	Arch Loss 1.7660 (1.9264)	Arch Hard Loss 1.7183 (1.8769)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.2%)	
11/17 06:22:21AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 33/49] Final Prec@1 71.2560%
11/17 06:22:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8707	Prec@(1,5) (52.1%, 80.4%)
11/17 06:23:02AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8371	Prec@(1,5) (52.2%, 80.9%)
11/17 06:23:22AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8442	Prec@(1,5) (52.0%, 80.9%)
11/17 06:23:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8455	Prec@(1,5) (52.0%, 81.1%)
11/17 06:23:41AM searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 51.9840%
11/17 06:23:41AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[4, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 11])
11/17 06:23:41AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9840%
11/17 06:25:41AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7556 (0.8746)	Arch Loss 1.8247 (1.9107)	Arch Hard Loss 1.7757 (1.8619)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.2%)	
11/17 06:27:41AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.6842 (0.8987)	Arch Loss 2.0484 (1.9248)	Arch Hard Loss 2.0045 (1.8760)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.8%, 95.0%)	
11/17 06:29:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0168 (0.8994)	Arch Loss 2.4286 (1.9345)	Arch Hard Loss 2.3808 (1.8858)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.4%, 95.0%)	
11/17 06:31:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0421 (0.9152)	Arch Loss 1.8807 (1.9369)	Arch Hard Loss 1.8280 (1.8882)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.7%)	
11/17 06:31:31AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 34/49] Final Prec@1 72.7480%
11/17 06:31:51AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8781	Prec@(1,5) (51.9%, 81.3%)
11/17 06:32:12AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.8777	Prec@(1,5) (51.7%, 81.0%)
11/17 06:32:32AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.8734	Prec@(1,5) (51.9%, 81.2%)
11/17 06:32:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.8673	Prec@(1,5) (52.0%, 81.3%)
11/17 06:32:50AM searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 51.9720%
11/17 06:32:50AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 9])
11/17 06:32:50AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9840%
11/17 06:34:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.9595 (0.8224)	Arch Loss 1.6713 (1.9396)	Arch Hard Loss 1.6215 (1.8908)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.9%)	
11/17 06:36:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.8909 (0.8517)	Arch Loss 1.8676 (1.9253)	Arch Hard Loss 1.8185 (1.8764)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.5%)	
11/17 06:38:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.1903 (0.8682)	Arch Loss 1.9167 (1.9152)	Arch Hard Loss 1.8675 (1.8662)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.3%)	
11/17 06:40:39AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1264 (0.8703)	Arch Loss 1.5731 (1.9271)	Arch Hard Loss 1.5236 (1.8780)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.3%)	
11/17 06:40:40AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 35/49] Final Prec@1 74.0800%
11/17 06:41:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.8143	Prec@(1,5) (52.8%, 81.7%)
11/17 06:41:21AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.8206	Prec@(1,5) (52.6%, 81.8%)
11/17 06:41:40AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.8274	Prec@(1,5) (52.8%, 81.7%)
11/17 06:41:59AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8282	Prec@(1,5) (52.7%, 81.8%)
11/17 06:41:59AM searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 52.7000%
11/17 06:41:59AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[7, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 6])
11/17 06:41:59AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.7000%
11/17 06:43:59AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.9088 (0.7590)	Arch Loss 1.9898 (1.9409)	Arch Hard Loss 1.9400 (1.8917)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.7%)	
11/17 06:46:00AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8038 (0.7975)	Arch Loss 1.7121 (1.9308)	Arch Hard Loss 1.6627 (1.8817)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.2%, 96.2%)	
11/17 06:48:00AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7533 (0.8096)	Arch Loss 1.8553 (1.9306)	Arch Hard Loss 1.8073 (1.8813)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 96.0%)	
11/17 06:49:48AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6887 (0.8219)	Arch Loss 1.7186 (1.9315)	Arch Hard Loss 1.6714 (1.8822)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.8%)	
11/17 06:49:49AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 36/49] Final Prec@1 75.5880%
11/17 06:50:10AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.8347	Prec@(1,5) (53.1%, 81.8%)
11/17 06:50:30AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.8347	Prec@(1,5) (53.4%, 81.6%)
11/17 06:50:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.8589	Prec@(1,5) (53.0%, 81.4%)
11/17 06:51:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.8534	Prec@(1,5) (53.0%, 81.5%)
11/17 06:51:09AM searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 52.9920%
11/17 06:51:09AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/17 06:51:10AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.9920%
11/17 06:53:09AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.7481 (0.7421)	Arch Loss 2.1097 (1.9387)	Arch Hard Loss 2.0599 (1.8894)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.9%)	
11/17 06:55:10AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.0064 (0.7613)	Arch Loss 2.2226 (1.9223)	Arch Hard Loss 2.1712 (1.8728)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.5%)	
11/17 06:57:10AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.7820 (0.7725)	Arch Loss 1.6774 (1.9289)	Arch Hard Loss 1.6297 (1.8795)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.3%)	
11/17 06:58:58AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.6588 (0.7778)	Arch Loss 1.4756 (1.9290)	Arch Hard Loss 1.4273 (1.8796)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
11/17 06:58:59AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 37/49] Final Prec@1 76.9840%
11/17 06:59:20AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8306	Prec@(1,5) (53.0%, 81.8%)
11/17 06:59:40AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8424	Prec@(1,5) (53.0%, 81.8%)
11/17 07:00:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.8362	Prec@(1,5) (53.4%, 81.8%)
11/17 07:00:18AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.8364	Prec@(1,5) (53.3%, 81.8%)
11/17 07:00:18AM searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 53.3160%
11/17 07:00:19AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[4, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 8])
11/17 07:00:19AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3160%
11/17 07:02:19AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.4250 (0.7187)	Arch Loss 1.9341 (1.9186)	Arch Hard Loss 1.8864 (1.8687)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.6%)	
11/17 07:04:19AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6004 (0.7304)	Arch Loss 2.3077 (1.8873)	Arch Hard Loss 2.2567 (1.8372)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.6%)	
11/17 07:06:19AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8686 (0.7307)	Arch Loss 1.8228 (1.9027)	Arch Hard Loss 1.7693 (1.8528)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
11/17 07:08:08AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.7850 (0.7402)	Arch Loss 2.0147 (1.9291)	Arch Hard Loss 1.9656 (1.8793)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.5%)	
11/17 07:08:08AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 38/49] Final Prec@1 78.4720%
11/17 07:08:29AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.8227	Prec@(1,5) (54.3%, 81.7%)
11/17 07:08:49AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.8365	Prec@(1,5) (53.6%, 81.9%)
11/17 07:09:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.8331	Prec@(1,5) (53.2%, 82.1%)
11/17 07:09:28AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.8332	Prec@(1,5) (53.2%, 82.1%)
11/17 07:09:28AM searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 53.2440%
11/17 07:09:28AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/17 07:09:28AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3160%
11/17 07:11:28AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.5934 (0.6753)	Arch Loss 1.4983 (1.9213)	Arch Hard Loss 1.4468 (1.8713)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.4%)	
11/17 07:13:28AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.4716 (0.6863)	Arch Loss 1.8732 (1.9298)	Arch Hard Loss 1.8258 (1.8800)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.3%)	
11/17 07:15:28AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.5125 (0.6974)	Arch Loss 2.0571 (1.9268)	Arch Hard Loss 2.0058 (1.8770)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.0%)	
11/17 07:17:16AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8796 (0.7052)	Arch Loss 1.9188 (1.9299)	Arch Hard Loss 1.8669 (1.8801)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.9%)	
11/17 07:17:17AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 39/49] Final Prec@1 79.3160%
11/17 07:17:38AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.8144	Prec@(1,5) (53.3%, 83.0%)
11/17 07:17:58AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.8163	Prec@(1,5) (53.4%, 82.6%)
11/17 07:18:18AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.8238	Prec@(1,5) (53.6%, 82.4%)
11/17 07:18:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.8328	Prec@(1,5) (53.4%, 82.3%)
11/17 07:18:37AM searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 53.4080%
11/17 07:18:37AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[4, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 9])
11/17 07:18:37AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4080%
11/17 07:20:38AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6659 (0.6445)	Arch Loss 1.8862 (1.9344)	Arch Hard Loss 1.8366 (1.8852)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/17 07:22:38AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.7283 (0.6470)	Arch Loss 1.9957 (1.9350)	Arch Hard Loss 1.9495 (1.8856)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.5%)	
11/17 07:24:38AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4437 (0.6649)	Arch Loss 1.7215 (1.9314)	Arch Hard Loss 1.6763 (1.8818)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.3%)	
11/17 07:26:27AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.9181 (0.6666)	Arch Loss 1.7761 (1.9197)	Arch Hard Loss 1.7234 (1.8701)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.3%)	
11/17 07:26:28AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 40/49] Final Prec@1 80.7600%
11/17 07:26:48AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7962	Prec@(1,5) (54.7%, 82.6%)
11/17 07:27:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.8188	Prec@(1,5) (54.5%, 82.1%)
11/17 07:27:29AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.8137	Prec@(1,5) (54.3%, 82.2%)
11/17 07:27:47AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.8194	Prec@(1,5) (54.2%, 82.2%)
11/17 07:27:47AM searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 54.1880%
11/17 07:27:47AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[6, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/17 07:27:48AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1880%
11/17 07:29:48AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.6301 (0.5987)	Arch Loss 1.8854 (1.9259)	Arch Hard Loss 1.8317 (1.8760)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.2%)	
11/17 07:31:48AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5650 (0.6149)	Arch Loss 2.0059 (1.9344)	Arch Hard Loss 1.9556 (1.8843)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.9%)	
11/17 07:33:48AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5012 (0.6155)	Arch Loss 1.9586 (1.9394)	Arch Hard Loss 1.9011 (1.8891)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.8%)	
11/17 07:35:37AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9454 (0.6287)	Arch Loss 1.7876 (1.9383)	Arch Hard Loss 1.7390 (1.8879)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.7%)	
11/17 07:35:37AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 41/49] Final Prec@1 81.6960%
11/17 07:35:58AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.8768	Prec@(1,5) (53.4%, 81.3%)
11/17 07:36:18AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.8721	Prec@(1,5) (53.3%, 81.4%)
11/17 07:36:38AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.8503	Prec@(1,5) (53.4%, 81.8%)
11/17 07:36:56AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.8491	Prec@(1,5) (53.7%, 81.8%)
11/17 07:36:57AM searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 53.7040%
11/17 07:36:57AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[6, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 11])
11/17 07:36:57AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1880%
11/17 07:38:57AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.5618 (0.5850)	Arch Loss 1.9666 (1.9210)	Arch Hard Loss 1.9186 (1.8696)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.8%)	
11/17 07:40:57AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7011 (0.5921)	Arch Loss 1.8128 (1.9168)	Arch Hard Loss 1.7625 (1.8653)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/17 07:42:57AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.5821 (0.5971)	Arch Loss 2.3290 (1.9236)	Arch Hard Loss 2.2800 (1.8720)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
11/17 07:44:45AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5604 (0.6017)	Arch Loss 1.8609 (1.9245)	Arch Hard Loss 1.8087 (1.8729)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.8%)	
11/17 07:44:46AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 42/49] Final Prec@1 82.7520%
11/17 07:45:07AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7795	Prec@(1,5) (54.5%, 82.8%)
11/17 07:45:27AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.8190	Prec@(1,5) (54.0%, 82.6%)
11/17 07:45:47AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.8226	Prec@(1,5) (53.9%, 82.4%)
11/17 07:46:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.8320	Prec@(1,5) (53.9%, 82.3%)
11/17 07:46:06AM searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 53.9080%
11/17 07:46:06AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 8])
11/17 07:46:06AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1880%
11/17 07:48:06AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.4488 (0.5691)	Arch Loss 2.1968 (1.8993)	Arch Hard Loss 2.1469 (1.8481)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.1%)	
11/17 07:50:06AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.5451 (0.5806)	Arch Loss 1.7730 (1.9151)	Arch Hard Loss 1.7202 (1.8635)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
11/17 07:52:06AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5989 (0.5812)	Arch Loss 2.0621 (1.9228)	Arch Hard Loss 2.0124 (1.8712)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
11/17 07:53:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.4886 (0.5844)	Arch Loss 1.6093 (1.9238)	Arch Hard Loss 1.5599 (1.8722)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/17 07:53:56AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 43/49] Final Prec@1 83.3920%
11/17 07:54:16AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7912	Prec@(1,5) (55.0%, 82.8%)
11/17 07:54:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.8006	Prec@(1,5) (54.8%, 82.7%)
11/17 07:54:57AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.8094	Prec@(1,5) (54.6%, 82.6%)
11/17 07:55:15AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.8228	Prec@(1,5) (54.4%, 82.4%)
11/17 07:55:15AM searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 54.3920%
11/17 07:55:15AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/17 07:55:16AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.3920%
11/17 07:57:15AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5143 (0.5419)	Arch Loss 2.0730 (1.9327)	Arch Hard Loss 2.0223 (1.8815)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.4%)	
11/17 07:59:16AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.7365 (0.5502)	Arch Loss 2.5618 (1.9172)	Arch Hard Loss 2.5125 (1.8664)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.2%)	
11/17 08:01:16AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.4240 (0.5610)	Arch Loss 1.8119 (1.9240)	Arch Hard Loss 1.7665 (1.8733)	Arch Beta Loss 0.0030 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.2%)	
11/17 08:03:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.4354 (0.5627)	Arch Loss 1.8936 (1.9225)	Arch Hard Loss 1.8422 (1.8720)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.2%)	
11/17 08:03:05AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 44/49] Final Prec@1 84.0240%
11/17 08:03:26AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.8042	Prec@(1,5) (54.3%, 82.9%)
11/17 08:03:46AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.8291	Prec@(1,5) (54.1%, 82.7%)
11/17 08:04:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.8235	Prec@(1,5) (54.2%, 82.5%)
11/17 08:04:24AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.8302	Prec@(1,5) (54.1%, 82.3%)
11/17 08:04:24AM searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 54.0760%
11/17 08:04:24AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/17 08:04:25AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.3920%
11/17 08:06:24AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.3358 (0.5352)	Arch Loss 1.3516 (1.9212)	Arch Hard Loss 1.3013 (1.8716)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.2%)	
11/17 08:08:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.6048 (0.5355)	Arch Loss 2.0592 (1.9235)	Arch Hard Loss 2.0092 (1.8737)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.3%)	
11/17 08:10:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6408 (0.5438)	Arch Loss 2.2684 (1.9271)	Arch Hard Loss 2.2220 (1.8771)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
11/17 08:12:13AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4861 (0.5460)	Arch Loss 2.0063 (1.9304)	Arch Hard Loss 1.9599 (1.8805)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.2%)	
11/17 08:12:14AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 45/49] Final Prec@1 84.9400%
11/17 08:12:34AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7858	Prec@(1,5) (55.4%, 83.0%)
11/17 08:12:55AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.8157	Prec@(1,5) (54.5%, 82.7%)
11/17 08:13:15AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.8166	Prec@(1,5) (54.5%, 82.6%)
11/17 08:13:33AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.8158	Prec@(1,5) (54.5%, 82.6%)
11/17 08:13:33AM searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 54.4800%
11/17 08:13:33AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[8, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[6, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 11])
11/17 08:13:34AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4800%
11/17 08:15:33AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.7055 (0.4982)	Arch Loss 1.9401 (1.9357)	Arch Hard Loss 1.8902 (1.8864)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
11/17 08:17:34AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.3553 (0.5206)	Arch Loss 2.1006 (1.9215)	Arch Hard Loss 2.0479 (1.8723)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
11/17 08:19:34AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.3814 (0.5230)	Arch Loss 1.5648 (1.9215)	Arch Hard Loss 1.5151 (1.8723)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.5%)	
11/17 08:21:22AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.4367 (0.5279)	Arch Loss 2.1254 (1.9199)	Arch Hard Loss 2.0767 (1.8706)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
11/17 08:21:23AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 46/49] Final Prec@1 85.7800%
11/17 08:21:43AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.8333	Prec@(1,5) (55.0%, 82.2%)
11/17 08:22:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.8241	Prec@(1,5) (54.5%, 82.4%)
11/17 08:22:23AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.8191	Prec@(1,5) (54.7%, 82.3%)
11/17 08:22:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.8225	Prec@(1,5) (54.4%, 82.3%)
11/17 08:22:42AM searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 54.4680%
11/17 08:22:42AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[9, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/17 08:22:42AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4800%
11/17 08:24:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.4894 (0.5112)	Arch Loss 1.6535 (1.8880)	Arch Hard Loss 1.6096 (1.8388)	Arch Beta Loss 0.0029 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.5%)	
11/17 08:26:43AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.4146 (0.5123)	Arch Loss 1.9578 (1.9224)	Arch Hard Loss 1.9053 (1.8733)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.6%)	
11/17 08:28:43AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.4787 (0.5178)	Arch Loss 1.8696 (1.9155)	Arch Hard Loss 1.8245 (1.8665)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.5%)	
11/17 08:30:31AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.5860 (0.5227)	Arch Loss 1.8061 (1.9209)	Arch Hard Loss 1.7632 (1.8719)	Arch Beta Loss 0.0029 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
11/17 08:30:32AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 47/49] Final Prec@1 85.9680%
11/17 08:30:53AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.8248	Prec@(1,5) (54.0%, 82.7%)
11/17 08:31:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.8036	Prec@(1,5) (54.9%, 82.8%)
11/17 08:31:33AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.8026	Prec@(1,5) (54.8%, 82.9%)
11/17 08:31:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.8098	Prec@(1,5) (54.7%, 82.7%)
11/17 08:31:52AM searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 54.7040%
11/17 08:31:52AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 11])
11/17 08:31:53AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7040%
11/17 08:33:52AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5687 (0.4911)	Arch Loss 1.8488 (1.8954)	Arch Hard Loss 1.7978 (1.8463)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/17 08:35:52AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5770 (0.5033)	Arch Loss 2.3485 (1.9412)	Arch Hard Loss 2.2927 (1.8922)	Arch Beta Loss 0.0037 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
11/17 08:37:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5281 (0.5110)	Arch Loss 1.6673 (1.9283)	Arch Hard Loss 1.6106 (1.8791)	Arch Beta Loss 0.0038 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.6%)	
11/17 08:39:41AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5260 (0.5161)	Arch Loss 2.0368 (1.9270)	Arch Hard Loss 1.9805 (1.8778)	Arch Beta Loss 0.0038 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
11/17 08:39:42AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 48/49] Final Prec@1 86.0920%
11/17 08:40:02AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.8244	Prec@(1,5) (54.4%, 82.3%)
11/17 08:40:23AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.8156	Prec@(1,5) (54.3%, 82.4%)
11/17 08:40:43AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.8051	Prec@(1,5) (54.4%, 82.6%)
11/17 08:41:01AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.8130	Prec@(1,5) (54.3%, 82.5%)
11/17 08:41:01AM searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 54.2960%
11/17 08:41:01AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[4, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/17 08:41:02AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7040%
11/17 08:43:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4185 (0.4985)	Arch Loss 2.0967 (1.9509)	Arch Hard Loss 2.0553 (1.9019)	Arch Beta Loss 0.0028 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
11/17 08:45:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.3365 (0.4943)	Arch Loss 1.7747 (1.9368)	Arch Hard Loss 1.7283 (1.8881)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.7%)	
11/17 08:47:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.4320 (0.4998)	Arch Loss 1.7555 (1.9249)	Arch Hard Loss 1.7178 (1.8764)	Arch Beta Loss 0.0025 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.6%)	
11/17 08:48:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5456 (0.5089)	Arch Loss 1.5736 (1.9242)	Arch Hard Loss 1.5324 (1.8757)	Arch Beta Loss 0.0028 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.6%)	
11/17 08:48:51AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 49/49] Final Prec@1 86.5840%
11/17 08:49:12AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7976	Prec@(1,5) (54.5%, 83.3%)
11/17 08:49:32AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.8175	Prec@(1,5) (54.5%, 82.6%)
11/17 08:49:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.8267	Prec@(1,5) (54.4%, 82.3%)
11/17 08:50:11AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.8189	Prec@(1,5) (54.4%, 82.4%)
11/17 08:50:11AM searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 54.4240%
11/17 08:50:11AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[7, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 08:50:11AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7040%
11/17 08:50:11AM trainer_runner.py:110 [INFO] Final best Prec@1 = 54.7040%
11/17 08:50:11AM trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[6, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 11])
