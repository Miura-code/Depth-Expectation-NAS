11/10 01:38:03PM parser.py:28 [INFO] 
11/10 01:38:03PM parser.py:29 [INFO] Parameters:
11/10 01:38:03PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s4-LengthBeta-sw3/DAG
11/10 01:38:03PM parser.py:31 [INFO] T=10.0
11/10 01:38:03PM parser.py:31 [INFO] ADVANCED=1
11/10 01:38:03PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/10 01:38:03PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/10 01:38:03PM parser.py:31 [INFO] ARCH_CRITERION=length
11/10 01:38:03PM parser.py:31 [INFO] BATCH_SIZE=64
11/10 01:38:03PM parser.py:31 [INFO] CASCADE=0
11/10 01:38:03PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/10 01:38:03PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/10 01:38:03PM parser.py:31 [INFO] DATA_PATH=../data/
11/10 01:38:03PM parser.py:31 [INFO] DATASET=cifar100
11/10 01:38:03PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/10 01:38:03PM parser.py:31 [INFO] DESCRIPTION=search_wtih_beta-cell-length-constriction
11/10 01:38:03PM parser.py:31 [INFO] DISCRETE=0
11/10 01:38:03PM parser.py:31 [INFO] EPOCHS=50
11/10 01:38:03PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/10 01:38:03PM parser.py:31 [INFO] EXP_NAME=s4-LengthBeta-sw3
11/10 01:38:03PM parser.py:31 [INFO] FINAL_L=1.0
11/10 01:38:03PM parser.py:31 [INFO] G=1.0
11/10 01:38:03PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/10 01:38:03PM parser.py:31 [INFO] GPUS=[0]
11/10 01:38:03PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/10 01:38:03PM parser.py:31 [INFO] INIT_CHANNELS=16
11/10 01:38:03PM parser.py:31 [INFO] L=0.0
11/10 01:38:03PM parser.py:31 [INFO] LAYERS=20
11/10 01:38:03PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/10 01:38:03PM parser.py:31 [INFO] NAME=Pruning
11/10 01:38:03PM parser.py:31 [INFO] NONKD=1
11/10 01:38:03PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s4-LengthBeta-sw3
11/10 01:38:03PM parser.py:31 [INFO] PCDARTS=0
11/10 01:38:03PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s4-LengthBeta-sw3/plots
11/10 01:38:03PM parser.py:31 [INFO] PRINT_FREQ=100
11/10 01:38:03PM parser.py:31 [INFO] RESET=0
11/10 01:38:03PM parser.py:31 [INFO] RESUME_PATH=None
11/10 01:38:03PM parser.py:31 [INFO] SAVE=s4-LengthBeta-sw3
11/10 01:38:03PM parser.py:31 [INFO] SEED=4
11/10 01:38:03PM parser.py:31 [INFO] SHARE_STAGE=0
11/10 01:38:03PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/10 01:38:03PM parser.py:31 [INFO] SPEC_CELL=1
11/10 01:38:03PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/10 01:38:03PM parser.py:31 [INFO] TEACHER_NAME=none
11/10 01:38:03PM parser.py:31 [INFO] TEACHER_PATH=none
11/10 01:38:03PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/10 01:38:03PM parser.py:31 [INFO] TYPE=Pruning
11/10 01:38:03PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/10 01:38:03PM parser.py:31 [INFO] W_LR=0.025
11/10 01:38:03PM parser.py:31 [INFO] W_LR_MIN=0.001
11/10 01:38:03PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/10 01:38:03PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/10 01:38:03PM parser.py:31 [INFO] WORKERS=4
11/10 01:38:03PM parser.py:32 [INFO] 
11/10 01:38:05PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/10 01:38:39PM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3178 (4.4444)	Arch Loss 4.3653 (4.4252)	Arch Hard Loss 4.3653 (4.4252)	Arch Beta Loss 0.0963 (0.0550)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.2%, 13.2%)	
11/10 01:39:10PM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1059 (4.2849)	Arch Loss 4.1716 (4.2579)	Arch Hard Loss 4.1716 (4.2579)	Arch Beta Loss 0.1950 (0.1005)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.5%, 17.2%)	
11/10 01:39:40PM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8241 (4.1827)	Arch Loss 3.8922 (4.1607)	Arch Hard Loss 3.8922 (4.1607)	Arch Beta Loss 0.2306 (0.1395)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.7%, 20.3%)	
11/10 01:40:06PM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9871 (4.1067)	Arch Loss 4.0148 (4.0919)	Arch Hard Loss 4.0148 (4.0919)	Arch Beta Loss 0.3541 (0.1779)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.6%, 22.7%)	
11/10 01:40:08PM searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  0/49] Final Prec@1 6.6520%
11/10 01:40:13PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.8211	Prec@(1,5) (10.1%, 31.4%)
11/10 01:40:17PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.8142	Prec@(1,5) (10.6%, 32.0%)
11/10 01:40:22PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.8023	Prec@(1,5) (10.7%, 32.2%)
11/10 01:40:26PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.8076	Prec@(1,5) (10.7%, 32.0%)
11/10 01:40:26PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 10.6600%
11/10 01:40:26PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG3_concat=[2, 3])
11/10 01:40:27PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 10.6600%
11/10 01:40:59午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8192 (3.7600)	Arch Loss 3.5068 (3.7817)	Arch Hard Loss 3.5066 (3.7814)	Arch Beta Loss 0.1824 (0.2668)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.7%, 33.3%)	
11/10 01:41:30午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.5239 (3.7240)	Arch Loss 3.6140 (3.7381)	Arch Hard Loss 3.6138 (3.7379)	Arch Beta Loss 0.1664 (0.2118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.5%, 34.6%)	
11/10 01:42:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7003 (3.6899)	Arch Loss 3.5258 (3.6997)	Arch Hard Loss 3.5257 (3.6995)	Arch Beta Loss 0.1533 (0.1946)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.3%, 35.8%)	
11/10 01:42:29午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7892 (3.6559)	Arch Loss 3.6692 (3.6574)	Arch Hard Loss 3.6691 (3.6572)	Arch Beta Loss 0.1594 (0.1877)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.9%, 36.9%)	
11/10 01:42:30午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  1/49] Final Prec@1 12.9400%
11/10 01:42:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5259	Prec@(1,5) (16.0%, 40.6%)
11/10 01:42:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5198	Prec@(1,5) (16.0%, 41.1%)
11/10 01:42:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5293	Prec@(1,5) (15.7%, 40.8%)
11/10 01:42:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5272	Prec@(1,5) (15.7%, 41.0%)
11/10 01:42:48午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 15.6600%
11/10 01:42:48午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG3_concat=[2, 3])
11/10 01:42:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 15.6600%
11/10 01:43:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.5878 (3.4420)	Arch Loss 3.5177 (3.4567)	Arch Hard Loss 3.5172 (3.4562)	Arch Beta Loss 0.1330 (0.1438)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.8%, 42.6%)	
11/10 01:43:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5763 (3.4243)	Arch Loss 3.3410 (3.4202)	Arch Hard Loss 3.3406 (3.4197)	Arch Beta Loss 0.1178 (0.1351)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.8%, 43.5%)	
11/10 01:44:24午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.2047 (3.3917)	Arch Loss 3.2462 (3.3844)	Arch Hard Loss 3.2458 (3.3839)	Arch Beta Loss 0.1025 (0.1254)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.4%, 44.5%)	
11/10 01:44:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.2034 (3.3571)	Arch Loss 3.1091 (3.3605)	Arch Hard Loss 3.1087 (3.3600)	Arch Beta Loss 0.1010 (0.1200)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.9%, 45.3%)	
11/10 01:44:52午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  2/49] Final Prec@1 17.9200%
11/10 01:44:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2446	Prec@(1,5) (21.0%, 49.6%)
11/10 01:45:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.2547	Prec@(1,5) (20.4%, 49.3%)
11/10 01:45:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.2569	Prec@(1,5) (20.1%, 49.1%)
11/10 01:45:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.2562	Prec@(1,5) (20.0%, 49.1%)
11/10 01:45:10午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 19.9840%
11/10 01:45:10午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[2, 3])
11/10 01:45:11午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.9840%
11/10 01:45:43午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5298 (3.1482)	Arch Loss 3.3105 (3.2323)	Arch Hard Loss 3.3099 (3.2315)	Arch Beta Loss 0.0694 (0.0867)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.0%, 52.1%)	
11/10 01:46:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.3274 (3.1481)	Arch Loss 3.0947 (3.1910)	Arch Hard Loss 3.0943 (3.1903)	Arch Beta Loss 0.0418 (0.0719)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.9%, 51.9%)	
11/10 01:46:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1395 (3.1256)	Arch Loss 3.2030 (3.1558)	Arch Hard Loss 3.2026 (3.1552)	Arch Beta Loss 0.0363 (0.0605)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.2%)	
11/10 01:47:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.3985 (3.1038)	Arch Loss 3.0579 (3.1369)	Arch Hard Loss 3.0577 (3.1365)	Arch Beta Loss 0.0231 (0.0533)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.7%, 52.8%)	
11/10 01:47:14午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  3/49] Final Prec@1 22.6480%
11/10 01:47:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.0090	Prec@(1,5) (24.2%, 54.5%)
11/10 01:47:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.0247	Prec@(1,5) (24.1%, 54.9%)
11/10 01:47:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.0369	Prec@(1,5) (23.7%, 54.6%)
11/10 01:47:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.0392	Prec@(1,5) (23.7%, 54.8%)
11/10 01:47:32午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 23.6640%
11/10 01:47:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[2, 3])
11/10 01:47:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.6640%
11/10 01:48:05午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.1556 (2.9564)	Arch Loss 2.9901 (3.0077)	Arch Hard Loss 2.9898 (3.0074)	Arch Beta Loss 0.0171 (0.0189)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.8%, 56.6%)	
11/10 01:48:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.9037 (2.9062)	Arch Loss 2.6977 (2.9966)	Arch Hard Loss 2.6975 (2.9964)	Arch Beta Loss 0.0102 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 57.9%)	
11/10 01:49:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.6392 (2.9003)	Arch Loss 2.9049 (2.9713)	Arch Hard Loss 2.9048 (2.9711)	Arch Beta Loss 0.0050 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 58.2%)	
11/10 01:49:35午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8710 (2.8946)	Arch Loss 3.4241 (2.9549)	Arch Hard Loss 3.4240 (2.9548)	Arch Beta Loss 0.0041 (0.0104)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 58.2%)	
11/10 01:49:35午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  4/49] Final Prec@1 26.7520%
11/10 01:49:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.8464	Prec@(1,5) (27.4%, 59.8%)
11/10 01:49:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.8461	Prec@(1,5) (27.5%, 59.5%)
11/10 01:49:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.8586	Prec@(1,5) (27.4%, 59.3%)
11/10 01:49:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.8521	Prec@(1,5) (27.4%, 59.5%)
11/10 01:49:53午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 27.4400%
11/10 01:49:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[2, 7])
11/10 01:49:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.4400%
11/10 01:50:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.9478 (2.7487)	Arch Loss 2.9833 (2.8456)	Arch Hard Loss 2.9832 (2.8455)	Arch Beta Loss 0.0051 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 61.5%)	
11/10 01:50:56午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.5530 (2.7488)	Arch Loss 2.7091 (2.8175)	Arch Hard Loss 2.7090 (2.8174)	Arch Beta Loss 0.0048 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.5%, 61.6%)	
11/10 01:51:26午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.9471 (2.7448)	Arch Loss 2.5257 (2.8231)	Arch Hard Loss 2.5256 (2.8230)	Arch Beta Loss 0.0033 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.5%, 61.7%)	
11/10 01:51:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.5395 (2.7242)	Arch Loss 2.7171 (2.7956)	Arch Hard Loss 2.7170 (2.7955)	Arch Beta Loss 0.0023 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.8%, 62.1%)	
11/10 01:51:54午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  5/49] Final Prec@1 29.8120%
11/10 01:51:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8358	Prec@(1,5) (27.8%, 60.1%)
11/10 01:52:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8524	Prec@(1,5) (27.7%, 59.7%)
11/10 01:52:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8431	Prec@(1,5) (27.7%, 59.6%)
11/10 01:52:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8451	Prec@(1,5) (27.7%, 59.7%)
11/10 01:52:12午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 27.6920%
11/10 01:52:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:52:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.6920%
11/10 01:52:44午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.6022 (2.5765)	Arch Loss 2.8068 (2.7127)	Arch Hard Loss 2.8067 (2.7126)	Arch Beta Loss 0.0023 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 65.4%)	
11/10 01:53:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.8244 (2.5694)	Arch Loss 2.4752 (2.6832)	Arch Hard Loss 2.4751 (2.6831)	Arch Beta Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.7%)	
11/10 01:53:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.2718 (2.5742)	Arch Loss 2.8515 (2.6865)	Arch Hard Loss 2.8514 (2.6864)	Arch Beta Loss 0.0033 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.8%)	
11/10 01:54:13午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.4552 (2.5678)	Arch Loss 2.6656 (2.6718)	Arch Hard Loss 2.6654 (2.6717)	Arch Beta Loss 0.0036 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 65.9%)	
11/10 01:54:14午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  6/49] Final Prec@1 32.9640%
11/10 01:54:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6379	Prec@(1,5) (31.6%, 64.0%)
11/10 01:54:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6457	Prec@(1,5) (31.3%, 64.1%)
11/10 01:54:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6579	Prec@(1,5) (31.0%, 64.2%)
11/10 01:54:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6498	Prec@(1,5) (31.0%, 64.5%)
11/10 01:54:32午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 31.0280%
11/10 01:54:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:54:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.0280%
11/10 01:55:05午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.4652 (2.4284)	Arch Loss 2.6030 (2.5971)	Arch Hard Loss 2.6028 (2.5969)	Arch Beta Loss 0.0030 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 68.9%)	
11/10 01:55:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.1434 (2.4467)	Arch Loss 2.8036 (2.5980)	Arch Hard Loss 2.8035 (2.5978)	Arch Beta Loss 0.0035 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.0%, 68.5%)	
11/10 01:56:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.1698 (2.4361)	Arch Loss 2.7045 (2.5829)	Arch Hard Loss 2.7043 (2.5828)	Arch Beta Loss 0.0036 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.9%)	
11/10 01:56:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.3051 (2.4373)	Arch Loss 2.6958 (2.5668)	Arch Hard Loss 2.6956 (2.5667)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.0%, 68.8%)	
11/10 01:56:37午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  7/49] Final Prec@1 35.9760%
11/10 01:56:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.4823	Prec@(1,5) (34.9%, 68.0%)
11/10 01:56:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.4860	Prec@(1,5) (34.9%, 67.9%)
11/10 01:56:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.4859	Prec@(1,5) (35.1%, 67.6%)
11/10 01:56:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.4881	Prec@(1,5) (35.1%, 67.5%)
11/10 01:56:55午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 35.0560%
11/10 01:56:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:56:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.0560%
11/10 01:57:28午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4652 (2.3367)	Arch Loss 2.9060 (2.4966)	Arch Hard Loss 2.9059 (2.4964)	Arch Beta Loss 0.0031 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 70.2%)	
11/10 01:57:59午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.3907 (2.3321)	Arch Loss 3.0653 (2.4963)	Arch Hard Loss 3.0652 (2.4961)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 70.8%)	
11/10 01:58:30午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.4485 (2.3138)	Arch Loss 2.4990 (2.4806)	Arch Hard Loss 2.4989 (2.4804)	Arch Beta Loss 0.0027 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.2%)	
11/10 01:58:58午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.5345 (2.3052)	Arch Loss 2.3069 (2.4657)	Arch Hard Loss 2.3067 (2.4655)	Arch Beta Loss 0.0024 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 71.5%)	
11/10 01:58:59午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  8/49] Final Prec@1 38.8440%
11/10 01:59:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4462	Prec@(1,5) (35.7%, 68.9%)
11/10 01:59:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4480	Prec@(1,5) (36.3%, 68.9%)
11/10 01:59:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4575	Prec@(1,5) (36.4%, 68.8%)
11/10 01:59:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4602	Prec@(1,5) (36.1%, 68.9%)
11/10 01:59:17午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 36.0840%
11/10 01:59:17午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:59:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.0840%
11/10 01:59:50午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.3329 (2.2002)	Arch Loss 2.2577 (2.4198)	Arch Hard Loss 2.2575 (2.4196)	Arch Beta Loss 0.0029 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.0%, 74.2%)	
11/10 02:00:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.2100 (2.2046)	Arch Loss 2.2677 (2.4000)	Arch Hard Loss 2.2675 (2.3998)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 74.0%)	
11/10 02:00:53午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.3641 (2.1997)	Arch Loss 2.1739 (2.3930)	Arch Hard Loss 2.1737 (2.3928)	Arch Beta Loss 0.0022 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.9%)	
11/10 02:01:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.5553 (2.2031)	Arch Loss 2.3395 (2.3840)	Arch Hard Loss 2.3393 (2.3838)	Arch Beta Loss 0.0023 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.9%, 73.9%)	
11/10 02:01:21午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  9/49] Final Prec@1 40.8480%
11/10 02:01:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.3441	Prec@(1,5) (38.5%, 70.7%)
11/10 02:01:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3476	Prec@(1,5) (38.5%, 70.8%)
11/10 02:01:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3441	Prec@(1,5) (38.4%, 71.0%)
11/10 02:01:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3443	Prec@(1,5) (38.6%, 70.8%)
11/10 02:01:39午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 38.6240%
11/10 02:01:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 02:01:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.6240%
11/10 02:02:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 1.8640 (2.0826)	Arch Loss 1.9580 (2.3418)	Arch Hard Loss 1.9578 (2.3415)	Arch Beta Loss 0.0024 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 76.4%)	
11/10 02:02:42午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.3886 (2.1120)	Arch Loss 2.5750 (2.3449)	Arch Hard Loss 2.5747 (2.3446)	Arch Beta Loss 0.0029 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.6%)	
11/10 02:03:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.6788 (2.1082)	Arch Loss 2.0716 (2.3188)	Arch Hard Loss 2.0712 (2.3185)	Arch Beta Loss 0.0035 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.6%)	
11/10 02:03:39午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1124 (2.1056)	Arch Loss 2.1965 (2.3062)	Arch Hard Loss 2.1963 (2.3059)	Arch Beta Loss 0.0024 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.7%)	
11/10 02:03:39午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 10/49] Final Prec@1 43.2480%
11/10 02:03:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3896	Prec@(1,5) (37.4%, 70.0%)
11/10 02:03:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3493	Prec@(1,5) (38.3%, 70.7%)
11/10 02:03:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3536	Prec@(1,5) (38.1%, 70.7%)
11/10 02:03:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3615	Prec@(1,5) (38.1%, 70.6%)
11/10 02:03:56午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 38.0560%
11/10 02:03:56午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 02:03:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.6240%
11/10 02:04:28午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.4923 (2.0086)	Arch Loss 2.4507 (2.2769)	Arch Hard Loss 2.4504 (2.2765)	Arch Beta Loss 0.0025 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 77.4%)	
11/10 02:04:59午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.1840 (2.0064)	Arch Loss 2.1633 (2.2513)	Arch Hard Loss 2.1630 (2.2509)	Arch Beta Loss 0.0033 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.5%)	
11/10 02:05:30午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2149 (2.0239)	Arch Loss 2.1960 (2.2426)	Arch Hard Loss 2.1957 (2.2423)	Arch Beta Loss 0.0032 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.2%)	
11/10 02:05:57午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.1568 (2.0265)	Arch Loss 2.6884 (2.2440)	Arch Hard Loss 2.6881 (2.2437)	Arch Beta Loss 0.0027 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.2%)	
11/10 02:05:57午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 11/49] Final Prec@1 44.6560%
11/10 02:06:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.2200	Prec@(1,5) (41.8%, 73.5%)
11/10 02:06:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.1874	Prec@(1,5) (42.7%, 73.7%)
11/10 02:06:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.1810	Prec@(1,5) (42.7%, 73.7%)
11/10 02:06:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.1719	Prec@(1,5) (42.8%, 74.0%)
11/10 02:06:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 42.8080%
11/10 02:06:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 02:06:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.8080%
11/10 02:06:49午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4879 (1.9366)	Arch Loss 1.8370 (2.2034)	Arch Hard Loss 1.8367 (2.2030)	Arch Beta Loss 0.0025 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 79.2%)	
11/10 02:07:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.9016 (1.9446)	Arch Loss 2.7378 (2.1961)	Arch Hard Loss 2.7375 (2.1957)	Arch Beta Loss 0.0023 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 78.7%)	
11/10 02:07:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9193 (1.9438)	Arch Loss 2.1265 (2.1934)	Arch Hard Loss 2.1261 (2.1931)	Arch Beta Loss 0.0031 (0.0028)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.7%)	
11/10 02:08:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.1091 (1.9494)	Arch Loss 1.9735 (2.1881)	Arch Hard Loss 1.9732 (2.1877)	Arch Beta Loss 0.0022 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.7%)	
11/10 02:08:20午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 12/49] Final Prec@1 46.2840%
11/10 02:08:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.1093	Prec@(1,5) (43.6%, 75.6%)
11/10 02:08:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1190	Prec@(1,5) (43.7%, 75.7%)
11/10 02:08:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1140	Prec@(1,5) (43.8%, 76.0%)
11/10 02:08:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1053	Prec@(1,5) (44.1%, 76.1%)
11/10 02:08:38午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 44.0600%
11/10 02:08:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:08:39午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.0600%
11/10 02:09:11午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.9677 (1.8369)	Arch Loss 2.3372 (2.1273)	Arch Hard Loss 2.3367 (2.1269)	Arch Beta Loss 0.0031 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.3%, 81.0%)	
11/10 02:09:43午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.9752 (1.8591)	Arch Loss 2.2920 (2.1438)	Arch Hard Loss 2.2916 (2.1434)	Arch Beta Loss 0.0024 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.6%)	
11/10 02:10:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.6165 (1.8636)	Arch Loss 2.3431 (2.1519)	Arch Hard Loss 2.3426 (2.1515)	Arch Beta Loss 0.0032 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.4%)	
11/10 02:10:42午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.8869 (1.8626)	Arch Loss 2.0658 (2.1465)	Arch Hard Loss 2.0652 (2.1461)	Arch Beta Loss 0.0032 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.3%)	
11/10 02:10:42午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 13/49] Final Prec@1 48.6440%
11/10 02:10:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1532	Prec@(1,5) (43.5%, 74.6%)
11/10 02:10:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1332	Prec@(1,5) (43.9%, 75.1%)
11/10 02:10:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1238	Prec@(1,5) (43.8%, 75.4%)
11/10 02:11:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1142	Prec@(1,5) (43.9%, 75.6%)
11/10 02:11:01午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 43.8720%
11/10 02:11:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:11:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.0600%
11/10 02:11:33午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.9559 (1.7453)	Arch Loss 2.2717 (2.1215)	Arch Hard Loss 2.2710 (2.1210)	Arch Beta Loss 0.0038 (0.0029)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.7%)	
11/10 02:12:04午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8581 (1.7620)	Arch Loss 1.9772 (2.1158)	Arch Hard Loss 1.9767 (2.1152)	Arch Beta Loss 0.0028 (0.0028)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.2%)	
11/10 02:12:35午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.0818 (1.7765)	Arch Loss 2.0132 (2.1168)	Arch Hard Loss 2.0127 (2.1163)	Arch Beta Loss 0.0027 (0.0028)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.5%, 82.0%)	
11/10 02:13:03午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.8225 (1.7962)	Arch Loss 1.9701 (2.0988)	Arch Hard Loss 1.9696 (2.0983)	Arch Beta Loss 0.0025 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.7%)	
11/10 02:13:03午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 14/49] Final Prec@1 49.9320%
11/10 02:13:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.0504	Prec@(1,5) (45.6%, 76.5%)
11/10 02:13:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.0491	Prec@(1,5) (45.4%, 76.8%)
11/10 02:13:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0507	Prec@(1,5) (45.3%, 76.4%)
11/10 02:13:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0624	Prec@(1,5) (45.1%, 76.4%)
11/10 02:13:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 45.0760%
11/10 02:13:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:13:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0760%
11/10 02:13:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.9108 (1.6827)	Arch Loss 2.3089 (2.0570)	Arch Hard Loss 2.3084 (2.0564)	Arch Beta Loss 0.0022 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.9%, 83.7%)	
11/10 02:14:26午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.5958 (1.7141)	Arch Loss 1.9014 (2.0703)	Arch Hard Loss 1.9008 (2.0697)	Arch Beta Loss 0.0030 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.0%)	
11/10 02:14:57午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.7296 (1.7227)	Arch Loss 1.9356 (2.0689)	Arch Hard Loss 1.9351 (2.0684)	Arch Beta Loss 0.0025 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.9%)	
11/10 02:15:24午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.2895 (1.7343)	Arch Loss 1.8472 (2.0599)	Arch Hard Loss 1.8468 (2.0593)	Arch Beta Loss 0.0021 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.6%)	
11/10 02:15:24午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 15/49] Final Prec@1 51.9040%
11/10 02:15:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0581	Prec@(1,5) (45.4%, 76.6%)
11/10 02:15:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0502	Prec@(1,5) (45.7%, 76.7%)
11/10 02:15:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0509	Prec@(1,5) (45.5%, 76.8%)
11/10 02:15:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0537	Prec@(1,5) (45.4%, 76.6%)
11/10 02:15:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 45.4200%
11/10 02:15:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:15:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.4200%
11/10 02:16:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7133 (1.6775)	Arch Loss 1.9680 (2.0109)	Arch Hard Loss 1.9672 (2.0103)	Arch Beta Loss 0.0034 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.6%)	
11/10 02:16:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.5811 (1.6663)	Arch Loss 2.2447 (2.0323)	Arch Hard Loss 2.2442 (2.0317)	Arch Beta Loss 0.0025 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.3%, 83.6%)	
11/10 02:17:16午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9846 (1.6808)	Arch Loss 2.0340 (2.0120)	Arch Hard Loss 2.0333 (2.0114)	Arch Beta Loss 0.0031 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.5%)	
11/10 02:17:43午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.4829 (1.6759)	Arch Loss 2.0283 (2.0185)	Arch Hard Loss 2.0277 (2.0179)	Arch Beta Loss 0.0027 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.6%)	
11/10 02:17:44午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 16/49] Final Prec@1 53.1040%
11/10 02:17:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 1.9773	Prec@(1,5) (46.1%, 78.1%)
11/10 02:17:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 1.9619	Prec@(1,5) (47.1%, 78.4%)
11/10 02:17:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 1.9681	Prec@(1,5) (47.4%, 78.3%)
11/10 02:18:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 1.9621	Prec@(1,5) (47.5%, 78.3%)
11/10 02:18:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 47.5040%
11/10 02:18:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:18:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.5040%
11/10 02:18:34午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.4832 (1.5382)	Arch Loss 1.8314 (1.9808)	Arch Hard Loss 1.8308 (1.9801)	Arch Beta Loss 0.0023 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.8%, 85.7%)	
11/10 02:19:04午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.5452 (1.5715)	Arch Loss 1.6875 (2.0155)	Arch Hard Loss 1.6868 (2.0148)	Arch Beta Loss 0.0029 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.3%)	
11/10 02:19:35午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.4713 (1.5943)	Arch Loss 2.0851 (2.0151)	Arch Hard Loss 2.0844 (2.0144)	Arch Beta Loss 0.0024 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.4%, 85.0%)	
11/10 02:20:04午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.3882 (1.6150)	Arch Loss 1.8591 (2.0101)	Arch Hard Loss 1.8584 (2.0094)	Arch Beta Loss 0.0029 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.6%)	
11/10 02:20:04午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 17/49] Final Prec@1 54.8240%
11/10 02:20:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 1.9490	Prec@(1,5) (47.4%, 78.5%)
11/10 02:20:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9396	Prec@(1,5) (47.7%, 78.7%)
11/10 02:20:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9463	Prec@(1,5) (47.7%, 78.4%)
11/10 02:20:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9324	Prec@(1,5) (47.8%, 78.7%)
11/10 02:20:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 47.8520%
11/10 02:20:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:20:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8520%
11/10 02:20:55午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.7656 (1.5556)	Arch Loss 1.6921 (1.9771)	Arch Hard Loss 1.6917 (1.9763)	Arch Beta Loss 0.0017 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.4%)	
11/10 02:21:26午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.7891 (1.5515)	Arch Loss 2.1427 (1.9879)	Arch Hard Loss 2.1420 (1.9872)	Arch Beta Loss 0.0024 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.6%)	
11/10 02:21:58午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.2237 (1.5601)	Arch Loss 1.5567 (1.9745)	Arch Hard Loss 1.5560 (1.9738)	Arch Beta Loss 0.0023 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.5%)	
11/10 02:22:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.4554 (1.5637)	Arch Loss 1.9685 (1.9706)	Arch Hard Loss 1.9678 (1.9699)	Arch Beta Loss 0.0023 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.5%)	
11/10 02:22:26午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 18/49] Final Prec@1 55.7880%
11/10 02:22:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9668	Prec@(1,5) (47.3%, 78.8%)
11/10 02:22:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9557	Prec@(1,5) (47.5%, 78.9%)
11/10 02:22:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9761	Prec@(1,5) (47.4%, 78.6%)
11/10 02:22:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9747	Prec@(1,5) (47.5%, 78.5%)
11/10 02:22:44午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 47.4480%
11/10 02:22:44午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:22:45午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8520%
11/10 02:23:17午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.1674 (1.4726)	Arch Loss 1.5737 (1.9402)	Arch Hard Loss 1.5731 (1.9394)	Arch Beta Loss 0.0020 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.1%)	
11/10 02:23:49午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 2.0535 (1.4989)	Arch Loss 2.0657 (1.9497)	Arch Hard Loss 2.0648 (1.9489)	Arch Beta Loss 0.0029 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.6%)	
11/10 02:24:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.6366 (1.5019)	Arch Loss 2.1866 (1.9466)	Arch Hard Loss 2.1859 (1.9458)	Arch Beta Loss 0.0022 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.4%)	
11/10 02:24:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.4582 (1.5144)	Arch Loss 1.6855 (1.9431)	Arch Hard Loss 1.6848 (1.9423)	Arch Beta Loss 0.0022 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.4%)	
11/10 02:24:49午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 19/49] Final Prec@1 57.0720%
11/10 02:24:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.8911	Prec@(1,5) (48.5%, 80.1%)
11/10 02:24:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.8946	Prec@(1,5) (48.3%, 80.3%)
11/10 02:25:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9096	Prec@(1,5) (48.0%, 79.9%)
11/10 02:25:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9106	Prec@(1,5) (48.2%, 79.7%)
11/10 02:25:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 48.1680%
11/10 02:25:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:25:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1680%
11/10 02:25:40午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6658 (1.3957)	Arch Loss 2.3958 (1.9070)	Arch Hard Loss 2.3949 (1.9061)	Arch Beta Loss 0.0029 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.0%)	
11/10 02:26:11午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.3623 (1.4222)	Arch Loss 1.7725 (1.9160)	Arch Hard Loss 1.7716 (1.9151)	Arch Beta Loss 0.0026 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.6%)	
11/10 02:26:42午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.3704 (1.4487)	Arch Loss 2.2707 (1.9286)	Arch Hard Loss 2.2700 (1.9278)	Arch Beta Loss 0.0019 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.2%)	
11/10 02:27:10午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4644 (1.4603)	Arch Loss 1.8655 (1.9292)	Arch Hard Loss 1.8648 (1.9283)	Arch Beta Loss 0.0020 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.0%)	
11/10 02:27:10午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 20/49] Final Prec@1 58.3760%
11/10 02:27:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.8994	Prec@(1,5) (48.5%, 79.5%)
11/10 02:27:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9317	Prec@(1,5) (47.8%, 79.1%)
11/10 02:27:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9243	Prec@(1,5) (48.0%, 79.2%)
11/10 02:27:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9273	Prec@(1,5) (48.2%, 79.3%)
11/10 02:27:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 48.1720%
11/10 02:27:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:27:29午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1720%
11/10 02:28:02午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.2813 (1.3680)	Arch Loss 2.0258 (1.9012)	Arch Hard Loss 2.0248 (1.9004)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.4%)	
11/10 02:28:32午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.6817 (1.3890)	Arch Loss 1.7353 (1.9067)	Arch Hard Loss 1.7342 (1.9058)	Arch Beta Loss 0.0031 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.1%)	
11/10 02:29:03午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.4602 (1.4017)	Arch Loss 2.1103 (1.9089)	Arch Hard Loss 2.1096 (1.9080)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.0%)	
11/10 02:29:30午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.4609 (1.4095)	Arch Loss 1.8901 (1.9046)	Arch Hard Loss 1.8891 (1.9037)	Arch Beta Loss 0.0028 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.9%)	
11/10 02:29:31午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 21/49] Final Prec@1 59.9760%
11/10 02:29:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.8582	Prec@(1,5) (49.7%, 79.7%)
11/10 02:29:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.8726	Prec@(1,5) (49.7%, 79.8%)
11/10 02:29:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.8740	Prec@(1,5) (49.6%, 79.8%)
11/10 02:29:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.8626	Prec@(1,5) (49.9%, 80.0%)
11/10 02:29:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 49.9200%
11/10 02:29:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:29:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.9200%
11/10 02:30:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.4482 (1.2725)	Arch Loss 2.1150 (1.9147)	Arch Hard Loss 2.1142 (1.9137)	Arch Beta Loss 0.0021 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.1%)	
11/10 02:30:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.2801 (1.3181)	Arch Loss 2.0902 (1.8813)	Arch Hard Loss 2.0892 (1.8804)	Arch Beta Loss 0.0024 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.5%)	
11/10 02:31:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.5663 (1.3432)	Arch Loss 1.6859 (1.8782)	Arch Hard Loss 1.6852 (1.8773)	Arch Beta Loss 0.0019 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.5%, 89.2%)	
11/10 02:31:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.2668 (1.3641)	Arch Loss 1.8164 (1.8855)	Arch Hard Loss 1.8157 (1.8846)	Arch Beta Loss 0.0018 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.9%)	
11/10 02:31:48午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 22/49] Final Prec@1 60.8840%
11/10 02:31:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9695	Prec@(1,5) (48.1%, 78.8%)
11/10 02:31:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9813	Prec@(1,5) (47.7%, 78.9%)
11/10 02:32:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9838	Prec@(1,5) (47.9%, 78.5%)
11/10 02:32:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9775	Prec@(1,5) (48.0%, 78.7%)
11/10 02:32:06午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 47.9640%
11/10 02:32:06午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:32:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.9200%
11/10 02:32:39午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.2566 (1.2547)	Arch Loss 2.1448 (1.9338)	Arch Hard Loss 2.1433 (1.9327)	Arch Beta Loss 0.0035 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.0%)	
11/10 02:33:10午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3315 (1.2872)	Arch Loss 1.9657 (1.9013)	Arch Hard Loss 1.9646 (1.9002)	Arch Beta Loss 0.0024 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.7%)	
11/10 02:33:41午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2926 (1.3058)	Arch Loss 1.5473 (1.8926)	Arch Hard Loss 1.5463 (1.8915)	Arch Beta Loss 0.0023 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.5%)	
11/10 02:34:09午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.0647 (1.3221)	Arch Loss 2.4830 (1.8773)	Arch Hard Loss 2.4817 (1.8762)	Arch Beta Loss 0.0031 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.2%)	
11/10 02:34:10午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 23/49] Final Prec@1 61.7960%
11/10 02:34:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8078	Prec@(1,5) (50.5%, 81.4%)
11/10 02:34:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8261	Prec@(1,5) (50.7%, 81.1%)
11/10 02:34:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8330	Prec@(1,5) (50.5%, 81.0%)
11/10 02:34:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8389	Prec@(1,5) (50.5%, 81.0%)
11/10 02:34:28午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 50.5400%
11/10 02:34:28午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:34:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.5400%
11/10 02:35:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.1834 (1.2582)	Arch Loss 1.7419 (1.8391)	Arch Hard Loss 1.7406 (1.8378)	Arch Beta Loss 0.0028 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.6%)	
11/10 02:35:32午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.6470 (1.2671)	Arch Loss 1.7366 (1.8593)	Arch Hard Loss 1.7355 (1.8581)	Arch Beta Loss 0.0025 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.4%)	
11/10 02:36:03午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3245 (1.2659)	Arch Loss 1.6132 (1.8472)	Arch Hard Loss 1.6121 (1.8460)	Arch Beta Loss 0.0022 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.3%)	
11/10 02:36:32午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.1725 (1.2818)	Arch Loss 2.0410 (1.8513)	Arch Hard Loss 2.0396 (1.8502)	Arch Beta Loss 0.0031 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.8%, 90.1%)	
11/10 02:36:32午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 24/49] Final Prec@1 62.7600%
11/10 02:36:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8598	Prec@(1,5) (50.8%, 80.7%)
11/10 02:36:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8798	Prec@(1,5) (50.4%, 80.6%)
11/10 02:36:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8773	Prec@(1,5) (50.4%, 80.5%)
11/10 02:36:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8786	Prec@(1,5) (50.5%, 80.4%)
11/10 02:36:50午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 50.4760%
11/10 02:36:50午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:36:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.5400%
11/10 02:37:23午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 0.7972 (1.2107)	Arch Loss 1.8595 (1.8342)	Arch Hard Loss 1.8586 (1.8331)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.9%)	
11/10 02:37:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.0334 (1.2138)	Arch Loss 1.6069 (1.8341)	Arch Hard Loss 1.6059 (1.8330)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
11/10 02:38:26午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.4090 (1.2251)	Arch Loss 1.5970 (1.8450)	Arch Hard Loss 1.5959 (1.8439)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.3%)	
11/10 02:38:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.2165 (1.2358)	Arch Loss 1.7181 (1.8464)	Arch Hard Loss 1.7170 (1.8453)	Arch Beta Loss 0.0022 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.3%)	
11/10 02:38:54午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 25/49] Final Prec@1 64.1200%
11/10 02:38:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8213	Prec@(1,5) (51.2%, 81.1%)
11/10 02:39:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8252	Prec@(1,5) (51.3%, 81.3%)
11/10 02:39:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8253	Prec@(1,5) (51.3%, 81.2%)
11/10 02:39:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8156	Prec@(1,5) (51.4%, 81.4%)
11/10 02:39:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 51.4240%
11/10 02:39:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:39:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4240%
11/10 02:39:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.8423 (1.1535)	Arch Loss 1.8508 (1.8306)	Arch Hard Loss 1.8496 (1.8294)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.4%)	
11/10 02:40:16午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.0280 (1.1754)	Arch Loss 2.0573 (1.8105)	Arch Hard Loss 2.0558 (1.8093)	Arch Beta Loss 0.0027 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.3%)	
11/10 02:40:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2604 (1.1849)	Arch Loss 1.5153 (1.8259)	Arch Hard Loss 1.5140 (1.8246)	Arch Beta Loss 0.0026 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.2%, 91.1%)	
11/10 02:41:16午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.3751 (1.1951)	Arch Loss 1.5981 (1.8267)	Arch Hard Loss 1.5971 (1.8255)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.1%)	
11/10 02:41:16午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 26/49] Final Prec@1 65.0360%
11/10 02:41:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.7807	Prec@(1,5) (52.5%, 81.8%)
11/10 02:41:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.7865	Prec@(1,5) (52.3%, 81.6%)
11/10 02:41:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.7933	Prec@(1,5) (52.0%, 81.4%)
11/10 02:41:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.7943	Prec@(1,5) (52.0%, 81.5%)
11/10 02:41:34午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 52.0360%
11/10 02:41:34午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:41:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.0360%
11/10 02:42:06午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.1359 (1.0758)	Arch Loss 1.9841 (1.8284)	Arch Hard Loss 1.9828 (1.8270)	Arch Beta Loss 0.0025 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.6%)	
11/10 02:42:37午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.2604 (1.1102)	Arch Loss 1.3428 (1.8067)	Arch Hard Loss 1.3411 (1.8053)	Arch Beta Loss 0.0029 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.2%)	
11/10 02:43:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1613 (1.1243)	Arch Loss 1.8465 (1.8181)	Arch Hard Loss 1.8450 (1.8168)	Arch Beta Loss 0.0026 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.0%)	
11/10 02:43:35午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.6873 (1.1387)	Arch Loss 1.7581 (1.8228)	Arch Hard Loss 1.7569 (1.8215)	Arch Beta Loss 0.0022 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.8%)	
11/10 02:43:35午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 27/49] Final Prec@1 66.9680%
11/10 02:43:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.7996	Prec@(1,5) (51.8%, 82.0%)
11/10 02:43:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.7763	Prec@(1,5) (52.4%, 82.1%)
11/10 02:43:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.7786	Prec@(1,5) (52.3%, 82.1%)
11/10 02:43:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.7821	Prec@(1,5) (52.4%, 82.0%)
11/10 02:43:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 52.3920%
11/10 02:43:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:43:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.3920%
11/10 02:44:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.2637 (1.0713)	Arch Loss 1.6634 (1.7741)	Arch Hard Loss 1.6622 (1.7727)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.7%)	
11/10 02:44:56午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.0090 (1.0999)	Arch Loss 1.7271 (1.7901)	Arch Hard Loss 1.7254 (1.7888)	Arch Beta Loss 0.0029 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.2%)	
11/10 02:45:26午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.7859 (1.1075)	Arch Loss 1.8805 (1.7963)	Arch Hard Loss 1.8792 (1.7950)	Arch Beta Loss 0.0020 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.2%)	
11/10 02:45:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.2535 (1.1081)	Arch Loss 1.9425 (1.7957)	Arch Hard Loss 1.9411 (1.7945)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.2%)	
11/10 02:45:55午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 28/49] Final Prec@1 68.0000%
11/10 02:46:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.7841	Prec@(1,5) (52.1%, 81.7%)
11/10 02:46:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.7830	Prec@(1,5) (52.2%, 82.0%)
11/10 02:46:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.7863	Prec@(1,5) (52.3%, 81.8%)
11/10 02:46:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7829	Prec@(1,5) (52.3%, 82.0%)
11/10 02:46:13午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 52.3360%
11/10 02:46:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:46:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.3920%
11/10 02:46:46午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1466 (1.0518)	Arch Loss 2.3359 (1.8286)	Arch Hard Loss 2.3345 (1.8272)	Arch Beta Loss 0.0023 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.1%)	
11/10 02:47:17午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.0394 (1.0487)	Arch Loss 2.0220 (1.8119)	Arch Hard Loss 2.0205 (1.8105)	Arch Beta Loss 0.0024 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.1%)	
11/10 02:47:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1864 (1.0652)	Arch Loss 1.4646 (1.8023)	Arch Hard Loss 1.4630 (1.8009)	Arch Beta Loss 0.0027 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.8%)	
11/10 02:48:16午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0695 (1.0752)	Arch Loss 1.4289 (1.7921)	Arch Hard Loss 1.4276 (1.7907)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
11/10 02:48:17午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 29/49] Final Prec@1 68.4560%
11/10 02:48:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7806	Prec@(1,5) (52.7%, 82.0%)
11/10 02:48:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7996	Prec@(1,5) (52.5%, 81.9%)
11/10 02:48:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7916	Prec@(1,5) (52.9%, 82.0%)
11/10 02:48:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7943	Prec@(1,5) (52.8%, 81.8%)
11/10 02:48:35午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 52.7800%
11/10 02:48:35午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:48:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.7800%
11/10 02:49:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.9898 (0.9918)	Arch Loss 1.7712 (1.7611)	Arch Hard Loss 1.7696 (1.7596)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.6%)	
11/10 02:49:39午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9167 (1.0248)	Arch Loss 1.8146 (1.7772)	Arch Hard Loss 1.8130 (1.7757)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.1%)	
11/10 02:50:10午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 0.7865 (1.0263)	Arch Loss 2.0959 (1.7840)	Arch Hard Loss 2.0946 (1.7825)	Arch Beta Loss 0.0020 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.1%)	
11/10 02:50:38午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 0.9981 (1.0272)	Arch Loss 1.5813 (1.7753)	Arch Hard Loss 1.5797 (1.7738)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.1%)	
11/10 02:50:39午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 30/49] Final Prec@1 69.8880%
11/10 02:50:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7477	Prec@(1,5) (54.7%, 82.6%)
11/10 02:50:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7568	Prec@(1,5) (53.8%, 82.2%)
11/10 02:50:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7622	Prec@(1,5) (53.4%, 82.3%)
11/10 02:50:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7622	Prec@(1,5) (53.3%, 82.4%)
11/10 02:50:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 53.2760%
11/10 02:50:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:50:57午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2760%
11/10 02:51:30午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.3424 (0.9328)	Arch Loss 1.4933 (1.7556)	Arch Hard Loss 1.4920 (1.7541)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.6%)	
11/10 02:52:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9197 (0.9635)	Arch Loss 1.7887 (1.7825)	Arch Hard Loss 1.7870 (1.7809)	Arch Beta Loss 0.0025 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.0%)	
11/10 02:52:32午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0437 (0.9731)	Arch Loss 1.3759 (1.7730)	Arch Hard Loss 1.3741 (1.7715)	Arch Beta Loss 0.0027 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.0%)	
11/10 02:53:00午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.0815 (0.9898)	Arch Loss 1.5696 (1.7840)	Arch Hard Loss 1.5679 (1.7824)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.7%)	
11/10 02:53:00午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 31/49] Final Prec@1 70.8840%
11/10 02:53:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7449	Prec@(1,5) (53.6%, 82.9%)
11/10 02:53:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7366	Prec@(1,5) (54.1%, 82.9%)
11/10 02:53:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7533	Prec@(1,5) (53.7%, 82.7%)
11/10 02:53:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7487	Prec@(1,5) (53.7%, 82.6%)
11/10 02:53:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 53.7120%
11/10 02:53:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:53:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7120%
11/10 02:53:51午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.9890 (0.9269)	Arch Loss 1.7533 (1.7965)	Arch Hard Loss 1.7518 (1.7949)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.3%)	
11/10 02:54:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9547 (0.9399)	Arch Loss 1.6226 (1.7794)	Arch Hard Loss 1.6213 (1.7779)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.2%)	
11/10 02:54:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.9249 (0.9530)	Arch Loss 1.4724 (1.7829)	Arch Hard Loss 1.4711 (1.7814)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.0%)	
11/10 02:55:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.6467 (0.9620)	Arch Loss 2.0317 (1.7746)	Arch Hard Loss 2.0301 (1.7731)	Arch Beta Loss 0.0023 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.7%, 93.9%)	
11/10 02:55:20午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 32/49] Final Prec@1 71.6920%
11/10 02:55:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8000	Prec@(1,5) (52.6%, 81.8%)
11/10 02:55:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7686	Prec@(1,5) (53.0%, 82.4%)
11/10 02:55:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7638	Prec@(1,5) (53.3%, 82.5%)
11/10 02:55:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7579	Prec@(1,5) (53.3%, 82.5%)
11/10 02:55:38午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 53.3200%
11/10 02:55:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:55:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7120%
11/10 02:56:11午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.9059 (0.8925)	Arch Loss 1.5119 (1.7592)	Arch Hard Loss 1.5099 (1.7575)	Arch Beta Loss 0.0027 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/10 02:56:41午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8898 (0.8984)	Arch Loss 1.4016 (1.7685)	Arch Hard Loss 1.3996 (1.7668)	Arch Beta Loss 0.0027 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/10 02:57:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.0421 (0.8987)	Arch Loss 1.4738 (1.7721)	Arch Hard Loss 1.4724 (1.7706)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.7%)	
11/10 02:57:40午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9564 (0.9174)	Arch Loss 1.8508 (1.7618)	Arch Hard Loss 1.8488 (1.7603)	Arch Beta Loss 0.0027 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.5%)	
11/10 02:57:41午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 33/49] Final Prec@1 73.1200%
11/10 02:57:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7076	Prec@(1,5) (53.9%, 83.5%)
11/10 02:57:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7359	Prec@(1,5) (54.1%, 82.9%)
11/10 02:57:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7322	Prec@(1,5) (54.2%, 83.0%)
11/10 02:57:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7362	Prec@(1,5) (54.0%, 83.0%)
11/10 02:57:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 54.0320%
11/10 02:57:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 02:57:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.0320%
11/10 02:58:31午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.6627 (0.8460)	Arch Loss 1.8865 (1.7330)	Arch Hard Loss 1.8845 (1.7313)	Arch Beta Loss 0.0026 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.4%)	
11/10 02:59:02午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.9454 (0.8545)	Arch Loss 1.8391 (1.7431)	Arch Hard Loss 1.8374 (1.7415)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
11/10 02:59:33午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0549 (0.8689)	Arch Loss 1.7244 (1.7525)	Arch Hard Loss 1.7228 (1.7509)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/10 03:00:02午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0758 (0.8823)	Arch Loss 2.1109 (1.7586)	Arch Hard Loss 2.1093 (1.7570)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.9%)	
11/10 03:00:02午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 34/49] Final Prec@1 73.8840%
11/10 03:00:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.6653	Prec@(1,5) (55.6%, 83.9%)
11/10 03:00:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7047	Prec@(1,5) (55.4%, 83.2%)
11/10 03:00:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7039	Prec@(1,5) (55.2%, 83.3%)
11/10 03:00:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7083	Prec@(1,5) (55.1%, 83.3%)
11/10 03:00:20午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 55.0720%
11/10 03:00:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:00:21午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0720%
11/10 03:00:53午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.7715 (0.8040)	Arch Loss 1.5336 (1.7461)	Arch Hard Loss 1.5321 (1.7445)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.2%)	
11/10 03:01:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.8928 (0.8336)	Arch Loss 1.4591 (1.7579)	Arch Hard Loss 1.4576 (1.7563)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.7%)	
11/10 03:01:56午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.8761 (0.8469)	Arch Loss 1.4675 (1.7476)	Arch Hard Loss 1.4661 (1.7459)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.4%)	
11/10 03:02:24午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.0323 (0.8515)	Arch Loss 1.3321 (1.7516)	Arch Hard Loss 1.3307 (1.7499)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
11/10 03:02:25午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 35/49] Final Prec@1 74.9440%
11/10 03:02:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.6923	Prec@(1,5) (56.2%, 83.7%)
11/10 03:02:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7106	Prec@(1,5) (55.3%, 83.6%)
11/10 03:02:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7074	Prec@(1,5) (55.2%, 83.6%)
11/10 03:02:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7034	Prec@(1,5) (55.1%, 83.6%)
11/10 03:02:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 55.0640%
11/10 03:02:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:02:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0720%
11/10 03:03:16午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8766 (0.7777)	Arch Loss 1.0617 (1.7133)	Arch Hard Loss 1.0605 (1.7116)	Arch Beta Loss 0.0015 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.0%)	
11/10 03:03:47午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8641 (0.7909)	Arch Loss 1.5319 (1.7398)	Arch Hard Loss 1.5304 (1.7381)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.9%)	
11/10 03:04:18午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8897 (0.8085)	Arch Loss 1.4924 (1.7509)	Arch Hard Loss 1.4909 (1.7493)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.7%)	
11/10 03:04:46午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8952 (0.8205)	Arch Loss 1.8936 (1.7446)	Arch Hard Loss 1.8926 (1.7430)	Arch Beta Loss 0.0013 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.5%)	
11/10 03:04:46午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 36/49] Final Prec@1 75.9880%
11/10 03:04:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7358	Prec@(1,5) (54.6%, 83.3%)
11/10 03:04:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7215	Prec@(1,5) (54.7%, 83.4%)
11/10 03:05:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7081	Prec@(1,5) (55.0%, 83.7%)
11/10 03:05:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7055	Prec@(1,5) (55.2%, 83.7%)
11/10 03:05:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 55.2320%
11/10 03:05:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:05:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2320%
11/10 03:05:37午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.7088 (0.7553)	Arch Loss 1.5574 (1.7275)	Arch Hard Loss 1.5555 (1.7259)	Arch Beta Loss 0.0023 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.3%)	
11/10 03:06:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.8901 (0.7636)	Arch Loss 1.8341 (1.7286)	Arch Hard Loss 1.8321 (1.7270)	Arch Beta Loss 0.0023 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.4%)	
11/10 03:06:39午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0513 (0.7787)	Arch Loss 1.9713 (1.7371)	Arch Hard Loss 1.9694 (1.7355)	Arch Beta Loss 0.0023 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.3%)	
11/10 03:07:07午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.7164 (0.7833)	Arch Loss 1.2408 (1.7380)	Arch Hard Loss 1.2387 (1.7364)	Arch Beta Loss 0.0024 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
11/10 03:07:08午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 37/49] Final Prec@1 76.9920%
11/10 03:07:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.6664	Prec@(1,5) (56.0%, 84.3%)
11/10 03:07:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7039	Prec@(1,5) (55.5%, 83.8%)
11/10 03:07:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.6857	Prec@(1,5) (55.7%, 84.1%)
11/10 03:07:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.6857	Prec@(1,5) (55.7%, 84.1%)
11/10 03:07:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 55.6760%
11/10 03:07:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:07:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6760%
11/10 03:07:57午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6371 (0.7363)	Arch Loss 1.5726 (1.7048)	Arch Hard Loss 1.5709 (1.7030)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.7%)	
11/10 03:08:28午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7796 (0.7595)	Arch Loss 1.8505 (1.7233)	Arch Hard Loss 1.8493 (1.7215)	Arch Beta Loss 0.0014 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.3%)	
11/10 03:08:58午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.0237 (0.7576)	Arch Loss 1.3826 (1.7338)	Arch Hard Loss 1.3807 (1.7320)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.3%)	
11/10 03:09:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.8317 (0.7665)	Arch Loss 1.9372 (1.7313)	Arch Hard Loss 1.9354 (1.7296)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
11/10 03:09:26午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 38/49] Final Prec@1 77.5640%
11/10 03:09:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.6870	Prec@(1,5) (56.3%, 84.1%)
11/10 03:09:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7013	Prec@(1,5) (55.4%, 84.0%)
11/10 03:09:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.6978	Prec@(1,5) (55.4%, 83.7%)
11/10 03:09:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.6996	Prec@(1,5) (55.4%, 83.7%)
11/10 03:09:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 55.3720%
11/10 03:09:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:09:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6760%
11/10 03:10:15午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.8940 (0.6958)	Arch Loss 2.0650 (1.7701)	Arch Hard Loss 2.0636 (1.7683)	Arch Beta Loss 0.0015 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.1%)	
11/10 03:10:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7303 (0.7156)	Arch Loss 1.4409 (1.7814)	Arch Hard Loss 1.4393 (1.7796)	Arch Beta Loss 0.0019 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.7%)	
11/10 03:11:16午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.9350 (0.7327)	Arch Loss 1.4106 (1.7599)	Arch Hard Loss 1.4092 (1.7581)	Arch Beta Loss 0.0015 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.4%)	
11/10 03:11:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8075 (0.7432)	Arch Loss 1.3344 (1.7521)	Arch Hard Loss 1.3332 (1.7503)	Arch Beta Loss 0.0014 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.3%)	
11/10 03:11:45午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 39/49] Final Prec@1 78.2560%
11/10 03:11:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.6951	Prec@(1,5) (55.2%, 84.0%)
11/10 03:11:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7053	Prec@(1,5) (55.3%, 83.8%)
11/10 03:11:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.6983	Prec@(1,5) (55.7%, 83.7%)
11/10 03:12:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7000	Prec@(1,5) (55.4%, 83.7%)
11/10 03:12:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 55.3920%
11/10 03:12:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:12:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6760%
11/10 03:12:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.8128 (0.6859)	Arch Loss 1.8131 (1.7306)	Arch Hard Loss 1.8107 (1.7289)	Arch Beta Loss 0.0027 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.0%)	
11/10 03:13:07午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.6177 (0.6924)	Arch Loss 1.3059 (1.7231)	Arch Hard Loss 1.3039 (1.7213)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.1%)	
11/10 03:13:38午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6069 (0.6983)	Arch Loss 1.6674 (1.7210)	Arch Hard Loss 1.6655 (1.7192)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 96.9%)	
11/10 03:14:07午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.6286 (0.7144)	Arch Loss 2.0657 (1.7374)	Arch Hard Loss 2.0639 (1.7356)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.8%)	
11/10 03:14:07午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 40/49] Final Prec@1 79.5080%
11/10 03:14:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7207	Prec@(1,5) (54.3%, 83.0%)
11/10 03:14:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.6653	Prec@(1,5) (55.7%, 84.1%)
11/10 03:14:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.6796	Prec@(1,5) (55.8%, 84.0%)
11/10 03:14:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.6890	Prec@(1,5) (55.7%, 84.0%)
11/10 03:14:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 55.7400%
11/10 03:14:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:14:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.7400%
11/10 03:14:58午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.4921 (0.6734)	Arch Loss 1.8762 (1.7446)	Arch Hard Loss 1.8745 (1.7426)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
11/10 03:15:29午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.8038 (0.6840)	Arch Loss 1.8756 (1.7569)	Arch Hard Loss 1.8746 (1.7550)	Arch Beta Loss 0.0011 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.0%)	
11/10 03:16:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.7693 (0.6837)	Arch Loss 1.2514 (1.7476)	Arch Hard Loss 1.2500 (1.7457)	Arch Beta Loss 0.0015 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.1%)	
11/10 03:16:29午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7043 (0.6889)	Arch Loss 1.6685 (1.7379)	Arch Hard Loss 1.6666 (1.7360)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
11/10 03:16:29午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 41/49] Final Prec@1 80.3320%
11/10 03:16:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.6801	Prec@(1,5) (56.0%, 84.0%)
11/10 03:16:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.6789	Prec@(1,5) (56.0%, 84.1%)
11/10 03:16:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7044	Prec@(1,5) (55.9%, 83.7%)
11/10 03:16:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.6940	Prec@(1,5) (55.9%, 83.9%)
11/10 03:16:48午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 55.9480%
11/10 03:16:48午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:16:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.9480%
11/10 03:17:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7561 (0.6426)	Arch Loss 1.8425 (1.7426)	Arch Hard Loss 1.8407 (1.7409)	Arch Beta Loss 0.0019 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.2%)	
11/10 03:17:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7377 (0.6524)	Arch Loss 1.5427 (1.7310)	Arch Hard Loss 1.5412 (1.7293)	Arch Beta Loss 0.0017 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
11/10 03:18:23午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6060 (0.6571)	Arch Loss 1.8481 (1.7307)	Arch Hard Loss 1.8467 (1.7291)	Arch Beta Loss 0.0015 (0.0017)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.3%)	
11/10 03:18:51午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.7092 (0.6635)	Arch Loss 1.1910 (1.7304)	Arch Hard Loss 1.1897 (1.7288)	Arch Beta Loss 0.0014 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.1%)	
11/10 03:18:52午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 42/49] Final Prec@1 80.8360%
11/10 03:18:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6738	Prec@(1,5) (56.1%, 84.2%)
11/10 03:19:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.6858	Prec@(1,5) (56.1%, 84.1%)
11/10 03:19:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.6936	Prec@(1,5) (55.8%, 84.0%)
11/10 03:19:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.6831	Prec@(1,5) (55.9%, 84.1%)
11/10 03:19:10午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 55.9400%
11/10 03:19:10午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:19:10午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.9480%
11/10 03:19:43午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.8351 (0.6232)	Arch Loss 1.6343 (1.7471)	Arch Hard Loss 1.6326 (1.7451)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.5%)	
11/10 03:20:13午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.4521 (0.6381)	Arch Loss 1.7837 (1.7320)	Arch Hard Loss 1.7819 (1.7300)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.4%)	
11/10 03:20:44午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6232 (0.6430)	Arch Loss 1.8176 (1.7404)	Arch Hard Loss 1.8156 (1.7384)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.4%)	
11/10 03:21:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.6756 (0.6483)	Arch Loss 1.6725 (1.7378)	Arch Hard Loss 1.6707 (1.7358)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.3%)	
11/10 03:21:12午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 43/49] Final Prec@1 81.4360%
11/10 03:21:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7242	Prec@(1,5) (55.0%, 83.4%)
11/10 03:21:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6990	Prec@(1,5) (55.5%, 83.7%)
11/10 03:21:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6946	Prec@(1,5) (55.8%, 84.1%)
11/10 03:21:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.6829	Prec@(1,5) (56.0%, 84.4%)
11/10 03:21:30午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 56.0120%
11/10 03:21:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:21:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0120%
11/10 03:22:02午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5816 (0.6052)	Arch Loss 1.7241 (1.7083)	Arch Hard Loss 1.7222 (1.7063)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
11/10 03:22:31午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6248 (0.6138)	Arch Loss 1.1882 (1.7508)	Arch Hard Loss 1.1868 (1.7488)	Arch Beta Loss 0.0015 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
11/10 03:23:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6221 (0.6257)	Arch Loss 1.8495 (1.7378)	Arch Hard Loss 1.8474 (1.7358)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.5%)	
11/10 03:23:27午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5274 (0.6284)	Arch Loss 1.6836 (1.7375)	Arch Hard Loss 1.6820 (1.7355)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/10 03:23:28午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 44/49] Final Prec@1 81.9520%
11/10 03:23:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6669	Prec@(1,5) (56.9%, 84.3%)
11/10 03:23:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6691	Prec@(1,5) (56.6%, 84.2%)
11/10 03:23:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6760	Prec@(1,5) (56.6%, 84.0%)
11/10 03:23:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.6753	Prec@(1,5) (56.3%, 83.9%)
11/10 03:23:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 56.3040%
11/10 03:23:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:23:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.3040%
11/10 03:24:18午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4925 (0.5776)	Arch Loss 1.5495 (1.7078)	Arch Hard Loss 1.5478 (1.7059)	Arch Beta Loss 0.0018 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.0%)	
11/10 03:24:49午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.6295 (0.5897)	Arch Loss 2.2178 (1.7195)	Arch Hard Loss 2.2161 (1.7176)	Arch Beta Loss 0.0018 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
11/10 03:25:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6558 (0.6095)	Arch Loss 1.9413 (1.7332)	Arch Hard Loss 1.9398 (1.7313)	Arch Beta Loss 0.0015 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
11/10 03:25:49午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6441 (0.6175)	Arch Loss 1.6012 (1.7296)	Arch Hard Loss 1.6001 (1.7276)	Arch Beta Loss 0.0011 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
11/10 03:25:49午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 45/49] Final Prec@1 82.6120%
11/10 03:25:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6817	Prec@(1,5) (56.0%, 84.1%)
11/10 03:25:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.6648	Prec@(1,5) (56.7%, 84.4%)
11/10 03:26:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.6694	Prec@(1,5) (56.6%, 84.4%)
11/10 03:26:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.6815	Prec@(1,5) (56.3%, 84.3%)
11/10 03:26:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 56.3040%
11/10 03:26:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/10 03:26:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.3040%
11/10 03:26:40午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.5650 (0.5846)	Arch Loss 1.8058 (1.7197)	Arch Hard Loss 1.8033 (1.7176)	Arch Beta Loss 0.0026 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
11/10 03:27:11午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5741 (0.5899)	Arch Loss 1.8557 (1.7315)	Arch Hard Loss 1.8531 (1.7294)	Arch Beta Loss 0.0027 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.9%)	
11/10 03:27:42午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.6743 (0.5973)	Arch Loss 1.7137 (1.7314)	Arch Hard Loss 1.7109 (1.7293)	Arch Beta Loss 0.0029 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.8%)	
11/10 03:28:10午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6301 (0.6060)	Arch Loss 1.6355 (1.7343)	Arch Hard Loss 1.6331 (1.7323)	Arch Beta Loss 0.0024 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.7%)	
11/10 03:28:11午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 46/49] Final Prec@1 82.9840%
11/10 03:28:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7000	Prec@(1,5) (56.4%, 83.7%)
11/10 03:28:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6968	Prec@(1,5) (56.0%, 84.0%)
11/10 03:28:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6933	Prec@(1,5) (56.1%, 84.1%)
11/10 03:28:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.6860	Prec@(1,5) (56.0%, 84.1%)
11/10 03:28:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 56.0360%
11/10 03:28:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[3, 5])
11/10 03:28:29午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.3040%
11/10 03:29:02午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.6410 (0.5797)	Arch Loss 1.4497 (1.7252)	Arch Hard Loss 1.4479 (1.7232)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
11/10 03:29:33午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.7361 (0.5908)	Arch Loss 2.0413 (1.7322)	Arch Hard Loss 2.0387 (1.7302)	Arch Beta Loss 0.0026 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.7%)	
11/10 03:30:04午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.6813 (0.5993)	Arch Loss 1.5470 (1.7385)	Arch Hard Loss 1.5450 (1.7365)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.7%)	
11/10 03:30:32午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7724 (0.6020)	Arch Loss 1.6594 (1.7385)	Arch Hard Loss 1.6573 (1.7365)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.7%)	
11/10 03:30:33午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 47/49] Final Prec@1 83.0280%
11/10 03:30:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6923	Prec@(1,5) (56.2%, 84.1%)
11/10 03:30:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6831	Prec@(1,5) (56.4%, 84.0%)
11/10 03:30:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6946	Prec@(1,5) (56.1%, 83.9%)
11/10 03:30:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6870	Prec@(1,5) (56.2%, 84.0%)
11/10 03:30:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 56.2040%
11/10 03:30:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[3, 5])
11/10 03:30:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.3040%
11/10 03:31:23午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5470 (0.5949)	Arch Loss 2.1839 (1.7213)	Arch Hard Loss 2.1822 (1.7193)	Arch Beta Loss 0.0017 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.7%)	
11/10 03:31:55午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.4599 (0.5857)	Arch Loss 1.9328 (1.7235)	Arch Hard Loss 1.9315 (1.7215)	Arch Beta Loss 0.0014 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 97.7%)	
11/10 03:32:26午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.7258 (0.5897)	Arch Loss 1.8275 (1.7394)	Arch Hard Loss 1.8257 (1.7373)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
11/10 03:32:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.7458 (0.5922)	Arch Loss 1.5364 (1.7414)	Arch Hard Loss 1.5345 (1.7393)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.8%)	
11/10 03:32:54午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 48/49] Final Prec@1 83.4520%
11/10 03:32:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7003	Prec@(1,5) (56.3%, 83.6%)
11/10 03:33:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6666	Prec@(1,5) (56.7%, 84.6%)
11/10 03:33:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6706	Prec@(1,5) (56.7%, 84.6%)
11/10 03:33:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6696	Prec@(1,5) (56.7%, 84.6%)
11/10 03:33:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 56.6920%
11/10 03:33:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[3, 5])
11/10 03:33:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/10 03:33:44午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4898 (0.5761)	Arch Loss 1.9981 (1.7007)	Arch Hard Loss 1.9951 (1.6985)	Arch Beta Loss 0.0030 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.0%)	
11/10 03:34:15午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.7902 (0.5855)	Arch Loss 1.6701 (1.7147)	Arch Hard Loss 1.6676 (1.7125)	Arch Beta Loss 0.0026 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
11/10 03:34:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.6302 (0.5866)	Arch Loss 1.8349 (1.7227)	Arch Hard Loss 1.8325 (1.7207)	Arch Beta Loss 0.0024 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
11/10 03:35:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5094 (0.5862)	Arch Loss 1.3754 (1.7390)	Arch Hard Loss 1.3737 (1.7369)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/10 03:35:13午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 49/49] Final Prec@1 83.4960%
11/10 03:35:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6693	Prec@(1,5) (56.8%, 84.6%)
11/10 03:35:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6853	Prec@(1,5) (56.4%, 84.5%)
11/10 03:35:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6801	Prec@(1,5) (56.3%, 84.5%)
11/10 03:35:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6897	Prec@(1,5) (56.3%, 84.4%)
11/10 03:35:31午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 56.3320%
11/10 03:35:31午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[3, 5])
11/10 03:35:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/10 03:35:31午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 56.6920%
11/10 03:35:31午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[3, 5])
