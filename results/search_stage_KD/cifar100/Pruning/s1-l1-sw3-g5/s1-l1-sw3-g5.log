11/20 01:36:49AM parser.py:28 [INFO] 
11/20 01:36:49AM parser.py:29 [INFO] Parameters:
11/20 01:36:49AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s1-l1-sw3-g5/DAG
11/20 01:36:49AM parser.py:31 [INFO] T=10.0
11/20 01:36:49AM parser.py:31 [INFO] ADVANCED=1
11/20 01:36:49AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/20 01:36:49AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/20 01:36:49AM parser.py:31 [INFO] ARCH_CRITERION=l1
11/20 01:36:49AM parser.py:31 [INFO] BATCH_SIZE=64
11/20 01:36:49AM parser.py:31 [INFO] CASCADE=0
11/20 01:36:49AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/20 01:36:49AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/20 01:36:49AM parser.py:31 [INFO] DATA_PATH=../data/
11/20 01:36:49AM parser.py:31 [INFO] DATASET=cifar100
11/20 01:36:49AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/20 01:36:49AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/20 01:36:49AM parser.py:31 [INFO] DISCRETE=0
11/20 01:36:49AM parser.py:31 [INFO] EPOCHS=50
11/20 01:36:49AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/20 01:36:49AM parser.py:31 [INFO] EXP_NAME=s1-l1-sw3-g5
11/20 01:36:49AM parser.py:31 [INFO] FINAL_L=0.0
11/20 01:36:49AM parser.py:31 [INFO] G=5.0
11/20 01:36:49AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/20 01:36:49AM parser.py:31 [INFO] GPUS=[0]
11/20 01:36:49AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/20 01:36:49AM parser.py:31 [INFO] INIT_CHANNELS=16
11/20 01:36:49AM parser.py:31 [INFO] L=0.0
11/20 01:36:49AM parser.py:31 [INFO] LAYERS=32
11/20 01:36:49AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/20 01:36:49AM parser.py:31 [INFO] NAME=Pruning
11/20 01:36:49AM parser.py:31 [INFO] NONKD=1
11/20 01:36:49AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s1-l1-sw3-g5
11/20 01:36:49AM parser.py:31 [INFO] PCDARTS=0
11/20 01:36:49AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s1-l1-sw3-g5/plots
11/20 01:36:49AM parser.py:31 [INFO] PRINT_FREQ=100
11/20 01:36:49AM parser.py:31 [INFO] RESET=0
11/20 01:36:49AM parser.py:31 [INFO] RESUME_PATH=None
11/20 01:36:49AM parser.py:31 [INFO] SAVE=s1-l1-sw3-g5
11/20 01:36:49AM parser.py:31 [INFO] SEED=1
11/20 01:36:49AM parser.py:31 [INFO] SHARE_STAGE=0
11/20 01:36:49AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/20 01:36:49AM parser.py:31 [INFO] SPEC_CELL=1
11/20 01:36:49AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/20 01:36:49AM parser.py:31 [INFO] TEACHER_NAME=none
11/20 01:36:49AM parser.py:31 [INFO] TEACHER_PATH=none
11/20 01:36:49AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/20 01:36:49AM parser.py:31 [INFO] TYPE=Pruning
11/20 01:36:49AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/20 01:36:49AM parser.py:31 [INFO] W_LR=0.025
11/20 01:36:49AM parser.py:31 [INFO] W_LR_MIN=0.001
11/20 01:36:49AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/20 01:36:49AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/20 01:36:49AM parser.py:31 [INFO] WORKERS=4
11/20 01:36:49AM parser.py:32 [INFO] 
11/20 01:36:50AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/20 01:37:46AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3978 (4.5398)	Arch Loss 4.5729 (4.5696)	Arch Hard Loss 4.5533 (4.5467)	Arch Beta Loss 0.0039 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 9.7%)	
11/20 01:38:41AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1335 (4.3842)	Arch Loss 4.0757 (4.4019)	Arch Hard Loss 4.0551 (4.3814)	Arch Beta Loss 0.0041 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.4%, 14.4%)	
11/20 01:39:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.7673 (4.2875)	Arch Loss 4.1528 (4.2962)	Arch Hard Loss 4.1323 (4.2765)	Arch Beta Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.4%, 17.5%)	
11/20 01:40:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2678 (4.2190)	Arch Loss 4.0150 (4.2241)	Arch Hard Loss 3.9970 (4.2048)	Arch Beta Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.0%, 19.4%)	
11/20 01:40:26AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  0/49] Final Prec@1 5.0320%
11/20 01:40:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0041	Prec@(1,5) (7.0%, 26.2%)
11/20 01:40:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9849	Prec@(1,5) (7.5%, 26.7%)
11/20 01:40:54AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9865	Prec@(1,5) (7.4%, 26.6%)
11/20 01:41:02AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9788	Prec@(1,5) (7.4%, 26.8%)
11/20 01:41:02AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 7.4160%
11/20 01:41:02AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[5, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[6, 8])
11/20 01:41:03AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.4160%
11/20 01:41:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8151 (3.8765)	Arch Loss 3.9903 (3.8812)	Arch Hard Loss 3.9747 (3.8634)	Arch Beta Loss 0.0031 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.0%, 29.6%)	
11/20 01:42:53午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.7713 (3.8370)	Arch Loss 3.9546 (3.8403)	Arch Hard Loss 3.9386 (3.8224)	Arch Beta Loss 0.0032 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.6%, 31.0%)	
11/20 01:43:47午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8414 (3.7984)	Arch Loss 3.7810 (3.7969)	Arch Hard Loss 3.7638 (3.7790)	Arch Beta Loss 0.0034 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.2%, 32.4%)	
11/20 01:44:36午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.4781 (3.7671)	Arch Loss 3.5636 (3.7618)	Arch Hard Loss 3.5454 (3.7440)	Arch Beta Loss 0.0036 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.8%, 33.4%)	
11/20 01:44:37午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  1/49] Final Prec@1 10.8400%
11/20 01:44:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6429	Prec@(1,5) (13.4%, 37.9%)
11/20 01:44:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6460	Prec@(1,5) (12.9%, 38.0%)
11/20 01:45:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6320	Prec@(1,5) (13.1%, 38.5%)
11/20 01:45:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6241	Prec@(1,5) (13.2%, 38.6%)
11/20 01:45:13午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 13.1840%
11/20 01:45:13午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[6, 11])
11/20 01:45:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.1840%
11/20 01:46:09午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.3574 (3.5364)	Arch Loss 3.5149 (3.5824)	Arch Hard Loss 3.4960 (3.5648)	Arch Beta Loss 0.0038 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.1%, 40.1%)	
11/20 01:47:04午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5323 (3.5313)	Arch Loss 3.4015 (3.5542)	Arch Hard Loss 3.3825 (3.5366)	Arch Beta Loss 0.0038 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 40.2%)	
11/20 01:47:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.3784 (3.4934)	Arch Loss 3.4954 (3.5251)	Arch Hard Loss 3.4780 (3.5076)	Arch Beta Loss 0.0035 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.5%)	
11/20 01:48:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.2705 (3.4709)	Arch Loss 3.2223 (3.4920)	Arch Hard Loss 3.2053 (3.4744)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.6%, 42.4%)	
11/20 01:48:48午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  2/49] Final Prec@1 15.6120%
11/20 01:48:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3479	Prec@(1,5) (18.0%, 46.2%)
11/20 01:49:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3550	Prec@(1,5) (18.1%, 46.1%)
11/20 01:49:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3553	Prec@(1,5) (18.0%, 46.0%)
11/20 01:49:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3556	Prec@(1,5) (17.9%, 45.9%)
11/20 01:49:24午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 17.8800%
11/20 01:49:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[2, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[3, 6])
11/20 01:49:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.8800%
11/20 01:50:20午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.2732 (3.2928)	Arch Loss 3.5421 (3.3745)	Arch Hard Loss 3.5251 (3.3570)	Arch Beta Loss 0.0034 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.8%, 47.1%)	
11/20 01:51:15午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.0616 (3.2667)	Arch Loss 3.1099 (3.3302)	Arch Hard Loss 3.0943 (3.3129)	Arch Beta Loss 0.0031 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.1%, 48.0%)	
11/20 01:52:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.2493 (3.2530)	Arch Loss 3.2094 (3.2842)	Arch Hard Loss 3.1929 (3.2669)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.4%, 48.3%)	
11/20 01:52:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.8517 (3.2314)	Arch Loss 3.2476 (3.2643)	Arch Hard Loss 3.2322 (3.2471)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.7%, 48.9%)	
11/20 01:52:59午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  3/49] Final Prec@1 19.7080%
11/20 01:53:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1948	Prec@(1,5) (21.4%, 50.5%)
11/20 01:53:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1861	Prec@(1,5) (21.4%, 50.4%)
11/20 01:53:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1844	Prec@(1,5) (21.1%, 50.4%)
11/20 01:53:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1844	Prec@(1,5) (21.2%, 50.4%)
11/20 01:53:36午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 21.1880%
11/20 01:53:36午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[2, 10], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[8, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[8, 10])
11/20 01:53:36午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.1880%
11/20 01:54:31午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.2451 (3.0564)	Arch Loss 2.9567 (3.1717)	Arch Hard Loss 2.9397 (3.1546)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 53.6%)	
11/20 01:55:26午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.9558 (3.0457)	Arch Loss 2.7800 (3.1474)	Arch Hard Loss 2.7627 (3.1303)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.3%, 53.9%)	
11/20 01:56:21午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.2773 (3.0478)	Arch Loss 2.8987 (3.1228)	Arch Hard Loss 2.8827 (3.1057)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.6%, 54.0%)	
11/20 01:57:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.0457 (3.0317)	Arch Loss 2.7510 (3.0983)	Arch Hard Loss 2.7332 (3.0812)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.8%, 54.4%)	
11/20 01:57:10午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  4/49] Final Prec@1 23.8160%
11/20 01:57:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0050	Prec@(1,5) (24.4%, 55.2%)
11/20 01:57:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9876	Prec@(1,5) (24.8%, 55.8%)
11/20 01:57:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9893	Prec@(1,5) (24.7%, 55.7%)
11/20 01:57:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9939	Prec@(1,5) (24.6%, 55.7%)
11/20 01:57:47午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 24.6120%
11/20 01:57:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[3, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[5, 10])
11/20 01:57:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.6120%
11/20 01:58:42午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.8771 (2.9019)	Arch Loss 2.9469 (2.9732)	Arch Hard Loss 2.9314 (2.9561)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.6%, 57.9%)	
11/20 01:59:37午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.7136 (2.8860)	Arch Loss 2.7144 (2.9547)	Arch Hard Loss 2.6969 (2.9377)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.1%, 58.4%)	
11/20 02:00:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.1767 (2.8833)	Arch Loss 2.6429 (2.9366)	Arch Hard Loss 2.6261 (2.9196)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.3%, 58.6%)	
11/20 02:01:21午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6666 (2.8665)	Arch Loss 2.8799 (2.9261)	Arch Hard Loss 2.8634 (2.9091)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.6%, 58.9%)	
11/20 02:01:21午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  5/49] Final Prec@1 26.5680%
11/20 02:01:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.9353	Prec@(1,5) (26.9%, 58.2%)
11/20 02:01:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.9573	Prec@(1,5) (26.2%, 57.5%)
11/20 02:01:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.9496	Prec@(1,5) (26.4%, 57.5%)
11/20 02:01:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.9464	Prec@(1,5) (26.5%, 57.6%)
11/20 02:01:58午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 26.5200%
11/20 02:01:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[4, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[4, 10])
11/20 02:01:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.5200%
11/20 02:02:53午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.9953 (2.7234)	Arch Loss 3.1141 (2.8642)	Arch Hard Loss 3.0974 (2.8474)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.2%, 62.1%)	
11/20 02:03:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.1854 (2.7275)	Arch Loss 2.5897 (2.8528)	Arch Hard Loss 2.5725 (2.8361)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.9%, 62.2%)	
11/20 02:04:42午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.7468 (2.7253)	Arch Loss 2.7380 (2.8225)	Arch Hard Loss 2.7200 (2.8060)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 61.9%)	
11/20 02:05:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7643 (2.7159)	Arch Loss 2.8593 (2.8115)	Arch Hard Loss 2.8426 (2.7949)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.2%, 62.2%)	
11/20 02:05:32午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  6/49] Final Prec@1 30.2240%
11/20 02:05:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6801	Prec@(1,5) (31.6%, 63.1%)
11/20 02:05:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7021	Prec@(1,5) (30.6%, 62.4%)
11/20 02:06:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7048	Prec@(1,5) (30.6%, 62.7%)
11/20 02:06:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7064	Prec@(1,5) (30.5%, 62.6%)
11/20 02:06:08午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 30.4800%
11/20 02:06:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 9], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[4, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
11/20 02:06:09午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.4800%
11/20 02:07:04午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.3587 (2.5890)	Arch Loss 2.8158 (2.7261)	Arch Hard Loss 2.7989 (2.7095)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 65.5%)	
11/20 02:07:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.6852 (2.5856)	Arch Loss 2.6026 (2.7197)	Arch Hard Loss 2.5858 (2.7031)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.1%, 65.8%)	
11/20 02:08:53午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.5736 (2.5753)	Arch Loss 2.4509 (2.7026)	Arch Hard Loss 2.4352 (2.6859)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.6%, 65.9%)	
11/20 02:09:42午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.2034 (2.5647)	Arch Loss 2.6049 (2.6951)	Arch Hard Loss 2.5883 (2.6784)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.8%, 65.9%)	
11/20 02:09:42午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  7/49] Final Prec@1 32.7720%
11/20 02:09:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5768	Prec@(1,5) (33.7%, 65.4%)
11/20 02:10:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5772	Prec@(1,5) (33.5%, 65.8%)
11/20 02:10:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5845	Prec@(1,5) (33.1%, 65.7%)
11/20 02:10:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5865	Prec@(1,5) (33.0%, 65.5%)
11/20 02:10:19午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 32.9840%
11/20 02:10:19午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[7, 9], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 9], DAG3=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[4, 10])
11/20 02:10:19午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.9840%
11/20 02:11:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.2891 (2.4294)	Arch Loss 2.8223 (2.6579)	Arch Hard Loss 2.8050 (2.6410)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.5%, 68.0%)	
11/20 02:12:09午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.4286 (2.4589)	Arch Loss 2.4265 (2.6324)	Arch Hard Loss 2.4091 (2.6156)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 67.8%)	
11/20 02:13:03午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.3874 (2.4539)	Arch Loss 2.5824 (2.6031)	Arch Hard Loss 2.5641 (2.5862)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.1%)	
11/20 02:13:52午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.7424 (2.4514)	Arch Loss 2.6767 (2.5888)	Arch Hard Loss 2.6610 (2.5719)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.3%)	
11/20 02:13:53午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  8/49] Final Prec@1 35.5320%
11/20 02:14:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5436	Prec@(1,5) (34.8%, 66.5%)
11/20 02:14:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5406	Prec@(1,5) (34.7%, 67.0%)
11/20 02:14:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5665	Prec@(1,5) (34.2%, 66.5%)
11/20 02:14:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5710	Prec@(1,5) (33.9%, 66.4%)
11/20 02:14:29午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 33.9200%
11/20 02:14:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[9, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[7, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/20 02:14:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.9200%
11/20 02:15:25午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.6583 (2.3271)	Arch Loss 2.6600 (2.5297)	Arch Hard Loss 2.6434 (2.5130)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.5%)	
11/20 02:16:19午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.2232 (2.3479)	Arch Loss 2.4101 (2.5076)	Arch Hard Loss 2.3928 (2.4910)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.1%, 70.6%)	
11/20 02:17:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.2203 (2.3466)	Arch Loss 2.4403 (2.5229)	Arch Hard Loss 2.4229 (2.5063)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.0%, 70.7%)	
11/20 02:18:03午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1055 (2.3410)	Arch Loss 2.3837 (2.5033)	Arch Hard Loss 2.3688 (2.4867)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 70.9%)	
11/20 02:18:03午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  9/49] Final Prec@1 37.8520%
11/20 02:18:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4072	Prec@(1,5) (36.8%, 69.3%)
11/20 02:18:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4172	Prec@(1,5) (36.6%, 69.2%)
11/20 02:18:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4295	Prec@(1,5) (36.2%, 69.0%)
11/20 02:18:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4259	Prec@(1,5) (36.3%, 69.0%)
11/20 02:18:39午前 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 36.3480%
11/20 02:18:39午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[6, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 7])
11/20 02:18:40午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.3480%
11/20 02:19:35午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.0332 (2.2245)	Arch Loss 2.3570 (2.4571)	Arch Hard Loss 2.3427 (2.4409)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.3%, 73.7%)	
11/20 02:20:30午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.2469 (2.2352)	Arch Loss 2.3200 (2.4585)	Arch Hard Loss 2.3047 (2.4423)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 73.3%)	
11/20 02:21:24午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3973 (2.2423)	Arch Loss 2.2353 (2.4431)	Arch Hard Loss 2.2178 (2.4268)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 73.1%)	
11/20 02:22:13午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1746 (2.2476)	Arch Loss 2.4225 (2.4291)	Arch Hard Loss 2.4045 (2.4128)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.9%)	
11/20 02:22:13午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 10/49] Final Prec@1 39.9840%
11/20 02:22:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3617	Prec@(1,5) (37.6%, 71.3%)
11/20 02:22:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3626	Prec@(1,5) (37.8%, 70.9%)
11/20 02:22:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3667	Prec@(1,5) (37.7%, 70.5%)
11/20 02:22:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3782	Prec@(1,5) (37.2%, 70.4%)
11/20 02:22:50午前 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 37.2520%
11/20 02:22:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[8, 10], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 6])
11/20 02:22:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.2520%
11/20 02:23:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.0123 (2.1178)	Arch Loss 2.4377 (2.3941)	Arch Hard Loss 2.4197 (2.3776)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.0%)	
11/20 02:24:40午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.1203 (2.1344)	Arch Loss 2.5211 (2.3539)	Arch Hard Loss 2.5046 (2.3373)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 75.1%)	
11/20 02:25:35午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.0319 (2.1386)	Arch Loss 2.4119 (2.3638)	Arch Hard Loss 2.3962 (2.3471)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.8%, 75.1%)	
11/20 02:26:24午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.3583 (2.1475)	Arch Loss 2.3993 (2.3638)	Arch Hard Loss 2.3824 (2.3472)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 74.9%)	
11/20 02:26:24午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 11/49] Final Prec@1 41.5200%
11/20 02:26:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3644	Prec@(1,5) (37.7%, 70.2%)
11/20 02:26:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3744	Prec@(1,5) (37.9%, 70.1%)
11/20 02:26:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3792	Prec@(1,5) (37.9%, 70.3%)
11/20 02:27:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3845	Prec@(1,5) (37.8%, 70.2%)
11/20 02:27:01午前 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 37.7600%
11/20 02:27:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[7, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/20 02:27:01午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.7600%
11/20 02:27:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4409 (2.0439)	Arch Loss 2.1625 (2.3650)	Arch Hard Loss 2.1457 (2.3486)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.3%, 77.1%)	
11/20 02:28:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.1780 (2.0549)	Arch Loss 2.1119 (2.3295)	Arch Hard Loss 2.0953 (2.3131)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 77.0%)	
11/20 02:29:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9321 (2.0587)	Arch Loss 2.4374 (2.3084)	Arch Hard Loss 2.4200 (2.2920)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 77.0%)	
11/20 02:30:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.9708 (2.0618)	Arch Loss 2.1774 (2.3044)	Arch Hard Loss 2.1613 (2.2879)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 76.9%)	
11/20 02:30:35午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 12/49] Final Prec@1 43.6520%
11/20 02:30:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2244	Prec@(1,5) (41.1%, 73.1%)
11/20 02:30:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2368	Prec@(1,5) (41.0%, 73.1%)
11/20 02:31:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2218	Prec@(1,5) (41.3%, 73.5%)
11/20 02:31:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2268	Prec@(1,5) (41.3%, 73.2%)
11/20 02:31:11午前 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 41.2440%
11/20 02:31:11午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[7, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/20 02:31:12午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.2440%
11/20 02:32:07午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.8294 (1.9489)	Arch Loss 2.0628 (2.2618)	Arch Hard Loss 2.0451 (2.2450)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 78.7%)	
11/20 02:33:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.1968 (1.9689)	Arch Loss 2.7360 (2.2734)	Arch Hard Loss 2.7190 (2.2567)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.4%)	
11/20 02:33:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.0558 (1.9835)	Arch Loss 2.3888 (2.2738)	Arch Hard Loss 2.3724 (2.2571)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 78.2%)	
11/20 02:34:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.1383 (1.9907)	Arch Loss 2.1682 (2.2644)	Arch Hard Loss 2.1525 (2.2476)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.0%)	
11/20 02:34:45午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 13/49] Final Prec@1 45.4240%
11/20 02:34:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2267	Prec@(1,5) (40.6%, 74.2%)
11/20 02:35:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2308	Prec@(1,5) (40.7%, 73.6%)
11/20 02:35:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2157	Prec@(1,5) (40.9%, 73.7%)
11/20 02:35:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2152	Prec@(1,5) (41.1%, 73.8%)
11/20 02:35:22午前 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 41.1040%
11/20 02:35:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[7, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[4, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/20 02:35:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.2440%
11/20 02:36:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.2187 (1.8777)	Arch Loss 2.4194 (2.2272)	Arch Hard Loss 2.4022 (2.2103)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.0%)	
11/20 02:37:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.5210 (1.8807)	Arch Loss 2.2272 (2.2085)	Arch Hard Loss 2.2088 (2.1917)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.1%, 80.0%)	
11/20 02:38:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.8452 (1.8944)	Arch Loss 2.1161 (2.1927)	Arch Hard Loss 2.0996 (2.1759)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.7%, 79.6%)	
11/20 02:38:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.7558 (1.9192)	Arch Loss 2.4633 (2.1944)	Arch Hard Loss 2.4477 (2.1776)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.0%, 79.1%)	
11/20 02:38:56午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 14/49] Final Prec@1 46.9800%
11/20 02:39:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1669	Prec@(1,5) (43.1%, 74.0%)
11/20 02:39:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1643	Prec@(1,5) (43.0%, 74.0%)
11/20 02:39:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1569	Prec@(1,5) (43.0%, 74.5%)
11/20 02:39:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1607	Prec@(1,5) (42.8%, 74.4%)
11/20 02:39:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 42.7880%
11/20 02:39:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 10])
11/20 02:39:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.7880%
11/20 02:40:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.6772 (1.8032)	Arch Loss 2.2363 (2.1584)	Arch Hard Loss 2.2199 (2.1414)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.3%)	
11/20 02:41:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.9185 (1.8478)	Arch Loss 1.9492 (2.1875)	Arch Hard Loss 1.9334 (2.1706)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.9%)	
11/20 02:42:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.8823 (1.8588)	Arch Loss 2.2203 (2.1689)	Arch Hard Loss 2.2041 (2.1521)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.4%, 80.6%)	
11/20 02:43:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.7427 (1.8592)	Arch Loss 1.7866 (2.1668)	Arch Hard Loss 1.7700 (2.1500)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.3%, 80.6%)	
11/20 02:43:07午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 15/49] Final Prec@1 48.2960%
11/20 02:43:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1398	Prec@(1,5) (42.4%, 75.4%)
11/20 02:43:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1383	Prec@(1,5) (42.6%, 75.2%)
11/20 02:43:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1360	Prec@(1,5) (42.9%, 75.3%)
11/20 02:43:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1455	Prec@(1,5) (42.7%, 75.2%)
11/20 02:43:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 42.7440%
11/20 02:43:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[5, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 11])
11/20 02:43:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.7880%
11/20 02:44:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.8289 (1.7866)	Arch Loss 2.0415 (2.1302)	Arch Hard Loss 2.0264 (2.1139)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.7%)	
11/20 02:45:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9028 (1.7855)	Arch Loss 2.2100 (2.1314)	Arch Hard Loss 2.1937 (2.1153)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.7%)	
11/20 02:46:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.6334 (1.8009)	Arch Loss 2.4022 (2.1266)	Arch Hard Loss 2.3860 (2.1104)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.4%)	
11/20 02:47:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.8020 (1.8021)	Arch Loss 2.0903 (2.1265)	Arch Hard Loss 2.0738 (2.1103)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.5%)	
11/20 02:47:17午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 16/49] Final Prec@1 50.2320%
11/20 02:47:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0692	Prec@(1,5) (44.7%, 76.7%)
11/20 02:47:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0614	Prec@(1,5) (45.0%, 76.6%)
11/20 02:47:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0662	Prec@(1,5) (45.1%, 76.5%)
11/20 02:47:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0697	Prec@(1,5) (45.0%, 76.4%)
11/20 02:47:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 45.0200%
11/20 02:47:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
11/20 02:47:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0200%
11/20 02:48:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.5086 (1.6814)	Arch Loss 2.1785 (2.1079)	Arch Hard Loss 2.1622 (2.0916)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.4%)	
11/20 02:49:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.9046 (1.6999)	Arch Loss 2.3514 (2.1059)	Arch Hard Loss 2.3343 (2.0896)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.3%)	
11/20 02:50:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8771 (1.7110)	Arch Loss 2.1184 (2.1013)	Arch Hard Loss 2.1020 (2.0851)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 83.2%)	
11/20 02:51:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.9281 (1.7242)	Arch Loss 2.2728 (2.0930)	Arch Hard Loss 2.2575 (2.0768)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.6%, 83.0%)	
11/20 02:51:28午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 17/49] Final Prec@1 51.5840%
11/20 02:51:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0514	Prec@(1,5) (45.6%, 76.7%)
11/20 02:51:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0608	Prec@(1,5) (45.4%, 76.5%)
11/20 02:51:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0593	Prec@(1,5) (45.3%, 76.7%)
11/20 02:52:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0594	Prec@(1,5) (45.1%, 76.6%)
11/20 02:52:04午前 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 45.0960%
11/20 02:52:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[2, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/20 02:52:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0960%
11/20 02:53:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4100 (1.6353)	Arch Loss 2.2495 (2.1226)	Arch Hard Loss 2.2333 (2.1060)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.6%)	
11/20 02:53:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4920 (1.6597)	Arch Loss 2.3132 (2.0971)	Arch Hard Loss 2.2956 (2.0805)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 84.2%)	
11/20 02:54:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.3257 (1.6606)	Arch Loss 2.3229 (2.0727)	Arch Hard Loss 2.3046 (2.0561)	Arch Beta Loss 0.0037 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 84.1%)	
11/20 02:55:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.5515 (1.6729)	Arch Loss 2.1910 (2.0607)	Arch Hard Loss 2.1734 (2.0442)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.8%)	
11/20 02:55:39午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 18/49] Final Prec@1 52.8640%
11/20 02:55:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9725	Prec@(1,5) (46.3%, 78.6%)
11/20 02:55:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9873	Prec@(1,5) (46.3%, 78.1%)
11/20 02:56:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9867	Prec@(1,5) (46.7%, 78.2%)
11/20 02:56:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9877	Prec@(1,5) (46.6%, 78.0%)
11/20 02:56:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 46.5240%
11/20 02:56:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[5, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/20 02:56:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.5240%
11/20 02:57:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.6612 (1.5970)	Arch Loss 2.1400 (2.0434)	Arch Hard Loss 2.1242 (2.0269)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.3%, 85.4%)	
11/20 02:58:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6666 (1.5895)	Arch Loss 1.9514 (2.0616)	Arch Hard Loss 1.9352 (2.0450)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.4%)	
11/20 02:59:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.7159 (1.6080)	Arch Loss 2.4882 (2.0585)	Arch Hard Loss 2.4709 (2.0419)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.5%, 85.0%)	
11/20 02:59:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.4704 (1.6249)	Arch Loss 2.4837 (2.0507)	Arch Hard Loss 2.4676 (2.0341)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.7%)	
11/20 02:59:49午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 19/49] Final Prec@1 54.0320%
11/20 02:59:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9828	Prec@(1,5) (46.5%, 78.1%)
11/20 03:00:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9864	Prec@(1,5) (46.6%, 78.2%)
11/20 03:00:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9754	Prec@(1,5) (47.0%, 78.4%)
11/20 03:00:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9772	Prec@(1,5) (46.8%, 78.3%)
11/20 03:00:26午前 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 46.8120%
11/20 03:00:26午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[6, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 11])
11/20 03:00:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.8120%
11/20 03:01:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.3855 (1.5193)	Arch Loss 1.7683 (2.0119)	Arch Hard Loss 1.7493 (1.9950)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.2%)	
11/20 03:02:16午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5886 (1.5401)	Arch Loss 2.3606 (2.0175)	Arch Hard Loss 2.3421 (2.0006)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.7%, 86.0%)	
11/20 03:03:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.2159 (1.5516)	Arch Loss 2.3311 (2.0061)	Arch Hard Loss 2.3147 (1.9892)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.7%)	
11/20 03:04:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4740 (1.5560)	Arch Loss 1.8839 (2.0088)	Arch Hard Loss 1.8670 (1.9920)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.6%)	
11/20 03:04:00午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 20/49] Final Prec@1 55.4520%
11/20 03:04:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0132	Prec@(1,5) (46.4%, 77.9%)
11/20 03:04:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0054	Prec@(1,5) (46.7%, 78.0%)
11/20 03:04:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0108	Prec@(1,5) (46.7%, 77.8%)
11/20 03:04:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0100	Prec@(1,5) (46.9%, 77.9%)
11/20 03:04:37午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 46.8600%
11/20 03:04:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 10])
11/20 03:04:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.8600%
11/20 03:05:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.1907 (1.4727)	Arch Loss 2.2442 (1.9939)	Arch Hard Loss 2.2287 (1.9770)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.9%)	
11/20 03:06:27午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3798 (1.5100)	Arch Loss 1.6983 (2.0158)	Arch Hard Loss 1.6825 (1.9989)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.3%)	
11/20 03:07:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.5508 (1.5184)	Arch Loss 2.1522 (1.9895)	Arch Hard Loss 2.1341 (1.9725)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.3%)	
11/20 03:08:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.4011 (1.5193)	Arch Loss 1.7560 (1.9939)	Arch Hard Loss 1.7386 (1.9770)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.2%)	
11/20 03:08:11午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 21/49] Final Prec@1 56.6400%
11/20 03:08:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9564	Prec@(1,5) (47.9%, 78.5%)
11/20 03:08:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9523	Prec@(1,5) (48.1%, 78.9%)
11/20 03:08:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9705	Prec@(1,5) (47.7%, 78.6%)
11/20 03:08:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9722	Prec@(1,5) (47.6%, 78.6%)
11/20 03:08:48午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 47.6040%
11/20 03:08:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 9])
11/20 03:08:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.6040%
11/20 03:09:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3386 (1.3856)	Arch Loss 1.7730 (2.0052)	Arch Hard Loss 1.7554 (1.9888)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.4%)	
11/20 03:10:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.3047 (1.4264)	Arch Loss 1.8752 (1.9860)	Arch Hard Loss 1.8595 (1.9697)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.6%)	
11/20 03:11:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3879 (1.4547)	Arch Loss 1.9983 (1.9813)	Arch Hard Loss 1.9824 (1.9650)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.2%)	
11/20 03:12:21午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.3523 (1.4628)	Arch Loss 1.7131 (1.9744)	Arch Hard Loss 1.6962 (1.9582)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.1%)	
11/20 03:12:22午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 22/49] Final Prec@1 58.1240%
11/20 03:12:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9787	Prec@(1,5) (48.0%, 78.8%)
11/20 03:12:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9336	Prec@(1,5) (49.1%, 79.3%)
11/20 03:12:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9351	Prec@(1,5) (48.8%, 79.1%)
11/20 03:12:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9419	Prec@(1,5) (48.5%, 79.1%)
11/20 03:12:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 48.5160%
11/20 03:12:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/20 03:12:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5160%
11/20 03:13:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4807 (1.3553)	Arch Loss 1.7054 (1.9594)	Arch Hard Loss 1.6903 (1.9435)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.0%)	
11/20 03:14:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3107 (1.3877)	Arch Loss 1.9605 (1.9495)	Arch Hard Loss 1.9454 (1.9335)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.6%)	
11/20 03:15:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2962 (1.4049)	Arch Loss 1.9653 (1.9488)	Arch Hard Loss 1.9498 (1.9329)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 88.1%)	
11/20 03:16:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3041 (1.4160)	Arch Loss 1.7930 (1.9425)	Arch Hard Loss 1.7775 (1.9267)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.9%)	
11/20 03:16:33午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 23/49] Final Prec@1 59.1360%
11/20 03:16:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9128	Prec@(1,5) (48.8%, 79.2%)
11/20 03:16:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9087	Prec@(1,5) (49.0%, 79.5%)
11/20 03:17:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9111	Prec@(1,5) (48.7%, 79.6%)
11/20 03:17:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9178	Prec@(1,5) (48.7%, 79.4%)
11/20 03:17:09午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 48.7080%
11/20 03:17:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[2, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[7, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 10])
11/20 03:17:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.7080%
11/20 03:18:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0592 (1.3323)	Arch Loss 1.5608 (1.9209)	Arch Hard Loss 1.5428 (1.9049)	Arch Beta Loss 0.0036 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.2%)	
11/20 03:19:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2695 (1.3347)	Arch Loss 1.8220 (1.9399)	Arch Hard Loss 1.8049 (1.9239)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.0%)	
11/20 03:19:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.1806 (1.3574)	Arch Loss 2.7695 (1.9427)	Arch Hard Loss 2.7534 (1.9267)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.5%)	
11/20 03:20:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.3302 (1.3745)	Arch Loss 1.8246 (1.9445)	Arch Hard Loss 1.8095 (1.9284)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.3%)	
11/20 03:20:44午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 24/49] Final Prec@1 60.6320%
11/20 03:20:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8716	Prec@(1,5) (49.2%, 80.5%)
11/20 03:21:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8597	Prec@(1,5) (49.8%, 80.5%)
11/20 03:21:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8513	Prec@(1,5) (50.2%, 80.7%)
11/20 03:21:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8582	Prec@(1,5) (50.2%, 80.6%)
11/20 03:21:20午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 50.1840%
11/20 03:21:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[6, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 8])
11/20 03:21:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1840%
11/20 03:22:16午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.0289 (1.2531)	Arch Loss 1.9362 (1.9254)	Arch Hard Loss 1.9189 (1.9091)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.4%)	
11/20 03:23:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.7054 (1.2964)	Arch Loss 1.8310 (1.9207)	Arch Hard Loss 1.8156 (1.9042)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.8%)	
11/20 03:24:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.5715 (1.3171)	Arch Loss 1.7877 (1.9190)	Arch Hard Loss 1.7715 (1.9023)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.3%)	
11/20 03:24:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.4459 (1.3223)	Arch Loss 2.1477 (1.9245)	Arch Hard Loss 2.1309 (1.9078)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.2%)	
11/20 03:24:55午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 25/49] Final Prec@1 61.6440%
11/20 03:25:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8854	Prec@(1,5) (50.0%, 80.1%)
11/20 03:25:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8661	Prec@(1,5) (50.2%, 80.5%)
11/20 03:25:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8653	Prec@(1,5) (50.3%, 80.5%)
11/20 03:25:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8692	Prec@(1,5) (50.3%, 80.4%)
11/20 03:25:31午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 50.2640%
11/20 03:25:31午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 6])
11/20 03:25:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.2640%
11/20 03:26:27午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.2146 (1.2359)	Arch Loss 2.1953 (1.9057)	Arch Hard Loss 2.1788 (1.8889)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.5%)	
11/20 03:27:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.1158 (1.2471)	Arch Loss 1.8285 (1.9066)	Arch Hard Loss 1.8102 (1.8898)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.4%)	
11/20 03:28:16午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.4869 (1.2617)	Arch Loss 2.4077 (1.9083)	Arch Hard Loss 2.3885 (1.8915)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.4%)	
11/20 03:29:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.2305 (1.2736)	Arch Loss 1.6793 (1.9134)	Arch Hard Loss 1.6623 (1.8965)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.2%)	
11/20 03:29:06午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 26/49] Final Prec@1 63.0040%
11/20 03:29:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8413	Prec@(1,5) (50.7%, 80.7%)
11/20 03:29:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8538	Prec@(1,5) (50.5%, 80.5%)
11/20 03:29:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8488	Prec@(1,5) (50.5%, 80.6%)
11/20 03:29:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8524	Prec@(1,5) (50.5%, 80.5%)
11/20 03:29:42午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 50.4440%
11/20 03:29:42午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[6, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[8, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 8])
11/20 03:29:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.4440%
11/20 03:30:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.2987 (1.1719)	Arch Loss 1.3622 (1.9050)	Arch Hard Loss 1.3459 (1.8880)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.4%)	
11/20 03:31:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.2865 (1.2049)	Arch Loss 1.9593 (1.9180)	Arch Hard Loss 1.9424 (1.9011)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.9%)	
11/20 03:32:27午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1617 (1.2250)	Arch Loss 1.9141 (1.9019)	Arch Hard Loss 1.8963 (1.8851)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.8%)	
11/20 03:33:16午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.4104 (1.2265)	Arch Loss 1.4950 (1.9106)	Arch Hard Loss 1.4790 (1.8939)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.8%)	
11/20 03:33:16午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 27/49] Final Prec@1 64.1040%
11/20 03:33:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8405	Prec@(1,5) (50.9%, 80.8%)
11/20 03:33:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8469	Prec@(1,5) (51.0%, 80.6%)
11/20 03:33:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8522	Prec@(1,5) (51.0%, 80.5%)
11/20 03:33:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8551	Prec@(1,5) (50.8%, 80.6%)
11/20 03:33:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 50.7920%
11/20 03:33:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 9])
11/20 03:33:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7920%
11/20 03:34:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9286 (1.1337)	Arch Loss 1.6959 (1.8737)	Arch Hard Loss 1.6793 (1.8572)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.2%)	
11/20 03:35:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.2813 (1.1643)	Arch Loss 1.5857 (1.8825)	Arch Hard Loss 1.5704 (1.8660)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.5%)	
11/20 03:36:37午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.8803 (1.1705)	Arch Loss 2.0590 (1.8802)	Arch Hard Loss 2.0430 (1.8637)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.4%)	
11/20 03:37:26午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.3677 (1.1824)	Arch Loss 1.5482 (1.8828)	Arch Hard Loss 1.5308 (1.8663)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.3%)	
11/20 03:37:27午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 28/49] Final Prec@1 65.5360%
11/20 03:37:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8218	Prec@(1,5) (50.7%, 81.1%)
11/20 03:37:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8216	Prec@(1,5) (50.9%, 81.2%)
11/20 03:37:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8292	Prec@(1,5) (51.2%, 80.9%)
11/20 03:38:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8339	Prec@(1,5) (51.0%, 81.0%)
11/20 03:38:03午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 51.0200%
11/20 03:38:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[6, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[4, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
11/20 03:38:03午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0200%
11/20 03:38:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.2422 (1.0809)	Arch Loss 1.3079 (1.8596)	Arch Hard Loss 1.2914 (1.8434)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.5%)	
11/20 03:39:53午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.2867 (1.1122)	Arch Loss 1.9243 (1.8743)	Arch Hard Loss 1.9090 (1.8581)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.2%)	
11/20 03:40:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.5266 (1.1270)	Arch Loss 2.0879 (1.8916)	Arch Hard Loss 2.0730 (1.8755)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.9%)	
11/20 03:41:37午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.2141 (1.1348)	Arch Loss 2.2831 (1.8892)	Arch Hard Loss 2.2676 (1.8731)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.9%)	
11/20 03:41:37午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 29/49] Final Prec@1 66.7280%
11/20 03:41:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8081	Prec@(1,5) (52.8%, 81.7%)
11/20 03:41:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8341	Prec@(1,5) (51.5%, 81.6%)
11/20 03:42:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8257	Prec@(1,5) (51.7%, 81.6%)
11/20 03:42:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8213	Prec@(1,5) (51.7%, 81.7%)
11/20 03:42:13午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 51.7240%
11/20 03:42:13午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/20 03:42:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.7240%
11/20 03:43:09午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.3141 (1.0433)	Arch Loss 2.2321 (1.8493)	Arch Hard Loss 2.2143 (1.8333)	Arch Beta Loss 0.0036 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.4%)	
11/20 03:44:04午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.1879 (1.0664)	Arch Loss 1.5659 (1.8680)	Arch Hard Loss 1.5506 (1.8520)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.9%)	
11/20 03:44:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1989 (1.0830)	Arch Loss 1.6075 (1.8726)	Arch Hard Loss 1.5920 (1.8566)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
11/20 03:45:47午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2868 (1.0962)	Arch Loss 2.2362 (1.8719)	Arch Hard Loss 2.2205 (1.8560)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
11/20 03:45:48午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 30/49] Final Prec@1 67.7000%
11/20 03:45:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8349	Prec@(1,5) (51.8%, 81.0%)
11/20 03:46:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8368	Prec@(1,5) (51.5%, 81.2%)
11/20 03:46:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8347	Prec@(1,5) (51.6%, 81.0%)
11/20 03:46:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8342	Prec@(1,5) (51.6%, 81.1%)
11/20 03:46:24午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 51.5720%
11/20 03:46:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[7, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/20 03:46:24午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.7240%
11/20 03:47:19午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9566 (1.0378)	Arch Loss 1.9042 (1.8654)	Arch Hard Loss 1.8875 (1.8496)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.0%)	
11/20 03:48:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.1839 (1.0250)	Arch Loss 1.5378 (1.8484)	Arch Hard Loss 1.5227 (1.8328)	Arch Beta Loss 0.0030 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
11/20 03:49:08午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0017 (1.0427)	Arch Loss 1.9844 (1.8507)	Arch Hard Loss 1.9680 (1.8350)	Arch Beta Loss 0.0033 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.9%)	
11/20 03:49:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3320 (1.0535)	Arch Loss 1.7892 (1.8658)	Arch Hard Loss 1.7749 (1.8501)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.8%)	
11/20 03:49:58午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 31/49] Final Prec@1 69.0160%
11/20 03:50:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8530	Prec@(1,5) (51.0%, 81.4%)
11/20 03:50:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8470	Prec@(1,5) (51.2%, 80.8%)
11/20 03:50:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8414	Prec@(1,5) (51.5%, 80.8%)
11/20 03:50:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8385	Prec@(1,5) (51.8%, 80.9%)
11/20 03:50:34午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 51.7720%
11/20 03:50:34午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 03:50:35午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.7720%
11/20 03:51:30午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8885 (0.9688)	Arch Loss 1.8531 (1.8559)	Arch Hard Loss 1.8361 (1.8399)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.8%)	
11/20 03:52:25午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.7898 (0.9737)	Arch Loss 2.4383 (1.8494)	Arch Hard Loss 2.4207 (1.8333)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
11/20 03:53:19午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.1696 (0.9870)	Arch Loss 1.7527 (1.8634)	Arch Hard Loss 1.7350 (1.8473)	Arch Beta Loss 0.0036 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.8%)	
11/20 03:54:08午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.9815 (0.9970)	Arch Loss 1.6692 (1.8636)	Arch Hard Loss 1.6526 (1.8475)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.6%)	
11/20 03:54:09午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 32/49] Final Prec@1 70.5000%
11/20 03:54:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8408	Prec@(1,5) (52.2%, 81.7%)
11/20 03:54:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8305	Prec@(1,5) (52.2%, 81.6%)
11/20 03:54:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8302	Prec@(1,5) (52.0%, 81.6%)
11/20 03:54:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8323	Prec@(1,5) (52.1%, 81.6%)
11/20 03:54:45午前 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 52.0440%
11/20 03:54:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[8, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[4, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 8])
11/20 03:54:45午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.0440%
11/20 03:55:41午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.9578 (0.9484)	Arch Loss 1.6072 (1.8990)	Arch Hard Loss 1.5917 (1.8829)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.5%)	
11/20 03:56:35午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.1589 (0.9354)	Arch Loss 2.1411 (1.8780)	Arch Hard Loss 2.1261 (1.8619)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.5%)	
11/20 03:57:30午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.9461 (0.9491)	Arch Loss 1.8930 (1.8793)	Arch Hard Loss 1.8777 (1.8633)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.3%)	
11/20 03:58:19午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9583 (0.9616)	Arch Loss 2.0857 (1.8746)	Arch Hard Loss 2.0712 (1.8585)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.3%, 94.1%)	
11/20 03:58:19午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 33/49] Final Prec@1 71.3320%
11/20 03:58:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8140	Prec@(1,5) (53.0%, 81.4%)
11/20 03:58:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8230	Prec@(1,5) (52.5%, 81.3%)
11/20 03:58:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8111	Prec@(1,5) (52.5%, 81.7%)
11/20 03:58:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8104	Prec@(1,5) (52.6%, 81.9%)
11/20 03:58:56午前 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 52.5960%
11/20 03:58:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
11/20 03:58:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.5960%
11/20 03:59:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.0685 (0.8643)	Arch Loss 2.0288 (1.8384)	Arch Hard Loss 2.0117 (1.8223)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.5%)	
11/20 04:00:46午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.0216 (0.8950)	Arch Loss 1.7052 (1.8565)	Arch Hard Loss 1.6887 (1.8404)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 95.1%)	
11/20 04:01:40午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0566 (0.9005)	Arch Loss 1.4591 (1.8587)	Arch Hard Loss 1.4433 (1.8425)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.9%)	
11/20 04:02:29午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.8961 (0.9069)	Arch Loss 2.1139 (1.8559)	Arch Hard Loss 2.0972 (1.8396)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.8%)	
11/20 04:02:30午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 34/49] Final Prec@1 73.0960%
11/20 04:02:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8233	Prec@(1,5) (52.3%, 81.5%)
11/20 04:02:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7933	Prec@(1,5) (52.8%, 82.1%)
11/20 04:02:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.8017	Prec@(1,5) (52.9%, 82.1%)
11/20 04:03:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.8102	Prec@(1,5) (52.9%, 82.0%)
11/20 04:03:06午前 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 52.9200%
11/20 04:03:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[8, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[9, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 5])
11/20 04:03:07午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.9200%
11/20 04:04:02午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.9458 (0.8334)	Arch Loss 2.1488 (1.8693)	Arch Hard Loss 2.1324 (1.8530)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.5%)	
11/20 04:04:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.7806 (0.8512)	Arch Loss 1.7173 (1.8700)	Arch Hard Loss 1.6991 (1.8536)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.3%)	
11/20 04:05:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.7615 (0.8598)	Arch Loss 2.3636 (1.8667)	Arch Hard Loss 2.3481 (1.8503)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.2%)	
11/20 04:06:40午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1899 (0.8685)	Arch Loss 2.1504 (1.8642)	Arch Hard Loss 2.1343 (1.8479)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/20 04:06:40午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 35/49] Final Prec@1 74.3800%
11/20 04:06:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7769	Prec@(1,5) (53.7%, 82.8%)
11/20 04:06:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7935	Prec@(1,5) (53.4%, 82.4%)
11/20 04:07:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.8022	Prec@(1,5) (53.3%, 82.0%)
11/20 04:07:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8120	Prec@(1,5) (53.4%, 81.9%)
11/20 04:07:17午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 53.3600%
11/20 04:07:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[6, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[7, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/20 04:07:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3600%
11/20 04:08:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.9383 (0.8015)	Arch Loss 1.8887 (1.8884)	Arch Hard Loss 1.8730 (1.8723)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.4%)	
11/20 04:09:07午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8037 (0.8104)	Arch Loss 2.5907 (1.8767)	Arch Hard Loss 2.5749 (1.8604)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.5%)	
11/20 04:10:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8460 (0.8230)	Arch Loss 2.3118 (1.8668)	Arch Hard Loss 2.2943 (1.8504)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.5%)	
11/20 04:10:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.9630 (0.8375)	Arch Loss 1.5794 (1.8691)	Arch Hard Loss 1.5639 (1.8528)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.4%)	
11/20 04:10:51午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 36/49] Final Prec@1 75.0760%
11/20 04:11:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7831	Prec@(1,5) (53.9%, 82.7%)
11/20 04:11:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7937	Prec@(1,5) (53.7%, 82.5%)
11/20 04:11:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7958	Prec@(1,5) (53.7%, 82.4%)
11/20 04:11:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.8036	Prec@(1,5) (53.5%, 82.2%)
11/20 04:11:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 53.4680%
11/20 04:11:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[8, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 11])
11/20 04:11:28午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4680%
11/20 04:12:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.8654 (0.7619)	Arch Loss 1.8552 (1.8360)	Arch Hard Loss 1.8403 (1.8198)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.1%)	
11/20 04:13:18午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.0382 (0.7628)	Arch Loss 2.2626 (1.8540)	Arch Hard Loss 2.2461 (1.8378)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
11/20 04:14:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8775 (0.7723)	Arch Loss 1.9072 (1.8592)	Arch Hard Loss 1.8914 (1.8430)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.0%)	
11/20 04:15:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.7346 (0.7877)	Arch Loss 2.0496 (1.8491)	Arch Hard Loss 2.0307 (1.8330)	Arch Beta Loss 0.0038 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
11/20 04:15:02午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 37/49] Final Prec@1 76.4400%
11/20 04:15:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8003	Prec@(1,5) (53.9%, 82.5%)
11/20 04:15:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8028	Prec@(1,5) (53.8%, 82.4%)
11/20 04:15:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7849	Prec@(1,5) (53.9%, 82.4%)
11/20 04:15:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7972	Prec@(1,5) (53.8%, 82.2%)
11/20 04:15:38午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 53.7680%
11/20 04:15:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[5, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 04:15:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7680%
11/20 04:16:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.8247 (0.7217)	Arch Loss 1.7083 (1.8590)	Arch Hard Loss 1.6934 (1.8431)	Arch Beta Loss 0.0030 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 97.0%)	
11/20 04:17:29午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6753 (0.7309)	Arch Loss 1.8963 (1.8578)	Arch Hard Loss 1.8809 (1.8419)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.6%)	
11/20 04:18:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.6181 (0.7375)	Arch Loss 1.8274 (1.8491)	Arch Hard Loss 1.8127 (1.8332)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.5%)	
11/20 04:19:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.9500 (0.7463)	Arch Loss 1.6140 (1.8466)	Arch Hard Loss 1.5993 (1.8308)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
11/20 04:19:13午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 38/49] Final Prec@1 77.8520%
11/20 04:19:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.8106	Prec@(1,5) (54.1%, 82.4%)
11/20 04:19:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.8233	Prec@(1,5) (53.8%, 82.1%)
11/20 04:19:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.8156	Prec@(1,5) (54.0%, 82.3%)
11/20 04:19:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.8096	Prec@(1,5) (53.9%, 82.4%)
11/20 04:19:49午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 53.9000%
11/20 04:19:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[8, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[7, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 9])
11/20 04:19:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.9000%
11/20 04:20:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.5989 (0.7037)	Arch Loss 1.6512 (1.8812)	Arch Hard Loss 1.6347 (1.8655)	Arch Beta Loss 0.0033 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.6%)	
11/20 04:21:40午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7306 (0.7127)	Arch Loss 1.5792 (1.8479)	Arch Hard Loss 1.5621 (1.8321)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.5%)	
11/20 04:22:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.8583 (0.7137)	Arch Loss 1.7322 (1.8409)	Arch Hard Loss 1.7169 (1.8250)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.5%)	
11/20 04:23:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8322 (0.7144)	Arch Loss 1.8573 (1.8472)	Arch Hard Loss 1.8411 (1.8312)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.6%)	
11/20 04:23:24午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 39/49] Final Prec@1 79.0040%
11/20 04:23:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.8185	Prec@(1,5) (54.0%, 82.3%)
11/20 04:23:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7984	Prec@(1,5) (54.2%, 82.3%)
11/20 04:23:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7947	Prec@(1,5) (54.3%, 82.5%)
11/20 04:24:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7860	Prec@(1,5) (54.3%, 82.7%)
11/20 04:24:00午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 54.3200%
11/20 04:24:00午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 04:24:01午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.3200%
11/20 04:24:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6427 (0.6564)	Arch Loss 1.7645 (1.8676)	Arch Hard Loss 1.7491 (1.8514)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.2%)	
11/20 04:25:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5718 (0.6676)	Arch Loss 1.4668 (1.8710)	Arch Hard Loss 1.4519 (1.8547)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.0%)	
11/20 04:26:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6846 (0.6775)	Arch Loss 1.4226 (1.8451)	Arch Hard Loss 1.4077 (1.8288)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
11/20 04:27:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.5939 (0.6827)	Arch Loss 2.4659 (1.8421)	Arch Hard Loss 2.4504 (1.8259)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
11/20 04:27:34午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 40/49] Final Prec@1 79.9880%
11/20 04:27:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.8142	Prec@(1,5) (53.1%, 82.6%)
11/20 04:27:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7753	Prec@(1,5) (54.0%, 83.1%)
11/20 04:28:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7881	Prec@(1,5) (54.2%, 82.8%)
11/20 04:28:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7775	Prec@(1,5) (54.4%, 82.9%)
11/20 04:28:11午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 54.3760%
11/20 04:28:11午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[5, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 11])
11/20 04:28:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.3760%
11/20 04:29:07午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.4777 (0.6267)	Arch Loss 1.8387 (1.8910)	Arch Hard Loss 1.8212 (1.8752)	Arch Beta Loss 0.0035 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.9%)	
11/20 04:30:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4291 (0.6281)	Arch Loss 1.3017 (1.8615)	Arch Hard Loss 1.2846 (1.8458)	Arch Beta Loss 0.0034 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.6%)	
11/20 04:30:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5588 (0.6403)	Arch Loss 1.9485 (1.8534)	Arch Hard Loss 1.9314 (1.8376)	Arch Beta Loss 0.0034 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/20 04:31:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7124 (0.6472)	Arch Loss 1.7659 (1.8533)	Arch Hard Loss 1.7497 (1.8375)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/20 04:31:45午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 41/49] Final Prec@1 81.3160%
11/20 04:31:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7650	Prec@(1,5) (55.7%, 83.0%)
11/20 04:32:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7820	Prec@(1,5) (54.6%, 83.0%)
11/20 04:32:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7829	Prec@(1,5) (54.4%, 83.0%)
11/20 04:32:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7799	Prec@(1,5) (54.5%, 83.1%)
11/20 04:32:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 54.4520%
11/20 04:32:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 9])
11/20 04:32:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4520%
11/20 04:33:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.4990 (0.5833)	Arch Loss 1.9724 (1.8210)	Arch Hard Loss 1.9582 (1.8053)	Arch Beta Loss 0.0028 (0.0031)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/20 04:34:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.5159 (0.6022)	Arch Loss 2.1372 (1.8549)	Arch Hard Loss 2.1225 (1.8391)	Arch Beta Loss 0.0029 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.6%)	
11/20 04:35:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.5902 (0.6155)	Arch Loss 1.6099 (1.8456)	Arch Hard Loss 1.5933 (1.8296)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.6%)	
11/20 04:35:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5583 (0.6240)	Arch Loss 1.7333 (1.8416)	Arch Hard Loss 1.7163 (1.8255)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/20 04:35:56午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 42/49] Final Prec@1 81.8920%
11/20 04:36:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.8001	Prec@(1,5) (53.9%, 82.5%)
11/20 04:36:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.8027	Prec@(1,5) (54.0%, 82.6%)
11/20 04:36:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7879	Prec@(1,5) (54.2%, 82.7%)
11/20 04:36:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7839	Prec@(1,5) (54.3%, 82.9%)
11/20 04:36:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 54.2800%
11/20 04:36:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/20 04:36:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4520%
11/20 04:37:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.8514 (0.5861)	Arch Loss 1.6737 (1.8122)	Arch Hard Loss 1.6562 (1.7956)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.7%)	
11/20 04:38:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.7223 (0.5943)	Arch Loss 1.8279 (1.8163)	Arch Hard Loss 1.8105 (1.7996)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.7%)	
11/20 04:39:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5759 (0.5919)	Arch Loss 1.6390 (1.8297)	Arch Hard Loss 1.6234 (1.8130)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.8%)	
11/20 04:40:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.6317 (0.5944)	Arch Loss 2.0677 (1.8418)	Arch Hard Loss 2.0501 (1.8251)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.8%)	
11/20 04:40:06午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 43/49] Final Prec@1 83.0080%
11/20 04:40:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7997	Prec@(1,5) (54.2%, 82.8%)
11/20 04:40:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7836	Prec@(1,5) (54.4%, 83.0%)
11/20 04:40:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7799	Prec@(1,5) (54.7%, 83.0%)
11/20 04:40:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7769	Prec@(1,5) (54.9%, 82.9%)
11/20 04:40:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 54.9120%
11/20 04:40:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[7, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 5])
11/20 04:40:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.9120%
11/20 04:41:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5170 (0.5615)	Arch Loss 2.3726 (1.8409)	Arch Hard Loss 2.3540 (1.8242)	Arch Beta Loss 0.0037 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.1%)	
11/20 04:42:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.5382 (0.5711)	Arch Loss 2.3087 (1.8342)	Arch Hard Loss 2.2908 (1.8175)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 97.9%)	
11/20 04:43:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.7663 (0.5747)	Arch Loss 2.4249 (1.8451)	Arch Hard Loss 2.4091 (1.8285)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 97.9%)	
11/20 04:44:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5609 (0.5754)	Arch Loss 1.6104 (1.8502)	Arch Hard Loss 1.5953 (1.8337)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 97.9%)	
11/20 04:44:17午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 44/49] Final Prec@1 83.8320%
11/20 04:44:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.7899	Prec@(1,5) (54.5%, 82.9%)
11/20 04:44:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.8035	Prec@(1,5) (54.4%, 82.8%)
11/20 04:44:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7934	Prec@(1,5) (54.6%, 83.0%)
11/20 04:44:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7889	Prec@(1,5) (54.9%, 83.1%)
11/20 04:44:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 54.8680%
11/20 04:44:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[6, 10], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 7])
11/20 04:44:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.9120%
11/20 04:45:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5332 (0.5417)	Arch Loss 1.8977 (1.8146)	Arch Hard Loss 1.8806 (1.7981)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.1%)	
11/20 04:46:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5166 (0.5519)	Arch Loss 1.8111 (1.8390)	Arch Hard Loss 1.7946 (1.8224)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.1%)	
11/20 04:47:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6097 (0.5494)	Arch Loss 1.7022 (1.8486)	Arch Hard Loss 1.6869 (1.8319)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.1%)	
11/20 04:48:27午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6450 (0.5588)	Arch Loss 1.6200 (1.8462)	Arch Hard Loss 1.6025 (1.8294)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.1%)	
11/20 04:48:27午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 45/49] Final Prec@1 84.3080%
11/20 04:48:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7705	Prec@(1,5) (55.1%, 83.3%)
11/20 04:48:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7525	Prec@(1,5) (55.6%, 83.4%)
11/20 04:48:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7773	Prec@(1,5) (55.1%, 83.0%)
11/20 04:49:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7752	Prec@(1,5) (55.1%, 83.1%)
11/20 04:49:04午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 55.0360%
11/20 04:49:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[6, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[6, 9], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 9])
11/20 04:49:04午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0360%
11/20 04:49:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.4378 (0.5215)	Arch Loss 1.8677 (1.8095)	Arch Hard Loss 1.8512 (1.7926)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.6%)	
11/20 04:50:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.6817 (0.5398)	Arch Loss 1.6651 (1.8301)	Arch Hard Loss 1.6474 (1.8132)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.3%)	
11/20 04:51:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.4253 (0.5446)	Arch Loss 1.9188 (1.8491)	Arch Hard Loss 1.9020 (1.8321)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.2%)	
11/20 04:52:37午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.4858 (0.5483)	Arch Loss 1.8749 (1.8423)	Arch Hard Loss 1.8592 (1.8254)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
11/20 04:52:38午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 46/49] Final Prec@1 84.6080%
11/20 04:52:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.8130	Prec@(1,5) (54.2%, 82.5%)
11/20 04:52:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7890	Prec@(1,5) (54.7%, 82.7%)
11/20 04:53:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7766	Prec@(1,5) (55.1%, 83.0%)
11/20 04:53:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7830	Prec@(1,5) (55.0%, 83.0%)
11/20 04:53:14午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 54.9680%
11/20 04:53:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[9, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 9])
11/20 04:53:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0360%
11/20 04:54:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.4707 (0.5114)	Arch Loss 1.8066 (1.8574)	Arch Hard Loss 1.7898 (1.8409)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
11/20 04:55:04午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.7009 (0.5246)	Arch Loss 1.6954 (1.8354)	Arch Hard Loss 1.6788 (1.8189)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.4%)	
11/20 04:55:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5647 (0.5236)	Arch Loss 1.6635 (1.8375)	Arch Hard Loss 1.6459 (1.8211)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/20 04:56:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.5715 (0.5301)	Arch Loss 1.8687 (1.8372)	Arch Hard Loss 1.8518 (1.8208)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/20 04:56:48午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 47/49] Final Prec@1 85.4200%
11/20 04:56:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7561	Prec@(1,5) (54.8%, 83.6%)
11/20 04:57:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7749	Prec@(1,5) (55.1%, 83.5%)
11/20 04:57:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7836	Prec@(1,5) (55.0%, 83.1%)
11/20 04:57:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7829	Prec@(1,5) (55.1%, 83.1%)
11/20 04:57:25午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 55.1160%
11/20 04:57:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
11/20 04:57:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.1160%
11/20 04:58:20午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.4728 (0.5005)	Arch Loss 1.9253 (1.8138)	Arch Hard Loss 1.9092 (1.7974)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.5%)	
11/20 04:59:15午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.4788 (0.5075)	Arch Loss 1.8539 (1.8267)	Arch Hard Loss 1.8373 (1.8102)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.5%)	
11/20 05:00:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3971 (0.5089)	Arch Loss 1.7086 (1.8345)	Arch Hard Loss 1.6925 (1.8178)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.5%)	
11/20 05:00:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5983 (0.5178)	Arch Loss 1.7850 (1.8434)	Arch Hard Loss 1.7680 (1.8266)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.4%)	
11/20 05:00:59午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 48/49] Final Prec@1 85.8120%
11/20 05:01:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7470	Prec@(1,5) (56.3%, 83.0%)
11/20 05:01:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7605	Prec@(1,5) (56.0%, 83.1%)
11/20 05:01:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7683	Prec@(1,5) (55.8%, 83.1%)
11/20 05:01:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7620	Prec@(1,5) (55.6%, 83.2%)
11/20 05:01:35午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 55.6360%
11/20 05:01:35午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[6, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 6])
11/20 05:01:36午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6360%
11/20 05:02:31午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4133 (0.4833)	Arch Loss 2.4647 (1.8592)	Arch Hard Loss 2.4451 (1.8421)	Arch Beta Loss 0.0039 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.6%)	
11/20 05:03:26午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.6193 (0.5000)	Arch Loss 2.0781 (1.8416)	Arch Hard Loss 2.0608 (1.8246)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.6%)	
11/20 05:04:20午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.4183 (0.5101)	Arch Loss 1.8084 (1.8471)	Arch Hard Loss 1.7923 (1.8303)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.5%)	
11/20 05:05:09午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.4693 (0.5192)	Arch Loss 2.1613 (1.8441)	Arch Hard Loss 2.1444 (1.8272)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.4%)	
11/20 05:05:10午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 49/49] Final Prec@1 85.8640%
11/20 05:05:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7932	Prec@(1,5) (55.1%, 83.7%)
11/20 05:05:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7963	Prec@(1,5) (55.0%, 83.0%)
11/20 05:05:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7786	Prec@(1,5) (55.3%, 83.3%)
11/20 05:05:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7813	Prec@(1,5) (55.0%, 83.1%)
11/20 05:05:46午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 55.0040%
11/20 05:05:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[5, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 05:05:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6360%
11/20 05:05:46午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 55.6360%
11/20 05:05:46午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[6, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 6])
