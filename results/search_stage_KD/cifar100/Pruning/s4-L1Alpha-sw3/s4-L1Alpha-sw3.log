11/10 11:48:49AM parser.py:28 [INFO] 
11/10 11:48:49AM parser.py:29 [INFO] Parameters:
11/10 11:48:49AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s4-L1Alpha-sw3/DAG
11/10 11:48:49AM parser.py:31 [INFO] T=10.0
11/10 11:48:49AM parser.py:31 [INFO] ADVANCED=1
11/10 11:48:49AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/10 11:48:49AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/10 11:48:49AM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/10 11:48:49AM parser.py:31 [INFO] BATCH_SIZE=64
11/10 11:48:49AM parser.py:31 [INFO] CASCADE=0
11/10 11:48:49AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/10 11:48:49AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/10 11:48:49AM parser.py:31 [INFO] DATA_PATH=../data/
11/10 11:48:49AM parser.py:31 [INFO] DATASET=cifar100
11/10 11:48:49AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/10 11:48:49AM parser.py:31 [INFO] DESCRIPTION=search_wtih_alpha-L1-constriction
11/10 11:48:49AM parser.py:31 [INFO] DISCRETE=0
11/10 11:48:49AM parser.py:31 [INFO] EPOCHS=50
11/10 11:48:49AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/10 11:48:49AM parser.py:31 [INFO] EXP_NAME=s4-L1Alpha-sw3
11/10 11:48:49AM parser.py:31 [INFO] FINAL_L=1.0
11/10 11:48:49AM parser.py:31 [INFO] G=1.0
11/10 11:48:49AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/10 11:48:49AM parser.py:31 [INFO] GPUS=[0]
11/10 11:48:49AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/10 11:48:49AM parser.py:31 [INFO] INIT_CHANNELS=16
11/10 11:48:49AM parser.py:31 [INFO] L=0.0
11/10 11:48:49AM parser.py:31 [INFO] LAYERS=20
11/10 11:48:49AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/10 11:48:49AM parser.py:31 [INFO] NAME=Pruning
11/10 11:48:49AM parser.py:31 [INFO] NONKD=1
11/10 11:48:49AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s4-L1Alpha-sw3
11/10 11:48:49AM parser.py:31 [INFO] PCDARTS=0
11/10 11:48:49AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s4-L1Alpha-sw3/plots
11/10 11:48:49AM parser.py:31 [INFO] PRINT_FREQ=100
11/10 11:48:49AM parser.py:31 [INFO] RESET=0
11/10 11:48:49AM parser.py:31 [INFO] RESUME_PATH=None
11/10 11:48:49AM parser.py:31 [INFO] SAVE=s4-L1Alpha-sw3
11/10 11:48:49AM parser.py:31 [INFO] SEED=4
11/10 11:48:49AM parser.py:31 [INFO] SHARE_STAGE=0
11/10 11:48:49AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/10 11:48:49AM parser.py:31 [INFO] SPEC_CELL=1
11/10 11:48:49AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/10 11:48:49AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/10 11:48:49AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/10 11:48:49AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/10 11:48:49AM parser.py:31 [INFO] TYPE=ArchKD
11/10 11:48:49AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/10 11:48:49AM parser.py:31 [INFO] W_LR=0.025
11/10 11:48:49AM parser.py:31 [INFO] W_LR_MIN=0.001
11/10 11:48:49AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/10 11:48:49AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/10 11:48:49AM parser.py:31 [INFO] WORKERS=4
11/10 11:48:49AM parser.py:32 [INFO] 
11/10 11:48:51AM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/10 11:48:52AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/10 11:49:24AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3745 (4.6303)	Arch Loss 4.2861 (4.6253)	Arch Hard Loss 4.2861 (4.6253)	Arch Alpha Loss 0.0579 (0.0405)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.5%, 9.0%)	
11/10 11:49:52AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1345 (4.4524)	Arch Loss 4.1865 (4.4449)	Arch Hard Loss 4.1865 (4.4449)	Arch Alpha Loss 0.0801 (0.0534)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.4%, 13.1%)	
11/10 11:50:21AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0803 (4.3471)	Arch Loss 4.3870 (4.3412)	Arch Hard Loss 4.3870 (4.3412)	Arch Alpha Loss 0.1093 (0.0659)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 15.7%)	
11/10 11:50:47AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9973 (4.2838)	Arch Loss 4.0665 (4.2736)	Arch Hard Loss 4.0665 (4.2736)	Arch Alpha Loss 0.1351 (0.0780)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.3%, 17.1%)	
11/10 11:50:48AM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 4.2920%
11/10 11:50:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0603	Prec@(1,5) (5.9%, 24.5%)
11/10 11:50:57AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.0585	Prec@(1,5) (6.1%, 24.3%)
11/10 11:51:01AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0593	Prec@(1,5) (6.1%, 24.2%)
11/10 11:51:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0621	Prec@(1,5) (6.2%, 24.3%)
11/10 11:51:05AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 6.1520%
11/10 11:51:05AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 11:51:05AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 6.1520%
11/10 11:51:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.0224 (3.9897)	Arch Loss 4.0333 (3.9859)	Arch Hard Loss 4.0332 (3.9858)	Arch Alpha Loss 0.0901 (0.1067)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.4%, 26.1%)	
11/10 11:52:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.9237 (3.9530)	Arch Loss 3.9995 (3.9561)	Arch Hard Loss 3.9994 (3.9560)	Arch Alpha Loss 0.0827 (0.0965)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.8%, 27.0%)	
11/10 11:52:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9005 (3.9284)	Arch Loss 3.7372 (3.9139)	Arch Hard Loss 3.7371 (3.9138)	Arch Alpha Loss 0.1065 (0.0960)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.1%, 27.8%)	
11/10 11:52:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.5764 (3.9009)	Arch Loss 3.6595 (3.8809)	Arch Hard Loss 3.6594 (3.8808)	Arch Alpha Loss 0.1085 (0.0979)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.5%, 28.6%)	
11/10 11:52:59午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 8.5400%
11/10 11:53:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6807	Prec@(1,5) (11.9%, 35.9%)
11/10 11:53:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6953	Prec@(1,5) (11.5%, 35.6%)
11/10 11:53:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6995	Prec@(1,5) (11.6%, 35.5%)
11/10 11:53:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.7100	Prec@(1,5) (11.6%, 35.3%)
11/10 11:53:16午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 11.5880%
11/10 11:53:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/10 11:53:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 11.5880%
11/10 11:53:46午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6180 (3.7199)	Arch Loss 3.4270 (3.7336)	Arch Hard Loss 3.4268 (3.7333)	Arch Alpha Loss 0.0503 (0.0722)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.7%, 34.7%)	
11/10 11:54:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8515 (3.7022)	Arch Loss 3.8251 (3.6973)	Arch Hard Loss 3.8249 (3.6970)	Arch Alpha Loss 0.0419 (0.0598)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.8%, 35.2%)	
11/10 11:54:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.2817 (3.6825)	Arch Loss 3.9248 (3.6803)	Arch Hard Loss 3.9246 (3.6800)	Arch Alpha Loss 0.0411 (0.0526)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.9%, 35.6%)	
11/10 11:55:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4391 (3.6607)	Arch Loss 3.7328 (3.6495)	Arch Hard Loss 3.7326 (3.6493)	Arch Alpha Loss 0.0409 (0.0496)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.4%, 36.4%)	
11/10 11:55:10午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 12.3520%
11/10 11:55:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.5045	Prec@(1,5) (15.1%, 42.3%)
11/10 11:55:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.5174	Prec@(1,5) (15.2%, 41.6%)
11/10 11:55:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.5192	Prec@(1,5) (15.3%, 41.2%)
11/10 11:55:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.5295	Prec@(1,5) (15.3%, 40.9%)
11/10 11:55:26午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 15.2760%
11/10 11:55:26午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
11/10 11:55:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 15.2760%
11/10 11:55:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5205 (3.4935)	Arch Loss 3.4435 (3.5162)	Arch Hard Loss 3.4434 (3.5160)	Arch Alpha Loss 0.0203 (0.0248)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.6%)	
11/10 11:56:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.4603 (3.4837)	Arch Loss 3.2099 (3.5177)	Arch Hard Loss 3.2098 (3.5175)	Arch Alpha Loss 0.0120 (0.0207)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.8%, 41.8%)	
11/10 11:56:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.2534 (3.4693)	Arch Loss 3.4246 (3.4855)	Arch Hard Loss 3.4245 (3.4853)	Arch Alpha Loss 0.0128 (0.0179)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.1%, 42.3%)	
11/10 11:57:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.5371 (3.4589)	Arch Loss 3.2121 (3.4622)	Arch Hard Loss 3.2120 (3.4620)	Arch Alpha Loss 0.0116 (0.0169)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.1%, 42.5%)	
11/10 11:57:20午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 16.0760%
11/10 11:57:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.4259	Prec@(1,5) (16.3%, 44.5%)
11/10 11:57:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.4164	Prec@(1,5) (16.8%, 44.6%)
11/10 11:57:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.4096	Prec@(1,5) (17.1%, 44.8%)
11/10 11:57:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.4028	Prec@(1,5) (17.1%, 45.1%)
11/10 11:57:37午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 17.1120%
11/10 11:57:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=range(6, 8))
11/10 11:57:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.1120%
11/10 11:58:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.0443 (3.3226)	Arch Loss 3.4228 (3.3658)	Arch Hard Loss 3.4227 (3.3656)	Arch Alpha Loss 0.0077 (0.0103)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.1%, 45.3%)	
11/10 11:58:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.1879 (3.3071)	Arch Loss 3.4402 (3.3548)	Arch Hard Loss 3.4401 (3.3546)	Arch Alpha Loss 0.0068 (0.0090)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.5%, 46.7%)	
11/10 11:59:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.0305 (3.2792)	Arch Loss 3.1968 (3.3271)	Arch Hard Loss 3.1967 (3.3270)	Arch Alpha Loss 0.0073 (0.0085)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.4%, 47.6%)	
11/10 11:59:29午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.3279 (3.2743)	Arch Loss 3.3547 (3.3018)	Arch Hard Loss 3.3546 (3.3017)	Arch Alpha Loss 0.0076 (0.0083)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 47.8%)	
11/10 11:59:29午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 19.5160%
11/10 11:59:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.2145	Prec@(1,5) (20.1%, 49.6%)
11/10 11:59:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.2030	Prec@(1,5) (20.8%, 49.7%)
11/10 11:59:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.2072	Prec@(1,5) (20.6%, 49.6%)
11/10 11:59:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.1998	Prec@(1,5) (20.8%, 49.7%)
11/10 11:59:46午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 20.8160%
11/10 11:59:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/10 11:59:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.8160%
11/10 12:00:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.9269 (3.1093)	Arch Loss 3.1474 (3.1914)	Arch Hard Loss 3.1473 (3.1912)	Arch Alpha Loss 0.0061 (0.0076)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 53.0%)	
11/10 12:00:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.2098 (3.1109)	Arch Loss 3.2448 (3.1754)	Arch Hard Loss 3.2446 (3.1752)	Arch Alpha Loss 0.0068 (0.0071)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.8%)	
11/10 12:01:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.9184 (3.1024)	Arch Loss 2.9944 (3.1549)	Arch Hard Loss 2.9943 (3.1547)	Arch Alpha Loss 0.0052 (0.0067)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 52.8%)	
11/10 12:01:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.8165 (3.0946)	Arch Loss 3.0223 (3.1420)	Arch Hard Loss 3.0222 (3.1419)	Arch Alpha Loss 0.0056 (0.0065)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 53.1%)	
11/10 12:01:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 22.9240%
11/10 12:01:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.1100	Prec@(1,5) (23.5%, 53.0%)
11/10 12:01:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.0975	Prec@(1,5) (23.4%, 53.2%)
11/10 12:01:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.0848	Prec@(1,5) (23.8%, 53.4%)
11/10 12:01:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.0792	Prec@(1,5) (23.8%, 53.7%)
11/10 12:01:58午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 23.7640%
11/10 12:01:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/10 12:01:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.7640%
11/10 12:02:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.2192 (2.9810)	Arch Loss 3.0475 (3.0305)	Arch Hard Loss 3.0473 (3.0302)	Arch Alpha Loss 0.0055 (0.0065)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.8%, 55.5%)	
11/10 12:02:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.7779 (2.9444)	Arch Loss 3.3298 (3.0208)	Arch Hard Loss 3.3297 (3.0206)	Arch Alpha Loss 0.0054 (0.0061)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 57.0%)	
11/10 12:03:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.0414 (2.9559)	Arch Loss 3.0406 (3.0050)	Arch Hard Loss 3.0404 (3.0048)	Arch Alpha Loss 0.0055 (0.0059)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.3%, 56.6%)	
11/10 12:03:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8667 (2.9453)	Arch Loss 2.9930 (3.0028)	Arch Hard Loss 2.9929 (3.0026)	Arch Alpha Loss 0.0045 (0.0057)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 56.7%)	
11/10 12:03:51午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 25.5160%
11/10 12:03:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.0097	Prec@(1,5) (25.3%, 55.7%)
11/10 12:04:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.9770	Prec@(1,5) (25.1%, 56.0%)
11/10 12:04:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.9742	Prec@(1,5) (25.2%, 56.0%)
11/10 12:04:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.9730	Prec@(1,5) (25.4%, 56.1%)
11/10 12:04:08午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 25.4000%
11/10 12:04:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/10 12:04:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.4000%
11/10 12:04:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.8584 (2.8498)	Arch Loss 3.0506 (2.9581)	Arch Hard Loss 3.0503 (2.9578)	Arch Alpha Loss 0.0060 (0.0059)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.6%, 58.9%)	
11/10 12:05:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.7110 (2.8377)	Arch Loss 3.0629 (2.9425)	Arch Hard Loss 3.0627 (2.9422)	Arch Alpha Loss 0.0055 (0.0057)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.7%, 59.0%)	
11/10 12:05:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7235 (2.8211)	Arch Loss 2.9583 (2.9091)	Arch Hard Loss 2.9581 (2.9088)	Arch Alpha Loss 0.0047 (0.0055)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.1%, 59.5%)	
11/10 12:06:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.0966 (2.8126)	Arch Loss 2.6703 (2.8986)	Arch Hard Loss 2.6701 (2.8983)	Arch Alpha Loss 0.0050 (0.0054)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.3%, 59.6%)	
11/10 12:06:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 28.2400%
11/10 12:06:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.8464	Prec@(1,5) (27.1%, 59.2%)
11/10 12:06:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.8356	Prec@(1,5) (27.5%, 59.6%)
11/10 12:06:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.8332	Prec@(1,5) (27.7%, 59.6%)
11/10 12:06:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.8329	Prec@(1,5) (27.9%, 59.7%)
11/10 12:06:19午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 27.9080%
11/10 12:06:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/10 12:06:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.9080%
11/10 12:06:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.9372 (2.7253)	Arch Loss 3.1043 (2.8706)	Arch Hard Loss 3.1040 (2.8703)	Arch Alpha Loss 0.0057 (0.0055)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.4%, 62.4%)	
11/10 12:07:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.9774 (2.7207)	Arch Loss 3.2419 (2.8382)	Arch Hard Loss 3.2416 (2.8379)	Arch Alpha Loss 0.0055 (0.0053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.5%, 62.4%)	
11/10 12:07:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.7758 (2.7023)	Arch Loss 2.7560 (2.8187)	Arch Hard Loss 2.7557 (2.8184)	Arch Alpha Loss 0.0054 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 62.6%)	
11/10 12:08:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.2671 (2.6872)	Arch Loss 2.6391 (2.8038)	Arch Hard Loss 2.6388 (2.8034)	Arch Alpha Loss 0.0052 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.9%, 62.9%)	
11/10 12:08:13午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 30.8640%
11/10 12:08:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.7336	Prec@(1,5) (31.0%, 62.0%)
11/10 12:08:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.7371	Prec@(1,5) (30.8%, 62.1%)
11/10 12:08:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.7431	Prec@(1,5) (30.8%, 62.3%)
11/10 12:08:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.7519	Prec@(1,5) (30.6%, 62.0%)
11/10 12:08:30午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 30.5600%
11/10 12:08:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/10 12:08:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.5600%
11/10 12:09:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.5559 (2.5907)	Arch Loss 3.1048 (2.7314)	Arch Hard Loss 3.1044 (2.7310)	Arch Alpha Loss 0.0056 (0.0052)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.3%, 65.6%)	
11/10 12:09:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.6470 (2.5806)	Arch Loss 2.8267 (2.7324)	Arch Hard Loss 2.8263 (2.7320)	Arch Alpha Loss 0.0050 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.7%)	
11/10 12:09:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.7302 (2.5817)	Arch Loss 2.3123 (2.7194)	Arch Hard Loss 2.3120 (2.7191)	Arch Alpha Loss 0.0048 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.7%)	
11/10 12:10:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.6591 (2.5814)	Arch Loss 2.8273 (2.7081)	Arch Hard Loss 2.8269 (2.7077)	Arch Alpha Loss 0.0047 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 65.8%)	
11/10 12:10:25午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 32.9880%
11/10 12:10:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.6427	Prec@(1,5) (31.3%, 63.8%)
11/10 12:10:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.6503	Prec@(1,5) (31.7%, 64.0%)
11/10 12:10:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.6477	Prec@(1,5) (32.1%, 64.4%)
11/10 12:10:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.6492	Prec@(1,5) (32.1%, 64.3%)
11/10 12:10:42午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 32.0760%
11/10 12:10:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:10:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.0760%
11/10 12:11:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.4858 (2.4446)	Arch Loss 2.8518 (2.6402)	Arch Hard Loss 2.8513 (2.6397)	Arch Alpha Loss 0.0053 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.8%, 68.2%)	
11/10 12:11:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.6519 (2.4712)	Arch Loss 2.5312 (2.6545)	Arch Hard Loss 2.5308 (2.6540)	Arch Alpha Loss 0.0043 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.4%, 67.2%)	
11/10 12:12:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.8404 (2.4726)	Arch Loss 2.6566 (2.6422)	Arch Hard Loss 2.6561 (2.6418)	Arch Alpha Loss 0.0051 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 67.5%)	
11/10 12:12:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.4279 (2.4779)	Arch Loss 2.3022 (2.6284)	Arch Hard Loss 2.3018 (2.6280)	Arch Alpha Loss 0.0043 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 67.4%)	
11/10 12:12:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 34.9320%
11/10 12:12:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.5751	Prec@(1,5) (33.3%, 65.2%)
11/10 12:12:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.5970	Prec@(1,5) (33.0%, 64.8%)
11/10 12:12:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.5979	Prec@(1,5) (33.3%, 65.0%)
11/10 12:12:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.5900	Prec@(1,5) (33.4%, 65.1%)
11/10 12:12:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 33.4040%
11/10 12:12:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:12:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.4040%
11/10 12:13:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.3590 (2.3706)	Arch Loss 2.6448 (2.5523)	Arch Hard Loss 2.6443 (2.5517)	Arch Alpha Loss 0.0047 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.7%, 70.9%)	
11/10 12:13:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.3148 (2.3822)	Arch Loss 2.7121 (2.5553)	Arch Hard Loss 2.7117 (2.5547)	Arch Alpha Loss 0.0041 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.5%, 70.5%)	
11/10 12:14:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.3117 (2.3832)	Arch Loss 2.3866 (2.5459)	Arch Hard Loss 2.3862 (2.5454)	Arch Alpha Loss 0.0038 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 70.1%)	
11/10 12:14:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.8800 (2.3851)	Arch Loss 2.3214 (2.5488)	Arch Hard Loss 2.3209 (2.5482)	Arch Alpha Loss 0.0047 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.9%)	
11/10 12:14:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 36.9560%
11/10 12:14:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.4905	Prec@(1,5) (35.6%, 67.6%)
11/10 12:14:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.4912	Prec@(1,5) (35.3%, 67.2%)
11/10 12:15:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.5077	Prec@(1,5) (35.1%, 66.9%)
11/10 12:15:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.5136	Prec@(1,5) (34.8%, 66.9%)
11/10 12:15:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 34.7920%
11/10 12:15:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:15:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.7920%
11/10 12:15:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.9262 (2.2824)	Arch Loss 2.4966 (2.5088)	Arch Hard Loss 2.4960 (2.5082)	Arch Alpha Loss 0.0047 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 72.3%)	
11/10 12:16:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.9199 (2.2999)	Arch Loss 2.4344 (2.5186)	Arch Hard Loss 2.4337 (2.5180)	Arch Alpha Loss 0.0050 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 72.0%)	
11/10 12:16:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.4414 (2.3027)	Arch Loss 2.5123 (2.5036)	Arch Hard Loss 2.5117 (2.5030)	Arch Alpha Loss 0.0042 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 71.8%)	
11/10 12:16:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.3056 (2.3024)	Arch Loss 2.0934 (2.4914)	Arch Hard Loss 2.0929 (2.4908)	Arch Alpha Loss 0.0037 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.8%)	
11/10 12:16:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 38.5280%
11/10 12:17:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.5233	Prec@(1,5) (34.3%, 67.1%)
11/10 12:17:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.4982	Prec@(1,5) (35.1%, 67.9%)
11/10 12:17:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.4877	Prec@(1,5) (35.1%, 68.2%)
11/10 12:17:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.4790	Prec@(1,5) (35.6%, 68.4%)
11/10 12:17:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 35.5760%
11/10 12:17:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:17:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.5760%
11/10 12:17:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.3722 (2.1864)	Arch Loss 2.3016 (2.4292)	Arch Hard Loss 2.3010 (2.4285)	Arch Alpha Loss 0.0043 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.0%, 73.7%)	
11/10 12:18:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.3232 (2.2067)	Arch Loss 2.2905 (2.4147)	Arch Hard Loss 2.2897 (2.4140)	Arch Alpha Loss 0.0051 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.6%, 73.7%)	
11/10 12:18:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.0803 (2.2120)	Arch Loss 2.0453 (2.4193)	Arch Hard Loss 2.0447 (2.4186)	Arch Alpha Loss 0.0037 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.5%)	
11/10 12:19:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.4406 (2.2100)	Arch Loss 2.3546 (2.4210)	Arch Hard Loss 2.3540 (2.4203)	Arch Alpha Loss 0.0040 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.6%)	
11/10 12:19:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 40.7520%
11/10 12:19:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.3715	Prec@(1,5) (38.5%, 70.1%)
11/10 12:19:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.3801	Prec@(1,5) (38.2%, 70.2%)
11/10 12:19:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.3714	Prec@(1,5) (38.2%, 70.3%)
11/10 12:19:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.3766	Prec@(1,5) (38.2%, 70.3%)
11/10 12:19:27午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 38.2040%
11/10 12:19:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:19:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2040%
11/10 12:19:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.0949 (2.1116)	Arch Loss 2.2738 (2.3946)	Arch Hard Loss 2.2729 (2.3937)	Arch Alpha Loss 0.0047 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.5%)	
11/10 12:20:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.2909 (2.1317)	Arch Loss 2.5899 (2.3880)	Arch Hard Loss 2.5892 (2.3872)	Arch Alpha Loss 0.0039 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 75.1%)	
11/10 12:20:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.1087 (2.1284)	Arch Loss 2.3699 (2.3826)	Arch Hard Loss 2.3691 (2.3818)	Arch Alpha Loss 0.0043 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.5%, 75.0%)	
11/10 12:21:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.0195 (2.1403)	Arch Loss 2.1534 (2.3762)	Arch Hard Loss 2.1526 (2.3754)	Arch Alpha Loss 0.0044 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 74.6%)	
11/10 12:21:20午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 42.1000%
11/10 12:21:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.3260	Prec@(1,5) (38.9%, 71.2%)
11/10 12:21:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.3172	Prec@(1,5) (39.4%, 71.4%)
11/10 12:21:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.3137	Prec@(1,5) (39.4%, 71.4%)
11/10 12:21:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.3130	Prec@(1,5) (39.4%, 71.4%)
11/10 12:21:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 39.3480%
11/10 12:21:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:21:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.3480%
11/10 12:22:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.2995 (2.0276)	Arch Loss 2.2941 (2.3501)	Arch Hard Loss 2.2932 (2.3491)	Arch Alpha Loss 0.0047 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.0%)	
11/10 12:22:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.9649 (2.0307)	Arch Loss 2.1492 (2.3285)	Arch Hard Loss 2.1483 (2.3276)	Arch Alpha Loss 0.0045 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.0%)	
11/10 12:23:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0473 (2.0504)	Arch Loss 2.3415 (2.3131)	Arch Hard Loss 2.3406 (2.3122)	Arch Alpha Loss 0.0044 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.8%)	
11/10 12:23:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.8560 (2.0557)	Arch Loss 2.4947 (2.3020)	Arch Hard Loss 2.4937 (2.3011)	Arch Alpha Loss 0.0051 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.7%)	
11/10 12:23:31午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 43.9080%
11/10 12:23:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.4522	Prec@(1,5) (38.1%, 69.8%)
11/10 12:23:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.4626	Prec@(1,5) (38.0%, 69.3%)
11/10 12:23:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.4601	Prec@(1,5) (38.0%, 69.4%)
11/10 12:23:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.4710	Prec@(1,5) (37.8%, 69.4%)
11/10 12:23:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 37.7760%
11/10 12:23:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:23:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.3480%
11/10 12:24:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.9482 (1.9768)	Arch Loss 2.1393 (2.3068)	Arch Hard Loss 2.1384 (2.3058)	Arch Alpha Loss 0.0042 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.5%, 78.6%)	
11/10 12:24:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.1009 (1.9947)	Arch Loss 2.4717 (2.2906)	Arch Hard Loss 2.4706 (2.2896)	Arch Alpha Loss 0.0046 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.2%)	
11/10 12:25:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.2543 (1.9902)	Arch Loss 2.4046 (2.2798)	Arch Hard Loss 2.4036 (2.2788)	Arch Alpha Loss 0.0045 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 78.2%)	
11/10 12:25:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.9557 (1.9843)	Arch Loss 2.5051 (2.2678)	Arch Hard Loss 2.5040 (2.2668)	Arch Alpha Loss 0.0049 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.2%)	
11/10 12:25:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 45.3680%
11/10 12:25:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.2210	Prec@(1,5) (42.5%, 73.6%)
11/10 12:25:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.2487	Prec@(1,5) (41.8%, 73.3%)
11/10 12:25:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.2791	Prec@(1,5) (41.3%, 72.8%)
11/10 12:25:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.2839	Prec@(1,5) (40.9%, 72.8%)
11/10 12:25:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 40.9400%
11/10 12:25:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:25:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.9400%
11/10 12:26:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.9915 (1.8913)	Arch Loss 2.0606 (2.2441)	Arch Hard Loss 2.0596 (2.2429)	Arch Alpha Loss 0.0041 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 80.1%)	
11/10 12:26:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.7298 (1.8935)	Arch Loss 2.2702 (2.2387)	Arch Hard Loss 2.2691 (2.2375)	Arch Alpha Loss 0.0041 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.7%)	
11/10 12:27:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.7146 (1.9139)	Arch Loss 2.5566 (2.2404)	Arch Hard Loss 2.5555 (2.2393)	Arch Alpha Loss 0.0042 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.7%, 79.2%)	
11/10 12:27:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.9811 (1.9203)	Arch Loss 2.2080 (2.2369)	Arch Hard Loss 2.2070 (2.2358)	Arch Alpha Loss 0.0040 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.4%, 79.0%)	
11/10 12:27:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 47.3960%
11/10 12:27:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.1994	Prec@(1,5) (42.5%, 74.0%)
11/10 12:28:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.1911	Prec@(1,5) (42.1%, 74.1%)
11/10 12:28:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.2056	Prec@(1,5) (41.8%, 73.7%)
11/10 12:28:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.2007	Prec@(1,5) (41.9%, 73.7%)
11/10 12:28:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 41.9320%
11/10 12:28:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:28:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.9320%
11/10 12:28:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.7170 (1.7947)	Arch Loss 2.1953 (2.1682)	Arch Hard Loss 2.1941 (2.1670)	Arch Alpha Loss 0.0043 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 82.0%)	
11/10 12:29:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.9794 (1.8237)	Arch Loss 1.9987 (2.1985)	Arch Hard Loss 1.9974 (2.1973)	Arch Alpha Loss 0.0043 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.0%, 81.2%)	
11/10 12:29:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6648 (1.8439)	Arch Loss 2.1397 (2.1925)	Arch Hard Loss 2.1384 (2.1913)	Arch Alpha Loss 0.0046 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.9%)	
11/10 12:30:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.8104 (1.8603)	Arch Loss 1.7530 (2.1905)	Arch Hard Loss 1.7518 (2.1894)	Arch Alpha Loss 0.0042 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.4%)	
11/10 12:30:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 48.8840%
11/10 12:30:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1915	Prec@(1,5) (42.3%, 73.5%)
11/10 12:30:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1928	Prec@(1,5) (42.6%, 74.1%)
11/10 12:30:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1968	Prec@(1,5) (42.6%, 74.1%)
11/10 12:30:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1969	Prec@(1,5) (42.6%, 74.1%)
11/10 12:30:19午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 42.5600%
11/10 12:30:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:30:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5600%
11/10 12:30:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.4468 (1.7516)	Arch Loss 2.3030 (2.1823)	Arch Hard Loss 2.3020 (2.1810)	Arch Alpha Loss 0.0032 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.4%, 81.8%)	
11/10 12:31:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6510 (1.7578)	Arch Loss 1.8461 (2.1793)	Arch Hard Loss 1.8449 (2.1780)	Arch Alpha Loss 0.0040 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.1%)	
11/10 12:31:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.6182 (1.7854)	Arch Loss 1.5909 (2.1735)	Arch Hard Loss 1.5897 (2.1722)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.5%)	
11/10 12:32:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.9531 (1.7977)	Arch Loss 2.0635 (2.1607)	Arch Hard Loss 2.0624 (2.1595)	Arch Alpha Loss 0.0034 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.0%, 81.4%)	
11/10 12:32:14午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 50.0040%
11/10 12:32:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.2052	Prec@(1,5) (42.4%, 74.3%)
11/10 12:32:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.2421	Prec@(1,5) (42.1%, 73.3%)
11/10 12:32:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.2409	Prec@(1,5) (42.2%, 73.5%)
11/10 12:32:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.2333	Prec@(1,5) (42.2%, 73.5%)
11/10 12:32:31午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 42.2120%
11/10 12:32:31午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:32:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5600%
11/10 12:33:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.5114 (1.7022)	Arch Loss 1.6648 (2.1170)	Arch Hard Loss 1.6635 (2.1156)	Arch Alpha Loss 0.0037 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.0%, 83.1%)	
11/10 12:33:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.9928 (1.7179)	Arch Loss 2.4231 (2.1376)	Arch Hard Loss 2.4217 (2.1362)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.9%)	
11/10 12:33:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.0478 (1.7217)	Arch Loss 1.7550 (2.1402)	Arch Hard Loss 1.7535 (2.1388)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.8%)	
11/10 12:34:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6125 (1.7349)	Arch Loss 2.1421 (2.1364)	Arch Hard Loss 2.1406 (2.1350)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.6%)	
11/10 12:34:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 51.3360%
11/10 12:34:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.1619	Prec@(1,5) (43.4%, 74.5%)
11/10 12:34:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.1543	Prec@(1,5) (43.7%, 74.5%)
11/10 12:34:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.1482	Prec@(1,5) (43.6%, 74.8%)
11/10 12:34:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.1577	Prec@(1,5) (43.4%, 74.6%)
11/10 12:34:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 43.4320%
11/10 12:34:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:34:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.4320%
11/10 12:35:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5095 (1.6289)	Arch Loss 2.2417 (2.0893)	Arch Hard Loss 2.2403 (2.0877)	Arch Alpha Loss 0.0038 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.8%, 84.6%)	
11/10 12:35:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4929 (1.6530)	Arch Loss 2.2973 (2.1233)	Arch Hard Loss 2.2958 (2.1217)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 84.3%)	
11/10 12:36:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.7804 (1.6690)	Arch Loss 2.3694 (2.1197)	Arch Hard Loss 2.3679 (2.1182)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.8%, 84.0%)	
11/10 12:36:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.7114 (1.6770)	Arch Loss 2.1202 (2.1042)	Arch Hard Loss 2.1189 (2.1027)	Arch Alpha Loss 0.0037 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.9%)	
11/10 12:36:33午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 52.7600%
11/10 12:36:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.0439	Prec@(1,5) (46.4%, 77.5%)
11/10 12:36:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.0304	Prec@(1,5) (46.5%, 77.6%)
11/10 12:36:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.0366	Prec@(1,5) (46.4%, 77.2%)
11/10 12:36:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.0427	Prec@(1,5) (46.1%, 77.1%)
11/10 12:36:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 46.1160%
11/10 12:36:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:36:50午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.1160%
11/10 12:37:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.2286 (1.5430)	Arch Loss 1.8268 (2.1031)	Arch Hard Loss 1.8250 (2.1015)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 86.7%)	
11/10 12:37:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.6168 (1.5542)	Arch Loss 1.8785 (2.1058)	Arch Hard Loss 1.8769 (2.1042)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.7%)	
11/10 12:38:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.8501 (1.5931)	Arch Loss 2.4010 (2.0997)	Arch Hard Loss 2.3995 (2.0981)	Arch Alpha Loss 0.0037 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.0%)	
11/10 12:38:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.5353 (1.6117)	Arch Loss 2.4788 (2.0721)	Arch Hard Loss 2.4773 (2.0705)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.6%)	
11/10 12:38:43午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 54.3880%
11/10 12:38:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9908	Prec@(1,5) (48.7%, 77.8%)
11/10 12:38:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.0160	Prec@(1,5) (47.3%, 77.5%)
11/10 12:38:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.0259	Prec@(1,5) (47.1%, 77.4%)
11/10 12:39:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.0180	Prec@(1,5) (47.2%, 77.6%)
11/10 12:39:00午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 47.1600%
11/10 12:39:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:39:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1600%
11/10 12:39:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4987 (1.5021)	Arch Loss 2.1085 (2.0681)	Arch Hard Loss 2.1069 (2.0663)	Arch Alpha Loss 0.0036 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.3%)	
11/10 12:39:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3544 (1.5302)	Arch Loss 1.8466 (2.0650)	Arch Hard Loss 1.8448 (2.0632)	Arch Alpha Loss 0.0041 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.9%)	
11/10 12:40:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.5017 (1.5488)	Arch Loss 2.0805 (2.0636)	Arch Hard Loss 2.0789 (2.0618)	Arch Alpha Loss 0.0036 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.8%)	
11/10 12:40:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.7036 (1.5725)	Arch Loss 1.9895 (2.0589)	Arch Hard Loss 1.9878 (2.0571)	Arch Alpha Loss 0.0040 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 85.3%)	
11/10 12:40:54午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 55.3240%
11/10 12:40:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.0134	Prec@(1,5) (46.5%, 77.6%)
11/10 12:41:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.0091	Prec@(1,5) (46.9%, 77.8%)
11/10 12:41:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.0173	Prec@(1,5) (46.6%, 77.7%)
11/10 12:41:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.0106	Prec@(1,5) (46.8%, 77.8%)
11/10 12:41:11午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 46.7480%
11/10 12:41:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:41:11午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1600%
11/10 12:41:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0802 (1.4826)	Arch Loss 2.0123 (2.0210)	Arch Hard Loss 2.0102 (2.0191)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.7%)	
11/10 12:42:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.8670 (1.4868)	Arch Loss 1.7286 (2.0187)	Arch Hard Loss 1.7267 (2.0169)	Arch Alpha Loss 0.0040 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.7%)	
11/10 12:42:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3436 (1.5021)	Arch Loss 1.9565 (2.0253)	Arch Hard Loss 1.9544 (2.0234)	Arch Alpha Loss 0.0044 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.5%)	
11/10 12:43:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.4094 (1.5036)	Arch Loss 2.1558 (2.0215)	Arch Hard Loss 2.1540 (2.0196)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.5%)	
11/10 12:43:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 57.0520%
11/10 12:43:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.0145	Prec@(1,5) (47.1%, 77.5%)
11/10 12:43:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.0159	Prec@(1,5) (46.9%, 77.8%)
11/10 12:43:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.0283	Prec@(1,5) (46.6%, 77.4%)
11/10 12:43:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.0194	Prec@(1,5) (46.8%, 77.6%)
11/10 12:43:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 46.8160%
11/10 12:43:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:43:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1600%
11/10 12:43:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.1369 (1.3967)	Arch Loss 1.9600 (2.0055)	Arch Hard Loss 1.9583 (2.0035)	Arch Alpha Loss 0.0035 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.3%)	
11/10 12:44:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.4893 (1.4189)	Arch Loss 1.9261 (2.0174)	Arch Hard Loss 1.9243 (2.0154)	Arch Alpha Loss 0.0036 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.8%)	
11/10 12:44:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.3114 (1.4371)	Arch Loss 2.0493 (2.0208)	Arch Hard Loss 2.0475 (2.0188)	Arch Alpha Loss 0.0036 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.5%)	
11/10 12:45:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.3628 (1.4551)	Arch Loss 1.8956 (2.0193)	Arch Hard Loss 1.8937 (2.0174)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.0%, 87.2%)	
11/10 12:45:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 57.9640%
11/10 12:45:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9521	Prec@(1,5) (47.7%, 78.8%)
11/10 12:45:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9876	Prec@(1,5) (47.1%, 78.5%)
11/10 12:45:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9949	Prec@(1,5) (47.3%, 78.2%)
11/10 12:45:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9876	Prec@(1,5) (47.5%, 78.3%)
11/10 12:45:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 47.4520%
11/10 12:45:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:45:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.4520%
11/10 12:46:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5803 (1.3141)	Arch Loss 2.2526 (2.0289)	Arch Hard Loss 2.2504 (2.0268)	Arch Alpha Loss 0.0040 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.4%)	
11/10 12:46:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.6536 (1.3748)	Arch Loss 1.9401 (2.0311)	Arch Hard Loss 1.9376 (2.0290)	Arch Alpha Loss 0.0047 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.4%)	
11/10 12:46:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.5774 (1.3881)	Arch Loss 2.0867 (2.0036)	Arch Hard Loss 2.0842 (2.0015)	Arch Alpha Loss 0.0046 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.2%)	
11/10 12:47:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.3948 (1.4015)	Arch Loss 2.3487 (2.0078)	Arch Hard Loss 2.3463 (2.0057)	Arch Alpha Loss 0.0044 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 88.0%)	
11/10 12:47:26午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 59.4560%
11/10 12:47:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.9541	Prec@(1,5) (48.0%, 79.0%)
11/10 12:47:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.9426	Prec@(1,5) (48.7%, 78.9%)
11/10 12:47:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.9573	Prec@(1,5) (48.4%, 78.9%)
11/10 12:47:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9683	Prec@(1,5) (48.3%, 78.6%)
11/10 12:47:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 48.2680%
11/10 12:47:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:47:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.2680%
11/10 12:48:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.3913 (1.2886)	Arch Loss 1.4820 (1.9800)	Arch Hard Loss 1.4797 (1.9777)	Arch Alpha Loss 0.0041 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.4%, 90.0%)	
11/10 12:48:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.0505 (1.3082)	Arch Loss 1.7509 (1.9980)	Arch Hard Loss 1.7491 (1.9957)	Arch Alpha Loss 0.0033 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.6%)	
11/10 12:49:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1817 (1.3217)	Arch Loss 1.3291 (1.9987)	Arch Hard Loss 1.3269 (1.9964)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.3%)	
11/10 12:49:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.3943 (1.3434)	Arch Loss 1.6912 (1.9902)	Arch Hard Loss 1.6891 (1.9880)	Arch Alpha Loss 0.0037 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 89.0%)	
11/10 12:49:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 61.0320%
11/10 12:49:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9867	Prec@(1,5) (48.6%, 79.2%)
11/10 12:49:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.0041	Prec@(1,5) (47.7%, 78.5%)
11/10 12:49:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.0060	Prec@(1,5) (48.1%, 78.4%)
11/10 12:49:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.9966	Prec@(1,5) (48.3%, 78.5%)
11/10 12:49:56午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 48.2600%
11/10 12:49:56午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:49:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.2680%
11/10 12:50:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.2868 (1.2491)	Arch Loss 1.6521 (1.9862)	Arch Hard Loss 1.6497 (1.9838)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 90.6%)	
11/10 12:50:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1223 (1.2623)	Arch Loss 2.4738 (1.9950)	Arch Hard Loss 2.4713 (1.9927)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 90.4%)	
11/10 12:51:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.9864 (1.2853)	Arch Loss 1.8328 (1.9798)	Arch Hard Loss 1.8302 (1.9775)	Arch Alpha Loss 0.0043 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 90.1%)	
11/10 12:51:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.4522 (1.2976)	Arch Loss 2.3814 (1.9910)	Arch Hard Loss 2.3787 (1.9887)	Arch Alpha Loss 0.0044 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.7%)	
11/10 12:51:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 61.8800%
11/10 12:51:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9353	Prec@(1,5) (49.8%, 79.2%)
11/10 12:51:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.9422	Prec@(1,5) (49.5%, 79.4%)
11/10 12:52:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.9417	Prec@(1,5) (49.7%, 79.7%)
11/10 12:52:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.9386	Prec@(1,5) (49.7%, 79.7%)
11/10 12:52:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 49.6760%
11/10 12:52:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:52:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6760%
11/10 12:52:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.2823 (1.1913)	Arch Loss 2.1618 (1.9828)	Arch Hard Loss 2.1596 (1.9803)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.8%)	
11/10 12:53:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.2770 (1.2136)	Arch Loss 1.7238 (1.9775)	Arch Hard Loss 1.7216 (1.9750)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.7%)	
11/10 12:53:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1284 (1.2350)	Arch Loss 1.8834 (1.9670)	Arch Hard Loss 1.8815 (1.9646)	Arch Alpha Loss 0.0031 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.4%)	
11/10 12:54:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.6218 (1.2464)	Arch Loss 1.6314 (1.9700)	Arch Hard Loss 1.6291 (1.9676)	Arch Alpha Loss 0.0037 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.1%)	
11/10 12:54:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 63.7000%
11/10 12:54:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.9245	Prec@(1,5) (49.8%, 79.9%)
11/10 12:54:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.9352	Prec@(1,5) (49.5%, 79.7%)
11/10 12:54:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.9383	Prec@(1,5) (49.6%, 79.6%)
11/10 12:54:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.9512	Prec@(1,5) (49.3%, 79.5%)
11/10 12:54:19午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 49.2560%
11/10 12:54:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:54:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6760%
11/10 12:54:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.1613 (1.1527)	Arch Loss 2.0467 (1.9500)	Arch Hard Loss 2.0434 (1.9474)	Arch Alpha Loss 0.0050 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.5%)	
11/10 12:55:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.2031 (1.1550)	Arch Loss 1.9054 (1.9510)	Arch Hard Loss 1.9026 (1.9484)	Arch Alpha Loss 0.0042 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.4%)	
11/10 12:55:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.4003 (1.1786)	Arch Loss 2.4004 (1.9489)	Arch Hard Loss 2.3976 (1.9463)	Arch Alpha Loss 0.0043 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.1%)	
11/10 12:56:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2402 (1.1919)	Arch Loss 2.1514 (1.9555)	Arch Hard Loss 2.1487 (1.9529)	Arch Alpha Loss 0.0042 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.9%)	
11/10 12:56:13午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 64.9720%
11/10 12:56:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9341	Prec@(1,5) (49.7%, 80.2%)
11/10 12:56:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9209	Prec@(1,5) (49.8%, 80.2%)
11/10 12:56:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9209	Prec@(1,5) (49.9%, 80.2%)
11/10 12:56:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9348	Prec@(1,5) (49.6%, 80.1%)
11/10 12:56:30午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 49.6120%
11/10 12:56:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:56:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6760%
11/10 12:57:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.3578 (1.0854)	Arch Loss 2.3582 (1.9315)	Arch Hard Loss 2.3560 (1.9289)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.4%)	
11/10 12:57:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.1846 (1.0955)	Arch Loss 2.0032 (1.9544)	Arch Hard Loss 2.0007 (1.9518)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.4%)	
11/10 12:57:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 0.9470 (1.1157)	Arch Loss 2.0236 (1.9479)	Arch Hard Loss 2.0211 (1.9454)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.2%)	
11/10 12:58:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.9892 (1.1320)	Arch Loss 1.6947 (1.9611)	Arch Hard Loss 1.6927 (1.9585)	Arch Alpha Loss 0.0030 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.8%)	
11/10 12:58:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 66.2600%
11/10 12:58:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.9262	Prec@(1,5) (50.3%, 80.0%)
11/10 12:58:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9297	Prec@(1,5) (50.1%, 80.4%)
11/10 12:58:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9430	Prec@(1,5) (50.2%, 80.2%)
11/10 12:58:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9407	Prec@(1,5) (50.2%, 80.2%)
11/10 12:58:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 50.1920%
11/10 12:58:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 12:58:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1920%
11/10 12:59:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.9986 (1.0385)	Arch Loss 1.8806 (1.9728)	Arch Hard Loss 1.8776 (1.9701)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.9%)	
11/10 12:59:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9868 (1.0571)	Arch Loss 1.8158 (1.9743)	Arch Hard Loss 1.8129 (1.9716)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.5%)	
11/10 01:00:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.1553 (1.0737)	Arch Loss 2.0789 (1.9722)	Arch Hard Loss 2.0758 (1.9695)	Arch Alpha Loss 0.0044 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.4%)	
11/10 01:00:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.1495 (1.0889)	Arch Loss 1.8671 (1.9595)	Arch Hard Loss 1.8642 (1.9567)	Arch Alpha Loss 0.0040 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
11/10 01:00:37午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 67.7120%
11/10 01:00:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8827	Prec@(1,5) (50.9%, 81.0%)
11/10 01:00:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8739	Prec@(1,5) (51.2%, 80.9%)
11/10 01:00:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8755	Prec@(1,5) (51.3%, 80.7%)
11/10 01:00:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8744	Prec@(1,5) (51.5%, 80.9%)
11/10 01:00:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 51.4600%
11/10 01:00:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:00:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4600%
11/10 01:01:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.9028 (0.9731)	Arch Loss 1.7233 (1.9469)	Arch Hard Loss 1.7203 (1.9439)	Arch Alpha Loss 0.0040 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.7%)	
11/10 01:01:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.1164 (0.9922)	Arch Loss 2.0360 (1.9667)	Arch Hard Loss 2.0334 (1.9638)	Arch Alpha Loss 0.0035 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
11/10 01:02:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2457 (1.0155)	Arch Loss 2.4359 (1.9616)	Arch Hard Loss 2.4330 (1.9587)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.4%)	
11/10 01:02:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9676 (1.0351)	Arch Loss 2.3969 (1.9562)	Arch Hard Loss 2.3941 (1.9533)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.2%)	
11/10 01:02:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 69.3920%
11/10 01:02:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.9020	Prec@(1,5) (51.5%, 80.8%)
11/10 01:02:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.9341	Prec@(1,5) (50.7%, 80.1%)
11/10 01:03:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.9274	Prec@(1,5) (50.6%, 80.2%)
11/10 01:03:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.9282	Prec@(1,5) (50.8%, 80.2%)
11/10 01:03:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 50.7640%
11/10 01:03:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:03:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4600%
11/10 01:03:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8039 (0.9491)	Arch Loss 2.0564 (1.9364)	Arch Hard Loss 2.0535 (1.9334)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.2%)	
11/10 01:04:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.8620 (0.9678)	Arch Loss 1.9173 (1.9357)	Arch Hard Loss 1.9144 (1.9327)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 94.0%)	
11/10 01:04:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.8546 (0.9765)	Arch Loss 1.6887 (1.9493)	Arch Hard Loss 1.6857 (1.9463)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.8%)	
11/10 01:04:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9949 (0.9918)	Arch Loss 1.8696 (1.9428)	Arch Hard Loss 1.8670 (1.9399)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.6%)	
11/10 01:04:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 70.2000%
11/10 01:05:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8741	Prec@(1,5) (51.6%, 82.0%)
11/10 01:05:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9060	Prec@(1,5) (51.3%, 81.3%)
11/10 01:05:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9030	Prec@(1,5) (51.6%, 81.2%)
11/10 01:05:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9033	Prec@(1,5) (51.6%, 81.1%)
11/10 01:05:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 51.6360%
11/10 01:05:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:05:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.6360%
11/10 01:05:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.9924 (0.8666)	Arch Loss 2.1862 (1.9230)	Arch Hard Loss 2.1829 (1.9201)	Arch Alpha Loss 0.0041 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.0%)	
11/10 01:06:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9963 (0.8930)	Arch Loss 2.2514 (1.9497)	Arch Hard Loss 2.2483 (1.9468)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.5%)	
11/10 01:06:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.1600 (0.9088)	Arch Loss 1.7859 (1.9469)	Arch Hard Loss 1.7825 (1.9439)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.4%)	
11/10 01:07:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.7940 (0.9252)	Arch Loss 2.1039 (1.9549)	Arch Hard Loss 2.1005 (1.9520)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.3%)	
11/10 01:07:10午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 72.2600%
11/10 01:07:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.8920	Prec@(1,5) (52.0%, 81.4%)
11/10 01:07:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9117	Prec@(1,5) (51.7%, 81.1%)
11/10 01:07:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9113	Prec@(1,5) (51.8%, 81.3%)
11/10 01:07:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9201	Prec@(1,5) (51.6%, 81.2%)
11/10 01:07:27午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 51.6400%
11/10 01:07:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:07:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.6400%
11/10 01:07:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6220 (0.8646)	Arch Loss 2.2865 (1.9624)	Arch Hard Loss 2.2840 (1.9593)	Arch Alpha Loss 0.0031 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.8%)	
11/10 01:08:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8290 (0.8638)	Arch Loss 1.6449 (1.9530)	Arch Hard Loss 1.6425 (1.9499)	Arch Alpha Loss 0.0029 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.0%)	
11/10 01:08:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7406 (0.8746)	Arch Loss 1.9365 (1.9650)	Arch Hard Loss 1.9334 (1.9620)	Arch Alpha Loss 0.0038 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.9%)	
11/10 01:09:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8020 (0.8844)	Arch Loss 1.8960 (1.9614)	Arch Hard Loss 1.8933 (1.9583)	Arch Alpha Loss 0.0034 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.9%)	
11/10 01:09:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 73.3680%
11/10 01:09:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.8709	Prec@(1,5) (52.7%, 82.0%)
11/10 01:09:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.8741	Prec@(1,5) (52.2%, 81.9%)
11/10 01:09:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.8829	Prec@(1,5) (52.3%, 81.6%)
11/10 01:09:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.8903	Prec@(1,5) (52.3%, 81.4%)
11/10 01:09:38午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 52.2400%
11/10 01:09:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:09:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.2400%
11/10 01:10:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.9272 (0.7997)	Arch Loss 1.7542 (1.9248)	Arch Hard Loss 1.7512 (1.9216)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.9%)	
11/10 01:10:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.7712 (0.8067)	Arch Loss 1.4946 (1.9347)	Arch Hard Loss 1.4915 (1.9316)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.8%)	
11/10 01:11:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.1061 (0.8237)	Arch Loss 1.6938 (1.9634)	Arch Hard Loss 1.6902 (1.9603)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.5%)	
11/10 01:11:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.0457 (0.8341)	Arch Loss 2.1464 (1.9574)	Arch Hard Loss 2.1432 (1.9543)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.4%)	
11/10 01:11:32午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 74.8480%
11/10 01:11:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8808	Prec@(1,5) (53.1%, 82.1%)
11/10 01:11:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8911	Prec@(1,5) (52.8%, 81.9%)
11/10 01:11:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9089	Prec@(1,5) (52.6%, 81.7%)
11/10 01:11:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9006	Prec@(1,5) (52.6%, 81.7%)
11/10 01:11:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 52.6040%
11/10 01:11:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:11:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6040%
11/10 01:12:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.8155 (0.7447)	Arch Loss 1.6231 (1.9851)	Arch Hard Loss 1.6203 (1.9818)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.2%)	
11/10 01:12:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8251 (0.7546)	Arch Loss 2.3148 (1.9673)	Arch Hard Loss 2.3117 (1.9640)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
11/10 01:13:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8637 (0.7667)	Arch Loss 2.0800 (1.9663)	Arch Hard Loss 2.0771 (1.9631)	Arch Alpha Loss 0.0034 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
11/10 01:13:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.7769 (0.7853)	Arch Loss 2.1769 (1.9754)	Arch Hard Loss 2.1735 (1.9721)	Arch Alpha Loss 0.0038 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.8%)	
11/10 01:13:43午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 76.4120%
11/10 01:13:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.8993	Prec@(1,5) (52.1%, 81.2%)
11/10 01:13:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.8926	Prec@(1,5) (52.8%, 81.5%)
11/10 01:13:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9032	Prec@(1,5) (52.5%, 81.4%)
11/10 01:14:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9039	Prec@(1,5) (52.6%, 81.5%)
11/10 01:14:00午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 52.6160%
11/10 01:14:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:14:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6160%
11/10 01:14:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.7679 (0.7395)	Arch Loss 1.5080 (1.9060)	Arch Hard Loss 1.5046 (1.9026)	Arch Alpha Loss 0.0038 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.4%)	
11/10 01:14:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.5798 (0.7348)	Arch Loss 1.9688 (1.9452)	Arch Hard Loss 1.9653 (1.9418)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.4%)	
11/10 01:15:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.8505 (0.7362)	Arch Loss 1.7101 (1.9453)	Arch Hard Loss 1.7064 (1.9419)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.4%)	
11/10 01:15:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8882 (0.7460)	Arch Loss 2.0782 (1.9652)	Arch Hard Loss 2.0749 (1.9619)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.4%)	
11/10 01:15:54午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 77.4760%
11/10 01:15:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9395	Prec@(1,5) (52.9%, 81.4%)
11/10 01:16:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.9098	Prec@(1,5) (53.3%, 81.8%)
11/10 01:16:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.8946	Prec@(1,5) (53.4%, 81.9%)
11/10 01:16:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.9002	Prec@(1,5) (53.3%, 81.9%)
11/10 01:16:11午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 53.2840%
11/10 01:16:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:16:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2840%
11/10 01:16:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.8027 (0.6633)	Arch Loss 2.0099 (1.9528)	Arch Hard Loss 2.0061 (1.9493)	Arch Alpha Loss 0.0042 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.0%)	
11/10 01:17:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5187 (0.6846)	Arch Loss 1.8145 (1.9653)	Arch Hard Loss 1.8108 (1.9618)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.7%)	
11/10 01:17:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4896 (0.6995)	Arch Loss 1.9013 (1.9787)	Arch Hard Loss 1.8977 (1.9752)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/10 01:18:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.7477 (0.7086)	Arch Loss 2.5488 (1.9536)	Arch Hard Loss 2.5455 (1.9501)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
11/10 01:18:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 78.5880%
11/10 01:18:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9080	Prec@(1,5) (53.5%, 82.0%)
11/10 01:18:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9175	Prec@(1,5) (53.5%, 81.8%)
11/10 01:18:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.9159	Prec@(1,5) (53.4%, 81.8%)
11/10 01:18:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9161	Prec@(1,5) (53.2%, 81.8%)
11/10 01:18:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 53.1560%
11/10 01:18:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:18:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2840%
11/10 01:18:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7194 (0.6359)	Arch Loss 1.8855 (1.9699)	Arch Hard Loss 1.8817 (1.9663)	Arch Alpha Loss 0.0040 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.1%)	
11/10 01:19:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6803 (0.6502)	Arch Loss 2.3124 (1.9832)	Arch Hard Loss 2.3088 (1.9797)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
11/10 01:19:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6647 (0.6579)	Arch Loss 1.6848 (1.9748)	Arch Hard Loss 1.6819 (1.9713)	Arch Alpha Loss 0.0032 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
11/10 01:20:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7463 (0.6689)	Arch Loss 2.0273 (1.9670)	Arch Hard Loss 2.0240 (1.9636)	Arch Alpha Loss 0.0035 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
11/10 01:20:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 79.5800%
11/10 01:20:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.9209	Prec@(1,5) (53.0%, 82.1%)
11/10 01:20:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.9170	Prec@(1,5) (53.2%, 81.8%)
11/10 01:20:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.9193	Prec@(1,5) (53.2%, 81.8%)
11/10 01:20:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9209	Prec@(1,5) (53.2%, 81.8%)
11/10 01:20:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 53.2160%
11/10 01:20:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:20:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2840%
11/10 01:21:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.5818 (0.6245)	Arch Loss 2.1072 (2.0452)	Arch Hard Loss 2.1033 (2.0418)	Arch Alpha Loss 0.0042 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.7%)	
11/10 01:21:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6351 (0.6216)	Arch Loss 1.6593 (2.0111)	Arch Hard Loss 1.6561 (2.0077)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.7%)	
11/10 01:22:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.7125 (0.6254)	Arch Loss 2.2182 (2.0048)	Arch Hard Loss 2.2142 (2.0013)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.6%)	
11/10 01:22:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5581 (0.6308)	Arch Loss 1.5553 (1.9839)	Arch Hard Loss 1.5511 (1.9804)	Arch Alpha Loss 0.0045 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.5%)	
11/10 01:22:26午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 80.7440%
11/10 01:22:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.9037	Prec@(1,5) (53.6%, 81.6%)
11/10 01:22:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.9095	Prec@(1,5) (53.6%, 81.8%)
11/10 01:22:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9133	Prec@(1,5) (53.5%, 81.8%)
11/10 01:22:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.9127	Prec@(1,5) (53.6%, 81.8%)
11/10 01:22:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 53.5480%
11/10 01:22:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:22:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5480%
11/10 01:23:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.5837 (0.5804)	Arch Loss 1.9306 (1.9622)	Arch Hard Loss 1.9272 (1.9586)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 98.0%)	
11/10 01:23:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.5017 (0.5887)	Arch Loss 2.0278 (1.9576)	Arch Hard Loss 2.0244 (1.9539)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.8%)	
11/10 01:24:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.3925 (0.5972)	Arch Loss 1.4031 (1.9688)	Arch Hard Loss 1.4000 (1.9652)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.7%)	
11/10 01:24:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.4214 (0.6005)	Arch Loss 2.1100 (1.9813)	Arch Hard Loss 2.1073 (1.9776)	Arch Alpha Loss 0.0028 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.6%)	
11/10 01:24:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 81.8400%
11/10 01:24:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.9332	Prec@(1,5) (53.2%, 81.6%)
11/10 01:24:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.9082	Prec@(1,5) (53.7%, 82.1%)
11/10 01:24:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9296	Prec@(1,5) (53.3%, 81.9%)
11/10 01:24:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9194	Prec@(1,5) (53.6%, 82.0%)
11/10 01:24:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 53.5600%
11/10 01:24:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:24:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5600%
11/10 01:25:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5373 (0.5675)	Arch Loss 2.2126 (1.9731)	Arch Hard Loss 2.2085 (1.9694)	Arch Alpha Loss 0.0042 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/10 01:25:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.4538 (0.5703)	Arch Loss 2.0234 (1.9801)	Arch Hard Loss 2.0190 (1.9764)	Arch Alpha Loss 0.0046 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/10 01:26:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.8640 (0.5692)	Arch Loss 2.3015 (1.9815)	Arch Hard Loss 2.2972 (1.9779)	Arch Alpha Loss 0.0045 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
11/10 01:26:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.4587 (0.5745)	Arch Loss 1.8601 (1.9803)	Arch Hard Loss 1.8562 (1.9767)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
11/10 01:26:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 82.8440%
11/10 01:26:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.8947	Prec@(1,5) (54.1%, 82.2%)
11/10 01:26:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.9063	Prec@(1,5) (54.1%, 82.1%)
11/10 01:26:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.8988	Prec@(1,5) (54.2%, 82.1%)
11/10 01:27:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.9072	Prec@(1,5) (54.1%, 82.2%)
11/10 01:27:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 54.1480%
11/10 01:27:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:27:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1480%
11/10 01:27:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4549 (0.5283)	Arch Loss 2.2066 (1.9852)	Arch Hard Loss 2.2034 (1.9815)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/10 01:28:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.6904 (0.5472)	Arch Loss 1.8105 (1.9894)	Arch Hard Loss 1.8069 (1.9857)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
11/10 01:28:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7842 (0.5484)	Arch Loss 1.6801 (1.9809)	Arch Hard Loss 1.6772 (1.9772)	Arch Alpha Loss 0.0029 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
11/10 01:28:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4681 (0.5571)	Arch Loss 2.5494 (1.9788)	Arch Hard Loss 2.5460 (1.9752)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
11/10 01:28:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 83.5680%
11/10 01:29:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.8787	Prec@(1,5) (54.3%, 82.5%)
11/10 01:29:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.9062	Prec@(1,5) (54.4%, 82.0%)
11/10 01:29:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.9225	Prec@(1,5) (54.1%, 82.0%)
11/10 01:29:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9185	Prec@(1,5) (53.8%, 81.9%)
11/10 01:29:13午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 53.8280%
11/10 01:29:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:29:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1480%
11/10 01:29:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.5376 (0.5140)	Arch Loss 1.7092 (1.9563)	Arch Hard Loss 1.7051 (1.9527)	Arch Alpha Loss 0.0042 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.6%)	
11/10 01:30:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.4335 (0.5347)	Arch Loss 2.1528 (1.9625)	Arch Hard Loss 2.1489 (1.9589)	Arch Alpha Loss 0.0040 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.2%)	
11/10 01:30:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5311 (0.5393)	Arch Loss 1.9505 (1.9735)	Arch Hard Loss 1.9461 (1.9698)	Arch Alpha Loss 0.0045 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.1%)	
11/10 01:31:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6218 (0.5459)	Arch Loss 2.0406 (1.9865)	Arch Hard Loss 2.0371 (1.9829)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.0%)	
11/10 01:31:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 84.0560%
11/10 01:31:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.9627	Prec@(1,5) (53.4%, 81.9%)
11/10 01:31:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.9355	Prec@(1,5) (53.7%, 82.1%)
11/10 01:31:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.9340	Prec@(1,5) (53.8%, 82.0%)
11/10 01:31:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.9291	Prec@(1,5) (53.8%, 82.0%)
11/10 01:31:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 53.8240%
11/10 01:31:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/10 01:31:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1480%
11/10 01:31:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.5377 (0.5242)	Arch Loss 2.1178 (1.9382)	Arch Hard Loss 2.1142 (1.9345)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.1%)	
11/10 01:32:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6325 (0.5215)	Arch Loss 2.3276 (1.9943)	Arch Hard Loss 2.3240 (1.9906)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.1%)	
11/10 01:32:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.4198 (0.5275)	Arch Loss 2.0578 (2.0007)	Arch Hard Loss 2.0545 (1.9970)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
11/10 01:33:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.5677 (0.5276)	Arch Loss 1.7216 (1.9935)	Arch Hard Loss 1.7183 (1.9898)	Arch Alpha Loss 0.0033 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
11/10 01:33:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 84.5040%
11/10 01:33:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.8962	Prec@(1,5) (53.7%, 82.6%)
11/10 01:33:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.9017	Prec@(1,5) (53.7%, 82.3%)
11/10 01:33:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.9090	Prec@(1,5) (53.9%, 82.2%)
11/10 01:33:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.9064	Prec@(1,5) (54.1%, 82.2%)
11/10 01:33:34午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 54.1080%
11/10 01:33:34午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG3_concat=range(6, 8))
11/10 01:33:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1480%
11/10 01:34:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.3961 (0.5031)	Arch Loss 2.0141 (1.9616)	Arch Hard Loss 2.0101 (1.9578)	Arch Alpha Loss 0.0040 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.5%)	
11/10 01:34:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.3882 (0.5030)	Arch Loss 1.7841 (1.9994)	Arch Hard Loss 1.7802 (1.9956)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/10 01:35:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5656 (0.5065)	Arch Loss 1.9254 (1.9684)	Arch Hard Loss 1.9217 (1.9647)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/10 01:35:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5764 (0.5130)	Arch Loss 2.0354 (1.9770)	Arch Hard Loss 2.0315 (1.9733)	Arch Alpha Loss 0.0040 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.3%)	
11/10 01:35:28午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 85.2320%
11/10 01:35:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.8824	Prec@(1,5) (54.2%, 82.4%)
11/10 01:35:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.8825	Prec@(1,5) (54.6%, 82.4%)
11/10 01:35:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.9034	Prec@(1,5) (54.2%, 82.1%)
11/10 01:35:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.9064	Prec@(1,5) (54.1%, 82.0%)
11/10 01:35:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 54.0560%
11/10 01:35:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG3_concat=range(6, 8))
11/10 01:35:45午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1480%
11/10 01:36:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.5562 (0.4954)	Arch Loss 2.0844 (1.9774)	Arch Hard Loss 2.0807 (1.9737)	Arch Alpha Loss 0.0038 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/10 01:36:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4693 (0.5013)	Arch Loss 1.5593 (1.9539)	Arch Hard Loss 1.5558 (1.9502)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/10 01:37:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5261 (0.5109)	Arch Loss 1.5244 (1.9724)	Arch Hard Loss 1.5208 (1.9686)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.4%)	
11/10 01:37:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.4780 (0.5118)	Arch Loss 2.2577 (1.9810)	Arch Hard Loss 2.2541 (1.9772)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/10 01:37:38午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 84.9400%
11/10 01:37:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.9561	Prec@(1,5) (53.6%, 81.5%)
11/10 01:37:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.9051	Prec@(1,5) (54.5%, 82.2%)
11/10 01:37:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.9161	Prec@(1,5) (54.2%, 82.1%)
11/10 01:37:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.9205	Prec@(1,5) (54.0%, 82.1%)
11/10 01:37:54午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 53.9840%
11/10 01:37:54午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG3_concat=range(6, 8))
11/10 01:37:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1480%
11/10 01:37:54午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 54.1480%
11/10 01:37:54午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
