11/23 03:18:38AM parser.py:28 [INFO] 
11/23 03:18:38AM parser.py:29 [INFO] Parameters:
11/23 03:18:38AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected-sw3-g-0.1/DAG
11/23 03:18:38AM parser.py:31 [INFO] T=10.0
11/23 03:18:38AM parser.py:31 [INFO] ADVANCED=1
11/23 03:18:38AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/23 03:18:38AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/23 03:18:38AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/23 03:18:38AM parser.py:31 [INFO] BATCH_SIZE=64
11/23 03:18:38AM parser.py:31 [INFO] CASCADE=0
11/23 03:18:38AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/23 03:18:38AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[]
11/23 03:18:38AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/23 03:18:38AM parser.py:31 [INFO] DATA_PATH=../data/
11/23 03:18:38AM parser.py:31 [INFO] DATASET=cifar100
11/23 03:18:38AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/23 03:18:38AM parser.py:31 [INFO] DESCRIPTION=search_with_-Beta-expected-Depth-constraint_slidewindow-3
11/23 03:18:38AM parser.py:31 [INFO] DISCRETE=0
11/23 03:18:38AM parser.py:31 [INFO] EPOCHS=50
11/23 03:18:38AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/23 03:18:38AM parser.py:31 [INFO] EXP_NAME=s0-expected-sw3-g-0.1
11/23 03:18:38AM parser.py:31 [INFO] FINAL_L=0.0
11/23 03:18:38AM parser.py:31 [INFO] G=-0.1
11/23 03:18:38AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/23 03:18:38AM parser.py:31 [INFO] GPUS=[0]
11/23 03:18:38AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/23 03:18:38AM parser.py:31 [INFO] INIT_CHANNELS=16
11/23 03:18:38AM parser.py:31 [INFO] L=0.0
11/23 03:18:38AM parser.py:31 [INFO] LAYERS=32
11/23 03:18:38AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/23 03:18:38AM parser.py:31 [INFO] NAME=Pruning
11/23 03:18:38AM parser.py:31 [INFO] NONKD=1
11/23 03:18:38AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-expected-sw3-g-0.1
11/23 03:18:38AM parser.py:31 [INFO] PCDARTS=0
11/23 03:18:38AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected-sw3-g-0.1/plots
11/23 03:18:38AM parser.py:31 [INFO] PRINT_FREQ=100
11/23 03:18:38AM parser.py:31 [INFO] RESET=0
11/23 03:18:38AM parser.py:31 [INFO] RESUME_PATH=None
11/23 03:18:38AM parser.py:31 [INFO] SAVE=s0-expected-sw3-g-0.1
11/23 03:18:38AM parser.py:31 [INFO] SEED=0
11/23 03:18:38AM parser.py:31 [INFO] SHARE_STAGE=0
11/23 03:18:38AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/23 03:18:38AM parser.py:31 [INFO] SPEC_CELL=1
11/23 03:18:38AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/23 03:18:38AM parser.py:31 [INFO] TEACHER_NAME=none
11/23 03:18:38AM parser.py:31 [INFO] TEACHER_PATH=none
11/23 03:18:38AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/23 03:18:38AM parser.py:31 [INFO] TYPE=Pruning
11/23 03:18:38AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/23 03:18:38AM parser.py:31 [INFO] W_LR=0.025
11/23 03:18:38AM parser.py:31 [INFO] W_LR_MIN=0.001
11/23 03:18:38AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/23 03:18:38AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/23 03:18:38AM parser.py:31 [INFO] WORKERS=4
11/23 03:18:38AM parser.py:32 [INFO] 
11/23 03:18:39AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/23 03:19:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3797 (4.4910)	Arch Loss -32.5230 (-31.9513)	Arch Hard Loss 4.3534 (4.4951)	Arch Beta Loss 368.7638 (364.4633)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.7%, 10.8%)	
11/23 03:20:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0512 (4.3570)	Arch Loss -33.5748 (-32.5266)	Arch Hard Loss 4.1830 (4.3567)	Arch Beta Loss 377.5780 (368.8328)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 14.9%)	
11/23 03:21:21AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0216 (4.2436)	Arch Loss -34.6576 (-33.0805)	Arch Hard Loss 3.9949 (4.2445)	Arch Beta Loss 386.5248 (373.2501)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.9%, 18.6%)	
11/23 03:22:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.7797 (4.1799)	Arch Loss -35.6384 (-33.5517)	Arch Hard Loss 3.8312 (4.1748)	Arch Beta Loss 394.6961 (377.2646)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 20.7%)	
11/23 03:22:11AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  0/49] Final Prec@1 5.5360%
11/23 03:22:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9883	Prec@(1,5) (8.5%, 27.2%)
11/23 03:22:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9753	Prec@(1,5) (8.6%, 28.2%)
11/23 03:22:35AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9768	Prec@(1,5) (8.6%, 28.1%)
11/23 03:22:42AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9734	Prec@(1,5) (8.7%, 28.2%)
11/23 03:22:42AM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 8.6480%
11/23 03:22:42AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[5, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[4, 11])
11/23 03:22:42AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.6480%
11/23 03:23:37午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9158 (3.8689)	Arch Loss -36.4052 (-36.0793)	Arch Hard Loss 3.9934 (3.8630)	Arch Beta Loss 403.9860 (399.4237)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.5%, 30.1%)	
11/23 03:24:31午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.8868 (3.8315)	Arch Loss -37.4476 (-36.5902)	Arch Hard Loss 3.8813 (3.8149)	Arch Beta Loss 413.2885 (404.0509)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.1%, 31.5%)	
11/23 03:25:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.6506 (3.7940)	Arch Loss -38.7851 (-37.0966)	Arch Hard Loss 3.4820 (3.7742)	Arch Beta Loss 422.6717 (408.7076)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.0%, 32.6%)	
11/23 03:26:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7534 (3.7539)	Arch Loss -39.1166 (-37.5506)	Arch Hard Loss 4.0013 (3.7415)	Arch Beta Loss 431.1785 (412.9215)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.4%, 33.9%)	
11/23 03:26:14午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  1/49] Final Prec@1 11.4000%
11/23 03:26:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6344	Prec@(1,5) (12.9%, 37.9%)
11/23 03:26:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6241	Prec@(1,5) (13.2%, 38.0%)
11/23 03:26:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6283	Prec@(1,5) (13.1%, 37.8%)
11/23 03:26:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6263	Prec@(1,5) (13.1%, 37.9%)
11/23 03:26:45午前 searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 13.0560%
11/23 03:26:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
11/23 03:26:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.0560%
11/23 03:27:40午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6211 (3.5816)	Arch Loss -40.4809 (-40.0276)	Arch Hard Loss 3.5963 (3.5791)	Arch Beta Loss 440.7722 (436.0674)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.7%, 38.2%)	
11/23 03:28:34午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4947 (3.5548)	Arch Loss -41.6108 (-40.5272)	Arch Hard Loss 3.4208 (3.5556)	Arch Beta Loss 450.3163 (440.8278)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.2%, 39.3%)	
11/23 03:29:28午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.1691 (3.5244)	Arch Loss -42.6245 (-41.0389)	Arch Hard Loss 3.3651 (3.5214)	Arch Beta Loss 459.8965 (445.6022)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.7%, 40.5%)	
11/23 03:30:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.3950 (3.4992)	Arch Loss -43.5474 (-41.4961)	Arch Hard Loss 3.3087 (3.4950)	Arch Beta Loss 468.5609 (449.9105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.3%)	
11/23 03:30:17午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  2/49] Final Prec@1 15.1720%
11/23 03:30:25午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4370	Prec@(1,5) (16.4%, 43.8%)
11/23 03:30:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4409	Prec@(1,5) (16.1%, 43.6%)
11/23 03:30:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4437	Prec@(1,5) (16.0%, 43.3%)
11/23 03:30:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4418	Prec@(1,5) (16.1%, 43.5%)
11/23 03:30:48午前 searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 16.0800%
11/23 03:30:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
11/23 03:30:49午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.0800%
11/23 03:31:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5732 (3.3527)	Arch Loss -44.4857 (-44.0051)	Arch Hard Loss 3.3499 (3.3498)	Arch Beta Loss 478.3561 (473.5491)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.2%, 45.1%)	
11/23 03:32:38午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1453 (3.3226)	Arch Loss -45.3524 (-44.5124)	Arch Hard Loss 3.4609 (3.3294)	Arch Beta Loss 488.1331 (478.4179)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.8%, 46.4%)	
11/23 03:33:32午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.0205 (3.2891)	Arch Loss -46.4480 (-45.0306)	Arch Hard Loss 3.3520 (3.3008)	Arch Beta Loss 498.0004 (483.3147)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.3%, 47.3%)	
11/23 03:34:20午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9887 (3.2631)	Arch Loss -47.5847 (-45.4941)	Arch Hard Loss 3.1119 (3.2807)	Arch Beta Loss 506.9658 (487.7478)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.8%, 48.1%)	
11/23 03:34:21午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  3/49] Final Prec@1 19.7760%
11/23 03:34:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1709	Prec@(1,5) (21.7%, 50.4%)
11/23 03:34:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1739	Prec@(1,5) (21.2%, 50.5%)
11/23 03:34:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1852	Prec@(1,5) (21.0%, 50.1%)
11/23 03:34:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1859	Prec@(1,5) (21.0%, 50.3%)
11/23 03:34:51午前 searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 21.0440%
11/23 03:34:51午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/23 03:34:52午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.0440%
11/23 03:35:46午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.0968 (3.0925)	Arch Loss -48.6347 (-48.0185)	Arch Hard Loss 3.0788 (3.1960)	Arch Beta Loss 517.1351 (512.1447)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 53.1%)	
11/23 03:36:40午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.0856 (3.0848)	Arch Loss -49.8397 (-48.5659)	Arch Hard Loss 2.8901 (3.1544)	Arch Beta Loss 527.2984 (517.2032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 53.2%)	
11/23 03:37:34午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.6834 (3.0791)	Arch Loss -50.5797 (-49.0905)	Arch Hard Loss 3.1737 (3.1384)	Arch Beta Loss 537.5338 (522.2888)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 53.4%)	
11/23 03:38:22午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8679 (3.0724)	Arch Loss -51.8240 (-49.5709)	Arch Hard Loss 2.8559 (3.1178)	Arch Beta Loss 546.7989 (526.8869)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.1%, 53.6%)	
11/23 03:38:23午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  4/49] Final Prec@1 23.1080%
11/23 03:38:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1056	Prec@(1,5) (22.4%, 53.7%)
11/23 03:38:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0765	Prec@(1,5) (23.0%, 54.4%)
11/23 03:38:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0682	Prec@(1,5) (23.0%, 54.9%)
11/23 03:38:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0691	Prec@(1,5) (23.1%, 54.8%)
11/23 03:38:54午前 searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 23.1480%
11/23 03:38:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/23 03:38:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.1480%
11/23 03:39:49午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.3104 (2.9472)	Arch Loss -52.7341 (-52.2198)	Arch Hard Loss 2.9902 (2.9925)	Arch Beta Loss 557.2430 (552.1229)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.1%, 56.1%)	
11/23 03:40:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.3263 (2.9330)	Arch Loss -53.5359 (-52.7352)	Arch Hard Loss 3.2236 (2.9944)	Arch Beta Loss 567.5941 (557.2963)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.7%)	
11/23 03:41:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8776 (2.9267)	Arch Loss -55.0557 (-53.2668)	Arch Hard Loss 2.7389 (2.9804)	Arch Beta Loss 577.9460 (562.4721)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.9%)	
11/23 03:42:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6166 (2.9141)	Arch Loss -55.8730 (-53.7486)	Arch Hard Loss 2.8512 (2.9642)	Arch Beta Loss 587.2423 (567.1282)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.0%, 57.5%)	
11/23 03:42:25午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  5/49] Final Prec@1 26.0200%
11/23 03:42:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8467	Prec@(1,5) (27.3%, 60.0%)
11/23 03:42:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8512	Prec@(1,5) (27.6%, 59.4%)
11/23 03:42:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8567	Prec@(1,5) (27.6%, 59.2%)
11/23 03:42:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8526	Prec@(1,5) (27.6%, 59.3%)
11/23 03:42:56午前 searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 27.5680%
11/23 03:42:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/23 03:42:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.5680%
11/23 03:43:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8075 (2.7658)	Arch Loss -56.9116 (-56.3861)	Arch Hard Loss 2.8504 (2.8678)	Arch Beta Loss 597.6194 (592.5392)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.1%, 60.6%)	
11/23 03:44:44午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.9107 (2.7762)	Arch Loss -57.8865 (-56.9004)	Arch Hard Loss 2.8959 (2.8655)	Arch Beta Loss 607.8237 (597.6594)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 60.5%)	
11/23 03:45:38午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.9335 (2.7727)	Arch Loss -59.0109 (-57.4309)	Arch Hard Loss 2.7836 (2.8445)	Arch Beta Loss 617.9449 (602.7546)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.7%, 60.8%)	
11/23 03:46:26午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8287 (2.7709)	Arch Loss -59.8647 (-57.8821)	Arch Hard Loss 2.8316 (2.8493)	Arch Beta Loss 626.9628 (607.3138)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.8%, 60.8%)	
11/23 03:46:27午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  6/49] Final Prec@1 28.8000%
11/23 03:46:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.8370	Prec@(1,5) (28.5%, 59.6%)
11/23 03:46:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.8283	Prec@(1,5) (28.9%, 60.2%)
11/23 03:46:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.8344	Prec@(1,5) (28.6%, 60.2%)
11/23 03:46:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.8379	Prec@(1,5) (28.5%, 60.1%)
11/23 03:46:58午前 searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 28.5120%
11/23 03:46:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/23 03:46:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.5120%
11/23 03:47:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.7859 (2.6485)	Arch Loss -60.8888 (-60.4218)	Arch Hard Loss 2.8076 (2.7858)	Arch Beta Loss 636.9644 (632.0755)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 64.2%)	
11/23 03:48:47午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.6481 (2.6563)	Arch Loss -61.9674 (-60.9290)	Arch Hard Loss 2.7046 (2.7699)	Arch Beta Loss 646.7195 (636.9889)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 63.9%)	
11/23 03:49:41午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.9833 (2.6504)	Arch Loss -62.4161 (-61.4155)	Arch Hard Loss 3.2171 (2.7700)	Arch Beta Loss 656.3320 (641.8548)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.9%)	
11/23 03:50:29午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.7971 (2.6447)	Arch Loss -63.8621 (-61.8733)	Arch Hard Loss 2.6226 (2.7459)	Arch Beta Loss 664.8474 (646.1918)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 64.0%)	
11/23 03:50:29午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  7/49] Final Prec@1 31.1480%
11/23 03:50:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.7100	Prec@(1,5) (30.2%, 62.5%)
11/23 03:50:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6883	Prec@(1,5) (30.8%, 62.9%)
11/23 03:50:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6846	Prec@(1,5) (30.8%, 63.0%)
11/23 03:51:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6950	Prec@(1,5) (30.4%, 62.8%)
11/23 03:51:00午前 searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 30.4400%
11/23 03:51:00午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/23 03:51:01午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.4400%
11/23 03:51:55午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.6174 (2.5304)	Arch Loss -64.4558 (-64.2706)	Arch Hard Loss 2.9669 (2.6939)	Arch Beta Loss 674.2266 (669.6455)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.5%, 66.4%)	
11/23 03:52:49午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.0355 (2.5304)	Arch Loss -65.2869 (-64.7366)	Arch Hard Loss 3.0464 (2.6877)	Arch Beta Loss 683.3329 (674.2431)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.8%, 66.5%)	
11/23 03:53:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.5484 (2.5325)	Arch Loss -66.4025 (-65.1997)	Arch Hard Loss 2.8222 (2.6781)	Arch Beta Loss 692.2468 (678.7785)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.5%)	
11/23 03:54:31午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.2476 (2.5267)	Arch Loss -67.1893 (-65.6166)	Arch Hard Loss 2.8211 (2.6640)	Arch Beta Loss 700.1035 (682.8060)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.8%, 66.8%)	
11/23 03:54:31午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  8/49] Final Prec@1 33.8400%
11/23 03:54:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5660	Prec@(1,5) (32.8%, 66.4%)
11/23 03:54:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5860	Prec@(1,5) (32.1%, 65.8%)
11/23 03:54:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5984	Prec@(1,5) (32.2%, 65.4%)
11/23 03:55:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5981	Prec@(1,5) (32.4%, 65.5%)
11/23 03:55:02午前 searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 32.4120%
11/23 03:55:02午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 03:55:02午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.4120%
11/23 03:55:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.6671 (2.4444)	Arch Loss -67.8707 (-67.8360)	Arch Hard Loss 3.0018 (2.6155)	Arch Beta Loss 708.7248 (704.5151)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.0%, 68.7%)	
11/23 03:56:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.5597 (2.4469)	Arch Loss -69.0661 (-68.2747)	Arch Hard Loss 2.6408 (2.5988)	Arch Beta Loss 717.0690 (708.7351)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 68.7%)	
11/23 03:57:44午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.6605 (2.4404)	Arch Loss -70.1428 (-68.6987)	Arch Hard Loss 2.3793 (2.5903)	Arch Beta Loss 725.2208 (712.8908)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.7%)	
11/23 03:58:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.2914 (2.4324)	Arch Loss -70.5876 (-69.0751)	Arch Hard Loss 2.6518 (2.5825)	Arch Beta Loss 732.3940 (716.5762)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.9%)	
11/23 03:58:33午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  9/49] Final Prec@1 35.5840%
11/23 03:58:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.5470	Prec@(1,5) (33.1%, 66.9%)
11/23 03:58:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.5350	Prec@(1,5) (33.9%, 67.0%)
11/23 03:58:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.5451	Prec@(1,5) (33.9%, 66.9%)
11/23 03:59:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.5434	Prec@(1,5) (34.0%, 66.9%)
11/23 03:59:04午前 searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 34.0000%
11/23 03:59:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 03:59:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.0000%
11/23 03:59:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.5513 (2.3150)	Arch Loss -71.4084 (-71.0890)	Arch Hard Loss 2.6173 (2.5529)	Arch Beta Loss 740.2573 (736.4189)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 71.4%)	
11/23 04:00:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4363 (2.3302)	Arch Loss -72.4047 (-71.4928)	Arch Hard Loss 2.3807 (2.5337)	Arch Beta Loss 747.8538 (740.2645)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 71.2%)	
11/23 04:01:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.4820 (2.3424)	Arch Loss -73.1658 (-71.8863)	Arch Hard Loss 2.3615 (2.5186)	Arch Beta Loss 755.2731 (744.0483)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 71.0%)	
11/23 04:02:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.4169 (2.3395)	Arch Loss -73.8068 (-72.2337)	Arch Hard Loss 2.3727 (2.5065)	Arch Beta Loss 761.7948 (747.4022)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 71.0%)	
11/23 04:02:37午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 10/49] Final Prec@1 37.7760%
11/23 04:02:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4960	Prec@(1,5) (35.3%, 67.1%)
11/23 04:02:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.4651	Prec@(1,5) (35.7%, 68.0%)
11/23 04:03:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.4792	Prec@(1,5) (35.5%, 67.8%)
11/23 04:03:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.4698	Prec@(1,5) (35.5%, 68.0%)
11/23 04:03:07午前 searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 35.4880%
11/23 04:03:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 04:03:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.4880%
11/23 04:04:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.1072 (2.2723)	Arch Loss -74.0378 (-74.0720)	Arch Hard Loss 2.8567 (2.4734)	Arch Beta Loss 768.9449 (765.4545)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 72.1%)	
11/23 04:04:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.6474 (2.2531)	Arch Loss -74.7726 (-74.4390)	Arch Hard Loss 2.8126 (2.4561)	Arch Beta Loss 775.8521 (768.9510)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.6%)	
11/23 04:05:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2500 (2.2496)	Arch Loss -76.0085 (-74.8024)	Arch Hard Loss 2.2500 (2.4365)	Arch Beta Loss 782.5853 (772.3894)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 72.8%)	
11/23 04:06:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.0519 (2.2575)	Arch Loss -76.5159 (-75.1083)	Arch Hard Loss 2.3355 (2.4353)	Arch Beta Loss 788.5140 (775.4363)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 72.7%)	
11/23 04:06:39午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 11/49] Final Prec@1 39.2600%
11/23 04:06:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3779	Prec@(1,5) (37.8%, 70.0%)
11/23 04:06:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3717	Prec@(1,5) (37.3%, 70.2%)
11/23 04:07:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3680	Prec@(1,5) (37.5%, 70.6%)
11/23 04:07:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3672	Prec@(1,5) (37.6%, 70.5%)
11/23 04:07:10午前 searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 37.6040%
11/23 04:07:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 04:07:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.6040%
11/23 04:08:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.1055 (2.1387)	Arch Loss -77.3054 (-76.7746)	Arch Hard Loss 2.1957 (2.4096)	Arch Beta Loss 795.0110 (791.8416)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.8%, 74.4%)	
11/23 04:08:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.2415 (2.1625)	Arch Loss -77.9416 (-77.0914)	Arch Hard Loss 2.1876 (2.4104)	Arch Beta Loss 801.2928 (795.0175)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 74.0%)	
11/23 04:09:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.1721 (2.1660)	Arch Loss -78.4738 (-77.4217)	Arch Hard Loss 2.2684 (2.3928)	Arch Beta Loss 807.4218 (798.1451)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 73.9%)	
11/23 04:10:41午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.7450 (2.1702)	Arch Loss -78.9588 (-77.7106)	Arch Hard Loss 2.3241 (2.3812)	Arch Beta Loss 812.8290 (800.9188)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.3%, 74.0%)	
11/23 04:10:42午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 12/49] Final Prec@1 41.2840%
11/23 04:10:50午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3852	Prec@(1,5) (37.5%, 70.1%)
11/23 04:10:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.3771	Prec@(1,5) (37.6%, 70.2%)
11/23 04:11:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.3717	Prec@(1,5) (37.8%, 70.2%)
11/23 04:11:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.3815	Prec@(1,5) (37.7%, 69.9%)
11/23 04:11:12午前 searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 37.7360%
11/23 04:11:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 04:11:13午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.7360%
11/23 04:12:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.8932 (2.0669)	Arch Loss -79.4767 (-79.2218)	Arch Hard Loss 2.4006 (2.3653)	Arch Beta Loss 818.7728 (815.8704)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 77.1%)	
11/23 04:13:02午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.0782 (2.1165)	Arch Loss -80.2041 (-79.5305)	Arch Hard Loss 2.2498 (2.3478)	Arch Beta Loss 824.5397 (818.7830)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 75.7%)	
11/23 04:13:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.8564 (2.1093)	Arch Loss -80.8711 (-79.8207)	Arch Hard Loss 2.1498 (2.3452)	Arch Beta Loss 830.2097 (821.6592)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 75.7%)	
11/23 04:14:44午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.8106 (2.1101)	Arch Loss -81.4945 (-80.0830)	Arch Hard Loss 2.0290 (2.3390)	Arch Beta Loss 835.2351 (824.2201)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (42.5%, 75.6%)	
11/23 04:14:45午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 13/49] Final Prec@1 42.5000%
11/23 04:14:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2827	Prec@(1,5) (39.6%, 72.3%)
11/23 04:15:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2871	Prec@(1,5) (39.5%, 72.3%)
11/23 04:15:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2752	Prec@(1,5) (39.9%, 72.2%)
11/23 04:15:16午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2769	Prec@(1,5) (40.0%, 72.4%)
11/23 04:15:16午前 searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 39.9880%
11/23 04:15:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 04:15:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.9880%
11/23 04:16:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.9977 (1.9828)	Arch Loss -81.7306 (-81.4761)	Arch Hard Loss 2.3483 (2.3313)	Arch Beta Loss 840.7896 (838.0738)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (45.5%, 78.7%)	
11/23 04:17:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.1353 (2.0171)	Arch Loss -82.3315 (-81.7638)	Arch Hard Loss 2.2925 (2.3173)	Arch Beta Loss 846.2390 (840.8109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.4%)	
11/23 04:17:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.0673 (2.0238)	Arch Loss -82.6907 (-82.0514)	Arch Hard Loss 2.4731 (2.3016)	Arch Beta Loss 851.6376 (843.5297)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (44.4%, 77.4%)	
11/23 04:18:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.9764 (2.0286)	Arch Loss -83.2970 (-82.3058)	Arch Hard Loss 2.3500 (2.2906)	Arch Beta Loss 856.4697 (845.9647)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.2%)	
11/23 04:18:48午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 14/49] Final Prec@1 44.5080%
11/23 04:18:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.2433	Prec@(1,5) (41.3%, 73.3%)
11/23 04:19:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.2624	Prec@(1,5) (40.5%, 72.7%)
11/23 04:19:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.2706	Prec@(1,5) (40.5%, 72.6%)
11/23 04:19:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.2716	Prec@(1,5) (40.5%, 72.5%)
11/23 04:19:19午前 searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 40.5160%
11/23 04:19:19午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:19:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.5160%
11/23 04:20:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.1344 (1.9279)	Arch Loss -83.8516 (-83.6321)	Arch Hard Loss 2.3348 (2.2901)	Arch Beta Loss 861.8641 (859.2219)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.3%, 78.9%)	
11/23 04:21:09午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.8308 (1.9448)	Arch Loss -84.4644 (-83.9017)	Arch Hard Loss 2.2562 (2.2874)	Arch Beta Loss 867.2053 (861.8909)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.8%, 78.8%)	
11/23 04:22:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0143 (1.9502)	Arch Loss -85.1832 (-84.1822)	Arch Hard Loss 2.0720 (2.2740)	Arch Beta Loss 872.5515 (864.5619)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.6%, 78.7%)	
11/23 04:22:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.7508 (1.9629)	Arch Loss -85.6656 (-84.4273)	Arch Hard Loss 2.0727 (2.2697)	Arch Beta Loss 877.3834 (866.9698)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.1%, 78.5%)	
11/23 04:22:51午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 15/49] Final Prec@1 46.0680%
11/23 04:23:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.2186	Prec@(1,5) (40.8%, 73.7%)
11/23 04:23:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.2124	Prec@(1,5) (41.0%, 73.5%)
11/23 04:23:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.2221	Prec@(1,5) (40.8%, 73.3%)
11/23 04:23:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.2170	Prec@(1,5) (41.0%, 73.4%)
11/23 04:23:22午前 searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 40.9600%
11/23 04:23:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:23:23午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.9600%
11/23 04:24:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7473 (1.8669)	Arch Loss -86.4749 (-85.7891)	Arch Hard Loss 1.8087 (2.2270)	Arch Beta Loss 882.8358 (880.1609)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.7%)	
11/23 04:25:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9242 (1.8903)	Arch Loss -86.6379 (-86.0718)	Arch Hard Loss 2.1912 (2.2155)	Arch Beta Loss 888.2903 (882.8730)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.8%, 80.1%)	
11/23 04:26:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9668 (1.9023)	Arch Loss -86.9882 (-86.3320)	Arch Hard Loss 2.3914 (2.2284)	Arch Beta Loss 893.7955 (885.6044)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.9%)	
11/23 04:26:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.9876 (1.9088)	Arch Loss -87.7727 (-86.5916)	Arch Hard Loss 2.1078 (2.2161)	Arch Beta Loss 898.8042 (888.0773)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.7%)	
11/23 04:26:54午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 16/49] Final Prec@1 47.1920%
11/23 04:27:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1987	Prec@(1,5) (41.8%, 74.2%)
11/23 04:27:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1866	Prec@(1,5) (41.9%, 74.1%)
11/23 04:27:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1831	Prec@(1,5) (42.0%, 74.0%)
11/23 04:27:25午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1787	Prec@(1,5) (42.2%, 74.2%)
11/23 04:27:25午前 searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 42.1920%
11/23 04:27:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:27:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.1920%
11/23 04:28:20午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.7962 (1.7961)	Arch Loss -87.9179 (-87.9625)	Arch Hard Loss 2.5304 (2.2066)	Arch Beta Loss 904.4835 (901.6910)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.0%, 81.1%)	
11/23 04:29:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.9628 (1.8292)	Arch Loss -88.7644 (-88.2494)	Arch Hard Loss 2.2536 (2.2028)	Arch Beta Loss 910.1801 (904.5225)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.6%)	
11/23 04:30:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.0437 (1.8496)	Arch Loss -89.7359 (-88.5288)	Arch Hard Loss 1.8571 (2.2087)	Arch Beta Loss 915.9301 (907.3749)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.4%, 80.4%)	
11/23 04:30:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.5273 (1.8603)	Arch Loss -90.0161 (-88.7914)	Arch Hard Loss 2.0998 (2.2044)	Arch Beta Loss 921.1592 (909.9580)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.9%, 80.3%)	
11/23 04:30:57午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 17/49] Final Prec@1 47.9400%
11/23 04:31:06午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.1102	Prec@(1,5) (44.2%, 75.9%)
11/23 04:31:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.1057	Prec@(1,5) (44.0%, 76.1%)
11/23 04:31:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.1127	Prec@(1,5) (43.8%, 75.9%)
11/23 04:31:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.1169	Prec@(1,5) (43.8%, 75.8%)
11/23 04:31:28午前 searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 43.7640%
11/23 04:31:28午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:31:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.7640%
11/23 04:32:24午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.8293 (1.7451)	Arch Loss -90.4943 (-90.2809)	Arch Hard Loss 2.2145 (2.1372)	Arch Beta Loss 927.0876 (924.1812)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.6%)	
11/23 04:33:18午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4734 (1.7922)	Arch Loss -91.2993 (-90.5529)	Arch Hard Loss 2.0015 (2.1597)	Arch Beta Loss 933.0084 (927.1259)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.6%, 81.9%)	
11/23 04:34:12午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.8596 (1.7976)	Arch Loss -91.6478 (-90.8430)	Arch Hard Loss 2.2506 (2.1662)	Arch Beta Loss 938.9840 (930.0923)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.6%)	
11/23 04:35:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.7873 (1.8111)	Arch Loss -92.8351 (-91.1198)	Arch Hard Loss 1.6035 (2.1576)	Arch Beta Loss 944.3865 (932.7740)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.4%, 81.4%)	
11/23 04:35:01午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 18/49] Final Prec@1 49.4080%
11/23 04:35:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1277	Prec@(1,5) (43.6%, 76.1%)
11/23 04:35:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1351	Prec@(1,5) (43.6%, 75.8%)
11/23 04:35:25午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1326	Prec@(1,5) (43.8%, 75.7%)
11/23 04:35:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1358	Prec@(1,5) (43.5%, 75.7%)
11/23 04:35:32午前 searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 43.5440%
11/23 04:35:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:35:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.7640%
11/23 04:36:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.3222 (1.7111)	Arch Loss -92.7852 (-92.5696)	Arch Hard Loss 2.2631 (2.1797)	Arch Beta Loss 950.4830 (947.4924)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.9%, 83.0%)	
11/23 04:37:21午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 2.0029 (1.7488)	Arch Loss -93.4274 (-92.8805)	Arch Hard Loss 2.2277 (2.1712)	Arch Beta Loss 956.5503 (950.5170)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.6%)	
11/23 04:38:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.0588 (1.7575)	Arch Loss -94.3077 (-93.2008)	Arch Hard Loss 1.9549 (2.1543)	Arch Beta Loss 962.6266 (953.5504)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.6%, 82.4%)	
11/23 04:39:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.6971 (1.7734)	Arch Loss -94.6452 (-93.4781)	Arch Hard Loss 2.1666 (2.1504)	Arch Beta Loss 968.1179 (956.2848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.3%, 82.1%)	
11/23 04:39:04午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 19/49] Final Prec@1 50.3240%
11/23 04:39:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.1854	Prec@(1,5) (43.0%, 74.1%)
11/23 04:39:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.1798	Prec@(1,5) (42.9%, 74.4%)
11/23 04:39:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.1654	Prec@(1,5) (42.9%, 74.9%)
11/23 04:39:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.1591	Prec@(1,5) (43.1%, 75.1%)
11/23 04:39:35午前 searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 43.0520%
11/23 04:39:35午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:39:35午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.7640%
11/23 04:40:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.8228 (1.6692)	Arch Loss -95.3285 (-94.9732)	Arch Hard Loss 2.0998 (2.1529)	Arch Beta Loss 974.2827 (971.2603)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.8%)	
11/23 04:41:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.6554 (1.7065)	Arch Loss -95.1932 (-95.2946)	Arch Hard Loss 2.8461 (2.1369)	Arch Beta Loss 980.3928 (974.3152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.8%, 83.3%)	
11/23 04:42:18午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.2615 (1.7182)	Arch Loss -96.8788 (-95.6001)	Arch Hard Loss 1.7712 (2.1368)	Arch Beta Loss 986.4997 (977.3691)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 83.1%)	
11/23 04:43:06午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.8825 (1.7368)	Arch Loss -97.4566 (-95.8810)	Arch Hard Loss 1.7428 (2.1307)	Arch Beta Loss 991.9941 (980.1175)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.4%, 82.6%)	
11/23 04:43:07午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 20/49] Final Prec@1 51.4160%
11/23 04:43:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0760	Prec@(1,5) (45.8%, 76.9%)
11/23 04:43:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0663	Prec@(1,5) (45.6%, 76.9%)
11/23 04:43:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0635	Prec@(1,5) (45.8%, 76.8%)
11/23 04:43:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0674	Prec@(1,5) (45.5%, 76.8%)
11/23 04:43:37午前 searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 45.4480%
11/23 04:43:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:43:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.4480%
11/23 04:44:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.8113 (1.6308)	Arch Loss -97.4765 (-97.3935)	Arch Hard Loss 2.3388 (2.1199)	Arch Beta Loss 998.1531 (995.1335)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 85.2%)	
11/23 04:45:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.6207 (1.6590)	Arch Loss -98.0343 (-97.7064)	Arch Hard Loss 2.3886 (2.1117)	Arch Beta Loss 1004.2286 (998.1806)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.9%, 84.3%)	
11/23 04:46:21午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.6168 (1.6806)	Arch Loss -98.8354 (-98.0221)	Arch Hard Loss 2.1928 (2.0996)	Arch Beta Loss 1010.2821 (1001.2171)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.7%)	
11/23 04:47:09午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.6231 (1.6887)	Arch Loss -99.4244 (-98.2944)	Arch Hard Loss 2.1452 (2.0998)	Arch Beta Loss 1015.6955 (1003.9417)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.4%)	
11/23 04:47:10午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 21/49] Final Prec@1 52.4960%
11/23 04:47:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.0628	Prec@(1,5) (45.4%, 76.0%)
11/23 04:47:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.0660	Prec@(1,5) (45.4%, 76.1%)
11/23 04:47:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.0718	Prec@(1,5) (45.4%, 76.0%)
11/23 04:47:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.0660	Prec@(1,5) (45.6%, 76.2%)
11/23 04:47:41午前 searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 45.6520%
11/23 04:47:41午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:47:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.6520%
11/23 04:48:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.5657 (1.5606)	Arch Loss -99.6127 (-99.7621)	Arch Hard Loss 2.5616 (2.1163)	Arch Beta Loss 1021.7437 (1018.7844)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.3%, 86.2%)	
11/23 04:49:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.6515 (1.5967)	Arch Loss -100.6296 (-100.0806)	Arch Hard Loss 2.1385 (2.0960)	Arch Beta Loss 1027.6808 (1021.7663)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.0%)	
11/23 04:50:24午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4444 (1.6201)	Arch Loss -101.0338 (-100.3802)	Arch Hard Loss 2.3219 (2.0926)	Arch Beta Loss 1033.5577 (1024.7271)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.8%)	
11/23 04:51:12午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.9857 (1.6370)	Arch Loss -101.9978 (-100.6513)	Arch Hard Loss 1.8806 (2.0862)	Arch Beta Loss 1038.7847 (1027.3753)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.5%)	
11/23 04:51:13午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 22/49] Final Prec@1 53.5600%
11/23 04:51:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.0454	Prec@(1,5) (45.9%, 77.3%)
11/23 04:51:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.0484	Prec@(1,5) (45.6%, 77.5%)
11/23 04:51:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.0488	Prec@(1,5) (45.5%, 77.4%)
11/23 04:51:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.0569	Prec@(1,5) (45.3%, 77.1%)
11/23 04:51:44午前 searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 45.3040%
11/23 04:51:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:51:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.6520%
11/23 04:52:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4143 (1.5190)	Arch Loss -102.6331 (-102.1080)	Arch Hard Loss 1.8249 (2.0663)	Arch Beta Loss 1044.5806 (1041.7426)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.4%, 86.3%)	
11/23 04:53:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.4709 (1.5556)	Arch Loss -102.4519 (-102.3903)	Arch Hard Loss 2.5720 (2.0691)	Arch Beta Loss 1050.2388 (1044.5935)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.7%)	
11/23 04:54:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.6399 (1.5674)	Arch Loss -103.5340 (-102.6576)	Arch Hard Loss 2.0474 (2.0839)	Arch Beta Loss 1055.8134 (1047.4148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.5%)	
11/23 04:55:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.8612 (1.5871)	Arch Loss -103.7724 (-102.9087)	Arch Hard Loss 2.3043 (2.0845)	Arch Beta Loss 1060.7666 (1049.9324)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.2%)	
11/23 04:55:16午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 23/49] Final Prec@1 55.1200%
11/23 04:55:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.0563	Prec@(1,5) (45.2%, 76.9%)
11/23 04:55:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.0445	Prec@(1,5) (45.5%, 77.2%)
11/23 04:55:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.0531	Prec@(1,5) (45.4%, 77.0%)
11/23 04:55:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.0567	Prec@(1,5) (45.4%, 77.0%)
11/23 04:55:47午前 searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 45.4560%
11/23 04:55:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:55:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.6520%
11/23 04:56:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.1120 (1.5027)	Arch Loss -104.4883 (-104.2977)	Arch Hard Loss 2.1384 (2.0606)	Arch Beta Loss 1066.2664 (1063.5831)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.7%)	
11/23 04:57:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.7062 (1.5423)	Arch Loss -105.0323 (-104.5587)	Arch Hard Loss 2.1307 (2.0696)	Arch Beta Loss 1071.6304 (1066.2831)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.2%)	
11/23 04:58:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.9333 (1.5451)	Arch Loss -105.5932 (-104.8273)	Arch Hard Loss 2.1005 (2.0687)	Arch Beta Loss 1076.9370 (1068.9603)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.1%, 86.1%)	
11/23 04:59:18午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.5825 (1.5584)	Arch Loss -106.0737 (-105.0636)	Arch Hard Loss 2.0929 (2.0717)	Arch Beta Loss 1081.6661 (1071.3530)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.8%)	
11/23 04:59:19午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 24/49] Final Prec@1 55.6600%
11/23 04:59:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.0864	Prec@(1,5) (45.6%, 76.8%)
11/23 04:59:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.0674	Prec@(1,5) (46.0%, 77.0%)
11/23 04:59:42午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.0712	Prec@(1,5) (45.8%, 77.0%)
11/23 04:59:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.0586	Prec@(1,5) (46.0%, 77.2%)
11/23 04:59:50午前 searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 46.0640%
11/23 04:59:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 04:59:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.0640%
11/23 05:00:44午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.5861 (1.4411)	Arch Loss -106.7101 (-106.4097)	Arch Hard Loss 1.9818 (2.0253)	Arch Beta Loss 1086.9189 (1084.3499)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.2%)	
11/23 05:01:38午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.4042 (1.4752)	Arch Loss -106.8373 (-106.6542)	Arch Hard Loss 2.3719 (2.0400)	Arch Beta Loss 1092.0913 (1086.9419)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.7%)	
11/23 05:02:32午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.2680 (1.4963)	Arch Loss -108.2534 (-106.9047)	Arch Hard Loss 1.4695 (2.0477)	Arch Beta Loss 1097.2291 (1089.5238)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.4%)	
11/23 05:03:20午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.2299 (1.5041)	Arch Loss -108.3060 (-107.1402)	Arch Hard Loss 1.8777 (2.0437)	Arch Beta Loss 1101.8376 (1091.8396)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.4%)	
11/23 05:03:20午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 25/49] Final Prec@1 56.9960%
11/23 05:03:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9958	Prec@(1,5) (47.7%, 78.3%)
11/23 05:03:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.0049	Prec@(1,5) (47.5%, 78.3%)
11/23 05:03:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9865	Prec@(1,5) (47.6%, 78.5%)
11/23 05:03:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9913	Prec@(1,5) (47.4%, 78.4%)
11/23 05:03:51午前 searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 47.3840%
11/23 05:03:51午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 05:03:52午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.3840%
11/23 05:04:46午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.9097 (1.4132)	Arch Loss -108.8522 (-108.4784)	Arch Hard Loss 1.8461 (1.9680)	Arch Beta Loss 1106.9839 (1104.4633)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.1%, 88.0%)	
11/23 05:05:40午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.2254 (1.4343)	Arch Loss -109.0797 (-108.7050)	Arch Hard Loss 2.1270 (1.9954)	Arch Beta Loss 1112.0664 (1107.0044)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.8%)	
11/23 05:06:34午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.5496 (1.4362)	Arch Loss -109.9984 (-108.9372)	Arch Hard Loss 1.7146 (2.0173)	Arch Beta Loss 1117.1301 (1109.5455)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.9%)	
11/23 05:07:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.3447 (1.4598)	Arch Loss -109.9947 (-109.1562)	Arch Hard Loss 2.1710 (2.0262)	Arch Beta Loss 1121.6570 (1111.8242)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.8%, 87.4%)	
11/23 05:07:23午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 26/49] Final Prec@1 57.8320%
11/23 05:07:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.0284	Prec@(1,5) (46.6%, 78.6%)
11/23 05:07:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.0087	Prec@(1,5) (47.2%, 78.2%)
11/23 05:07:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.0115	Prec@(1,5) (47.2%, 78.1%)
11/23 05:07:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.0155	Prec@(1,5) (46.9%, 77.9%)
11/23 05:07:54午前 searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 46.9320%
11/23 05:07:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 05:07:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.3840%
11/23 05:08:49午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.1522 (1.3233)	Arch Loss -110.2415 (-110.4079)	Arch Hard Loss 2.4285 (2.0149)	Arch Beta Loss 1126.6992 (1124.2272)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 89.2%)	
11/23 05:09:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.7731 (1.3784)	Arch Loss -111.5381 (-110.6703)	Arch Hard Loss 1.6255 (2.0010)	Arch Beta Loss 1131.6356 (1126.7129)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.4%)	
11/23 05:10:37午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.3545 (1.3912)	Arch Loss -111.4170 (-110.9168)	Arch Hard Loss 2.2357 (2.0011)	Arch Beta Loss 1136.5267 (1129.1789)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.2%)	
11/23 05:11:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.2375 (1.4096)	Arch Loss -112.4855 (-111.1429)	Arch Hard Loss 1.6014 (1.9954)	Arch Beta Loss 1140.8687 (1131.3830)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.9%)	
11/23 05:11:26午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 27/49] Final Prec@1 59.2320%
11/23 05:11:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.0207	Prec@(1,5) (47.2%, 78.0%)
11/23 05:11:42午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.0132	Prec@(1,5) (47.2%, 78.1%)
11/23 05:11:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.0162	Prec@(1,5) (47.2%, 78.1%)
11/23 05:11:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.0109	Prec@(1,5) (47.4%, 78.2%)
11/23 05:11:56午前 searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 47.3640%
11/23 05:11:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 05:11:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.3840%
11/23 05:12:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.6240 (1.2876)	Arch Loss -112.6201 (-112.3901)	Arch Hard Loss 1.9457 (1.9413)	Arch Beta Loss 1145.6577 (1143.3147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.6%)	
11/23 05:13:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1601 (1.3257)	Arch Loss -113.5630 (-112.5921)	Arch Hard Loss 1.4658 (1.9738)	Arch Beta Loss 1150.2872 (1145.6586)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.5%, 89.0%)	
11/23 05:14:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.4930 (1.3466)	Arch Loss -113.7600 (-112.8004)	Arch Hard Loss 1.7219 (1.9963)	Arch Beta Loss 1154.8184 (1147.9670)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.8%)	
11/23 05:15:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.5562 (1.3742)	Arch Loss -114.0794 (-112.9900)	Arch Hard Loss 1.8017 (2.0115)	Arch Beta Loss 1158.8103 (1150.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.4%)	
11/23 05:15:28午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 28/49] Final Prec@1 60.3280%
11/23 05:15:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.0347	Prec@(1,5) (46.6%, 78.1%)
11/23 05:15:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.0419	Prec@(1,5) (46.2%, 78.2%)
11/23 05:15:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.0230	Prec@(1,5) (47.0%, 78.2%)
11/23 05:15:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.0127	Prec@(1,5) (47.2%, 78.5%)
11/23 05:15:59午前 searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 47.1920%
11/23 05:15:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
11/23 05:15:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.3840%
11/23 05:16:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.4011 (1.2619)	Arch Loss -114.3859 (-114.0752)	Arch Hard Loss 1.9312 (2.0290)	Arch Beta Loss 1163.1711 (1161.0427)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.1%, 90.4%)	
11/23 05:17:47午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.1075 (1.2673)	Arch Loss -114.9196 (-114.2945)	Arch Hard Loss 1.8162 (2.0226)	Arch Beta Loss 1167.3586 (1163.1705)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.2%)	
11/23 05:18:41午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1791 (1.2924)	Arch Loss -114.6613 (-114.5084)	Arch Hard Loss 2.4803 (2.0168)	Arch Beta Loss 1171.4163 (1165.2525)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.6%)	
11/23 05:19:29午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.2732 (1.3094)	Arch Loss -115.4517 (-114.6975)	Arch Hard Loss 2.0454 (2.0117)	Arch Beta Loss 1174.9706 (1167.0918)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.3%)	
11/23 05:19:30午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 29/49] Final Prec@1 61.7040%
11/23 05:19:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.0271	Prec@(1,5) (48.2%, 78.1%)
11/23 05:19:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.0317	Prec@(1,5) (48.1%, 78.2%)
11/23 05:19:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.0436	Prec@(1,5) (48.1%, 78.2%)
11/23 05:20:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.0269	Prec@(1,5) (48.1%, 78.6%)
11/23 05:20:01午前 searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 48.1080%
11/23 05:20:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:20:01午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1080%
11/23 05:20:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.3306 (1.2161)	Arch Loss -116.2049 (-115.7208)	Arch Hard Loss 1.6794 (1.9747)	Arch Beta Loss 1178.8429 (1176.9544)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.8%)	
11/23 05:21:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.4847 (1.2214)	Arch Loss -116.0762 (-115.9019)	Arch Hard Loss 2.1786 (1.9820)	Arch Beta Loss 1182.5479 (1178.8389)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.6%)	
11/23 05:22:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.4081 (1.2435)	Arch Loss -116.5890 (-116.0876)	Arch Hard Loss 2.0230 (1.9805)	Arch Beta Loss 1186.1202 (1180.6809)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.4%)	
11/23 05:23:32午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.4254 (1.2689)	Arch Loss -116.8984 (-116.2444)	Arch Hard Loss 2.0248 (1.9857)	Arch Beta Loss 1189.2322 (1182.3014)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.7%, 90.1%)	
11/23 05:23:32午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 30/49] Final Prec@1 62.6440%
11/23 05:23:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.1932	Prec@(1,5) (44.5%, 76.1%)
11/23 05:23:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.1700	Prec@(1,5) (45.4%, 76.1%)
11/23 05:23:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.1798	Prec@(1,5) (45.1%, 75.9%)
11/23 05:24:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.1818	Prec@(1,5) (45.1%, 75.9%)
11/23 05:24:03午前 searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 45.0760%
11/23 05:24:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:24:03午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1080%
11/23 05:24:58午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.1950 (1.1756)	Arch Loss -117.0389 (-117.1478)	Arch Hard Loss 2.2211 (1.9484)	Arch Beta Loss 1192.5996 (1190.9615)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.1%)	
11/23 05:25:52午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.0940 (1.1959)	Arch Loss -117.6855 (-117.2761)	Arch Hard Loss 1.8946 (1.9834)	Arch Beta Loss 1195.8014 (1192.5948)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.9%)	
11/23 05:26:46午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.4721 (1.2171)	Arch Loss -117.8086 (-117.4312)	Arch Hard Loss 2.0805 (1.9875)	Arch Beta Loss 1198.8906 (1194.1871)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.7%)	
11/23 05:27:34午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.5745 (1.2307)	Arch Loss -118.2542 (-117.5798)	Arch Hard Loss 1.9036 (1.9790)	Arch Beta Loss 1201.5779 (1195.5881)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.5%)	
11/23 05:27:34午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 31/49] Final Prec@1 63.8080%
11/23 05:27:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.0293	Prec@(1,5) (47.6%, 78.2%)
11/23 05:27:50午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.0205	Prec@(1,5) (47.5%, 78.6%)
11/23 05:27:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.0366	Prec@(1,5) (47.6%, 78.5%)
11/23 05:28:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.0453	Prec@(1,5) (47.4%, 78.3%)
11/23 05:28:05午前 searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 47.3520%
11/23 05:28:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:28:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1080%
11/23 05:29:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.2788 (1.1366)	Arch Loss -118.5024 (-118.3436)	Arch Hard Loss 1.9453 (1.9629)	Arch Beta Loss 1204.4769 (1203.0653)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.7%)	
11/23 05:29:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9000 (1.1444)	Arch Loss -118.3184 (-118.4614)	Arch Hard Loss 2.4053 (1.9858)	Arch Beta Loss 1207.2377 (1204.4725)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.8%)	
11/23 05:30:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.9602 (1.1539)	Arch Loss -119.0146 (-118.5883)	Arch Hard Loss 1.9736 (1.9959)	Arch Beta Loss 1209.8820 (1205.8422)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.6%)	
11/23 05:31:37午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.1634 (1.1711)	Arch Loss -119.6383 (-118.7166)	Arch Hard Loss 1.5797 (1.9877)	Arch Beta Loss 1212.1801 (1207.0438)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.4%)	
11/23 05:31:37午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 32/49] Final Prec@1 65.0720%
11/23 05:31:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.4533	Prec@(1,5) (41.6%, 72.3%)
11/23 05:31:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.4424	Prec@(1,5) (42.3%, 72.3%)
11/23 05:32:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.4379	Prec@(1,5) (42.1%, 72.4%)
11/23 05:32:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.4441	Prec@(1,5) (42.0%, 72.2%)
11/23 05:32:08午前 searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 42.0000%
11/23 05:32:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:32:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1080%
11/23 05:33:02午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.2553 (1.0597)	Arch Loss -119.5960 (-119.3694)	Arch Hard Loss 1.8708 (1.9762)	Arch Beta Loss 1214.6681 (1213.4566)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.8%)	
11/23 05:33:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.1141 (1.0904)	Arch Loss -120.1904 (-119.5245)	Arch Hard Loss 1.5124 (1.9418)	Arch Beta Loss 1217.0282 (1214.6624)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.4%)	
11/23 05:34:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2625 (1.1121)	Arch Loss -119.5066 (-119.6119)	Arch Hard Loss 2.4234 (1.9717)	Arch Beta Loss 1219.3002 (1215.8359)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 92.2%)	
11/23 05:35:38午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1860 (1.1252)	Arch Loss -120.5296 (-119.7109)	Arch Hard Loss 1.5959 (1.9756)	Arch Beta Loss 1221.2552 (1216.8643)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 92.1%)	
11/23 05:35:39午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 33/49] Final Prec@1 66.5080%
11/23 05:35:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1165	Prec@(1,5) (47.5%, 77.8%)
11/23 05:35:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.1103	Prec@(1,5) (47.7%, 77.9%)
11/23 05:36:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.1102	Prec@(1,5) (47.7%, 78.0%)
11/23 05:36:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.1123	Prec@(1,5) (47.8%, 78.0%)
11/23 05:36:10午前 searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 47.7800%
11/23 05:36:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:36:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1080%
11/23 05:37:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8737 (1.0085)	Arch Loss -120.4213 (-120.3247)	Arch Hard Loss 1.9160 (1.9096)	Arch Beta Loss 1223.3729 (1222.3432)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.8%)	
11/23 05:37:58午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.6903 (1.0480)	Arch Loss -120.4357 (-120.3936)	Arch Hard Loss 2.1041 (1.9438)	Arch Beta Loss 1225.3981 (1223.3742)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.1%)	
11/23 05:38:52午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0859 (1.0563)	Arch Loss -120.4497 (-120.4877)	Arch Hard Loss 2.2844 (1.9501)	Arch Beta Loss 1227.3409 (1224.3779)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.9%)	
11/23 05:39:41午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.2195 (1.0695)	Arch Loss -120.9876 (-120.5711)	Arch Hard Loss 1.9140 (1.9547)	Arch Beta Loss 1229.0162 (1225.2587)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.7%)	
11/23 05:39:41午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 34/49] Final Prec@1 68.1280%
11/23 05:39:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.2196	Prec@(1,5) (46.3%, 76.9%)
11/23 05:39:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.2224	Prec@(1,5) (45.9%, 76.7%)
11/23 05:40:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.2124	Prec@(1,5) (46.0%, 76.8%)
11/23 05:40:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.2077	Prec@(1,5) (45.9%, 77.0%)
11/23 05:40:12午前 searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 45.8680%
11/23 05:40:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:40:12午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1080%
11/23 05:41:06午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.2088 (0.9757)	Arch Loss -121.2743 (-121.0295)	Arch Hard Loss 1.8093 (1.9654)	Arch Beta Loss 1230.8361 (1229.9486)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.6%)	
11/23 05:42:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.2020 (1.0022)	Arch Loss -121.5977 (-121.1207)	Arch Hard Loss 1.6582 (1.9624)	Arch Beta Loss 1232.5591 (1230.8308)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.3%)	
11/23 05:42:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.1999 (1.0128)	Arch Loss -121.2955 (-121.2115)	Arch Hard Loss 2.1261 (1.9572)	Arch Beta Loss 1234.2157 (1231.6876)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.3%)	
11/23 05:43:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.2945 (1.0210)	Arch Loss -121.8739 (-121.2655)	Arch Hard Loss 1.6911 (1.9784)	Arch Beta Loss 1235.6498 (1232.4392)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.2%)	
11/23 05:43:43午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 35/49] Final Prec@1 69.1200%
11/23 05:43:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.0108	Prec@(1,5) (49.7%, 79.9%)
11/23 05:43:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.0140	Prec@(1,5) (49.9%, 79.6%)
11/23 05:44:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.0121	Prec@(1,5) (50.0%, 79.5%)
11/23 05:44:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.0203	Prec@(1,5) (50.0%, 79.4%)
11/23 05:44:14午前 searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 49.9640%
11/23 05:44:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:44:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.9640%
11/23 05:45:09午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.9629 (0.9099)	Arch Loss -121.4884 (-121.6691)	Arch Hard Loss 2.2314 (1.9755)	Arch Beta Loss 1237.1981 (1236.4467)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.5%)	
11/23 05:46:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.1106 (0.9428)	Arch Loss -122.2085 (-121.7500)	Arch Hard Loss 1.6593 (1.9698)	Arch Beta Loss 1238.6781 (1237.1984)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.3%)	
11/23 05:46:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.9174 (0.9595)	Arch Loss -122.1044 (-121.8421)	Arch Hard Loss 1.9060 (1.9513)	Arch Beta Loss 1240.1041 (1237.9341)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.2%, 94.1%)	
11/23 05:47:46午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8410 (0.9636)	Arch Loss -122.3525 (-121.9038)	Arch Hard Loss 1.7804 (1.9541)	Arch Beta Loss 1241.3296 (1238.5791)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 94.1%)	
11/23 05:47:46午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 36/49] Final Prec@1 70.8920%
11/23 05:47:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.2640	Prec@(1,5) (47.3%, 76.2%)
11/23 05:48:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.2269	Prec@(1,5) (47.7%, 77.0%)
11/23 05:48:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.2567	Prec@(1,5) (47.4%, 76.7%)
11/23 05:48:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.2617	Prec@(1,5) (47.1%, 76.6%)
11/23 05:48:17午前 searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 47.1400%
11/23 05:48:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:48:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.9640%
11/23 05:49:12午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.9428 (0.8634)	Arch Loss -121.8915 (-122.2201)	Arch Hard Loss 2.3744 (1.9814)	Arch Beta Loss 1242.6584 (1242.0142)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 94.9%)	
11/23 05:50:06午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.9759 (0.8795)	Arch Loss -122.3105 (-122.2960)	Arch Hard Loss 2.0813 (1.9697)	Arch Beta Loss 1243.9182 (1242.6568)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.8%)	
11/23 05:51:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8524 (0.8886)	Arch Loss -122.8940 (-122.3567)	Arch Hard Loss 1.6193 (1.9716)	Arch Beta Loss 1245.1333 (1243.2832)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.7%)	
11/23 05:51:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.8767 (0.8955)	Arch Loss -122.7685 (-122.4147)	Arch Hard Loss 1.8502 (1.9687)	Arch Beta Loss 1246.1864 (1243.8337)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.7%)	
11/23 05:51:49午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 37/49] Final Prec@1 73.0720%
11/23 05:51:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1712	Prec@(1,5) (47.5%, 78.2%)
11/23 05:52:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1535	Prec@(1,5) (48.1%, 78.5%)
11/23 05:52:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1430	Prec@(1,5) (48.5%, 78.6%)
11/23 05:52:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1517	Prec@(1,5) (48.3%, 78.4%)
11/23 05:52:20午前 searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 48.3080%
11/23 05:52:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:52:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.9640%
11/23 05:53:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6135 (0.8406)	Arch Loss -122.9583 (-122.7243)	Arch Hard Loss 1.7744 (1.9528)	Arch Beta Loss 1247.3273 (1246.7704)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.3%)	
11/23 05:54:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6399 (0.8465)	Arch Loss -122.7764 (-122.7989)	Arch Hard Loss 2.0647 (1.9335)	Arch Beta Loss 1248.4109 (1247.3240)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.2%)	
11/23 05:55:02午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.0344 (0.8484)	Arch Loss -123.0186 (-122.8423)	Arch Hard Loss 1.9256 (1.9438)	Arch Beta Loss 1249.4419 (1247.8616)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.2%)	
11/23 05:55:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6505 (0.8536)	Arch Loss -122.9080 (-122.8667)	Arch Hard Loss 2.1255 (1.9664)	Arch Beta Loss 1250.3345 (1248.3312)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.2%)	
11/23 05:55:51午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 38/49] Final Prec@1 74.1240%
11/23 05:55:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.0533	Prec@(1,5) (50.5%, 79.6%)
11/23 05:56:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.0563	Prec@(1,5) (50.0%, 79.5%)
11/23 05:56:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.0503	Prec@(1,5) (50.1%, 79.8%)
11/23 05:56:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.0492	Prec@(1,5) (50.2%, 79.8%)
11/23 05:56:22午前 searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 50.1760%
11/23 05:56:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 05:56:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 05:57:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.7298 (0.7757)	Arch Loss -123.4768 (-123.1326)	Arch Hard Loss 1.6538 (1.9509)	Arch Beta Loss 1251.3055 (1250.8343)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.7%)	
11/23 05:58:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6958 (0.7843)	Arch Loss -123.3925 (-123.1686)	Arch Hard Loss 1.8301 (1.9617)	Arch Beta Loss 1252.2258 (1251.3028)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.8%)	
11/23 05:59:04午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.6414 (0.7920)	Arch Loss -123.1706 (-123.1980)	Arch Hard Loss 2.1402 (1.9780)	Arch Beta Loss 1253.1080 (1251.7602)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.8%)	
11/23 05:59:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8622 (0.7978)	Arch Loss -123.3085 (-123.2403)	Arch Hard Loss 2.0797 (1.9759)	Arch Beta Loss 1253.8828 (1252.1623)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
11/23 05:59:53午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 39/49] Final Prec@1 75.8200%
11/23 06:00:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1748	Prec@(1,5) (48.3%, 78.4%)
11/23 06:00:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1590	Prec@(1,5) (48.4%, 78.6%)
11/23 06:00:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1584	Prec@(1,5) (48.5%, 78.6%)
11/23 06:00:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1611	Prec@(1,5) (48.5%, 78.5%)
11/23 06:00:24午前 searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 48.5200%
11/23 06:00:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:00:24午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:01:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.7562 (0.7455)	Arch Loss -123.3209 (-123.4079)	Arch Hard Loss 2.1500 (2.0224)	Arch Beta Loss 1254.7092 (1254.3026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
11/23 06:02:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.9475 (0.7451)	Arch Loss -123.5805 (-123.4556)	Arch Hard Loss 1.9694 (2.0152)	Arch Beta Loss 1255.4989 (1254.7079)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.3%)	
11/23 06:03:07午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6103 (0.7607)	Arch Loss -123.6337 (-123.5062)	Arch Hard Loss 1.9928 (2.0040)	Arch Beta Loss 1256.2654 (1255.1017)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.1%)	
11/23 06:03:55午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.9301 (0.7641)	Arch Loss -124.0698 (-123.5575)	Arch Hard Loss 1.6227 (1.9872)	Arch Beta Loss 1256.9249 (1255.4472)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.1%)	
11/23 06:03:56午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 40/49] Final Prec@1 76.5920%
11/23 06:04:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.5057	Prec@(1,5) (45.0%, 76.2%)
11/23 06:04:11午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.4948	Prec@(1,5) (45.3%, 76.0%)
11/23 06:04:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.4953	Prec@(1,5) (45.5%, 75.9%)
11/23 06:04:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.5049	Prec@(1,5) (45.4%, 75.6%)
11/23 06:04:26午前 searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 45.4560%
11/23 06:04:26午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:04:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:05:21午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.6238 (0.6870)	Arch Loss -123.7959 (-123.7335)	Arch Hard Loss 1.9682 (1.9955)	Arch Beta Loss 1257.6412 (1257.2908)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.8%)	
11/23 06:06:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5687 (0.6978)	Arch Loss -123.8980 (-123.7496)	Arch Hard Loss 1.9338 (2.0140)	Arch Beta Loss 1258.3173 (1257.6358)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.7%)	
11/23 06:07:09午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6682 (0.7009)	Arch Loss -124.0465 (-123.7945)	Arch Hard Loss 1.8510 (2.0030)	Arch Beta Loss 1258.9755 (1257.9747)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.7%)	
11/23 06:07:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9988 (0.7130)	Arch Loss -124.2221 (-123.8223)	Arch Hard Loss 1.7323 (2.0049)	Arch Beta Loss 1259.5439 (1258.2723)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.6%)	
11/23 06:07:57午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 41/49] Final Prec@1 78.1280%
11/23 06:08:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.4788	Prec@(1,5) (44.8%, 75.2%)
11/23 06:08:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.5189	Prec@(1,5) (44.8%, 74.7%)
11/23 06:08:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.5118	Prec@(1,5) (44.9%, 75.1%)
11/23 06:08:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.5179	Prec@(1,5) (44.9%, 74.9%)
11/23 06:08:28午前 searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 44.8880%
11/23 06:08:28午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:08:28午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:09:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.5958 (0.6598)	Arch Loss -124.2311 (-123.9909)	Arch Hard Loss 1.7843 (1.9948)	Arch Beta Loss 1260.1545 (1259.8571)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.1%)	
11/23 06:10:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6508 (0.6605)	Arch Loss -123.9926 (-124.0354)	Arch Hard Loss 2.0828 (1.9805)	Arch Beta Loss 1260.7537 (1260.1587)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
11/23 06:11:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6430 (0.6757)	Arch Loss -123.7258 (-124.0582)	Arch Hard Loss 2.4052 (1.9869)	Arch Beta Loss 1261.3098 (1260.4514)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.3%, 97.0%)	
11/23 06:11:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.6698 (0.6831)	Arch Loss -123.7179 (-124.0786)	Arch Hard Loss 2.4590 (1.9918)	Arch Beta Loss 1261.7698 (1260.7035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.9%)	
11/23 06:11:59午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 42/49] Final Prec@1 79.0640%
11/23 06:12:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.2925	Prec@(1,5) (47.5%, 77.2%)
11/23 06:12:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.3299	Prec@(1,5) (46.6%, 76.9%)
11/23 06:12:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.3267	Prec@(1,5) (46.7%, 76.8%)
11/23 06:12:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.3329	Prec@(1,5) (46.7%, 76.9%)
11/23 06:12:30午前 searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 46.6840%
11/23 06:12:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:12:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:13:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7729 (0.6425)	Arch Loss -123.8968 (-124.2193)	Arch Hard Loss 2.3334 (1.9849)	Arch Beta Loss 1262.3022 (1262.0417)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.1%)	
11/23 06:14:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.7637 (0.6459)	Arch Loss -124.2953 (-124.2424)	Arch Hard Loss 1.9845 (1.9872)	Arch Beta Loss 1262.7974 (1262.2958)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
11/23 06:15:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7967 (0.6455)	Arch Loss -123.8546 (-124.2643)	Arch Hard Loss 2.4735 (1.9903)	Arch Beta Loss 1263.2804 (1262.5457)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.2%)	
11/23 06:16:01午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.5440 (0.6482)	Arch Loss -124.6642 (-124.2877)	Arch Hard Loss 1.7056 (1.9887)	Arch Beta Loss 1263.6979 (1262.7642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.2%)	
11/23 06:16:02午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 43/49] Final Prec@1 80.4920%
11/23 06:16:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.2449	Prec@(1,5) (47.6%, 78.5%)
11/23 06:16:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.2503	Prec@(1,5) (48.1%, 78.3%)
11/23 06:16:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.2652	Prec@(1,5) (48.2%, 78.2%)
11/23 06:16:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.2804	Prec@(1,5) (48.1%, 78.1%)
11/23 06:16:33午前 searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 48.1480%
11/23 06:16:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:16:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:17:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5172 (0.6062)	Arch Loss -124.1301 (-124.3900)	Arch Hard Loss 2.2841 (2.0025)	Arch Beta Loss 1264.1426 (1263.9245)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.5%)	
11/23 06:18:22午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.7325 (0.6110)	Arch Loss -123.6665 (-124.4294)	Arch Hard Loss 2.7911 (1.9849)	Arch Beta Loss 1264.5762 (1264.1431)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.5%)	
11/23 06:19:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.4913 (0.6189)	Arch Loss -124.3713 (-124.4383)	Arch Hard Loss 2.1280 (1.9975)	Arch Beta Loss 1264.9924 (1264.3588)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
11/23 06:20:04午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5434 (0.6178)	Arch Loss -124.6208 (-124.4621)	Arch Hard Loss 1.9134 (1.9925)	Arch Beta Loss 1265.3418 (1264.5460)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.5%)	
11/23 06:20:04午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 44/49] Final Prec@1 81.2720%
11/23 06:20:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.2545	Prec@(1,5) (49.1%, 78.6%)
11/23 06:20:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.2908	Prec@(1,5) (48.8%, 78.1%)
11/23 06:20:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.2812	Prec@(1,5) (48.8%, 78.3%)
11/23 06:20:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.2893	Prec@(1,5) (48.8%, 78.1%)
11/23 06:20:35午前 searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 48.8200%
11/23 06:20:35午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:20:35午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:21:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4763 (0.5711)	Arch Loss -125.1590 (-124.5734)	Arch Hard Loss 1.4132 (1.9806)	Arch Beta Loss 1265.7227 (1265.5396)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
11/23 06:22:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.7068 (0.5784)	Arch Loss -124.5270 (-124.5928)	Arch Hard Loss 2.0816 (1.9795)	Arch Beta Loss 1266.0863 (1265.7233)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.9%)	
11/23 06:23:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6597 (0.5815)	Arch Loss -124.4436 (-124.6005)	Arch Hard Loss 2.2001 (1.9898)	Arch Beta Loss 1266.4363 (1265.9034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
11/23 06:24:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6264 (0.5833)	Arch Loss -124.7501 (-124.6111)	Arch Hard Loss 1.9232 (1.9950)	Arch Beta Loss 1266.7338 (1266.0613)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.8%)	
11/23 06:24:06午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 45/49] Final Prec@1 82.3920%
11/23 06:24:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.4459	Prec@(1,5) (45.2%, 75.7%)
11/23 06:24:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.4849	Prec@(1,5) (44.9%, 75.3%)
11/23 06:24:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.4959	Prec@(1,5) (44.8%, 75.1%)
11/23 06:24:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.5002	Prec@(1,5) (44.7%, 75.0%)
11/23 06:24:36午前 searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 44.6840%
11/23 06:24:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:24:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:25:31午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.7222 (0.5423)	Arch Loss -124.6826 (-124.6726)	Arch Hard Loss 2.0238 (2.0178)	Arch Beta Loss 1267.0637 (1266.9041)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
11/23 06:26:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.4239 (0.5492)	Arch Loss -125.1146 (-124.7185)	Arch Hard Loss 1.6236 (1.9879)	Arch Beta Loss 1267.3818 (1267.0642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
11/23 06:27:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.4344 (0.5576)	Arch Loss -125.0204 (-124.7370)	Arch Hard Loss 1.7471 (1.9850)	Arch Beta Loss 1267.6758 (1267.2202)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 98.0%)	
11/23 06:28:07午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.3803 (0.5641)	Arch Loss -124.6574 (-124.7472)	Arch Hard Loss 2.1363 (1.9884)	Arch Beta Loss 1267.9370 (1267.3555)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.0%)	
11/23 06:28:08午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 46/49] Final Prec@1 82.7720%
11/23 06:28:16午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.2737	Prec@(1,5) (48.6%, 78.0%)
11/23 06:28:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.2441	Prec@(1,5) (48.8%, 78.1%)
11/23 06:28:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.2430	Prec@(1,5) (48.8%, 78.3%)
11/23 06:28:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.2407	Prec@(1,5) (48.7%, 78.3%)
11/23 06:28:39午前 searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 48.7280%
11/23 06:28:39午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:28:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:29:34午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.5370 (0.5355)	Arch Loss -125.5566 (-124.7914)	Arch Hard Loss 1.2650 (2.0167)	Arch Beta Loss 1268.2155 (1268.0804)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.5%)	
11/23 06:30:28午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6023 (0.5364)	Arch Loss -124.9314 (-124.7887)	Arch Hard Loss 1.9180 (2.0333)	Arch Beta Loss 1268.4941 (1268.2195)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.3%)	
11/23 06:31:21午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.6069 (0.5475)	Arch Loss -124.8517 (-124.8273)	Arch Hard Loss 2.0240 (2.0083)	Arch Beta Loss 1268.7578 (1268.3560)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
11/23 06:32:10午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7133 (0.5486)	Arch Loss -124.6708 (-124.8333)	Arch Hard Loss 2.2274 (2.0142)	Arch Beta Loss 1268.9814 (1268.4750)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/23 06:32:11午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 47/49] Final Prec@1 83.5520%
11/23 06:32:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.4116	Prec@(1,5) (45.5%, 76.8%)
11/23 06:32:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.4147	Prec@(1,5) (46.1%, 76.6%)
11/23 06:32:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.4231	Prec@(1,5) (46.3%, 76.6%)
11/23 06:32:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.4232	Prec@(1,5) (46.2%, 76.5%)
11/23 06:32:41午前 searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 46.2440%
11/23 06:32:41午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:32:42午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1760%
11/23 06:33:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5711 (0.5321)	Arch Loss -125.2225 (-124.9432)	Arch Hard Loss 1.6998 (1.9677)	Arch Beta Loss 1269.2230 (1269.1093)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.5%)	
11/23 06:34:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5245 (0.5325)	Arch Loss -124.5400 (-124.9133)	Arch Hard Loss 2.4053 (2.0090)	Arch Beta Loss 1269.4530 (1269.2233)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.3%)	
11/23 06:35:24午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5316 (0.5427)	Arch Loss -125.0614 (-124.9242)	Arch Hard Loss 1.9066 (2.0096)	Arch Beta Loss 1269.6801 (1269.3380)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.0%)	
11/23 06:36:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5165 (0.5480)	Arch Loss -124.8615 (-124.9316)	Arch Hard Loss 2.1267 (2.0124)	Arch Beta Loss 1269.8824 (1269.4400)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.1%)	
11/23 06:36:13午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 48/49] Final Prec@1 83.4280%
11/23 06:36:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.1653	Prec@(1,5) (50.9%, 80.3%)
11/23 06:36:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.1622	Prec@(1,5) (50.6%, 80.0%)
11/23 06:36:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.1499	Prec@(1,5) (50.8%, 79.9%)
11/23 06:36:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.1492	Prec@(1,5) (50.7%, 80.0%)
11/23 06:36:44午前 searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 50.6520%
11/23 06:36:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:36:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.6520%
11/23 06:37:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4224 (0.5122)	Arch Loss -124.9734 (-124.9719)	Arch Hard Loss 2.0355 (2.0266)	Arch Beta Loss 1270.0889 (1269.9847)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.5%)	
11/23 06:38:32午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4499 (0.5170)	Arch Loss -124.9372 (-124.9972)	Arch Hard Loss 2.0919 (2.0116)	Arch Beta Loss 1270.2908 (1270.0882)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/23 06:39:26午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.3832 (0.5263)	Arch Loss -124.8191 (-125.0017)	Arch Hard Loss 2.2291 (2.0170)	Arch Beta Loss 1270.4813 (1270.1867)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
11/23 06:40:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5752 (0.5368)	Arch Loss -125.6335 (-125.0074)	Arch Hard Loss 1.4310 (2.0200)	Arch Beta Loss 1270.6447 (1270.2739)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.1%)	
11/23 06:40:15午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 49/49] Final Prec@1 83.8760%
11/23 06:40:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.8937	Prec@(1,5) (40.3%, 69.9%)
11/23 06:40:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.8867	Prec@(1,5) (40.1%, 70.2%)
11/23 06:40:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.9057	Prec@(1,5) (39.8%, 69.9%)
11/23 06:40:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.8860	Prec@(1,5) (40.1%, 70.1%)
11/23 06:40:46午前 searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 40.0760%
11/23 06:40:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
11/23 06:40:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.6520%
11/23 06:40:46午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 50.6520%
11/23 06:40:46午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
