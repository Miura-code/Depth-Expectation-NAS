11/20 05:05:55AM parser.py:28 [INFO] 
11/20 05:05:55AM parser.py:29 [INFO] Parameters:
11/20 05:05:55AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s1-length-sw3-g5/DAG
11/20 05:05:55AM parser.py:31 [INFO] T=10.0
11/20 05:05:55AM parser.py:31 [INFO] ADVANCED=1
11/20 05:05:55AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/20 05:05:55AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/20 05:05:55AM parser.py:31 [INFO] ARCH_CRITERION=length
11/20 05:05:55AM parser.py:31 [INFO] BATCH_SIZE=64
11/20 05:05:55AM parser.py:31 [INFO] CASCADE=0
11/20 05:05:55AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/20 05:05:55AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/20 05:05:55AM parser.py:31 [INFO] DATA_PATH=../data/
11/20 05:05:55AM parser.py:31 [INFO] DATASET=cifar100
11/20 05:05:55AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/20 05:05:55AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/20 05:05:55AM parser.py:31 [INFO] DISCRETE=0
11/20 05:05:55AM parser.py:31 [INFO] EPOCHS=50
11/20 05:05:55AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/20 05:05:55AM parser.py:31 [INFO] EXP_NAME=s1-length-sw3-g5
11/20 05:05:55AM parser.py:31 [INFO] FINAL_L=0.0
11/20 05:05:55AM parser.py:31 [INFO] G=5.0
11/20 05:05:55AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/20 05:05:55AM parser.py:31 [INFO] GPUS=[0]
11/20 05:05:55AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/20 05:05:55AM parser.py:31 [INFO] INIT_CHANNELS=16
11/20 05:05:55AM parser.py:31 [INFO] L=0.0
11/20 05:05:55AM parser.py:31 [INFO] LAYERS=32
11/20 05:05:55AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/20 05:05:55AM parser.py:31 [INFO] NAME=Pruning
11/20 05:05:55AM parser.py:31 [INFO] NONKD=1
11/20 05:05:55AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s1-length-sw3-g5
11/20 05:05:55AM parser.py:31 [INFO] PCDARTS=0
11/20 05:05:55AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s1-length-sw3-g5/plots
11/20 05:05:55AM parser.py:31 [INFO] PRINT_FREQ=100
11/20 05:05:55AM parser.py:31 [INFO] RESET=0
11/20 05:05:55AM parser.py:31 [INFO] RESUME_PATH=None
11/20 05:05:55AM parser.py:31 [INFO] SAVE=s1-length-sw3-g5
11/20 05:05:55AM parser.py:31 [INFO] SEED=1
11/20 05:05:55AM parser.py:31 [INFO] SHARE_STAGE=0
11/20 05:05:55AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/20 05:05:55AM parser.py:31 [INFO] SPEC_CELL=1
11/20 05:05:55AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/20 05:05:55AM parser.py:31 [INFO] TEACHER_NAME=none
11/20 05:05:55AM parser.py:31 [INFO] TEACHER_PATH=none
11/20 05:05:55AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/20 05:05:55AM parser.py:31 [INFO] TYPE=Pruning
11/20 05:05:55AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/20 05:05:55AM parser.py:31 [INFO] W_LR=0.025
11/20 05:05:55AM parser.py:31 [INFO] W_LR_MIN=0.001
11/20 05:05:55AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/20 05:05:55AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/20 05:05:55AM parser.py:31 [INFO] WORKERS=4
11/20 05:05:55AM parser.py:32 [INFO] 
11/20 05:05:56AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/20 05:06:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.5526 (4.5185)	Arch Loss 4.6439 (4.6400)	Arch Hard Loss 4.5568 (4.5383)	Arch Beta Loss 0.0174 (0.0203)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 10.2%)	
11/20 05:07:47AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2400 (4.3909)	Arch Loss 4.2569 (4.4891)	Arch Hard Loss 4.1556 (4.3978)	Arch Beta Loss 0.0203 (0.0183)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.5%, 14.3%)	
11/20 05:08:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8921 (4.3007)	Arch Loss 4.1453 (4.3894)	Arch Hard Loss 4.0546 (4.3016)	Arch Beta Loss 0.0181 (0.0176)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.4%, 16.9%)	
11/20 05:09:31AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.0832 (4.2300)	Arch Loss 4.0834 (4.3139)	Arch Hard Loss 4.0061 (4.2278)	Arch Beta Loss 0.0154 (0.0172)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.0%, 19.1%)	
11/20 05:09:32AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  0/49] Final Prec@1 5.0520%
11/20 05:09:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9492	Prec@(1,5) (7.8%, 27.7%)
11/20 05:09:51AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9273	Prec@(1,5) (8.5%, 28.3%)
11/20 05:10:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9318	Prec@(1,5) (8.4%, 28.2%)
11/20 05:10:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9227	Prec@(1,5) (8.4%, 28.4%)
11/20 05:10:09AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 8.4160%
11/20 05:10:09AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/20 05:10:09AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.4160%
11/20 05:11:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8500 (3.8828)	Arch Loss 4.0821 (3.9748)	Arch Hard Loss 4.0135 (3.8943)	Arch Beta Loss 0.0137 (0.0161)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.5%, 29.7%)	
11/20 05:11:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.9175 (3.8585)	Arch Loss 3.9177 (3.9376)	Arch Hard Loss 3.8503 (3.8571)	Arch Beta Loss 0.0135 (0.0161)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.1%, 30.5%)	
11/20 05:12:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.6302 (3.8253)	Arch Loss 3.9427 (3.8927)	Arch Hard Loss 3.8726 (3.8123)	Arch Beta Loss 0.0140 (0.0161)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.5%, 31.5%)	
11/20 05:13:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.6767 (3.7965)	Arch Loss 3.8375 (3.8587)	Arch Hard Loss 3.7573 (3.7783)	Arch Beta Loss 0.0160 (0.0161)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.2%, 32.6%)	
11/20 05:13:44午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  1/49] Final Prec@1 10.2560%
11/20 05:13:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6847	Prec@(1,5) (11.7%, 36.9%)
11/20 05:14:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6761	Prec@(1,5) (11.8%, 36.8%)
11/20 05:14:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6652	Prec@(1,5) (12.3%, 36.9%)
11/20 05:14:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6574	Prec@(1,5) (12.5%, 37.0%)
11/20 05:14:20午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 12.4880%
11/20 05:14:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[5, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[6, 7])
11/20 05:14:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.4880%
11/20 05:15:16午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.5017 (3.5720)	Arch Loss 3.6063 (3.6743)	Arch Hard Loss 3.5326 (3.5945)	Arch Beta Loss 0.0147 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.7%, 39.4%)	
11/20 05:16:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5254 (3.5632)	Arch Loss 3.4690 (3.6319)	Arch Hard Loss 3.3964 (3.5522)	Arch Beta Loss 0.0145 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.8%, 39.6%)	
11/20 05:17:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.5185 (3.5220)	Arch Loss 3.6483 (3.6065)	Arch Hard Loss 3.5614 (3.5269)	Arch Beta Loss 0.0174 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.5%, 41.0%)	
11/20 05:17:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4625 (3.4976)	Arch Loss 3.2835 (3.5779)	Arch Hard Loss 3.1898 (3.4983)	Arch Beta Loss 0.0187 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 41.8%)	
11/20 05:17:55午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  2/49] Final Prec@1 14.8960%
11/20 05:18:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4346	Prec@(1,5) (16.1%, 43.7%)
11/20 05:18:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4417	Prec@(1,5) (16.3%, 43.4%)
11/20 05:18:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4365	Prec@(1,5) (16.6%, 43.6%)
11/20 05:18:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4380	Prec@(1,5) (16.5%, 43.6%)
11/20 05:18:31午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 16.5040%
11/20 05:18:31午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[5, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[6, 7])
11/20 05:18:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.5040%
11/20 05:19:27午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.3747 (3.3321)	Arch Loss 3.5683 (3.4510)	Arch Hard Loss 3.4939 (3.3713)	Arch Beta Loss 0.0149 (0.0159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (18.1%, 46.6%)	
11/20 05:20:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.4124 (3.3076)	Arch Loss 3.3120 (3.4254)	Arch Hard Loss 3.2305 (3.3456)	Arch Beta Loss 0.0163 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.6%, 47.3%)	
11/20 05:21:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.4353 (3.2861)	Arch Loss 3.2407 (3.3787)	Arch Hard Loss 3.1694 (3.2989)	Arch Beta Loss 0.0143 (0.0160)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (19.2%, 47.8%)	
11/20 05:22:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.0472 (3.2663)	Arch Loss 3.4710 (3.3581)	Arch Hard Loss 3.4060 (3.2783)	Arch Beta Loss 0.0130 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 48.4%)	
11/20 05:22:07午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  3/49] Final Prec@1 19.5040%
11/20 05:22:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2214	Prec@(1,5) (20.6%, 51.2%)
11/20 05:22:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2014	Prec@(1,5) (21.0%, 51.3%)
11/20 05:22:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2004	Prec@(1,5) (21.0%, 51.0%)
11/20 05:22:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1989	Prec@(1,5) (21.3%, 51.0%)
11/20 05:22:43午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 21.2520%
11/20 05:22:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[2, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[4, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[5, 9])
11/20 05:22:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.2520%
11/20 05:23:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.3023 (3.1146)	Arch Loss 3.0469 (3.2693)	Arch Hard Loss 2.9494 (3.1892)	Arch Beta Loss 0.0195 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.4%, 52.8%)	
11/20 05:24:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.9397 (3.0949)	Arch Loss 2.8472 (3.2423)	Arch Hard Loss 2.7617 (3.1623)	Arch Beta Loss 0.0171 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.2%, 53.3%)	
11/20 05:25:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.1360 (3.0924)	Arch Loss 3.1263 (3.2197)	Arch Hard Loss 3.0345 (3.1397)	Arch Beta Loss 0.0184 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 53.2%)	
11/20 05:26:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.9987 (3.0734)	Arch Loss 2.9746 (3.1987)	Arch Hard Loss 2.8953 (3.1190)	Arch Beta Loss 0.0159 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.5%, 53.5%)	
11/20 05:26:18午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  4/49] Final Prec@1 22.4680%
11/20 05:26:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0359	Prec@(1,5) (24.5%, 54.9%)
11/20 05:26:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0121	Prec@(1,5) (25.0%, 55.5%)
11/20 05:26:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0172	Prec@(1,5) (24.6%, 55.3%)
11/20 05:26:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0254	Prec@(1,5) (24.6%, 55.0%)
11/20 05:26:54午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 24.5720%
11/20 05:26:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[5, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[5, 9])
11/20 05:26:55午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.5720%
11/20 05:27:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.9840 (2.9135)	Arch Loss 3.1177 (3.0615)	Arch Hard Loss 3.0473 (2.9824)	Arch Beta Loss 0.0141 (0.0158)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 56.9%)	
11/20 05:28:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.5830 (2.9023)	Arch Loss 2.8496 (3.0487)	Arch Hard Loss 2.7795 (2.9697)	Arch Beta Loss 0.0140 (0.0158)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 57.4%)	
11/20 05:29:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.1972 (2.9014)	Arch Loss 2.7540 (3.0291)	Arch Hard Loss 2.6712 (2.9499)	Arch Beta Loss 0.0165 (0.0158)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 57.6%)	
11/20 05:30:29午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.5479 (2.8829)	Arch Loss 3.0146 (3.0159)	Arch Hard Loss 2.9315 (2.9366)	Arch Beta Loss 0.0166 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.4%, 58.2%)	
11/20 05:30:29午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  5/49] Final Prec@1 26.3720%
11/20 05:30:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8624	Prec@(1,5) (27.9%, 59.6%)
11/20 05:30:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8746	Prec@(1,5) (27.1%, 58.9%)
11/20 05:30:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8672	Prec@(1,5) (27.1%, 59.1%)
11/20 05:31:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8599	Prec@(1,5) (27.4%, 59.2%)
11/20 05:31:06午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 27.3600%
11/20 05:31:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[5, 6])
11/20 05:31:06午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.3600%
11/20 05:32:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.1009 (2.7222)	Arch Loss 3.2582 (2.9358)	Arch Hard Loss 3.1736 (2.8560)	Arch Beta Loss 0.0169 (0.0160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 62.0%)	
11/20 05:32:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.2816 (2.7323)	Arch Loss 2.7370 (2.9248)	Arch Hard Loss 2.6533 (2.8450)	Arch Beta Loss 0.0167 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 61.9%)	
11/20 05:33:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.6534 (2.7325)	Arch Loss 2.7424 (2.9008)	Arch Hard Loss 2.6702 (2.8211)	Arch Beta Loss 0.0144 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.6%, 62.0%)	
11/20 05:34:40午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8768 (2.7285)	Arch Loss 3.0528 (2.8901)	Arch Hard Loss 2.9686 (2.8104)	Arch Beta Loss 0.0168 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.6%, 62.1%)	
11/20 05:34:40午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  6/49] Final Prec@1 29.6320%
11/20 05:34:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7388	Prec@(1,5) (29.4%, 61.9%)
11/20 05:34:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7509	Prec@(1,5) (29.6%, 61.4%)
11/20 05:35:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7503	Prec@(1,5) (29.6%, 61.6%)
11/20 05:35:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7499	Prec@(1,5) (29.8%, 61.7%)
11/20 05:35:17午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 29.7720%
11/20 05:35:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[4, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 6])
11/20 05:35:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.7720%
11/20 05:36:13午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.3518 (2.5971)	Arch Loss 3.0852 (2.8011)	Arch Hard Loss 3.0028 (2.7214)	Arch Beta Loss 0.0165 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.6%, 65.4%)	
11/20 05:37:08午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.6983 (2.5894)	Arch Loss 2.7730 (2.7942)	Arch Hard Loss 2.6995 (2.7147)	Arch Beta Loss 0.0147 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 65.6%)	
11/20 05:38:02午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.8264 (2.5874)	Arch Loss 2.5876 (2.7740)	Arch Hard Loss 2.5142 (2.6945)	Arch Beta Loss 0.0147 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.1%, 65.5%)	
11/20 05:38:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.3506 (2.5799)	Arch Loss 2.6211 (2.7740)	Arch Hard Loss 2.5532 (2.6945)	Arch Beta Loss 0.0136 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.3%, 65.6%)	
11/20 05:38:52午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  7/49] Final Prec@1 32.2720%
11/20 05:39:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6340	Prec@(1,5) (32.1%, 63.9%)
11/20 05:39:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6287	Prec@(1,5) (32.5%, 64.3%)
11/20 05:39:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6375	Prec@(1,5) (32.1%, 64.1%)
11/20 05:39:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6415	Prec@(1,5) (32.1%, 64.2%)
11/20 05:39:28午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 32.0680%
11/20 05:39:28午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[5, 9])
11/20 05:39:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.0680%
11/20 05:40:24午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.2529 (2.4356)	Arch Loss 2.9527 (2.7346)	Arch Hard Loss 2.8653 (2.6552)	Arch Beta Loss 0.0175 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.9%, 68.8%)	
11/20 05:41:19午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.3870 (2.4697)	Arch Loss 2.6812 (2.7072)	Arch Hard Loss 2.5902 (2.6278)	Arch Beta Loss 0.0182 (0.0159)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.0%, 68.1%)	
11/20 05:42:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2967 (2.4672)	Arch Loss 2.5502 (2.6777)	Arch Hard Loss 2.4619 (2.5985)	Arch Beta Loss 0.0177 (0.0158)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 68.1%)	
11/20 05:43:03午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.7418 (2.4672)	Arch Loss 2.5771 (2.6701)	Arch Hard Loss 2.4980 (2.5911)	Arch Beta Loss 0.0158 (0.0158)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 68.3%)	
11/20 05:43:03午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  8/49] Final Prec@1 35.0960%
11/20 05:43:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5470	Prec@(1,5) (34.8%, 66.3%)
11/20 05:43:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5360	Prec@(1,5) (35.0%, 66.6%)
11/20 05:43:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5704	Prec@(1,5) (34.0%, 66.2%)
11/20 05:43:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5782	Prec@(1,5) (33.9%, 65.9%)
11/20 05:43:40午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 33.9240%
11/20 05:43:40午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[5, 7], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
11/20 05:43:40午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.9240%
11/20 05:44:35午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.7194 (2.3269)	Arch Loss 2.6609 (2.6036)	Arch Hard Loss 2.5922 (2.5257)	Arch Beta Loss 0.0137 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 71.5%)	
11/20 05:45:30午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.2147 (2.3516)	Arch Loss 2.5426 (2.5946)	Arch Hard Loss 2.4668 (2.5168)	Arch Beta Loss 0.0152 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 70.8%)	
11/20 05:46:25午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.1134 (2.3490)	Arch Loss 2.2117 (2.6038)	Arch Hard Loss 2.1397 (2.5261)	Arch Beta Loss 0.0144 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.6%)	
11/20 05:47:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.2892 (2.3453)	Arch Loss 2.5351 (2.5820)	Arch Hard Loss 2.4620 (2.5046)	Arch Beta Loss 0.0146 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.8%)	
11/20 05:47:14午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  9/49] Final Prec@1 37.4560%
11/20 05:47:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.3772	Prec@(1,5) (38.2%, 69.4%)
11/20 05:47:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3909	Prec@(1,5) (37.5%, 69.2%)
11/20 05:47:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4010	Prec@(1,5) (37.2%, 69.1%)
11/20 05:47:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4008	Prec@(1,5) (37.3%, 69.1%)
11/20 05:47:51午前 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 37.3600%
11/20 05:47:51午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[5, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=[2, 8])
11/20 05:47:51午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.3600%
11/20 05:48:47午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 1.9647 (2.2180)	Arch Loss 2.5279 (2.5297)	Arch Hard Loss 2.4493 (2.4532)	Arch Beta Loss 0.0157 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.5%)	
11/20 05:49:41午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.3637 (2.2271)	Arch Loss 2.4519 (2.5249)	Arch Hard Loss 2.3776 (2.4483)	Arch Beta Loss 0.0148 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.3%, 73.2%)	
11/20 05:50:36午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.4646 (2.2458)	Arch Loss 2.4708 (2.5175)	Arch Hard Loss 2.3873 (2.4409)	Arch Beta Loss 0.0167 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 72.9%)	
11/20 05:51:25午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1186 (2.2479)	Arch Loss 2.3788 (2.4996)	Arch Hard Loss 2.2907 (2.4230)	Arch Beta Loss 0.0176 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 73.0%)	
11/20 05:51:26午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 10/49] Final Prec@1 39.7080%
11/20 05:51:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3585	Prec@(1,5) (36.9%, 70.8%)
11/20 05:51:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3598	Prec@(1,5) (37.1%, 70.7%)
11/20 05:51:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3693	Prec@(1,5) (37.1%, 70.4%)
11/20 05:52:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3780	Prec@(1,5) (36.9%, 70.5%)
11/20 05:52:02午前 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 36.8840%
11/20 05:52:02午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/20 05:52:02午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.3600%
11/20 05:52:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.1656 (2.1402)	Arch Loss 2.6161 (2.4789)	Arch Hard Loss 2.5466 (2.4023)	Arch Beta Loss 0.0139 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.5%, 75.0%)	
11/20 05:53:53午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.0305 (2.1479)	Arch Loss 2.5720 (2.4312)	Arch Hard Loss 2.4994 (2.3548)	Arch Beta Loss 0.0145 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.2%, 75.0%)	
11/20 05:54:47午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.1364 (2.1515)	Arch Loss 2.3560 (2.4379)	Arch Hard Loss 2.2805 (2.3617)	Arch Beta Loss 0.0151 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 74.9%)	
11/20 05:55:37午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.5350 (2.1586)	Arch Loss 2.3523 (2.4386)	Arch Hard Loss 2.2736 (2.3624)	Arch Beta Loss 0.0157 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 74.9%)	
11/20 05:55:37午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 11/49] Final Prec@1 41.8640%
11/20 05:55:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3402	Prec@(1,5) (38.4%, 71.7%)
11/20 05:55:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3444	Prec@(1,5) (38.4%, 71.6%)
11/20 05:56:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3422	Prec@(1,5) (38.4%, 71.4%)
11/20 05:56:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3470	Prec@(1,5) (38.3%, 71.2%)
11/20 05:56:13午前 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 38.3080%
11/20 05:56:13午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 11])
11/20 05:56:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.3080%
11/20 05:57:09午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.2726 (2.0216)	Arch Loss 2.2024 (2.4227)	Arch Hard Loss 2.1138 (2.3467)	Arch Beta Loss 0.0177 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.5%)	
11/20 05:58:04午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.1825 (2.0411)	Arch Loss 2.3345 (2.3986)	Arch Hard Loss 2.2538 (2.3226)	Arch Beta Loss 0.0161 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.3%, 77.0%)	
11/20 05:58:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.8969 (2.0603)	Arch Loss 2.5425 (2.3756)	Arch Hard Loss 2.4672 (2.2996)	Arch Beta Loss 0.0151 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 76.6%)	
11/20 05:59:47午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.8867 (2.0721)	Arch Loss 2.3421 (2.3741)	Arch Hard Loss 2.2682 (2.2980)	Arch Beta Loss 0.0148 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 76.3%)	
11/20 05:59:48午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 12/49] Final Prec@1 43.2280%
11/20 05:59:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3191	Prec@(1,5) (39.9%, 71.8%)
11/20 06:00:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2981	Prec@(1,5) (40.2%, 71.9%)
11/20 06:00:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2861	Prec@(1,5) (40.5%, 72.3%)
11/20 06:00:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2909	Prec@(1,5) (40.3%, 72.0%)
11/20 06:00:24午前 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 40.2640%
11/20 06:00:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[6, 7])
11/20 06:00:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.2640%
11/20 06:01:20午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.8698 (1.9415)	Arch Loss 2.2579 (2.3292)	Arch Hard Loss 2.1833 (2.2530)	Arch Beta Loss 0.0149 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.7%)	
11/20 06:02:15午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.1695 (1.9680)	Arch Loss 2.9223 (2.3540)	Arch Hard Loss 2.8543 (2.2780)	Arch Beta Loss 0.0136 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.4%)	
11/20 06:03:09午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.9849 (1.9848)	Arch Loss 2.6415 (2.3487)	Arch Hard Loss 2.5688 (2.2727)	Arch Beta Loss 0.0145 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.3%, 78.1%)	
11/20 06:03:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0618 (1.9924)	Arch Loss 2.1018 (2.3349)	Arch Hard Loss 2.0267 (2.2590)	Arch Beta Loss 0.0150 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 78.0%)	
11/20 06:03:59午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 13/49] Final Prec@1 45.2480%
11/20 06:04:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2402	Prec@(1,5) (40.5%, 73.6%)
11/20 06:04:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2345	Prec@(1,5) (40.7%, 73.4%)
11/20 06:04:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2236	Prec@(1,5) (41.1%, 73.4%)
11/20 06:04:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2204	Prec@(1,5) (41.2%, 73.4%)
11/20 06:04:35午前 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 41.1800%
11/20 06:04:35午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[5, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[6, 7])
11/20 06:04:36午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.1800%
11/20 06:05:31午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.1300 (1.8855)	Arch Loss 2.3490 (2.3150)	Arch Hard Loss 2.2739 (2.2395)	Arch Beta Loss 0.0150 (0.0151)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 80.2%)	
11/20 06:06:26午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.5480 (1.9030)	Arch Loss 2.2593 (2.2994)	Arch Hard Loss 2.1769 (2.2237)	Arch Beta Loss 0.0165 (0.0151)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.9%)	
11/20 06:07:21午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.0530 (1.9149)	Arch Loss 2.1868 (2.2771)	Arch Hard Loss 2.1077 (2.2013)	Arch Beta Loss 0.0158 (0.0151)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.7%)	
11/20 06:08:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.8426 (1.9259)	Arch Loss 2.7452 (2.2759)	Arch Hard Loss 2.6594 (2.2001)	Arch Beta Loss 0.0172 (0.0152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 79.4%)	
11/20 06:08:11午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 14/49] Final Prec@1 46.8520%
11/20 06:08:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1425	Prec@(1,5) (43.5%, 74.4%)
11/20 06:08:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1460	Prec@(1,5) (43.4%, 74.4%)
11/20 06:08:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1339	Prec@(1,5) (43.5%, 74.7%)
11/20 06:08:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1368	Prec@(1,5) (43.4%, 74.7%)
11/20 06:08:47午前 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 43.3920%
11/20 06:08:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[6, 7])
11/20 06:08:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3920%
11/20 06:09:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.7591 (1.8143)	Arch Loss 2.4843 (2.2623)	Arch Hard Loss 2.4052 (2.1858)	Arch Beta Loss 0.0158 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 81.3%)	
11/20 06:10:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.1917 (1.8458)	Arch Loss 2.0077 (2.2680)	Arch Hard Loss 1.9332 (2.1913)	Arch Beta Loss 0.0149 (0.0153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.3%, 80.8%)	
11/20 06:11:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0501 (1.8628)	Arch Loss 2.2372 (2.2516)	Arch Hard Loss 2.1635 (2.1748)	Arch Beta Loss 0.0147 (0.0154)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 80.4%)	
11/20 06:12:21午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.8093 (1.8639)	Arch Loss 1.7576 (2.2472)	Arch Hard Loss 1.6924 (2.1703)	Arch Beta Loss 0.0130 (0.0154)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 80.4%)	
11/20 06:12:22午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 15/49] Final Prec@1 48.0880%
11/20 06:12:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1624	Prec@(1,5) (43.1%, 74.8%)
11/20 06:12:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1601	Prec@(1,5) (42.9%, 75.0%)
11/20 06:12:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1560	Prec@(1,5) (43.1%, 75.0%)
11/20 06:12:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1608	Prec@(1,5) (43.0%, 74.9%)
11/20 06:12:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 42.9960%
11/20 06:12:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[6, 7])
11/20 06:12:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3920%
11/20 06:13:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7564 (1.7976)	Arch Loss 2.1544 (2.2058)	Arch Hard Loss 2.0587 (2.1285)	Arch Beta Loss 0.0191 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 82.0%)	
11/20 06:14:48午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.7985 (1.7832)	Arch Loss 2.4668 (2.1975)	Arch Hard Loss 2.3799 (2.1199)	Arch Beta Loss 0.0174 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.5%, 82.2%)	
11/20 06:15:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.7525 (1.7935)	Arch Loss 2.6498 (2.2025)	Arch Hard Loss 2.5570 (2.1247)	Arch Beta Loss 0.0186 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.9%, 82.2%)	
11/20 06:16:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.0595 (1.7963)	Arch Loss 2.4648 (2.2010)	Arch Hard Loss 2.3876 (2.1230)	Arch Beta Loss 0.0154 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 82.0%)	
11/20 06:16:33午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 16/49] Final Prec@1 50.1840%
11/20 06:16:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0805	Prec@(1,5) (44.6%, 75.8%)
11/20 06:16:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0670	Prec@(1,5) (44.8%, 76.2%)
11/20 06:17:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0750	Prec@(1,5) (44.6%, 76.1%)
11/20 06:17:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0761	Prec@(1,5) (44.6%, 76.2%)
11/20 06:17:09午前 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 44.6160%
11/20 06:17:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[6, 7])
11/20 06:17:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.6160%
11/20 06:18:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.4081 (1.6662)	Arch Loss 2.5278 (2.1736)	Arch Hard Loss 2.4643 (2.0955)	Arch Beta Loss 0.0127 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.7%)	
11/20 06:19:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.8106 (1.6875)	Arch Loss 2.2789 (2.1864)	Arch Hard Loss 2.2086 (2.1084)	Arch Beta Loss 0.0141 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.0%, 83.4%)	
11/20 06:19:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.9458 (1.7057)	Arch Loss 1.9354 (2.1766)	Arch Hard Loss 1.8731 (2.0988)	Arch Beta Loss 0.0125 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 83.0%)	
11/20 06:20:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.8172 (1.7272)	Arch Loss 2.2712 (2.1741)	Arch Hard Loss 2.1969 (2.0962)	Arch Beta Loss 0.0149 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.8%)	
11/20 06:20:44午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 17/49] Final Prec@1 51.3040%
11/20 06:20:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0546	Prec@(1,5) (45.4%, 77.2%)
11/20 06:21:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0585	Prec@(1,5) (45.0%, 76.9%)
11/20 06:21:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0560	Prec@(1,5) (44.8%, 76.8%)
11/20 06:21:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0562	Prec@(1,5) (44.9%, 76.8%)
11/20 06:21:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 44.9080%
11/20 06:21:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:21:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.9080%
11/20 06:22:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4106 (1.6266)	Arch Loss 2.2970 (2.2075)	Arch Hard Loss 2.2138 (2.1298)	Arch Beta Loss 0.0166 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.5%, 85.0%)	
11/20 06:23:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.5296 (1.6522)	Arch Loss 2.2802 (2.1682)	Arch Hard Loss 2.2041 (2.0906)	Arch Beta Loss 0.0152 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 84.3%)	
11/20 06:24:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.4405 (1.6536)	Arch Loss 2.5656 (2.1563)	Arch Hard Loss 2.4890 (2.0787)	Arch Beta Loss 0.0153 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 84.1%)	
11/20 06:24:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.5105 (1.6706)	Arch Loss 2.2869 (2.1412)	Arch Hard Loss 2.1955 (2.0636)	Arch Beta Loss 0.0183 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.8%)	
11/20 06:24:55午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 18/49] Final Prec@1 52.8160%
11/20 06:25:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0218	Prec@(1,5) (46.2%, 77.6%)
11/20 06:25:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0078	Prec@(1,5) (46.0%, 77.9%)
11/20 06:25:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0039	Prec@(1,5) (46.4%, 77.9%)
11/20 06:25:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0064	Prec@(1,5) (46.3%, 77.7%)
11/20 06:25:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 46.2800%
11/20 06:25:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:25:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2800%
11/20 06:26:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.6705 (1.5914)	Arch Loss 2.1871 (2.0696)	Arch Hard Loss 2.1095 (1.9922)	Arch Beta Loss 0.0155 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.2%, 85.6%)	
11/20 06:27:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.5912 (1.5923)	Arch Loss 2.0853 (2.1088)	Arch Hard Loss 2.0048 (2.0312)	Arch Beta Loss 0.0161 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 85.4%)	
11/20 06:28:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.8363 (1.6070)	Arch Loss 2.4380 (2.1125)	Arch Hard Loss 2.3595 (2.0349)	Arch Beta Loss 0.0157 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.3%, 85.0%)	
11/20 06:29:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.2305 (1.6219)	Arch Loss 2.5286 (2.1137)	Arch Hard Loss 2.4616 (2.0361)	Arch Beta Loss 0.0134 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.8%)	
11/20 06:29:07午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 19/49] Final Prec@1 53.8480%
11/20 06:29:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0541	Prec@(1,5) (45.2%, 77.6%)
11/20 06:29:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0487	Prec@(1,5) (45.8%, 77.3%)
11/20 06:29:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0507	Prec@(1,5) (45.8%, 77.1%)
11/20 06:29:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0480	Prec@(1,5) (45.9%, 77.1%)
11/20 06:29:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 45.8520%
11/20 06:29:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:29:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2800%
11/20 06:30:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6112 (1.5377)	Arch Loss 2.0354 (2.1036)	Arch Hard Loss 1.9517 (2.0259)	Arch Beta Loss 0.0167 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 86.2%)	
11/20 06:31:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.4296 (1.5532)	Arch Loss 2.4079 (2.1004)	Arch Hard Loss 2.3174 (2.0229)	Arch Beta Loss 0.0181 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.7%)	
11/20 06:32:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.4741 (1.5579)	Arch Loss 2.5407 (2.0813)	Arch Hard Loss 2.4578 (2.0037)	Arch Beta Loss 0.0166 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.6%)	
11/20 06:33:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.5186 (1.5695)	Arch Loss 1.8202 (2.0838)	Arch Hard Loss 1.7417 (2.0061)	Arch Beta Loss 0.0157 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.3%, 85.6%)	
11/20 06:33:18午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 20/49] Final Prec@1 55.3160%
11/20 06:33:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0080	Prec@(1,5) (46.0%, 77.8%)
11/20 06:33:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0061	Prec@(1,5) (46.4%, 77.7%)
11/20 06:33:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0073	Prec@(1,5) (46.4%, 77.7%)
11/20 06:33:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0065	Prec@(1,5) (46.5%, 77.6%)
11/20 06:33:54午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 46.5440%
11/20 06:33:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:33:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.5440%
11/20 06:34:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.1493 (1.4658)	Arch Loss 2.2715 (2.1002)	Arch Hard Loss 2.2033 (2.0225)	Arch Beta Loss 0.0136 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 87.3%)	
11/20 06:35:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.1959 (1.5040)	Arch Loss 1.9048 (2.1155)	Arch Hard Loss 1.8408 (2.0380)	Arch Beta Loss 0.0128 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.5%)	
11/20 06:36:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.5726 (1.5134)	Arch Loss 2.1209 (2.0818)	Arch Hard Loss 2.0519 (2.0043)	Arch Beta Loss 0.0138 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.4%)	
11/20 06:37:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.4025 (1.5161)	Arch Loss 1.6611 (2.0811)	Arch Hard Loss 1.5837 (2.0034)	Arch Beta Loss 0.0155 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.4%, 86.3%)	
11/20 06:37:28午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 21/49] Final Prec@1 56.4640%
11/20 06:37:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9671	Prec@(1,5) (48.0%, 78.7%)
11/20 06:37:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9567	Prec@(1,5) (48.4%, 78.7%)
11/20 06:37:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9650	Prec@(1,5) (48.0%, 78.5%)
11/20 06:38:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9659	Prec@(1,5) (47.8%, 78.5%)
11/20 06:38:05午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 47.7760%
11/20 06:38:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:38:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.7760%
11/20 06:39:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3405 (1.3898)	Arch Loss 2.0524 (2.0691)	Arch Hard Loss 1.9710 (1.9911)	Arch Beta Loss 0.0163 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.6%)	
11/20 06:39:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4857 (1.4321)	Arch Loss 2.1260 (2.0612)	Arch Hard Loss 2.0401 (1.9830)	Arch Beta Loss 0.0172 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.8%)	
11/20 06:40:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3179 (1.4521)	Arch Loss 2.3475 (2.0612)	Arch Hard Loss 2.2604 (1.9827)	Arch Beta Loss 0.0174 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.4%)	
11/20 06:41:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.5509 (1.4672)	Arch Loss 1.6336 (2.0558)	Arch Hard Loss 1.5469 (1.9772)	Arch Beta Loss 0.0173 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.2%, 87.2%)	
11/20 06:41:39午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 22/49] Final Prec@1 58.1520%
11/20 06:41:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9678	Prec@(1,5) (48.5%, 78.0%)
11/20 06:41:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9324	Prec@(1,5) (49.2%, 78.7%)
11/20 06:42:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9389	Prec@(1,5) (48.8%, 78.5%)
11/20 06:42:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9519	Prec@(1,5) (48.4%, 78.4%)
11/20 06:42:16午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 48.4200%
11/20 06:42:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:42:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4200%
11/20 06:43:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4735 (1.3603)	Arch Loss 1.7900 (2.0332)	Arch Hard Loss 1.7095 (1.9539)	Arch Beta Loss 0.0161 (0.0159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.6%)	
11/20 06:44:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3924 (1.3892)	Arch Loss 1.9269 (2.0295)	Arch Hard Loss 1.8501 (1.9503)	Arch Beta Loss 0.0154 (0.0159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.4%)	
11/20 06:45:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.2070 (1.4119)	Arch Loss 2.1074 (2.0365)	Arch Hard Loss 2.0269 (1.9572)	Arch Beta Loss 0.0161 (0.0159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 88.0%)	
11/20 06:45:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4362 (1.4222)	Arch Loss 1.9184 (2.0293)	Arch Hard Loss 1.8476 (1.9501)	Arch Beta Loss 0.0142 (0.0159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.9%)	
11/20 06:45:51午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 23/49] Final Prec@1 59.0400%
11/20 06:46:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9180	Prec@(1,5) (48.9%, 79.7%)
11/20 06:46:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9146	Prec@(1,5) (49.1%, 79.5%)
11/20 06:46:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9152	Prec@(1,5) (49.2%, 79.4%)
11/20 06:46:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9157	Prec@(1,5) (49.2%, 79.4%)
11/20 06:46:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 49.1760%
11/20 06:46:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:46:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1760%
11/20 06:47:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.2561 (1.3198)	Arch Loss 1.5728 (2.0112)	Arch Hard Loss 1.4837 (1.9321)	Arch Beta Loss 0.0178 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.5%)	
11/20 06:48:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3052 (1.3304)	Arch Loss 2.0936 (2.0074)	Arch Hard Loss 2.0100 (1.9284)	Arch Beta Loss 0.0167 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.3%)	
11/20 06:49:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.2674 (1.3619)	Arch Loss 2.7422 (2.0124)	Arch Hard Loss 2.6669 (1.9335)	Arch Beta Loss 0.0151 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.8%)	
11/20 06:50:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.4379 (1.3755)	Arch Loss 2.1821 (2.0154)	Arch Hard Loss 2.1022 (1.9365)	Arch Beta Loss 0.0160 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.6%)	
11/20 06:50:01午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 24/49] Final Prec@1 60.1040%
11/20 06:50:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8678	Prec@(1,5) (50.0%, 80.1%)
11/20 06:50:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8665	Prec@(1,5) (50.1%, 80.2%)
11/20 06:50:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8696	Prec@(1,5) (49.9%, 80.2%)
11/20 06:50:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8807	Prec@(1,5) (49.7%, 80.1%)
11/20 06:50:38午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 49.6920%
11/20 06:50:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:50:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6920%
11/20 06:51:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.0248 (1.2260)	Arch Loss 1.8274 (1.9586)	Arch Hard Loss 1.7569 (1.8800)	Arch Beta Loss 0.0141 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.7%)	
11/20 06:52:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.6198 (1.2807)	Arch Loss 1.8670 (1.9722)	Arch Hard Loss 1.7949 (1.8938)	Arch Beta Loss 0.0144 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 90.1%)	
11/20 06:53:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.4540 (1.3037)	Arch Loss 2.1471 (1.9880)	Arch Hard Loss 2.0766 (1.9096)	Arch Beta Loss 0.0141 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.5%)	
11/20 06:54:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.5609 (1.3156)	Arch Loss 2.2016 (1.9961)	Arch Hard Loss 2.1315 (1.9177)	Arch Beta Loss 0.0140 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.4%)	
11/20 06:54:12午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 25/49] Final Prec@1 61.7480%
11/20 06:54:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9172	Prec@(1,5) (49.0%, 79.7%)
11/20 06:54:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9067	Prec@(1,5) (49.4%, 80.0%)
11/20 06:54:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9021	Prec@(1,5) (49.6%, 79.9%)
11/20 06:54:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9043	Prec@(1,5) (49.6%, 79.9%)
11/20 06:54:49午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 49.6160%
11/20 06:54:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:54:49午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6920%
11/20 06:55:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.0911 (1.2201)	Arch Loss 2.2821 (1.9811)	Arch Hard Loss 2.2006 (1.9032)	Arch Beta Loss 0.0163 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 91.0%)	
11/20 06:56:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.0541 (1.2444)	Arch Loss 2.2412 (1.9860)	Arch Hard Loss 2.1494 (1.9080)	Arch Beta Loss 0.0184 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.8%)	
11/20 06:57:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.4069 (1.2600)	Arch Loss 2.6863 (1.9823)	Arch Hard Loss 2.6009 (1.9040)	Arch Beta Loss 0.0171 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.5%)	
11/20 06:58:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.3060 (1.2782)	Arch Loss 1.7017 (1.9922)	Arch Hard Loss 1.6097 (1.9138)	Arch Beta Loss 0.0184 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.8%, 90.3%)	
11/20 06:58:23午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 26/49] Final Prec@1 62.8440%
11/20 06:58:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8444	Prec@(1,5) (51.3%, 81.0%)
11/20 06:58:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8639	Prec@(1,5) (50.8%, 80.6%)
11/20 06:58:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8589	Prec@(1,5) (50.5%, 80.5%)
11/20 06:58:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8603	Prec@(1,5) (50.8%, 80.6%)
11/20 06:58:59午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 50.7800%
11/20 06:58:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 06:59:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7800%
11/20 06:59:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.4430 (1.1792)	Arch Loss 1.7136 (1.9843)	Arch Hard Loss 1.6397 (1.9049)	Arch Beta Loss 0.0148 (0.0159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.5%)	
11/20 07:00:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.1364 (1.2127)	Arch Loss 2.2633 (1.9983)	Arch Hard Loss 2.1922 (1.9191)	Arch Beta Loss 0.0142 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.9%)	
11/20 07:01:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.3319 (1.2218)	Arch Loss 2.0195 (1.9757)	Arch Hard Loss 1.9517 (1.8966)	Arch Beta Loss 0.0136 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.8%)	
11/20 07:02:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.3236 (1.2284)	Arch Loss 1.7617 (1.9804)	Arch Hard Loss 1.6934 (1.9011)	Arch Beta Loss 0.0137 (0.0158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.7%)	
11/20 07:02:34午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 27/49] Final Prec@1 63.9120%
11/20 07:02:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8883	Prec@(1,5) (50.1%, 79.8%)
11/20 07:02:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8878	Prec@(1,5) (50.2%, 80.1%)
11/20 07:03:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8943	Prec@(1,5) (50.2%, 80.1%)
11/20 07:03:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8975	Prec@(1,5) (50.1%, 80.0%)
11/20 07:03:10午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 50.0920%
11/20 07:03:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:03:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7800%
11/20 07:04:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.0633 (1.1352)	Arch Loss 2.2732 (1.9655)	Arch Hard Loss 2.1811 (1.8874)	Arch Beta Loss 0.0184 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.4%)	
11/20 07:05:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1339 (1.1528)	Arch Loss 1.7072 (1.9656)	Arch Hard Loss 1.6233 (1.8874)	Arch Beta Loss 0.0168 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.2%)	
11/20 07:05:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.9045 (1.1613)	Arch Loss 2.1038 (1.9660)	Arch Hard Loss 2.0121 (1.8878)	Arch Beta Loss 0.0183 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.3%)	
11/20 07:06:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.4405 (1.1743)	Arch Loss 1.6128 (1.9652)	Arch Hard Loss 1.5298 (1.8869)	Arch Beta Loss 0.0166 (0.0157)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.2%)	
11/20 07:06:45午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 28/49] Final Prec@1 65.4520%
11/20 07:06:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8469	Prec@(1,5) (51.0%, 80.6%)
11/20 07:07:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8487	Prec@(1,5) (51.2%, 80.8%)
11/20 07:07:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8513	Prec@(1,5) (51.0%, 80.8%)
11/20 07:07:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8551	Prec@(1,5) (50.9%, 80.9%)
11/20 07:07:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 50.9400%
11/20 07:07:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:07:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.9400%
11/20 07:08:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.2871 (1.0819)	Arch Loss 1.2983 (1.9508)	Arch Hard Loss 1.2330 (1.8726)	Arch Beta Loss 0.0131 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.7%)	
11/20 07:09:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.1956 (1.1100)	Arch Loss 1.9649 (1.9640)	Arch Hard Loss 1.9000 (1.8861)	Arch Beta Loss 0.0130 (0.0156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 92.4%)	
11/20 07:10:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.4307 (1.1211)	Arch Loss 2.0768 (1.9696)	Arch Hard Loss 2.0115 (1.8920)	Arch Beta Loss 0.0131 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 92.1%)	
11/20 07:10:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9837 (1.1289)	Arch Loss 2.4973 (1.9623)	Arch Hard Loss 2.4243 (1.8848)	Arch Beta Loss 0.0146 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.1%)	
11/20 07:10:56午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 29/49] Final Prec@1 66.6760%
11/20 07:11:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8094	Prec@(1,5) (52.2%, 81.5%)
11/20 07:11:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8333	Prec@(1,5) (51.6%, 81.2%)
11/20 07:11:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8238	Prec@(1,5) (51.6%, 81.2%)
11/20 07:11:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8262	Prec@(1,5) (51.6%, 81.2%)
11/20 07:11:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 51.6400%
11/20 07:11:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:11:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.6400%
11/20 07:12:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.2707 (1.0278)	Arch Loss 2.5247 (1.9307)	Arch Hard Loss 2.4373 (1.8533)	Arch Beta Loss 0.0175 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.7%)	
11/20 07:13:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.2928 (1.0571)	Arch Loss 1.5342 (1.9521)	Arch Hard Loss 1.4445 (1.8749)	Arch Beta Loss 0.0179 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.1%)	
11/20 07:14:18午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.0873 (1.0785)	Arch Loss 1.7694 (1.9536)	Arch Hard Loss 1.6877 (1.8766)	Arch Beta Loss 0.0163 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.7%)	
11/20 07:15:07午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2111 (1.0904)	Arch Loss 2.2026 (1.9512)	Arch Hard Loss 2.1159 (1.8744)	Arch Beta Loss 0.0173 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.6%)	
11/20 07:15:07午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 30/49] Final Prec@1 67.8320%
11/20 07:15:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8833	Prec@(1,5) (50.5%, 80.9%)
11/20 07:15:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8668	Prec@(1,5) (50.7%, 81.0%)
11/20 07:15:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8605	Prec@(1,5) (51.0%, 80.9%)
11/20 07:15:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8572	Prec@(1,5) (51.1%, 81.0%)
11/20 07:15:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 51.0760%
11/20 07:15:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 10], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:15:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.6400%
11/20 07:16:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8787 (1.0212)	Arch Loss 1.9920 (1.9347)	Arch Hard Loss 1.9186 (1.8590)	Arch Beta Loss 0.0147 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.5%)	
11/20 07:17:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9884 (1.0097)	Arch Loss 1.5949 (1.9134)	Arch Hard Loss 1.5260 (1.8378)	Arch Beta Loss 0.0138 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.7%)	
11/20 07:18:29午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0278 (1.0313)	Arch Loss 2.0774 (1.9129)	Arch Hard Loss 2.0015 (1.8375)	Arch Beta Loss 0.0152 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
11/20 07:19:18午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3797 (1.0476)	Arch Loss 1.4803 (1.9283)	Arch Hard Loss 1.4145 (1.8530)	Arch Beta Loss 0.0132 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.1%)	
11/20 07:19:18午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 31/49] Final Prec@1 69.2520%
11/20 07:19:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8381	Prec@(1,5) (51.6%, 81.8%)
11/20 07:19:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8362	Prec@(1,5) (51.6%, 81.6%)
11/20 07:19:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8275	Prec@(1,5) (52.0%, 81.4%)
11/20 07:19:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8197	Prec@(1,5) (52.1%, 81.5%)
11/20 07:19:55午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 52.0840%
11/20 07:19:55午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:19:55午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.0840%
11/20 07:20:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8363 (0.9660)	Arch Loss 2.1394 (1.9236)	Arch Hard Loss 2.0579 (1.8489)	Arch Beta Loss 0.0163 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.7%)	
11/20 07:21:45午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9636 (0.9686)	Arch Loss 2.3304 (1.9182)	Arch Hard Loss 2.2551 (1.8436)	Arch Beta Loss 0.0151 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.0%)	
11/20 07:22:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.9364 (0.9835)	Arch Loss 1.9374 (1.9322)	Arch Hard Loss 1.8561 (1.8577)	Arch Beta Loss 0.0163 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.9%)	
11/20 07:23:29午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.0555 (0.9982)	Arch Loss 1.7876 (1.9316)	Arch Hard Loss 1.7012 (1.8571)	Arch Beta Loss 0.0173 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.6%)	
11/20 07:23:29午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 32/49] Final Prec@1 70.3640%
11/20 07:23:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8337	Prec@(1,5) (50.8%, 81.7%)
11/20 07:23:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8344	Prec@(1,5) (51.6%, 81.2%)
11/20 07:23:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8127	Prec@(1,5) (52.1%, 81.5%)
11/20 07:24:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8141	Prec@(1,5) (52.3%, 81.5%)
11/20 07:24:05午前 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 52.3440%
11/20 07:24:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:24:06午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.3440%
11/20 07:25:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7930 (0.9552)	Arch Loss 1.6252 (1.9400)	Arch Hard Loss 1.5584 (1.8654)	Arch Beta Loss 0.0134 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.2%)	
11/20 07:25:56午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.2211 (0.9490)	Arch Loss 2.0483 (1.9245)	Arch Hard Loss 1.9808 (1.8500)	Arch Beta Loss 0.0135 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.2%)	
11/20 07:26:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2189 (0.9529)	Arch Loss 1.9862 (1.9292)	Arch Hard Loss 1.9261 (1.8546)	Arch Beta Loss 0.0120 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.3%)	
11/20 07:27:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.8973 (0.9637)	Arch Loss 2.2644 (1.9274)	Arch Hard Loss 2.1937 (1.8527)	Arch Beta Loss 0.0141 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.1%)	
11/20 07:27:40午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 33/49] Final Prec@1 71.5320%
11/20 07:27:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8210	Prec@(1,5) (51.8%, 81.3%)
11/20 07:27:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8260	Prec@(1,5) (51.9%, 81.2%)
11/20 07:28:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8149	Prec@(1,5) (52.1%, 81.6%)
11/20 07:28:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8209	Prec@(1,5) (52.3%, 81.4%)
11/20 07:28:16午前 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 52.2840%
11/20 07:28:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[5, 6], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:28:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.3440%
11/20 07:29:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.9964 (0.8716)	Arch Loss 2.0521 (1.9042)	Arch Hard Loss 1.9658 (1.8290)	Arch Beta Loss 0.0173 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.5%)	
11/20 07:30:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.0209 (0.8888)	Arch Loss 1.8625 (1.9262)	Arch Hard Loss 1.7833 (1.8513)	Arch Beta Loss 0.0159 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.8%, 95.1%)	
11/20 07:31:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.9600 (0.9036)	Arch Loss 1.8275 (1.9255)	Arch Hard Loss 1.7523 (1.8506)	Arch Beta Loss 0.0150 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.8%)	
11/20 07:31:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0038 (0.9104)	Arch Loss 2.0089 (1.9162)	Arch Hard Loss 1.9340 (1.8415)	Arch Beta Loss 0.0150 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.7%)	
11/20 07:31:50午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 34/49] Final Prec@1 73.2680%
11/20 07:32:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8021	Prec@(1,5) (52.9%, 81.9%)
11/20 07:32:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7824	Prec@(1,5) (53.3%, 82.1%)
11/20 07:32:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7810	Prec@(1,5) (53.4%, 82.2%)
11/20 07:32:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7888	Prec@(1,5) (53.3%, 82.1%)
11/20 07:32:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 53.2920%
11/20 07:32:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:32:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2920%
11/20 07:33:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.8798 (0.8514)	Arch Loss 2.0889 (1.9339)	Arch Hard Loss 2.0207 (1.8602)	Arch Beta Loss 0.0136 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.5%)	
11/20 07:34:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.7206 (0.8644)	Arch Loss 1.8619 (1.9260)	Arch Hard Loss 1.7898 (1.8524)	Arch Beta Loss 0.0144 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.5%)	
11/20 07:35:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.5602 (0.8695)	Arch Loss 2.3635 (1.9223)	Arch Hard Loss 2.2979 (1.8489)	Arch Beta Loss 0.0131 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.4%)	
11/20 07:36:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.0637 (0.8778)	Arch Loss 1.9718 (1.9185)	Arch Hard Loss 1.9061 (1.8451)	Arch Beta Loss 0.0131 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.2%)	
11/20 07:36:01午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 35/49] Final Prec@1 74.2840%
11/20 07:36:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.8074	Prec@(1,5) (53.1%, 82.3%)
11/20 07:36:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.8201	Prec@(1,5) (52.4%, 82.1%)
11/20 07:36:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.8211	Prec@(1,5) (52.6%, 82.0%)
11/20 07:36:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8280	Prec@(1,5) (52.5%, 81.9%)
11/20 07:36:38午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 52.4400%
11/20 07:36:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:36:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2920%
11/20 07:37:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.0225 (0.8086)	Arch Loss 2.1134 (1.9032)	Arch Hard Loss 2.0363 (1.8299)	Arch Beta Loss 0.0154 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.7%)	
11/20 07:38:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.0958 (0.8171)	Arch Loss 2.3544 (1.9058)	Arch Hard Loss 2.2748 (1.8332)	Arch Beta Loss 0.0159 (0.0145)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.7%)	
11/20 07:39:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7350 (0.8277)	Arch Loss 1.9167 (1.9018)	Arch Hard Loss 1.8383 (1.8296)	Arch Beta Loss 0.0157 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.7%)	
11/20 07:40:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.0296 (0.8393)	Arch Loss 1.8800 (1.9048)	Arch Hard Loss 1.8054 (1.8328)	Arch Beta Loss 0.0149 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.5%)	
11/20 07:40:12午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 36/49] Final Prec@1 75.2160%
11/20 07:40:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.8230	Prec@(1,5) (53.4%, 82.1%)
11/20 07:40:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.8151	Prec@(1,5) (53.4%, 81.9%)
11/20 07:40:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.8166	Prec@(1,5) (53.4%, 82.0%)
11/20 07:40:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.8188	Prec@(1,5) (53.1%, 81.9%)
11/20 07:40:48午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 53.1240%
11/20 07:40:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:40:49午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2920%
11/20 07:41:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.1015 (0.7805)	Arch Loss 2.2140 (1.9062)	Arch Hard Loss 2.1500 (1.8342)	Arch Beta Loss 0.0128 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.3%)	
11/20 07:42:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.9542 (0.7799)	Arch Loss 2.1349 (1.9095)	Arch Hard Loss 2.0743 (1.8376)	Arch Beta Loss 0.0121 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.4%)	
11/20 07:43:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8785 (0.7876)	Arch Loss 2.0930 (1.9278)	Arch Hard Loss 2.0269 (1.8558)	Arch Beta Loss 0.0132 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
11/20 07:44:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.7500 (0.7986)	Arch Loss 2.1144 (1.9156)	Arch Hard Loss 2.0448 (1.8435)	Arch Beta Loss 0.0139 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
11/20 07:44:23午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 37/49] Final Prec@1 76.5360%
11/20 07:44:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8194	Prec@(1,5) (52.9%, 82.2%)
11/20 07:44:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8162	Prec@(1,5) (53.0%, 82.2%)
11/20 07:44:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7949	Prec@(1,5) (53.3%, 82.5%)
11/20 07:44:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7974	Prec@(1,5) (53.4%, 82.3%)
11/20 07:44:59午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 53.3840%
11/20 07:44:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:45:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3840%
11/20 07:45:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.7888 (0.7480)	Arch Loss 2.1616 (1.9376)	Arch Hard Loss 2.0869 (1.8656)	Arch Beta Loss 0.0149 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.5%)	
11/20 07:46:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7186 (0.7452)	Arch Loss 2.1031 (1.9113)	Arch Hard Loss 2.0315 (1.8394)	Arch Beta Loss 0.0143 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.4%)	
11/20 07:47:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.7319 (0.7522)	Arch Loss 1.7987 (1.9129)	Arch Hard Loss 1.7202 (1.8409)	Arch Beta Loss 0.0157 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
11/20 07:48:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.1125 (0.7619)	Arch Loss 1.5817 (1.9080)	Arch Hard Loss 1.5020 (1.8358)	Arch Beta Loss 0.0159 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.4%)	
11/20 07:48:34午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 38/49] Final Prec@1 77.8280%
11/20 07:48:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.8084	Prec@(1,5) (53.7%, 82.1%)
11/20 07:48:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7969	Prec@(1,5) (53.8%, 82.2%)
11/20 07:49:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7925	Prec@(1,5) (54.0%, 82.4%)
11/20 07:49:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7942	Prec@(1,5) (53.8%, 82.4%)
11/20 07:49:10午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 53.7600%
11/20 07:49:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:49:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7600%
11/20 07:50:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.6882 (0.7157)	Arch Loss 1.7805 (1.9185)	Arch Hard Loss 1.7119 (1.8454)	Arch Beta Loss 0.0137 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.9%)	
11/20 07:51:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7174 (0.7243)	Arch Loss 1.5603 (1.8973)	Arch Hard Loss 1.4924 (1.8240)	Arch Beta Loss 0.0136 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.8%)	
11/20 07:51:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.7562 (0.7286)	Arch Loss 1.6923 (1.8943)	Arch Hard Loss 1.6209 (1.8211)	Arch Beta Loss 0.0143 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.7%)	
11/20 07:52:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8640 (0.7315)	Arch Loss 2.1585 (1.9008)	Arch Hard Loss 2.0830 (1.8274)	Arch Beta Loss 0.0151 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.6%)	
11/20 07:52:45午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 39/49] Final Prec@1 78.5040%
11/20 07:52:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7734	Prec@(1,5) (54.1%, 82.6%)
11/20 07:53:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7651	Prec@(1,5) (54.5%, 82.4%)
11/20 07:53:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7676	Prec@(1,5) (54.5%, 82.6%)
11/20 07:53:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7620	Prec@(1,5) (54.6%, 82.8%)
11/20 07:53:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 54.5600%
11/20 07:53:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:53:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5600%
11/20 07:54:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.7073 (0.6706)	Arch Loss 1.6871 (1.9294)	Arch Hard Loss 1.6118 (1.8548)	Arch Beta Loss 0.0151 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.1%)	
11/20 07:55:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5792 (0.6840)	Arch Loss 1.8868 (1.9290)	Arch Hard Loss 1.8028 (1.8544)	Arch Beta Loss 0.0168 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 96.9%)	
11/20 07:56:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.7482 (0.6916)	Arch Loss 1.4868 (1.9129)	Arch Hard Loss 1.4049 (1.8386)	Arch Beta Loss 0.0164 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
11/20 07:56:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.4538 (0.6930)	Arch Loss 2.4372 (1.9067)	Arch Hard Loss 2.3626 (1.8327)	Arch Beta Loss 0.0149 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/20 07:56:56午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 40/49] Final Prec@1 79.9600%
11/20 07:57:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.8030	Prec@(1,5) (53.6%, 82.5%)
11/20 07:57:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7662	Prec@(1,5) (54.3%, 82.9%)
11/20 07:57:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7727	Prec@(1,5) (54.3%, 82.7%)
11/20 07:57:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7657	Prec@(1,5) (54.5%, 82.9%)
11/20 07:57:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 54.4440%
11/20 07:57:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 07:57:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5600%
11/20 07:58:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.5290 (0.6464)	Arch Loss 1.8812 (1.9520)	Arch Hard Loss 1.8172 (1.8797)	Arch Beta Loss 0.0128 (0.0145)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.5%)	
11/20 07:59:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4681 (0.6576)	Arch Loss 1.4539 (1.9059)	Arch Hard Loss 1.3895 (1.8338)	Arch Beta Loss 0.0129 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.4%)	
11/20 08:00:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5733 (0.6662)	Arch Loss 1.8923 (1.9030)	Arch Hard Loss 1.8197 (1.8308)	Arch Beta Loss 0.0145 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.3%)	
11/20 08:01:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.6799 (0.6730)	Arch Loss 1.7976 (1.8980)	Arch Hard Loss 1.7210 (1.8259)	Arch Beta Loss 0.0153 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.3%)	
11/20 08:01:06午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 41/49] Final Prec@1 80.7240%
11/20 08:01:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7472	Prec@(1,5) (54.3%, 82.6%)
11/20 08:01:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7552	Prec@(1,5) (54.2%, 82.8%)
11/20 08:01:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7616	Prec@(1,5) (54.3%, 82.8%)
11/20 08:01:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7616	Prec@(1,5) (54.3%, 82.8%)
11/20 08:01:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 54.2800%
11/20 08:01:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[4, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:01:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5600%
11/20 08:02:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.5922 (0.6148)	Arch Loss 2.0962 (1.8513)	Arch Hard Loss 2.0240 (1.7792)	Arch Beta Loss 0.0144 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
11/20 08:03:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.5837 (0.6271)	Arch Loss 1.8255 (1.8800)	Arch Hard Loss 1.7626 (1.8073)	Arch Beta Loss 0.0126 (0.0145)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.5%)	
11/20 08:04:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6745 (0.6396)	Arch Loss 1.8402 (1.8884)	Arch Hard Loss 1.7619 (1.8153)	Arch Beta Loss 0.0157 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.5%)	
11/20 08:05:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5995 (0.6467)	Arch Loss 1.8355 (1.8827)	Arch Hard Loss 1.7546 (1.8095)	Arch Beta Loss 0.0162 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.4%)	
11/20 08:05:17午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 42/49] Final Prec@1 81.7680%
11/20 08:05:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.8165	Prec@(1,5) (53.6%, 82.1%)
11/20 08:05:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7888	Prec@(1,5) (54.0%, 82.6%)
11/20 08:05:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7834	Prec@(1,5) (54.2%, 82.3%)
11/20 08:05:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7774	Prec@(1,5) (54.3%, 82.5%)
11/20 08:05:54午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 54.2680%
11/20 08:05:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[5, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:05:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5600%
11/20 08:06:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.8771 (0.5970)	Arch Loss 1.8485 (1.8641)	Arch Hard Loss 1.7756 (1.7901)	Arch Beta Loss 0.0146 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.7%)	
11/20 08:07:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.7706 (0.6174)	Arch Loss 1.7875 (1.8713)	Arch Hard Loss 1.7149 (1.7972)	Arch Beta Loss 0.0145 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.6%)	
11/20 08:08:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6568 (0.6206)	Arch Loss 1.7893 (1.8747)	Arch Hard Loss 1.7161 (1.8003)	Arch Beta Loss 0.0146 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
11/20 08:09:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.7806 (0.6193)	Arch Loss 2.1207 (1.8900)	Arch Hard Loss 2.0426 (1.8158)	Arch Beta Loss 0.0156 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
11/20 08:09:28午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 43/49] Final Prec@1 82.6520%
11/20 08:09:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7957	Prec@(1,5) (54.6%, 82.3%)
11/20 08:09:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7861	Prec@(1,5) (54.6%, 82.5%)
11/20 08:09:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7786	Prec@(1,5) (54.7%, 82.6%)
11/20 08:10:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7723	Prec@(1,5) (54.9%, 82.8%)
11/20 08:10:04午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 54.8880%
11/20 08:10:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[5, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:10:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8880%
11/20 08:11:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5760 (0.5916)	Arch Loss 2.4417 (1.8652)	Arch Hard Loss 2.3696 (1.7919)	Arch Beta Loss 0.0144 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/20 08:11:55午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.4881 (0.5967)	Arch Loss 2.1513 (1.8746)	Arch Hard Loss 2.0647 (1.8008)	Arch Beta Loss 0.0173 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.9%)	
11/20 08:12:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6942 (0.5976)	Arch Loss 2.4105 (1.8851)	Arch Hard Loss 2.3339 (1.8112)	Arch Beta Loss 0.0153 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/20 08:13:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.4874 (0.6025)	Arch Loss 1.5188 (1.8901)	Arch Hard Loss 1.4473 (1.8162)	Arch Beta Loss 0.0143 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/20 08:13:39午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 44/49] Final Prec@1 83.1600%
11/20 08:13:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.7496	Prec@(1,5) (55.3%, 82.9%)
11/20 08:13:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7782	Prec@(1,5) (54.6%, 82.6%)
11/20 08:14:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7717	Prec@(1,5) (54.6%, 82.7%)
11/20 08:14:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7738	Prec@(1,5) (54.6%, 82.7%)
11/20 08:14:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 54.5680%
11/20 08:14:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:14:15午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8880%
11/20 08:15:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5398 (0.5718)	Arch Loss 1.8860 (1.8710)	Arch Hard Loss 1.8168 (1.7971)	Arch Beta Loss 0.0138 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.2%)	
11/20 08:16:06午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5769 (0.5794)	Arch Loss 1.9383 (1.8914)	Arch Hard Loss 1.8776 (1.8177)	Arch Beta Loss 0.0121 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/20 08:17:01午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6103 (0.5822)	Arch Loss 1.6097 (1.8885)	Arch Hard Loss 1.5428 (1.8152)	Arch Beta Loss 0.0134 (0.0147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/20 08:17:50午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6661 (0.5879)	Arch Loss 2.0269 (1.8888)	Arch Hard Loss 1.9565 (1.8157)	Arch Beta Loss 0.0141 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
11/20 08:17:50午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 45/49] Final Prec@1 83.9360%
11/20 08:18:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7912	Prec@(1,5) (54.3%, 82.5%)
11/20 08:18:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7585	Prec@(1,5) (55.1%, 83.0%)
11/20 08:18:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7739	Prec@(1,5) (54.8%, 82.6%)
11/20 08:18:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7720	Prec@(1,5) (54.7%, 82.7%)
11/20 08:18:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 54.7040%
11/20 08:18:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 10], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:18:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8880%
11/20 08:19:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6057 (0.5403)	Arch Loss 2.0943 (1.8599)	Arch Hard Loss 2.0215 (1.7877)	Arch Beta Loss 0.0146 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/20 08:20:17午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.6850 (0.5637)	Arch Loss 1.8263 (1.8813)	Arch Hard Loss 1.7510 (1.8091)	Arch Beta Loss 0.0151 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
11/20 08:21:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.6020 (0.5669)	Arch Loss 1.9283 (1.8819)	Arch Hard Loss 1.8571 (1.8097)	Arch Beta Loss 0.0142 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.1%)	
11/20 08:22:00午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.3965 (0.5699)	Arch Loss 1.9332 (1.8823)	Arch Hard Loss 1.8642 (1.8103)	Arch Beta Loss 0.0138 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.1%)	
11/20 08:22:01午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 46/49] Final Prec@1 84.5280%
11/20 08:22:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7991	Prec@(1,5) (54.3%, 82.7%)
11/20 08:22:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7704	Prec@(1,5) (54.9%, 82.8%)
11/20 08:22:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7645	Prec@(1,5) (54.8%, 82.9%)
11/20 08:22:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7731	Prec@(1,5) (54.6%, 82.9%)
11/20 08:22:37午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 54.5480%
11/20 08:22:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 10], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[5, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:22:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8880%
11/20 08:23:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.7048 (0.5465)	Arch Loss 1.9206 (1.8827)	Arch Hard Loss 1.8399 (1.8119)	Arch Beta Loss 0.0161 (0.0142)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.2%)	
11/20 08:24:27午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.7317 (0.5557)	Arch Loss 1.5135 (1.8737)	Arch Hard Loss 1.4377 (1.8027)	Arch Beta Loss 0.0152 (0.0142)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.2%)	
11/20 08:25:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.6738 (0.5613)	Arch Loss 1.7121 (1.8821)	Arch Hard Loss 1.6417 (1.8113)	Arch Beta Loss 0.0141 (0.0142)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.2%)	
11/20 08:26:11午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.6881 (0.5671)	Arch Loss 2.0496 (1.8836)	Arch Hard Loss 1.9843 (1.8130)	Arch Beta Loss 0.0131 (0.0141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.2%)	
11/20 08:26:11午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 47/49] Final Prec@1 84.5280%
11/20 08:26:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7255	Prec@(1,5) (55.6%, 83.8%)
11/20 08:26:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7584	Prec@(1,5) (55.2%, 83.2%)
11/20 08:26:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7570	Prec@(1,5) (55.1%, 83.0%)
11/20 08:26:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7653	Prec@(1,5) (55.0%, 82.9%)
11/20 08:26:48午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 55.0080%
11/20 08:26:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:26:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0080%
11/20 08:27:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5114 (0.5392)	Arch Loss 1.9207 (1.8564)	Arch Hard Loss 1.8467 (1.7860)	Arch Beta Loss 0.0148 (0.0141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
11/20 08:28:38午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.7236 (0.5490)	Arch Loss 1.7455 (1.8614)	Arch Hard Loss 1.6707 (1.7909)	Arch Beta Loss 0.0150 (0.0141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/20 08:29:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.4369 (0.5498)	Arch Loss 1.5401 (1.8769)	Arch Hard Loss 1.4633 (1.8063)	Arch Beta Loss 0.0154 (0.0141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.4%)	
11/20 08:30:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.7221 (0.5556)	Arch Loss 2.1109 (1.8901)	Arch Hard Loss 2.0375 (1.8193)	Arch Beta Loss 0.0147 (0.0142)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.4%)	
11/20 08:30:22午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 48/49] Final Prec@1 84.8440%
11/20 08:30:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7424	Prec@(1,5) (55.5%, 83.2%)
11/20 08:30:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7503	Prec@(1,5) (55.7%, 83.2%)
11/20 08:30:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7623	Prec@(1,5) (55.3%, 83.0%)
11/20 08:30:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7584	Prec@(1,5) (55.3%, 83.0%)
11/20 08:30:59午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 55.3080%
11/20 08:30:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 9], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:30:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.3080%
11/20 08:31:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.5332 (0.5275)	Arch Loss 2.3719 (1.8909)	Arch Hard Loss 2.3068 (1.8190)	Arch Beta Loss 0.0130 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.6%)	
11/20 08:32:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4814 (0.5364)	Arch Loss 1.9247 (1.8823)	Arch Hard Loss 1.8517 (1.8105)	Arch Beta Loss 0.0146 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/20 08:33:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.3451 (0.5470)	Arch Loss 1.8600 (1.8876)	Arch Hard Loss 1.7929 (1.8157)	Arch Beta Loss 0.0134 (0.0144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.3%)	
11/20 08:34:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5523 (0.5553)	Arch Loss 2.0516 (1.8779)	Arch Hard Loss 1.9819 (1.8063)	Arch Beta Loss 0.0139 (0.0143)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.2%)	
11/20 08:34:33午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 49/49] Final Prec@1 84.9120%
11/20 08:34:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7465	Prec@(1,5) (54.8%, 83.2%)
11/20 08:34:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7540	Prec@(1,5) (54.7%, 83.0%)
11/20 08:35:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7444	Prec@(1,5) (55.0%, 83.2%)
11/20 08:35:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7521	Prec@(1,5) (55.1%, 83.0%)
11/20 08:35:10午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 55.0800%
11/20 08:35:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/20 08:35:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.3080%
11/20 08:35:10午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 55.3080%
11/20 08:35:10午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 9], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
