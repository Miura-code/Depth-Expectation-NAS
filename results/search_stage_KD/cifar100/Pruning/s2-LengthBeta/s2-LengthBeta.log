11/07 10:10:43AM parser.py:28 [INFO] 
11/07 10:10:43AM parser.py:29 [INFO] Parameters:
11/07 10:10:43AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s2-LengthBeta/DAG
11/07 10:10:43AM parser.py:31 [INFO] T=10.0
11/07 10:10:43AM parser.py:31 [INFO] ADVANCED=1
11/07 10:10:43AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/07 10:10:43AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/07 10:10:43AM parser.py:31 [INFO] BATCH_SIZE=64
11/07 10:10:43AM parser.py:31 [INFO] BETA_CRITERION=length
11/07 10:10:43AM parser.py:31 [INFO] CASCADE=0
11/07 10:10:43AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/07 10:10:43AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/07 10:10:43AM parser.py:31 [INFO] DATA_PATH=../data/
11/07 10:10:43AM parser.py:31 [INFO] DATASET=cifar100
11/07 10:10:43AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/07 10:10:43AM parser.py:31 [INFO] DESCRIPTION=search_wtih_cell-length-constriction
11/07 10:10:43AM parser.py:31 [INFO] DISCRETE=0
11/07 10:10:43AM parser.py:31 [INFO] EPOCHS=50
11/07 10:10:43AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/07 10:10:43AM parser.py:31 [INFO] EXP_NAME=s2-LengthBeta
11/07 10:10:43AM parser.py:31 [INFO] FINAL_L=1.0
11/07 10:10:43AM parser.py:31 [INFO] G=1.0
11/07 10:10:43AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/07 10:10:43AM parser.py:31 [INFO] GPUS=[0]
11/07 10:10:43AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/07 10:10:43AM parser.py:31 [INFO] INIT_CHANNELS=16
11/07 10:10:43AM parser.py:31 [INFO] L=0.0
11/07 10:10:43AM parser.py:31 [INFO] LAYERS=20
11/07 10:10:43AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/07 10:10:43AM parser.py:31 [INFO] NAME=Pruning
11/07 10:10:43AM parser.py:31 [INFO] NONKD=1
11/07 10:10:43AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s2-LengthBeta
11/07 10:10:43AM parser.py:31 [INFO] PCDARTS=0
11/07 10:10:43AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s2-LengthBeta/plots
11/07 10:10:43AM parser.py:31 [INFO] PRINT_FREQ=100
11/07 10:10:43AM parser.py:31 [INFO] RESET=0
11/07 10:10:43AM parser.py:31 [INFO] RESUME_PATH=None
11/07 10:10:43AM parser.py:31 [INFO] SAVE=s2-LengthBeta
11/07 10:10:43AM parser.py:31 [INFO] SEED=2
11/07 10:10:43AM parser.py:31 [INFO] SHARE_STAGE=0
11/07 10:10:43AM parser.py:31 [INFO] SLIDE_WINDOW=10
11/07 10:10:43AM parser.py:31 [INFO] SPEC_CELL=1
11/07 10:10:43AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/07 10:10:43AM parser.py:31 [INFO] TEACHER_NAME=none
11/07 10:10:43AM parser.py:31 [INFO] TEACHER_PATH=none
11/07 10:10:43AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/07 10:10:43AM parser.py:31 [INFO] TYPE=Pruning
11/07 10:10:43AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/07 10:10:43AM parser.py:31 [INFO] W_LR=0.025
11/07 10:10:43AM parser.py:31 [INFO] W_LR_MIN=0.001
11/07 10:10:43AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/07 10:10:43AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/07 10:10:43AM parser.py:31 [INFO] WORKERS=4
11/07 10:10:43AM parser.py:32 [INFO] 
11/07 10:10:45AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/07 10:11:34AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.2842 (4.4398)	Arch Loss 4.1428 (4.4190)	Arch Hard Loss 4.1428 (4.4190)	Arch Beta Loss 0.0687 (0.0425)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.1%, 12.9%)	
11/07 10:12:19AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 3.6715 (4.2715)	Arch Loss 4.1186 (4.2574)	Arch Hard Loss 4.1186 (4.2574)	Arch Beta Loss 0.1201 (0.0709)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.9%, 18.1%)	
11/07 10:13:05AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0086 (4.1628)	Arch Loss 3.7707 (4.1456)	Arch Hard Loss 3.7707 (4.1456)	Arch Beta Loss 0.1581 (0.0969)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.9%, 21.6%)	
11/07 10:13:46AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8262 (4.0902)	Arch Loss 3.7018 (4.0717)	Arch Hard Loss 3.7018 (4.0717)	Arch Beta Loss 0.2004 (0.1154)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.8%, 23.8%)	
11/07 10:13:47AM searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  0/49] Final Prec@1 6.8560%
11/07 10:13:54AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.7555	Prec@(1,5) (11.2%, 34.8%)
11/07 10:14:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.7503	Prec@(1,5) (11.4%, 34.9%)
11/07 10:14:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.7457	Prec@(1,5) (11.3%, 34.8%)
11/07 10:14:12AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.7487	Prec@(1,5) (11.3%, 34.7%)
11/07 10:14:12AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 11.2880%
11/07 10:14:12AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)]], DAG1_concat=[2, 4], DAG2=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=[2, 5], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[4, 5])
11/07 10:14:12AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 11.2880%
11/07 10:14:59午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9276 (3.7014)	Arch Loss 3.7165 (3.7237)	Arch Hard Loss 3.7164 (3.7236)	Arch Beta Loss 0.1029 (0.1306)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.7%, 35.5%)	
11/07 10:15:45午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.4885 (3.6714)	Arch Loss 3.5058 (3.6677)	Arch Hard Loss 3.5057 (3.6675)	Arch Beta Loss 0.0904 (0.1091)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.5%, 36.7%)	
11/07 10:16:30午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.4682 (3.6384)	Arch Loss 3.7511 (3.6272)	Arch Hard Loss 3.7510 (3.6271)	Arch Beta Loss 0.1009 (0.1072)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.0%, 37.7%)	
11/07 10:17:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.5660 (3.6016)	Arch Loss 3.4498 (3.5944)	Arch Hard Loss 3.4497 (3.5943)	Arch Beta Loss 0.0921 (0.1048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.6%, 38.6%)	
11/07 10:17:12午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  1/49] Final Prec@1 13.5560%
11/07 10:17:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.4710	Prec@(1,5) (16.4%, 43.3%)
11/07 10:17:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.4442	Prec@(1,5) (17.2%, 43.7%)
11/07 10:17:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.4470	Prec@(1,5) (17.3%, 43.5%)
11/07 10:17:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.4418	Prec@(1,5) (17.3%, 43.7%)
11/07 10:17:36午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 17.2800%
11/07 10:17:36午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 5), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[4, 5])
11/07 10:17:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.2800%
11/07 10:18:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.1183 (3.3817)	Arch Loss 3.3817 (3.3901)	Arch Hard Loss 3.3816 (3.3900)	Arch Beta Loss 0.0338 (0.0444)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.2%, 44.7%)	
11/07 10:19:09午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 2.8300 (3.3486)	Arch Loss 3.9012 (3.3688)	Arch Hard Loss 3.9011 (3.3687)	Arch Beta Loss 0.0187 (0.0368)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.1%, 46.0%)	
11/07 10:19:54午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.3928 (3.3210)	Arch Loss 3.3649 (3.3320)	Arch Hard Loss 3.3648 (3.3319)	Arch Beta Loss 0.0153 (0.0300)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.8%, 47.0%)	
11/07 10:20:36午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 2.9818 (3.3023)	Arch Loss 3.1863 (3.3171)	Arch Hard Loss 3.1862 (3.3170)	Arch Beta Loss 0.0195 (0.0262)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.1%, 47.5%)	
11/07 10:20:36午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  2/49] Final Prec@1 19.1360%
11/07 10:20:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2398	Prec@(1,5) (20.4%, 50.2%)
11/07 10:20:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.2241	Prec@(1,5) (20.7%, 50.6%)
11/07 10:20:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.2411	Prec@(1,5) (20.4%, 50.0%)
11/07 10:21:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.2420	Prec@(1,5) (20.2%, 49.9%)
11/07 10:21:01午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 20.2000%
11/07 10:21:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[4, 5])
11/07 10:21:01午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.2000%
11/07 10:21:48午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.1117 (3.1305)	Arch Loss 3.1225 (3.1716)	Arch Hard Loss 3.1225 (3.1715)	Arch Beta Loss 0.0054 (0.0074)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.0%)	
11/07 10:22:33午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 2.9094 (3.1255)	Arch Loss 3.3980 (3.1569)	Arch Hard Loss 3.3980 (3.1569)	Arch Beta Loss 0.0044 (0.0066)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 51.8%)	
11/07 10:23:19午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.0900 (3.1043)	Arch Loss 3.0803 (3.1381)	Arch Hard Loss 3.0802 (3.1380)	Arch Beta Loss 0.0131 (0.0066)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.3%)	
11/07 10:24:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9150 (3.0769)	Arch Loss 3.5592 (3.1219)	Arch Hard Loss 3.5592 (3.1218)	Arch Beta Loss 0.0085 (0.0070)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 53.3%)	
11/07 10:24:00午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  3/49] Final Prec@1 22.8840%
11/07 10:24:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.0194	Prec@(1,5) (25.0%, 55.0%)
11/07 10:24:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.0225	Prec@(1,5) (24.9%, 54.9%)
11/07 10:24:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.0058	Prec@(1,5) (25.0%, 55.5%)
11/07 10:24:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.0103	Prec@(1,5) (24.9%, 55.5%)
11/07 10:24:25午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 24.8920%
11/07 10:24:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[4, 5])
11/07 10:24:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.8920%
11/07 10:25:12午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.2622 (2.9039)	Arch Loss 2.9329 (3.0115)	Arch Hard Loss 2.9328 (3.0114)	Arch Beta Loss 0.0059 (0.0061)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.8%, 58.0%)	
11/07 10:25:58午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.8087 (2.9121)	Arch Loss 3.0394 (2.9845)	Arch Hard Loss 3.0393 (2.9844)	Arch Beta Loss 0.0041 (0.0055)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.1%, 57.6%)	
11/07 10:26:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.9074 (2.8848)	Arch Loss 2.6620 (2.9521)	Arch Hard Loss 2.6620 (2.9520)	Arch Beta Loss 0.0038 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 58.3%)	
11/07 10:27:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8334 (2.8727)	Arch Loss 3.1935 (2.9373)	Arch Hard Loss 3.1934 (2.9372)	Arch Beta Loss 0.0045 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.0%, 58.6%)	
11/07 10:27:25午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  4/49] Final Prec@1 26.9520%
11/07 10:27:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.9179	Prec@(1,5) (27.0%, 58.0%)
11/07 10:27:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.8999	Prec@(1,5) (27.2%, 58.3%)
11/07 10:27:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9017	Prec@(1,5) (27.2%, 58.3%)
11/07 10:27:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9026	Prec@(1,5) (27.0%, 58.1%)
11/07 10:27:50午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 26.9920%
11/07 10:27:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[4, 5])
11/07 10:27:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.9920%
11/07 10:28:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.5129 (2.7195)	Arch Loss 3.2611 (2.8238)	Arch Hard Loss 3.2610 (2.8237)	Arch Beta Loss 0.0044 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.5%, 62.3%)	
11/07 10:29:22午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.7898 (2.7168)	Arch Loss 2.9103 (2.7912)	Arch Hard Loss 2.9102 (2.7911)	Arch Beta Loss 0.0040 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 62.3%)	
11/07 10:30:08午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.6541 (2.7090)	Arch Loss 2.7977 (2.7855)	Arch Hard Loss 2.7977 (2.7854)	Arch Beta Loss 0.0024 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.0%, 62.5%)	
11/07 10:30:49午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.9380 (2.7018)	Arch Loss 2.6392 (2.7760)	Arch Hard Loss 2.6391 (2.7759)	Arch Beta Loss 0.0034 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.3%, 62.7%)	
11/07 10:30:49午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  5/49] Final Prec@1 30.3520%
11/07 10:30:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8009	Prec@(1,5) (28.7%, 61.4%)
11/07 10:31:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.7827	Prec@(1,5) (28.5%, 61.9%)
11/07 10:31:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.7802	Prec@(1,5) (28.9%, 61.7%)
11/07 10:31:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.7748	Prec@(1,5) (29.0%, 61.8%)
11/07 10:31:14午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 29.0520%
11/07 10:31:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=[3, 5])
11/07 10:31:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.0520%
11/07 10:32:01午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.4646 (2.5205)	Arch Loss 2.6978 (2.6547)	Arch Hard Loss 2.6976 (2.6546)	Arch Beta Loss 0.0031 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.6%, 67.4%)	
11/07 10:32:46午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.3610 (2.5313)	Arch Loss 2.5997 (2.6436)	Arch Hard Loss 2.5995 (2.6434)	Arch Beta Loss 0.0045 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.8%, 66.7%)	
11/07 10:33:32午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.6598 (2.5261)	Arch Loss 2.3810 (2.6408)	Arch Hard Loss 2.3809 (2.6407)	Arch Beta Loss 0.0031 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 66.8%)	
11/07 10:34:13午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.2615 (2.5316)	Arch Loss 2.3531 (2.6378)	Arch Hard Loss 2.3530 (2.6376)	Arch Beta Loss 0.0035 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 66.8%)	
11/07 10:34:13午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  6/49] Final Prec@1 33.9880%
11/07 10:34:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.5755	Prec@(1,5) (33.5%, 66.4%)
11/07 10:34:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.5668	Prec@(1,5) (33.7%, 66.2%)
11/07 10:34:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.5602	Prec@(1,5) (33.8%, 66.2%)
11/07 10:34:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.5594	Prec@(1,5) (33.8%, 66.3%)
11/07 10:34:38午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 33.7840%
11/07 10:34:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:34:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.7840%
11/07 10:35:25午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.3236 (2.4050)	Arch Loss 2.5130 (2.6004)	Arch Hard Loss 2.5129 (2.6002)	Arch Beta Loss 0.0035 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.6%, 69.7%)	
11/07 10:36:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4547 (2.4081)	Arch Loss 2.3495 (2.5666)	Arch Hard Loss 2.3493 (2.5665)	Arch Beta Loss 0.0024 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.3%)	
11/07 10:36:56午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.1613 (2.4077)	Arch Loss 2.6030 (2.5485)	Arch Hard Loss 2.6029 (2.5483)	Arch Beta Loss 0.0026 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.3%, 69.7%)	
11/07 10:37:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.2926 (2.4073)	Arch Loss 3.1392 (2.5284)	Arch Hard Loss 3.1390 (2.5282)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.3%, 69.7%)	
11/07 10:37:38午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  7/49] Final Prec@1 36.2920%
11/07 10:37:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5967	Prec@(1,5) (34.0%, 65.7%)
11/07 10:37:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5817	Prec@(1,5) (33.9%, 66.2%)
11/07 10:37:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5590	Prec@(1,5) (34.2%, 66.4%)
11/07 10:38:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5595	Prec@(1,5) (34.3%, 66.3%)
11/07 10:38:03午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 34.3560%
11/07 10:38:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)]], DAG3_concat=[3, 5])
11/07 10:38:03午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.3560%
11/07 10:38:50午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4820 (2.2713)	Arch Loss 2.4990 (2.4926)	Arch Hard Loss 2.4988 (2.4924)	Arch Beta Loss 0.0033 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 72.3%)	
11/07 10:39:35午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 1.9872 (2.2826)	Arch Loss 2.7657 (2.4450)	Arch Hard Loss 2.7655 (2.4448)	Arch Beta Loss 0.0025 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 72.3%)	
11/07 10:40:21午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.1926 (2.2734)	Arch Loss 2.1762 (2.4389)	Arch Hard Loss 2.1760 (2.4387)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.4%, 72.3%)	
11/07 10:41:02午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.2347 (2.2734)	Arch Loss 2.4080 (2.4304)	Arch Hard Loss 2.4078 (2.4302)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.4%, 72.4%)	
11/07 10:41:02午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  8/49] Final Prec@1 39.3920%
11/07 10:41:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4193	Prec@(1,5) (37.5%, 69.6%)
11/07 10:41:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4075	Prec@(1,5) (37.5%, 69.6%)
11/07 10:41:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4104	Prec@(1,5) (37.4%, 69.7%)
11/07 10:41:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4011	Prec@(1,5) (37.2%, 69.8%)
11/07 10:41:27午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 37.2400%
11/07 10:41:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:41:28午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.2400%
11/07 10:42:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.0894 (2.1243)	Arch Loss 2.2211 (2.3677)	Arch Hard Loss 2.2208 (2.3674)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 75.8%)	
11/07 10:43:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.4664 (2.1543)	Arch Loss 2.2126 (2.3700)	Arch Hard Loss 2.2124 (2.3697)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 75.0%)	
11/07 10:43:46午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.5468 (2.1535)	Arch Loss 2.0380 (2.3631)	Arch Hard Loss 2.0377 (2.3629)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 75.0%)	
11/07 10:44:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1019 (2.1615)	Arch Loss 2.1710 (2.3528)	Arch Hard Loss 2.1708 (2.3526)	Arch Beta Loss 0.0029 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.6%)	
11/07 10:44:27午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  9/49] Final Prec@1 41.6120%
11/07 10:44:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.3466	Prec@(1,5) (38.1%, 71.4%)
11/07 10:44:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3371	Prec@(1,5) (38.3%, 70.9%)
11/07 10:44:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3446	Prec@(1,5) (38.2%, 70.7%)
11/07 10:44:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3530	Prec@(1,5) (38.1%, 70.5%)
11/07 10:44:52午前 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 38.1240%
11/07 10:44:52午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=[3, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:44:52午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.1240%
11/07 10:45:39午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.3069 (2.0404)	Arch Loss 2.2848 (2.2929)	Arch Hard Loss 2.2846 (2.2926)	Arch Beta Loss 0.0027 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.3%, 77.2%)	
11/07 10:46:25午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.1141 (2.0484)	Arch Loss 2.3000 (2.2989)	Arch Hard Loss 2.2996 (2.2986)	Arch Beta Loss 0.0038 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 77.4%)	
11/07 10:47:10午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 1.9321 (2.0530)	Arch Loss 2.2001 (2.2730)	Arch Hard Loss 2.1999 (2.2727)	Arch Beta Loss 0.0024 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 77.2%)	
11/07 10:47:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.5807 (2.0551)	Arch Loss 1.8492 (2.2608)	Arch Hard Loss 1.8490 (2.2605)	Arch Beta Loss 0.0023 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.1%, 77.1%)	
11/07 10:47:51午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 10/49] Final Prec@1 44.1080%
11/07 10:47:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3037	Prec@(1,5) (39.0%, 72.4%)
11/07 10:48:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.2893	Prec@(1,5) (39.6%, 72.4%)
11/07 10:48:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.2706	Prec@(1,5) (40.2%, 72.9%)
11/07 10:48:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.2809	Prec@(1,5) (40.1%, 72.6%)
11/07 10:48:16午前 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 40.1040%
11/07 10:48:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:48:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.1040%
11/07 10:49:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 1.7924 (1.9513)	Arch Loss 2.2873 (2.1860)	Arch Hard Loss 2.2870 (2.1856)	Arch Beta Loss 0.0026 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.2%, 78.5%)	
11/07 10:49:49午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.0610 (1.9585)	Arch Loss 2.7226 (2.2187)	Arch Hard Loss 2.7223 (2.2184)	Arch Beta Loss 0.0030 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.2%)	
11/07 10:50:34午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2448 (1.9767)	Arch Loss 2.0796 (2.1955)	Arch Hard Loss 2.0792 (2.1951)	Arch Beta Loss 0.0035 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 77.8%)	
11/07 10:51:15午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.9407 (1.9851)	Arch Loss 1.8633 (2.1967)	Arch Hard Loss 1.8630 (2.1964)	Arch Beta Loss 0.0024 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 77.7%)	
11/07 10:51:16午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 11/49] Final Prec@1 45.8200%
11/07 10:51:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.1612	Prec@(1,5) (42.6%, 74.3%)
11/07 10:51:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.1621	Prec@(1,5) (42.4%, 74.4%)
11/07 10:51:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.1570	Prec@(1,5) (42.6%, 74.5%)
11/07 10:51:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.1534	Prec@(1,5) (42.6%, 74.7%)
11/07 10:51:40午前 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 42.6360%
11/07 10:51:40午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:51:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.6360%
11/07 10:52:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.2795 (1.8718)	Arch Loss 2.1766 (2.1467)	Arch Hard Loss 2.1763 (2.1463)	Arch Beta Loss 0.0023 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.1%)	
11/07 10:53:13午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.9202 (1.8700)	Arch Loss 1.8116 (2.1442)	Arch Hard Loss 1.8114 (2.1439)	Arch Beta Loss 0.0021 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.0%)	
11/07 10:53:58午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.6921 (1.8848)	Arch Loss 1.7929 (2.1378)	Arch Hard Loss 1.7925 (2.1375)	Arch Beta Loss 0.0024 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 80.0%)	
11/07 10:54:39午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.9355 (1.8902)	Arch Loss 2.1972 (2.1330)	Arch Hard Loss 2.1969 (2.1326)	Arch Beta Loss 0.0021 (0.0027)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.9%)	
11/07 10:54:40午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 12/49] Final Prec@1 47.8640%
11/07 10:54:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.0907	Prec@(1,5) (44.2%, 75.9%)
11/07 10:54:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.0767	Prec@(1,5) (44.8%, 76.0%)
11/07 10:54:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.0831	Prec@(1,5) (44.5%, 75.9%)
11/07 10:55:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.0834	Prec@(1,5) (44.3%, 76.2%)
11/07 10:55:04午前 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 44.2840%
11/07 10:55:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:55:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.2840%
11/07 10:55:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.6264 (1.7699)	Arch Loss 2.0443 (2.0857)	Arch Hard Loss 2.0439 (2.0853)	Arch Beta Loss 0.0024 (0.0027)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.7%)	
11/07 10:56:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.9407 (1.7960)	Arch Loss 2.2252 (2.0989)	Arch Hard Loss 2.2249 (2.0985)	Arch Beta Loss 0.0020 (0.0027)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.5%)	
11/07 10:57:23午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.0188 (1.8036)	Arch Loss 1.7563 (2.0868)	Arch Hard Loss 1.7559 (2.0864)	Arch Beta Loss 0.0023 (0.0026)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.5%)	
11/07 10:58:04午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.9695 (1.8164)	Arch Loss 2.2771 (2.0768)	Arch Hard Loss 2.2767 (2.0764)	Arch Beta Loss 0.0025 (0.0026)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.3%)	
11/07 10:58:04午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 13/49] Final Prec@1 49.7400%
11/07 10:58:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.0591	Prec@(1,5) (45.2%, 77.3%)
11/07 10:58:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.0511	Prec@(1,5) (45.5%, 77.2%)
11/07 10:58:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.0482	Prec@(1,5) (45.5%, 77.1%)
11/07 10:58:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.0510	Prec@(1,5) (45.4%, 77.1%)
11/07 10:58:29午前 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 45.4440%
11/07 10:58:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 10:58:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.4440%
11/07 10:59:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.5476 (1.7128)	Arch Loss 2.2022 (2.0134)	Arch Hard Loss 2.2017 (2.0129)	Arch Beta Loss 0.0027 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.4%, 83.1%)	
11/07 11:00:02午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8188 (1.7322)	Arch Loss 2.1109 (2.0366)	Arch Hard Loss 2.1106 (2.0361)	Arch Beta Loss 0.0020 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.6%)	
11/07 11:00:47午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.7768 (1.7491)	Arch Loss 2.3914 (2.0393)	Arch Hard Loss 2.3910 (2.0388)	Arch Beta Loss 0.0021 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.9%, 82.4%)	
11/07 11:01:28午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.1985 (1.7518)	Arch Loss 2.2263 (2.0350)	Arch Hard Loss 2.2260 (2.0346)	Arch Beta Loss 0.0016 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.8%, 82.2%)	
11/07 11:01:29午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 14/49] Final Prec@1 50.7520%
11/07 11:01:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 1.9691	Prec@(1,5) (46.9%, 78.5%)
11/07 11:01:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 1.9936	Prec@(1,5) (46.4%, 77.7%)
11/07 11:01:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0100	Prec@(1,5) (45.8%, 77.6%)
11/07 11:01:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0201	Prec@(1,5) (45.7%, 77.4%)
11/07 11:01:54午前 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 45.6520%
11/07 11:01:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:01:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.6520%
11/07 11:02:41午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.8524 (1.6450)	Arch Loss 1.6181 (1.9600)	Arch Hard Loss 1.6178 (1.9595)	Arch Beta Loss 0.0015 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.7%)	
11/07 11:03:26午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.0300 (1.6717)	Arch Loss 1.8211 (1.9834)	Arch Hard Loss 1.8207 (1.9830)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.7%)	
11/07 11:04:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.7357 (1.6727)	Arch Loss 2.0425 (1.9839)	Arch Hard Loss 2.0421 (1.9835)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.7%)	
11/07 11:04:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.6084 (1.6750)	Arch Loss 2.0114 (1.9928)	Arch Hard Loss 2.0108 (1.9923)	Arch Beta Loss 0.0027 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.7%)	
11/07 11:04:53午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 15/49] Final Prec@1 52.8000%
11/07 11:05:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 1.9937	Prec@(1,5) (46.8%, 77.7%)
11/07 11:05:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 1.9747	Prec@(1,5) (47.0%, 78.1%)
11/07 11:05:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 1.9760	Prec@(1,5) (46.7%, 78.2%)
11/07 11:05:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 1.9729	Prec@(1,5) (46.7%, 78.3%)
11/07 11:05:18午前 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 46.6520%
11/07 11:05:18午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:05:18午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6520%
11/07 11:06:05午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.6521 (1.5693)	Arch Loss 2.1373 (1.9781)	Arch Hard Loss 2.1368 (1.9775)	Arch Beta Loss 0.0024 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.5%)	
11/07 11:06:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.6104 (1.5727)	Arch Loss 2.5588 (1.9695)	Arch Hard Loss 2.5580 (1.9689)	Arch Beta Loss 0.0034 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.5%)	
11/07 11:07:36午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.1716 (1.5945)	Arch Loss 1.4768 (1.9709)	Arch Hard Loss 1.4764 (1.9703)	Arch Beta Loss 0.0019 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 85.1%)	
11/07 11:08:17午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.4268 (1.6139)	Arch Loss 1.5262 (1.9687)	Arch Hard Loss 1.5254 (1.9681)	Arch Beta Loss 0.0034 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.7%)	
11/07 11:08:17午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 16/49] Final Prec@1 54.0920%
11/07 11:08:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 1.9913	Prec@(1,5) (46.7%, 77.7%)
11/07 11:08:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 1.9517	Prec@(1,5) (47.7%, 78.7%)
11/07 11:08:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 1.9502	Prec@(1,5) (47.7%, 78.7%)
11/07 11:08:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 1.9430	Prec@(1,5) (47.8%, 78.9%)
11/07 11:08:42午前 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 47.8160%
11/07 11:08:42午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:08:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8160%
11/07 11:09:29午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.1384 (1.5349)	Arch Loss 2.0405 (1.9490)	Arch Hard Loss 2.0399 (1.9484)	Arch Beta Loss 0.0021 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.9%)	
11/07 11:10:15午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.6388 (1.5425)	Arch Loss 2.1639 (1.9420)	Arch Hard Loss 2.1634 (1.9414)	Arch Beta Loss 0.0018 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.9%)	
11/07 11:11:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.6561 (1.5508)	Arch Loss 1.9224 (1.9414)	Arch Hard Loss 1.9218 (1.9408)	Arch Beta Loss 0.0024 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.6%)	
11/07 11:11:41午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.4731 (1.5605)	Arch Loss 2.2845 (1.9435)	Arch Hard Loss 2.2840 (1.9429)	Arch Beta Loss 0.0017 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.6%)	
11/07 11:11:42午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 17/49] Final Prec@1 55.5760%
11/07 11:11:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 1.9294	Prec@(1,5) (47.8%, 79.5%)
11/07 11:11:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9207	Prec@(1,5) (48.7%, 79.2%)
11/07 11:12:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9304	Prec@(1,5) (48.3%, 79.1%)
11/07 11:12:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9313	Prec@(1,5) (48.3%, 79.2%)
11/07 11:12:06午前 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 48.3200%
11/07 11:12:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:12:07午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3200%
11/07 11:12:53午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.1178 (1.4639)	Arch Loss 1.8435 (1.8958)	Arch Hard Loss 1.8425 (1.8951)	Arch Beta Loss 0.0033 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.3%)	
11/07 11:13:39午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.2388 (1.4786)	Arch Loss 1.5503 (1.9191)	Arch Hard Loss 1.5496 (1.9184)	Arch Beta Loss 0.0026 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.9%)	
11/07 11:14:25午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.4665 (1.5022)	Arch Loss 2.1658 (1.9264)	Arch Hard Loss 2.1652 (1.9258)	Arch Beta Loss 0.0020 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.6%)	
11/07 11:15:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.4362 (1.5094)	Arch Loss 2.1254 (1.9221)	Arch Hard Loss 2.1249 (1.9215)	Arch Beta Loss 0.0018 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.5%)	
11/07 11:15:06午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 18/49] Final Prec@1 57.0040%
11/07 11:15:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9227	Prec@(1,5) (48.4%, 79.2%)
11/07 11:15:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9091	Prec@(1,5) (48.8%, 79.5%)
11/07 11:15:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9087	Prec@(1,5) (48.7%, 79.5%)
11/07 11:15:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.8949	Prec@(1,5) (48.8%, 79.8%)
11/07 11:15:31午前 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 48.8440%
11/07 11:15:31午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:15:31午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.8440%
11/07 11:16:18午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.6989 (1.4028)	Arch Loss 2.0955 (1.8812)	Arch Hard Loss 2.0947 (1.8804)	Arch Beta Loss 0.0026 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.2%)	
11/07 11:17:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6934 (1.4253)	Arch Loss 2.2738 (1.8984)	Arch Hard Loss 2.2730 (1.8976)	Arch Beta Loss 0.0026 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.7%)	
11/07 11:17:49午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.1398 (1.4491)	Arch Loss 2.0660 (1.8974)	Arch Hard Loss 2.0650 (1.8967)	Arch Beta Loss 0.0032 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.6%)	
11/07 11:18:30午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.1741 (1.4613)	Arch Loss 1.8903 (1.8975)	Arch Hard Loss 1.8896 (1.8968)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.0%, 87.4%)	
11/07 11:18:30午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 19/49] Final Prec@1 58.0440%
11/07 11:18:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.8572	Prec@(1,5) (50.8%, 80.1%)
11/07 11:18:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.8690	Prec@(1,5) (50.2%, 79.8%)
11/07 11:18:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.8723	Prec@(1,5) (50.0%, 79.9%)
11/07 11:18:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.8730	Prec@(1,5) (50.0%, 79.9%)
11/07 11:18:55午前 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 50.0520%
11/07 11:18:55午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:18:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.0520%
11/07 11:19:42午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.4608 (1.3271)	Arch Loss 1.6406 (1.8252)	Arch Hard Loss 1.6395 (1.8244)	Arch Beta Loss 0.0030 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.4%)	
11/07 11:20:28午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5120 (1.3649)	Arch Loss 1.8108 (1.8896)	Arch Hard Loss 1.8098 (1.8887)	Arch Beta Loss 0.0029 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.7%)	
11/07 11:21:13午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.6866 (1.3900)	Arch Loss 2.1464 (1.8795)	Arch Hard Loss 2.1454 (1.8786)	Arch Beta Loss 0.0030 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.3%)	
11/07 11:21:54午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.1536 (1.4088)	Arch Loss 1.6037 (1.8664)	Arch Hard Loss 1.6030 (1.8655)	Arch Beta Loss 0.0021 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.9%)	
11/07 11:21:55午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 20/49] Final Prec@1 59.5120%
11/07 11:22:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.8360	Prec@(1,5) (50.6%, 80.8%)
11/07 11:22:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.8391	Prec@(1,5) (50.4%, 80.8%)
11/07 11:22:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.8279	Prec@(1,5) (51.0%, 80.9%)
11/07 11:22:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.8410	Prec@(1,5) (50.7%, 80.8%)
11/07 11:22:19午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 50.7200%
11/07 11:22:19午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:22:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7200%
11/07 11:23:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.3797 (1.2879)	Arch Loss 2.4333 (1.8777)	Arch Hard Loss 2.4327 (1.8768)	Arch Beta Loss 0.0015 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 90.1%)	
11/07 11:23:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3893 (1.3190)	Arch Loss 2.1017 (1.8757)	Arch Hard Loss 2.1008 (1.8748)	Arch Beta Loss 0.0025 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.6%)	
11/07 11:24:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.5143 (1.3382)	Arch Loss 1.7822 (1.8621)	Arch Hard Loss 1.7813 (1.8612)	Arch Beta Loss 0.0023 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.2%, 89.2%)	
11/07 11:25:18午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.7111 (1.3655)	Arch Loss 2.2466 (1.8658)	Arch Hard Loss 2.2460 (1.8650)	Arch Beta Loss 0.0016 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.6%)	
11/07 11:25:19午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 21/49] Final Prec@1 60.4560%
11/07 11:25:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.8219	Prec@(1,5) (51.1%, 81.5%)
11/07 11:25:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.8442	Prec@(1,5) (50.9%, 81.0%)
11/07 11:25:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.8377	Prec@(1,5) (50.9%, 80.9%)
11/07 11:25:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.8535	Prec@(1,5) (50.5%, 80.6%)
11/07 11:25:44午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 50.4520%
11/07 11:25:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:25:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7200%
11/07 11:26:30午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3574 (1.2708)	Arch Loss 1.9855 (1.8535)	Arch Hard Loss 1.9844 (1.8525)	Arch Beta Loss 0.0027 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.8%, 90.1%)	
11/07 11:27:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.0558 (1.2773)	Arch Loss 1.7307 (1.8492)	Arch Hard Loss 1.7296 (1.8483)	Arch Beta Loss 0.0025 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 90.1%)	
11/07 11:28:01午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.1064 (1.2950)	Arch Loss 1.8399 (1.8443)	Arch Hard Loss 1.8391 (1.8434)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.7%)	
11/07 11:28:42午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.5476 (1.3094)	Arch Loss 2.0255 (1.8371)	Arch Hard Loss 2.0245 (1.8362)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.5%)	
11/07 11:28:43午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 22/49] Final Prec@1 61.7600%
11/07 11:28:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8396	Prec@(1,5) (50.9%, 80.8%)
11/07 11:28:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8416	Prec@(1,5) (50.6%, 80.6%)
11/07 11:29:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8299	Prec@(1,5) (50.8%, 81.1%)
11/07 11:29:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8263	Prec@(1,5) (51.0%, 81.0%)
11/07 11:29:08午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 50.9640%
11/07 11:29:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], DAG3_concat=[3, 5])
11/07 11:29:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.9640%
11/07 11:29:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4320 (1.2175)	Arch Loss 1.7159 (1.8392)	Arch Hard Loss 1.7146 (1.8381)	Arch Beta Loss 0.0031 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 91.2%)	
11/07 11:30:40午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3444 (1.2521)	Arch Loss 1.3025 (1.8380)	Arch Hard Loss 1.3018 (1.8369)	Arch Beta Loss 0.0016 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.5%)	
11/07 11:31:26午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.0013 (1.2727)	Arch Loss 1.3380 (1.8172)	Arch Hard Loss 1.3372 (1.8162)	Arch Beta Loss 0.0020 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.2%)	
11/07 11:32:07午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.5548 (1.2730)	Arch Loss 1.7881 (1.8240)	Arch Hard Loss 1.7872 (1.8230)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.8%, 90.2%)	
11/07 11:32:07午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 23/49] Final Prec@1 62.7800%
11/07 11:32:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8434	Prec@(1,5) (51.6%, 80.6%)
11/07 11:32:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8196	Prec@(1,5) (51.5%, 81.1%)
11/07 11:32:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8291	Prec@(1,5) (51.2%, 81.0%)
11/07 11:32:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8360	Prec@(1,5) (51.1%, 80.9%)
11/07 11:32:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 51.1160%
11/07 11:32:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)]], DAG3_concat=[3, 5])
11/07 11:32:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.1160%
11/07 11:33:19午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 0.9584 (1.1836)	Arch Loss 1.3910 (1.8323)	Arch Hard Loss 1.3898 (1.8313)	Arch Beta Loss 0.0026 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.1%)	
11/07 11:34:04午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.6710 (1.1874)	Arch Loss 2.2488 (1.8197)	Arch Hard Loss 2.2477 (1.8187)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.2%)	
11/07 11:34:50午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.2163 (1.2102)	Arch Loss 2.0049 (1.8232)	Arch Hard Loss 2.0041 (1.8222)	Arch Beta Loss 0.0017 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.9%)	
11/07 11:35:31午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2359 (1.2237)	Arch Loss 1.8437 (1.8200)	Arch Hard Loss 1.8426 (1.8190)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.6%)	
11/07 11:35:31午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 24/49] Final Prec@1 63.8960%
11/07 11:35:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8082	Prec@(1,5) (52.0%, 81.5%)
11/07 11:35:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8077	Prec@(1,5) (51.7%, 81.4%)
11/07 11:35:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8111	Prec@(1,5) (51.7%, 81.4%)
11/07 11:35:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8159	Prec@(1,5) (51.5%, 81.3%)
11/07 11:35:56午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 51.4680%
11/07 11:35:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)]], DAG3_concat=[3, 5])
11/07 11:35:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4680%
11/07 11:36:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.0540 (1.1289)	Arch Loss 1.9989 (1.7993)	Arch Hard Loss 1.9980 (1.7981)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 92.2%)	
11/07 11:37:29午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.4623 (1.1612)	Arch Loss 1.9652 (1.8183)	Arch Hard Loss 1.9643 (1.8172)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.3%)	
11/07 11:38:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.3275 (1.1721)	Arch Loss 1.8232 (1.8141)	Arch Hard Loss 1.8221 (1.8130)	Arch Beta Loss 0.0023 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.4%)	
11/07 11:38:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.1462 (1.1826)	Arch Loss 1.6588 (1.8090)	Arch Hard Loss 1.6579 (1.8079)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.2%)	
11/07 11:38:56午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 25/49] Final Prec@1 65.2960%
11/07 11:39:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.7843	Prec@(1,5) (53.3%, 82.0%)
11/07 11:39:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.7794	Prec@(1,5) (53.1%, 81.9%)
11/07 11:39:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.7893	Prec@(1,5) (53.1%, 81.7%)
11/07 11:39:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.7995	Prec@(1,5) (52.7%, 81.6%)
11/07 11:39:20午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 52.6560%
11/07 11:39:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)]], DAG3_concat=[3, 5])
11/07 11:39:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6560%
11/07 11:40:07午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 0.9469 (1.0799)	Arch Loss 1.6332 (1.8138)	Arch Hard Loss 1.6320 (1.8126)	Arch Beta Loss 0.0023 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.4%)	
11/07 11:40:53午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.9763 (1.1016)	Arch Loss 1.8394 (1.8095)	Arch Hard Loss 1.8384 (1.8083)	Arch Beta Loss 0.0020 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.3%)	
11/07 11:41:38午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2009 (1.1161)	Arch Loss 2.1522 (1.8006)	Arch Hard Loss 2.1507 (1.7994)	Arch Beta Loss 0.0028 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.8%, 92.2%)	
11/07 11:42:19午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0202 (1.1324)	Arch Loss 1.8351 (1.7948)	Arch Hard Loss 1.8337 (1.7936)	Arch Beta Loss 0.0026 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.9%)	
11/07 11:42:20午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 26/49] Final Prec@1 66.4560%
11/07 11:42:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8189	Prec@(1,5) (52.3%, 81.6%)
11/07 11:42:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8068	Prec@(1,5) (52.4%, 81.6%)
11/07 11:42:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8072	Prec@(1,5) (52.4%, 81.8%)
11/07 11:42:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8128	Prec@(1,5) (52.3%, 81.7%)
11/07 11:42:45午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 52.2440%
11/07 11:42:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 1)]], DAG3_concat=[3, 5])
11/07 11:42:45午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6560%
11/07 11:43:32午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 0.9857 (1.0306)	Arch Loss 2.1452 (1.8131)	Arch Hard Loss 2.1440 (1.8118)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.4%)	
11/07 11:44:17午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 0.9840 (1.0553)	Arch Loss 1.3333 (1.7868)	Arch Hard Loss 1.3320 (1.7855)	Arch Beta Loss 0.0023 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.1%)	
11/07 11:45:02午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1835 (1.0754)	Arch Loss 1.8106 (1.7916)	Arch Hard Loss 1.8091 (1.7903)	Arch Beta Loss 0.0027 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.7%)	
11/07 11:45:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.1510 (1.0976)	Arch Loss 1.8897 (1.7788)	Arch Hard Loss 1.8884 (1.7775)	Arch Beta Loss 0.0023 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.4%)	
11/07 11:45:44午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 27/49] Final Prec@1 67.7080%
11/07 11:45:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.7710	Prec@(1,5) (52.8%, 82.7%)
11/07 11:45:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.7537	Prec@(1,5) (53.3%, 82.8%)
11/07 11:46:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.7643	Prec@(1,5) (53.2%, 82.6%)
11/07 11:46:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.7600	Prec@(1,5) (53.3%, 82.7%)
11/07 11:46:09午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 53.2640%
11/07 11:46:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 1)]], DAG3_concat=[3, 5])
11/07 11:46:09午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2640%
11/07 11:46:56午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.3092 (1.0184)	Arch Loss 1.5276 (1.7783)	Arch Hard Loss 1.5267 (1.7770)	Arch Beta Loss 0.0017 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.6%)	
11/07 11:47:42午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.4588 (1.0210)	Arch Loss 1.6959 (1.7962)	Arch Hard Loss 1.6948 (1.7949)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.6%)	
11/07 11:48:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.9573 (1.0355)	Arch Loss 1.7507 (1.7930)	Arch Hard Loss 1.7497 (1.7917)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.0%, 93.4%)	
11/07 11:49:08午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.0984 (1.0514)	Arch Loss 2.1511 (1.7896)	Arch Hard Loss 2.1496 (1.7883)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.1%)	
11/07 11:49:09午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 28/49] Final Prec@1 68.6800%
11/07 11:49:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.7284	Prec@(1,5) (53.7%, 83.3%)
11/07 11:49:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.7456	Prec@(1,5) (53.8%, 82.9%)
11/07 11:49:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.7509	Prec@(1,5) (53.7%, 82.8%)
11/07 11:49:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7558	Prec@(1,5) (53.3%, 82.8%)
11/07 11:49:34午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 53.3480%
11/07 11:49:34午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)]], DAG3_concat=[3, 5])
11/07 11:49:34午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3480%
11/07 11:50:21午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.9450 (1.0069)	Arch Loss 1.6570 (1.7749)	Arch Hard Loss 1.6554 (1.7735)	Arch Beta Loss 0.0026 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.7%)	
11/07 11:51:07午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9544 (1.0112)	Arch Loss 1.2931 (1.7638)	Arch Hard Loss 1.2915 (1.7624)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.5%)	
11/07 11:51:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.2896 (1.0154)	Arch Loss 1.9204 (1.7683)	Arch Hard Loss 1.9188 (1.7669)	Arch Beta Loss 0.0026 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.4%)	
11/07 11:52:33午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0486 (1.0170)	Arch Loss 1.6256 (1.7664)	Arch Hard Loss 1.6242 (1.7649)	Arch Beta Loss 0.0023 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.3%)	
11/07 11:52:33午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 29/49] Final Prec@1 69.8280%
11/07 11:52:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7279	Prec@(1,5) (53.7%, 82.9%)
11/07 11:52:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7216	Prec@(1,5) (54.0%, 82.8%)
11/07 11:52:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7220	Prec@(1,5) (53.9%, 83.1%)
11/07 11:52:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7160	Prec@(1,5) (54.1%, 83.2%)
11/07 11:52:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 54.1080%
11/07 11:52:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)]], DAG3_concat=[3, 5])
11/07 11:52:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1080%
11/07 11:53:45午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.0634 (0.9116)	Arch Loss 1.3346 (1.7300)	Arch Hard Loss 1.3334 (1.7284)	Arch Beta Loss 0.0018 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.5%)	
11/07 11:54:31午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.7670 (0.9392)	Arch Loss 1.7397 (1.7373)	Arch Hard Loss 1.7386 (1.7357)	Arch Beta Loss 0.0018 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.3%)	
11/07 11:55:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 0.9848 (0.9655)	Arch Loss 1.7817 (1.7639)	Arch Hard Loss 1.7799 (1.7624)	Arch Beta Loss 0.0026 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.9%)	
11/07 11:55:57午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0276 (0.9805)	Arch Loss 2.4067 (1.7687)	Arch Hard Loss 2.4050 (1.7672)	Arch Beta Loss 0.0026 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.7%)	
11/07 11:55:58午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 30/49] Final Prec@1 70.9200%
11/07 11:56:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7631	Prec@(1,5) (53.4%, 82.8%)
11/07 11:56:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7471	Prec@(1,5) (53.7%, 83.1%)
11/07 11:56:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7568	Prec@(1,5) (53.4%, 83.1%)
11/07 11:56:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7634	Prec@(1,5) (53.5%, 82.9%)
11/07 11:56:23午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 53.4920%
11/07 11:56:23午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 11:56:23午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.1080%
11/07 11:57:09午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8498 (0.9020)	Arch Loss 2.0191 (1.7516)	Arch Hard Loss 2.0179 (1.7501)	Arch Beta Loss 0.0018 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.9%)	
11/07 11:57:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.0354 (0.8985)	Arch Loss 1.9890 (1.7709)	Arch Hard Loss 1.9873 (1.7693)	Arch Beta Loss 0.0024 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
11/07 11:58:41午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 0.8874 (0.9250)	Arch Loss 1.6997 (1.7603)	Arch Hard Loss 1.6977 (1.7587)	Arch Beta Loss 0.0029 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.5%)	
11/07 11:59:22午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 0.9567 (0.9338)	Arch Loss 1.4334 (1.7570)	Arch Hard Loss 1.4322 (1.7555)	Arch Beta Loss 0.0017 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.3%)	
11/07 11:59:22午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 31/49] Final Prec@1 72.1280%
11/07 11:59:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7440	Prec@(1,5) (54.4%, 82.8%)
11/07 11:59:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7546	Prec@(1,5) (54.6%, 82.7%)
11/07 11:59:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7530	Prec@(1,5) (54.7%, 82.7%)
11/07 11:59:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7652	Prec@(1,5) (54.5%, 82.6%)
11/07 11:59:47午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 54.4680%
11/07 11:59:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 11:59:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4680%
11/07 12:00:34午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.8419 (0.8660)	Arch Loss 1.6190 (1.7000)	Arch Hard Loss 1.6178 (1.6985)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/07 12:01:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9888 (0.8742)	Arch Loss 1.9505 (1.7392)	Arch Hard Loss 1.9491 (1.7378)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.9%, 95.2%)	
11/07 12:02:05午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8028 (0.8880)	Arch Loss 1.7603 (1.7339)	Arch Hard Loss 1.7590 (1.7325)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.9%)	
11/07 12:02:46午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.2743 (0.9003)	Arch Loss 1.8451 (1.7531)	Arch Hard Loss 1.8439 (1.7517)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.8%)	
11/07 12:02:47午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 32/49] Final Prec@1 73.0320%
11/07 12:02:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7597	Prec@(1,5) (53.8%, 83.2%)
11/07 12:02:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7595	Prec@(1,5) (54.1%, 83.2%)
11/07 12:03:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7524	Prec@(1,5) (54.2%, 83.3%)
11/07 12:03:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7534	Prec@(1,5) (54.1%, 83.2%)
11/07 12:03:11午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 54.0840%
11/07 12:03:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:03:11午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4680%
11/07 12:03:58午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.6160 (0.8200)	Arch Loss 1.5769 (1.7355)	Arch Hard Loss 1.5751 (1.7340)	Arch Beta Loss 0.0025 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.4%)	
11/07 12:04:44午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.0906 (0.8448)	Arch Loss 1.6766 (1.7392)	Arch Hard Loss 1.6751 (1.7378)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.2%)	
11/07 12:05:29午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.0394 (0.8615)	Arch Loss 2.4843 (1.7400)	Arch Hard Loss 2.4834 (1.7386)	Arch Beta Loss 0.0013 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.0%)	
11/07 12:06:10午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.8111 (0.8686)	Arch Loss 1.8187 (1.7390)	Arch Hard Loss 1.8169 (1.7376)	Arch Beta Loss 0.0025 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.0%)	
11/07 12:06:11午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 33/49] Final Prec@1 74.1000%
11/07 12:06:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.6521	Prec@(1,5) (55.9%, 84.2%)
11/07 12:06:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.6791	Prec@(1,5) (55.5%, 84.0%)
11/07 12:06:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.6910	Prec@(1,5) (55.5%, 83.9%)
11/07 12:06:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.6982	Prec@(1,5) (55.3%, 83.8%)
11/07 12:06:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 55.3120%
11/07 12:06:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:06:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.3120%
11/07 12:07:22午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7890 (0.7962)	Arch Loss 2.2890 (1.7517)	Arch Hard Loss 2.2877 (1.7502)	Arch Beta Loss 0.0017 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 95.8%)	
11/07 12:08:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.5810 (0.8003)	Arch Loss 2.1853 (1.7375)	Arch Hard Loss 2.1838 (1.7360)	Arch Beta Loss 0.0020 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.8%)	
11/07 12:08:54午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.7711 (0.8123)	Arch Loss 1.3468 (1.7356)	Arch Hard Loss 1.3443 (1.7340)	Arch Beta Loss 0.0032 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
11/07 12:09:35午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9471 (0.8177)	Arch Loss 1.8053 (1.7397)	Arch Hard Loss 1.8031 (1.7382)	Arch Beta Loss 0.0028 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.7%)	
11/07 12:09:35午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 34/49] Final Prec@1 75.5160%
11/07 12:09:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7358	Prec@(1,5) (55.1%, 83.5%)
11/07 12:09:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7100	Prec@(1,5) (55.5%, 83.7%)
11/07 12:09:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7159	Prec@(1,5) (55.2%, 83.7%)
11/07 12:10:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7085	Prec@(1,5) (55.3%, 83.8%)
11/07 12:10:00午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 55.3280%
11/07 12:10:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:10:00午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.3280%
11/07 12:10:47午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.0182 (0.7442)	Arch Loss 1.8391 (1.7052)	Arch Hard Loss 1.8374 (1.7034)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.3%)	
11/07 12:11:33午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9762 (0.7626)	Arch Loss 1.9979 (1.7194)	Arch Hard Loss 1.9965 (1.7176)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.2%)	
11/07 12:12:18午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.7525 (0.7687)	Arch Loss 1.9842 (1.7365)	Arch Hard Loss 1.9828 (1.7348)	Arch Beta Loss 0.0017 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.1%)	
11/07 12:12:59午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.7770 (0.7801)	Arch Loss 1.8881 (1.7378)	Arch Hard Loss 1.8863 (1.7361)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.9%)	
11/07 12:13:00午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 35/49] Final Prec@1 76.7000%
11/07 12:13:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.6856	Prec@(1,5) (56.0%, 84.0%)
11/07 12:13:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.6904	Prec@(1,5) (55.6%, 84.0%)
11/07 12:13:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7094	Prec@(1,5) (55.4%, 83.9%)
11/07 12:13:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7036	Prec@(1,5) (55.4%, 83.9%)
11/07 12:13:24午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 55.4320%
11/07 12:13:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/07 12:13:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.4320%
11/07 12:14:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6455 (0.7125)	Arch Loss 1.6813 (1.7277)	Arch Hard Loss 1.6793 (1.7259)	Arch Beta Loss 0.0024 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.8%)	
11/07 12:14:57午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.6848 (0.7268)	Arch Loss 1.8470 (1.7394)	Arch Hard Loss 1.8456 (1.7377)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.7%)	
11/07 12:15:42午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7587 (0.7417)	Arch Loss 1.0400 (1.7367)	Arch Hard Loss 1.0383 (1.7350)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.5%)	
11/07 12:16:23午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.9138 (0.7501)	Arch Loss 2.0561 (1.7409)	Arch Hard Loss 2.0546 (1.7393)	Arch Beta Loss 0.0019 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.4%)	
11/07 12:16:24午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 36/49] Final Prec@1 77.3960%
11/07 12:16:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7349	Prec@(1,5) (55.5%, 83.4%)
11/07 12:16:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.6868	Prec@(1,5) (56.5%, 84.2%)
11/07 12:16:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.6759	Prec@(1,5) (56.6%, 84.4%)
11/07 12:16:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.6915	Prec@(1,5) (56.3%, 84.1%)
11/07 12:16:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 56.2960%
11/07 12:16:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 5)]], DAG3_concat=[3, 5])
11/07 12:16:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2960%
11/07 12:17:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.8075 (0.6747)	Arch Loss 1.7638 (1.6945)	Arch Hard Loss 1.7626 (1.6927)	Arch Beta Loss 0.0014 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.0%)	
11/07 12:18:21午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.7209 (0.6868)	Arch Loss 1.8670 (1.7175)	Arch Hard Loss 1.8656 (1.7157)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.9%)	
11/07 12:19:07午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.6993 (0.6925)	Arch Loss 2.0925 (1.7318)	Arch Hard Loss 2.0906 (1.7301)	Arch Beta Loss 0.0023 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
11/07 12:19:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.9168 (0.7073)	Arch Loss 2.5402 (1.7367)	Arch Hard Loss 2.5384 (1.7350)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.8%)	
11/07 12:19:48午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 37/49] Final Prec@1 79.0520%
11/07 12:19:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.6655	Prec@(1,5) (56.4%, 84.7%)
11/07 12:20:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.6781	Prec@(1,5) (56.1%, 84.3%)
11/07 12:20:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.6861	Prec@(1,5) (56.2%, 84.2%)
11/07 12:20:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.6885	Prec@(1,5) (56.2%, 84.2%)
11/07 12:20:13午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 56.2400%
11/07 12:20:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 2)]], DAG3_concat=[3, 5])
11/07 12:20:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2960%
11/07 12:21:00午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.4354 (0.6755)	Arch Loss 1.9956 (1.7310)	Arch Hard Loss 1.9936 (1.7291)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.1%)	
11/07 12:21:45午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.4509 (0.6686)	Arch Loss 1.8001 (1.7369)	Arch Hard Loss 1.7983 (1.7351)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.2%)	
11/07 12:22:31午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.7231 (0.6735)	Arch Loss 1.9917 (1.7164)	Arch Hard Loss 1.9898 (1.7146)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.2%)	
11/07 12:23:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6283 (0.6777)	Arch Loss 1.8197 (1.7275)	Arch Hard Loss 1.8180 (1.7257)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.1%)	
11/07 12:23:12午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 38/49] Final Prec@1 79.8760%
11/07 12:23:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7080	Prec@(1,5) (56.2%, 83.9%)
11/07 12:23:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7047	Prec@(1,5) (56.0%, 84.0%)
11/07 12:23:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.6965	Prec@(1,5) (56.1%, 84.1%)
11/07 12:23:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.6894	Prec@(1,5) (56.0%, 84.1%)
11/07 12:23:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 55.9840%
11/07 12:23:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 2)]], DAG3_concat=[3, 5])
11/07 12:23:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2960%
11/07 12:24:24午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.8176 (0.6206)	Arch Loss 1.3875 (1.6881)	Arch Hard Loss 1.3860 (1.6862)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.5%)	
11/07 12:25:10午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6042 (0.6295)	Arch Loss 1.8887 (1.7171)	Arch Hard Loss 1.8866 (1.7152)	Arch Beta Loss 0.0024 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/07 12:25:55午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.8804 (0.6390)	Arch Loss 1.6667 (1.7209)	Arch Hard Loss 1.6650 (1.7190)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/07 12:26:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.7634 (0.6441)	Arch Loss 1.3857 (1.7316)	Arch Hard Loss 1.3838 (1.7298)	Arch Beta Loss 0.0022 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/07 12:26:36午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 39/49] Final Prec@1 81.3440%
11/07 12:26:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.6944	Prec@(1,5) (56.2%, 84.3%)
11/07 12:26:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.6790	Prec@(1,5) (56.8%, 84.4%)
11/07 12:26:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.6861	Prec@(1,5) (56.6%, 84.1%)
11/07 12:27:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.6847	Prec@(1,5) (56.6%, 84.2%)
11/07 12:27:01午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 56.6000%
11/07 12:27:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:27:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6000%
11/07 12:27:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.5617 (0.6248)	Arch Loss 1.6912 (1.7254)	Arch Hard Loss 1.6895 (1.7234)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.7%)	
11/07 12:28:34午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.7330 (0.6156)	Arch Loss 1.8893 (1.7149)	Arch Hard Loss 1.8876 (1.7130)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.7%)	
11/07 12:29:20午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6380 (0.6219)	Arch Loss 2.0809 (1.7210)	Arch Hard Loss 2.0787 (1.7190)	Arch Beta Loss 0.0025 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.7%)	
11/07 12:30:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.5570 (0.6233)	Arch Loss 1.8178 (1.7265)	Arch Hard Loss 1.8158 (1.7246)	Arch Beta Loss 0.0022 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.7%)	
11/07 12:30:01午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 40/49] Final Prec@1 81.6880%
11/07 12:30:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.6990	Prec@(1,5) (55.9%, 84.0%)
11/07 12:30:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.6720	Prec@(1,5) (56.3%, 84.7%)
11/07 12:30:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.6753	Prec@(1,5) (56.4%, 84.8%)
11/07 12:30:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.6822	Prec@(1,5) (56.3%, 84.5%)
11/07 12:30:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 56.3160%
11/07 12:30:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:30:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6000%
11/07 12:31:13午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.6652 (0.5767)	Arch Loss 2.0631 (1.7351)	Arch Hard Loss 2.0612 (1.7330)	Arch Beta Loss 0.0020 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/07 12:31:59午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4438 (0.5856)	Arch Loss 2.1324 (1.7228)	Arch Hard Loss 2.1304 (1.7207)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.9%)	
11/07 12:32:44午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6211 (0.5870)	Arch Loss 1.2691 (1.7232)	Arch Hard Loss 1.2673 (1.7212)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.9%)	
11/07 12:33:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.4503 (0.5960)	Arch Loss 1.8066 (1.7282)	Arch Hard Loss 1.8047 (1.7263)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
11/07 12:33:26午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 41/49] Final Prec@1 82.6280%
11/07 12:33:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.6825	Prec@(1,5) (56.4%, 84.2%)
11/07 12:33:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.6501	Prec@(1,5) (57.1%, 84.8%)
11/07 12:33:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.6564	Prec@(1,5) (56.9%, 84.6%)
11/07 12:33:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.6750	Prec@(1,5) (56.6%, 84.3%)
11/07 12:33:50午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 56.6160%
11/07 12:33:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:33:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6160%
11/07 12:34:37午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6265 (0.5671)	Arch Loss 2.2915 (1.6869)	Arch Hard Loss 2.2895 (1.6850)	Arch Beta Loss 0.0022 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 97.9%)	
11/07 12:35:23午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7854 (0.5605)	Arch Loss 1.9641 (1.7239)	Arch Hard Loss 1.9623 (1.7220)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
11/07 12:36:08午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.4070 (0.5667)	Arch Loss 1.0697 (1.7169)	Arch Hard Loss 1.0674 (1.7150)	Arch Beta Loss 0.0024 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
11/07 12:36:49午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.6061 (0.5754)	Arch Loss 1.8010 (1.7215)	Arch Hard Loss 1.7989 (1.7196)	Arch Beta Loss 0.0022 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
11/07 12:36:50午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 42/49] Final Prec@1 83.5800%
11/07 12:36:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7114	Prec@(1,5) (55.8%, 84.2%)
11/07 12:37:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.6926	Prec@(1,5) (56.5%, 84.5%)
11/07 12:37:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.6746	Prec@(1,5) (56.8%, 84.7%)
11/07 12:37:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.6746	Prec@(1,5) (56.7%, 84.7%)
11/07 12:37:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 56.6920%
11/07 12:37:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:37:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/07 12:38:02午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.4747 (0.5489)	Arch Loss 1.9263 (1.7523)	Arch Hard Loss 1.9247 (1.7504)	Arch Beta Loss 0.0017 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.1%)	
11/07 12:38:48午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.5561 (0.5487)	Arch Loss 1.8578 (1.7267)	Arch Hard Loss 1.8559 (1.7248)	Arch Beta Loss 0.0020 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.2%)	
11/07 12:39:33午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5865 (0.5516)	Arch Loss 1.4393 (1.7118)	Arch Hard Loss 1.4375 (1.7099)	Arch Beta Loss 0.0019 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.2%)	
11/07 12:40:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.5364 (0.5531)	Arch Loss 1.9559 (1.7135)	Arch Hard Loss 1.9538 (1.7116)	Arch Beta Loss 0.0022 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.1%)	
11/07 12:40:15午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 43/49] Final Prec@1 84.2880%
11/07 12:40:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6500	Prec@(1,5) (57.3%, 84.9%)
11/07 12:40:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6738	Prec@(1,5) (56.5%, 84.5%)
11/07 12:40:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6597	Prec@(1,5) (57.0%, 84.7%)
11/07 12:40:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.6624	Prec@(1,5) (57.0%, 84.5%)
11/07 12:40:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 56.9640%
11/07 12:40:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:40:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.9640%
11/07 12:41:27午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.6028 (0.5129)	Arch Loss 2.1072 (1.7150)	Arch Hard Loss 2.1058 (1.7132)	Arch Beta Loss 0.0015 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.4%)	
11/07 12:42:12午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6661 (0.5164)	Arch Loss 1.4440 (1.7221)	Arch Hard Loss 1.4422 (1.7202)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.4%)	
11/07 12:42:58午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.5298 (0.5228)	Arch Loss 2.0508 (1.7233)	Arch Hard Loss 2.0491 (1.7214)	Arch Beta Loss 0.0017 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.5%)	
11/07 12:43:39午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.4286 (0.5328)	Arch Loss 1.7946 (1.7170)	Arch Hard Loss 1.7929 (1.7150)	Arch Beta Loss 0.0017 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/07 12:43:39午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 44/49] Final Prec@1 84.9160%
11/07 12:43:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6498	Prec@(1,5) (57.4%, 84.9%)
11/07 12:43:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6696	Prec@(1,5) (56.9%, 84.7%)
11/07 12:43:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6718	Prec@(1,5) (56.9%, 84.6%)
11/07 12:44:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.6721	Prec@(1,5) (56.9%, 84.8%)
11/07 12:44:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 56.9040%
11/07 12:44:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:44:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.9640%
11/07 12:44:51午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.6746 (0.5148)	Arch Loss 2.0906 (1.7176)	Arch Hard Loss 2.0883 (1.7157)	Arch Beta Loss 0.0024 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.5%)	
11/07 12:45:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.6215 (0.5220)	Arch Loss 1.9400 (1.7288)	Arch Hard Loss 1.9380 (1.7268)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.5%)	
11/07 12:46:22午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.4193 (0.5197)	Arch Loss 1.8766 (1.7208)	Arch Hard Loss 1.8745 (1.7188)	Arch Beta Loss 0.0021 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.5%)	
11/07 12:47:03午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4790 (0.5219)	Arch Loss 1.6636 (1.7240)	Arch Hard Loss 1.6613 (1.7220)	Arch Beta Loss 0.0024 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.5%)	
11/07 12:47:03午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 45/49] Final Prec@1 85.2080%
11/07 12:47:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7199	Prec@(1,5) (56.1%, 83.7%)
11/07 12:47:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.6996	Prec@(1,5) (56.5%, 84.1%)
11/07 12:47:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.6723	Prec@(1,5) (57.1%, 84.5%)
11/07 12:47:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.6652	Prec@(1,5) (57.2%, 84.7%)
11/07 12:47:28午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 57.1720%
11/07 12:47:28午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:47:29午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 57.1720%
11/07 12:48:15午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.4754 (0.4768)	Arch Loss 1.5402 (1.7312)	Arch Hard Loss 1.5381 (1.7292)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.8%)	
11/07 12:49:01午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5888 (0.4847)	Arch Loss 1.9469 (1.7292)	Arch Hard Loss 1.9450 (1.7272)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.6%)	
11/07 12:49:46午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5630 (0.4968)	Arch Loss 1.8983 (1.7240)	Arch Hard Loss 1.8966 (1.7220)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.6%)	
11/07 12:50:27午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.5266 (0.5035)	Arch Loss 1.8334 (1.7197)	Arch Hard Loss 1.8318 (1.7176)	Arch Beta Loss 0.0016 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
11/07 12:50:28午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 46/49] Final Prec@1 85.9560%
11/07 12:50:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.6848	Prec@(1,5) (56.7%, 84.8%)
11/07 12:50:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6761	Prec@(1,5) (56.8%, 84.8%)
11/07 12:50:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6672	Prec@(1,5) (56.9%, 84.8%)
11/07 12:50:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.6662	Prec@(1,5) (57.0%, 84.9%)
11/07 12:50:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 57.0240%
11/07 12:50:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:50:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 57.1720%
11/07 12:51:40午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.4786 (0.4844)	Arch Loss 1.8767 (1.7456)	Arch Hard Loss 1.8735 (1.7435)	Arch Beta Loss 0.0032 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.6%)	
11/07 12:52:25午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.4961 (0.4899)	Arch Loss 1.4360 (1.7232)	Arch Hard Loss 1.4330 (1.7211)	Arch Beta Loss 0.0030 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.6%)	
11/07 12:53:11午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.4649 (0.4966)	Arch Loss 1.6910 (1.7148)	Arch Hard Loss 1.6887 (1.7127)	Arch Beta Loss 0.0023 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.6%)	
11/07 12:53:52午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.5896 (0.4996)	Arch Loss 0.9784 (1.7129)	Arch Hard Loss 0.9766 (1.7109)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.6%)	
11/07 12:53:52午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 47/49] Final Prec@1 86.2240%
11/07 12:53:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6123	Prec@(1,5) (57.2%, 86.2%)
11/07 12:54:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6300	Prec@(1,5) (57.4%, 85.4%)
11/07 12:54:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6401	Prec@(1,5) (57.2%, 85.1%)
11/07 12:54:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6533	Prec@(1,5) (57.2%, 84.8%)
11/07 12:54:17午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 57.2280%
11/07 12:54:17午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:54:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 57.2280%
11/07 12:55:04午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.2790 (0.4742)	Arch Loss 1.7157 (1.7273)	Arch Hard Loss 1.7143 (1.7253)	Arch Beta Loss 0.0015 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/07 12:55:50午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5662 (0.4774)	Arch Loss 1.6218 (1.7091)	Arch Hard Loss 1.6200 (1.7070)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.7%)	
11/07 12:56:36午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5266 (0.4857)	Arch Loss 2.1052 (1.7066)	Arch Hard Loss 2.1035 (1.7046)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.7%)	
11/07 12:57:17午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5896 (0.4912)	Arch Loss 1.2159 (1.7007)	Arch Hard Loss 1.2144 (1.6987)	Arch Beta Loss 0.0015 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
11/07 12:57:17午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 48/49] Final Prec@1 86.6720%
11/07 12:57:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.6713	Prec@(1,5) (57.2%, 84.6%)
11/07 12:57:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6616	Prec@(1,5) (57.0%, 84.8%)
11/07 12:57:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6600	Prec@(1,5) (56.9%, 84.7%)
11/07 12:57:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6520	Prec@(1,5) (57.1%, 84.7%)
11/07 12:57:42午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 57.0560%
11/07 12:57:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 12:57:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 57.2280%
11/07 12:58:29午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.5310 (0.4729)	Arch Loss 1.3156 (1.7151)	Arch Hard Loss 1.3132 (1.7132)	Arch Beta Loss 0.0024 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.9%)	
11/07 12:59:14午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4734 (0.4752)	Arch Loss 1.6551 (1.7154)	Arch Hard Loss 1.6535 (1.7134)	Arch Beta Loss 0.0016 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
11/07 01:00:00午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.3483 (0.4811)	Arch Loss 1.6876 (1.7064)	Arch Hard Loss 1.6858 (1.7044)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.7%)	
11/07 01:00:41午後 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6200 (0.4862)	Arch Loss 1.4153 (1.7091)	Arch Hard Loss 1.4131 (1.7071)	Arch Beta Loss 0.0022 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
11/07 01:00:41午後 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 49/49] Final Prec@1 86.5840%
11/07 01:00:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6890	Prec@(1,5) (56.4%, 84.2%)
11/07 01:00:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6783	Prec@(1,5) (56.7%, 84.5%)
11/07 01:01:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6700	Prec@(1,5) (57.1%, 84.6%)
11/07 01:01:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6697	Prec@(1,5) (57.0%, 84.6%)
11/07 01:01:06午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 56.9600%
11/07 01:01:06午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
11/07 01:01:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 57.2280%
11/07 01:01:06午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 57.2280%
11/07 01:01:06午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)]], DAG2_concat=[3, 5], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)]], DAG3_concat=[3, 5])
