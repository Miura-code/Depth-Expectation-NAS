11/17 08:50:20AM parser.py:28 [INFO] 
11/17 08:50:20AM parser.py:29 [INFO] Parameters:
11/17 08:50:20AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g15/DAG
11/17 08:50:20AM parser.py:31 [INFO] T=10.0
11/17 08:50:20AM parser.py:31 [INFO] ADVANCED=1
11/17 08:50:20AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/17 08:50:20AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/17 08:50:20AM parser.py:31 [INFO] ARCH_CRITERION=length
11/17 08:50:20AM parser.py:31 [INFO] BATCH_SIZE=64
11/17 08:50:20AM parser.py:31 [INFO] CASCADE=0
11/17 08:50:20AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/17 08:50:20AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/17 08:50:20AM parser.py:31 [INFO] DATA_PATH=../data/
11/17 08:50:20AM parser.py:31 [INFO] DATASET=cifar100
11/17 08:50:20AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/17 08:50:20AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/17 08:50:20AM parser.py:31 [INFO] DISCRETE=0
11/17 08:50:20AM parser.py:31 [INFO] EPOCHS=50
11/17 08:50:20AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/17 08:50:20AM parser.py:31 [INFO] EXP_NAME=s0-length-sw3-g15
11/17 08:50:20AM parser.py:31 [INFO] FINAL_L=0.0
11/17 08:50:20AM parser.py:31 [INFO] G=15.0
11/17 08:50:20AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/17 08:50:20AM parser.py:31 [INFO] GPUS=[0]
11/17 08:50:20AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/17 08:50:20AM parser.py:31 [INFO] INIT_CHANNELS=16
11/17 08:50:20AM parser.py:31 [INFO] L=0.0
11/17 08:50:20AM parser.py:31 [INFO] LAYERS=32
11/17 08:50:20AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/17 08:50:20AM parser.py:31 [INFO] NAME=Pruning
11/17 08:50:20AM parser.py:31 [INFO] NONKD=1
11/17 08:50:20AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g15
11/17 08:50:20AM parser.py:31 [INFO] PCDARTS=0
11/17 08:50:20AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g15/plots
11/17 08:50:20AM parser.py:31 [INFO] PRINT_FREQ=100
11/17 08:50:20AM parser.py:31 [INFO] RESET=0
11/17 08:50:20AM parser.py:31 [INFO] RESUME_PATH=None
11/17 08:50:20AM parser.py:31 [INFO] SAVE=s0-length-sw3-g15
11/17 08:50:20AM parser.py:31 [INFO] SEED=0
11/17 08:50:20AM parser.py:31 [INFO] SHARE_STAGE=0
11/17 08:50:20AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/17 08:50:20AM parser.py:31 [INFO] SPEC_CELL=1
11/17 08:50:20AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/17 08:50:20AM parser.py:31 [INFO] TEACHER_NAME=none
11/17 08:50:20AM parser.py:31 [INFO] TEACHER_PATH=none
11/17 08:50:20AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/17 08:50:20AM parser.py:31 [INFO] TYPE=Pruning
11/17 08:50:20AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/17 08:50:20AM parser.py:31 [INFO] W_LR=0.025
11/17 08:50:20AM parser.py:31 [INFO] W_LR_MIN=0.001
11/17 08:50:20AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/17 08:50:20AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/17 08:50:20AM parser.py:31 [INFO] WORKERS=4
11/17 08:50:20AM parser.py:32 [INFO] 
11/17 08:50:26AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/17 08:52:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3375 (4.5364)	Arch Loss 4.5852 (4.8300)	Arch Hard Loss 4.3395 (4.5347)	Arch Beta Loss 0.0164 (0.0197)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 9.3%)	
11/17 08:54:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0083 (4.3872)	Arch Loss 4.5120 (4.6423)	Arch Hard Loss 4.2716 (4.3778)	Arch Beta Loss 0.0160 (0.0176)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.5%, 14.1%)	
11/17 08:56:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9786 (4.2795)	Arch Loss 4.2024 (4.5294)	Arch Hard Loss 3.9526 (4.2752)	Arch Beta Loss 0.0167 (0.0169)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.5%, 17.4%)	
11/17 08:58:19AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8084 (4.2161)	Arch Loss 3.9798 (4.4575)	Arch Hard Loss 3.7468 (4.2081)	Arch Beta Loss 0.0155 (0.0166)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.2%, 19.3%)	
11/17 08:58:23AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  0/49] Final Prec@1 5.2320%
11/17 08:58:43AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9254	Prec@(1,5) (8.1%, 28.5%)
11/17 08:59:03AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9097	Prec@(1,5) (8.4%, 29.0%)
11/17 08:59:24AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9091	Prec@(1,5) (8.5%, 29.2%)
11/17 08:59:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9113	Prec@(1,5) (8.4%, 29.0%)
11/17 08:59:42AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 8.4120%
11/17 08:59:42AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG2_concat=[7, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/17 08:59:43AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.4120%
11/17 09:01:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9430 (3.9023)	Arch Loss 4.2376 (4.1184)	Arch Hard Loss 4.0063 (3.8850)	Arch Beta Loss 0.0154 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.9%, 28.6%)	
11/17 09:03:43AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.8225 (3.8641)	Arch Loss 4.1182 (4.0736)	Arch Hard Loss 3.9055 (3.8401)	Arch Beta Loss 0.0142 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.3%, 30.0%)	
11/17 09:05:43AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.6147 (3.8286)	Arch Loss 3.7120 (4.0415)	Arch Hard Loss 3.4928 (3.8080)	Arch Beta Loss 0.0146 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.0%, 31.3%)	
11/17 09:07:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8904 (3.7929)	Arch Loss 4.2221 (4.0072)	Arch Hard Loss 3.9978 (3.7736)	Arch Beta Loss 0.0150 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.4%, 32.5%)	
11/17 09:07:33AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  1/49] Final Prec@1 10.4360%
11/17 09:07:53AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6128	Prec@(1,5) (13.4%, 38.4%)
11/17 09:08:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6009	Prec@(1,5) (13.8%, 38.4%)
11/17 09:08:34AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6101	Prec@(1,5) (13.4%, 38.3%)
11/17 09:08:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6105	Prec@(1,5) (13.4%, 38.2%)
11/17 09:08:52AM searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 13.4200%
11/17 09:08:52AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/17 09:08:53AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.4200%
11/17 09:10:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.7340 (3.6282)	Arch Loss 3.8480 (3.8594)	Arch Hard Loss 3.6070 (3.6257)	Arch Beta Loss 0.0161 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.1%, 37.2%)	
11/17 09:12:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5958 (3.6054)	Arch Loss 3.6156 (3.8356)	Arch Hard Loss 3.3818 (3.6020)	Arch Beta Loss 0.0156 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.3%, 38.2%)	
11/17 09:14:54AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.4358 (3.5734)	Arch Loss 3.8730 (3.8045)	Arch Hard Loss 3.6351 (3.5708)	Arch Beta Loss 0.0159 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.8%, 39.0%)	
11/17 09:16:42AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.5130 (3.5529)	Arch Loss 3.6384 (3.7780)	Arch Hard Loss 3.3820 (3.5443)	Arch Beta Loss 0.0171 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.1%, 39.4%)	
11/17 09:16:43AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  2/49] Final Prec@1 14.0720%
11/17 09:17:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4076	Prec@(1,5) (16.6%, 44.6%)
11/17 09:17:24AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4186	Prec@(1,5) (16.5%, 43.9%)
11/17 09:17:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4198	Prec@(1,5) (16.5%, 43.9%)
11/17 09:18:03AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4189	Prec@(1,5) (16.5%, 43.8%)
11/17 09:18:03AM searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 16.5520%
11/17 09:18:03AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 10], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 5])
11/17 09:18:04AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.5520%
11/17 09:20:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.6455 (3.4321)	Arch Loss 3.5284 (3.6451)	Arch Hard Loss 3.3107 (3.4113)	Arch Beta Loss 0.0145 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.3%, 43.2%)	
11/17 09:22:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.2309 (3.3919)	Arch Loss 3.8671 (3.6284)	Arch Hard Loss 3.6243 (3.3946)	Arch Beta Loss 0.0162 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 44.8%)	
11/17 09:24:05AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.1459 (3.3536)	Arch Loss 3.6504 (3.5995)	Arch Hard Loss 3.4390 (3.3658)	Arch Beta Loss 0.0141 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.8%, 45.8%)	
11/17 09:25:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.1273 (3.3311)	Arch Loss 3.4172 (3.5815)	Arch Hard Loss 3.2049 (3.3478)	Arch Beta Loss 0.0142 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.4%, 46.4%)	
11/17 09:25:54AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  3/49] Final Prec@1 18.3480%
11/17 09:26:14AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2760	Prec@(1,5) (20.2%, 47.8%)
11/17 09:26:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2674	Prec@(1,5) (20.1%, 48.2%)
11/17 09:26:55AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2727	Prec@(1,5) (19.9%, 48.2%)
11/17 09:27:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2710	Prec@(1,5) (19.8%, 48.3%)
11/17 09:27:14AM searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 19.8400%
11/17 09:27:14AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[7, 9], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 8])
11/17 09:27:14AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.8400%
11/17 09:29:14AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.1025 (3.1594)	Arch Loss 3.2954 (3.4983)	Arch Hard Loss 3.0557 (3.2645)	Arch Beta Loss 0.0160 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 51.6%)	
11/17 09:31:15AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.1580 (3.1407)	Arch Loss 3.2336 (3.4541)	Arch Hard Loss 2.9819 (3.2202)	Arch Beta Loss 0.0168 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.5%, 51.5%)	
11/17 09:33:15AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.7068 (3.1301)	Arch Loss 3.3307 (3.4289)	Arch Hard Loss 3.0907 (3.1946)	Arch Beta Loss 0.0160 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.6%, 51.6%)	
11/17 09:35:04AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.0801 (3.1181)	Arch Loss 3.1362 (3.4010)	Arch Hard Loss 2.8865 (3.1665)	Arch Beta Loss 0.0166 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.9%, 52.0%)	
11/17 09:35:04AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  4/49] Final Prec@1 21.8880%
11/17 09:35:25AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1306	Prec@(1,5) (22.4%, 53.0%)
11/17 09:35:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.1071	Prec@(1,5) (22.8%, 53.6%)
11/17 09:36:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.1031	Prec@(1,5) (23.0%, 53.8%)
11/17 09:36:24AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.1029	Prec@(1,5) (23.1%, 53.7%)
11/17 09:36:24AM searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 23.0920%
11/17 09:36:24AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 5])
11/17 09:36:25AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.0920%
11/17 09:38:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.2046 (2.9738)	Arch Loss 3.3162 (3.2712)	Arch Hard Loss 3.0995 (3.0358)	Arch Beta Loss 0.0144 (0.0157)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.8%, 55.6%)	
11/17 09:40:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.3078 (2.9581)	Arch Loss 3.4931 (3.2723)	Arch Hard Loss 3.2669 (3.0373)	Arch Beta Loss 0.0151 (0.0157)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 56.3%)	
11/17 09:42:26AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8001 (2.9457)	Arch Loss 3.0634 (3.2390)	Arch Hard Loss 2.8333 (3.0042)	Arch Beta Loss 0.0153 (0.0157)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.5%)	
11/17 09:44:14AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6881 (2.9322)	Arch Loss 3.1615 (3.2204)	Arch Hard Loss 2.9270 (2.9856)	Arch Beta Loss 0.0156 (0.0157)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 57.0%)	
11/17 09:44:15AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  5/49] Final Prec@1 25.9400%
11/17 09:44:36AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8872	Prec@(1,5) (26.9%, 57.9%)
11/17 09:44:56AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8962	Prec@(1,5) (26.5%, 57.9%)
11/17 09:45:16AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.9063	Prec@(1,5) (26.3%, 57.7%)
11/17 09:45:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8959	Prec@(1,5) (26.6%, 58.0%)
11/17 09:45:35AM searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 26.5880%
11/17 09:45:35AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 5])
11/17 09:45:36AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.5880%
11/17 09:47:35AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8460 (2.7667)	Arch Loss 3.1390 (3.1296)	Arch Hard Loss 2.9101 (2.8956)	Arch Beta Loss 0.0153 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 61.2%)	
11/17 09:49:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.8830 (2.7828)	Arch Loss 3.2100 (3.1089)	Arch Hard Loss 2.9748 (2.8752)	Arch Beta Loss 0.0157 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.6%, 60.7%)	
11/17 09:51:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.9013 (2.7798)	Arch Loss 2.9475 (3.0861)	Arch Hard Loss 2.7045 (2.8524)	Arch Beta Loss 0.0162 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.4%, 60.7%)	
11/17 09:53:25AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8933 (2.7742)	Arch Loss 3.0156 (3.0839)	Arch Hard Loss 2.7628 (2.8503)	Arch Beta Loss 0.0169 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.7%, 60.9%)	
11/17 09:53:26AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  6/49] Final Prec@1 28.6920%
11/17 09:53:46AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7778	Prec@(1,5) (29.8%, 60.8%)
11/17 09:54:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7733	Prec@(1,5) (30.0%, 60.9%)
11/17 09:54:27AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7885	Prec@(1,5) (29.4%, 60.7%)
11/17 09:54:45AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7954	Prec@(1,5) (29.0%, 60.4%)
11/17 09:54:45AM searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 29.0120%
11/17 09:54:46AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 09:54:46AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.0120%
11/17 09:56:46AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.9059 (2.6328)	Arch Loss 2.9864 (2.9997)	Arch Hard Loss 2.7439 (2.7663)	Arch Beta Loss 0.0162 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 64.3%)	
11/17 09:58:47AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4572 (2.6320)	Arch Loss 3.0380 (2.9744)	Arch Hard Loss 2.8267 (2.7413)	Arch Beta Loss 0.0141 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.3%, 64.4%)	
11/17 10:00:47AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7692 (2.6298)	Arch Loss 3.3864 (2.9755)	Arch Hard Loss 3.1553 (2.7422)	Arch Beta Loss 0.0154 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.4%)	
11/17 10:02:36AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.7760 (2.6247)	Arch Loss 2.8653 (2.9593)	Arch Hard Loss 2.6481 (2.7261)	Arch Beta Loss 0.0145 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.9%, 64.4%)	
11/17 10:02:36AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  7/49] Final Prec@1 31.9440%
11/17 10:02:57AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6931	Prec@(1,5) (30.7%, 63.1%)
11/17 10:03:17AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6747	Prec@(1,5) (30.8%, 63.6%)
11/17 10:03:38AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6712	Prec@(1,5) (31.0%, 63.9%)
11/17 10:03:56AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6761	Prec@(1,5) (30.9%, 63.6%)
11/17 10:03:56AM searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 30.9040%
11/17 10:03:56AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 10:03:57AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.9040%
11/17 10:05:57AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4765 (2.5023)	Arch Loss 3.2033 (2.9045)	Arch Hard Loss 2.9428 (2.6712)	Arch Beta Loss 0.0174 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.7%, 67.3%)	
11/17 10:07:58AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 1.9982 (2.4980)	Arch Loss 3.1684 (2.8925)	Arch Hard Loss 2.9303 (2.6590)	Arch Beta Loss 0.0159 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.3%, 67.2%)	
11/17 10:09:59AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.3959 (2.5000)	Arch Loss 2.8074 (2.8860)	Arch Hard Loss 2.5624 (2.6523)	Arch Beta Loss 0.0163 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 67.4%)	
11/17 10:11:47AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.0960 (2.4965)	Arch Loss 2.8906 (2.8698)	Arch Hard Loss 2.6522 (2.6360)	Arch Beta Loss 0.0159 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.5%)	
11/17 10:11:48AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  8/49] Final Prec@1 34.4160%
11/17 10:12:08AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5530	Prec@(1,5) (33.3%, 66.6%)
11/17 10:12:29AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5727	Prec@(1,5) (33.1%, 66.3%)
11/17 10:12:49AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5861	Prec@(1,5) (32.9%, 65.8%)
11/17 10:13:08AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5909	Prec@(1,5) (32.8%, 65.7%)
11/17 10:13:08AM searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 32.8480%
11/17 10:13:08AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 10:13:08AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.8480%
11/17 10:15:10AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.5098 (2.4018)	Arch Loss 3.0631 (2.8282)	Arch Hard Loss 2.8350 (2.5936)	Arch Beta Loss 0.0152 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.1%, 69.3%)	
11/17 10:17:11AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.4417 (2.4092)	Arch Loss 2.7432 (2.7946)	Arch Hard Loss 2.5238 (2.5601)	Arch Beta Loss 0.0146 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.6%)	
11/17 10:19:11AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.2814 (2.3967)	Arch Loss 2.6475 (2.7800)	Arch Hard Loss 2.4289 (2.5457)	Arch Beta Loss 0.0146 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 69.6%)	
11/17 10:21:00AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1901 (2.3909)	Arch Loss 2.6304 (2.7751)	Arch Hard Loss 2.4049 (2.5408)	Arch Beta Loss 0.0150 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 69.8%)	
11/17 10:21:00AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  9/49] Final Prec@1 36.8360%
11/17 10:21:21AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4939	Prec@(1,5) (34.9%, 68.2%)
11/17 10:21:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4755	Prec@(1,5) (34.9%, 68.2%)
11/17 10:22:02AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4854	Prec@(1,5) (34.9%, 68.1%)
11/17 10:22:19AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4877	Prec@(1,5) (34.7%, 68.1%)
11/17 10:22:19AM searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 34.7000%
11/17 10:22:19AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 10:22:20AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.7000%
11/17 10:24:21AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.5563 (2.2717)	Arch Loss 2.7690 (2.7408)	Arch Hard Loss 2.5285 (2.5068)	Arch Beta Loss 0.0160 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.5%, 72.2%)	
11/17 10:26:22AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.5234 (2.2898)	Arch Loss 2.5349 (2.7257)	Arch Hard Loss 2.2828 (2.4916)	Arch Beta Loss 0.0168 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.0%)	
11/17 10:28:22AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3461 (2.2971)	Arch Loss 2.4724 (2.7109)	Arch Hard Loss 2.2350 (2.4769)	Arch Beta Loss 0.0158 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.8%)	
11/17 10:30:10AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.2721 (2.2923)	Arch Loss 2.5090 (2.6997)	Arch Hard Loss 2.2699 (2.4657)	Arch Beta Loss 0.0159 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 71.9%)	
11/17 10:30:11AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 10/49] Final Prec@1 38.8600%
11/17 10:30:32AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4526	Prec@(1,5) (35.5%, 68.5%)
11/17 10:30:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.4371	Prec@(1,5) (35.8%, 68.6%)
11/17 10:31:13AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.4523	Prec@(1,5) (35.9%, 68.4%)
11/17 10:31:30AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.4500	Prec@(1,5) (36.0%, 68.6%)
11/17 10:31:30AM searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 35.9640%
11/17 10:31:30AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[6, 7])
11/17 10:31:31AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.9640%
11/17 10:33:32AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.0555 (2.1971)	Arch Loss 3.0403 (2.6632)	Arch Hard Loss 2.8184 (2.4289)	Arch Beta Loss 0.0148 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 73.2%)	
11/17 10:35:33AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4023 (2.1855)	Arch Loss 2.8574 (2.6512)	Arch Hard Loss 2.6237 (2.4169)	Arch Beta Loss 0.0156 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.3%, 73.6%)	
11/17 10:37:34AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.1205 (2.1812)	Arch Loss 2.5167 (2.6371)	Arch Hard Loss 2.2880 (2.4031)	Arch Beta Loss 0.0153 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.3%, 73.8%)	
11/17 10:39:22AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.0217 (2.1897)	Arch Loss 2.5028 (2.6326)	Arch Hard Loss 2.2777 (2.3987)	Arch Beta Loss 0.0150 (0.0156)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 73.7%)	
11/17 10:39:23AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 11/49] Final Prec@1 41.1280%
11/17 10:39:43AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3500	Prec@(1,5) (37.4%, 71.4%)
11/17 10:40:04AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3367	Prec@(1,5) (38.0%, 71.5%)
11/17 10:40:24AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3271	Prec@(1,5) (38.3%, 71.8%)
11/17 10:40:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3300	Prec@(1,5) (38.2%, 71.6%)
11/17 10:40:41AM searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 38.2280%
11/17 10:40:42AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[4, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 10:40:42AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2280%
11/17 10:42:44AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.9443 (2.0626)	Arch Loss 2.5388 (2.5848)	Arch Hard Loss 2.3155 (2.3516)	Arch Beta Loss 0.0149 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 76.8%)	
11/17 10:44:44AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.3064 (2.0921)	Arch Loss 2.4311 (2.5871)	Arch Hard Loss 2.1959 (2.3540)	Arch Beta Loss 0.0157 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 76.0%)	
11/17 10:46:45AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9702 (2.0996)	Arch Loss 2.6696 (2.5701)	Arch Hard Loss 2.4265 (2.3372)	Arch Beta Loss 0.0162 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 75.8%)	
11/17 10:48:33AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.9294 (2.1058)	Arch Loss 2.4569 (2.5585)	Arch Hard Loss 2.2048 (2.3256)	Arch Beta Loss 0.0168 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.7%)	
11/17 10:48:34AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 12/49] Final Prec@1 42.7960%
11/17 10:48:55AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3073	Prec@(1,5) (39.4%, 71.6%)
11/17 10:49:15AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.3019	Prec@(1,5) (39.2%, 71.5%)
11/17 10:49:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.3044	Prec@(1,5) (39.3%, 71.4%)
11/17 10:49:52AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.3138	Prec@(1,5) (39.1%, 71.1%)
11/17 10:49:52AM searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 39.0720%
11/17 10:49:53AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 10:49:53AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.0720%
11/17 10:51:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1119 (1.9821)	Arch Loss 2.6528 (2.5424)	Arch Hard Loss 2.4133 (2.3095)	Arch Beta Loss 0.0160 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 78.4%)	
11/17 10:53:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.7163 (2.0299)	Arch Loss 2.4004 (2.5144)	Arch Hard Loss 2.1802 (2.2814)	Arch Beta Loss 0.0147 (0.0155)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.3%)	
11/17 10:55:56AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.8527 (2.0253)	Arch Loss 2.3303 (2.5141)	Arch Hard Loss 2.1048 (2.2812)	Arch Beta Loss 0.0150 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.6%)	
11/17 10:57:44AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0399 (2.0234)	Arch Loss 2.2619 (2.5025)	Arch Hard Loss 2.0382 (2.2699)	Arch Beta Loss 0.0149 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.5%)	
11/17 10:57:45AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 13/49] Final Prec@1 44.7640%
11/17 10:58:06AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1976	Prec@(1,5) (41.6%, 73.8%)
11/17 10:58:26AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2123	Prec@(1,5) (41.3%, 73.7%)
11/17 10:58:46AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1976	Prec@(1,5) (41.6%, 73.9%)
11/17 10:59:03AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2030	Prec@(1,5) (41.5%, 73.8%)
11/17 10:59:03AM searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 41.5080%
11/17 10:59:04AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 10:59:04AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.5080%
11/17 11:01:05AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.9552 (1.9021)	Arch Loss 2.5933 (2.4883)	Arch Hard Loss 2.3449 (2.2565)	Arch Beta Loss 0.0166 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.4%)	
11/17 11:03:06AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.0257 (1.9370)	Arch Loss 2.4591 (2.4809)	Arch Hard Loss 2.2277 (2.2487)	Arch Beta Loss 0.0154 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.8%)	
11/17 11:05:07AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.0434 (1.9401)	Arch Loss 2.5728 (2.4690)	Arch Hard Loss 2.3453 (2.2366)	Arch Beta Loss 0.0152 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.7%)	
11/17 11:06:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.7771 (1.9441)	Arch Loss 2.5064 (2.4608)	Arch Hard Loss 2.2745 (2.2286)	Arch Beta Loss 0.0155 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.5%)	
11/17 11:06:56AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 14/49] Final Prec@1 46.4240%
11/17 11:07:16AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1530	Prec@(1,5) (43.2%, 74.9%)
11/17 11:07:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1695	Prec@(1,5) (42.6%, 74.4%)
11/17 11:07:57AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1706	Prec@(1,5) (42.5%, 74.3%)
11/17 11:08:14AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1766	Prec@(1,5) (42.3%, 74.3%)
11/17 11:08:14AM searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 42.2760%
11/17 11:08:15AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 11:08:15AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.2760%
11/17 11:10:17AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.1102 (1.8360)	Arch Loss 2.4999 (2.4488)	Arch Hard Loss 2.2668 (2.2168)	Arch Beta Loss 0.0155 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.9%)	
11/17 11:12:18AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.7271 (1.8538)	Arch Loss 2.2144 (2.4349)	Arch Hard Loss 1.9917 (2.2031)	Arch Beta Loss 0.0149 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.5%)	
11/17 11:14:18AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9413 (1.8577)	Arch Loss 2.3916 (2.4365)	Arch Hard Loss 2.1643 (2.2049)	Arch Beta Loss 0.0152 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.5%)	
11/17 11:16:06AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.5979 (1.8691)	Arch Loss 2.1948 (2.4258)	Arch Hard Loss 1.9664 (2.1945)	Arch Beta Loss 0.0152 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.3%, 80.5%)	
11/17 11:16:07AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 15/49] Final Prec@1 48.2880%
11/17 11:16:28AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1759	Prec@(1,5) (42.5%, 74.7%)
11/17 11:16:48AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1535	Prec@(1,5) (42.8%, 75.1%)
11/17 11:17:09AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1665	Prec@(1,5) (42.5%, 74.7%)
11/17 11:17:26AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1597	Prec@(1,5) (42.7%, 74.9%)
11/17 11:17:26AM searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 42.6520%
11/17 11:17:26AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 11:17:27AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.6520%
11/17 11:19:28AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7030 (1.7666)	Arch Loss 1.9397 (2.3634)	Arch Hard Loss 1.7126 (2.1332)	Arch Beta Loss 0.0151 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.2%)	
11/17 11:21:29AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9462 (1.7969)	Arch Loss 2.4141 (2.3568)	Arch Hard Loss 2.1656 (2.1265)	Arch Beta Loss 0.0166 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.7%)	
11/17 11:23:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.6440 (1.8025)	Arch Loss 2.6532 (2.3752)	Arch Hard Loss 2.4140 (2.1451)	Arch Beta Loss 0.0159 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.6%)	
11/17 11:25:18AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7555 (1.8084)	Arch Loss 2.4388 (2.3660)	Arch Hard Loss 2.2077 (2.1359)	Arch Beta Loss 0.0154 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.4%)	
11/17 11:25:19AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 16/49] Final Prec@1 49.8280%
11/17 11:25:40AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1249	Prec@(1,5) (43.6%, 75.1%)
11/17 11:26:00AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0976	Prec@(1,5) (44.2%, 75.9%)
11/17 11:26:20AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0968	Prec@(1,5) (44.1%, 76.0%)
11/17 11:26:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0820	Prec@(1,5) (44.3%, 76.3%)
11/17 11:26:37AM searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 44.2720%
11/17 11:26:37AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 11:26:38AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.2720%
11/17 11:28:39AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.8736 (1.6913)	Arch Loss 2.4274 (2.3537)	Arch Hard Loss 2.2135 (2.1237)	Arch Beta Loss 0.0143 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.2%, 83.6%)	
11/17 11:30:40AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.7020 (1.7208)	Arch Loss 2.3911 (2.3486)	Arch Hard Loss 2.1478 (2.1186)	Arch Beta Loss 0.0162 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 83.1%)	
11/17 11:32:40AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.0180 (1.7393)	Arch Loss 2.0256 (2.3637)	Arch Hard Loss 1.8129 (2.1337)	Arch Beta Loss 0.0142 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.7%)	
11/17 11:34:29AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.3404 (1.7506)	Arch Loss 2.3027 (2.3557)	Arch Hard Loss 2.0815 (2.1258)	Arch Beta Loss 0.0147 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.5%, 82.6%)	
11/17 11:34:29AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 17/49] Final Prec@1 50.4880%
11/17 11:34:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.1232	Prec@(1,5) (43.4%, 74.8%)
11/17 11:35:10AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.1147	Prec@(1,5) (43.9%, 75.4%)
11/17 11:35:31AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.1160	Prec@(1,5) (44.0%, 75.4%)
11/17 11:35:48AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.1183	Prec@(1,5) (44.0%, 75.3%)
11/17 11:35:48AM searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 44.0440%
11/17 11:35:48AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 11:35:48AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.2720%
11/17 11:37:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.3545 (1.6246)	Arch Loss 2.4702 (2.2933)	Arch Hard Loss 2.2302 (2.0640)	Arch Beta Loss 0.0160 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.3%, 84.5%)	
11/17 11:39:50AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.5603 (1.6719)	Arch Loss 2.0462 (2.3141)	Arch Hard Loss 1.8239 (2.0849)	Arch Beta Loss 0.0148 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.6%)	
11/17 11:41:51AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.7722 (1.6841)	Arch Loss 2.2069 (2.3236)	Arch Hard Loss 1.9722 (2.0943)	Arch Beta Loss 0.0156 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.5%)	
11/17 11:43:39AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.8078 (1.6926)	Arch Loss 1.7247 (2.3067)	Arch Hard Loss 1.4846 (2.0775)	Arch Beta Loss 0.0160 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.4%)	
11/17 11:43:40AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 18/49] Final Prec@1 52.5280%
11/17 11:44:01AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0516	Prec@(1,5) (44.8%, 76.7%)
11/17 11:44:21AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0404	Prec@(1,5) (45.8%, 77.0%)
11/17 11:44:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0428	Prec@(1,5) (45.7%, 77.0%)
11/17 11:44:59AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0431	Prec@(1,5) (45.6%, 77.2%)
11/17 11:44:59AM searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 45.6040%
11/17 11:44:59AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 11:45:00AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.6040%
11/17 11:47:01AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.1270 (1.5807)	Arch Loss 2.6753 (2.3015)	Arch Hard Loss 2.4758 (2.0724)	Arch Beta Loss 0.0133 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.3%)	
11/17 11:49:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.8896 (1.6116)	Arch Loss 2.5013 (2.3022)	Arch Hard Loss 2.2812 (2.0733)	Arch Beta Loss 0.0147 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.7%)	
11/17 11:51:02AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.0139 (1.6251)	Arch Loss 2.0221 (2.2830)	Arch Hard Loss 1.8009 (2.0544)	Arch Beta Loss 0.0147 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.5%)	
11/17 11:52:51AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.5788 (1.6384)	Arch Loss 2.3232 (2.2750)	Arch Hard Loss 2.1045 (2.0465)	Arch Beta Loss 0.0146 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.3%)	
11/17 11:52:52AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 19/49] Final Prec@1 53.8800%
11/17 11:53:12AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0504	Prec@(1,5) (45.8%, 76.2%)
11/17 11:53:33AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0552	Prec@(1,5) (45.4%, 76.8%)
11/17 11:53:53AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0370	Prec@(1,5) (45.9%, 76.9%)
11/17 11:54:02AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0316	Prec@(1,5) (45.9%, 77.0%)
11/17 11:54:02AM searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 45.8800%
11/17 11:54:02AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 11:54:03AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.8800%
11/17 11:55:53AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6209 (1.5277)	Arch Loss 2.3832 (2.2772)	Arch Hard Loss 2.1429 (2.0493)	Arch Beta Loss 0.0160 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.6%)	
11/17 11:57:54AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.6421 (1.5498)	Arch Loss 2.8178 (2.2658)	Arch Hard Loss 2.5821 (2.0383)	Arch Beta Loss 0.0157 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.7%, 86.5%)	
11/17 11:59:55AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.1900 (1.5626)	Arch Loss 1.9186 (2.2571)	Arch Hard Loss 1.6836 (2.0296)	Arch Beta Loss 0.0157 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.4%, 86.1%)	
11/17 12:01:43PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6646 (1.5835)	Arch Loss 2.2052 (2.2494)	Arch Hard Loss 1.9671 (2.0220)	Arch Beta Loss 0.0159 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.6%)	
11/17 12:01:44PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 20/49] Final Prec@1 54.9320%
11/17 12:02:05PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9868	Prec@(1,5) (47.1%, 78.2%)
11/17 12:02:22PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9851	Prec@(1,5) (47.0%, 78.4%)
11/17 12:02:43PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9883	Prec@(1,5) (47.1%, 78.1%)
11/17 12:03:01PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9918	Prec@(1,5) (47.0%, 78.0%)
11/17 12:03:01PM searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 47.0280%
11/17 12:03:02PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[4, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:03:02PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0280%
11/17 12:05:02PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.4010 (1.4554)	Arch Loss 2.8016 (2.2298)	Arch Hard Loss 2.5651 (2.0031)	Arch Beta Loss 0.0158 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.9%)	
11/17 12:07:02PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4989 (1.4925)	Arch Loss 2.6022 (2.2313)	Arch Hard Loss 2.4042 (2.0048)	Arch Beta Loss 0.0132 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 87.0%)	
11/17 12:09:03PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.5287 (1.5153)	Arch Loss 1.9576 (2.2217)	Arch Hard Loss 1.7474 (1.9951)	Arch Beta Loss 0.0140 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.6%)	
11/17 12:10:52PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.7272 (1.5295)	Arch Loss 2.0389 (2.2278)	Arch Hard Loss 1.8316 (2.0012)	Arch Beta Loss 0.0138 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.4%, 86.3%)	
11/17 12:10:53PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 21/49] Final Prec@1 56.4040%
11/17 12:11:13PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9621	Prec@(1,5) (48.0%, 77.9%)
11/17 12:11:33PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9733	Prec@(1,5) (47.6%, 77.9%)
11/17 12:11:54PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9666	Prec@(1,5) (47.7%, 78.2%)
11/17 12:12:12PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9631	Prec@(1,5) (47.7%, 78.2%)
11/17 12:12:12PM searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 47.6720%
11/17 12:12:12PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:12:13PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.6720%
11/17 12:14:13PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.7152 (1.4024)	Arch Loss 2.3684 (2.2522)	Arch Hard Loss 2.1232 (2.0255)	Arch Beta Loss 0.0164 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.7%)	
11/17 12:16:14PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4277 (1.4420)	Arch Loss 2.1575 (2.2183)	Arch Hard Loss 1.9045 (1.9916)	Arch Beta Loss 0.0169 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.4%, 88.0%)	
11/17 12:18:14PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.2841 (1.4600)	Arch Loss 2.6617 (2.2082)	Arch Hard Loss 2.4271 (1.9814)	Arch Beta Loss 0.0156 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.7%)	
11/17 12:20:03PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.6512 (1.4762)	Arch Loss 2.1809 (2.2036)	Arch Hard Loss 1.9717 (1.9770)	Arch Beta Loss 0.0139 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 87.3%)	
11/17 12:20:04PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 22/49] Final Prec@1 57.5080%
11/17 12:20:24PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9319	Prec@(1,5) (49.0%, 79.0%)
11/17 12:20:44PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9260	Prec@(1,5) (48.5%, 79.0%)
11/17 12:21:05PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9265	Prec@(1,5) (48.6%, 79.1%)
11/17 12:21:23PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9382	Prec@(1,5) (48.5%, 78.9%)
11/17 12:21:23PM searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 48.4720%
11/17 12:21:23PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:21:24PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4720%
11/17 12:23:24PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.3154 (1.3430)	Arch Loss 1.7681 (2.1683)	Arch Hard Loss 1.5300 (1.9418)	Arch Beta Loss 0.0159 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.8%, 89.6%)	
11/17 12:25:25PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.4684 (1.3947)	Arch Loss 2.4637 (2.1703)	Arch Hard Loss 2.2537 (1.9446)	Arch Beta Loss 0.0140 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.4%)	
11/17 12:27:25PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.5057 (1.4128)	Arch Loss 1.9767 (2.1844)	Arch Hard Loss 1.7683 (1.9590)	Arch Beta Loss 0.0139 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 88.2%)	
11/17 12:29:14PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4995 (1.4305)	Arch Loss 2.4497 (2.1821)	Arch Hard Loss 2.2407 (1.9570)	Arch Beta Loss 0.0139 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.9%)	
11/17 12:29:15PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 23/49] Final Prec@1 58.8400%
11/17 12:29:35PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8987	Prec@(1,5) (48.5%, 79.3%)
11/17 12:29:55PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9108	Prec@(1,5) (48.3%, 79.6%)
11/17 12:30:16PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9245	Prec@(1,5) (48.1%, 79.1%)
11/17 12:30:34PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9379	Prec@(1,5) (48.1%, 79.1%)
11/17 12:30:34PM searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 48.1360%
11/17 12:30:34PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:30:35PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4720%
11/17 12:32:34PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0689 (1.3257)	Arch Loss 2.2906 (2.1583)	Arch Hard Loss 2.0755 (1.9348)	Arch Beta Loss 0.0143 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.4%)	
11/17 12:34:35PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.5704 (1.3545)	Arch Loss 2.3129 (2.1729)	Arch Hard Loss 2.0955 (1.9492)	Arch Beta Loss 0.0145 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.9%)	
11/17 12:36:36PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6989 (1.3651)	Arch Loss 2.1842 (2.1749)	Arch Hard Loss 1.9716 (1.9512)	Arch Beta Loss 0.0142 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.8%)	
11/17 12:38:24PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.1192 (1.3794)	Arch Loss 1.8713 (2.1764)	Arch Hard Loss 1.6359 (1.9526)	Arch Beta Loss 0.0157 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.5%)	
11/17 12:38:25PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 24/49] Final Prec@1 60.3280%
11/17 12:38:46PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8967	Prec@(1,5) (49.5%, 80.1%)
11/17 12:39:06PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8978	Prec@(1,5) (49.5%, 79.9%)
11/17 12:39:26PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9071	Prec@(1,5) (49.0%, 79.6%)
11/17 12:39:44PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9021	Prec@(1,5) (49.1%, 79.6%)
11/17 12:39:44PM searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 49.1160%
11/17 12:39:45PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:39:45PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1160%
11/17 12:41:45PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.5199 (1.2891)	Arch Loss 2.3329 (2.1307)	Arch Hard Loss 2.1420 (1.9061)	Arch Beta Loss 0.0127 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.6%)	
11/17 12:43:46PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3489 (1.3092)	Arch Loss 2.4724 (2.1345)	Arch Hard Loss 2.2580 (1.9097)	Arch Beta Loss 0.0143 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.5%)	
11/17 12:45:47PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.1216 (1.3224)	Arch Loss 1.5839 (2.1486)	Arch Hard Loss 1.3641 (1.9238)	Arch Beta Loss 0.0147 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.4%)	
11/17 12:47:35PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.2347 (1.3326)	Arch Loss 1.6333 (2.1437)	Arch Hard Loss 1.4178 (1.9188)	Arch Beta Loss 0.0144 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.2%)	
11/17 12:47:36PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 25/49] Final Prec@1 61.6680%
11/17 12:47:57PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8939	Prec@(1,5) (50.0%, 80.2%)
11/17 12:48:17PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8956	Prec@(1,5) (50.0%, 79.8%)
11/17 12:48:37PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8769	Prec@(1,5) (49.9%, 80.2%)
11/17 12:48:55PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8808	Prec@(1,5) (49.7%, 80.3%)
11/17 12:48:56PM searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 49.6920%
11/17 12:48:56PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:48:56PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.6920%
11/17 12:50:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.6226 (1.2359)	Arch Loss 1.9352 (2.0572)	Arch Hard Loss 1.6861 (1.8317)	Arch Beta Loss 0.0166 (0.0150)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.7%)	
11/17 12:52:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.8840 (1.2679)	Arch Loss 2.1477 (2.0984)	Arch Hard Loss 1.9023 (1.8722)	Arch Beta Loss 0.0164 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.1%)	
11/17 12:54:57PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.1753 (1.2702)	Arch Loss 2.0215 (2.1205)	Arch Hard Loss 1.7564 (1.8942)	Arch Beta Loss 0.0177 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.2%)	
11/17 12:56:46PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0446 (1.2946)	Arch Loss 2.3732 (2.1307)	Arch Hard Loss 2.1279 (1.9042)	Arch Beta Loss 0.0164 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.8%)	
11/17 12:56:46PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 26/49] Final Prec@1 62.3200%
11/17 12:57:07PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8438	Prec@(1,5) (50.7%, 81.0%)
11/17 12:57:27PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8478	Prec@(1,5) (50.7%, 80.8%)
11/17 12:57:47PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8495	Prec@(1,5) (50.8%, 80.7%)
11/17 12:58:06PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8541	Prec@(1,5) (50.5%, 80.6%)
11/17 12:58:06PM searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 50.5200%
11/17 12:58:06PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 12:58:07PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.5200%
11/17 01:00:07PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.1113 (1.1675)	Arch Loss 2.6870 (2.1290)	Arch Hard Loss 2.4831 (1.9021)	Arch Beta Loss 0.0136 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.6%)	
11/17 01:02:07PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.4213 (1.2074)	Arch Loss 2.0906 (2.1166)	Arch Hard Loss 1.8818 (1.8890)	Arch Beta Loss 0.0139 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.9%)	
11/17 01:04:08PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1705 (1.2202)	Arch Loss 2.2586 (2.1145)	Arch Hard Loss 2.0386 (1.8866)	Arch Beta Loss 0.0147 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.8%)	
11/17 01:05:57PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.2424 (1.2344)	Arch Loss 2.0077 (2.1124)	Arch Hard Loss 1.7818 (1.8843)	Arch Beta Loss 0.0151 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.4%)	
11/17 01:05:57PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 27/49] Final Prec@1 64.0520%
11/17 01:06:18PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8845	Prec@(1,5) (49.5%, 80.1%)
11/17 01:06:38PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8772	Prec@(1,5) (50.0%, 80.2%)
11/17 01:06:58PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8741	Prec@(1,5) (50.0%, 80.4%)
11/17 01:07:17PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8680	Prec@(1,5) (50.0%, 80.5%)
11/17 01:07:17PM searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 49.9560%
11/17 01:07:17PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 01:07:18PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.5200%
11/17 01:09:17PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.4618 (1.1442)	Arch Loss 1.9020 (2.0751)	Arch Hard Loss 1.6643 (1.8468)	Arch Beta Loss 0.0159 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.4%)	
11/17 01:11:18PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 0.9129 (1.1586)	Arch Loss 1.8024 (2.0894)	Arch Hard Loss 1.5679 (1.8609)	Arch Beta Loss 0.0156 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.4%)	
11/17 01:13:19PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.3216 (1.1664)	Arch Loss 1.8499 (2.1106)	Arch Hard Loss 1.6443 (1.8816)	Arch Beta Loss 0.0137 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.3%)	
11/17 01:15:07PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.0395 (1.1893)	Arch Loss 1.7261 (2.1204)	Arch Hard Loss 1.4775 (1.8912)	Arch Beta Loss 0.0166 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.0%)	
11/17 01:15:08PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 28/49] Final Prec@1 65.4840%
11/17 01:15:29PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8574	Prec@(1,5) (50.5%, 80.6%)
11/17 01:15:48PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8720	Prec@(1,5) (50.2%, 80.5%)
11/17 01:16:09PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8451	Prec@(1,5) (51.0%, 80.8%)
11/17 01:16:27PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8458	Prec@(1,5) (51.0%, 80.7%)
11/17 01:16:27PM searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 51.0520%
11/17 01:16:28PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 01:16:28PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0520%
11/17 01:18:28PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.0916 (1.1067)	Arch Loss 2.0662 (2.1257)	Arch Hard Loss 1.8321 (1.8944)	Arch Beta Loss 0.0156 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.5%)	
11/17 01:20:29PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.8782 (1.1161)	Arch Loss 1.8484 (2.1207)	Arch Hard Loss 1.6317 (1.8899)	Arch Beta Loss 0.0144 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 92.3%)	
11/17 01:22:29PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1674 (1.1372)	Arch Loss 2.2558 (2.1113)	Arch Hard Loss 2.0477 (1.8804)	Arch Beta Loss 0.0139 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.0%)	
11/17 01:24:18PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0452 (1.1465)	Arch Loss 2.0471 (2.1070)	Arch Hard Loss 1.8591 (1.8762)	Arch Beta Loss 0.0125 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.8%)	
11/17 01:24:19PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 29/49] Final Prec@1 66.3160%
11/17 01:24:39PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8402	Prec@(1,5) (51.7%, 80.5%)
11/17 01:24:59PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8133	Prec@(1,5) (52.4%, 81.2%)
11/17 01:25:20PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8246	Prec@(1,5) (51.9%, 81.2%)
11/17 01:25:38PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8152	Prec@(1,5) (52.0%, 81.3%)
11/17 01:25:38PM searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 51.9480%
11/17 01:25:39PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 01:25:39PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9480%
11/17 01:27:39PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.0711 (1.0507)	Arch Loss 1.7582 (2.0805)	Arch Hard Loss 1.5168 (1.8489)	Arch Beta Loss 0.0161 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
11/17 01:29:39PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.3803 (1.0552)	Arch Loss 2.5497 (2.0974)	Arch Hard Loss 2.2612 (1.8656)	Arch Beta Loss 0.0192 (0.0155)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.1%)	
11/17 01:31:40PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.2452 (1.0739)	Arch Loss 2.0403 (2.0884)	Arch Hard Loss 1.7749 (1.8568)	Arch Beta Loss 0.0177 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
11/17 01:33:28PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0944 (1.0977)	Arch Loss 2.7178 (2.0948)	Arch Hard Loss 2.4930 (1.8635)	Arch Beta Loss 0.0150 (0.0154)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.4%)	
11/17 01:33:29PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 30/49] Final Prec@1 67.7680%
11/17 01:33:50PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8443	Prec@(1,5) (51.1%, 81.0%)
11/17 01:34:10PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8335	Prec@(1,5) (51.5%, 81.1%)
11/17 01:34:30PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8363	Prec@(1,5) (51.4%, 81.0%)
11/17 01:34:48PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8298	Prec@(1,5) (51.5%, 81.2%)
11/17 01:34:49PM searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 51.5080%
11/17 01:34:49PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 01:34:49PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9480%
11/17 01:36:49PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9723 (1.0102)	Arch Loss 2.3443 (2.0716)	Arch Hard Loss 2.1489 (1.8421)	Arch Beta Loss 0.0130 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.4%)	
11/17 01:38:50PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9201 (1.0217)	Arch Loss 2.0865 (2.1037)	Arch Hard Loss 1.8743 (1.8743)	Arch Beta Loss 0.0141 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.5%)	
11/17 01:40:50PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.2768 (1.0563)	Arch Loss 2.1941 (2.1080)	Arch Hard Loss 1.9816 (1.8788)	Arch Beta Loss 0.0142 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.0%)	
11/17 01:42:39PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3009 (1.0728)	Arch Loss 2.0293 (2.1001)	Arch Hard Loss 1.8016 (1.8708)	Arch Beta Loss 0.0152 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.6%)	
11/17 01:42:40PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 31/49] Final Prec@1 68.4280%
11/17 01:43:00PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8056	Prec@(1,5) (52.3%, 81.8%)
11/17 01:43:20PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8047	Prec@(1,5) (52.3%, 81.7%)
11/17 01:43:40PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8124	Prec@(1,5) (52.2%, 81.6%)
11/17 01:43:59PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8193	Prec@(1,5) (52.1%, 81.4%)
11/17 01:43:59PM searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 52.1000%
11/17 01:43:59PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 01:44:00PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.1000%
11/17 01:46:00PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.2135 (0.9880)	Arch Loss 1.7843 (2.0677)	Arch Hard Loss 1.5482 (1.8393)	Arch Beta Loss 0.0157 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
11/17 01:48:00PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9128 (0.9993)	Arch Loss 2.1927 (2.0774)	Arch Hard Loss 1.9898 (1.8490)	Arch Beta Loss 0.0135 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.7%)	
11/17 01:50:01PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.7950 (1.0011)	Arch Loss 2.0277 (2.0806)	Arch Hard Loss 1.7752 (1.8526)	Arch Beta Loss 0.0168 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.7%)	
11/17 01:51:50PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.1624 (1.0162)	Arch Loss 1.9819 (2.0710)	Arch Hard Loss 1.7164 (1.8432)	Arch Beta Loss 0.0177 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.5%)	
11/17 01:51:50PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 32/49] Final Prec@1 70.2800%
11/17 01:52:11PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8266	Prec@(1,5) (52.2%, 82.0%)
11/17 01:52:31PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8125	Prec@(1,5) (52.9%, 81.9%)
11/17 01:52:51PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8042	Prec@(1,5) (52.9%, 81.8%)
11/17 01:53:10PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8003	Prec@(1,5) (53.0%, 82.0%)
11/17 01:53:10PM searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 53.0520%
11/17 01:53:10PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 01:53:11PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.0520%
11/17 01:54:51PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7665 (0.9162)	Arch Loss 2.0586 (2.0561)	Arch Hard Loss 1.8458 (1.8295)	Arch Beta Loss 0.0142 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.0%)	
11/17 01:56:51PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8429 (0.9505)	Arch Loss 1.8516 (2.0443)	Arch Hard Loss 1.6508 (1.8173)	Arch Beta Loss 0.0134 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.4%)	
11/17 01:58:52PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.1552 (0.9647)	Arch Loss 2.4983 (2.0731)	Arch Hard Loss 2.2786 (1.8462)	Arch Beta Loss 0.0146 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.3%)	
11/17 02:00:38PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.0393 (0.9759)	Arch Loss 1.9495 (2.0738)	Arch Hard Loss 1.7324 (1.8471)	Arch Beta Loss 0.0145 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.1%)	
11/17 02:00:39PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 33/49] Final Prec@1 71.3280%
11/17 02:01:00PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7941	Prec@(1,5) (52.7%, 81.2%)
11/17 02:01:18PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7747	Prec@(1,5) (53.5%, 81.6%)
11/17 02:01:39PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7761	Prec@(1,5) (53.3%, 81.8%)
11/17 02:01:57PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7747	Prec@(1,5) (53.3%, 81.8%)
11/17 02:01:57PM searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 53.2960%
11/17 02:01:58PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:01:58PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2960%
11/17 02:04:00PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8014 (0.8888)	Arch Loss 2.2831 (2.0138)	Arch Hard Loss 2.0218 (1.7872)	Arch Beta Loss 0.0174 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.0%)	
11/17 02:06:00PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.6595 (0.9187)	Arch Loss 2.0472 (2.0362)	Arch Hard Loss 1.7847 (1.8094)	Arch Beta Loss 0.0175 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
11/17 02:08:01PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0166 (0.9306)	Arch Loss 2.5168 (2.0529)	Arch Hard Loss 2.2673 (1.8259)	Arch Beta Loss 0.0166 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.5%)	
11/17 02:09:48PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.8925 (0.9418)	Arch Loss 2.1961 (2.0560)	Arch Hard Loss 1.9746 (1.8290)	Arch Beta Loss 0.0148 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.4%)	
11/17 02:09:49PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 34/49] Final Prec@1 72.3520%
11/17 02:10:10PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8113	Prec@(1,5) (53.5%, 81.9%)
11/17 02:10:30PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7983	Prec@(1,5) (53.2%, 81.9%)
11/17 02:10:50PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7898	Prec@(1,5) (53.4%, 81.9%)
11/17 02:11:09PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7912	Prec@(1,5) (53.3%, 82.0%)
11/17 02:11:09PM searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 53.2720%
11/17 02:11:09PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:11:09PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2960%
11/17 02:13:11PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.9561 (0.8566)	Arch Loss 1.8460 (2.0460)	Arch Hard Loss 1.6375 (1.8185)	Arch Beta Loss 0.0139 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.3%)	
11/17 02:15:12PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.1701 (0.8817)	Arch Loss 2.0017 (2.0477)	Arch Hard Loss 1.7808 (1.8205)	Arch Beta Loss 0.0147 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
11/17 02:17:11PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0653 (0.8964)	Arch Loss 2.1279 (2.0447)	Arch Hard Loss 1.9442 (1.8178)	Arch Beta Loss 0.0122 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.8%)	
11/17 02:19:00PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1733 (0.9016)	Arch Loss 1.7132 (2.0586)	Arch Hard Loss 1.5078 (1.8319)	Arch Beta Loss 0.0137 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.8%)	
11/17 02:19:01PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 35/49] Final Prec@1 73.3840%
11/17 02:19:22PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7919	Prec@(1,5) (53.1%, 82.0%)
11/17 02:19:42PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7977	Prec@(1,5) (52.9%, 81.9%)
11/17 02:20:02PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7987	Prec@(1,5) (53.0%, 81.9%)
11/17 02:20:21PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8016	Prec@(1,5) (52.8%, 82.0%)
11/17 02:20:21PM searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 52.8480%
11/17 02:20:21PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:20:21PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2960%
11/17 02:22:21PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.9061 (0.8203)	Arch Loss 2.1640 (2.0667)	Arch Hard Loss 1.9489 (1.8406)	Arch Beta Loss 0.0143 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.9%)	
11/17 02:24:22PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.9577 (0.8481)	Arch Loss 1.6344 (2.0577)	Arch Hard Loss 1.3901 (1.8314)	Arch Beta Loss 0.0163 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.6%)	
11/17 02:26:23PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7736 (0.8559)	Arch Loss 2.1593 (2.0632)	Arch Hard Loss 1.9213 (1.8366)	Arch Beta Loss 0.0159 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.4%)	
11/17 02:28:12PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6900 (0.8577)	Arch Loss 1.8407 (2.0689)	Arch Hard Loss 1.5875 (1.8420)	Arch Beta Loss 0.0169 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.3%)	
11/17 02:28:13PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 36/49] Final Prec@1 74.7920%
11/17 02:28:33PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7771	Prec@(1,5) (53.4%, 82.2%)
11/17 02:28:54PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7793	Prec@(1,5) (53.8%, 82.4%)
11/17 02:29:14PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7881	Prec@(1,5) (53.7%, 82.3%)
11/17 02:29:30PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7956	Prec@(1,5) (53.4%, 82.2%)
11/17 02:29:30PM searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 53.4600%
11/17 02:29:31PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 10], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:29:31PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4600%
11/17 02:31:33PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.6800 (0.7923)	Arch Loss 2.3281 (2.0707)	Arch Hard Loss 2.1281 (1.8431)	Arch Beta Loss 0.0133 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.2%)	
11/17 02:33:34PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.7177 (0.8010)	Arch Loss 2.1431 (2.0438)	Arch Hard Loss 1.9273 (1.8159)	Arch Beta Loss 0.0144 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.4%, 96.2%)	
11/17 02:35:34PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8057 (0.8162)	Arch Loss 1.9750 (2.0572)	Arch Hard Loss 1.7592 (1.8296)	Arch Beta Loss 0.0144 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.9%)	
11/17 02:37:22PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.6054 (0.8204)	Arch Loss 1.9673 (2.0539)	Arch Hard Loss 1.7545 (1.8264)	Arch Beta Loss 0.0142 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.9%)	
11/17 02:37:23PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 37/49] Final Prec@1 75.7840%
11/17 02:37:44PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7909	Prec@(1,5) (53.1%, 82.5%)
11/17 02:38:04PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7880	Prec@(1,5) (53.5%, 82.4%)
11/17 02:38:25PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7911	Prec@(1,5) (53.6%, 82.4%)
11/17 02:38:43PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7984	Prec@(1,5) (53.4%, 82.2%)
11/17 02:38:43PM searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 53.4160%
11/17 02:38:43PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:38:44PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4600%
11/17 02:40:45PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6883 (0.7666)	Arch Loss 1.6300 (2.0351)	Arch Hard Loss 1.3784 (1.8077)	Arch Beta Loss 0.0168 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.4%)	
11/17 02:42:46PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.6435 (0.7771)	Arch Loss 2.3191 (2.0276)	Arch Hard Loss 2.0775 (1.8004)	Arch Beta Loss 0.0161 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.2%)	
11/17 02:44:46PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8863 (0.7824)	Arch Loss 2.1027 (2.0313)	Arch Hard Loss 1.8529 (1.8039)	Arch Beta Loss 0.0166 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.2%)	
11/17 02:46:34PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6473 (0.7892)	Arch Loss 2.2789 (2.0495)	Arch Hard Loss 2.0606 (1.8221)	Arch Beta Loss 0.0146 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.2%)	
11/17 02:46:35PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 38/49] Final Prec@1 76.6600%
11/17 02:46:56PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7753	Prec@(1,5) (54.1%, 82.4%)
11/17 02:47:16PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7726	Prec@(1,5) (53.5%, 82.6%)
11/17 02:47:37PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7722	Prec@(1,5) (53.7%, 82.7%)
11/17 02:47:55PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7716	Prec@(1,5) (53.8%, 82.6%)
11/17 02:47:55PM searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 53.7560%
11/17 02:47:55PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[4, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:47:56PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7560%
11/17 02:49:57PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.6965 (0.7178)	Arch Loss 1.9214 (2.0407)	Arch Hard Loss 1.7064 (1.8131)	Arch Beta Loss 0.0143 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.9%)	
11/17 02:51:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.5182 (0.7305)	Arch Loss 2.0543 (2.0252)	Arch Hard Loss 1.8635 (1.7979)	Arch Beta Loss 0.0127 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/17 02:53:57PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.5434 (0.7428)	Arch Loss 2.4523 (2.0405)	Arch Hard Loss 2.2462 (1.8131)	Arch Beta Loss 0.0137 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.5%)	
11/17 02:55:46PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.7623 (0.7495)	Arch Loss 2.1834 (2.0407)	Arch Hard Loss 1.9759 (1.8134)	Arch Beta Loss 0.0138 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.5%)	
11/17 02:55:47PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 39/49] Final Prec@1 78.2360%
11/17 02:56:08PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7608	Prec@(1,5) (54.2%, 83.0%)
11/17 02:56:28PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7652	Prec@(1,5) (54.4%, 82.8%)
11/17 02:56:48PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7656	Prec@(1,5) (54.6%, 82.8%)
11/17 02:57:06PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7660	Prec@(1,5) (54.4%, 82.8%)
11/17 02:57:06PM searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 54.4080%
11/17 02:57:06PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[5, 9], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 02:57:07PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4080%
11/17 02:59:07PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.7348 (0.7045)	Arch Loss 2.3500 (2.0699)	Arch Hard Loss 2.1280 (1.8417)	Arch Beta Loss 0.0148 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.9%)	
11/17 03:01:08PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.6896 (0.7075)	Arch Loss 2.1938 (2.0584)	Arch Hard Loss 1.9555 (1.8299)	Arch Beta Loss 0.0159 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
11/17 03:03:09PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.5672 (0.7223)	Arch Loss 1.8891 (2.0615)	Arch Hard Loss 1.6723 (1.8325)	Arch Beta Loss 0.0145 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.9%)	
11/17 03:04:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.0748 (0.7240)	Arch Loss 1.8956 (2.0461)	Arch Hard Loss 1.6420 (1.8167)	Arch Beta Loss 0.0169 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/17 03:04:57PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 40/49] Final Prec@1 78.8920%
11/17 03:05:18PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7384	Prec@(1,5) (54.3%, 83.0%)
11/17 03:05:38PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7410	Prec@(1,5) (54.4%, 83.0%)
11/17 03:05:58PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7447	Prec@(1,5) (54.3%, 82.8%)
11/17 03:06:17PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7491	Prec@(1,5) (54.1%, 82.9%)
11/17 03:06:17PM searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 54.1400%
11/17 03:06:17PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 03:06:17PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4080%
11/17 03:08:19PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.5886 (0.6652)	Arch Loss 2.0252 (2.0594)	Arch Hard Loss 1.8118 (1.8303)	Arch Beta Loss 0.0142 (0.0153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
11/17 03:10:20PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5022 (0.6777)	Arch Loss 1.9526 (2.0460)	Arch Hard Loss 1.7327 (1.8177)	Arch Beta Loss 0.0147 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.2%)	
11/17 03:12:19PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5896 (0.6788)	Arch Loss 1.9357 (2.0455)	Arch Hard Loss 1.7260 (1.8181)	Arch Beta Loss 0.0140 (0.0152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
11/17 03:14:08PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.8138 (0.6881)	Arch Loss 1.7381 (2.0441)	Arch Hard Loss 1.5482 (1.8173)	Arch Beta Loss 0.0127 (0.0151)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
11/17 03:14:09PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 41/49] Final Prec@1 80.2240%
11/17 03:14:30PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7523	Prec@(1,5) (55.0%, 82.7%)
11/17 03:14:50PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7632	Prec@(1,5) (54.5%, 82.7%)
11/17 03:15:11PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7582	Prec@(1,5) (54.5%, 82.7%)
11/17 03:15:29PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7622	Prec@(1,5) (54.5%, 82.7%)
11/17 03:15:29PM searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 54.5000%
11/17 03:15:29PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 03:15:30PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5000%
11/17 03:17:32PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6723 (0.6411)	Arch Loss 1.8498 (2.0509)	Arch Hard Loss 1.6040 (1.8273)	Arch Beta Loss 0.0164 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.8%)	
11/17 03:19:31PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7284 (0.6452)	Arch Loss 1.8779 (2.0285)	Arch Hard Loss 1.6202 (1.8049)	Arch Beta Loss 0.0172 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/17 03:21:32PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6666 (0.6594)	Arch Loss 2.1694 (2.0260)	Arch Hard Loss 1.9199 (1.8030)	Arch Beta Loss 0.0166 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/17 03:23:21PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5348 (0.6668)	Arch Loss 2.2381 (2.0274)	Arch Hard Loss 2.0017 (1.8048)	Arch Beta Loss 0.0158 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.3%)	
11/17 03:23:21PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 42/49] Final Prec@1 81.2440%
11/17 03:23:42PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7103	Prec@(1,5) (55.5%, 83.6%)
11/17 03:24:02PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7523	Prec@(1,5) (54.7%, 83.1%)
11/17 03:24:23PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7526	Prec@(1,5) (54.8%, 83.1%)
11/17 03:24:41PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7538	Prec@(1,5) (54.8%, 83.1%)
11/17 03:24:41PM searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 54.8280%
11/17 03:24:42PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 03:24:42PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8280%
11/17 03:26:42PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7244 (0.6280)	Arch Loss 1.9700 (2.0217)	Arch Hard Loss 1.7927 (1.8004)	Arch Beta Loss 0.0118 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
11/17 03:28:43PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.6511 (0.6425)	Arch Loss 1.9226 (2.0210)	Arch Hard Loss 1.7331 (1.7992)	Arch Beta Loss 0.0126 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.5%)	
11/17 03:30:44PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7630 (0.6407)	Arch Loss 2.2700 (2.0273)	Arch Hard Loss 2.0686 (1.8050)	Arch Beta Loss 0.0134 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
11/17 03:32:33PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.6265 (0.6434)	Arch Loss 1.6583 (2.0248)	Arch Hard Loss 1.4293 (1.8021)	Arch Beta Loss 0.0153 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.5%)	
11/17 03:32:34PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 43/49] Final Prec@1 81.6440%
11/17 03:32:54PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7373	Prec@(1,5) (54.8%, 83.5%)
11/17 03:33:15PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7339	Prec@(1,5) (54.9%, 83.5%)
11/17 03:33:34PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7353	Prec@(1,5) (54.9%, 83.4%)
11/17 03:33:52PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7499	Prec@(1,5) (54.8%, 83.1%)
11/17 03:33:52PM searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 54.8280%
11/17 03:33:52PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 03:33:53PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8280%
11/17 03:35:54PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5334 (0.6102)	Arch Loss 2.2312 (1.9980)	Arch Hard Loss 1.9868 (1.7751)	Arch Beta Loss 0.0163 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.8%)	
11/17 03:37:55PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8318 (0.6192)	Arch Loss 2.3939 (2.0129)	Arch Hard Loss 2.1571 (1.7900)	Arch Beta Loss 0.0158 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
11/17 03:39:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.4956 (0.6272)	Arch Loss 2.0494 (2.0209)	Arch Hard Loss 1.7980 (1.7982)	Arch Beta Loss 0.0168 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
11/17 03:41:44PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.4633 (0.6282)	Arch Loss 2.1155 (2.0203)	Arch Hard Loss 1.8585 (1.7977)	Arch Beta Loss 0.0171 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
11/17 03:41:45PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 44/49] Final Prec@1 82.5040%
11/17 03:42:06PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.7165	Prec@(1,5) (55.2%, 83.7%)
11/17 03:42:26PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7502	Prec@(1,5) (54.8%, 83.4%)
11/17 03:42:46PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7420	Prec@(1,5) (55.0%, 83.2%)
11/17 03:43:05PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7524	Prec@(1,5) (54.8%, 83.1%)
11/17 03:43:05PM searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 54.8480%
11/17 03:43:05PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 03:43:06PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8480%
11/17 03:45:08PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4637 (0.6125)	Arch Loss 1.6034 (2.0112)	Arch Hard Loss 1.3883 (1.7892)	Arch Beta Loss 0.0143 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.6%)	
11/17 03:47:08PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.6748 (0.6071)	Arch Loss 2.0508 (2.0078)	Arch Hard Loss 1.8617 (1.7856)	Arch Beta Loss 0.0126 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.7%)	
11/17 03:49:08PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7506 (0.6071)	Arch Loss 2.3533 (2.0150)	Arch Hard Loss 2.1614 (1.7926)	Arch Beta Loss 0.0128 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.7%)	
11/17 03:50:57PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6360 (0.6120)	Arch Loss 2.0211 (2.0249)	Arch Hard Loss 1.8348 (1.8023)	Arch Beta Loss 0.0124 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.7%)	
11/17 03:50:58PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 45/49] Final Prec@1 82.8040%
11/17 03:51:19PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6988	Prec@(1,5) (55.9%, 83.8%)
11/17 03:51:39PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7439	Prec@(1,5) (55.2%, 83.4%)
11/17 03:52:00PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7561	Prec@(1,5) (54.9%, 83.0%)
11/17 03:52:18PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7516	Prec@(1,5) (54.8%, 83.1%)
11/17 03:52:18PM searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 54.8400%
11/17 03:52:19PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 03:52:19PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8480%
11/17 03:54:20PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6773 (0.5581)	Arch Loss 1.8205 (2.0324)	Arch Hard Loss 1.5638 (1.8096)	Arch Beta Loss 0.0171 (0.0149)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.1%)	
11/17 03:56:20PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5506 (0.5779)	Arch Loss 2.1686 (2.0236)	Arch Hard Loss 1.9269 (1.8014)	Arch Beta Loss 0.0161 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/17 03:58:21PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5073 (0.5827)	Arch Loss 1.8774 (2.0276)	Arch Hard Loss 1.6445 (1.8056)	Arch Beta Loss 0.0155 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
11/17 04:00:09PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.4789 (0.5884)	Arch Loss 2.3228 (2.0235)	Arch Hard Loss 2.0837 (1.8019)	Arch Beta Loss 0.0159 (0.0148)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 97.9%)	
11/17 04:00:10PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 46/49] Final Prec@1 83.8480%
11/17 04:00:31PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7533	Prec@(1,5) (54.9%, 83.0%)
11/17 04:00:51PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7459	Prec@(1,5) (55.0%, 83.0%)
11/17 04:01:11PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7537	Prec@(1,5) (55.0%, 83.1%)
11/17 04:01:30PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7481	Prec@(1,5) (55.1%, 83.2%)
11/17 04:01:30PM searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 55.0960%
11/17 04:01:30PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[4, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 04:01:31PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0960%
11/17 04:03:31PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.6258 (0.5931)	Arch Loss 1.3907 (2.0140)	Arch Hard Loss 1.2084 (1.7944)	Arch Beta Loss 0.0122 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 98.1%)	
11/17 04:05:32PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6253 (0.5844)	Arch Loss 1.8118 (2.0285)	Arch Hard Loss 1.6123 (1.8092)	Arch Beta Loss 0.0133 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
11/17 04:07:33PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5306 (0.5897)	Arch Loss 1.3677 (2.0238)	Arch Hard Loss 1.1796 (1.8043)	Arch Beta Loss 0.0125 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.1%)	
11/17 04:09:20PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.6360 (0.5927)	Arch Loss 2.2212 (2.0249)	Arch Hard Loss 2.0289 (1.8055)	Arch Beta Loss 0.0128 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.1%)	
11/17 04:09:21PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 47/49] Final Prec@1 83.5640%
11/17 04:09:42PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7359	Prec@(1,5) (55.2%, 83.0%)
11/17 04:10:02PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7321	Prec@(1,5) (55.0%, 83.4%)
11/17 04:10:23PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7406	Prec@(1,5) (54.9%, 83.4%)
11/17 04:10:41PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7443	Prec@(1,5) (54.9%, 83.3%)
11/17 04:10:41PM searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 54.9160%
11/17 04:10:41PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[3, 8], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 04:10:42PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0960%
11/17 04:12:43PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5145 (0.5621)	Arch Loss 2.0378 (2.0063)	Arch Hard Loss 1.8055 (1.7873)	Arch Beta Loss 0.0155 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.2%)	
11/17 04:14:45PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5600 (0.5710)	Arch Loss 2.3441 (2.0211)	Arch Hard Loss 2.0883 (1.8019)	Arch Beta Loss 0.0171 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.1%)	
11/17 04:16:44PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.7376 (0.5804)	Arch Loss 2.2524 (2.0143)	Arch Hard Loss 2.0012 (1.7952)	Arch Beta Loss 0.0167 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.0%)	
11/17 04:18:32PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6234 (0.5863)	Arch Loss 2.1350 (2.0164)	Arch Hard Loss 1.8896 (1.7971)	Arch Beta Loss 0.0164 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.0%)	
11/17 04:18:33PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 48/49] Final Prec@1 84.0720%
11/17 04:18:54PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7738	Prec@(1,5) (54.8%, 83.3%)
11/17 04:19:14PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7416	Prec@(1,5) (55.0%, 83.6%)
11/17 04:19:35PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7325	Prec@(1,5) (55.1%, 83.6%)
11/17 04:19:53PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7390	Prec@(1,5) (55.2%, 83.5%)
11/17 04:19:53PM searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 55.1680%
11/17 04:19:53PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 04:19:54PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.1680%
11/17 04:21:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4694 (0.5678)	Arch Loss 1.9964 (2.0051)	Arch Hard Loss 1.8160 (1.7855)	Arch Beta Loss 0.0120 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.2%)	
11/17 04:23:55PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4463 (0.5657)	Arch Loss 1.8667 (2.0176)	Arch Hard Loss 1.6822 (1.7980)	Arch Beta Loss 0.0123 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.2%)	
11/17 04:25:56PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.4547 (0.5731)	Arch Loss 2.1739 (2.0202)	Arch Hard Loss 1.9677 (1.8009)	Arch Beta Loss 0.0137 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.0%)	
11/17 04:27:44PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6803 (0.5782)	Arch Loss 1.4454 (2.0225)	Arch Hard Loss 1.2469 (1.8034)	Arch Beta Loss 0.0132 (0.0146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.0%)	
11/17 04:27:45PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 49/49] Final Prec@1 84.2880%
11/17 04:28:06PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7314	Prec@(1,5) (55.1%, 83.2%)
11/17 04:28:26PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7408	Prec@(1,5) (55.3%, 83.1%)
11/17 04:28:47PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7548	Prec@(1,5) (55.0%, 83.0%)
11/17 04:29:05PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7453	Prec@(1,5) (55.2%, 83.2%)
11/17 04:29:05PM searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 55.2080%
11/17 04:29:05PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
11/17 04:29:06PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2080%
11/17 04:29:06PM trainer_runner.py:110 [INFO] Final best Prec@1 = 55.2080%
11/17 04:29:06PM trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[5, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 7])
