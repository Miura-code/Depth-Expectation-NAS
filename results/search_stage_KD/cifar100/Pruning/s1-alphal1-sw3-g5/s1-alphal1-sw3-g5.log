11/20 08:35:19AM parser.py:28 [INFO] 
11/20 08:35:19AM parser.py:29 [INFO] Parameters:
11/20 08:35:19AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s1-alphal1-sw3-g5/DAG
11/20 08:35:19AM parser.py:31 [INFO] T=10.0
11/20 08:35:19AM parser.py:31 [INFO] ADVANCED=1
11/20 08:35:19AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/20 08:35:19AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/20 08:35:19AM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/20 08:35:19AM parser.py:31 [INFO] BATCH_SIZE=64
11/20 08:35:19AM parser.py:31 [INFO] CASCADE=0
11/20 08:35:19AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/20 08:35:19AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/20 08:35:19AM parser.py:31 [INFO] DATA_PATH=../data/
11/20 08:35:19AM parser.py:31 [INFO] DATASET=cifar100
11/20 08:35:19AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/20 08:35:19AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/20 08:35:19AM parser.py:31 [INFO] DISCRETE=0
11/20 08:35:19AM parser.py:31 [INFO] EPOCHS=50
11/20 08:35:19AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/20 08:35:19AM parser.py:31 [INFO] EXP_NAME=s1-alphal1-sw3-g5
11/20 08:35:19AM parser.py:31 [INFO] FINAL_L=5.0
11/20 08:35:19AM parser.py:31 [INFO] G=5.0
11/20 08:35:19AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/20 08:35:19AM parser.py:31 [INFO] GPUS=[0]
11/20 08:35:19AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/20 08:35:19AM parser.py:31 [INFO] INIT_CHANNELS=16
11/20 08:35:19AM parser.py:31 [INFO] L=5.0
11/20 08:35:19AM parser.py:31 [INFO] LAYERS=32
11/20 08:35:19AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/20 08:35:19AM parser.py:31 [INFO] NAME=Pruning
11/20 08:35:19AM parser.py:31 [INFO] NONKD=1
11/20 08:35:19AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s1-alphal1-sw3-g5
11/20 08:35:19AM parser.py:31 [INFO] PCDARTS=0
11/20 08:35:19AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s1-alphal1-sw3-g5/plots
11/20 08:35:19AM parser.py:31 [INFO] PRINT_FREQ=100
11/20 08:35:19AM parser.py:31 [INFO] RESET=0
11/20 08:35:19AM parser.py:31 [INFO] RESUME_PATH=None
11/20 08:35:19AM parser.py:31 [INFO] SAVE=s1-alphal1-sw3-g5
11/20 08:35:19AM parser.py:31 [INFO] SEED=1
11/20 08:35:19AM parser.py:31 [INFO] SHARE_STAGE=0
11/20 08:35:19AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/20 08:35:19AM parser.py:31 [INFO] SPEC_CELL=1
11/20 08:35:19AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/20 08:35:19AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/20 08:35:19AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/20 08:35:19AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/20 08:35:19AM parser.py:31 [INFO] TYPE=ArchKD
11/20 08:35:19AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/20 08:35:19AM parser.py:31 [INFO] W_LR=0.025
11/20 08:35:19AM parser.py:31 [INFO] W_LR_MIN=0.001
11/20 08:35:19AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/20 08:35:19AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/20 08:35:19AM parser.py:31 [INFO] WORKERS=4
11/20 08:35:19AM parser.py:32 [INFO] 
11/20 08:35:20AM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/20 08:35:21AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/20 08:36:06AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.5856 (4.7232)	Arch Loss 4.5348 (4.7848)	Arch Hard Loss 4.4793 (4.7276)	Arch Alpha Loss 0.0111 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.4%, 6.5%)	
11/20 08:36:49AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2177 (4.5965)	Arch Loss 4.4771 (4.6504)	Arch Hard Loss 4.4217 (4.5953)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 8.8%)	
11/20 08:37:32AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.3100 (4.5101)	Arch Loss 4.2516 (4.5586)	Arch Hard Loss 4.1955 (4.5041)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 10.7%)	
11/20 08:38:11AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.0218 (4.4495)	Arch Loss 4.2259 (4.4992)	Arch Hard Loss 4.1728 (4.4449)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.9%, 12.3%)	
11/20 08:38:12AM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 2.8480%
11/20 08:38:19AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.1462	Prec@(1,5) (5.4%, 20.0%)
11/20 08:38:26AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.1462	Prec@(1,5) (5.6%, 20.3%)
11/20 08:38:32AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.1419	Prec@(1,5) (5.7%, 20.8%)
11/20 08:38:38AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.1421	Prec@(1,5) (5.6%, 20.7%)
11/20 08:38:38AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 5.5840%
11/20 08:38:38AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 08:38:39AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 5.5840%
11/20 08:39:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.0487 (4.1567)	Arch Loss 4.0564 (4.2260)	Arch Hard Loss 4.0049 (4.1727)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.0%, 19.7%)	
11/20 08:40:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.0205 (4.1327)	Arch Loss 4.4165 (4.1930)	Arch Hard Loss 4.3656 (4.1396)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.3%, 20.7%)	
11/20 08:40:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 4.3293 (4.1049)	Arch Loss 4.1486 (4.1669)	Arch Hard Loss 4.0981 (4.1136)	Arch Alpha Loss 0.0101 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 21.9%)	
11/20 08:41:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.9675 (4.0828)	Arch Loss 4.0060 (4.1419)	Arch Hard Loss 3.9527 (4.0885)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.8%, 22.5%)	
11/20 08:41:28午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 5.8000%
11/20 08:41:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.9593	Prec@(1,5) (7.6%, 26.8%)
11/20 08:41:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.9571	Prec@(1,5) (7.7%, 27.1%)
11/20 08:41:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.9616	Prec@(1,5) (7.7%, 26.9%)
11/20 08:41:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.9597	Prec@(1,5) (7.7%, 26.8%)
11/20 08:41:54午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 7.6600%
11/20 08:41:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 08:41:55午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.6600%
11/20 08:42:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.9583 (3.9328)	Arch Loss 3.8025 (4.0001)	Arch Hard Loss 3.7489 (3.9462)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.0%, 27.3%)	
11/20 08:43:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 4.0124 (3.9139)	Arch Loss 3.9447 (3.9852)	Arch Hard Loss 3.8911 (3.9312)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.2%, 28.4%)	
11/20 08:44:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 4.2252 (3.9096)	Arch Loss 3.8227 (3.9670)	Arch Hard Loss 3.7684 (3.9130)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.3%, 28.4%)	
11/20 08:44:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.9120 (3.8885)	Arch Loss 4.0689 (3.9493)	Arch Hard Loss 4.0121 (3.8952)	Arch Alpha Loss 0.0114 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.6%, 29.1%)	
11/20 08:44:43午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 8.5840%
11/20 08:44:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.8263	Prec@(1,5) (9.2%, 31.0%)
11/20 08:44:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.8327	Prec@(1,5) (9.2%, 30.7%)
11/20 08:45:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.8418	Prec@(1,5) (9.2%, 30.3%)
11/20 08:45:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.8389	Prec@(1,5) (9.3%, 30.5%)
11/20 08:45:09午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.3320%
11/20 08:45:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 08:45:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.3320%
11/20 08:45:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.8685 (3.7852)	Arch Loss 3.8506 (3.8715)	Arch Hard Loss 3.7983 (3.8174)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.0%, 32.6%)	
11/20 08:46:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7491 (3.7754)	Arch Loss 3.8955 (3.8491)	Arch Hard Loss 3.8409 (3.7951)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.2%, 32.9%)	
11/20 08:47:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.7589 (3.7553)	Arch Loss 3.9474 (3.8276)	Arch Hard Loss 3.8942 (3.7735)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.6%, 33.5%)	
11/20 08:47:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.7207 (3.7416)	Arch Loss 3.4496 (3.8059)	Arch Hard Loss 3.3989 (3.7519)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.9%, 33.9%)	
11/20 08:48:00午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 10.8880%
11/20 08:48:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.6872	Prec@(1,5) (12.0%, 35.6%)
11/20 08:48:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.6795	Prec@(1,5) (12.2%, 36.0%)
11/20 08:48:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.6807	Prec@(1,5) (12.0%, 35.7%)
11/20 08:48:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.6773	Prec@(1,5) (12.1%, 35.9%)
11/20 08:48:26午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 12.0600%
11/20 08:48:26午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 08:48:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.0600%
11/20 08:49:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.5792 (3.6070)	Arch Loss 3.7776 (3.7067)	Arch Hard Loss 3.7237 (3.6530)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.2%, 37.6%)	
11/20 08:49:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.7361 (3.6133)	Arch Loss 3.4959 (3.6995)	Arch Hard Loss 3.4430 (3.6460)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.4%, 37.5%)	
11/20 08:50:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.6982 (3.6127)	Arch Loss 3.6471 (3.6782)	Arch Hard Loss 3.5927 (3.6247)	Arch Alpha Loss 0.0109 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.4%, 37.7%)	
11/20 08:51:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.4274 (3.6007)	Arch Loss 3.8567 (3.6555)	Arch Hard Loss 3.8010 (3.6019)	Arch Alpha Loss 0.0111 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.6%, 38.2%)	
11/20 08:51:16午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.6280%
11/20 08:51:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5322	Prec@(1,5) (14.2%, 41.2%)
11/20 08:51:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5247	Prec@(1,5) (14.4%, 40.7%)
11/20 08:51:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5235	Prec@(1,5) (14.6%, 40.9%)
11/20 08:51:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5166	Prec@(1,5) (14.7%, 41.1%)
11/20 08:51:42午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.7160%
11/20 08:51:42午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 08:51:42午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.7160%
11/20 08:52:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.3843 (3.4812)	Arch Loss 3.5738 (3.5369)	Arch Hard Loss 3.5217 (3.4830)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.5%, 42.1%)	
11/20 08:53:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.4402 (3.4689)	Arch Loss 3.1377 (3.5640)	Arch Hard Loss 3.0851 (3.5100)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.6%, 42.0%)	
11/20 08:53:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.4137 (3.4624)	Arch Loss 3.6610 (3.5478)	Arch Hard Loss 3.6094 (3.4936)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.8%, 42.2%)	
11/20 08:54:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.5449 (3.4550)	Arch Loss 3.6216 (3.5292)	Arch Hard Loss 3.5662 (3.4750)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.1%, 42.5%)	
11/20 08:54:32午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 16.0600%
11/20 08:54:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.4270	Prec@(1,5) (16.3%, 44.3%)
11/20 08:54:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.4212	Prec@(1,5) (16.8%, 44.1%)
11/20 08:54:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.4163	Prec@(1,5) (16.8%, 44.2%)
11/20 08:54:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.4169	Prec@(1,5) (16.8%, 44.0%)
11/20 08:54:58午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 16.8000%
11/20 08:54:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/20 08:54:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.8000%
11/20 08:55:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.6106 (3.3610)	Arch Loss 3.4720 (3.4600)	Arch Hard Loss 3.4163 (3.4054)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.6%, 45.2%)	
11/20 08:56:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.2699 (3.3538)	Arch Loss 3.4577 (3.4432)	Arch Hard Loss 3.4026 (3.3886)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.7%, 45.4%)	
11/20 08:57:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.3390 (3.3580)	Arch Loss 3.0148 (3.4324)	Arch Hard Loss 2.9586 (3.3778)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.9%, 45.3%)	
11/20 08:57:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.4138 (3.3514)	Arch Loss 3.5790 (3.4229)	Arch Hard Loss 3.5233 (3.3684)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.0%, 45.6%)	
11/20 08:57:47午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.9720%
11/20 08:57:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.3915	Prec@(1,5) (17.0%, 45.9%)
11/20 08:58:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3898	Prec@(1,5) (17.1%, 45.8%)
11/20 08:58:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.3962	Prec@(1,5) (17.0%, 45.5%)
11/20 08:58:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.4026	Prec@(1,5) (17.0%, 45.3%)
11/20 08:58:14午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 17.0520%
11/20 08:58:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 08:58:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.0520%
11/20 08:58:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.1546 (3.2625)	Arch Loss 3.6835 (3.3558)	Arch Hard Loss 3.6289 (3.3011)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.9%, 47.5%)	
11/20 08:59:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.2808 (3.2634)	Arch Loss 3.2933 (3.3481)	Arch Hard Loss 3.2374 (3.2932)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.3%, 47.5%)	
11/20 09:00:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.0527 (3.2464)	Arch Loss 3.3651 (3.3206)	Arch Hard Loss 3.3101 (3.2656)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.7%, 48.0%)	
11/20 09:01:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.9268 (3.2461)	Arch Loss 3.1110 (3.3213)	Arch Hard Loss 3.0587 (3.2663)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.8%, 48.1%)	
11/20 09:01:02午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 19.7800%
11/20 09:01:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.2949	Prec@(1,5) (19.4%, 48.6%)
11/20 09:01:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.3018	Prec@(1,5) (19.4%, 47.7%)
11/20 09:01:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.3108	Prec@(1,5) (19.2%, 47.6%)
11/20 09:01:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.3178	Prec@(1,5) (18.9%, 47.6%)
11/20 09:01:28午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 18.8840%
11/20 09:01:28午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/20 09:01:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 18.8840%
11/20 09:02:13午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.3475 (3.1328)	Arch Loss 3.4537 (3.2480)	Arch Hard Loss 3.3979 (3.1928)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.5%, 50.7%)	
11/20 09:02:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.1575 (3.1334)	Arch Loss 2.9765 (3.2525)	Arch Hard Loss 2.9216 (3.1974)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.3%, 50.7%)	
11/20 09:03:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.9062 (3.1326)	Arch Loss 2.8891 (3.2419)	Arch Hard Loss 2.8341 (3.1870)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.1%, 50.8%)	
11/20 09:04:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.5733 (3.1236)	Arch Loss 3.2832 (3.2356)	Arch Hard Loss 3.2281 (3.1808)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.1%, 51.4%)	
11/20 09:04:18午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 22.1200%
11/20 09:04:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1592	Prec@(1,5) (21.4%, 52.0%)
11/20 09:04:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1644	Prec@(1,5) (21.4%, 51.9%)
11/20 09:04:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1630	Prec@(1,5) (21.7%, 51.7%)
11/20 09:04:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1681	Prec@(1,5) (21.6%, 51.7%)
11/20 09:04:44午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 21.6400%
11/20 09:04:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/20 09:04:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.6400%
11/20 09:05:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.9329 (3.0620)	Arch Loss 3.2522 (3.1874)	Arch Hard Loss 3.1990 (3.1332)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.1%, 53.2%)	
11/20 09:06:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.3615 (3.0463)	Arch Loss 3.1879 (3.1826)	Arch Hard Loss 3.1339 (3.1284)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.4%, 53.8%)	
11/20 09:06:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.3753 (3.0416)	Arch Loss 3.1397 (3.1596)	Arch Hard Loss 3.0878 (3.1054)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.4%, 54.1%)	
11/20 09:07:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.7760 (3.0325)	Arch Loss 3.5668 (3.1546)	Arch Hard Loss 3.5104 (3.1001)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.6%, 54.3%)	
11/20 09:07:33午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 23.6000%
11/20 09:07:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.1017	Prec@(1,5) (23.2%, 52.8%)
11/20 09:07:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.1178	Prec@(1,5) (23.0%, 52.8%)
11/20 09:07:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.1232	Prec@(1,5) (23.0%, 52.4%)
11/20 09:07:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.1245	Prec@(1,5) (23.1%, 52.3%)
11/20 09:07:59午前 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 23.0720%
11/20 09:07:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/20 09:08:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.0720%
11/20 09:08:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9346 (2.9372)	Arch Loss 3.0840 (3.0963)	Arch Hard Loss 3.0271 (3.0407)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.1%, 56.9%)	
11/20 09:09:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 3.2101 (2.9381)	Arch Loss 2.9146 (3.1097)	Arch Hard Loss 2.8587 (3.0541)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.1%, 56.5%)	
11/20 09:10:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.8226 (2.9372)	Arch Loss 3.3095 (3.0942)	Arch Hard Loss 3.2534 (3.0387)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.0%, 56.6%)	
11/20 09:10:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 3.0530 (2.9352)	Arch Loss 3.2030 (3.0781)	Arch Hard Loss 3.1470 (3.0228)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.1%, 56.7%)	
11/20 09:10:51午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 26.0760%
11/20 09:10:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.0143	Prec@(1,5) (25.2%, 55.7%)
11/20 09:11:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.0093	Prec@(1,5) (25.3%, 55.2%)
11/20 09:11:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 3.0108	Prec@(1,5) (25.1%, 55.2%)
11/20 09:11:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 3.0044	Prec@(1,5) (25.1%, 55.5%)
11/20 09:11:17午前 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 25.0400%
11/20 09:11:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/20 09:11:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.0400%
11/20 09:12:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.4281 (2.8372)	Arch Loss 2.9393 (2.9917)	Arch Hard Loss 2.8848 (2.9368)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.4%, 58.7%)	
11/20 09:12:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4646 (2.8315)	Arch Loss 2.6618 (3.0164)	Arch Hard Loss 2.6076 (2.9614)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.6%, 59.0%)	
11/20 09:13:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.8856 (2.8507)	Arch Loss 2.9456 (3.0167)	Arch Hard Loss 2.8919 (2.9617)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 58.9%)	
11/20 09:14:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.7814 (2.8501)	Arch Loss 2.5455 (2.9995)	Arch Hard Loss 2.4938 (2.9446)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 58.7%)	
11/20 09:14:06午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 27.4560%
11/20 09:14:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.9472	Prec@(1,5) (26.2%, 57.6%)
11/20 09:14:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.9408	Prec@(1,5) (26.6%, 57.5%)
11/20 09:14:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9435	Prec@(1,5) (26.7%, 57.3%)
11/20 09:14:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.9464	Prec@(1,5) (26.7%, 57.1%)
11/20 09:14:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 26.7000%
11/20 09:14:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/20 09:14:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.7000%
11/20 09:15:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.8188 (2.7632)	Arch Loss 2.5670 (2.9679)	Arch Hard Loss 2.5113 (2.9132)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 60.9%)	
11/20 09:16:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.9807 (2.7589)	Arch Loss 2.8869 (2.9586)	Arch Hard Loss 2.8314 (2.9039)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.4%, 60.9%)	
11/20 09:16:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.2912 (2.7555)	Arch Loss 2.8111 (2.9490)	Arch Hard Loss 2.7540 (2.8943)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 60.9%)	
11/20 09:17:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 3.0274 (2.7583)	Arch Loss 3.0055 (2.9439)	Arch Hard Loss 2.9502 (2.8892)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 60.9%)	
11/20 09:17:22午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 29.3080%
11/20 09:17:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.8489	Prec@(1,5) (28.4%, 58.9%)
11/20 09:17:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.8358	Prec@(1,5) (28.5%, 59.3%)
11/20 09:17:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.8420	Prec@(1,5) (28.3%, 59.2%)
11/20 09:17:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.8459	Prec@(1,5) (28.4%, 59.2%)
11/20 09:17:48午前 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 28.3800%
11/20 09:17:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/20 09:17:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.3800%
11/20 09:18:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.3153 (2.6658)	Arch Loss 2.7098 (2.8775)	Arch Hard Loss 2.6581 (2.8229)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 63.3%)	
11/20 09:19:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.8661 (2.6829)	Arch Loss 2.7280 (2.9005)	Arch Hard Loss 2.6766 (2.8460)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 62.8%)	
11/20 09:19:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 3.0124 (2.6903)	Arch Loss 3.0140 (2.8901)	Arch Hard Loss 2.9624 (2.8356)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 62.8%)	
11/20 09:20:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.7229 (2.6851)	Arch Loss 2.7689 (2.8749)	Arch Hard Loss 2.7157 (2.8205)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.9%, 62.9%)	
11/20 09:20:38午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 30.8560%
11/20 09:20:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.7782	Prec@(1,5) (29.6%, 60.6%)
11/20 09:20:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8003	Prec@(1,5) (29.5%, 60.4%)
11/20 09:20:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.8041	Prec@(1,5) (29.2%, 60.3%)
11/20 09:21:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.7998	Prec@(1,5) (29.4%, 60.4%)
11/20 09:21:04午前 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 29.3560%
11/20 09:21:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/20 09:21:04午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.3560%
11/20 09:21:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.1729 (2.5764)	Arch Loss 2.5262 (2.7982)	Arch Hard Loss 2.4699 (2.7435)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 64.7%)	
11/20 09:22:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.9356 (2.5870)	Arch Loss 2.7831 (2.8086)	Arch Hard Loss 2.7276 (2.7539)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.5%, 65.1%)	
11/20 09:23:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.6261 (2.5961)	Arch Loss 2.9660 (2.8267)	Arch Hard Loss 2.9110 (2.7721)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.6%, 64.8%)	
11/20 09:23:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.4388 (2.6024)	Arch Loss 2.5166 (2.8173)	Arch Hard Loss 2.4609 (2.7628)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.5%, 64.7%)	
11/20 09:23:54午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 32.4960%
11/20 09:24:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.7179	Prec@(1,5) (30.5%, 61.6%)
11/20 09:24:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.7287	Prec@(1,5) (30.8%, 61.7%)
11/20 09:24:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.7131	Prec@(1,5) (31.2%, 62.1%)
11/20 09:24:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.6984	Prec@(1,5) (31.5%, 62.5%)
11/20 09:24:20午前 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 31.4560%
11/20 09:24:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:24:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.4560%
11/20 09:25:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.4156 (2.4719)	Arch Loss 2.6771 (2.7764)	Arch Hard Loss 2.6232 (2.7216)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.7%, 67.5%)	
11/20 09:25:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.3209 (2.5012)	Arch Loss 2.7048 (2.7545)	Arch Hard Loss 2.6513 (2.6996)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 66.9%)	
11/20 09:26:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.7401 (2.5250)	Arch Loss 2.5475 (2.7455)	Arch Hard Loss 2.4949 (2.6905)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.3%)	
11/20 09:27:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.7960 (2.5250)	Arch Loss 3.0461 (2.7526)	Arch Hard Loss 2.9949 (2.6977)	Arch Alpha Loss 0.0102 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 66.4%)	
11/20 09:27:11午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 33.9240%
11/20 09:27:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.7043	Prec@(1,5) (31.9%, 63.2%)
11/20 09:27:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.7249	Prec@(1,5) (31.2%, 62.3%)
11/20 09:27:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.7205	Prec@(1,5) (31.2%, 62.5%)
11/20 09:27:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.7268	Prec@(1,5) (31.2%, 62.3%)
11/20 09:27:37午前 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 31.1920%
11/20 09:27:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:27:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.4560%
11/20 09:28:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.5798 (2.4245)	Arch Loss 2.1907 (2.7132)	Arch Hard Loss 2.1332 (2.6587)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.9%, 68.0%)	
11/20 09:29:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.7861 (2.4492)	Arch Loss 2.4805 (2.7116)	Arch Hard Loss 2.4226 (2.6569)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 67.7%)	
11/20 09:29:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.4007 (2.4541)	Arch Loss 2.9615 (2.7089)	Arch Hard Loss 2.9041 (2.6542)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 67.4%)	
11/20 09:30:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.0762 (2.4562)	Arch Loss 2.8645 (2.7031)	Arch Hard Loss 2.8068 (2.6484)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.4%, 67.5%)	
11/20 09:30:26午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 35.4080%
11/20 09:30:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.6356	Prec@(1,5) (32.9%, 63.5%)
11/20 09:30:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.6579	Prec@(1,5) (32.2%, 63.0%)
11/20 09:30:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.6645	Prec@(1,5) (32.2%, 63.0%)
11/20 09:30:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.6682	Prec@(1,5) (32.4%, 63.0%)
11/20 09:30:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 32.4160%
11/20 09:30:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:30:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.4160%
11/20 09:31:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.4282 (2.3674)	Arch Loss 2.9102 (2.6835)	Arch Hard Loss 2.8591 (2.6285)	Arch Alpha Loss 0.0102 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.6%)	
11/20 09:32:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.5639 (2.3531)	Arch Loss 2.6013 (2.6578)	Arch Hard Loss 2.5508 (2.6025)	Arch Alpha Loss 0.0101 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 69.9%)	
11/20 09:33:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.2166 (2.3648)	Arch Loss 2.6777 (2.6558)	Arch Hard Loss 2.6236 (2.6004)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.7%)	
11/20 09:33:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.5714 (2.3852)	Arch Loss 2.1257 (2.6600)	Arch Hard Loss 2.0715 (2.6047)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.1%, 69.3%)	
11/20 09:33:44午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 37.1000%
11/20 09:33:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.5249	Prec@(1,5) (33.8%, 66.3%)
11/20 09:33:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.5283	Prec@(1,5) (34.5%, 66.2%)
11/20 09:34:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.5350	Prec@(1,5) (34.3%, 66.1%)
11/20 09:34:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.5344	Prec@(1,5) (34.2%, 66.2%)
11/20 09:34:10午前 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 34.2480%
11/20 09:34:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:34:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.2480%
11/20 09:34:55午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.3651 (2.3108)	Arch Loss 2.6971 (2.5910)	Arch Hard Loss 2.6415 (2.5362)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 71.4%)	
11/20 09:35:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.6538 (2.3194)	Arch Loss 2.5819 (2.6016)	Arch Hard Loss 2.5264 (2.5470)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.0%)	
11/20 09:36:22午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.1171 (2.3249)	Arch Loss 2.6308 (2.6131)	Arch Hard Loss 2.5739 (2.5586)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 70.8%)	
11/20 09:37:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.5160 (2.3269)	Arch Loss 2.5699 (2.6047)	Arch Hard Loss 2.5138 (2.5501)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 70.8%)	
11/20 09:37:01午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 38.2960%
11/20 09:37:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5620	Prec@(1,5) (34.0%, 65.8%)
11/20 09:37:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5581	Prec@(1,5) (34.2%, 65.9%)
11/20 09:37:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5489	Prec@(1,5) (34.4%, 66.1%)
11/20 09:37:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5488	Prec@(1,5) (34.5%, 66.2%)
11/20 09:37:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 34.4720%
11/20 09:37:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:37:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.4720%
11/20 09:38:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.8079 (2.2505)	Arch Loss 2.2823 (2.6028)	Arch Hard Loss 2.2275 (2.5481)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.4%, 72.5%)	
11/20 09:38:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 2.1518 (2.2444)	Arch Loss 2.2376 (2.5922)	Arch Hard Loss 2.1825 (2.5376)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 72.1%)	
11/20 09:39:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.1102 (2.2381)	Arch Loss 2.6107 (2.5862)	Arch Hard Loss 2.5574 (2.5313)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 72.3%)	
11/20 09:40:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.4825 (2.2495)	Arch Loss 2.8518 (2.5753)	Arch Hard Loss 2.7969 (2.5204)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 72.1%)	
11/20 09:40:17午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 39.8920%
11/20 09:40:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.5290	Prec@(1,5) (36.0%, 66.8%)
11/20 09:40:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.5068	Prec@(1,5) (36.1%, 67.2%)
11/20 09:40:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.5043	Prec@(1,5) (35.9%, 67.2%)
11/20 09:40:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.5017	Prec@(1,5) (36.0%, 67.3%)
11/20 09:40:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 36.0320%
11/20 09:40:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:40:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.0320%
11/20 09:41:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 2.2448 (2.1264)	Arch Loss 2.3586 (2.5399)	Arch Hard Loss 2.3015 (2.4849)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.5%, 74.8%)	
11/20 09:42:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.9745 (2.1707)	Arch Loss 2.4142 (2.5492)	Arch Hard Loss 2.3608 (2.4944)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.0%)	
11/20 09:42:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.0735 (2.1771)	Arch Loss 2.1694 (2.5474)	Arch Hard Loss 2.1184 (2.4927)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.0%)	
11/20 09:43:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 2.0366 (2.1808)	Arch Loss 2.5640 (2.5334)	Arch Hard Loss 2.5110 (2.4788)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 73.8%)	
11/20 09:43:32午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 41.4720%
11/20 09:43:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.5036	Prec@(1,5) (35.5%, 67.4%)
11/20 09:43:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.4692	Prec@(1,5) (36.2%, 68.2%)
11/20 09:43:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.4675	Prec@(1,5) (36.3%, 68.2%)
11/20 09:43:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.4670	Prec@(1,5) (36.3%, 68.2%)
11/20 09:43:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 36.2800%
11/20 09:43:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:43:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.2800%
11/20 09:44:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.1917 (2.0837)	Arch Loss 1.8912 (2.5118)	Arch Hard Loss 1.8380 (2.4581)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 75.6%)	
11/20 09:45:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.7512 (2.0896)	Arch Loss 2.1321 (2.4767)	Arch Hard Loss 2.0799 (2.4232)	Arch Alpha Loss 0.0104 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 75.8%)	
11/20 09:46:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 2.1293 (2.1008)	Arch Loss 2.8737 (2.4958)	Arch Hard Loss 2.8210 (2.4424)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 75.5%)	
11/20 09:46:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.0141 (2.1144)	Arch Loss 2.8182 (2.4968)	Arch Hard Loss 2.7659 (2.4434)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 75.0%)	
11/20 09:46:48午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 43.2200%
11/20 09:46:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.4213	Prec@(1,5) (36.9%, 69.8%)
11/20 09:47:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4165	Prec@(1,5) (37.2%, 69.7%)
11/20 09:47:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4006	Prec@(1,5) (37.6%, 69.6%)
11/20 09:47:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.3973	Prec@(1,5) (37.8%, 69.6%)
11/20 09:47:14午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 37.7840%
11/20 09:47:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:47:15午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.7840%
11/20 09:47:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.9706 (2.0021)	Arch Loss 2.4779 (2.4534)	Arch Hard Loss 2.4226 (2.3997)	Arch Alpha Loss 0.0111 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 77.1%)	
11/20 09:48:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 2.1812 (2.0437)	Arch Loss 2.5205 (2.4657)	Arch Hard Loss 2.4680 (2.4122)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.3%)	
11/20 09:49:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.9103 (2.0559)	Arch Loss 2.2146 (2.4721)	Arch Hard Loss 2.1606 (2.4187)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.2%)	
11/20 09:50:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7571 (2.0580)	Arch Loss 1.9940 (2.4623)	Arch Hard Loss 1.9371 (2.4089)	Arch Alpha Loss 0.0114 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 76.1%)	
11/20 09:50:04午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 43.6040%
11/20 09:50:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.3596	Prec@(1,5) (38.8%, 70.4%)
11/20 09:50:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.3813	Prec@(1,5) (38.4%, 70.5%)
11/20 09:50:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.3831	Prec@(1,5) (38.3%, 70.6%)
11/20 09:50:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.3811	Prec@(1,5) (38.3%, 70.5%)
11/20 09:50:30午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 38.3200%
11/20 09:50:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:50:31午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.3200%
11/20 09:51:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 2.0142 (1.9318)	Arch Loss 2.2629 (2.4197)	Arch Hard Loss 2.2101 (2.3660)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.9%)	
11/20 09:51:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 2.1108 (1.9768)	Arch Loss 2.3433 (2.4408)	Arch Hard Loss 2.2892 (2.3872)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.1%)	
11/20 09:52:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.8535 (1.9825)	Arch Loss 2.2993 (2.4372)	Arch Hard Loss 2.2455 (2.3834)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.9%)	
11/20 09:53:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.9274 (1.9925)	Arch Loss 2.5665 (2.4275)	Arch Hard Loss 2.5125 (2.3736)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 77.7%)	
11/20 09:53:20午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 45.4200%
11/20 09:53:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.4311	Prec@(1,5) (37.9%, 69.2%)
11/20 09:53:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.4087	Prec@(1,5) (38.2%, 70.0%)
11/20 09:53:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.4332	Prec@(1,5) (38.2%, 69.5%)
11/20 09:53:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.4228	Prec@(1,5) (38.4%, 69.6%)
11/20 09:53:46午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 38.4240%
11/20 09:53:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:53:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.4240%
11/20 09:54:30午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 2.4374 (1.8733)	Arch Loss 2.7000 (2.4219)	Arch Hard Loss 2.6470 (2.3676)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 79.6%)	
11/20 09:55:13午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.8265 (1.8920)	Arch Loss 2.2103 (2.3916)	Arch Hard Loss 2.1575 (2.3377)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.6%)	
11/20 09:55:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.7354 (1.9029)	Arch Loss 2.9782 (2.4052)	Arch Hard Loss 2.9226 (2.3514)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.3%, 79.2%)	
11/20 09:56:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.0046 (1.9166)	Arch Loss 2.2020 (2.4037)	Arch Hard Loss 2.1470 (2.3499)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 79.0%)	
11/20 09:56:35午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 47.0160%
11/20 09:56:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.4749	Prec@(1,5) (37.5%, 69.4%)
11/20 09:56:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.4638	Prec@(1,5) (37.7%, 69.6%)
11/20 09:56:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.4533	Prec@(1,5) (38.0%, 69.7%)
11/20 09:57:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.4519	Prec@(1,5) (38.1%, 69.6%)
11/20 09:57:01午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 38.0600%
11/20 09:57:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 09:57:02午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.4240%
11/20 09:57:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.9764 (1.8253)	Arch Loss 2.4867 (2.3540)	Arch Hard Loss 2.4358 (2.3004)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 81.1%)	
11/20 09:58:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.7133 (1.8307)	Arch Loss 2.7459 (2.3739)	Arch Hard Loss 2.6964 (2.3200)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.5%)	
11/20 09:59:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 2.0087 (1.8540)	Arch Loss 2.1086 (2.3717)	Arch Hard Loss 2.0563 (2.3177)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.1%)	
11/20 09:59:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.9398 (1.8643)	Arch Loss 2.3162 (2.3687)	Arch Hard Loss 2.2678 (2.3148)	Arch Alpha Loss 0.0097 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 79.8%)	
11/20 09:59:51午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 48.4840%
11/20 09:59:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.3301	Prec@(1,5) (40.1%, 71.3%)
11/20 10:00:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.3354	Prec@(1,5) (40.0%, 71.6%)
11/20 10:00:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.3274	Prec@(1,5) (40.0%, 71.8%)
11/20 10:00:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.3179	Prec@(1,5) (40.2%, 71.8%)
11/20 10:00:17午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 40.1960%
11/20 10:00:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:00:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.1960%
11/20 10:01:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5904 (1.7346)	Arch Loss 2.6240 (2.3391)	Arch Hard Loss 2.5662 (2.2857)	Arch Alpha Loss 0.0115 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.7%)	
11/20 10:01:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.8518 (1.7758)	Arch Loss 2.2717 (2.3567)	Arch Hard Loss 2.2152 (2.3034)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.8%)	
11/20 10:02:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.6602 (1.7890)	Arch Loss 2.8687 (2.3567)	Arch Hard Loss 2.8120 (2.3032)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.5%)	
11/20 10:03:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.9867 (1.8099)	Arch Loss 2.3820 (2.3572)	Arch Hard Loss 2.3229 (2.3037)	Arch Alpha Loss 0.0118 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.2%)	
11/20 10:03:07午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 49.6480%
11/20 10:03:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.3570	Prec@(1,5) (40.2%, 70.1%)
11/20 10:03:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.3524	Prec@(1,5) (39.8%, 70.5%)
11/20 10:03:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.3533	Prec@(1,5) (39.8%, 70.5%)
11/20 10:03:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.3510	Prec@(1,5) (39.7%, 70.6%)
11/20 10:03:34午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 39.7000%
11/20 10:03:34午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:03:34午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.1960%
11/20 10:04:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.8351 (1.7230)	Arch Loss 2.2891 (2.3268)	Arch Hard Loss 2.2414 (2.2736)	Arch Alpha Loss 0.0095 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.5%)	
11/20 10:05:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.6528 (1.7300)	Arch Loss 2.0532 (2.3185)	Arch Hard Loss 2.0047 (2.2653)	Arch Alpha Loss 0.0097 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 82.6%)	
11/20 10:05:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.8298 (1.7459)	Arch Loss 2.1146 (2.3412)	Arch Hard Loss 2.0652 (2.2879)	Arch Alpha Loss 0.0099 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.2%)	
11/20 10:06:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.9107 (1.7549)	Arch Loss 2.2361 (2.3320)	Arch Hard Loss 2.1885 (2.2787)	Arch Alpha Loss 0.0095 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.0%)	
11/20 10:06:24午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 51.1320%
11/20 10:06:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.2786	Prec@(1,5) (41.2%, 72.1%)
11/20 10:06:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.2675	Prec@(1,5) (41.5%, 72.4%)
11/20 10:06:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.2705	Prec@(1,5) (41.5%, 72.6%)
11/20 10:06:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.2683	Prec@(1,5) (41.6%, 72.7%)
11/20 10:06:50午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 41.6360%
11/20 10:06:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:06:51午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.6360%
11/20 10:07:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.5833 (1.6457)	Arch Loss 2.4646 (2.2979)	Arch Hard Loss 2.4017 (2.2439)	Arch Alpha Loss 0.0126 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.8%)	
11/20 10:08:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.7590 (1.6778)	Arch Loss 2.6109 (2.2943)	Arch Hard Loss 2.5503 (2.2402)	Arch Alpha Loss 0.0121 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.6%)	
11/20 10:09:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.2914 (1.6718)	Arch Loss 2.5283 (2.3073)	Arch Hard Loss 2.4688 (2.2530)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.4%)	
11/20 10:09:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.6186 (1.6867)	Arch Loss 2.7361 (2.3027)	Arch Hard Loss 2.6772 (2.2483)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 83.1%)	
11/20 10:09:41午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 52.2880%
11/20 10:09:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.1754	Prec@(1,5) (43.2%, 74.9%)
11/20 10:09:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.1827	Prec@(1,5) (43.5%, 75.0%)
11/20 10:10:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.1946	Prec@(1,5) (43.4%, 74.7%)
11/20 10:10:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.1888	Prec@(1,5) (43.4%, 74.6%)
11/20 10:10:07午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 43.3960%
11/20 10:10:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:10:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3960%
11/20 10:10:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.5221 (1.5512)	Arch Loss 2.0058 (2.3107)	Arch Hard Loss 1.9549 (2.2562)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.5%)	
11/20 10:11:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.8115 (1.5781)	Arch Loss 2.2994 (2.2943)	Arch Hard Loss 2.2480 (2.2397)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.1%)	
11/20 10:12:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.5503 (1.5991)	Arch Loss 2.3003 (2.2995)	Arch Hard Loss 2.2504 (2.2448)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 84.7%)	
11/20 10:12:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.8182 (1.6132)	Arch Loss 1.9863 (2.2824)	Arch Hard Loss 1.9365 (2.2278)	Arch Alpha Loss 0.0099 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 84.5%)	
11/20 10:12:58午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 54.9720%
11/20 10:13:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.2427	Prec@(1,5) (43.0%, 73.8%)
11/20 10:13:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.2452	Prec@(1,5) (42.6%, 73.7%)
11/20 10:13:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2465	Prec@(1,5) (42.6%, 73.8%)
11/20 10:13:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2405	Prec@(1,5) (42.7%, 74.0%)
11/20 10:13:24午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 42.7040%
11/20 10:13:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:13:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3960%
11/20 10:14:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.2898 (1.4972)	Arch Loss 2.1214 (2.2812)	Arch Hard Loss 2.0610 (2.2268)	Arch Alpha Loss 0.0121 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.6%)	
11/20 10:14:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.4171 (1.5086)	Arch Loss 2.2546 (2.3009)	Arch Hard Loss 2.1979 (2.2462)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.8%, 86.3%)	
11/20 10:15:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.4837 (1.5311)	Arch Loss 2.5433 (2.2826)	Arch Hard Loss 2.4834 (2.2279)	Arch Alpha Loss 0.0120 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 86.0%)	
11/20 10:16:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.5866 (1.5514)	Arch Loss 2.7837 (2.2902)	Arch Hard Loss 2.7270 (2.2356)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.7%)	
11/20 10:16:14午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 55.4360%
11/20 10:16:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.2030	Prec@(1,5) (44.6%, 74.5%)
11/20 10:16:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.1979	Prec@(1,5) (44.6%, 74.5%)
11/20 10:16:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.1908	Prec@(1,5) (44.5%, 74.7%)
11/20 10:16:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.1819	Prec@(1,5) (44.6%, 74.9%)
11/20 10:16:40午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 44.5480%
11/20 10:16:40午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:16:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.5480%
11/20 10:17:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.5820 (1.4466)	Arch Loss 2.4178 (2.2555)	Arch Hard Loss 2.3623 (2.2012)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.2%)	
11/20 10:18:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.3128 (1.4727)	Arch Loss 2.2492 (2.2810)	Arch Hard Loss 2.1966 (2.2267)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.9%)	
11/20 10:18:51午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.4815 (1.4960)	Arch Loss 2.0109 (2.2767)	Arch Hard Loss 1.9575 (2.2224)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.5%)	
11/20 10:19:30午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.5709 (1.5091)	Arch Loss 2.7549 (2.2763)	Arch Hard Loss 2.7029 (2.2219)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.8%, 86.3%)	
11/20 10:19:31午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 56.7360%
11/20 10:19:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1750	Prec@(1,5) (44.6%, 75.6%)
11/20 10:19:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1600	Prec@(1,5) (44.7%, 75.7%)
11/20 10:19:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.1594	Prec@(1,5) (44.8%, 75.6%)
11/20 10:19:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.1661	Prec@(1,5) (44.7%, 75.5%)
11/20 10:19:57午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 44.6800%
11/20 10:19:57午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:19:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.6800%
11/20 10:20:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.4475 (1.3800)	Arch Loss 2.2257 (2.2323)	Arch Hard Loss 2.1693 (2.1780)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.1%)	
11/20 10:21:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.5964 (1.4103)	Arch Loss 2.6780 (2.2600)	Arch Hard Loss 2.6191 (2.2058)	Arch Alpha Loss 0.0118 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.7%)	
11/20 10:22:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.5186 (1.4169)	Arch Loss 2.6055 (2.2596)	Arch Hard Loss 2.5455 (2.2053)	Arch Alpha Loss 0.0120 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.8%)	
11/20 10:22:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.2103 (1.4355)	Arch Loss 1.6232 (2.2562)	Arch Hard Loss 1.5647 (2.2018)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.4%)	
11/20 10:22:47午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 58.6640%
11/20 10:22:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.1507	Prec@(1,5) (45.2%, 75.5%)
11/20 10:23:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1696	Prec@(1,5) (45.2%, 75.2%)
11/20 10:23:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1707	Prec@(1,5) (45.0%, 75.3%)
11/20 10:23:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.1609	Prec@(1,5) (45.3%, 75.5%)
11/20 10:23:14午前 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 45.2920%
11/20 10:23:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:23:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.2920%
11/20 10:23:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.4813 (1.3273)	Arch Loss 2.2070 (2.2857)	Arch Hard Loss 2.1568 (2.2310)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.2%)	
11/20 10:24:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.3596 (1.3470)	Arch Loss 2.1563 (2.2510)	Arch Hard Loss 2.1073 (2.1963)	Arch Alpha Loss 0.0098 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 89.1%)	
11/20 10:25:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.4987 (1.3579)	Arch Loss 2.0414 (2.2496)	Arch Hard Loss 1.9891 (2.1950)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.8%)	
11/20 10:26:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.5892 (1.3736)	Arch Loss 2.0537 (2.2533)	Arch Hard Loss 2.0010 (2.1987)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.5%)	
11/20 10:26:03午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 60.3920%
11/20 10:26:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1607	Prec@(1,5) (44.9%, 75.4%)
11/20 10:26:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.1418	Prec@(1,5) (45.9%, 75.8%)
11/20 10:26:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.1361	Prec@(1,5) (45.7%, 75.8%)
11/20 10:26:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.1448	Prec@(1,5) (45.6%, 75.8%)
11/20 10:26:30午前 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 45.5920%
11/20 10:26:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:26:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.5920%
11/20 10:27:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.5402 (1.2122)	Arch Loss 2.6831 (2.2569)	Arch Hard Loss 2.6258 (2.2023)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.7%)	
11/20 10:27:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.4348 (1.2616)	Arch Loss 2.6142 (2.2541)	Arch Hard Loss 2.5555 (2.1998)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 90.3%)	
11/20 10:28:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1714 (1.2830)	Arch Loss 2.6379 (2.2496)	Arch Hard Loss 2.5796 (2.1952)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.9%)	
11/20 10:29:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.1458 (1.3026)	Arch Loss 2.4242 (2.2469)	Arch Hard Loss 2.3667 (2.1926)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.5%)	
11/20 10:29:19午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 62.1600%
11/20 10:29:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1895	Prec@(1,5) (45.4%, 75.2%)
11/20 10:29:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1880	Prec@(1,5) (45.2%, 75.5%)
11/20 10:29:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1859	Prec@(1,5) (45.4%, 75.5%)
11/20 10:29:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1672	Prec@(1,5) (45.6%, 75.8%)
11/20 10:29:46午前 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 45.6120%
11/20 10:29:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:29:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.6120%
11/20 10:30:30午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.3201 (1.1975)	Arch Loss 2.2412 (2.2143)	Arch Hard Loss 2.1891 (2.1602)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.7%)	
11/20 10:31:13午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.2735 (1.2045)	Arch Loss 2.0768 (2.2330)	Arch Hard Loss 2.0269 (2.1790)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.8%)	
11/20 10:31:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.1111 (1.2276)	Arch Loss 3.0054 (2.2535)	Arch Hard Loss 2.9542 (2.1994)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.3%)	
11/20 10:32:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1612 (1.2324)	Arch Loss 2.2859 (2.2526)	Arch Hard Loss 2.2321 (2.1983)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.3%)	
11/20 10:32:35午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 64.3080%
11/20 10:32:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.1806	Prec@(1,5) (45.8%, 76.3%)
11/20 10:32:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.1817	Prec@(1,5) (45.6%, 76.0%)
11/20 10:32:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.1817	Prec@(1,5) (45.4%, 75.9%)
11/20 10:33:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.1775	Prec@(1,5) (45.7%, 76.0%)
11/20 10:33:01午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 45.7440%
11/20 10:33:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/20 10:33:02午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7440%
11/20 10:33:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.2749 (1.1166)	Arch Loss 2.2029 (2.2761)	Arch Hard Loss 2.1489 (2.2212)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.0%)	
11/20 10:34:29午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.2358 (1.1469)	Arch Loss 2.4161 (2.2668)	Arch Hard Loss 2.3631 (2.2121)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.6%)	
11/20 10:35:12午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.1484 (1.1584)	Arch Loss 2.1074 (2.2669)	Arch Hard Loss 2.0527 (2.2125)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.4%)	
11/20 10:35:51午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.4425 (1.1703)	Arch Loss 2.5050 (2.2712)	Arch Hard Loss 2.4496 (2.2169)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.2%)	
11/20 10:35:52午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 66.1000%
11/20 10:35:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.1761	Prec@(1,5) (46.0%, 76.4%)
11/20 10:36:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.1847	Prec@(1,5) (45.9%, 76.3%)
11/20 10:36:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.1862	Prec@(1,5) (46.0%, 76.2%)
11/20 10:36:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.1760	Prec@(1,5) (46.1%, 76.3%)
11/20 10:36:18午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 46.0480%
11/20 10:36:18午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:36:18午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.0480%
11/20 10:37:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.9082 (1.0501)	Arch Loss 2.5496 (2.3026)	Arch Hard Loss 2.4988 (2.2486)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.8%)	
11/20 10:37:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.8937 (1.0564)	Arch Loss 2.5895 (2.2685)	Arch Hard Loss 2.5358 (2.2146)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.8%)	
11/20 10:38:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0147 (1.0900)	Arch Loss 2.6954 (2.2574)	Arch Hard Loss 2.6426 (2.2036)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.3%)	
11/20 10:39:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.0112 (1.1042)	Arch Loss 2.4662 (2.2670)	Arch Hard Loss 2.4145 (2.2132)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.2%)	
11/20 10:39:08午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 67.1560%
11/20 10:39:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1588	Prec@(1,5) (47.2%, 76.5%)
11/20 10:39:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1811	Prec@(1,5) (46.7%, 76.3%)
11/20 10:39:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1913	Prec@(1,5) (46.4%, 76.3%)
11/20 10:39:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1791	Prec@(1,5) (46.6%, 76.5%)
11/20 10:39:34午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 46.6240%
11/20 10:39:34午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:39:34午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6240%
11/20 10:40:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 1.2720 (0.9658)	Arch Loss 2.3818 (2.2548)	Arch Hard Loss 2.3262 (2.1999)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.0%)	
11/20 10:41:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.9175 (1.0042)	Arch Loss 2.3321 (2.2733)	Arch Hard Loss 2.2765 (2.2187)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.5%)	
11/20 10:41:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.3086 (1.0337)	Arch Loss 2.6740 (2.2867)	Arch Hard Loss 2.6144 (2.2322)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.0%)	
11/20 10:42:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.1330 (1.0444)	Arch Loss 1.9175 (2.2770)	Arch Hard Loss 1.8618 (2.2227)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.9%)	
11/20 10:42:23午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 68.9560%
11/20 10:42:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.1650	Prec@(1,5) (47.1%, 76.6%)
11/20 10:42:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.1606	Prec@(1,5) (46.9%, 76.9%)
11/20 10:42:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.1648	Prec@(1,5) (46.9%, 76.7%)
11/20 10:42:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.1689	Prec@(1,5) (46.7%, 76.7%)
11/20 10:42:49午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 46.7360%
11/20 10:42:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:42:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.7360%
11/20 10:43:34午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 1.0166 (0.9406)	Arch Loss 2.5866 (2.2673)	Arch Hard Loss 2.5342 (2.2134)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.4%)	
11/20 10:44:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7286 (0.9515)	Arch Loss 2.4441 (2.2650)	Arch Hard Loss 2.3927 (2.2109)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.0%)	
11/20 10:45:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.9597 (0.9698)	Arch Loss 2.0696 (2.2726)	Arch Hard Loss 2.0135 (2.2184)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.7%)	
11/20 10:45:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 1.1389 (0.9791)	Arch Loss 3.0465 (2.2799)	Arch Hard Loss 2.9932 (2.2258)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.5%)	
11/20 10:45:39午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 71.0480%
11/20 10:45:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1457	Prec@(1,5) (47.1%, 78.1%)
11/20 10:45:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1845	Prec@(1,5) (46.9%, 77.4%)
11/20 10:46:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1710	Prec@(1,5) (47.4%, 77.2%)
11/20 10:46:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1661	Prec@(1,5) (47.4%, 77.3%)
11/20 10:46:06午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 47.4160%
11/20 10:46:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:46:06午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.4160%
11/20 10:46:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6994 (0.8908)	Arch Loss 2.0782 (2.2850)	Arch Hard Loss 2.0211 (2.2307)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.8%)	
11/20 10:47:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.6260 (0.8961)	Arch Loss 2.5497 (2.2766)	Arch Hard Loss 2.4949 (2.2224)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/20 10:48:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 1.1127 (0.9016)	Arch Loss 2.5191 (2.2793)	Arch Hard Loss 2.4651 (2.2253)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.6%)	
11/20 10:48:55午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.7628 (0.9136)	Arch Loss 2.3101 (2.2778)	Arch Hard Loss 2.2584 (2.2238)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.3%)	
11/20 10:48:55午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 72.9000%
11/20 10:49:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.1861	Prec@(1,5) (47.3%, 77.4%)
11/20 10:49:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.1771	Prec@(1,5) (46.9%, 77.7%)
11/20 10:49:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.1702	Prec@(1,5) (47.2%, 77.5%)
11/20 10:49:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.1554	Prec@(1,5) (47.6%, 77.6%)
11/20 10:49:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 47.6480%
11/20 10:49:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:49:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.6480%
11/20 10:50:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 1.0371 (0.8246)	Arch Loss 2.9218 (2.2709)	Arch Hard Loss 2.8668 (2.2172)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.5%)	
11/20 10:50:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.7165 (0.8505)	Arch Loss 2.2732 (2.2857)	Arch Hard Loss 2.2183 (2.2320)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.1%)	
11/20 10:51:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.8037 (0.8567)	Arch Loss 2.6676 (2.2834)	Arch Hard Loss 2.6148 (2.2297)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
11/20 10:52:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 1.0079 (0.8646)	Arch Loss 2.6874 (2.2838)	Arch Hard Loss 2.6348 (2.2302)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.0%)	
11/20 10:52:10午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 74.2040%
11/20 10:52:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.1920	Prec@(1,5) (47.0%, 77.5%)
11/20 10:52:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.1950	Prec@(1,5) (47.5%, 77.0%)
11/20 10:52:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.1844	Prec@(1,5) (47.6%, 77.3%)
11/20 10:52:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.1858	Prec@(1,5) (47.8%, 77.4%)
11/20 10:52:36午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 47.7560%
11/20 10:52:36午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:52:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.7560%
11/20 10:53:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7168 (0.7668)	Arch Loss 2.3714 (2.2602)	Arch Hard Loss 2.3203 (2.2071)	Arch Alpha Loss 0.0102 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 96.3%)	
11/20 10:54:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6173 (0.7915)	Arch Loss 2.4052 (2.2872)	Arch Hard Loss 2.3521 (2.2340)	Arch Alpha Loss 0.0106 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.8%)	
11/20 10:54:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.9724 (0.8040)	Arch Loss 2.3890 (2.2977)	Arch Hard Loss 2.3368 (2.2445)	Arch Alpha Loss 0.0104 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.7%)	
11/20 10:55:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 1.1277 (0.8171)	Arch Loss 2.9700 (2.3038)	Arch Hard Loss 2.9191 (2.2506)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.6%)	
11/20 10:55:26午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 75.2280%
11/20 10:55:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.1396	Prec@(1,5) (48.8%, 77.8%)
11/20 10:55:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.1724	Prec@(1,5) (48.2%, 77.3%)
11/20 10:55:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.1520	Prec@(1,5) (48.7%, 77.8%)
11/20 10:55:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.1835	Prec@(1,5) (48.4%, 77.3%)
11/20 10:55:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 48.4320%
11/20 10:55:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:55:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4320%
11/20 10:56:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.6013 (0.7506)	Arch Loss 2.0909 (2.3589)	Arch Hard Loss 2.0351 (2.3054)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
11/20 10:57:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.9003 (0.7543)	Arch Loss 2.0406 (2.3305)	Arch Hard Loss 1.9861 (2.2769)	Arch Alpha Loss 0.0109 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.3%)	
11/20 10:58:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6675 (0.7616)	Arch Loss 2.1964 (2.3153)	Arch Hard Loss 2.1399 (2.2620)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.2%)	
11/20 10:58:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.7697 (0.7700)	Arch Loss 2.1535 (2.3121)	Arch Hard Loss 2.1025 (2.2588)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
11/20 10:58:43午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 76.8800%
11/20 10:58:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.2260	Prec@(1,5) (47.7%, 77.3%)
11/20 10:58:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.1902	Prec@(1,5) (48.0%, 77.9%)
11/20 10:59:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.1819	Prec@(1,5) (48.3%, 77.8%)
11/20 10:59:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.1969	Prec@(1,5) (48.2%, 77.6%)
11/20 10:59:09午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 48.1720%
11/20 10:59:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 10:59:09午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4320%
11/20 10:59:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5004 (0.6921)	Arch Loss 2.0257 (2.3531)	Arch Hard Loss 1.9747 (2.2997)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.9%)	
11/20 11:00:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6066 (0.7168)	Arch Loss 2.6242 (2.3377)	Arch Hard Loss 2.5710 (2.2845)	Arch Alpha Loss 0.0106 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/20 11:01:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.7390 (0.7294)	Arch Loss 2.1797 (2.3243)	Arch Hard Loss 2.1237 (2.2711)	Arch Alpha Loss 0.0112 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.5%)	
11/20 11:01:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.8467 (0.7371)	Arch Loss 1.6784 (2.3286)	Arch Hard Loss 1.6211 (2.2752)	Arch Alpha Loss 0.0115 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.4%)	
11/20 11:01:59午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 77.9720%
11/20 11:02:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.1892	Prec@(1,5) (48.8%, 77.9%)
11/20 11:02:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.2011	Prec@(1,5) (48.3%, 77.5%)
11/20 11:02:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.2053	Prec@(1,5) (48.4%, 77.4%)
11/20 11:02:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.1990	Prec@(1,5) (48.5%, 77.5%)
11/20 11:02:25午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 48.4520%
11/20 11:02:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 11:02:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4520%
11/20 11:03:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.7276 (0.6696)	Arch Loss 3.0580 (2.3462)	Arch Hard Loss 3.0056 (2.2927)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 96.7%)	
11/20 11:03:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.8854 (0.6914)	Arch Loss 2.0904 (2.3403)	Arch Hard Loss 2.0377 (2.2871)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.6%)	
11/20 11:04:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.8516 (0.6973)	Arch Loss 2.3079 (2.3405)	Arch Hard Loss 2.2531 (2.2873)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.7%)	
11/20 11:05:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7955 (0.7061)	Arch Loss 2.4621 (2.3310)	Arch Hard Loss 2.4097 (2.2776)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.6%)	
11/20 11:05:14午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 78.9000%
11/20 11:05:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.2069	Prec@(1,5) (48.2%, 77.8%)
11/20 11:05:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.2372	Prec@(1,5) (48.0%, 77.3%)
11/20 11:05:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.2274	Prec@(1,5) (48.2%, 77.6%)
11/20 11:05:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.2237	Prec@(1,5) (48.3%, 77.5%)
11/20 11:05:40午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 48.2560%
11/20 11:05:40午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 11:05:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4520%
11/20 11:06:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.7340 (0.6678)	Arch Loss 2.5126 (2.2942)	Arch Hard Loss 2.4563 (2.2404)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.1%)	
11/20 11:07:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.7826 (0.6656)	Arch Loss 2.3815 (2.3221)	Arch Hard Loss 2.3278 (2.2683)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.0%)	
11/20 11:07:51午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.8097 (0.6669)	Arch Loss 2.1093 (2.3499)	Arch Hard Loss 2.0552 (2.2962)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.0%)	
11/20 11:08:30午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.7986 (0.6719)	Arch Loss 2.8847 (2.3472)	Arch Hard Loss 2.8302 (2.2935)	Arch Alpha Loss 0.0109 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/20 11:08:31午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 79.9120%
11/20 11:08:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.2189	Prec@(1,5) (48.6%, 78.1%)
11/20 11:08:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.2200	Prec@(1,5) (48.7%, 77.6%)
11/20 11:08:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.2356	Prec@(1,5) (48.5%, 77.4%)
11/20 11:08:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.2358	Prec@(1,5) (48.6%, 77.5%)
11/20 11:08:57午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 48.5880%
11/20 11:08:57午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 11:08:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5880%
11/20 11:09:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.5817 (0.6398)	Arch Loss 2.1507 (2.3365)	Arch Hard Loss 2.0979 (2.2833)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.3%)	
11/20 11:10:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6867 (0.6374)	Arch Loss 2.2211 (2.3314)	Arch Hard Loss 2.1717 (2.2782)	Arch Alpha Loss 0.0099 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.2%)	
11/20 11:11:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.7742 (0.6436)	Arch Loss 1.9805 (2.3325)	Arch Hard Loss 1.9295 (2.2794)	Arch Alpha Loss 0.0102 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.2%)	
11/20 11:11:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.6764 (0.6492)	Arch Loss 2.5375 (2.3343)	Arch Hard Loss 2.4869 (2.2812)	Arch Alpha Loss 0.0101 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.2%)	
11/20 11:11:47午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 80.8440%
11/20 11:11:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.1992	Prec@(1,5) (49.3%, 77.7%)
11/20 11:12:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.2013	Prec@(1,5) (49.2%, 77.9%)
11/20 11:12:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.2241	Prec@(1,5) (48.7%, 77.7%)
11/20 11:12:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.2389	Prec@(1,5) (48.6%, 77.5%)
11/20 11:12:13午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 48.5960%
11/20 11:12:13午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 11:12:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5960%
11/20 11:12:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6475 (0.6150)	Arch Loss 2.0783 (2.3417)	Arch Hard Loss 2.0205 (2.2888)	Arch Alpha Loss 0.0115 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.3%)	
11/20 11:13:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.4618 (0.6177)	Arch Loss 2.4269 (2.3388)	Arch Hard Loss 2.3705 (2.2854)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.3%)	
11/20 11:14:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5692 (0.6250)	Arch Loss 2.0949 (2.3610)	Arch Hard Loss 2.0386 (2.3074)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.2%)	
11/20 11:15:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5718 (0.6274)	Arch Loss 2.6998 (2.3562)	Arch Hard Loss 2.6453 (2.3024)	Arch Alpha Loss 0.0109 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.3%)	
11/20 11:15:03午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 81.6360%
11/20 11:15:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.1998	Prec@(1,5) (49.7%, 78.0%)
11/20 11:15:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.2206	Prec@(1,5) (49.4%, 77.9%)
11/20 11:15:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.2261	Prec@(1,5) (49.2%, 77.9%)
11/20 11:15:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.2428	Prec@(1,5) (48.8%, 77.7%)
11/20 11:15:29午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 48.8080%
11/20 11:15:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 11:15:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.8080%
11/20 11:16:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4258 (0.5768)	Arch Loss 2.6265 (2.3214)	Arch Hard Loss 2.5714 (2.2673)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.8%)	
11/20 11:16:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5718 (0.5861)	Arch Loss 2.6164 (2.3534)	Arch Hard Loss 2.5611 (2.2992)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.7%)	
11/20 11:17:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.6260 (0.5965)	Arch Loss 2.0873 (2.3642)	Arch Hard Loss 2.0300 (2.3099)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
11/20 11:18:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5728 (0.6014)	Arch Loss 2.0793 (2.3835)	Arch Hard Loss 2.0204 (2.3292)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.7%)	
11/20 11:18:19午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 82.3520%
11/20 11:18:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.2318	Prec@(1,5) (48.8%, 78.0%)
11/20 11:18:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.2455	Prec@(1,5) (48.3%, 77.8%)
11/20 11:18:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.2486	Prec@(1,5) (48.4%, 77.7%)
11/20 11:18:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.2393	Prec@(1,5) (48.6%, 77.7%)
11/20 11:18:45午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 48.5840%
11/20 11:18:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 11:18:45午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.8080%
11/20 11:18:45午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 48.8080%
11/20 11:18:45午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
