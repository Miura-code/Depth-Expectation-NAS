11/09 11:47:32AM parser.py:28 [INFO] 
11/09 11:47:32AM parser.py:29 [INFO] Parameters:
11/09 11:47:32AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s2-L1Alpha-sw3/DAG
11/09 11:47:32AM parser.py:31 [INFO] T=10.0
11/09 11:47:32AM parser.py:31 [INFO] ADVANCED=1
11/09 11:47:32AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/09 11:47:32AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/09 11:47:32AM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/09 11:47:32AM parser.py:31 [INFO] BATCH_SIZE=64
11/09 11:47:32AM parser.py:31 [INFO] CASCADE=0
11/09 11:47:32AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/09 11:47:32AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/09 11:47:32AM parser.py:31 [INFO] DATA_PATH=../data/
11/09 11:47:32AM parser.py:31 [INFO] DATASET=cifar100
11/09 11:47:32AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/09 11:47:32AM parser.py:31 [INFO] DESCRIPTION=search_wtih_alpha-L1-constriction
11/09 11:47:32AM parser.py:31 [INFO] DISCRETE=0
11/09 11:47:32AM parser.py:31 [INFO] EPOCHS=50
11/09 11:47:32AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/09 11:47:32AM parser.py:31 [INFO] EXP_NAME=s2-L1Alpha-sw3
11/09 11:47:32AM parser.py:31 [INFO] FINAL_L=1.0
11/09 11:47:32AM parser.py:31 [INFO] G=1.0
11/09 11:47:32AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/09 11:47:32AM parser.py:31 [INFO] GPUS=[0]
11/09 11:47:32AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/09 11:47:32AM parser.py:31 [INFO] INIT_CHANNELS=16
11/09 11:47:32AM parser.py:31 [INFO] L=0.0
11/09 11:47:32AM parser.py:31 [INFO] LAYERS=20
11/09 11:47:32AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/09 11:47:32AM parser.py:31 [INFO] NAME=Pruning
11/09 11:47:32AM parser.py:31 [INFO] NONKD=1
11/09 11:47:32AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s2-L1Alpha-sw3
11/09 11:47:32AM parser.py:31 [INFO] PCDARTS=0
11/09 11:47:32AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s2-L1Alpha-sw3/plots
11/09 11:47:32AM parser.py:31 [INFO] PRINT_FREQ=100
11/09 11:47:32AM parser.py:31 [INFO] RESET=0
11/09 11:47:32AM parser.py:31 [INFO] RESUME_PATH=None
11/09 11:47:32AM parser.py:31 [INFO] SAVE=s2-L1Alpha-sw3
11/09 11:47:32AM parser.py:31 [INFO] SEED=2
11/09 11:47:32AM parser.py:31 [INFO] SHARE_STAGE=0
11/09 11:47:32AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/09 11:47:32AM parser.py:31 [INFO] SPEC_CELL=1
11/09 11:47:32AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/09 11:47:32AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/09 11:47:32AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/09 11:47:32AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/09 11:47:32AM parser.py:31 [INFO] TYPE=ArchKD
11/09 11:47:32AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/09 11:47:32AM parser.py:31 [INFO] W_LR=0.025
11/09 11:47:32AM parser.py:31 [INFO] W_LR_MIN=0.001
11/09 11:47:32AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/09 11:47:32AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/09 11:47:32AM parser.py:31 [INFO] WORKERS=4
11/09 11:47:32AM parser.py:32 [INFO] 
11/09 11:47:34AM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/09 11:47:35AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/09 11:48:07AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6138 (4.6409)	Arch Loss 4.3506 (4.6538)	Arch Hard Loss 4.3506 (4.6538)	Arch Alpha Loss 0.0727 (0.0532)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.8%, 8.7%)	
11/09 11:48:36AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1107 (4.4783)	Arch Loss 4.2043 (4.4819)	Arch Hard Loss 4.2043 (4.4819)	Arch Alpha Loss 0.0810 (0.0639)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 12.4%)	
11/09 11:49:04AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9843 (4.3680)	Arch Loss 4.1102 (4.3660)	Arch Hard Loss 4.1102 (4.3660)	Arch Alpha Loss 0.1340 (0.0776)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.8%, 15.6%)	
11/09 11:49:29AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.0913 (4.2962)	Arch Loss 3.8451 (4.2961)	Arch Hard Loss 3.8451 (4.2961)	Arch Alpha Loss 0.1806 (0.0952)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.5%, 17.3%)	
11/09 11:49:30AM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 4.5160%
11/09 11:49:35AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0320	Prec@(1,5) (6.5%, 24.6%)
11/09 11:49:39AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.0299	Prec@(1,5) (6.6%, 24.6%)
11/09 11:49:44AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0283	Prec@(1,5) (6.6%, 24.8%)
11/09 11:49:48AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0287	Prec@(1,5) (6.6%, 24.8%)
11/09 11:49:48AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 6.5800%
11/09 11:49:48AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)]], DAG1_concat=range(6, 8), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=range(6, 8))
11/09 11:49:48AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 6.5800%
11/09 11:50:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8863 (3.9650)	Arch Loss 3.8603 (3.9762)	Arch Hard Loss 3.8602 (3.9761)	Arch Alpha Loss 0.1051 (0.1443)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.3%, 26.4%)	
11/09 11:50:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.0626 (3.9319)	Arch Loss 3.7585 (3.9422)	Arch Hard Loss 3.7584 (3.9421)	Arch Alpha Loss 0.0850 (0.1225)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.1%, 27.9%)	
11/09 11:51:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 4.1478 (3.9017)	Arch Loss 3.8755 (3.9025)	Arch Hard Loss 3.8754 (3.9024)	Arch Alpha Loss 0.0937 (0.1113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.6%, 29.1%)	
11/09 11:51:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7763 (3.8772)	Arch Loss 3.7512 (3.8725)	Arch Hard Loss 3.7511 (3.8724)	Arch Alpha Loss 0.1249 (0.1107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.1%, 29.8%)	
11/09 11:51:42午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 9.0680%
11/09 11:51:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.7502	Prec@(1,5) (11.3%, 34.5%)
11/09 11:51:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.7397	Prec@(1,5) (11.7%, 34.6%)
11/09 11:51:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.7391	Prec@(1,5) (11.6%, 34.4%)
11/09 11:51:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.7373	Prec@(1,5) (11.6%, 34.4%)
11/09 11:51:59午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 11.5800%
11/09 11:51:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=range(6, 8))
11/09 11:52:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 11.5800%
11/09 11:52:30午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8950 (3.7041)	Arch Loss 3.8643 (3.7150)	Arch Hard Loss 3.8640 (3.7146)	Arch Alpha Loss 0.0775 (0.0930)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.2%, 34.7%)	
11/09 11:52:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.6301 (3.6786)	Arch Loss 3.6812 (3.6891)	Arch Hard Loss 3.6809 (3.6888)	Arch Alpha Loss 0.0769 (0.0846)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.9%, 36.1%)	
11/09 11:53:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.5445 (3.6505)	Arch Loss 3.6828 (3.6493)	Arch Hard Loss 3.6825 (3.6490)	Arch Alpha Loss 0.0637 (0.0795)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.4%, 37.0%)	
11/09 11:53:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.3351 (3.6340)	Arch Loss 3.6507 (3.6356)	Arch Hard Loss 3.6504 (3.6353)	Arch Alpha Loss 0.0714 (0.0770)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.7%, 37.3%)	
11/09 11:53:53午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 12.7160%
11/09 11:53:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4949	Prec@(1,5) (15.0%, 41.9%)
11/09 11:54:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.5122	Prec@(1,5) (14.8%, 41.0%)
11/09 11:54:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.5190	Prec@(1,5) (14.6%, 40.8%)
11/09 11:54:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.5239	Prec@(1,5) (14.7%, 40.9%)
11/09 11:54:09午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 14.6440%
11/09 11:54:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 11:54:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.6440%
11/09 11:54:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5519 (3.4792)	Arch Loss 3.7944 (3.5239)	Arch Hard Loss 3.7940 (3.5235)	Arch Alpha Loss 0.0413 (0.0507)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 42.5%)	
11/09 11:55:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.3862 (3.4582)	Arch Loss 3.5960 (3.4852)	Arch Hard Loss 3.5957 (3.4848)	Arch Alpha Loss 0.0270 (0.0422)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.0%, 43.1%)	
11/09 11:55:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.2235 (3.4542)	Arch Loss 3.2799 (3.4625)	Arch Hard Loss 3.2797 (3.4622)	Arch Alpha Loss 0.0257 (0.0371)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.1%, 43.0%)	
11/09 11:56:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9968 (3.4323)	Arch Loss 3.0586 (3.4458)	Arch Hard Loss 3.0583 (3.4455)	Arch Alpha Loss 0.0265 (0.0343)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.4%, 43.7%)	
11/09 11:56:02午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 16.4120%
11/09 11:56:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.4157	Prec@(1,5) (17.3%, 44.0%)
11/09 11:56:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.4187	Prec@(1,5) (17.2%, 44.4%)
11/09 11:56:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.4165	Prec@(1,5) (17.0%, 44.6%)
11/09 11:56:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.4170	Prec@(1,5) (17.0%, 44.6%)
11/09 11:56:19午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 17.0000%
11/09 11:56:19午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 11:56:19午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.0000%
11/09 11:56:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.6784 (3.3066)	Arch Loss 3.3031 (3.3694)	Arch Hard Loss 3.3028 (3.3691)	Arch Alpha Loss 0.0165 (0.0204)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.4%, 46.7%)	
11/09 11:57:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.4318 (3.2896)	Arch Loss 3.3190 (3.3157)	Arch Hard Loss 3.3188 (3.3155)	Arch Alpha Loss 0.0145 (0.0175)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.9%, 46.9%)	
11/09 11:57:46午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.2110 (3.2714)	Arch Loss 3.1119 (3.2882)	Arch Hard Loss 3.1117 (3.2879)	Arch Alpha Loss 0.0119 (0.0161)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 47.7%)	
11/09 11:58:12午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.2542 (3.2631)	Arch Loss 3.1816 (3.2812)	Arch Hard Loss 3.1815 (3.2810)	Arch Alpha Loss 0.0085 (0.0147)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.7%, 48.0%)	
11/09 11:58:12午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 19.6320%
11/09 11:58:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.2614	Prec@(1,5) (19.8%, 49.3%)
11/09 11:58:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.2961	Prec@(1,5) (18.9%, 48.1%)
11/09 11:58:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.3046	Prec@(1,5) (18.7%, 47.6%)
11/09 11:58:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.2951	Prec@(1,5) (18.9%, 47.9%)
11/09 11:58:29午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 18.9000%
11/09 11:58:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 11:58:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 18.9000%
11/09 11:58:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.0762 (3.1001)	Arch Loss 3.3820 (3.1796)	Arch Hard Loss 3.3818 (3.1794)	Arch Alpha Loss 0.0080 (0.0089)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.0%, 52.7%)	
11/09 11:59:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.2228 (3.1078)	Arch Loss 2.9422 (3.1783)	Arch Hard Loss 2.9420 (3.1782)	Arch Alpha Loss 0.0059 (0.0077)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.1%, 52.3%)	
11/09 11:59:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.7700 (3.0954)	Arch Loss 3.0619 (3.1557)	Arch Hard Loss 3.0618 (3.1555)	Arch Alpha Loss 0.0046 (0.0071)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.5%)	
11/09 12:00:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.3747 (3.0897)	Arch Loss 3.5951 (3.1413)	Arch Hard Loss 3.5950 (3.1411)	Arch Alpha Loss 0.0053 (0.0068)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.7%)	
11/09 12:00:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 22.4280%
11/09 12:00:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.1009	Prec@(1,5) (22.6%, 52.9%)
11/09 12:00:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.0923	Prec@(1,5) (23.0%, 53.2%)
11/09 12:00:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.0850	Prec@(1,5) (22.8%, 53.4%)
11/09 12:00:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.0796	Prec@(1,5) (22.9%, 53.5%)
11/09 12:00:40午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 22.9000%
11/09 12:00:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 12:00:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.9000%
11/09 12:01:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8021 (2.9783)	Arch Loss 3.3811 (3.0226)	Arch Hard Loss 3.3809 (3.0224)	Arch Alpha Loss 0.0058 (0.0064)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.3%, 55.7%)	
11/09 12:01:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.0516 (2.9593)	Arch Loss 3.2328 (3.0183)	Arch Hard Loss 3.2327 (3.0181)	Arch Alpha Loss 0.0045 (0.0061)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 56.4%)	
11/09 12:02:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.6916 (2.9660)	Arch Loss 3.0836 (3.0187)	Arch Hard Loss 3.0834 (3.0185)	Arch Alpha Loss 0.0053 (0.0058)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.4%, 56.1%)	
11/09 12:02:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.6217 (2.9523)	Arch Loss 2.8118 (3.0065)	Arch Hard Loss 2.8116 (3.0063)	Arch Alpha Loss 0.0046 (0.0057)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.5%, 56.6%)	
11/09 12:02:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 25.4680%
11/09 12:02:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.0557	Prec@(1,5) (23.8%, 54.8%)
11/09 12:02:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.0406	Prec@(1,5) (24.4%, 55.4%)
11/09 12:02:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.0319	Prec@(1,5) (24.5%, 55.6%)
11/09 12:02:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.0354	Prec@(1,5) (24.3%, 55.4%)
11/09 12:02:52午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 24.2680%
11/09 12:02:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 12:02:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.2680%
11/09 12:03:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.8953 (2.8233)	Arch Loss 3.4194 (2.9128)	Arch Hard Loss 3.4191 (2.9125)	Arch Alpha Loss 0.0053 (0.0058)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 59.4%)	
11/09 12:03:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.9882 (2.8205)	Arch Loss 2.8867 (2.9181)	Arch Hard Loss 2.8864 (2.9178)	Arch Alpha Loss 0.0051 (0.0056)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.8%, 59.5%)	
11/09 12:04:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.0773 (2.8255)	Arch Loss 2.6081 (2.9028)	Arch Hard Loss 2.6079 (2.9025)	Arch Alpha Loss 0.0043 (0.0054)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.8%, 59.4%)	
11/09 12:04:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.8452 (2.8197)	Arch Loss 2.4680 (2.8849)	Arch Hard Loss 2.4678 (2.8846)	Arch Alpha Loss 0.0048 (0.0053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.1%, 59.5%)	
11/09 12:04:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 28.1280%
11/09 12:04:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.8372	Prec@(1,5) (28.1%, 59.3%)
11/09 12:04:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.8315	Prec@(1,5) (28.2%, 59.6%)
11/09 12:04:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.8478	Prec@(1,5) (27.6%, 59.4%)
11/09 12:05:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.8394	Prec@(1,5) (27.8%, 59.7%)
11/09 12:05:03午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 27.8720%
11/09 12:05:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 12:05:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.8720%
11/09 12:05:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4564 (2.6770)	Arch Loss 2.7458 (2.8127)	Arch Hard Loss 2.7454 (2.8123)	Arch Alpha Loss 0.0060 (0.0055)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.9%, 63.0%)	
11/09 12:06:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.4298 (2.6882)	Arch Loss 2.8956 (2.8034)	Arch Hard Loss 2.8953 (2.8031)	Arch Alpha Loss 0.0053 (0.0053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.4%, 63.1%)	
11/09 12:06:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.7348 (2.6887)	Arch Loss 2.6477 (2.8042)	Arch Hard Loss 2.6474 (2.8038)	Arch Alpha Loss 0.0052 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.5%, 63.0%)	
11/09 12:06:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.6451 (2.6844)	Arch Loss 2.6507 (2.7852)	Arch Hard Loss 2.6504 (2.7849)	Arch Alpha Loss 0.0048 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.5%, 63.1%)	
11/09 12:06:57午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 30.5240%
11/09 12:07:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.7288	Prec@(1,5) (30.6%, 62.5%)
11/09 12:07:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.7313	Prec@(1,5) (30.1%, 62.5%)
11/09 12:07:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.7309	Prec@(1,5) (29.9%, 62.4%)
11/09 12:07:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.7319	Prec@(1,5) (30.0%, 62.3%)
11/09 12:07:14午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 30.0200%
11/09 12:07:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 12:07:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.0200%
11/09 12:07:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.5897 (2.5410)	Arch Loss 2.7645 (2.7027)	Arch Hard Loss 2.7641 (2.7022)	Arch Alpha Loss 0.0051 (0.0054)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.6%)	
11/09 12:08:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.4390 (2.5681)	Arch Loss 2.4661 (2.7019)	Arch Hard Loss 2.4657 (2.7015)	Arch Alpha Loss 0.0049 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.8%)	
11/09 12:08:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.1094 (2.5695)	Arch Loss 2.6894 (2.6986)	Arch Hard Loss 2.6891 (2.6983)	Arch Alpha Loss 0.0044 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.9%)	
11/09 12:09:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.4167 (2.5775)	Arch Loss 2.6788 (2.6860)	Arch Hard Loss 2.6785 (2.6856)	Arch Alpha Loss 0.0043 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.6%)	
11/09 12:09:07午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 32.7440%
11/09 12:09:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.6636	Prec@(1,5) (31.4%, 63.5%)
11/09 12:09:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.6331	Prec@(1,5) (31.9%, 64.3%)
11/09 12:09:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.6213	Prec@(1,5) (32.2%, 64.6%)
11/09 12:09:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.6228	Prec@(1,5) (32.3%, 64.6%)
11/09 12:09:24午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 32.2840%
11/09 12:09:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 12:09:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.2840%
11/09 12:09:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.4818 (2.4820)	Arch Loss 2.4729 (2.6825)	Arch Hard Loss 2.4724 (2.6820)	Arch Alpha Loss 0.0054 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.0%, 67.9%)	
11/09 12:10:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4137 (2.4753)	Arch Loss 2.9860 (2.6435)	Arch Hard Loss 2.9855 (2.6430)	Arch Alpha Loss 0.0052 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.4%, 68.0%)	
11/09 12:10:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.6240 (2.4647)	Arch Loss 2.5442 (2.6111)	Arch Hard Loss 2.5438 (2.6106)	Arch Alpha Loss 0.0045 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.0%)	
11/09 12:11:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.4711 (2.4770)	Arch Loss 2.9507 (2.6046)	Arch Hard Loss 2.9503 (2.6042)	Arch Alpha Loss 0.0047 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 67.8%)	
11/09 12:11:18午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 35.2920%
11/09 12:11:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.6207	Prec@(1,5) (32.7%, 64.5%)
11/09 12:11:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.6054	Prec@(1,5) (33.2%, 65.4%)
11/09 12:11:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.5901	Prec@(1,5) (33.7%, 65.5%)
11/09 12:11:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.6003	Prec@(1,5) (33.5%, 65.3%)
11/09 12:11:35午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 33.4800%
11/09 12:11:35午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/09 12:11:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.4800%
11/09 12:12:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.2341 (2.3681)	Arch Loss 2.3384 (2.5574)	Arch Hard Loss 2.3380 (2.5568)	Arch Alpha Loss 0.0043 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 69.6%)	
11/09 12:12:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4027 (2.3799)	Arch Loss 2.7051 (2.5607)	Arch Hard Loss 2.7045 (2.5602)	Arch Alpha Loss 0.0050 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.4%, 69.7%)	
11/09 12:13:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.3471 (2.3779)	Arch Loss 2.5736 (2.5531)	Arch Hard Loss 2.5731 (2.5525)	Arch Alpha Loss 0.0048 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.6%)	
11/09 12:13:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.2913 (2.3743)	Arch Loss 2.4648 (2.5371)	Arch Hard Loss 2.4643 (2.5365)	Arch Alpha Loss 0.0045 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 69.8%)	
11/09 12:13:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 37.5880%
11/09 12:13:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.5886	Prec@(1,5) (33.3%, 65.7%)
11/09 12:13:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.6011	Prec@(1,5) (32.9%, 65.4%)
11/09 12:13:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.6094	Prec@(1,5) (32.7%, 65.3%)
11/09 12:13:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.6165	Prec@(1,5) (32.6%, 64.9%)
11/09 12:13:46午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 32.6000%
11/09 12:13:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:13:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.4800%
11/09 12:14:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4352 (2.2642)	Arch Loss 2.4774 (2.5498)	Arch Hard Loss 2.4768 (2.5492)	Arch Alpha Loss 0.0045 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 72.0%)	
11/09 12:14:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.8647 (2.2815)	Arch Loss 2.7972 (2.5150)	Arch Hard Loss 2.7966 (2.5144)	Arch Alpha Loss 0.0048 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.6%)	
11/09 12:15:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.0667 (2.2839)	Arch Loss 2.4743 (2.4995)	Arch Hard Loss 2.4737 (2.4989)	Arch Alpha Loss 0.0046 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 71.7%)	
11/09 12:15:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.3607 (2.2872)	Arch Loss 2.2583 (2.4893)	Arch Hard Loss 2.2577 (2.4887)	Arch Alpha Loss 0.0045 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 71.6%)	
11/09 12:15:40午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 38.7280%
11/09 12:15:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.5206	Prec@(1,5) (35.5%, 67.4%)
11/09 12:15:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.5019	Prec@(1,5) (35.8%, 67.8%)
11/09 12:15:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.5052	Prec@(1,5) (35.7%, 67.7%)
11/09 12:15:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.5123	Prec@(1,5) (35.3%, 67.6%)
11/09 12:15:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 35.3240%
11/09 12:15:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:15:57午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.3240%
11/09 12:16:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.8740 (2.1550)	Arch Loss 2.9143 (2.4108)	Arch Hard Loss 2.9137 (2.4100)	Arch Alpha Loss 0.0042 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.8%)	
11/09 12:16:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.2324 (2.1714)	Arch Loss 2.5262 (2.4121)	Arch Hard Loss 2.5256 (2.4114)	Arch Alpha Loss 0.0043 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 74.2%)	
11/09 12:17:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.1034 (2.1894)	Arch Loss 2.7691 (2.4237)	Arch Hard Loss 2.7684 (2.4230)	Arch Alpha Loss 0.0043 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 74.0%)	
11/09 12:17:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.3535 (2.1999)	Arch Loss 2.6865 (2.4185)	Arch Hard Loss 2.6858 (2.4178)	Arch Alpha Loss 0.0042 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.6%, 73.8%)	
11/09 12:17:51午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 40.6360%
11/09 12:17:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.4077	Prec@(1,5) (37.9%, 68.7%)
11/09 12:17:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.4096	Prec@(1,5) (37.6%, 69.4%)
11/09 12:18:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.4125	Prec@(1,5) (37.5%, 69.6%)
11/09 12:18:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.4034	Prec@(1,5) (37.7%, 69.6%)
11/09 12:18:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 37.6440%
11/09 12:18:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:18:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.6440%
11/09 12:18:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.2287 (2.1192)	Arch Loss 2.3165 (2.4204)	Arch Hard Loss 2.3157 (2.4196)	Arch Alpha Loss 0.0048 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 74.9%)	
11/09 12:19:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.2280 (2.1337)	Arch Loss 2.8363 (2.3838)	Arch Hard Loss 2.8356 (2.3830)	Arch Alpha Loss 0.0038 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 74.6%)	
11/09 12:19:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.9825 (2.1329)	Arch Loss 2.2022 (2.3748)	Arch Hard Loss 2.2015 (2.3740)	Arch Alpha Loss 0.0038 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 74.6%)	
11/09 12:20:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.2901 (2.1342)	Arch Loss 2.2004 (2.3702)	Arch Hard Loss 2.1997 (2.3694)	Arch Alpha Loss 0.0042 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.2%, 74.8%)	
11/09 12:20:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 42.2080%
11/09 12:20:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.3213	Prec@(1,5) (39.2%, 70.8%)
11/09 12:20:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.3380	Prec@(1,5) (38.5%, 70.5%)
11/09 12:20:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.3323	Prec@(1,5) (38.8%, 70.4%)
11/09 12:20:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.3324	Prec@(1,5) (38.8%, 70.5%)
11/09 12:20:19午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 38.7640%
11/09 12:20:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:20:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.7640%
11/09 12:20:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.0052 (2.0283)	Arch Loss 2.3056 (2.3674)	Arch Hard Loss 2.3048 (2.3665)	Arch Alpha Loss 0.0040 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.2%, 76.9%)	
11/09 12:21:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.1340 (2.0518)	Arch Loss 2.1293 (2.3385)	Arch Hard Loss 2.1284 (2.3376)	Arch Alpha Loss 0.0043 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.4%)	
11/09 12:21:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9430 (2.0577)	Arch Loss 1.6970 (2.3210)	Arch Hard Loss 1.6959 (2.3201)	Arch Alpha Loss 0.0053 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.5%)	
11/09 12:22:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.0514 (2.0615)	Arch Loss 2.1420 (2.3146)	Arch Hard Loss 2.1410 (2.3137)	Arch Alpha Loss 0.0047 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.4%)	
11/09 12:22:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 43.9680%
11/09 12:22:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.2831	Prec@(1,5) (40.1%, 71.8%)
11/09 12:22:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.3027	Prec@(1,5) (39.7%, 71.5%)
11/09 12:22:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.3197	Prec@(1,5) (39.2%, 71.1%)
11/09 12:22:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.3153	Prec@(1,5) (39.3%, 71.3%)
11/09 12:22:30午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 39.2720%
11/09 12:22:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:22:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.2720%
11/09 12:23:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.3354 (1.9780)	Arch Loss 2.2148 (2.2644)	Arch Hard Loss 2.2137 (2.2634)	Arch Alpha Loss 0.0045 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.3%)	
11/09 12:23:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.7222 (1.9748)	Arch Loss 1.9608 (2.2619)	Arch Hard Loss 1.9598 (2.2609)	Arch Alpha Loss 0.0043 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.1%)	
11/09 12:23:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.5617 (1.9829)	Arch Loss 2.0944 (2.2690)	Arch Hard Loss 2.0934 (2.2680)	Arch Alpha Loss 0.0044 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.7%, 78.0%)	
11/09 12:24:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.6998 (1.9809)	Arch Loss 1.9835 (2.2598)	Arch Hard Loss 1.9825 (2.2589)	Arch Alpha Loss 0.0040 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.0%)	
11/09 12:24:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 45.8080%
11/09 12:24:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.2798	Prec@(1,5) (40.9%, 72.3%)
11/09 12:24:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.2752	Prec@(1,5) (41.1%, 72.9%)
11/09 12:24:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.2553	Prec@(1,5) (41.2%, 73.3%)
11/09 12:24:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.2684	Prec@(1,5) (41.0%, 72.9%)
11/09 12:24:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 40.9960%
11/09 12:24:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:24:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.9960%
11/09 12:25:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.9061 (1.8844)	Arch Loss 2.4733 (2.2232)	Arch Hard Loss 2.4721 (2.2220)	Arch Alpha Loss 0.0048 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 79.9%)	
11/09 12:25:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.1330 (1.9107)	Arch Loss 2.2362 (2.2338)	Arch Hard Loss 2.2350 (2.2327)	Arch Alpha Loss 0.0046 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.4%)	
11/09 12:26:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8912 (1.9191)	Arch Loss 2.3326 (2.2280)	Arch Hard Loss 2.3314 (2.2269)	Arch Alpha Loss 0.0044 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.3%)	
11/09 12:26:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.0712 (1.9216)	Arch Loss 2.1983 (2.2333)	Arch Hard Loss 2.1973 (2.2322)	Arch Alpha Loss 0.0039 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.2%)	
11/09 12:26:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 47.1960%
11/09 12:26:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.1641	Prec@(1,5) (42.8%, 74.5%)
11/09 12:26:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.1730	Prec@(1,5) (42.4%, 74.9%)
11/09 12:26:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.1828	Prec@(1,5) (42.3%, 74.6%)
11/09 12:26:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.1774	Prec@(1,5) (42.6%, 74.7%)
11/09 12:26:52午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 42.5920%
11/09 12:26:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:26:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5920%
11/09 12:27:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.6818 (1.8381)	Arch Loss 1.9651 (2.2067)	Arch Hard Loss 1.9638 (2.2055)	Arch Alpha Loss 0.0042 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.7%)	
11/09 12:27:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.7838 (1.8438)	Arch Loss 2.4666 (2.1890)	Arch Hard Loss 2.4653 (2.1878)	Arch Alpha Loss 0.0046 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.4%)	
11/09 12:28:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.9080 (1.8541)	Arch Loss 2.0130 (2.1885)	Arch Hard Loss 2.0118 (2.1873)	Arch Alpha Loss 0.0043 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.2%)	
11/09 12:28:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.9168 (1.8569)	Arch Loss 2.0549 (2.1833)	Arch Hard Loss 2.0537 (2.1821)	Arch Alpha Loss 0.0044 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.3%)	
11/09 12:28:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 48.5160%
11/09 12:28:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1746	Prec@(1,5) (42.2%, 74.3%)
11/09 12:28:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1766	Prec@(1,5) (42.5%, 74.4%)
11/09 12:28:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1913	Prec@(1,5) (42.2%, 74.1%)
11/09 12:29:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1897	Prec@(1,5) (42.4%, 74.2%)
11/09 12:29:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 42.3840%
11/09 12:29:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:29:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5920%
11/09 12:29:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.0161 (1.7630)	Arch Loss 2.3566 (2.2030)	Arch Hard Loss 2.3552 (2.2017)	Arch Alpha Loss 0.0042 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.8%)	
11/09 12:30:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.7615 (1.7673)	Arch Loss 2.1285 (2.2100)	Arch Hard Loss 2.1275 (2.2087)	Arch Alpha Loss 0.0033 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.7%)	
11/09 12:30:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.0405 (1.7852)	Arch Loss 2.6173 (2.1961)	Arch Hard Loss 2.6161 (2.1948)	Arch Alpha Loss 0.0035 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.5%)	
11/09 12:30:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.0772 (1.7972)	Arch Loss 1.8798 (2.1745)	Arch Hard Loss 1.8789 (2.1732)	Arch Alpha Loss 0.0028 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.3%)	
11/09 12:30:57午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 49.7760%
11/09 12:31:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.1450	Prec@(1,5) (43.3%, 75.0%)
11/09 12:31:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.1542	Prec@(1,5) (42.9%, 74.9%)
11/09 12:31:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.1522	Prec@(1,5) (42.9%, 75.1%)
11/09 12:31:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.1536	Prec@(1,5) (43.0%, 75.0%)
11/09 12:31:14午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 43.0320%
11/09 12:31:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:31:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0320%
11/09 12:31:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.7991 (1.6847)	Arch Loss 1.9989 (2.1431)	Arch Hard Loss 1.9974 (2.1416)	Arch Alpha Loss 0.0043 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 83.6%)	
11/09 12:32:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.7994 (1.7037)	Arch Loss 2.0973 (2.1521)	Arch Hard Loss 2.0958 (2.1506)	Arch Alpha Loss 0.0044 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 83.3%)	
11/09 12:32:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.8178 (1.7285)	Arch Loss 1.9277 (2.1358)	Arch Hard Loss 1.9263 (2.1344)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.6%)	
11/09 12:33:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4844 (1.7386)	Arch Loss 2.7476 (2.1302)	Arch Hard Loss 2.7463 (2.1288)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.5%)	
11/09 12:33:08午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 51.1240%
11/09 12:33:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0480	Prec@(1,5) (45.4%, 76.9%)
11/09 12:33:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0451	Prec@(1,5) (45.4%, 76.8%)
11/09 12:33:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0400	Prec@(1,5) (45.7%, 76.9%)
11/09 12:33:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0439	Prec@(1,5) (45.7%, 76.8%)
11/09 12:33:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 45.7040%
11/09 12:33:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:33:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7040%
11/09 12:33:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.9130 (1.5989)	Arch Loss 1.9948 (2.1193)	Arch Hard Loss 1.9932 (2.1177)	Arch Alpha Loss 0.0045 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.7%)	
11/09 12:34:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.8090 (1.6468)	Arch Loss 1.8831 (2.1191)	Arch Hard Loss 1.8815 (2.1176)	Arch Alpha Loss 0.0043 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.7%, 83.9%)	
11/09 12:34:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.5116 (1.6581)	Arch Loss 2.0985 (2.1085)	Arch Hard Loss 2.0969 (2.1070)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.3%, 83.9%)	
11/09 12:35:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.7286 (1.6773)	Arch Loss 2.2366 (2.1178)	Arch Hard Loss 2.2351 (2.1162)	Arch Alpha Loss 0.0041 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.5%)	
11/09 12:35:19午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 52.8320%
11/09 12:35:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.0635	Prec@(1,5) (45.0%, 76.6%)
11/09 12:35:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.0775	Prec@(1,5) (45.0%, 76.3%)
11/09 12:35:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.0856	Prec@(1,5) (44.5%, 76.3%)
11/09 12:35:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.0693	Prec@(1,5) (44.9%, 76.5%)
11/09 12:35:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 44.9520%
11/09 12:35:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:35:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7040%
11/09 12:36:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3733 (1.5805)	Arch Loss 1.7944 (2.1005)	Arch Hard Loss 1.7929 (2.0988)	Arch Alpha Loss 0.0038 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.1%, 84.6%)	
11/09 12:36:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.7872 (1.6027)	Arch Loss 2.0569 (2.0740)	Arch Hard Loss 2.0553 (2.0723)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.4%)	
11/09 12:37:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.7206 (1.6152)	Arch Loss 2.2394 (2.0722)	Arch Hard Loss 2.2376 (2.0705)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.3%)	
11/09 12:37:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7093 (1.6263)	Arch Loss 1.7666 (2.0739)	Arch Hard Loss 1.7652 (2.0723)	Arch Alpha Loss 0.0033 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.3%, 84.1%)	
11/09 12:37:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 54.3280%
11/09 12:37:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.0264	Prec@(1,5) (47.0%, 76.8%)
11/09 12:37:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.0287	Prec@(1,5) (46.6%, 77.0%)
11/09 12:37:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.0304	Prec@(1,5) (46.6%, 77.0%)
11/09 12:37:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.0241	Prec@(1,5) (46.8%, 77.1%)
11/09 12:37:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 46.8440%
11/09 12:37:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:37:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.8440%
11/09 12:38:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.8414 (1.5174)	Arch Loss 2.0823 (2.0391)	Arch Hard Loss 2.0802 (2.0372)	Arch Alpha Loss 0.0047 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.5%)	
11/09 12:38:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.5761 (1.5318)	Arch Loss 2.2012 (2.0515)	Arch Hard Loss 2.1993 (2.0497)	Arch Alpha Loss 0.0045 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.2%)	
11/09 12:39:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.7083 (1.5517)	Arch Loss 2.4218 (2.0612)	Arch Hard Loss 2.4200 (2.0594)	Arch Alpha Loss 0.0042 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.7%)	
11/09 12:39:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.2274 (1.5724)	Arch Loss 2.3442 (2.0619)	Arch Hard Loss 2.3423 (2.0602)	Arch Alpha Loss 0.0044 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 85.4%)	
11/09 12:39:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 55.1800%
11/09 12:39:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.1441	Prec@(1,5) (44.8%, 74.9%)
11/09 12:39:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.1313	Prec@(1,5) (44.6%, 75.5%)
11/09 12:39:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.1224	Prec@(1,5) (44.7%, 75.7%)
11/09 12:39:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.1169	Prec@(1,5) (44.8%, 75.8%)
11/09 12:39:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 44.8120%
11/09 12:39:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:39:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.8440%
11/09 12:40:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.3983 (1.4473)	Arch Loss 1.7559 (1.9975)	Arch Hard Loss 1.7540 (1.9956)	Arch Alpha Loss 0.0042 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.2%)	
11/09 12:40:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.7078 (1.4882)	Arch Loss 2.2575 (2.0134)	Arch Hard Loss 2.2556 (2.0115)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.6%)	
11/09 12:41:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.3523 (1.5046)	Arch Loss 2.1088 (2.0265)	Arch Hard Loss 2.1068 (2.0247)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.2%)	
11/09 12:41:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2220 (1.5149)	Arch Loss 2.4710 (2.0370)	Arch Hard Loss 2.4688 (2.0352)	Arch Alpha Loss 0.0047 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.0%)	
11/09 12:41:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 56.7040%
11/09 12:41:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.0381	Prec@(1,5) (46.6%, 77.2%)
11/09 12:42:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.0239	Prec@(1,5) (46.7%, 77.2%)
11/09 12:42:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.0381	Prec@(1,5) (46.7%, 76.9%)
11/09 12:42:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.0275	Prec@(1,5) (46.8%, 77.3%)
11/09 12:42:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 46.8080%
11/09 12:42:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:42:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.8440%
11/09 12:42:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.8343 (1.4334)	Arch Loss 2.2726 (2.0421)	Arch Hard Loss 2.2706 (2.0399)	Arch Alpha Loss 0.0039 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.6%)	
11/09 12:43:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.6148 (1.4401)	Arch Loss 2.1685 (2.0454)	Arch Hard Loss 2.1664 (2.0434)	Arch Alpha Loss 0.0042 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.6%)	
11/09 12:43:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.6120 (1.4612)	Arch Loss 2.3968 (2.0256)	Arch Hard Loss 2.3946 (2.0235)	Arch Alpha Loss 0.0043 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.2%)	
11/09 12:44:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.5648 (1.4678)	Arch Loss 1.7262 (2.0202)	Arch Hard Loss 1.7243 (2.0182)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.1%)	
11/09 12:44:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 57.9080%
11/09 12:44:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9847	Prec@(1,5) (47.8%, 78.4%)
11/09 12:44:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9923	Prec@(1,5) (47.4%, 78.1%)
11/09 12:44:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9759	Prec@(1,5) (48.0%, 78.3%)
11/09 12:44:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9884	Prec@(1,5) (47.8%, 78.3%)
11/09 12:44:19午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 47.8120%
11/09 12:44:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:44:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8120%
11/09 12:44:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.2026 (1.3455)	Arch Loss 1.8858 (2.0526)	Arch Hard Loss 1.8835 (2.0505)	Arch Alpha Loss 0.0042 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.8%)	
11/09 12:45:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.4640 (1.3629)	Arch Loss 1.7579 (2.0303)	Arch Hard Loss 1.7559 (2.0282)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.8%)	
11/09 12:45:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.5776 (1.3984)	Arch Loss 1.6768 (2.0310)	Arch Hard Loss 1.6751 (2.0290)	Arch Alpha Loss 0.0032 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.0%)	
11/09 12:46:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.4993 (1.4087)	Arch Loss 2.1292 (2.0132)	Arch Hard Loss 2.1272 (2.0111)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.8%)	
11/09 12:46:14午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 59.4960%
11/09 12:46:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.9739	Prec@(1,5) (48.3%, 78.4%)
11/09 12:46:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.9716	Prec@(1,5) (48.2%, 78.5%)
11/09 12:46:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.9663	Prec@(1,5) (48.3%, 78.5%)
11/09 12:46:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9683	Prec@(1,5) (48.4%, 78.4%)
11/09 12:46:31午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 48.3800%
11/09 12:46:31午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:46:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3800%
11/09 12:47:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.5075 (1.2859)	Arch Loss 2.3240 (2.0084)	Arch Hard Loss 2.3217 (2.0061)	Arch Alpha Loss 0.0040 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.7%)	
11/09 12:47:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.1394 (1.3143)	Arch Loss 1.9123 (1.9928)	Arch Hard Loss 1.9102 (1.9905)	Arch Alpha Loss 0.0037 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.4%)	
11/09 12:47:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1901 (1.3382)	Arch Loss 1.9318 (2.0003)	Arch Hard Loss 1.9296 (1.9980)	Arch Alpha Loss 0.0040 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.9%, 89.0%)	
11/09 12:48:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.4432 (1.3487)	Arch Loss 1.8703 (2.0024)	Arch Hard Loss 1.8678 (2.0001)	Arch Alpha Loss 0.0045 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.8%)	
11/09 12:48:25午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 60.8920%
11/09 12:48:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9786	Prec@(1,5) (48.2%, 78.6%)
11/09 12:48:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.9779	Prec@(1,5) (48.4%, 78.8%)
11/09 12:48:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.9733	Prec@(1,5) (48.4%, 79.0%)
11/09 12:48:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.9709	Prec@(1,5) (48.5%, 79.0%)
11/09 12:48:42午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 48.5120%
11/09 12:48:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:48:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5120%
11/09 12:49:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.2592 (1.2743)	Arch Loss 2.3843 (2.0173)	Arch Hard Loss 2.3820 (2.0148)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 90.0%)	
11/09 12:49:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.3026 (1.2915)	Arch Loss 1.6752 (1.9847)	Arch Hard Loss 1.6728 (1.9823)	Arch Alpha Loss 0.0040 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.5%)	
11/09 12:50:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.4123 (1.3013)	Arch Loss 2.0435 (1.9728)	Arch Hard Loss 2.0413 (1.9704)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.4%)	
11/09 12:50:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.1064 (1.3105)	Arch Loss 1.8165 (1.9787)	Arch Hard Loss 1.8143 (1.9763)	Arch Alpha Loss 0.0037 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.3%)	
11/09 12:50:37午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 61.6080%
11/09 12:50:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9143	Prec@(1,5) (49.6%, 80.4%)
11/09 12:50:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.9491	Prec@(1,5) (49.0%, 79.9%)
11/09 12:50:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.9385	Prec@(1,5) (49.1%, 79.8%)
11/09 12:50:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.9359	Prec@(1,5) (49.3%, 79.9%)
11/09 12:50:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 49.2560%
11/09 12:50:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:50:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2560%
11/09 12:51:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.2917 (1.1832)	Arch Loss 1.8806 (1.9716)	Arch Hard Loss 1.8777 (1.9690)	Arch Alpha Loss 0.0046 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.2%)	
11/09 12:51:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.0383 (1.2131)	Arch Loss 2.3328 (1.9696)	Arch Hard Loss 2.3302 (1.9670)	Arch Alpha Loss 0.0041 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.8%)	
11/09 12:52:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.2759 (1.2428)	Arch Loss 2.0093 (1.9600)	Arch Hard Loss 2.0068 (1.9575)	Arch Alpha Loss 0.0040 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.5%)	
11/09 12:52:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9782 (1.2541)	Arch Loss 2.1122 (1.9728)	Arch Hard Loss 2.1100 (1.9703)	Arch Alpha Loss 0.0036 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.6%, 90.3%)	
11/09 12:52:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 63.5560%
11/09 12:52:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.9076	Prec@(1,5) (49.5%, 79.9%)
11/09 12:52:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.9394	Prec@(1,5) (48.7%, 79.8%)
11/09 12:53:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.9395	Prec@(1,5) (48.8%, 79.8%)
11/09 12:53:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.9413	Prec@(1,5) (49.1%, 79.8%)
11/09 12:53:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 49.0720%
11/09 12:53:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:53:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2560%
11/09 12:53:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.9004 (1.1324)	Arch Loss 1.8632 (1.9507)	Arch Hard Loss 1.8609 (1.9481)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.7%)	
11/09 12:54:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.2509 (1.1566)	Arch Loss 1.9118 (1.9528)	Arch Hard Loss 1.9089 (1.9502)	Arch Alpha Loss 0.0044 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.5%)	
11/09 12:54:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1510 (1.1832)	Arch Loss 1.9816 (1.9693)	Arch Hard Loss 1.9792 (1.9668)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.3%)	
11/09 12:54:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2645 (1.1981)	Arch Loss 1.7318 (1.9734)	Arch Hard Loss 1.7295 (1.9709)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.0%)	
11/09 12:54:59午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 64.8400%
11/09 12:55:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9230	Prec@(1,5) (49.6%, 80.5%)
11/09 12:55:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9589	Prec@(1,5) (49.0%, 79.8%)
11/09 12:55:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9701	Prec@(1,5) (48.7%, 79.6%)
11/09 12:55:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9767	Prec@(1,5) (48.6%, 79.5%)
11/09 12:55:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 48.6280%
11/09 12:55:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:55:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2560%
11/09 12:55:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.1676 (1.0984)	Arch Loss 1.9837 (1.9797)	Arch Hard Loss 1.9808 (1.9771)	Arch Alpha Loss 0.0042 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.2%)	
11/09 12:56:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.1239 (1.1246)	Arch Loss 2.2918 (1.9473)	Arch Hard Loss 2.2892 (1.9447)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 91.8%)	
11/09 12:56:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.5440 (1.1393)	Arch Loss 2.3835 (1.9677)	Arch Hard Loss 2.3810 (1.9651)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.7%)	
11/09 12:57:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.2236 (1.1487)	Arch Loss 2.2765 (1.9579)	Arch Hard Loss 2.2740 (1.9553)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.5%)	
11/09 12:57:08午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 66.3600%
11/09 12:57:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.9289	Prec@(1,5) (50.1%, 80.9%)
11/09 12:57:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9378	Prec@(1,5) (50.2%, 80.6%)
11/09 12:57:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9443	Prec@(1,5) (49.9%, 80.3%)
11/09 12:57:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9363	Prec@(1,5) (50.1%, 80.4%)
11/09 12:57:24午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 50.1120%
11/09 12:57:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:57:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.1120%
11/09 12:57:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.7760 (1.0359)	Arch Loss 2.1392 (1.9241)	Arch Hard Loss 2.1363 (1.9213)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.3%)	
11/09 12:58:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.1574 (1.0631)	Arch Loss 1.6734 (1.9497)	Arch Hard Loss 1.6708 (1.9469)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.8%)	
11/09 12:58:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.0590 (1.0797)	Arch Loss 1.7659 (1.9507)	Arch Hard Loss 1.7631 (1.9479)	Arch Alpha Loss 0.0040 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.5%)	
11/09 12:59:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 0.8891 (1.0918)	Arch Loss 2.0364 (1.9533)	Arch Hard Loss 2.0339 (1.9506)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.4%)	
11/09 12:59:18午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 67.4600%
11/09 12:59:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.9696	Prec@(1,5) (50.1%, 80.3%)
11/09 12:59:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.9753	Prec@(1,5) (50.2%, 80.1%)
11/09 12:59:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.9661	Prec@(1,5) (50.5%, 80.0%)
11/09 12:59:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.9800	Prec@(1,5) (50.3%, 79.7%)
11/09 12:59:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 50.2960%
11/09 12:59:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 12:59:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.2960%
11/09 01:00:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.2827 (1.0109)	Arch Loss 1.8588 (1.9562)	Arch Hard Loss 1.8558 (1.9533)	Arch Alpha Loss 0.0041 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
11/09 01:00:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.1790 (1.0175)	Arch Loss 1.9432 (1.9583)	Arch Hard Loss 1.9405 (1.9554)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.1%)	
11/09 01:01:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.1937 (1.0370)	Arch Loss 1.7822 (1.9640)	Arch Hard Loss 1.7797 (1.9611)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.9%)	
11/09 01:01:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.4707 (1.0473)	Arch Loss 2.0127 (1.9560)	Arch Hard Loss 2.0101 (1.9531)	Arch Alpha Loss 0.0034 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.6%)	
11/09 01:01:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 68.9520%
11/09 01:01:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8967	Prec@(1,5) (50.5%, 81.2%)
11/09 01:01:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8953	Prec@(1,5) (51.2%, 80.9%)
11/09 01:01:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.9047	Prec@(1,5) (51.0%, 80.7%)
11/09 01:01:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8980	Prec@(1,5) (51.5%, 80.8%)
11/09 01:01:55午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 51.4640%
11/09 01:01:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:01:55午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4640%
11/09 01:02:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.2730 (0.9385)	Arch Loss 1.8664 (1.9492)	Arch Hard Loss 1.8638 (1.9462)	Arch Alpha Loss 0.0034 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.2%)	
11/09 01:02:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.9209 (0.9547)	Arch Loss 1.6949 (1.9311)	Arch Hard Loss 1.6922 (1.9281)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 93.9%)	
11/09 01:03:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1235 (0.9604)	Arch Loss 1.9899 (1.9452)	Arch Hard Loss 1.9868 (1.9422)	Arch Alpha Loss 0.0040 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
11/09 01:03:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9226 (0.9846)	Arch Loss 1.7105 (1.9517)	Arch Hard Loss 1.7075 (1.9487)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.7%)	
11/09 01:03:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 70.5520%
11/09 01:03:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.9105	Prec@(1,5) (51.7%, 80.8%)
11/09 01:03:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9191	Prec@(1,5) (51.3%, 80.8%)
11/09 01:04:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9252	Prec@(1,5) (51.0%, 80.7%)
11/09 01:04:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9322	Prec@(1,5) (51.0%, 80.7%)
11/09 01:04:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 51.0200%
11/09 01:04:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:04:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4640%
11/09 01:04:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.8530 (0.9255)	Arch Loss 1.5493 (1.9619)	Arch Hard Loss 1.5466 (1.9589)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.3%)	
11/09 01:05:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9989 (0.9235)	Arch Loss 1.9353 (1.9317)	Arch Hard Loss 1.9327 (1.9287)	Arch Alpha Loss 0.0032 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.5%)	
11/09 01:05:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.9526 (0.9375)	Arch Loss 1.5053 (1.9521)	Arch Hard Loss 1.5027 (1.9491)	Arch Alpha Loss 0.0032 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.3%)	
11/09 01:06:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.7570 (0.9409)	Arch Loss 1.3955 (1.9521)	Arch Hard Loss 1.3928 (1.9492)	Arch Alpha Loss 0.0034 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.2%)	
11/09 01:06:01午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 71.9400%
11/09 01:06:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.8879	Prec@(1,5) (53.0%, 81.2%)
11/09 01:06:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9187	Prec@(1,5) (52.4%, 81.0%)
11/09 01:06:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9143	Prec@(1,5) (52.2%, 81.1%)
11/09 01:06:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9193	Prec@(1,5) (52.1%, 81.0%)
11/09 01:06:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 52.1200%
11/09 01:06:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:06:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.1200%
11/09 01:06:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.0497 (0.8497)	Arch Loss 2.2162 (1.9722)	Arch Hard Loss 2.2125 (1.9691)	Arch Alpha Loss 0.0046 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 95.5%)	
11/09 01:07:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8159 (0.8708)	Arch Loss 2.0584 (1.9643)	Arch Hard Loss 2.0555 (1.9613)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 95.2%)	
11/09 01:07:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8870 (0.8883)	Arch Loss 1.8979 (1.9582)	Arch Hard Loss 1.8944 (1.9552)	Arch Alpha Loss 0.0042 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 95.0%)	
11/09 01:08:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.9722 (0.8906)	Arch Loss 1.9226 (1.9519)	Arch Hard Loss 1.9195 (1.9489)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.9%)	
11/09 01:08:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 72.7800%
11/09 01:08:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.9228	Prec@(1,5) (51.5%, 81.0%)
11/09 01:08:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9257	Prec@(1,5) (51.5%, 81.0%)
11/09 01:08:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.8989	Prec@(1,5) (52.0%, 81.2%)
11/09 01:08:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9119	Prec@(1,5) (51.9%, 81.0%)
11/09 01:08:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 51.9040%
11/09 01:08:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:08:29午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.1200%
11/09 01:08:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.9537 (0.8048)	Arch Loss 2.2779 (1.9480)	Arch Hard Loss 2.2747 (1.9449)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.6%)	
11/09 01:09:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.6954 (0.8123)	Arch Loss 1.8286 (1.9629)	Arch Hard Loss 1.8257 (1.9598)	Arch Alpha Loss 0.0035 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.5%)	
11/09 01:09:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8343 (0.8284)	Arch Loss 2.1459 (1.9677)	Arch Hard Loss 2.1423 (1.9646)	Arch Alpha Loss 0.0042 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.4%)	
11/09 01:10:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.9304 (0.8386)	Arch Loss 2.0599 (1.9714)	Arch Hard Loss 2.0562 (1.9683)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.3%)	
11/09 01:10:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 74.6480%
11/09 01:10:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8785	Prec@(1,5) (52.4%, 81.7%)
11/09 01:10:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.9136	Prec@(1,5) (51.7%, 81.5%)
11/09 01:10:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9150	Prec@(1,5) (52.1%, 81.5%)
11/09 01:10:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9117	Prec@(1,5) (52.3%, 81.5%)
11/09 01:10:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 52.3240%
11/09 01:10:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:10:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.3240%
11/09 01:11:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6848 (0.7637)	Arch Loss 1.8075 (2.0050)	Arch Hard Loss 1.8044 (2.0016)	Arch Alpha Loss 0.0035 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.2%)	
11/09 01:11:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 1.0028 (0.7791)	Arch Loss 1.8958 (1.9999)	Arch Hard Loss 1.8929 (1.9966)	Arch Alpha Loss 0.0034 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
11/09 01:12:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8658 (0.7937)	Arch Loss 1.8806 (1.9722)	Arch Hard Loss 1.8773 (1.9689)	Arch Alpha Loss 0.0038 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.8%)	
11/09 01:12:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.7909 (0.8003)	Arch Loss 1.8570 (1.9722)	Arch Hard Loss 1.8540 (1.9689)	Arch Alpha Loss 0.0035 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
11/09 01:12:34午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 75.7920%
11/09 01:12:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.8852	Prec@(1,5) (52.2%, 81.7%)
11/09 01:12:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9007	Prec@(1,5) (52.3%, 81.3%)
11/09 01:12:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9052	Prec@(1,5) (52.2%, 81.3%)
11/09 01:12:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.8971	Prec@(1,5) (52.4%, 81.3%)
11/09 01:12:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 52.4240%
11/09 01:12:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:12:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.4240%
11/09 01:13:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.6734 (0.7104)	Arch Loss 1.6783 (1.9611)	Arch Hard Loss 1.6747 (1.9577)	Arch Alpha Loss 0.0041 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.7%)	
11/09 01:13:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7312 (0.7274)	Arch Loss 1.9915 (1.9472)	Arch Hard Loss 1.9881 (1.9438)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.8%)	
11/09 01:14:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.7844 (0.7403)	Arch Loss 1.6546 (1.9500)	Arch Hard Loss 1.6511 (1.9466)	Arch Alpha Loss 0.0040 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.5%)	
11/09 01:14:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.7045 (0.7525)	Arch Loss 1.8632 (1.9484)	Arch Hard Loss 1.8600 (1.9450)	Arch Alpha Loss 0.0035 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.4%)	
11/09 01:14:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 77.0080%
11/09 01:14:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.8788	Prec@(1,5) (52.9%, 82.8%)
11/09 01:14:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.9048	Prec@(1,5) (53.1%, 82.0%)
11/09 01:14:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.9157	Prec@(1,5) (52.8%, 81.8%)
11/09 01:15:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.9257	Prec@(1,5) (52.4%, 81.7%)
11/09 01:15:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 52.4480%
11/09 01:15:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:15:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.4480%
11/09 01:15:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.7090 (0.6908)	Arch Loss 1.8415 (2.0023)	Arch Hard Loss 1.8379 (1.9989)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.8%)	
11/09 01:16:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5546 (0.6858)	Arch Loss 1.9486 (1.9615)	Arch Hard Loss 1.9448 (1.9580)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.8%)	
11/09 01:16:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.8275 (0.6929)	Arch Loss 2.0507 (1.9716)	Arch Hard Loss 2.0470 (1.9682)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.7%)	
11/09 01:16:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.6469 (0.7051)	Arch Loss 2.2426 (1.9774)	Arch Hard Loss 2.2387 (1.9740)	Arch Alpha Loss 0.0043 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
11/09 01:16:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 78.6160%
11/09 01:17:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9468	Prec@(1,5) (51.8%, 81.5%)
11/09 01:17:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9263	Prec@(1,5) (52.5%, 81.4%)
11/09 01:17:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.9316	Prec@(1,5) (52.3%, 81.5%)
11/09 01:17:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9251	Prec@(1,5) (52.5%, 81.6%)
11/09 01:17:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 52.4880%
11/09 01:17:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:17:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.4880%
11/09 01:17:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.5846 (0.6139)	Arch Loss 1.3695 (1.9832)	Arch Hard Loss 1.3665 (1.9797)	Arch Alpha Loss 0.0032 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.5%)	
11/09 01:18:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6208 (0.6372)	Arch Loss 1.6952 (1.9741)	Arch Hard Loss 1.6915 (1.9706)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
11/09 01:18:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6837 (0.6547)	Arch Loss 2.2332 (1.9847)	Arch Hard Loss 2.2292 (1.9812)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.2%)	
11/09 01:19:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7627 (0.6650)	Arch Loss 2.1308 (1.9800)	Arch Hard Loss 2.1277 (1.9765)	Arch Alpha Loss 0.0033 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
11/09 01:19:10午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 79.7000%
11/09 01:19:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.8796	Prec@(1,5) (53.3%, 82.8%)
11/09 01:19:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.8990	Prec@(1,5) (53.0%, 82.4%)
11/09 01:19:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.9146	Prec@(1,5) (52.9%, 82.1%)
11/09 01:19:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9153	Prec@(1,5) (52.9%, 82.1%)
11/09 01:19:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 52.9280%
11/09 01:19:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:19:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.9280%
11/09 01:19:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7904 (0.6092)	Arch Loss 1.7185 (1.9937)	Arch Hard Loss 1.7152 (1.9902)	Arch Alpha Loss 0.0035 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.5%)	
11/09 01:20:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.5408 (0.6172)	Arch Loss 2.4901 (2.0095)	Arch Hard Loss 2.4867 (2.0060)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.4%)	
11/09 01:20:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.8468 (0.6270)	Arch Loss 1.8194 (1.9996)	Arch Hard Loss 1.8162 (1.9961)	Arch Alpha Loss 0.0035 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.4%)	
11/09 01:21:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5025 (0.6329)	Arch Loss 2.4746 (1.9971)	Arch Hard Loss 2.4711 (1.9935)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.3%)	
11/09 01:21:19午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 80.8560%
11/09 01:21:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.9473	Prec@(1,5) (52.9%, 81.9%)
11/09 01:21:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.9506	Prec@(1,5) (53.1%, 81.9%)
11/09 01:21:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9541	Prec@(1,5) (53.2%, 81.9%)
11/09 01:21:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.9442	Prec@(1,5) (53.3%, 82.0%)
11/09 01:21:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 53.2800%
11/09 01:21:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:21:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2800%
11/09 01:22:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.4203 (0.5834)	Arch Loss 1.9008 (1.9248)	Arch Hard Loss 1.8970 (1.9211)	Arch Alpha Loss 0.0040 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.9%)	
11/09 01:22:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.7039 (0.5886)	Arch Loss 1.9969 (1.9647)	Arch Hard Loss 1.9930 (1.9611)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.7%)	
11/09 01:23:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.2970 (0.5999)	Arch Loss 1.6026 (1.9753)	Arch Hard Loss 1.5992 (1.9717)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.6%)	
11/09 01:23:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.7209 (0.6053)	Arch Loss 2.0290 (1.9792)	Arch Hard Loss 2.0253 (1.9756)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
11/09 01:23:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 81.8040%
11/09 01:23:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.9588	Prec@(1,5) (52.7%, 81.5%)
11/09 01:23:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.9512	Prec@(1,5) (52.9%, 81.6%)
11/09 01:23:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9315	Prec@(1,5) (53.1%, 81.9%)
11/09 01:23:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9260	Prec@(1,5) (53.3%, 81.9%)
11/09 01:23:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 53.2600%
11/09 01:23:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:23:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2800%
11/09 01:24:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.6086 (0.5662)	Arch Loss 1.6853 (1.9846)	Arch Hard Loss 1.6814 (1.9809)	Arch Alpha Loss 0.0040 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/09 01:24:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.3976 (0.5812)	Arch Loss 2.1861 (1.9892)	Arch Hard Loss 2.1824 (1.9855)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.7%)	
11/09 01:25:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6445 (0.5796)	Arch Loss 1.9500 (1.9937)	Arch Hard Loss 1.9460 (1.9901)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
11/09 01:25:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5473 (0.5808)	Arch Loss 2.1486 (1.9956)	Arch Hard Loss 2.1447 (1.9919)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
11/09 01:25:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 82.5120%
11/09 01:25:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.9047	Prec@(1,5) (54.0%, 81.7%)
11/09 01:25:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.9309	Prec@(1,5) (53.8%, 81.8%)
11/09 01:25:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.9465	Prec@(1,5) (53.6%, 81.7%)
11/09 01:25:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.9396	Prec@(1,5) (53.5%, 82.0%)
11/09 01:25:56午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 53.5120%
11/09 01:25:56午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:25:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5120%
11/09 01:26:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5068 (0.5394)	Arch Loss 2.0918 (1.9871)	Arch Hard Loss 2.0891 (1.9834)	Arch Alpha Loss 0.0028 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 97.9%)	
11/09 01:26:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.3908 (0.5560)	Arch Loss 1.9018 (1.9822)	Arch Hard Loss 1.8987 (1.9786)	Arch Alpha Loss 0.0032 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.8%)	
11/09 01:27:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.4627 (0.5547)	Arch Loss 1.8241 (1.9992)	Arch Hard Loss 1.8209 (1.9955)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/09 01:27:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.4682 (0.5597)	Arch Loss 2.0979 (1.9962)	Arch Hard Loss 2.0949 (1.9925)	Arch Alpha Loss 0.0031 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.8%)	
11/09 01:27:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 83.2240%
11/09 01:27:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.9115	Prec@(1,5) (54.4%, 82.3%)
11/09 01:27:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.9409	Prec@(1,5) (53.8%, 82.1%)
11/09 01:28:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.9399	Prec@(1,5) (53.6%, 82.0%)
11/09 01:28:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9426	Prec@(1,5) (53.4%, 82.1%)
11/09 01:28:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 53.4200%
11/09 01:28:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:28:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5120%
11/09 01:28:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6034 (0.5412)	Arch Loss 1.4811 (1.9372)	Arch Hard Loss 1.4769 (1.9335)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.1%)	
11/09 01:29:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5674 (0.5409)	Arch Loss 1.8717 (1.9532)	Arch Hard Loss 1.8675 (1.9495)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.1%)	
11/09 01:29:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.4472 (0.5379)	Arch Loss 1.7407 (1.9838)	Arch Hard Loss 1.7371 (1.9801)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.2%)	
11/09 01:30:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.4839 (0.5375)	Arch Loss 1.7694 (1.9939)	Arch Hard Loss 1.7659 (1.9902)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.1%)	
11/09 01:30:01午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 84.0920%
11/09 01:30:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.9456	Prec@(1,5) (53.1%, 82.0%)
11/09 01:30:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.9237	Prec@(1,5) (53.7%, 81.9%)
11/09 01:30:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.9503	Prec@(1,5) (53.5%, 81.8%)
11/09 01:30:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.9476	Prec@(1,5) (53.6%, 81.9%)
11/09 01:30:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 53.5560%
11/09 01:30:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:30:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5560%
11/09 01:30:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.3571 (0.5107)	Arch Loss 1.7633 (2.0012)	Arch Hard Loss 1.7595 (1.9975)	Arch Alpha Loss 0.0038 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.4%)	
11/09 01:31:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5911 (0.5108)	Arch Loss 2.0817 (1.9875)	Arch Hard Loss 2.0777 (1.9838)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.3%)	
11/09 01:31:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.6674 (0.5228)	Arch Loss 2.0551 (1.9948)	Arch Hard Loss 2.0511 (1.9911)	Arch Alpha Loss 0.0040 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.3%)	
11/09 01:32:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7317 (0.5265)	Arch Loss 2.0065 (1.9979)	Arch Hard Loss 2.0021 (1.9942)	Arch Alpha Loss 0.0044 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
11/09 01:32:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 84.5960%
11/09 01:32:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.9194	Prec@(1,5) (54.1%, 82.0%)
11/09 01:32:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.9421	Prec@(1,5) (53.8%, 81.9%)
11/09 01:32:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.9387	Prec@(1,5) (53.7%, 82.1%)
11/09 01:32:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.9399	Prec@(1,5) (53.6%, 82.1%)
11/09 01:32:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 53.5840%
11/09 01:32:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:32:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5840%
11/09 01:33:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5747 (0.4993)	Arch Loss 2.1611 (2.0039)	Arch Hard Loss 2.1573 (2.0001)	Arch Alpha Loss 0.0038 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.3%)	
11/09 01:33:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6462 (0.5103)	Arch Loss 1.7717 (2.0114)	Arch Hard Loss 1.7678 (2.0077)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.2%)	
11/09 01:33:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3819 (0.5081)	Arch Loss 1.7423 (2.0132)	Arch Hard Loss 1.7390 (2.0094)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.3%)	
11/09 01:34:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6776 (0.5137)	Arch Loss 1.7222 (2.0002)	Arch Hard Loss 1.7181 (1.9965)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
11/09 01:34:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 85.0480%
11/09 01:34:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.9271	Prec@(1,5) (53.1%, 82.0%)
11/09 01:34:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.9446	Prec@(1,5) (53.3%, 82.0%)
11/09 01:34:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.9292	Prec@(1,5) (53.6%, 82.2%)
11/09 01:34:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.9434	Prec@(1,5) (53.6%, 82.1%)
11/09 01:34:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 53.5520%
11/09 01:34:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:34:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5840%
11/09 01:35:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.5042 (0.4797)	Arch Loss 2.4439 (2.0206)	Arch Hard Loss 2.4406 (2.0168)	Arch Alpha Loss 0.0034 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.6%)	
11/09 01:35:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5133 (0.4934)	Arch Loss 2.1610 (2.0044)	Arch Hard Loss 2.1577 (2.0007)	Arch Alpha Loss 0.0033 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.4%)	
11/09 01:36:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.3423 (0.4979)	Arch Loss 2.0639 (2.0015)	Arch Hard Loss 2.0611 (1.9978)	Arch Alpha Loss 0.0028 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/09 01:36:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.7473 (0.5002)	Arch Loss 2.0173 (2.0135)	Arch Hard Loss 2.0140 (2.0099)	Arch Alpha Loss 0.0034 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/09 01:36:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 85.3600%
11/09 01:36:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.9503	Prec@(1,5) (53.3%, 81.8%)
11/09 01:36:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.9450	Prec@(1,5) (53.6%, 81.8%)
11/09 01:36:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.9505	Prec@(1,5) (53.6%, 82.0%)
11/09 01:36:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.9618	Prec@(1,5) (53.5%, 81.8%)
11/09 01:36:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 53.5400%
11/09 01:36:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/09 01:36:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5840%
11/09 01:36:54午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 53.5840%
11/09 01:36:54午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
