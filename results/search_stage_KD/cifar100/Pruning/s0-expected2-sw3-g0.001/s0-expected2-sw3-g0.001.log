12/03 03:43:47PM parser.py:28 [INFO] 
12/03 03:43:47PM parser.py:29 [INFO] Parameters:
12/03 03:43:47PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g0.001/DAG
12/03 03:43:47PM parser.py:31 [INFO] T=10.0
12/03 03:43:47PM parser.py:31 [INFO] ADVANCED=1
12/03 03:43:47PM parser.py:31 [INFO] ALPHA_LR=0.0003
12/03 03:43:47PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/03 03:43:47PM parser.py:31 [INFO] ARCH_CRITERION=expected
12/03 03:43:47PM parser.py:31 [INFO] BATCH_SIZE=64
12/03 03:43:47PM parser.py:31 [INFO] CASCADE=0
12/03 03:43:47PM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/03 03:43:47PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 20]
12/03 03:43:47PM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/03 03:43:47PM parser.py:31 [INFO] DATA_PATH=../data/
12/03 03:43:47PM parser.py:31 [INFO] DATASET=cifar100
12/03 03:43:47PM parser.py:31 [INFO] DEPTH_COEF=0.0
12/03 03:43:47PM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/03 03:43:47PM parser.py:31 [INFO] DISCRETE=1
12/03 03:43:47PM parser.py:31 [INFO] EPOCHS=50
12/03 03:43:47PM parser.py:31 [INFO] EVAL_EPOCHS=100
12/03 03:43:47PM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g0.001
12/03 03:43:47PM parser.py:31 [INFO] FINAL_L=0.0
12/03 03:43:47PM parser.py:31 [INFO] G=0.001
12/03 03:43:47PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/03 03:43:47PM parser.py:31 [INFO] GPUS=[0]
12/03 03:43:47PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/03 03:43:47PM parser.py:31 [INFO] INIT_CHANNELS=16
12/03 03:43:47PM parser.py:31 [INFO] L=0.0
12/03 03:43:47PM parser.py:31 [INFO] LAYERS=32
12/03 03:43:47PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/03 03:43:47PM parser.py:31 [INFO] NAME=Pruning
12/03 03:43:47PM parser.py:31 [INFO] NONKD=1
12/03 03:43:47PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g0.001
12/03 03:43:47PM parser.py:31 [INFO] PCDARTS=0
12/03 03:43:47PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g0.001/plots
12/03 03:43:47PM parser.py:31 [INFO] PRINT_FREQ=100
12/03 03:43:47PM parser.py:31 [INFO] RESET=0
12/03 03:43:47PM parser.py:31 [INFO] RESUME_PATH=None
12/03 03:43:47PM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g0.001
12/03 03:43:47PM parser.py:31 [INFO] SEED=0
12/03 03:43:47PM parser.py:31 [INFO] SHARE_STAGE=0
12/03 03:43:47PM parser.py:31 [INFO] SLIDE_WINDOW=3
12/03 03:43:47PM parser.py:31 [INFO] SPEC_CELL=1
12/03 03:43:47PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/03 03:43:47PM parser.py:31 [INFO] TEACHER_NAME=none
12/03 03:43:47PM parser.py:31 [INFO] TEACHER_PATH=none
12/03 03:43:47PM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/03 03:43:47PM parser.py:31 [INFO] TYPE=Pruning
12/03 03:43:47PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/03 03:43:47PM parser.py:31 [INFO] W_LR=0.025
12/03 03:43:47PM parser.py:31 [INFO] W_LR_MIN=0.001
12/03 03:43:47PM parser.py:31 [INFO] W_MOMENTUM=0.9
12/03 03:43:47PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/03 03:43:47PM parser.py:31 [INFO] WORKERS=4
12/03 03:43:47PM parser.py:32 [INFO] 
12/03 03:43:49PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/03 03:44:40PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3238 (4.5254)	Arch Loss 4.3577 (4.5240)	Arch Hard Loss 4.3515 (4.5178)	Arch Beta Loss 6.1908 (6.1922)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 9.4%)	
12/03 03:45:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0709 (4.3985)	Arch Loss 4.3295 (4.4028)	Arch Hard Loss 4.3233 (4.3966)	Arch Beta Loss 6.1817 (6.1895)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.1%, 13.3%)	
12/03 03:46:15PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9497 (4.3005)	Arch Loss 4.0487 (4.3051)	Arch Hard Loss 4.0425 (4.2989)	Arch Beta Loss 6.1752 (6.1858)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.0%, 16.5%)	
12/03 03:46:57PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9654 (4.2326)	Arch Loss 3.9290 (4.2323)	Arch Hard Loss 3.9228 (4.2261)	Arch Beta Loss 6.1665 (6.1823)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.9%, 18.7%)	
12/03 03:46:58PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  0/49] Final Prec@1 4.9160%
12/03 03:47:06PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9532	Prec@(1,5) (7.6%, 28.1%)
12/03 03:47:12PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9474	Prec@(1,5) (7.7%, 28.6%)
12/03 03:47:18PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9444	Prec@(1,5) (7.9%, 28.9%)
12/03 03:47:24PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9448	Prec@(1,5) (7.9%, 28.5%)
12/03 03:47:24PM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 7.9120%
12/03 03:47:24PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('avg_pool_3x3', 2)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 4])
12/03 03:47:25PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.9120%
12/03 03:48:15PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.7729 (3.8918)	Arch Loss 4.1156 (3.8936)	Arch Hard Loss 4.1094 (3.8874)	Arch Beta Loss 6.1586 (6.1612)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.4%, 29.2%)	
12/03 03:49:05PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.8085 (3.8537)	Arch Loss 3.8129 (3.8359)	Arch Hard Loss 3.8068 (3.8297)	Arch Beta Loss 6.1467 (6.1563)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.2%, 30.8%)	
12/03 03:49:54PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.6108 (3.8116)	Arch Loss 3.4815 (3.7943)	Arch Hard Loss 3.4753 (3.7882)	Arch Beta Loss 6.1404 (6.1519)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.0%, 32.3%)	
12/03 03:50:38PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7788 (3.7650)	Arch Loss 3.9340 (3.7561)	Arch Hard Loss 3.9278 (3.7499)	Arch Beta Loss 6.1361 (6.1488)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.7%, 33.9%)	
12/03 03:50:39PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  1/49] Final Prec@1 10.7040%
12/03 03:50:46PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5505	Prec@(1,5) (15.3%, 40.9%)
12/03 03:50:53PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5482	Prec@(1,5) (14.9%, 40.5%)
12/03 03:50:59PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5495	Prec@(1,5) (14.6%, 40.5%)
12/03 03:51:05PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5524	Prec@(1,5) (14.5%, 40.4%)
12/03 03:51:05PM searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 14.5160%
12/03 03:51:05PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 7])
12/03 03:51:06PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.5160%
12/03 03:51:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.5684 (3.5476)	Arch Loss 3.4093 (3.5640)	Arch Hard Loss 3.4032 (3.5578)	Arch Beta Loss 6.1269 (6.1306)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 40.3%)	
12/03 03:52:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4848 (3.5303)	Arch Loss 3.3886 (3.5489)	Arch Hard Loss 3.3825 (3.5428)	Arch Beta Loss 6.1255 (6.1288)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.0%, 40.6%)	
12/03 03:53:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.2170 (3.4900)	Arch Loss 3.6287 (3.5077)	Arch Hard Loss 3.6226 (3.5016)	Arch Beta Loss 6.1172 (6.1260)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.7%, 41.8%)	
12/03 03:54:15PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.3490 (3.4650)	Arch Loss 3.2326 (3.4817)	Arch Hard Loss 3.2265 (3.4756)	Arch Beta Loss 6.1082 (6.1227)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.2%, 42.6%)	
12/03 03:54:15PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  2/49] Final Prec@1 16.1840%
12/03 03:54:22PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4093	Prec@(1,5) (16.5%, 46.2%)
12/03 03:54:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4221	Prec@(1,5) (16.3%, 45.5%)
12/03 03:54:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4190	Prec@(1,5) (16.5%, 45.7%)
12/03 03:54:41PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4189	Prec@(1,5) (16.8%, 45.7%)
12/03 03:54:41PM searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 16.8280%
12/03 03:54:42PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 7])
12/03 03:54:42PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.8280%
12/03 03:55:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5992 (3.3258)	Arch Loss 3.2724 (3.3228)	Arch Hard Loss 3.2663 (3.3167)	Arch Beta Loss 6.0991 (6.1029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.7%, 46.1%)	
12/03 03:56:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.0526 (3.2850)	Arch Loss 3.3775 (3.2945)	Arch Hard Loss 3.3714 (3.2884)	Arch Beta Loss 6.0929 (6.0999)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.4%, 47.6%)	
12/03 03:57:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.0206 (3.2552)	Arch Loss 3.3216 (3.2685)	Arch Hard Loss 3.3155 (3.2625)	Arch Beta Loss 6.0828 (6.0956)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.8%, 48.4%)	
12/03 03:57:53PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.0994 (3.2353)	Arch Loss 3.1002 (3.2534)	Arch Hard Loss 3.0941 (3.2473)	Arch Beta Loss 6.0691 (6.0910)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.2%, 49.1%)	
12/03 03:57:53PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  3/49] Final Prec@1 20.1920%
12/03 03:58:00PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2333	Prec@(1,5) (20.6%, 49.8%)
12/03 03:58:07PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2225	Prec@(1,5) (20.4%, 50.0%)
12/03 03:58:13PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2307	Prec@(1,5) (20.5%, 49.5%)
12/03 03:58:19PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2316	Prec@(1,5) (20.5%, 49.4%)
12/03 03:58:19PM searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 20.5080%
12/03 03:58:19PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 7])
12/03 03:58:20PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.5080%
12/03 03:59:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.0634 (3.0671)	Arch Loss 3.0298 (3.1709)	Arch Hard Loss 3.0237 (3.1648)	Arch Beta Loss 6.0576 (6.0635)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 54.3%)	
12/03 03:59:57PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.0202 (3.0598)	Arch Loss 2.9450 (3.1364)	Arch Hard Loss 2.9390 (3.1304)	Arch Beta Loss 6.0480 (6.0584)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.3%, 54.1%)	
12/03 04:00:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.6143 (3.0507)	Arch Loss 3.0343 (3.1100)	Arch Hard Loss 3.0282 (3.1039)	Arch Beta Loss 6.0383 (6.0531)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 54.1%)	
12/03 04:01:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.0497 (3.0455)	Arch Loss 2.8266 (3.0899)	Arch Hard Loss 2.8206 (3.0839)	Arch Beta Loss 6.0228 (6.0480)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 54.1%)	
12/03 04:01:30PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  4/49] Final Prec@1 23.5400%
12/03 04:01:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1691	Prec@(1,5) (21.9%, 52.5%)
12/03 04:01:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.1226	Prec@(1,5) (22.5%, 53.8%)
12/03 04:01:50PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.1148	Prec@(1,5) (22.7%, 54.0%)
12/03 04:01:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.1108	Prec@(1,5) (22.9%, 54.0%)
12/03 04:01:56PM searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 22.9080%
12/03 04:01:56PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 7])
12/03 04:01:57PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.9080%
12/03 04:02:47PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.0503 (2.8861)	Arch Loss 3.0250 (2.9663)	Arch Hard Loss 3.0190 (2.9602)	Arch Beta Loss 6.0133 (6.0183)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.0%, 58.1%)	
12/03 04:03:36PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.1058 (2.8740)	Arch Loss 3.0802 (2.9681)	Arch Hard Loss 3.0742 (2.9621)	Arch Beta Loss 6.0007 (6.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.3%, 58.3%)	
12/03 04:04:25PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8299 (2.8717)	Arch Loss 2.5949 (2.9423)	Arch Hard Loss 2.5889 (2.9363)	Arch Beta Loss 5.9914 (6.0068)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.1%, 58.2%)	
12/03 04:05:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6521 (2.8617)	Arch Loss 2.6917 (2.9243)	Arch Hard Loss 2.6858 (2.9183)	Arch Beta Loss 5.9845 (6.0026)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.2%, 58.7%)	
12/03 04:05:09PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  5/49] Final Prec@1 27.1840%
12/03 04:05:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8017	Prec@(1,5) (28.4%, 60.2%)
12/03 04:05:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8112	Prec@(1,5) (28.2%, 60.7%)
12/03 04:05:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8122	Prec@(1,5) (28.1%, 60.5%)
12/03 04:05:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8070	Prec@(1,5) (28.3%, 60.6%)
12/03 04:05:35PM searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 28.2960%
12/03 04:05:35PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 6])
12/03 04:05:36PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.2960%
12/03 04:06:25PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.5790 (2.6941)	Arch Loss 2.9690 (2.8211)	Arch Hard Loss 2.9630 (2.8151)	Arch Beta Loss 5.9710 (5.9776)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.3%, 63.1%)	
12/03 04:07:14PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.8547 (2.7180)	Arch Loss 2.7801 (2.8154)	Arch Hard Loss 2.7741 (2.8094)	Arch Beta Loss 5.9578 (5.9714)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 62.0%)	
12/03 04:08:02PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.9678 (2.7182)	Arch Loss 2.9396 (2.7955)	Arch Hard Loss 2.9336 (2.7895)	Arch Beta Loss 5.9506 (5.9661)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 62.2%)	
12/03 04:08:46PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7993 (2.7131)	Arch Loss 2.7665 (2.7968)	Arch Hard Loss 2.7606 (2.7909)	Arch Beta Loss 5.9487 (5.9621)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.0%, 62.4%)	
12/03 04:08:47PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  6/49] Final Prec@1 29.9960%
12/03 04:08:54PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7179	Prec@(1,5) (31.4%, 61.8%)
12/03 04:09:01PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7102	Prec@(1,5) (31.1%, 62.8%)
12/03 04:09:07PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7145	Prec@(1,5) (30.9%, 62.6%)
12/03 04:09:13PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7211	Prec@(1,5) (30.7%, 62.3%)
12/03 04:09:13PM searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 30.6600%
12/03 04:09:13PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 6])
12/03 04:09:14PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.6600%
12/03 04:10:04PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.8473 (2.5767)	Arch Loss 2.6457 (2.7140)	Arch Hard Loss 2.6398 (2.7080)	Arch Beta Loss 5.9331 (5.9389)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 65.2%)	
12/03 04:10:53PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.5340 (2.5772)	Arch Loss 2.6562 (2.7066)	Arch Hard Loss 2.6503 (2.7007)	Arch Beta Loss 5.9200 (5.9329)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.3%, 65.7%)	
12/03 04:11:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.6699 (2.5704)	Arch Loss 3.2771 (2.7007)	Arch Hard Loss 3.2712 (2.6947)	Arch Beta Loss 5.9104 (5.9275)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.8%)	
12/03 04:12:26PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.6139 (2.5658)	Arch Loss 2.7149 (2.6804)	Arch Hard Loss 2.7090 (2.6745)	Arch Beta Loss 5.9024 (5.9224)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 65.9%)	
12/03 04:12:27PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  7/49] Final Prec@1 32.8520%
12/03 04:12:34PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6433	Prec@(1,5) (32.5%, 63.9%)
12/03 04:12:41PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6183	Prec@(1,5) (32.5%, 64.8%)
12/03 04:12:47PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6151	Prec@(1,5) (32.4%, 64.9%)
12/03 04:12:53PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6235	Prec@(1,5) (32.2%, 64.6%)
12/03 04:12:53PM searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 32.1640%
12/03 04:12:53PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 6])
12/03 04:12:54PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.1640%
12/03 04:13:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.3413 (2.4465)	Arch Loss 2.7561 (2.6104)	Arch Hard Loss 2.7502 (2.6045)	Arch Beta Loss 5.8919 (5.8968)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 69.0%)	
12/03 04:14:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.1287 (2.4475)	Arch Loss 2.8692 (2.6100)	Arch Hard Loss 2.8633 (2.6042)	Arch Beta Loss 5.8788 (5.8911)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.0%, 69.2%)	
12/03 04:15:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.3874 (2.4445)	Arch Loss 2.5928 (2.6079)	Arch Hard Loss 2.5869 (2.6021)	Arch Beta Loss 5.8715 (5.8857)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 69.0%)	
12/03 04:16:08PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.1242 (2.4426)	Arch Loss 2.5822 (2.5946)	Arch Hard Loss 2.5763 (2.5887)	Arch Beta Loss 5.8646 (5.8819)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.4%, 69.0%)	
12/03 04:16:09PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  8/49] Final Prec@1 35.3720%
12/03 04:16:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4794	Prec@(1,5) (35.2%, 68.4%)
12/03 04:16:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5015	Prec@(1,5) (34.6%, 67.6%)
12/03 04:16:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5148	Prec@(1,5) (34.3%, 67.2%)
12/03 04:16:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5151	Prec@(1,5) (34.3%, 67.2%)
12/03 04:16:35PM searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 34.2800%
12/03 04:16:35PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:16:36PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.2800%
12/03 04:17:26PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.4258 (2.3474)	Arch Loss 2.6900 (2.5526)	Arch Hard Loss 2.6841 (2.5467)	Arch Beta Loss 5.8481 (5.8569)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.1%, 70.7%)	
12/03 04:18:16PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.5099 (2.3516)	Arch Loss 2.5086 (2.5210)	Arch Hard Loss 2.5028 (2.5152)	Arch Beta Loss 5.8371 (5.8494)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 71.1%)	
12/03 04:19:05PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.3681 (2.3438)	Arch Loss 2.3092 (2.5149)	Arch Hard Loss 2.3034 (2.5091)	Arch Beta Loss 5.8311 (5.8442)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.0%, 71.2%)	
12/03 04:19:49PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1740 (2.3422)	Arch Loss 2.4816 (2.5094)	Arch Hard Loss 2.4758 (2.5036)	Arch Beta Loss 5.8236 (5.8403)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 71.1%)	
12/03 04:19:50PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  9/49] Final Prec@1 37.8840%
12/03 04:19:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4896	Prec@(1,5) (35.3%, 68.2%)
12/03 04:20:03PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4703	Prec@(1,5) (35.5%, 68.5%)
12/03 04:20:10PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4815	Prec@(1,5) (35.3%, 68.2%)
12/03 04:20:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4796	Prec@(1,5) (35.4%, 68.2%)
12/03 04:20:16PM searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 35.3880%
12/03 04:20:16PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:20:16PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.3880%
12/03 04:21:07PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.4986 (2.2356)	Arch Loss 2.5446 (2.4928)	Arch Hard Loss 2.5388 (2.4870)	Arch Beta Loss 5.8175 (5.8206)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.1%)	
12/03 04:21:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4277 (2.2507)	Arch Loss 2.3728 (2.4570)	Arch Hard Loss 2.3670 (2.4511)	Arch Beta Loss 5.8096 (5.8173)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 73.1%)	
12/03 04:22:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3904 (2.2540)	Arch Loss 2.1236 (2.4384)	Arch Hard Loss 2.1178 (2.4326)	Arch Beta Loss 5.8026 (5.8135)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.8%, 72.9%)	
12/03 04:23:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.1614 (2.2436)	Arch Loss 2.3946 (2.4280)	Arch Hard Loss 2.3888 (2.4222)	Arch Beta Loss 5.7930 (5.8097)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 73.1%)	
12/03 04:23:30PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 10/49] Final Prec@1 40.1680%
12/03 04:23:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4089	Prec@(1,5) (37.5%, 69.5%)
12/03 04:23:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3762	Prec@(1,5) (37.6%, 70.1%)
12/03 04:23:51PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3863	Prec@(1,5) (37.5%, 70.0%)
12/03 04:23:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3835	Prec@(1,5) (37.5%, 70.1%)
12/03 04:23:57PM searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 37.4840%
12/03 04:23:57PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[2, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:23:57PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.4840%
12/03 04:24:48PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.1017 (2.1320)	Arch Loss 2.8691 (2.3712)	Arch Hard Loss 2.8633 (2.3654)	Arch Beta Loss 5.7875 (5.7902)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.2%, 75.7%)	
12/03 04:25:37PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.5130 (2.1234)	Arch Loss 2.7449 (2.3741)	Arch Hard Loss 2.7392 (2.3683)	Arch Beta Loss 5.7784 (5.7862)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 75.6%)	
12/03 04:26:26PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.1414 (2.1331)	Arch Loss 2.2862 (2.3675)	Arch Hard Loss 2.2804 (2.3617)	Arch Beta Loss 5.7690 (5.7817)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 75.4%)	
12/03 04:27:11PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.9825 (2.1460)	Arch Loss 2.2048 (2.3629)	Arch Hard Loss 2.1991 (2.3571)	Arch Beta Loss 5.7660 (5.7783)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 75.2%)	
12/03 04:27:11PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 11/49] Final Prec@1 41.6080%
12/03 04:27:18PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3649	Prec@(1,5) (38.1%, 70.4%)
12/03 04:27:25PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3608	Prec@(1,5) (38.3%, 70.6%)
12/03 04:27:32PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3478	Prec@(1,5) (38.6%, 70.9%)
12/03 04:27:38PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3456	Prec@(1,5) (38.7%, 70.8%)
12/03 04:27:38PM searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 38.7240%
12/03 04:27:38PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:27:38PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.7240%
12/03 04:28:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.9928 (2.0260)	Arch Loss 2.0941 (2.3253)	Arch Hard Loss 2.0883 (2.3195)	Arch Beta Loss 5.7590 (5.7626)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 77.4%)	
12/03 04:29:18PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.2186 (2.0552)	Arch Loss 2.0245 (2.3285)	Arch Hard Loss 2.0187 (2.3227)	Arch Beta Loss 5.7557 (5.7599)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.9%)	
12/03 04:30:07PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9690 (2.0531)	Arch Loss 2.4164 (2.3124)	Arch Hard Loss 2.4107 (2.3066)	Arch Beta Loss 5.7449 (5.7568)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.3%, 77.0%)	
12/03 04:30:51PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.7289 (2.0594)	Arch Loss 2.3240 (2.2999)	Arch Hard Loss 2.3183 (2.2941)	Arch Beta Loss 5.7380 (5.7532)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.7%)	
12/03 04:30:52PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 12/49] Final Prec@1 43.9800%
12/03 04:30:59PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2706	Prec@(1,5) (39.8%, 72.5%)
12/03 04:31:05PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2564	Prec@(1,5) (40.0%, 72.6%)
12/03 04:31:11PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2598	Prec@(1,5) (40.0%, 72.6%)
12/03 04:31:17PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2669	Prec@(1,5) (40.0%, 72.4%)
12/03 04:31:17PM searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 39.9760%
12/03 04:31:17PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:31:18PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.9760%
12/03 04:32:08PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1112 (1.9420)	Arch Loss 2.3470 (2.2718)	Arch Hard Loss 2.3413 (2.2661)	Arch Beta Loss 5.7314 (5.7336)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.5%, 78.6%)	
12/03 04:32:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.6612 (1.9886)	Arch Loss 2.2490 (2.2583)	Arch Hard Loss 2.2433 (2.2525)	Arch Beta Loss 5.7221 (5.7304)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.5%, 77.9%)	
12/03 04:33:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.7849 (1.9894)	Arch Loss 2.2832 (2.2577)	Arch Hard Loss 2.2775 (2.2520)	Arch Beta Loss 5.7190 (5.7268)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.8%, 78.1%)	
12/03 04:34:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.8822 (1.9923)	Arch Loss 1.9199 (2.2544)	Arch Hard Loss 1.9142 (2.2486)	Arch Beta Loss 5.7160 (5.7249)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.7%, 78.0%)	
12/03 04:34:30PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 13/49] Final Prec@1 45.6520%
12/03 04:34:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2260	Prec@(1,5) (41.3%, 73.6%)
12/03 04:34:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2538	Prec@(1,5) (40.4%, 73.1%)
12/03 04:34:50PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2370	Prec@(1,5) (40.8%, 73.3%)
12/03 04:34:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2393	Prec@(1,5) (40.8%, 73.1%)
12/03 04:34:56PM searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 40.7920%
12/03 04:34:56PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:34:57PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.7920%
12/03 04:35:47PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8253 (1.8598)	Arch Loss 2.3537 (2.2084)	Arch Hard Loss 2.3480 (2.2027)	Arch Beta Loss 5.7055 (5.7115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.7%)	
12/03 04:36:36PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8851 (1.9010)	Arch Loss 2.2341 (2.2131)	Arch Hard Loss 2.2284 (2.2074)	Arch Beta Loss 5.6999 (5.7069)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.8%)	
12/03 04:37:26PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.9737 (1.9085)	Arch Loss 2.3690 (2.2046)	Arch Hard Loss 2.3633 (2.1989)	Arch Beta Loss 5.6934 (5.7030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.7%, 79.6%)	
12/03 04:38:10PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.7836 (1.9136)	Arch Loss 2.2708 (2.1944)	Arch Hard Loss 2.2651 (2.1887)	Arch Beta Loss 5.6850 (5.6996)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.5%)	
12/03 04:38:11PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 14/49] Final Prec@1 47.4880%
12/03 04:38:18PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.2040	Prec@(1,5) (41.5%, 74.5%)
12/03 04:38:25PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.2303	Prec@(1,5) (41.0%, 73.8%)
12/03 04:38:31PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.2270	Prec@(1,5) (40.9%, 73.7%)
12/03 04:38:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.2334	Prec@(1,5) (40.8%, 73.5%)
12/03 04:38:37PM searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 40.8480%
12/03 04:38:37PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:38:38PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.8480%
12/03 04:39:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.0925 (1.8109)	Arch Loss 2.2222 (2.1799)	Arch Hard Loss 2.2165 (2.1742)	Arch Beta Loss 5.6781 (5.6808)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.1%)	
12/03 04:40:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.5957 (1.8187)	Arch Loss 2.0039 (2.1748)	Arch Hard Loss 1.9982 (2.1691)	Arch Beta Loss 5.6738 (5.6786)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.0%)	
12/03 04:41:06PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9872 (1.8203)	Arch Loss 1.8764 (2.1782)	Arch Hard Loss 1.8708 (2.1726)	Arch Beta Loss 5.6660 (5.6755)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.1%)	
12/03 04:41:51PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.5902 (1.8309)	Arch Loss 2.0855 (2.1757)	Arch Hard Loss 2.0798 (2.1701)	Arch Beta Loss 5.6584 (5.6724)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 81.1%)	
12/03 04:41:51PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 15/49] Final Prec@1 49.2520%
12/03 04:41:58PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.2081	Prec@(1,5) (41.2%, 74.1%)
12/03 04:42:05PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1795	Prec@(1,5) (42.1%, 74.3%)
12/03 04:42:12PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1915	Prec@(1,5) (42.0%, 74.0%)
12/03 04:42:17PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1862	Prec@(1,5) (42.2%, 74.2%)
12/03 04:42:17PM searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 42.2320%
12/03 04:42:17PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:42:18PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.2320%
12/03 04:43:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7311 (1.7645)	Arch Loss 1.8925 (2.1628)	Arch Hard Loss 1.8869 (2.1572)	Arch Beta Loss 5.6449 (5.6518)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.3%)	
12/03 04:43:58PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.8121 (1.7751)	Arch Loss 2.0642 (2.1434)	Arch Hard Loss 2.0586 (2.1378)	Arch Beta Loss 5.6368 (5.6466)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 82.1%)	
12/03 04:44:46PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.8557 (1.7809)	Arch Loss 2.3033 (2.1455)	Arch Hard Loss 2.2977 (2.1399)	Arch Beta Loss 5.6323 (5.6427)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.9%)	
12/03 04:45:30PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.6567 (1.7832)	Arch Loss 2.1397 (2.1320)	Arch Hard Loss 2.1341 (2.1264)	Arch Beta Loss 5.6271 (5.6397)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.9%)	
12/03 04:45:31PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 16/49] Final Prec@1 50.2640%
12/03 04:45:38PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1384	Prec@(1,5) (43.2%, 75.3%)
12/03 04:45:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1209	Prec@(1,5) (43.6%, 75.5%)
12/03 04:45:51PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1180	Prec@(1,5) (43.9%, 75.7%)
12/03 04:45:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1087	Prec@(1,5) (43.9%, 75.9%)
12/03 04:45:57PM searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 43.9400%
12/03 04:45:57PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:45:58PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.9400%
12/03 04:46:48PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.4770 (1.6647)	Arch Loss 2.1006 (2.0936)	Arch Hard Loss 2.0950 (2.0880)	Arch Beta Loss 5.6196 (5.6237)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.2%, 84.3%)	
12/03 04:47:36PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.6052 (1.6843)	Arch Loss 2.0371 (2.0920)	Arch Hard Loss 2.0315 (2.0864)	Arch Beta Loss 5.6148 (5.6209)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.9%)	
12/03 04:48:24PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8509 (1.6997)	Arch Loss 1.8739 (2.1018)	Arch Hard Loss 1.8683 (2.0961)	Arch Beta Loss 5.6131 (5.6184)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 83.5%)	
12/03 04:49:06PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.5368 (1.7133)	Arch Loss 2.2062 (2.1041)	Arch Hard Loss 2.2006 (2.0985)	Arch Beta Loss 5.6072 (5.6166)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 83.4%)	
12/03 04:49:07PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 17/49] Final Prec@1 51.7720%
12/03 04:49:14PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0669	Prec@(1,5) (44.7%, 76.6%)
12/03 04:49:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0366	Prec@(1,5) (45.5%, 77.1%)
12/03 04:49:27PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0412	Prec@(1,5) (45.4%, 77.1%)
12/03 04:49:33PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0410	Prec@(1,5) (45.4%, 77.0%)
12/03 04:49:33PM searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 45.3680%
12/03 04:49:33PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 6])
12/03 04:49:34PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.3680%
12/03 04:50:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.3882 (1.6078)	Arch Loss 2.1477 (2.0405)	Arch Hard Loss 2.1421 (2.0349)	Arch Beta Loss 5.5984 (5.6025)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.0%)	
12/03 04:51:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4000 (1.6541)	Arch Loss 2.0368 (2.0568)	Arch Hard Loss 2.0312 (2.0512)	Arch Beta Loss 5.5921 (5.5986)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.7%, 84.1%)	
12/03 04:52:00PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.7076 (1.6520)	Arch Loss 2.3325 (2.0596)	Arch Hard Loss 2.3269 (2.0540)	Arch Beta Loss 5.5899 (5.5966)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.8%, 84.2%)	
12/03 04:52:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.9374 (1.6631)	Arch Loss 1.4721 (2.0466)	Arch Hard Loss 1.4665 (2.0410)	Arch Beta Loss 5.5857 (5.5942)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.9%)	
12/03 04:52:43PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 18/49] Final Prec@1 53.4640%
12/03 04:52:50PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0413	Prec@(1,5) (45.3%, 77.0%)
12/03 04:52:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0426	Prec@(1,5) (45.3%, 77.2%)
12/03 04:53:04PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0391	Prec@(1,5) (45.6%, 77.0%)
12/03 04:53:10PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0447	Prec@(1,5) (45.3%, 77.1%)
12/03 04:53:10PM searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 45.3040%
12/03 04:53:10PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 04:53:10PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.3680%
12/03 04:54:00PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.1771 (1.5539)	Arch Loss 2.1395 (2.0316)	Arch Hard Loss 2.1339 (2.0260)	Arch Beta Loss 5.5820 (5.5848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.5%)	
12/03 04:54:49PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.8500 (1.5828)	Arch Loss 2.3678 (2.0411)	Arch Hard Loss 2.3622 (2.0356)	Arch Beta Loss 5.5807 (5.5835)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.7%, 85.2%)	
12/03 04:55:39PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.0597 (1.5960)	Arch Loss 1.6320 (2.0229)	Arch Hard Loss 1.6265 (2.0173)	Arch Beta Loss 5.5719 (5.5807)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.9%)	
12/03 04:56:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.6894 (1.6119)	Arch Loss 2.1635 (2.0201)	Arch Hard Loss 2.1580 (2.0146)	Arch Beta Loss 5.5670 (5.5781)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.6%)	
12/03 04:56:24PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 19/49] Final Prec@1 54.4320%
12/03 04:56:31PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0299	Prec@(1,5) (45.7%, 77.7%)
12/03 04:56:38PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0380	Prec@(1,5) (45.6%, 77.0%)
12/03 04:56:45PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0216	Prec@(1,5) (45.8%, 77.3%)
12/03 04:56:51PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0161	Prec@(1,5) (45.8%, 77.4%)
12/03 04:56:51PM searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 45.8080%
12/03 04:56:51PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 04:56:52PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.8080%
12/03 04:57:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.5706 (1.5175)	Arch Loss 1.8062 (2.0077)	Arch Hard Loss 1.8007 (2.0021)	Arch Beta Loss 5.5599 (5.5642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.2%, 86.6%)	
12/03 04:58:33PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5118 (1.5235)	Arch Loss 2.5242 (2.0036)	Arch Hard Loss 2.5187 (1.9980)	Arch Beta Loss 5.5570 (5.5615)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 86.4%)	
12/03 04:59:22PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.1947 (1.5340)	Arch Loss 1.7190 (2.0060)	Arch Hard Loss 1.7134 (2.0005)	Arch Beta Loss 5.5495 (5.5588)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.9%, 86.2%)	
12/03 05:00:06PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.5897 (1.5561)	Arch Loss 1.7144 (2.0067)	Arch Hard Loss 1.7088 (2.0011)	Arch Beta Loss 5.5405 (5.5558)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.8%)	
12/03 05:00:07PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 20/49] Final Prec@1 55.5680%
12/03 05:00:14PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0183	Prec@(1,5) (46.8%, 77.0%)
12/03 05:00:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0102	Prec@(1,5) (46.8%, 77.4%)
12/03 05:00:26PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0082	Prec@(1,5) (46.8%, 77.5%)
12/03 05:00:32PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0214	Prec@(1,5) (46.5%, 77.3%)
12/03 05:00:32PM searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 46.4760%
12/03 05:00:32PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:00:33PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.4760%
12/03 05:01:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.4288 (1.4252)	Arch Loss 2.4011 (1.9795)	Arch Hard Loss 2.3956 (1.9740)	Arch Beta Loss 5.5331 (5.5363)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.1%, 88.4%)	
12/03 05:02:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4328 (1.4658)	Arch Loss 2.2737 (1.9924)	Arch Hard Loss 2.2681 (1.9869)	Arch Beta Loss 5.5208 (5.5318)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.0%, 87.4%)	
12/03 05:02:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.5463 (1.4835)	Arch Loss 1.8307 (1.9849)	Arch Hard Loss 1.8252 (1.9794)	Arch Beta Loss 5.5177 (5.5278)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.7%, 87.0%)	
12/03 05:03:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.6121 (1.4981)	Arch Loss 1.7766 (1.9841)	Arch Hard Loss 1.7711 (1.9786)	Arch Beta Loss 5.5115 (5.5246)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.8%)	
12/03 05:03:42PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 21/49] Final Prec@1 57.3560%
12/03 05:03:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9634	Prec@(1,5) (48.2%, 77.7%)
12/03 05:03:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9493	Prec@(1,5) (48.3%, 78.2%)
12/03 05:04:02PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9528	Prec@(1,5) (47.8%, 78.2%)
12/03 05:04:08PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9462	Prec@(1,5) (47.9%, 78.4%)
12/03 05:04:08PM searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 47.9080%
12/03 05:04:08PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:04:09PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9080%
12/03 05:04:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.5124 (1.3678)	Arch Loss 2.2476 (1.9746)	Arch Hard Loss 2.2421 (1.9691)	Arch Beta Loss 5.5043 (5.5070)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.9%)	
12/03 05:05:48PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4449 (1.4082)	Arch Loss 1.9227 (1.9460)	Arch Hard Loss 1.9172 (1.9405)	Arch Beta Loss 5.5035 (5.5053)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.0%)	
12/03 05:06:37PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3257 (1.4289)	Arch Loss 2.3386 (1.9407)	Arch Hard Loss 2.3331 (1.9352)	Arch Beta Loss 5.4974 (5.5035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.6%)	
12/03 05:07:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.5117 (1.4445)	Arch Loss 1.8070 (1.9427)	Arch Hard Loss 1.8015 (1.9372)	Arch Beta Loss 5.4985 (5.5021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.5%)	
12/03 05:07:22PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 22/49] Final Prec@1 58.7600%
12/03 05:07:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8931	Prec@(1,5) (49.6%, 79.5%)
12/03 05:07:36PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9084	Prec@(1,5) (49.1%, 79.5%)
12/03 05:07:42PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9146	Prec@(1,5) (48.7%, 79.4%)
12/03 05:07:48PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9223	Prec@(1,5) (48.4%, 79.3%)
12/03 05:07:48PM searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 48.4680%
12/03 05:07:48PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:07:49PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4680%
12/03 05:08:39PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4097 (1.3062)	Arch Loss 1.8231 (1.9272)	Arch Hard Loss 1.8176 (1.9217)	Arch Beta Loss 5.4965 (5.4972)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.7%)	
12/03 05:09:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3048 (1.3488)	Arch Loss 2.1301 (1.9317)	Arch Hard Loss 2.1246 (1.9262)	Arch Beta Loss 5.4892 (5.4946)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.9%)	
12/03 05:10:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.6152 (1.3674)	Arch Loss 1.6069 (1.9375)	Arch Hard Loss 1.6014 (1.9320)	Arch Beta Loss 5.4863 (5.4922)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.7%)	
12/03 05:11:01PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.5621 (1.3833)	Arch Loss 2.0728 (1.9360)	Arch Hard Loss 2.0673 (1.9305)	Arch Beta Loss 5.4800 (5.4898)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.4%)	
12/03 05:11:02PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 23/49] Final Prec@1 60.4080%
12/03 05:11:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8791	Prec@(1,5) (49.1%, 79.1%)
12/03 05:11:15PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8728	Prec@(1,5) (49.4%, 79.6%)
12/03 05:11:22PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8782	Prec@(1,5) (49.4%, 79.5%)
12/03 05:11:28PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8812	Prec@(1,5) (49.2%, 79.7%)
12/03 05:11:28PM searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 49.2520%
12/03 05:11:28PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:11:28PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2520%
12/03 05:12:19PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 0.9386 (1.2966)	Arch Loss 2.0085 (1.9232)	Arch Hard Loss 2.0030 (1.9177)	Arch Beta Loss 5.4763 (5.4779)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 90.0%)	
12/03 05:13:07PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3696 (1.3217)	Arch Loss 2.1279 (1.9281)	Arch Hard Loss 2.1224 (1.9227)	Arch Beta Loss 5.4701 (5.4755)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.4%)	
12/03 05:13:55PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.5984 (1.3351)	Arch Loss 1.5303 (1.9219)	Arch Hard Loss 1.5249 (1.9165)	Arch Beta Loss 5.4645 (5.4728)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.5%, 89.2%)	
12/03 05:14:38PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2186 (1.3516)	Arch Loss 1.8059 (1.9277)	Arch Hard Loss 1.8005 (1.9223)	Arch Beta Loss 5.4602 (5.4702)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.9%)	
12/03 05:14:38PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 24/49] Final Prec@1 61.0720%
12/03 05:14:45PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9143	Prec@(1,5) (49.3%, 79.7%)
12/03 05:14:52PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8991	Prec@(1,5) (49.6%, 79.8%)
12/03 05:14:58PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9065	Prec@(1,5) (49.5%, 79.5%)
12/03 05:15:04PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8971	Prec@(1,5) (49.6%, 79.8%)
12/03 05:15:04PM searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 49.5800%
12/03 05:15:04PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:15:05PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.5800%
12/03 05:15:55PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3260 (1.2580)	Arch Loss 2.2098 (1.8822)	Arch Hard Loss 2.2043 (1.8768)	Arch Beta Loss 5.4544 (5.4573)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.4%)	
12/03 05:16:44PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.4482 (1.2768)	Arch Loss 2.2222 (1.8963)	Arch Hard Loss 2.2167 (1.8908)	Arch Beta Loss 5.4466 (5.4540)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.0%)	
12/03 05:17:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.1579 (1.2875)	Arch Loss 1.3596 (1.9040)	Arch Hard Loss 1.3541 (1.8986)	Arch Beta Loss 5.4432 (5.4507)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.7%)	
12/03 05:18:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.2202 (1.2981)	Arch Loss 1.5208 (1.8987)	Arch Hard Loss 1.5154 (1.8932)	Arch Beta Loss 5.4389 (5.4486)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.6%)	
12/03 05:18:17PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 25/49] Final Prec@1 62.5520%
12/03 05:18:24PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8602	Prec@(1,5) (50.5%, 80.6%)
12/03 05:18:31PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8625	Prec@(1,5) (50.7%, 80.3%)
12/03 05:18:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8492	Prec@(1,5) (50.6%, 80.6%)
12/03 05:18:43PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8515	Prec@(1,5) (50.4%, 80.5%)
12/03 05:18:43PM searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 50.4040%
12/03 05:18:43PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:18:44PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.4040%
12/03 05:19:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5866 (1.2176)	Arch Loss 1.7140 (1.8347)	Arch Hard Loss 1.7086 (1.8292)	Arch Beta Loss 5.4328 (5.4369)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.0%)	
12/03 05:20:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.8577 (1.2307)	Arch Loss 2.1809 (1.8621)	Arch Hard Loss 2.1755 (1.8567)	Arch Beta Loss 5.4273 (5.4334)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.8%)	
12/03 05:21:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2214 (1.2289)	Arch Loss 1.6795 (1.8728)	Arch Hard Loss 1.6741 (1.8674)	Arch Beta Loss 5.4249 (5.4306)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.8%)	
12/03 05:21:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0978 (1.2496)	Arch Loss 2.1832 (1.8821)	Arch Hard Loss 2.1778 (1.8767)	Arch Beta Loss 5.4237 (5.4291)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.4%)	
12/03 05:21:57PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 26/49] Final Prec@1 63.9080%
12/03 05:22:04PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8428	Prec@(1,5) (50.2%, 80.8%)
12/03 05:22:11PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8261	Prec@(1,5) (51.0%, 81.1%)
12/03 05:22:17PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8392	Prec@(1,5) (50.7%, 80.8%)
12/03 05:22:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8413	Prec@(1,5) (50.5%, 80.8%)
12/03 05:22:23PM searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 50.4920%
12/03 05:22:23PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:22:24PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.4920%
12/03 05:23:14PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 0.9309 (1.1398)	Arch Loss 2.4509 (1.8745)	Arch Hard Loss 2.4454 (1.8691)	Arch Beta Loss 5.4166 (5.4199)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.2%)	
12/03 05:24:04PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.6820 (1.1796)	Arch Loss 1.5260 (1.8736)	Arch Hard Loss 1.5205 (1.8682)	Arch Beta Loss 5.4107 (5.4162)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.5%)	
12/03 05:24:53PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1448 (1.1896)	Arch Loss 2.0847 (1.8716)	Arch Hard Loss 2.0792 (1.8662)	Arch Beta Loss 5.4104 (5.4146)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.2%)	
12/03 05:25:37PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 0.9223 (1.2057)	Arch Loss 1.4880 (1.8698)	Arch Hard Loss 1.4826 (1.8643)	Arch Beta Loss 5.4085 (5.4136)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.9%)	
12/03 05:25:38PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 27/49] Final Prec@1 65.1040%
12/03 05:25:45PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8386	Prec@(1,5) (51.1%, 80.5%)
12/03 05:25:52PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8242	Prec@(1,5) (51.4%, 81.0%)
12/03 05:25:58PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8204	Prec@(1,5) (51.3%, 81.2%)
12/03 05:26:04PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8136	Prec@(1,5) (51.3%, 81.2%)
12/03 05:26:04PM searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 51.2880%
12/03 05:26:04PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:26:05PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.2880%
12/03 05:26:54PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.2668 (1.1244)	Arch Loss 1.8816 (1.8301)	Arch Hard Loss 1.8762 (1.8247)	Arch Beta Loss 5.4011 (5.4051)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.5%, 92.4%)	
12/03 05:27:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 0.9781 (1.1437)	Arch Loss 1.5157 (1.8451)	Arch Hard Loss 1.5103 (1.8397)	Arch Beta Loss 5.3977 (5.4027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 92.1%)	
12/03 05:28:30PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.3233 (1.1465)	Arch Loss 1.8597 (1.8497)	Arch Hard Loss 1.8543 (1.8443)	Arch Beta Loss 5.3955 (5.4008)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 92.0%)	
12/03 05:29:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 0.9095 (1.1671)	Arch Loss 1.4766 (1.8568)	Arch Hard Loss 1.4712 (1.8514)	Arch Beta Loss 5.3916 (5.3990)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.7%)	
12/03 05:29:13PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 28/49] Final Prec@1 65.9760%
12/03 05:29:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8084	Prec@(1,5) (51.2%, 81.2%)
12/03 05:29:27PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8415	Prec@(1,5) (50.3%, 80.8%)
12/03 05:29:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8290	Prec@(1,5) (50.8%, 81.0%)
12/03 05:29:41PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8205	Prec@(1,5) (51.1%, 81.1%)
12/03 05:29:41PM searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 51.0720%
12/03 05:29:41PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:29:41PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.2880%
12/03 05:30:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1955 (1.0741)	Arch Loss 1.7640 (1.8576)	Arch Hard Loss 1.7586 (1.8522)	Arch Beta Loss 5.3851 (5.3878)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.7%)	
12/03 05:31:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.8164 (1.0903)	Arch Loss 1.5402 (1.8515)	Arch Hard Loss 1.5348 (1.8461)	Arch Beta Loss 5.3761 (5.3844)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.5%)	
12/03 05:32:10PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1042 (1.1116)	Arch Loss 2.0069 (1.8491)	Arch Hard Loss 2.0016 (1.8438)	Arch Beta Loss 5.3711 (5.3806)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.3%)	
12/03 05:32:54PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.1076 (1.1243)	Arch Loss 1.8068 (1.8452)	Arch Hard Loss 1.8015 (1.8398)	Arch Beta Loss 5.3662 (5.3777)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.2%)	
12/03 05:32:55PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 29/49] Final Prec@1 67.2640%
12/03 05:33:02PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7816	Prec@(1,5) (52.5%, 81.8%)
12/03 05:33:08PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7760	Prec@(1,5) (52.8%, 82.0%)
12/03 05:33:14PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7894	Prec@(1,5) (52.4%, 81.7%)
12/03 05:33:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7801	Prec@(1,5) (52.3%, 81.8%)
12/03 05:33:20PM searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 52.3520%
12/03 05:33:20PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:33:21PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.3520%
12/03 05:34:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.0282 (1.0363)	Arch Loss 1.4759 (1.8135)	Arch Hard Loss 1.4706 (1.8082)	Arch Beta Loss 5.3618 (5.3634)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.4%)	
12/03 05:35:01PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.3370 (1.0363)	Arch Loss 1.8755 (1.8340)	Arch Hard Loss 1.8701 (1.8287)	Arch Beta Loss 5.3545 (5.3609)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.3%)	
12/03 05:35:50PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.2479 (1.0573)	Arch Loss 1.6652 (1.8314)	Arch Hard Loss 1.6599 (1.8260)	Arch Beta Loss 5.3544 (5.3587)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.0%)	
12/03 05:36:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2380 (1.0812)	Arch Loss 2.1359 (1.8339)	Arch Hard Loss 2.1306 (1.8285)	Arch Beta Loss 5.3498 (5.3571)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.8%)	
12/03 05:36:35PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 30/49] Final Prec@1 68.2960%
12/03 05:36:42PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8007	Prec@(1,5) (52.9%, 81.3%)
12/03 05:36:48PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7850	Prec@(1,5) (52.9%, 81.8%)
12/03 05:36:54PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7962	Prec@(1,5) (52.5%, 81.7%)
12/03 05:37:00PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8010	Prec@(1,5) (52.5%, 81.5%)
12/03 05:37:00PM searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 52.4760%
12/03 05:37:00PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:37:01PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.4760%
12/03 05:37:51PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9936 (1.0045)	Arch Loss 1.9036 (1.8213)	Arch Hard Loss 1.8983 (1.8160)	Arch Beta Loss 5.3406 (5.3446)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.5%)	
12/03 05:38:41PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.8464 (1.0195)	Arch Loss 1.8029 (1.8306)	Arch Hard Loss 1.7975 (1.8253)	Arch Beta Loss 5.3437 (5.3430)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
12/03 05:39:31PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1749 (1.0413)	Arch Loss 2.0531 (1.8371)	Arch Hard Loss 2.0477 (1.8317)	Arch Beta Loss 5.3346 (5.3417)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.2%)	
12/03 05:40:16PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3101 (1.0529)	Arch Loss 1.6864 (1.8284)	Arch Hard Loss 1.6811 (1.8230)	Arch Beta Loss 5.3321 (5.3398)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.0%)	
12/03 05:40:16PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 31/49] Final Prec@1 69.2440%
12/03 05:40:24PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7677	Prec@(1,5) (52.6%, 82.4%)
12/03 05:40:30PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7599	Prec@(1,5) (53.0%, 82.1%)
12/03 05:40:36PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7711	Prec@(1,5) (52.8%, 82.0%)
12/03 05:40:42PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7792	Prec@(1,5) (52.6%, 81.9%)
12/03 05:40:42PM searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 52.6280%
12/03 05:40:42PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:40:43PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6280%
12/03 05:41:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.1486 (0.9792)	Arch Loss 1.5270 (1.7809)	Arch Hard Loss 1.5216 (1.7755)	Arch Beta Loss 5.3270 (5.3303)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.9%)	
12/03 05:42:22PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.8748 (0.9938)	Arch Loss 2.0660 (1.8133)	Arch Hard Loss 2.0607 (1.8080)	Arch Beta Loss 5.3262 (5.3281)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
12/03 05:43:11PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8827 (0.9972)	Arch Loss 2.0419 (1.8201)	Arch Hard Loss 2.0366 (1.8148)	Arch Beta Loss 5.3270 (5.3277)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.8%)	
12/03 05:43:55PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.0311 (1.0074)	Arch Loss 1.8797 (1.8075)	Arch Hard Loss 1.8743 (1.8022)	Arch Beta Loss 5.3235 (5.3272)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.7%)	
12/03 05:43:56PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 32/49] Final Prec@1 70.4520%
12/03 05:44:03PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7760	Prec@(1,5) (52.6%, 82.2%)
12/03 05:44:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7678	Prec@(1,5) (53.2%, 82.3%)
12/03 05:44:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7634	Prec@(1,5) (53.1%, 82.2%)
12/03 05:44:22PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7560	Prec@(1,5) (53.3%, 82.2%)
12/03 05:44:22PM searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 53.3240%
12/03 05:44:22PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:44:23PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3240%
12/03 05:45:13PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7894 (0.9047)	Arch Loss 1.9059 (1.7971)	Arch Hard Loss 1.9006 (1.7917)	Arch Beta Loss 5.3177 (5.3200)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.7%, 95.1%)	
12/03 05:46:02PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8815 (0.9386)	Arch Loss 1.3639 (1.7670)	Arch Hard Loss 1.3586 (1.7617)	Arch Beta Loss 5.3129 (5.3176)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.4%)	
12/03 05:46:52PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.1255 (0.9547)	Arch Loss 2.3284 (1.7945)	Arch Hard Loss 2.3231 (1.7892)	Arch Beta Loss 5.3103 (5.3156)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.2%)	
12/03 05:47:36PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1134 (0.9707)	Arch Loss 1.7799 (1.7955)	Arch Hard Loss 1.7746 (1.7902)	Arch Beta Loss 5.3094 (5.3144)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.1%)	
12/03 05:47:37PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 33/49] Final Prec@1 71.7120%
12/03 05:47:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7843	Prec@(1,5) (52.6%, 82.2%)
12/03 05:47:50PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7613	Prec@(1,5) (53.4%, 82.0%)
12/03 05:47:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7680	Prec@(1,5) (53.1%, 82.1%)
12/03 05:48:02PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7738	Prec@(1,5) (53.1%, 82.0%)
12/03 05:48:02PM searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 53.0600%
12/03 05:48:02PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:48:03PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3240%
12/03 05:48:54PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7927 (0.8948)	Arch Loss 1.9759 (1.7522)	Arch Hard Loss 1.9705 (1.7469)	Arch Beta Loss 5.3044 (5.3064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 95.1%)	
12/03 05:49:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.6489 (0.9240)	Arch Loss 1.9739 (1.7755)	Arch Hard Loss 1.9686 (1.7702)	Arch Beta Loss 5.2983 (5.3033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.7%)	
12/03 05:50:33PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.9719 (0.9254)	Arch Loss 2.0115 (1.7870)	Arch Hard Loss 2.0062 (1.7817)	Arch Beta Loss 5.2960 (5.3013)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.6%)	
12/03 05:51:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9466 (0.9398)	Arch Loss 1.6044 (1.7920)	Arch Hard Loss 1.5991 (1.7867)	Arch Beta Loss 5.2906 (5.2996)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.5%)	
12/03 05:51:18PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 34/49] Final Prec@1 72.5640%
12/03 05:51:25PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7727	Prec@(1,5) (53.2%, 82.0%)
12/03 05:51:31PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7745	Prec@(1,5) (53.0%, 82.3%)
12/03 05:51:38PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7579	Prec@(1,5) (53.3%, 82.4%)
12/03 05:51:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7640	Prec@(1,5) (53.1%, 82.3%)
12/03 05:51:44PM searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 53.1000%
12/03 05:51:44PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:51:44PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3240%
12/03 05:52:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.1202 (0.8649)	Arch Loss 1.7022 (1.7983)	Arch Hard Loss 1.6970 (1.7930)	Arch Beta Loss 5.2872 (5.2899)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.2%)	
12/03 05:53:24PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.0337 (0.8818)	Arch Loss 1.6437 (1.7871)	Arch Hard Loss 1.6384 (1.7818)	Arch Beta Loss 5.2847 (5.2878)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.7%, 94.9%)	
12/03 05:54:13PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0731 (0.8964)	Arch Loss 1.8137 (1.7734)	Arch Hard Loss 1.8084 (1.7681)	Arch Beta Loss 5.2816 (5.2861)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.8%)	
12/03 05:54:57PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.2112 (0.8994)	Arch Loss 1.5256 (1.7791)	Arch Hard Loss 1.5204 (1.7738)	Arch Beta Loss 5.2770 (5.2844)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
12/03 05:54:58PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 35/49] Final Prec@1 74.0040%
12/03 05:55:05PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.6937	Prec@(1,5) (54.6%, 82.9%)
12/03 05:55:12PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7045	Prec@(1,5) (54.2%, 82.9%)
12/03 05:55:18PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7125	Prec@(1,5) (54.4%, 82.9%)
12/03 05:55:24PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7175	Prec@(1,5) (54.4%, 82.7%)
12/03 05:55:25PM searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 54.3600%
12/03 05:55:25PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:55:25PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.3600%
12/03 05:56:16PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.7641 (0.8332)	Arch Loss 1.9155 (1.7944)	Arch Hard Loss 1.9102 (1.7891)	Arch Beta Loss 5.2762 (5.2759)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.7%)	
12/03 05:57:05PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.9325 (0.8486)	Arch Loss 1.5969 (1.7733)	Arch Hard Loss 1.5916 (1.7680)	Arch Beta Loss 5.2699 (5.2745)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.5%)	
12/03 05:57:54PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8042 (0.8632)	Arch Loss 1.7685 (1.7734)	Arch Hard Loss 1.7632 (1.7681)	Arch Beta Loss 5.2643 (5.2721)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.3%)	
12/03 05:58:38PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6838 (0.8676)	Arch Loss 1.7012 (1.7770)	Arch Hard Loss 1.6959 (1.7717)	Arch Beta Loss 5.2572 (5.2694)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
12/03 05:58:39PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 36/49] Final Prec@1 74.8560%
12/03 05:58:46PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7174	Prec@(1,5) (53.8%, 82.8%)
12/03 05:58:52PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7104	Prec@(1,5) (54.4%, 82.9%)
12/03 05:58:59PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7233	Prec@(1,5) (54.4%, 82.8%)
12/03 05:59:05PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7288	Prec@(1,5) (54.0%, 82.7%)
12/03 05:59:05PM searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 53.9760%
12/03 05:59:05PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 05:59:05PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.3600%
12/03 05:59:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.6938 (0.8045)	Arch Loss 2.0589 (1.7730)	Arch Hard Loss 2.0536 (1.7678)	Arch Beta Loss 5.2518 (5.2548)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.3%)	
12/03 06:00:46PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.8417 (0.8166)	Arch Loss 2.0128 (1.7548)	Arch Hard Loss 2.0076 (1.7496)	Arch Beta Loss 5.2484 (5.2522)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.0%)	
12/03 06:01:36PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.7788 (0.8276)	Arch Loss 1.6492 (1.7638)	Arch Hard Loss 1.6440 (1.7586)	Arch Beta Loss 5.2456 (5.2508)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.8%)	
12/03 06:02:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.6513 (0.8312)	Arch Loss 1.4510 (1.7637)	Arch Hard Loss 1.4457 (1.7585)	Arch Beta Loss 5.2418 (5.2492)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.8%)	
12/03 06:02:21PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 37/49] Final Prec@1 76.0640%
12/03 06:02:28PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7160	Prec@(1,5) (54.2%, 83.3%)
12/03 06:02:34PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7241	Prec@(1,5) (54.2%, 83.2%)
12/03 06:02:41PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7072	Prec@(1,5) (54.7%, 83.3%)
12/03 06:02:47PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7124	Prec@(1,5) (54.5%, 83.3%)
12/03 06:02:47PM searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 54.5200%
12/03 06:02:47PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:02:48PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5200%
12/03 06:03:38PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6311 (0.8005)	Arch Loss 1.5833 (1.7646)	Arch Hard Loss 1.5781 (1.7594)	Arch Beta Loss 5.2387 (5.2404)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.3%, 95.9%)	
12/03 06:04:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7329 (0.8011)	Arch Loss 1.8827 (1.7517)	Arch Hard Loss 1.8775 (1.7464)	Arch Beta Loss 5.2356 (5.2388)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 95.9%)	
12/03 06:05:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.0678 (0.8051)	Arch Loss 1.6815 (1.7481)	Arch Hard Loss 1.6763 (1.7428)	Arch Beta Loss 5.2291 (5.2366)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 95.9%)	
12/03 06:06:01PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.6597 (0.8105)	Arch Loss 1.8628 (1.7606)	Arch Hard Loss 1.8576 (1.7554)	Arch Beta Loss 5.2254 (5.2346)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.0%)	
12/03 06:06:02PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 38/49] Final Prec@1 76.6080%
12/03 06:06:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7296	Prec@(1,5) (55.3%, 82.3%)
12/03 06:06:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7042	Prec@(1,5) (55.2%, 83.0%)
12/03 06:06:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7024	Prec@(1,5) (54.9%, 83.2%)
12/03 06:06:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7009	Prec@(1,5) (54.9%, 83.2%)
12/03 06:06:29PM searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 54.8920%
12/03 06:06:29PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:06:30PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8920%
12/03 06:07:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.7050 (0.7472)	Arch Loss 1.5657 (1.7572)	Arch Hard Loss 1.5604 (1.7519)	Arch Beta Loss 5.2237 (5.2246)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.7%)	
12/03 06:08:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6689 (0.7592)	Arch Loss 1.6455 (1.7562)	Arch Hard Loss 1.6403 (1.7510)	Arch Beta Loss 5.2194 (5.2231)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.5%)	
12/03 06:08:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.6205 (0.7720)	Arch Loss 1.7013 (1.7595)	Arch Hard Loss 1.6961 (1.7543)	Arch Beta Loss 5.2121 (5.2207)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.3%)	
12/03 06:09:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.7360 (0.7774)	Arch Loss 1.8843 (1.7567)	Arch Hard Loss 1.8791 (1.7515)	Arch Beta Loss 5.2117 (5.2185)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.1%)	
12/03 06:09:43PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 39/49] Final Prec@1 77.7560%
12/03 06:09:50PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7135	Prec@(1,5) (54.2%, 83.1%)
12/03 06:09:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7217	Prec@(1,5) (54.4%, 82.9%)
12/03 06:10:03PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7216	Prec@(1,5) (54.5%, 82.9%)
12/03 06:10:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7224	Prec@(1,5) (54.6%, 82.9%)
12/03 06:10:09PM searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 54.6200%
12/03 06:10:09PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:10:10PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.8920%
12/03 06:11:00PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.7612 (0.7374)	Arch Loss 1.9478 (1.8070)	Arch Hard Loss 1.9426 (1.8018)	Arch Beta Loss 5.2079 (5.2101)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.7%)	
12/03 06:11:49PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.8015 (0.7413)	Arch Loss 2.0203 (1.7776)	Arch Hard Loss 2.0151 (1.7724)	Arch Beta Loss 5.2040 (5.2082)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.7%)	
12/03 06:12:38PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.7147 (0.7543)	Arch Loss 1.6391 (1.7734)	Arch Hard Loss 1.6339 (1.7682)	Arch Beta Loss 5.1989 (5.2063)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
12/03 06:13:22PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.9348 (0.7533)	Arch Loss 1.6475 (1.7629)	Arch Hard Loss 1.6423 (1.7577)	Arch Beta Loss 5.1972 (5.2043)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
12/03 06:13:23PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 40/49] Final Prec@1 78.7640%
12/03 06:13:30PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.6898	Prec@(1,5) (54.8%, 83.6%)
12/03 06:13:36PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.6879	Prec@(1,5) (55.2%, 83.3%)
12/03 06:13:43PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.6882	Prec@(1,5) (55.2%, 83.4%)
12/03 06:13:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.6920	Prec@(1,5) (55.1%, 83.4%)
12/03 06:13:49PM searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 55.0880%
12/03 06:13:49PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:13:49PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0880%
12/03 06:14:39PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7357 (0.7027)	Arch Loss 1.7636 (1.7738)	Arch Hard Loss 1.7584 (1.7686)	Arch Beta Loss 5.1947 (5.1958)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
12/03 06:15:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6529 (0.7161)	Arch Loss 1.6819 (1.7638)	Arch Hard Loss 1.6767 (1.7587)	Arch Beta Loss 5.1898 (5.1940)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
12/03 06:16:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6249 (0.7162)	Arch Loss 1.5133 (1.7594)	Arch Hard Loss 1.5081 (1.7542)	Arch Beta Loss 5.1867 (5.1921)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 96.9%)	
12/03 06:17:01PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.8689 (0.7274)	Arch Loss 1.5250 (1.7533)	Arch Hard Loss 1.5198 (1.7481)	Arch Beta Loss 5.1835 (5.1905)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.8%)	
12/03 06:17:02PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 41/49] Final Prec@1 79.7760%
12/03 06:17:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7207	Prec@(1,5) (55.2%, 82.9%)
12/03 06:17:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7085	Prec@(1,5) (54.8%, 83.1%)
12/03 06:17:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7003	Prec@(1,5) (55.2%, 83.3%)
12/03 06:17:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.6989	Prec@(1,5) (55.2%, 83.3%)
12/03 06:17:29PM searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 55.2480%
12/03 06:17:29PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:17:30PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2480%
12/03 06:18:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7353 (0.6866)	Arch Loss 1.5200 (1.7784)	Arch Hard Loss 1.5148 (1.7732)	Arch Beta Loss 5.1807 (5.1823)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
12/03 06:19:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7143 (0.6934)	Arch Loss 1.8844 (1.7383)	Arch Hard Loss 1.8792 (1.7332)	Arch Beta Loss 5.1773 (5.1806)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
12/03 06:19:58PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.7094 (0.7014)	Arch Loss 2.1027 (1.7434)	Arch Hard Loss 2.0976 (1.7383)	Arch Beta Loss 5.1715 (5.1783)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.2%)	
12/03 06:20:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.7283 (0.7064)	Arch Loss 1.9371 (1.7391)	Arch Hard Loss 1.9320 (1.7339)	Arch Beta Loss 5.1677 (5.1764)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
12/03 06:20:42PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 42/49] Final Prec@1 80.2920%
12/03 06:20:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6598	Prec@(1,5) (54.8%, 84.0%)
12/03 06:20:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.6959	Prec@(1,5) (54.4%, 83.4%)
12/03 06:21:02PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.6844	Prec@(1,5) (54.9%, 83.6%)
12/03 06:21:08PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.6876	Prec@(1,5) (55.1%, 83.5%)
12/03 06:21:08PM searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 55.1040%
12/03 06:21:08PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:21:09PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.2480%
12/03 06:21:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7842 (0.6689)	Arch Loss 1.6974 (1.7302)	Arch Hard Loss 1.6923 (1.7251)	Arch Beta Loss 5.1628 (5.1647)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.4%)	
12/03 06:22:48PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.7173 (0.6875)	Arch Loss 1.5162 (1.7465)	Arch Hard Loss 1.5110 (1.7413)	Arch Beta Loss 5.1602 (5.1631)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.2%)	
12/03 06:23:37PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7744 (0.6902)	Arch Loss 1.9565 (1.7420)	Arch Hard Loss 1.9514 (1.7368)	Arch Beta Loss 5.1605 (5.1620)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.1%)	
12/03 06:24:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.6014 (0.6907)	Arch Loss 1.7155 (1.7411)	Arch Hard Loss 1.7103 (1.7359)	Arch Beta Loss 5.1584 (5.1614)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.1%)	
12/03 06:24:22PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 43/49] Final Prec@1 81.2000%
12/03 06:24:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6719	Prec@(1,5) (55.3%, 84.2%)
12/03 06:24:36PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6630	Prec@(1,5) (55.5%, 84.1%)
12/03 06:24:42PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6627	Prec@(1,5) (55.6%, 83.9%)
12/03 06:24:48PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.6797	Prec@(1,5) (55.4%, 83.5%)
12/03 06:24:48PM searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 55.3920%
12/03 06:24:48PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:24:49PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.3920%
12/03 06:25:39PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.7247 (0.6775)	Arch Loss 1.9080 (1.7137)	Arch Hard Loss 1.9028 (1.7086)	Arch Beta Loss 5.1585 (5.1594)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
12/03 06:26:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8258 (0.6770)	Arch Loss 2.2761 (1.7281)	Arch Hard Loss 2.2710 (1.7229)	Arch Beta Loss 5.1553 (5.1582)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
12/03 06:27:18PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.7097 (0.6806)	Arch Loss 1.9026 (1.7364)	Arch Hard Loss 1.8975 (1.7312)	Arch Beta Loss 5.1530 (5.1567)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
12/03 06:28:02PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5771 (0.6795)	Arch Loss 1.7967 (1.7388)	Arch Hard Loss 1.7916 (1.7337)	Arch Beta Loss 5.1497 (5.1553)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.3%)	
12/03 06:28:03PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 44/49] Final Prec@1 81.2160%
12/03 06:28:10PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6444	Prec@(1,5) (56.6%, 84.2%)
12/03 06:28:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6723	Prec@(1,5) (55.9%, 83.7%)
12/03 06:28:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6798	Prec@(1,5) (55.6%, 83.4%)
12/03 06:28:28PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.6867	Prec@(1,5) (55.4%, 83.4%)
12/03 06:28:29PM searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 55.4240%
12/03 06:28:29PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/03 06:28:29PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.4240%
12/03 06:29:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5035 (0.6766)	Arch Loss 1.3668 (1.7365)	Arch Hard Loss 1.3617 (1.7314)	Arch Beta Loss 5.1459 (5.1480)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.3%)	
12/03 06:30:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.7534 (0.6671)	Arch Loss 1.8999 (1.7433)	Arch Hard Loss 1.8947 (1.7381)	Arch Beta Loss 5.1415 (5.1454)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.4%)	
12/03 06:30:58PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7937 (0.6671)	Arch Loss 2.0388 (1.7369)	Arch Hard Loss 2.0336 (1.7317)	Arch Beta Loss 5.1396 (5.1437)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.4%)	
12/03 06:31:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.5918 (0.6681)	Arch Loss 1.8839 (1.7460)	Arch Hard Loss 1.8787 (1.7408)	Arch Beta Loss 5.1376 (5.1424)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.4%)	
12/03 06:31:43PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 45/49] Final Prec@1 81.7680%
12/03 06:31:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6479	Prec@(1,5) (56.5%, 83.6%)
12/03 06:31:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.6813	Prec@(1,5) (55.7%, 83.5%)
12/03 06:32:02PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.6815	Prec@(1,5) (55.6%, 83.5%)
12/03 06:32:08PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.6819	Prec@(1,5) (55.6%, 83.5%)
12/03 06:32:08PM searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 55.6160%
12/03 06:32:08PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/03 06:32:09PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6160%
12/03 06:32:57PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.9393 (0.6307)	Arch Loss 1.4718 (1.7275)	Arch Hard Loss 1.4666 (1.7224)	Arch Beta Loss 5.1366 (5.1368)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.5%)	
12/03 06:33:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5598 (0.6394)	Arch Loss 1.5828 (1.7266)	Arch Hard Loss 1.5777 (1.7215)	Arch Beta Loss 5.1295 (5.1346)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.6%)	
12/03 06:34:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.4801 (0.6438)	Arch Loss 1.7656 (1.7330)	Arch Hard Loss 1.7604 (1.7279)	Arch Beta Loss 5.1250 (5.1320)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.6%)	
12/03 06:35:15PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.5746 (0.6519)	Arch Loss 1.7452 (1.7361)	Arch Hard Loss 1.7401 (1.7310)	Arch Beta Loss 5.1213 (5.1299)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.5%)	
12/03 06:35:15PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 46/49] Final Prec@1 82.5600%
12/03 06:35:22PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.6916	Prec@(1,5) (55.4%, 83.3%)
12/03 06:35:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6856	Prec@(1,5) (55.4%, 83.4%)
12/03 06:35:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6822	Prec@(1,5) (55.4%, 83.5%)
12/03 06:35:41PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.6824	Prec@(1,5) (55.5%, 83.5%)
12/03 06:35:41PM searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 55.4640%
12/03 06:35:41PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/03 06:35:42PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6160%
12/03 06:36:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.6536 (0.6505)	Arch Loss 1.3772 (1.7124)	Arch Hard Loss 1.3721 (1.7073)	Arch Beta Loss 5.1174 (5.1190)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.5%)	
12/03 06:37:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5813 (0.6383)	Arch Loss 1.7431 (1.7370)	Arch Hard Loss 1.7380 (1.7319)	Arch Beta Loss 5.1147 (5.1176)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.7%)	
12/03 06:38:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5919 (0.6466)	Arch Loss 1.6308 (1.7314)	Arch Hard Loss 1.6257 (1.7263)	Arch Beta Loss 5.1099 (5.1159)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.6%)	
12/03 06:38:52PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7401 (0.6507)	Arch Loss 1.9527 (1.7341)	Arch Hard Loss 1.9476 (1.7290)	Arch Beta Loss 5.1094 (5.1143)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.6%)	
12/03 06:38:52PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 47/49] Final Prec@1 82.7240%
12/03 06:38:59PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6793	Prec@(1,5) (55.5%, 84.0%)
12/03 06:39:06PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6723	Prec@(1,5) (55.6%, 83.9%)
12/03 06:39:13PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6692	Prec@(1,5) (55.6%, 83.9%)
12/03 06:39:18PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6776	Prec@(1,5) (55.4%, 83.7%)
12/03 06:39:19PM searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 55.3760%
12/03 06:39:19PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/03 06:39:19PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6160%
12/03 06:40:08PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6719 (0.6355)	Arch Loss 1.6969 (1.7201)	Arch Hard Loss 1.6918 (1.7150)	Arch Beta Loss 5.1051 (5.1070)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.6%)	
12/03 06:40:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6389 (0.6328)	Arch Loss 2.1313 (1.7342)	Arch Hard Loss 2.1262 (1.7291)	Arch Beta Loss 5.0999 (5.1044)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.7%)	
12/03 06:41:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.7096 (0.6412)	Arch Loss 1.6999 (1.7356)	Arch Hard Loss 1.6948 (1.7305)	Arch Beta Loss 5.0992 (5.1026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.6%)	
12/03 06:42:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6085 (0.6453)	Arch Loss 1.8557 (1.7336)	Arch Hard Loss 1.8506 (1.7285)	Arch Beta Loss 5.0941 (5.1013)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.5%)	
12/03 06:42:30PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 48/49] Final Prec@1 82.8440%
12/03 06:42:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.6784	Prec@(1,5) (55.6%, 83.6%)
12/03 06:42:43PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6746	Prec@(1,5) (55.5%, 83.3%)
12/03 06:42:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6750	Prec@(1,5) (55.3%, 83.5%)
12/03 06:42:55PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6783	Prec@(1,5) (55.3%, 83.4%)
12/03 06:42:55PM searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 55.2880%
12/03 06:42:55PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/03 06:42:56PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6160%
12/03 06:43:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.6164 (0.6378)	Arch Loss 1.5995 (1.7436)	Arch Hard Loss 1.5944 (1.7385)	Arch Beta Loss 5.0903 (5.0916)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
12/03 06:44:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5045 (0.6271)	Arch Loss 1.6348 (1.7352)	Arch Hard Loss 1.6297 (1.7301)	Arch Beta Loss 5.0895 (5.0908)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
12/03 06:45:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5128 (0.6307)	Arch Loss 1.9367 (1.7416)	Arch Hard Loss 1.9317 (1.7365)	Arch Beta Loss 5.0864 (5.0899)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.8%)	
12/03 06:46:07PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.7634 (0.6365)	Arch Loss 1.3414 (1.7453)	Arch Hard Loss 1.3364 (1.7402)	Arch Beta Loss 5.0851 (5.0890)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.7%)	
12/03 06:46:07PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 49/49] Final Prec@1 83.0640%
12/03 06:46:15PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6432	Prec@(1,5) (56.1%, 84.0%)
12/03 06:46:21PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6743	Prec@(1,5) (55.5%, 83.8%)
12/03 06:46:28PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6834	Prec@(1,5) (55.4%, 83.4%)
12/03 06:46:33PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6752	Prec@(1,5) (55.5%, 83.5%)
12/03 06:46:34PM searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 55.5240%
12/03 06:46:34PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/03 06:46:34PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6160%
12/03 06:46:34PM trainer_runner.py:110 [INFO] Final best Prec@1 = 55.6160%
12/03 06:46:34PM trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[3, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
