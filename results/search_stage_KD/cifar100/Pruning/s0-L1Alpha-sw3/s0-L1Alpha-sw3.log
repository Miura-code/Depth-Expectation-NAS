11/07 07:45:58PM parser.py:28 [INFO] 
11/07 07:45:58PM parser.py:29 [INFO] Parameters:
11/07 07:45:58PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-L1Alpha-sw3/DAG
11/07 07:45:58PM parser.py:31 [INFO] T=10.0
11/07 07:45:58PM parser.py:31 [INFO] ADVANCED=1
11/07 07:45:58PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/07 07:45:58PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/07 07:45:58PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/07 07:45:58PM parser.py:31 [INFO] BATCH_SIZE=64
11/07 07:45:58PM parser.py:31 [INFO] CASCADE=0
11/07 07:45:58PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/07 07:45:58PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/07 07:45:58PM parser.py:31 [INFO] DATA_PATH=../data/
11/07 07:45:58PM parser.py:31 [INFO] DATASET=cifar100
11/07 07:45:58PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/07 07:45:58PM parser.py:31 [INFO] DESCRIPTION=search_wtih_alpha-L1-constriction
11/07 07:45:58PM parser.py:31 [INFO] DISCRETE=0
11/07 07:45:58PM parser.py:31 [INFO] EPOCHS=50
11/07 07:45:58PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/07 07:45:58PM parser.py:31 [INFO] EXP_NAME=s0-L1Alpha-sw3
11/07 07:45:58PM parser.py:31 [INFO] FINAL_L=1.0
11/07 07:45:58PM parser.py:31 [INFO] G=1.0
11/07 07:45:58PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/07 07:45:58PM parser.py:31 [INFO] GPUS=[0]
11/07 07:45:58PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/07 07:45:58PM parser.py:31 [INFO] INIT_CHANNELS=16
11/07 07:45:58PM parser.py:31 [INFO] L=0.0
11/07 07:45:58PM parser.py:31 [INFO] LAYERS=20
11/07 07:45:58PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/07 07:45:58PM parser.py:31 [INFO] NAME=Pruning
11/07 07:45:58PM parser.py:31 [INFO] NONKD=1
11/07 07:45:58PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-L1Alpha-sw3
11/07 07:45:58PM parser.py:31 [INFO] PCDARTS=0
11/07 07:45:58PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-L1Alpha-sw3/plots
11/07 07:45:58PM parser.py:31 [INFO] PRINT_FREQ=100
11/07 07:45:58PM parser.py:31 [INFO] RESET=0
11/07 07:45:58PM parser.py:31 [INFO] RESUME_PATH=None
11/07 07:45:58PM parser.py:31 [INFO] SAVE=s0-L1Alpha-sw3
11/07 07:45:58PM parser.py:31 [INFO] SEED=0
11/07 07:45:58PM parser.py:31 [INFO] SHARE_STAGE=0
11/07 07:45:58PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/07 07:45:58PM parser.py:31 [INFO] SPEC_CELL=1
11/07 07:45:58PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/07 07:45:58PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/07 07:45:58PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/07 07:45:58PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/07 07:45:58PM parser.py:31 [INFO] TYPE=ArchKD
11/07 07:45:58PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/07 07:45:58PM parser.py:31 [INFO] W_LR=0.025
11/07 07:45:58PM parser.py:31 [INFO] W_LR_MIN=0.001
11/07 07:45:58PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/07 07:45:58PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/07 07:45:58PM parser.py:31 [INFO] WORKERS=4
11/07 07:45:58PM parser.py:32 [INFO] 
11/07 07:46:00PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/07 07:46:00PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/07 07:46:32PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.5103 (4.6722)	Arch Loss 4.4659 (4.6662)	Arch Hard Loss 4.4659 (4.6662)	Arch Alpha Loss 0.0735 (0.0518)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.1%, 8.7%)	
11/07 07:47:01PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2280 (4.5019)	Arch Loss 4.3086 (4.4989)	Arch Hard Loss 4.3086 (4.4989)	Arch Alpha Loss 0.0841 (0.0656)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.1%, 12.5%)	
11/07 07:47:29PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.3280 (4.3932)	Arch Loss 4.1630 (4.3880)	Arch Hard Loss 4.1630 (4.3880)	Arch Alpha Loss 0.0998 (0.0739)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 15.1%)	
11/07 07:47:55PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9930 (4.3195)	Arch Loss 4.0481 (4.3167)	Arch Hard Loss 4.0481 (4.3167)	Arch Alpha Loss 0.1176 (0.0809)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.6%, 17.1%)	
11/07 07:47:56PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 4.5720%
11/07 07:48:01PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.1093	Prec@(1,5) (6.2%, 23.2%)
11/07 07:48:05PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.1014	Prec@(1,5) (6.1%, 22.8%)
11/07 07:48:09PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0979	Prec@(1,5) (6.3%, 23.1%)
11/07 07:48:13PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0998	Prec@(1,5) (6.2%, 23.2%)
11/07 07:48:13PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 6.2400%
11/07 07:48:13PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 07:48:14PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 6.2400%
11/07 07:48:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9329 (3.9767)	Arch Loss 3.9927 (3.9925)	Arch Hard Loss 3.9926 (3.9924)	Arch Alpha Loss 0.0931 (0.1021)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.5%, 26.1%)	
11/07 07:49:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.2044 (3.9508)	Arch Loss 3.9995 (3.9467)	Arch Hard Loss 3.9994 (3.9466)	Arch Alpha Loss 0.1018 (0.0984)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.2%, 27.4%)	
11/07 07:49:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9474 (3.9213)	Arch Loss 3.6126 (3.9187)	Arch Hard Loss 3.6125 (3.9186)	Arch Alpha Loss 0.0791 (0.0958)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.6%, 28.6%)	
11/07 07:50:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.5366 (3.8973)	Arch Loss 3.9561 (3.8857)	Arch Hard Loss 3.9560 (3.8857)	Arch Alpha Loss 0.0894 (0.0932)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.8%, 29.4%)	
11/07 07:50:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 8.8600%
11/07 07:50:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.8052	Prec@(1,5) (10.3%, 32.3%)
11/07 07:50:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.8094	Prec@(1,5) (10.5%, 32.5%)
11/07 07:50:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.7960	Prec@(1,5) (10.7%, 32.8%)
11/07 07:50:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.7948	Prec@(1,5) (10.8%, 32.9%)
11/07 07:50:22午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 10.7680%
11/07 07:50:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG3_concat=range(6, 8))
11/07 07:50:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 10.7680%
11/07 07:50:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.5416 (3.7161)	Arch Loss 3.8636 (3.7146)	Arch Hard Loss 3.8633 (3.7144)	Arch Alpha Loss 0.0546 (0.0584)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.5%, 36.3%)	
11/07 07:51:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.7496 (3.6889)	Arch Loss 3.6893 (3.6858)	Arch Hard Loss 3.6892 (3.6856)	Arch Alpha Loss 0.0381 (0.0522)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.6%, 36.4%)	
11/07 07:51:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.5821 (3.6613)	Arch Loss 3.5956 (3.6601)	Arch Hard Loss 3.5955 (3.6600)	Arch Alpha Loss 0.0309 (0.0460)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.8%, 37.2%)	
11/07 07:52:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.8998 (3.6374)	Arch Loss 3.3557 (3.6388)	Arch Hard Loss 3.3556 (3.6386)	Arch Alpha Loss 0.0313 (0.0422)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.1%, 37.8%)	
11/07 07:52:15午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 13.1120%
11/07 07:52:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.6036	Prec@(1,5) (14.4%, 39.5%)
11/07 07:52:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.6013	Prec@(1,5) (14.6%, 39.4%)
11/07 07:52:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.5882	Prec@(1,5) (14.6%, 39.4%)
11/07 07:52:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.5916	Prec@(1,5) (14.6%, 39.3%)
11/07 07:52:32午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 14.5880%
11/07 07:52:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/07 07:52:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.5880%
11/07 07:53:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.4905 (3.4593)	Arch Loss 3.4023 (3.4963)	Arch Hard Loss 3.4020 (3.4961)	Arch Alpha Loss 0.0269 (0.0244)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.9%, 42.9%)	
11/07 07:53:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.4118 (3.4379)	Arch Loss 3.3789 (3.4693)	Arch Hard Loss 3.3787 (3.4691)	Arch Alpha Loss 0.0199 (0.0223)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.1%, 43.6%)	
11/07 07:53:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.4892 (3.4278)	Arch Loss 3.4008 (3.4546)	Arch Hard Loss 3.4006 (3.4544)	Arch Alpha Loss 0.0164 (0.0210)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.4%, 43.5%)	
11/07 07:54:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.2069 (3.4041)	Arch Loss 3.0049 (3.4260)	Arch Hard Loss 3.0048 (3.4258)	Arch Alpha Loss 0.0145 (0.0198)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.9%, 44.3%)	
11/07 07:54:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 16.8640%
11/07 07:54:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.4129	Prec@(1,5) (17.8%, 44.9%)
11/07 07:54:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.4106	Prec@(1,5) (17.7%, 45.2%)
11/07 07:54:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.4104	Prec@(1,5) (17.9%, 44.9%)
11/07 07:54:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.4074	Prec@(1,5) (18.0%, 45.2%)
11/07 07:54:41午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 17.9680%
11/07 07:54:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/07 07:54:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.9680%
11/07 07:55:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.8885 (3.2305)	Arch Loss 3.3368 (3.2790)	Arch Hard Loss 3.3367 (3.2788)	Arch Alpha Loss 0.0100 (0.0128)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.6%)	
11/07 07:55:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.2577 (3.2268)	Arch Loss 3.1947 (3.2570)	Arch Hard Loss 3.1945 (3.2568)	Arch Alpha Loss 0.0098 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.8%, 49.7%)	
11/07 07:56:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.1046 (3.2087)	Arch Loss 3.3954 (3.2456)	Arch Hard Loss 3.3953 (3.2455)	Arch Alpha Loss 0.0075 (0.0098)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.3%, 50.1%)	
11/07 07:56:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.5154 (3.1962)	Arch Loss 3.2039 (3.2365)	Arch Hard Loss 3.2038 (3.2364)	Arch Alpha Loss 0.0069 (0.0091)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 50.4%)	
11/07 07:56:34午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 20.6640%
11/07 07:56:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1773	Prec@(1,5) (21.8%, 51.5%)
11/07 07:56:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.1876	Prec@(1,5) (21.5%, 51.4%)
11/07 07:56:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.1777	Prec@(1,5) (21.7%, 51.6%)
11/07 07:56:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.1692	Prec@(1,5) (21.9%, 51.7%)
11/07 07:56:51午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 21.9280%
11/07 07:56:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/07 07:56:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.9280%
11/07 07:57:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.2563 (3.0661)	Arch Loss 3.4520 (3.1242)	Arch Hard Loss 3.4518 (3.1240)	Arch Alpha Loss 0.0072 (0.0071)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 52.6%)	
11/07 07:57:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.3908 (3.0614)	Arch Loss 2.8967 (3.1065)	Arch Hard Loss 2.8965 (3.1063)	Arch Alpha Loss 0.0069 (0.0070)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 53.2%)	
11/07 07:58:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.0044 (3.0312)	Arch Loss 3.0766 (3.0872)	Arch Hard Loss 3.0764 (3.0870)	Arch Alpha Loss 0.0066 (0.0068)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.1%, 54.1%)	
11/07 07:58:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.7850 (3.0241)	Arch Loss 2.8497 (3.0766)	Arch Hard Loss 2.8496 (3.0765)	Arch Alpha Loss 0.0043 (0.0065)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.2%, 54.4%)	
11/07 07:58:45午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 24.1720%
11/07 07:58:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.0111	Prec@(1,5) (24.9%, 55.1%)
11/07 07:58:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.0124	Prec@(1,5) (25.0%, 55.2%)
11/07 07:58:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.0160	Prec@(1,5) (24.8%, 55.0%)
11/07 07:59:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.0018	Prec@(1,5) (25.1%, 55.5%)
11/07 07:59:01午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 25.0960%
11/07 07:59:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/07 07:59:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.0960%
11/07 07:59:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.0029 (2.9087)	Arch Loss 3.2737 (2.9911)	Arch Hard Loss 3.2735 (2.9909)	Arch Alpha Loss 0.0052 (0.0063)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 57.3%)	
11/07 08:00:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.0357 (2.8976)	Arch Loss 3.2901 (2.9692)	Arch Hard Loss 3.2900 (2.9690)	Arch Alpha Loss 0.0050 (0.0061)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.3%, 57.7%)	
11/07 08:00:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.8105 (2.8877)	Arch Loss 3.2968 (2.9445)	Arch Hard Loss 3.2966 (2.9443)	Arch Alpha Loss 0.0057 (0.0058)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 58.1%)	
11/07 08:00:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.1446 (2.8838)	Arch Loss 2.7021 (2.9376)	Arch Hard Loss 2.7019 (2.9374)	Arch Alpha Loss 0.0046 (0.0056)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 58.2%)	
11/07 08:00:54午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 26.6600%
11/07 08:00:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.9015	Prec@(1,5) (26.6%, 57.2%)
11/07 08:01:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.8965	Prec@(1,5) (27.0%, 57.7%)
11/07 08:01:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.8928	Prec@(1,5) (27.2%, 57.7%)
11/07 08:01:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.8871	Prec@(1,5) (27.3%, 58.0%)
11/07 08:01:11午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 27.2440%
11/07 08:01:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=range(6, 8))
11/07 08:01:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.2440%
11/07 08:01:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.3282 (2.7616)	Arch Loss 2.8277 (2.9078)	Arch Hard Loss 2.8274 (2.9075)	Arch Alpha Loss 0.0057 (0.0059)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.2%, 61.1%)	
11/07 08:02:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.1379 (2.7607)	Arch Loss 2.9778 (2.8688)	Arch Hard Loss 2.9775 (2.8685)	Arch Alpha Loss 0.0058 (0.0056)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 60.9%)	
11/07 08:02:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7433 (2.7596)	Arch Loss 2.9740 (2.8563)	Arch Hard Loss 2.9738 (2.8561)	Arch Alpha Loss 0.0044 (0.0054)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.8%, 60.8%)	
11/07 08:03:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.5590 (2.7522)	Arch Loss 2.7472 (2.8421)	Arch Hard Loss 2.7470 (2.8418)	Arch Alpha Loss 0.0050 (0.0053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.1%, 61.1%)	
11/07 08:03:03午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 29.0680%
11/07 08:03:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.7970	Prec@(1,5) (28.7%, 60.5%)
11/07 08:03:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.8012	Prec@(1,5) (28.3%, 60.5%)
11/07 08:03:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.8101	Prec@(1,5) (28.3%, 60.2%)
11/07 08:03:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.8115	Prec@(1,5) (28.3%, 60.2%)
11/07 08:03:20午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 28.3520%
11/07 08:03:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:03:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.3520%
11/07 08:03:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.7441 (2.6611)	Arch Loss 2.8818 (2.7871)	Arch Hard Loss 2.8815 (2.7868)	Arch Alpha Loss 0.0055 (0.0056)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.6%, 64.4%)	
11/07 08:04:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.4638 (2.6648)	Arch Loss 2.6580 (2.7708)	Arch Hard Loss 2.6577 (2.7704)	Arch Alpha Loss 0.0051 (0.0053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.8%)	
11/07 08:04:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.3626 (2.6486)	Arch Loss 2.7347 (2.7521)	Arch Hard Loss 2.7344 (2.7518)	Arch Alpha Loss 0.0052 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 64.2%)	
11/07 08:05:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.9672 (2.6378)	Arch Loss 2.7534 (2.7458)	Arch Hard Loss 2.7531 (2.7455)	Arch Alpha Loss 0.0047 (0.0050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.2%)	
11/07 08:05:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 31.7760%
11/07 08:05:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.7963	Prec@(1,5) (29.3%, 60.9%)
11/07 08:05:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.7875	Prec@(1,5) (29.8%, 60.7%)
11/07 08:05:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.7834	Prec@(1,5) (29.9%, 60.9%)
11/07 08:05:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.7771	Prec@(1,5) (30.1%, 61.0%)
11/07 08:05:28午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 30.0840%
11/07 08:05:28午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:05:29午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.0840%
11/07 08:05:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 3.0593 (2.5502)	Arch Loss 2.9462 (2.6963)	Arch Hard Loss 2.9458 (2.6959)	Arch Alpha Loss 0.0053 (0.0053)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.1%)	
11/07 08:06:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.6455 (2.5463)	Arch Loss 2.3362 (2.6899)	Arch Hard Loss 2.3358 (2.6895)	Arch Alpha Loss 0.0045 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.5%, 66.3%)	
11/07 08:06:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.2583 (2.5451)	Arch Loss 2.4475 (2.6752)	Arch Hard Loss 2.4471 (2.6748)	Arch Alpha Loss 0.0045 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.5%, 66.3%)	
11/07 08:07:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.9197 (2.5300)	Arch Loss 2.4159 (2.6716)	Arch Hard Loss 2.4156 (2.6712)	Arch Alpha Loss 0.0041 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.5%)	
11/07 08:07:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 33.8960%
11/07 08:07:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.7498	Prec@(1,5) (30.3%, 62.5%)
11/07 08:07:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.7566	Prec@(1,5) (30.7%, 62.1%)
11/07 08:07:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.7566	Prec@(1,5) (30.6%, 62.1%)
11/07 08:07:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.7558	Prec@(1,5) (30.5%, 62.2%)
11/07 08:07:38午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 30.5320%
11/07 08:07:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:07:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.5320%
11/07 08:08:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.6856 (2.3899)	Arch Loss 2.5641 (2.6049)	Arch Hard Loss 2.5637 (2.6044)	Arch Alpha Loss 0.0043 (0.0051)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.2%, 69.2%)	
11/07 08:08:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.3241 (2.4008)	Arch Loss 2.4184 (2.5948)	Arch Hard Loss 2.4180 (2.5944)	Arch Alpha Loss 0.0041 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.6%, 69.2%)	
11/07 08:09:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.1829 (2.4173)	Arch Loss 2.6906 (2.5841)	Arch Hard Loss 2.6902 (2.5836)	Arch Alpha Loss 0.0042 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.0%, 68.8%)	
11/07 08:09:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.3694 (2.4283)	Arch Loss 2.6338 (2.5820)	Arch Hard Loss 2.6334 (2.5815)	Arch Alpha Loss 0.0042 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.8%, 68.6%)	
11/07 08:09:31午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 35.7880%
11/07 08:09:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.6235	Prec@(1,5) (33.0%, 64.4%)
11/07 08:09:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.6250	Prec@(1,5) (33.3%, 64.8%)
11/07 08:09:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.6237	Prec@(1,5) (33.3%, 64.9%)
11/07 08:09:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.6246	Prec@(1,5) (33.3%, 64.8%)
11/07 08:09:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 33.2640%
11/07 08:09:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:09:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.2640%
11/07 08:10:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.6808 (2.3584)	Arch Loss 2.6722 (2.5555)	Arch Hard Loss 2.6717 (2.5549)	Arch Alpha Loss 0.0045 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 70.8%)	
11/07 08:10:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.0508 (2.3529)	Arch Loss 2.4024 (2.5319)	Arch Hard Loss 2.4019 (2.5314)	Arch Alpha Loss 0.0044 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 71.2%)	
11/07 08:11:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.4137 (2.3528)	Arch Loss 2.3167 (2.5297)	Arch Hard Loss 2.3163 (2.5291)	Arch Alpha Loss 0.0040 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 70.6%)	
11/07 08:11:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.3487 (2.3417)	Arch Loss 2.1581 (2.5150)	Arch Hard Loss 2.1575 (2.5145)	Arch Alpha Loss 0.0048 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 70.7%)	
11/07 08:11:42午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 37.9280%
11/07 08:11:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.5560	Prec@(1,5) (33.8%, 66.5%)
11/07 08:11:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.5354	Prec@(1,5) (34.6%, 67.1%)
11/07 08:11:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.5405	Prec@(1,5) (34.5%, 66.9%)
11/07 08:11:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.5355	Prec@(1,5) (34.6%, 67.0%)
11/07 08:11:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 34.6360%
11/07 08:11:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:11:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.6360%
11/07 08:12:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.3119 (2.2440)	Arch Loss 2.6270 (2.4557)	Arch Hard Loss 2.6264 (2.4551)	Arch Alpha Loss 0.0046 (0.0049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.8%, 72.1%)	
11/07 08:12:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.0273 (2.2550)	Arch Loss 2.8011 (2.4736)	Arch Hard Loss 2.8005 (2.4730)	Arch Alpha Loss 0.0044 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 72.1%)	
11/07 08:13:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.0031 (2.2547)	Arch Loss 2.7134 (2.4636)	Arch Hard Loss 2.7129 (2.4629)	Arch Alpha Loss 0.0037 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.3%)	
11/07 08:13:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.4300 (2.2590)	Arch Loss 2.6512 (2.4582)	Arch Hard Loss 2.6506 (2.4576)	Arch Alpha Loss 0.0040 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 72.1%)	
11/07 08:13:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 39.5800%
11/07 08:13:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3875	Prec@(1,5) (37.6%, 69.9%)
11/07 08:14:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.3841	Prec@(1,5) (37.4%, 69.8%)
11/07 08:14:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.3808	Prec@(1,5) (37.6%, 69.9%)
11/07 08:14:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.3856	Prec@(1,5) (37.5%, 69.9%)
11/07 08:14:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 37.5240%
11/07 08:14:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:14:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.5240%
11/07 08:14:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1220 (2.1454)	Arch Loss 2.8012 (2.4350)	Arch Hard Loss 2.8005 (2.4342)	Arch Alpha Loss 0.0046 (0.0047)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.3%, 75.0%)	
11/07 08:15:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.2308 (2.1713)	Arch Loss 2.0066 (2.4222)	Arch Hard Loss 2.0060 (2.4215)	Arch Alpha Loss 0.0037 (0.0046)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.0%)	
11/07 08:15:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.7915 (2.1846)	Arch Loss 2.5544 (2.4115)	Arch Hard Loss 2.5536 (2.4108)	Arch Alpha Loss 0.0045 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 73.9%)	
11/07 08:16:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.4757 (2.1876)	Arch Loss 2.7342 (2.4038)	Arch Hard Loss 2.7336 (2.4031)	Arch Alpha Loss 0.0038 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 73.9%)	
11/07 08:16:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 41.5440%
11/07 08:16:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.4136	Prec@(1,5) (37.6%, 69.5%)
11/07 08:16:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.4180	Prec@(1,5) (37.2%, 69.2%)
11/07 08:16:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.4268	Prec@(1,5) (37.3%, 68.8%)
11/07 08:16:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.4248	Prec@(1,5) (37.4%, 68.9%)
11/07 08:16:17午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 37.4520%
11/07 08:16:17午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:16:17午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.5240%
11/07 08:16:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.7369 (2.0538)	Arch Loss 2.1711 (2.3184)	Arch Hard Loss 2.1702 (2.3176)	Arch Alpha Loss 0.0045 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 76.5%)	
11/07 08:17:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8888 (2.0781)	Arch Loss 2.5136 (2.3357)	Arch Hard Loss 2.5127 (2.3349)	Arch Alpha Loss 0.0050 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 75.9%)	
11/07 08:17:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.2974 (2.0914)	Arch Loss 2.4068 (2.3350)	Arch Hard Loss 2.4059 (2.3342)	Arch Alpha Loss 0.0047 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.7%)	
11/07 08:18:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.5605 (2.1046)	Arch Loss 2.4140 (2.3428)	Arch Hard Loss 2.4133 (2.3420)	Arch Alpha Loss 0.0039 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.5%)	
11/07 08:18:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 43.0080%
11/07 08:18:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.3697	Prec@(1,5) (38.2%, 70.6%)
11/07 08:18:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.3881	Prec@(1,5) (37.9%, 70.0%)
11/07 08:18:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.3871	Prec@(1,5) (38.1%, 70.1%)
11/07 08:18:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.3775	Prec@(1,5) (37.9%, 70.2%)
11/07 08:18:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 37.9200%
11/07 08:18:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:18:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.9200%
11/07 08:18:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.9270 (2.0039)	Arch Loss 1.8543 (2.3066)	Arch Hard Loss 1.8533 (2.3057)	Arch Alpha Loss 0.0049 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.6%)	
11/07 08:19:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.1577 (2.0085)	Arch Loss 2.4487 (2.3134)	Arch Hard Loss 2.4478 (2.3125)	Arch Alpha Loss 0.0044 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.4%)	
11/07 08:19:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0462 (2.0267)	Arch Loss 2.1999 (2.3023)	Arch Hard Loss 2.1990 (2.3015)	Arch Alpha Loss 0.0044 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.0%)	
11/07 08:20:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.0836 (2.0233)	Arch Loss 1.9912 (2.2954)	Arch Hard Loss 1.9903 (2.2945)	Arch Alpha Loss 0.0042 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.0%)	
11/07 08:20:20午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 44.5520%
11/07 08:20:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.2944	Prec@(1,5) (39.8%, 72.5%)
11/07 08:20:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.2997	Prec@(1,5) (39.8%, 72.5%)
11/07 08:20:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.2935	Prec@(1,5) (40.0%, 72.6%)
11/07 08:20:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.3101	Prec@(1,5) (39.9%, 72.3%)
11/07 08:20:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 39.8640%
11/07 08:20:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:20:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8640%
11/07 08:21:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.8497 (1.9516)	Arch Loss 2.3766 (2.3136)	Arch Hard Loss 2.3757 (2.3126)	Arch Alpha Loss 0.0038 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.9%)	
11/07 08:21:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.0418 (1.9597)	Arch Loss 2.2124 (2.2704)	Arch Hard Loss 2.2115 (2.2693)	Arch Alpha Loss 0.0037 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.5%)	
11/07 08:22:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.6687 (1.9579)	Arch Loss 2.2022 (2.2632)	Arch Hard Loss 2.2012 (2.2622)	Arch Alpha Loss 0.0043 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.5%)	
11/07 08:22:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.1465 (1.9623)	Arch Loss 2.1640 (2.2507)	Arch Hard Loss 2.1632 (2.2497)	Arch Alpha Loss 0.0035 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.4%)	
11/07 08:22:31午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 46.3120%
11/07 08:22:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.2733	Prec@(1,5) (40.6%, 72.0%)
11/07 08:22:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.2733	Prec@(1,5) (40.9%, 72.5%)
11/07 08:22:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.2826	Prec@(1,5) (40.4%, 72.1%)
11/07 08:22:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.2677	Prec@(1,5) (40.7%, 72.5%)
11/07 08:22:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 40.7400%
11/07 08:22:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:22:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.7400%
11/07 08:23:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.8020 (1.8543)	Arch Loss 2.4638 (2.1944)	Arch Hard Loss 2.4626 (2.1933)	Arch Alpha Loss 0.0048 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.4%)	
11/07 08:23:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.0253 (1.8525)	Arch Loss 2.1168 (2.2011)	Arch Hard Loss 2.1156 (2.2000)	Arch Alpha Loss 0.0046 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.4%)	
11/07 08:24:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.8423 (1.8762)	Arch Loss 2.2018 (2.2023)	Arch Hard Loss 2.2009 (2.2012)	Arch Alpha Loss 0.0038 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 79.7%)	
11/07 08:24:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.9355 (1.8916)	Arch Loss 2.3883 (2.1991)	Arch Hard Loss 2.3873 (2.1980)	Arch Alpha Loss 0.0039 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.4%)	
11/07 08:24:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 48.1200%
11/07 08:24:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.1689	Prec@(1,5) (41.8%, 74.8%)
11/07 08:24:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.1792	Prec@(1,5) (41.9%, 74.4%)
11/07 08:24:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.1840	Prec@(1,5) (42.0%, 74.1%)
11/07 08:24:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.1842	Prec@(1,5) (42.2%, 74.1%)
11/07 08:24:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 42.1520%
11/07 08:24:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:24:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.1520%
11/07 08:25:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.9939 (1.7503)	Arch Loss 2.7322 (2.2183)	Arch Hard Loss 2.7309 (2.2170)	Arch Alpha Loss 0.0044 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.7%)	
11/07 08:25:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.0685 (1.7930)	Arch Loss 1.9487 (2.1922)	Arch Hard Loss 1.9475 (2.1909)	Arch Alpha Loss 0.0042 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 82.1%)	
11/07 08:26:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.2122 (1.8199)	Arch Loss 1.7776 (2.1880)	Arch Hard Loss 1.7765 (2.1868)	Arch Alpha Loss 0.0037 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 81.4%)	
11/07 08:26:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.4083 (1.8274)	Arch Loss 2.5910 (2.1788)	Arch Hard Loss 2.5898 (2.1776)	Arch Alpha Loss 0.0042 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 81.3%)	
11/07 08:26:51午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 49.1240%
11/07 08:26:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1269	Prec@(1,5) (43.4%, 75.5%)
11/07 08:26:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1023	Prec@(1,5) (44.2%, 76.1%)
11/07 08:27:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1261	Prec@(1,5) (43.8%, 75.5%)
11/07 08:27:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1162	Prec@(1,5) (44.2%, 75.4%)
11/07 08:27:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 44.2120%
11/07 08:27:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:27:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.2120%
11/07 08:27:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.5749 (1.7394)	Arch Loss 2.0614 (2.1505)	Arch Hard Loss 2.0599 (2.1492)	Arch Alpha Loss 0.0046 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.6%)	
11/07 08:28:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 2.1059 (1.7334)	Arch Loss 2.3473 (2.1393)	Arch Hard Loss 2.3461 (2.1380)	Arch Alpha Loss 0.0038 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.7%)	
11/07 08:28:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.5795 (1.7481)	Arch Loss 2.0973 (2.1408)	Arch Hard Loss 2.0961 (2.1396)	Arch Alpha Loss 0.0037 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.4%)	
11/07 08:28:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.6057 (1.7698)	Arch Loss 1.9098 (2.1508)	Arch Hard Loss 1.9085 (2.1495)	Arch Alpha Loss 0.0043 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.0%)	
11/07 08:29:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 50.6800%
11/07 08:29:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.1681	Prec@(1,5) (42.7%, 75.6%)
11/07 08:29:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.1575	Prec@(1,5) (43.1%, 75.5%)
11/07 08:29:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.1521	Prec@(1,5) (43.3%, 75.5%)
11/07 08:29:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.1523	Prec@(1,5) (43.4%, 75.4%)
11/07 08:29:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 43.3720%
11/07 08:29:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:29:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.2120%
11/07 08:29:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.9854 (1.6703)	Arch Loss 2.2393 (2.1572)	Arch Hard Loss 2.2378 (2.1557)	Arch Alpha Loss 0.0043 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.1%)	
11/07 08:30:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5162 (1.6993)	Arch Loss 1.8688 (2.1293)	Arch Hard Loss 1.8673 (2.1279)	Arch Alpha Loss 0.0043 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.2%, 82.7%)	
11/07 08:30:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.6707 (1.7070)	Arch Loss 2.1236 (2.1130)	Arch Hard Loss 2.1223 (2.1116)	Arch Alpha Loss 0.0037 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.8%)	
11/07 08:31:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.4128 (1.7180)	Arch Loss 1.6745 (2.1088)	Arch Hard Loss 1.6735 (2.1074)	Arch Alpha Loss 0.0031 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.6%)	
11/07 08:31:10午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 51.7200%
11/07 08:31:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0893	Prec@(1,5) (44.6%, 76.0%)
11/07 08:31:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0845	Prec@(1,5) (44.8%, 76.0%)
11/07 08:31:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0808	Prec@(1,5) (44.9%, 76.1%)
11/07 08:31:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0761	Prec@(1,5) (44.9%, 76.3%)
11/07 08:31:27午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 44.8920%
11/07 08:31:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:31:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.8920%
11/07 08:31:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.2748 (1.5777)	Arch Loss 2.3989 (2.0640)	Arch Hard Loss 2.3970 (2.0624)	Arch Alpha Loss 0.0049 (0.0043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.2%)	
11/07 08:32:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.9864 (1.6180)	Arch Loss 1.6571 (2.0591)	Arch Hard Loss 1.6557 (2.0576)	Arch Alpha Loss 0.0035 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.5%)	
11/07 08:32:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.6087 (1.6424)	Arch Loss 1.9595 (2.0771)	Arch Hard Loss 1.9578 (2.0755)	Arch Alpha Loss 0.0044 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.1%)	
11/07 08:33:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.6971 (1.6544)	Arch Loss 1.9414 (2.0702)	Arch Hard Loss 1.9398 (2.0686)	Arch Alpha Loss 0.0043 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.0%)	
11/07 08:33:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 53.5920%
11/07 08:33:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.0318	Prec@(1,5) (45.9%, 77.8%)
11/07 08:33:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.0439	Prec@(1,5) (45.7%, 77.5%)
11/07 08:33:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.0414	Prec@(1,5) (45.9%, 77.3%)
11/07 08:33:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.0494	Prec@(1,5) (45.8%, 77.1%)
11/07 08:33:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 45.8160%
11/07 08:33:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:33:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.8160%
11/07 08:34:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.5359 (1.5456)	Arch Loss 2.1769 (2.0454)	Arch Hard Loss 2.1752 (2.0437)	Arch Alpha Loss 0.0043 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.7%)	
11/07 08:34:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.9876 (1.5701)	Arch Loss 2.3752 (2.0450)	Arch Hard Loss 2.3734 (2.0434)	Arch Alpha Loss 0.0043 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 85.3%)	
11/07 08:35:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4816 (1.5787)	Arch Loss 2.0134 (2.0444)	Arch Hard Loss 2.0117 (2.0428)	Arch Alpha Loss 0.0043 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.0%)	
11/07 08:35:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.5049 (1.5925)	Arch Loss 2.0100 (2.0510)	Arch Hard Loss 2.0083 (2.0494)	Arch Alpha Loss 0.0042 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.9%, 84.7%)	
11/07 08:35:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 54.8800%
11/07 08:35:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.0854	Prec@(1,5) (45.3%, 76.7%)
11/07 08:35:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.0908	Prec@(1,5) (45.1%, 76.4%)
11/07 08:35:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.1059	Prec@(1,5) (44.7%, 76.1%)
11/07 08:35:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.1017	Prec@(1,5) (44.7%, 76.1%)
11/07 08:35:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 44.7600%
11/07 08:35:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:35:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.8160%
11/07 08:36:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.1163 (1.5154)	Arch Loss 1.6478 (2.0574)	Arch Hard Loss 1.6461 (2.0556)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.9%)	
11/07 08:36:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.9773 (1.5300)	Arch Loss 2.0051 (2.0457)	Arch Hard Loss 2.0036 (2.0439)	Arch Alpha Loss 0.0032 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.8%)	
11/07 08:37:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.4511 (1.5491)	Arch Loss 2.4106 (2.0555)	Arch Hard Loss 2.4095 (2.0538)	Arch Alpha Loss 0.0025 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.4%)	
11/07 08:37:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.2649 (1.5474)	Arch Loss 2.1833 (2.0406)	Arch Hard Loss 2.1819 (2.0388)	Arch Alpha Loss 0.0034 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.6%)	
11/07 08:37:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 55.9000%
11/07 08:37:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.0175	Prec@(1,5) (47.6%, 77.9%)
11/07 08:37:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.0027	Prec@(1,5) (47.6%, 78.2%)
11/07 08:37:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9925	Prec@(1,5) (47.4%, 78.3%)
11/07 08:37:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9938	Prec@(1,5) (47.4%, 78.2%)
11/07 08:37:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 47.4200%
11/07 08:37:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:37:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.4200%
11/07 08:38:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.4799 (1.4234)	Arch Loss 1.8409 (2.0411)	Arch Hard Loss 1.8388 (2.0393)	Arch Alpha Loss 0.0046 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.9%)	
11/07 08:38:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 0.9546 (1.4555)	Arch Loss 2.4017 (2.0343)	Arch Hard Loss 2.3999 (2.0324)	Arch Alpha Loss 0.0038 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.5%)	
11/07 08:39:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.5325 (1.4815)	Arch Loss 1.9995 (2.0309)	Arch Hard Loss 1.9977 (2.0290)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.9%)	
11/07 08:39:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.3516 (1.4954)	Arch Loss 1.9428 (2.0294)	Arch Hard Loss 1.9412 (2.0275)	Arch Alpha Loss 0.0034 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.6%)	
11/07 08:39:51午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 57.3480%
11/07 08:39:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.0853	Prec@(1,5) (45.5%, 77.2%)
11/07 08:40:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.0813	Prec@(1,5) (45.6%, 77.0%)
11/07 08:40:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.0835	Prec@(1,5) (45.4%, 76.9%)
11/07 08:40:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.0895	Prec@(1,5) (45.3%, 76.9%)
11/07 08:40:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 45.3440%
11/07 08:40:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:40:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.4200%
11/07 08:40:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3561 (1.4013)	Arch Loss 2.1804 (2.0321)	Arch Hard Loss 2.1784 (2.0301)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.1%)	
11/07 08:41:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.6363 (1.4094)	Arch Loss 2.0003 (2.0358)	Arch Hard Loss 1.9982 (2.0337)	Arch Alpha Loss 0.0041 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 87.9%)	
11/07 08:41:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.5624 (1.4327)	Arch Loss 2.1348 (2.0156)	Arch Hard Loss 2.1331 (2.0136)	Arch Alpha Loss 0.0036 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.4%)	
11/07 08:42:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.3258 (1.4378)	Arch Loss 2.0406 (2.0118)	Arch Hard Loss 2.0387 (2.0098)	Arch Alpha Loss 0.0037 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.3%)	
11/07 08:42:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 58.9280%
11/07 08:42:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9141	Prec@(1,5) (49.2%, 79.2%)
11/07 08:42:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9505	Prec@(1,5) (48.5%, 79.0%)
11/07 08:42:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.9309	Prec@(1,5) (48.9%, 79.3%)
11/07 08:42:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9392	Prec@(1,5) (48.5%, 79.2%)
11/07 08:42:17午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 48.5400%
11/07 08:42:17午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:42:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5400%
11/07 08:42:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5285 (1.3194)	Arch Loss 2.0064 (1.9835)	Arch Hard Loss 2.0043 (1.9813)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.2%)	
11/07 08:43:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.4013 (1.3470)	Arch Loss 1.4251 (1.9704)	Arch Hard Loss 1.4228 (1.9682)	Arch Alpha Loss 0.0043 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.9%)	
11/07 08:43:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2292 (1.3647)	Arch Loss 2.2782 (1.9733)	Arch Hard Loss 2.2760 (1.9712)	Arch Alpha Loss 0.0041 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.5%)	
11/07 08:44:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.5378 (1.3834)	Arch Loss 1.9272 (1.9817)	Arch Hard Loss 1.9251 (1.9796)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.2%)	
11/07 08:44:09午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 60.1880%
11/07 08:44:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8987	Prec@(1,5) (49.2%, 80.1%)
11/07 08:44:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.9013	Prec@(1,5) (49.7%, 79.8%)
11/07 08:44:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.9102	Prec@(1,5) (49.6%, 79.7%)
11/07 08:44:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9115	Prec@(1,5) (49.5%, 79.6%)
11/07 08:44:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 49.5520%
11/07 08:44:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:44:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.5520%
11/07 08:44:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.3277 (1.2702)	Arch Loss 2.1060 (1.9341)	Arch Hard Loss 2.1038 (1.9318)	Arch Alpha Loss 0.0039 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.6%)	
11/07 08:45:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.1695 (1.2900)	Arch Loss 1.9318 (1.9678)	Arch Hard Loss 1.9298 (1.9655)	Arch Alpha Loss 0.0036 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.4%)	
11/07 08:45:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.7828 (1.3089)	Arch Loss 1.8951 (1.9845)	Arch Hard Loss 1.8929 (1.9822)	Arch Alpha Loss 0.0039 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.1%)	
11/07 08:46:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.5544 (1.3270)	Arch Loss 1.8840 (1.9843)	Arch Hard Loss 1.8819 (1.9820)	Arch Alpha Loss 0.0037 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.9%)	
11/07 08:46:19午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 61.6720%
11/07 08:46:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.9825	Prec@(1,5) (49.2%, 79.6%)
11/07 08:46:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.9903	Prec@(1,5) (48.7%, 79.3%)
11/07 08:46:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.0005	Prec@(1,5) (48.5%, 78.9%)
11/07 08:46:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.0031	Prec@(1,5) (48.5%, 79.0%)
11/07 08:46:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 48.5160%
11/07 08:46:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:46:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.5520%
11/07 08:47:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.3963 (1.2312)	Arch Loss 2.1491 (1.9348)	Arch Hard Loss 2.1464 (1.9324)	Arch Alpha Loss 0.0046 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.2%)	
11/07 08:47:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.0714 (1.2467)	Arch Loss 1.9374 (1.9534)	Arch Hard Loss 1.9346 (1.9510)	Arch Alpha Loss 0.0046 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.0%)	
11/07 08:48:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.0953 (1.2695)	Arch Loss 1.5386 (1.9595)	Arch Hard Loss 1.5359 (1.9572)	Arch Alpha Loss 0.0045 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.7%)	
11/07 08:48:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.0634 (1.2810)	Arch Loss 1.9515 (1.9671)	Arch Hard Loss 1.9492 (1.9648)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.7%)	
11/07 08:48:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 62.5720%
11/07 08:48:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9959	Prec@(1,5) (48.3%, 78.7%)
11/07 08:48:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.9846	Prec@(1,5) (48.8%, 78.9%)
11/07 08:48:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.9611	Prec@(1,5) (49.4%, 79.2%)
11/07 08:48:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.9611	Prec@(1,5) (49.2%, 79.3%)
11/07 08:48:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 49.1840%
11/07 08:48:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:48:45午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.5520%
11/07 08:49:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.3868 (1.1720)	Arch Loss 2.1965 (1.9207)	Arch Hard Loss 2.1940 (1.9181)	Arch Alpha Loss 0.0041 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.5%)	
11/07 08:49:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.3008 (1.1998)	Arch Loss 1.0908 (1.9609)	Arch Hard Loss 1.0886 (1.9584)	Arch Alpha Loss 0.0035 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 91.1%)	
11/07 08:50:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.2689 (1.2192)	Arch Loss 1.7488 (1.9661)	Arch Hard Loss 1.7466 (1.9636)	Arch Alpha Loss 0.0035 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.7%)	
11/07 08:50:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.2829 (1.2310)	Arch Loss 2.2579 (1.9626)	Arch Hard Loss 2.2559 (1.9602)	Arch Alpha Loss 0.0032 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.5%)	
11/07 08:50:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 63.9280%
11/07 08:50:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.9017	Prec@(1,5) (50.2%, 80.5%)
11/07 08:50:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.9071	Prec@(1,5) (50.1%, 80.3%)
11/07 08:50:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.9020	Prec@(1,5) (50.4%, 80.4%)
11/07 08:50:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8907	Prec@(1,5) (50.7%, 80.6%)
11/07 08:50:55午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 50.7200%
11/07 08:50:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:50:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7200%
11/07 08:51:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.8892 (1.1405)	Arch Loss 2.3242 (1.9883)	Arch Hard Loss 2.3214 (1.9857)	Arch Alpha Loss 0.0042 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.3%)	
11/07 08:51:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9565 (1.1581)	Arch Loss 2.1584 (1.9655)	Arch Hard Loss 2.1559 (1.9629)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.3%)	
11/07 08:52:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1840 (1.1645)	Arch Loss 2.5143 (1.9565)	Arch Hard Loss 2.5118 (1.9539)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.2%)	
11/07 08:52:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 0.9370 (1.1737)	Arch Loss 1.8324 (1.9658)	Arch Hard Loss 1.8296 (1.9632)	Arch Alpha Loss 0.0044 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.0%)	
11/07 08:52:48午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 65.7080%
11/07 08:52:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.9088	Prec@(1,5) (50.7%, 80.6%)
11/07 08:52:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.9215	Prec@(1,5) (50.3%, 80.2%)
11/07 08:53:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.9220	Prec@(1,5) (50.6%, 80.0%)
11/07 08:53:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.9202	Prec@(1,5) (50.4%, 80.0%)
11/07 08:53:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 50.3880%
11/07 08:53:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:53:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7200%
11/07 08:53:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.1074 (1.0593)	Arch Loss 2.5804 (1.9741)	Arch Hard Loss 2.5780 (1.9714)	Arch Alpha Loss 0.0036 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.6%)	
11/07 08:54:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.3209 (1.0990)	Arch Loss 2.0175 (1.9862)	Arch Hard Loss 2.0152 (1.9835)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.2%)	
11/07 08:54:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 0.9540 (1.1239)	Arch Loss 2.2019 (1.9826)	Arch Hard Loss 2.1993 (1.9799)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.9%)	
11/07 08:54:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3807 (1.1369)	Arch Loss 2.1358 (1.9676)	Arch Hard Loss 2.1333 (1.9650)	Arch Alpha Loss 0.0037 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.8%)	
11/07 08:54:55午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 66.4000%
11/07 08:55:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.9462	Prec@(1,5) (50.4%, 80.2%)
11/07 08:55:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.9360	Prec@(1,5) (50.5%, 80.2%)
11/07 08:55:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.9228	Prec@(1,5) (50.8%, 80.3%)
11/07 08:55:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.9234	Prec@(1,5) (50.6%, 80.3%)
11/07 08:55:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 50.5640%
11/07 08:55:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:55:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7200%
11/07 08:55:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.9641 (1.0001)	Arch Loss 2.0597 (1.9655)	Arch Hard Loss 2.0567 (1.9627)	Arch Alpha Loss 0.0042 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.5%)	
11/07 08:56:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.2039 (1.0333)	Arch Loss 1.8113 (1.9721)	Arch Hard Loss 1.8088 (1.9693)	Arch Alpha Loss 0.0035 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.2%)	
11/07 08:56:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.3740 (1.0545)	Arch Loss 1.8910 (1.9613)	Arch Hard Loss 1.8882 (1.9585)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.8%)	
11/07 08:57:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.2578 (1.0699)	Arch Loss 1.5915 (1.9593)	Arch Hard Loss 1.5892 (1.9566)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.5%)	
11/07 08:57:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 68.5720%
11/07 08:57:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.9489	Prec@(1,5) (50.0%, 80.7%)
11/07 08:57:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.9565	Prec@(1,5) (50.2%, 80.4%)
11/07 08:57:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.9557	Prec@(1,5) (50.1%, 80.3%)
11/07 08:57:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.9492	Prec@(1,5) (50.5%, 80.2%)
11/07 08:57:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 50.5320%
11/07 08:57:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:57:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7200%
11/07 08:57:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8042 (0.9962)	Arch Loss 2.3004 (1.9041)	Arch Hard Loss 2.2974 (1.9012)	Arch Alpha Loss 0.0040 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.5%)	
11/07 08:58:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.9407 (0.9951)	Arch Loss 2.1391 (1.9291)	Arch Hard Loss 2.1364 (1.9263)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.6%)	
11/07 08:58:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.9054 (1.0055)	Arch Loss 1.5071 (1.9407)	Arch Hard Loss 1.5044 (1.9379)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.4%)	
11/07 08:59:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.0039 (1.0231)	Arch Loss 2.4549 (1.9660)	Arch Hard Loss 2.4517 (1.9632)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.1%)	
11/07 08:59:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 69.6240%
11/07 08:59:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.9866	Prec@(1,5) (50.7%, 80.0%)
11/07 08:59:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.9732	Prec@(1,5) (50.7%, 80.1%)
11/07 08:59:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.9550	Prec@(1,5) (50.9%, 80.3%)
11/07 08:59:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.9474	Prec@(1,5) (51.1%, 80.5%)
11/07 08:59:32午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 51.0680%
11/07 08:59:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 08:59:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0680%
11/07 09:00:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.9822 (0.9281)	Arch Loss 2.1445 (1.9514)	Arch Hard Loss 2.1416 (1.9484)	Arch Alpha Loss 0.0037 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.3%)	
11/07 09:00:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.9400 (0.9403)	Arch Loss 1.6642 (1.9601)	Arch Hard Loss 1.6613 (1.9572)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.2%)	
11/07 09:00:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1582 (0.9485)	Arch Loss 2.2446 (1.9737)	Arch Hard Loss 2.2415 (1.9709)	Arch Alpha Loss 0.0040 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.1%)	
11/07 09:01:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0775 (0.9610)	Arch Loss 1.9227 (1.9614)	Arch Hard Loss 1.9200 (1.9585)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
11/07 09:01:25午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 71.1280%
11/07 09:01:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.9754	Prec@(1,5) (50.2%, 80.3%)
11/07 09:01:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.9466	Prec@(1,5) (51.3%, 80.6%)
11/07 09:01:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.9324	Prec@(1,5) (51.3%, 80.8%)
11/07 09:01:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.9221	Prec@(1,5) (51.5%, 80.9%)
11/07 09:01:42午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 51.4800%
11/07 09:01:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:01:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4800%
11/07 09:02:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.1010 (0.8842)	Arch Loss 1.7271 (1.9516)	Arch Hard Loss 1.7243 (1.9487)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
11/07 09:02:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9460 (0.8851)	Arch Loss 2.3558 (1.9416)	Arch Hard Loss 2.3527 (1.9386)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.9%)	
11/07 09:03:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.8071 (0.8880)	Arch Loss 1.8211 (1.9427)	Arch Hard Loss 1.8183 (1.9397)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
11/07 09:03:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.9531 (0.9070)	Arch Loss 1.7880 (1.9475)	Arch Hard Loss 1.7852 (1.9446)	Arch Alpha Loss 0.0035 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.5%)	
11/07 09:03:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 72.5560%
11/07 09:03:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.9312	Prec@(1,5) (52.0%, 81.3%)
11/07 09:03:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.9309	Prec@(1,5) (51.6%, 81.1%)
11/07 09:03:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.9207	Prec@(1,5) (51.7%, 81.2%)
11/07 09:03:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.9313	Prec@(1,5) (51.5%, 80.9%)
11/07 09:03:52午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 51.4960%
11/07 09:03:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:03:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4960%
11/07 09:04:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.7954 (0.7961)	Arch Loss 2.4512 (1.9264)	Arch Hard Loss 2.4482 (1.9233)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.6%)	
11/07 09:04:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.6007 (0.8164)	Arch Loss 2.1526 (1.9441)	Arch Hard Loss 2.1490 (1.9410)	Arch Alpha Loss 0.0045 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.3%)	
11/07 09:05:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.0092 (0.8382)	Arch Loss 2.4469 (1.9485)	Arch Hard Loss 2.4433 (1.9454)	Arch Alpha Loss 0.0045 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.1%)	
11/07 09:05:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.6804 (0.8549)	Arch Loss 1.5298 (1.9619)	Arch Hard Loss 1.5263 (1.9588)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 94.9%)	
11/07 09:05:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 74.4240%
11/07 09:05:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.8981	Prec@(1,5) (52.6%, 81.7%)
11/07 09:05:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.9033	Prec@(1,5) (52.6%, 81.7%)
11/07 09:05:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.9336	Prec@(1,5) (52.0%, 81.2%)
11/07 09:06:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.9409	Prec@(1,5) (52.0%, 81.2%)
11/07 09:06:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 52.0400%
11/07 09:06:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:06:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.0400%
11/07 09:06:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.5914 (0.7874)	Arch Loss 2.5524 (1.9661)	Arch Hard Loss 2.5496 (1.9630)	Arch Alpha Loss 0.0033 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.0%, 96.0%)	
11/07 09:07:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.9139 (0.7914)	Arch Loss 1.8403 (1.9511)	Arch Hard Loss 1.8372 (1.9479)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.8%)	
11/07 09:07:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0945 (0.8045)	Arch Loss 2.2803 (1.9619)	Arch Hard Loss 2.2774 (1.9588)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.7%)	
11/07 09:07:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.7031 (0.8132)	Arch Loss 1.6301 (1.9610)	Arch Hard Loss 1.6265 (1.9578)	Arch Alpha Loss 0.0043 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.6%)	
11/07 09:07:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 75.1480%
11/07 09:08:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.9051	Prec@(1,5) (53.2%, 81.7%)
11/07 09:08:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.9150	Prec@(1,5) (52.9%, 81.5%)
11/07 09:08:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.9116	Prec@(1,5) (53.0%, 81.6%)
11/07 09:08:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.9091	Prec@(1,5) (52.9%, 81.6%)
11/07 09:08:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 52.9440%
11/07 09:08:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:08:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.9440%
11/07 09:08:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.7739 (0.7215)	Arch Loss 2.7760 (2.0299)	Arch Hard Loss 2.7728 (2.0265)	Arch Alpha Loss 0.0037 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.8%, 97.0%)	
11/07 09:09:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8240 (0.7370)	Arch Loss 1.2917 (2.0065)	Arch Hard Loss 1.2882 (2.0031)	Arch Alpha Loss 0.0040 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.6%)	
11/07 09:09:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8284 (0.7515)	Arch Loss 2.0000 (1.9695)	Arch Hard Loss 1.9968 (1.9662)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.4%)	
11/07 09:10:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.7807 (0.7654)	Arch Loss 1.6848 (1.9696)	Arch Hard Loss 1.6813 (1.9663)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.5%, 96.2%)	
11/07 09:10:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 76.5120%
11/07 09:10:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9208	Prec@(1,5) (52.8%, 81.5%)
11/07 09:10:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9009	Prec@(1,5) (53.2%, 81.7%)
11/07 09:10:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9154	Prec@(1,5) (53.1%, 81.6%)
11/07 09:10:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9279	Prec@(1,5) (52.8%, 81.4%)
11/07 09:10:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 52.8080%
11/07 09:10:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:10:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.9440%
11/07 09:10:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.7615 (0.6950)	Arch Loss 2.1941 (1.9453)	Arch Hard Loss 2.1909 (1.9419)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
11/07 09:11:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.8821 (0.6990)	Arch Loss 1.6960 (1.9713)	Arch Hard Loss 1.6931 (1.9680)	Arch Alpha Loss 0.0033 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.8%)	
11/07 09:11:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.8535 (0.7073)	Arch Loss 1.9970 (1.9649)	Arch Hard Loss 1.9939 (1.9616)	Arch Alpha Loss 0.0035 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.6%)	
11/07 09:12:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.7701 (0.7106)	Arch Loss 1.8119 (1.9670)	Arch Hard Loss 1.8085 (1.9637)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.7%)	
11/07 09:12:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 78.4120%
11/07 09:12:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.9052	Prec@(1,5) (53.3%, 82.3%)
11/07 09:12:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.8922	Prec@(1,5) (53.4%, 82.1%)
11/07 09:12:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.9121	Prec@(1,5) (53.2%, 81.8%)
11/07 09:12:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.9190	Prec@(1,5) (53.1%, 81.8%)
11/07 09:12:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 53.0680%
11/07 09:12:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:12:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.0680%
11/07 09:13:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6746 (0.6567)	Arch Loss 1.6621 (1.9585)	Arch Hard Loss 1.6582 (1.9550)	Arch Alpha Loss 0.0042 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/07 09:13:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5922 (0.6679)	Arch Loss 1.5907 (1.9712)	Arch Hard Loss 1.5872 (1.9677)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
11/07 09:14:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.7596 (0.6593)	Arch Loss 2.2077 (1.9737)	Arch Hard Loss 2.2042 (1.9702)	Arch Alpha Loss 0.0039 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.0%)	
11/07 09:14:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.6637 (0.6733)	Arch Loss 2.3857 (1.9781)	Arch Hard Loss 2.3817 (1.9747)	Arch Alpha Loss 0.0044 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
11/07 09:14:27午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 79.7440%
11/07 09:14:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9268	Prec@(1,5) (53.1%, 82.2%)
11/07 09:14:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9094	Prec@(1,5) (53.3%, 82.1%)
11/07 09:14:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.9188	Prec@(1,5) (53.3%, 81.8%)
11/07 09:14:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9184	Prec@(1,5) (53.1%, 81.8%)
11/07 09:14:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 53.1480%
11/07 09:14:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:14:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.1480%
11/07 09:15:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7224 (0.6046)	Arch Loss 2.5058 (1.9823)	Arch Hard Loss 2.5028 (1.9787)	Arch Alpha Loss 0.0033 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.4%)	
11/07 09:15:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6694 (0.6279)	Arch Loss 1.6911 (1.9911)	Arch Hard Loss 1.6878 (1.9876)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.4%)	
11/07 09:16:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.7344 (0.6431)	Arch Loss 1.5869 (2.0023)	Arch Hard Loss 1.5834 (1.9987)	Arch Alpha Loss 0.0038 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
11/07 09:16:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7475 (0.6518)	Arch Loss 2.2324 (1.9962)	Arch Hard Loss 2.2286 (1.9927)	Arch Alpha Loss 0.0041 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
11/07 09:16:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 80.2720%
11/07 09:16:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.9129	Prec@(1,5) (53.9%, 81.9%)
11/07 09:16:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.9328	Prec@(1,5) (53.4%, 81.8%)
11/07 09:16:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.9239	Prec@(1,5) (53.3%, 82.0%)
11/07 09:16:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.9224	Prec@(1,5) (53.4%, 81.9%)
11/07 09:16:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 53.4080%
11/07 09:16:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:16:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4080%
11/07 09:17:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6454 (0.5903)	Arch Loss 1.8496 (1.9615)	Arch Hard Loss 1.8460 (1.9578)	Arch Alpha Loss 0.0038 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.3%)	
11/07 09:17:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7531 (0.5823)	Arch Loss 1.8893 (1.9659)	Arch Hard Loss 1.8859 (1.9622)	Arch Alpha Loss 0.0036 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.5%)	
11/07 09:18:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6776 (0.5868)	Arch Loss 1.9727 (1.9724)	Arch Hard Loss 1.9691 (1.9687)	Arch Alpha Loss 0.0039 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.6%)	
11/07 09:18:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.5820 (0.6029)	Arch Loss 1.8128 (1.9709)	Arch Hard Loss 1.8090 (1.9672)	Arch Alpha Loss 0.0040 (0.0039)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.5%)	
11/07 09:18:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 82.0680%
11/07 09:18:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.8851	Prec@(1,5) (53.5%, 82.4%)
11/07 09:18:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.8916	Prec@(1,5) (53.5%, 82.2%)
11/07 09:18:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9007	Prec@(1,5) (53.5%, 82.2%)
11/07 09:19:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.8962	Prec@(1,5) (53.5%, 82.2%)
11/07 09:19:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 53.4960%
11/07 09:19:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:19:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.4960%
11/07 09:19:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.6141 (0.5463)	Arch Loss 2.5003 (1.9830)	Arch Hard Loss 2.4972 (1.9795)	Arch Alpha Loss 0.0032 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.2%)	
11/07 09:20:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.4976 (0.5605)	Arch Loss 1.7065 (1.9800)	Arch Hard Loss 1.7025 (1.9766)	Arch Alpha Loss 0.0042 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.1%)	
11/07 09:20:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5542 (0.5674)	Arch Loss 1.8911 (1.9740)	Arch Hard Loss 1.8879 (1.9705)	Arch Alpha Loss 0.0034 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.0%)	
11/07 09:20:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.4950 (0.5770)	Arch Loss 2.3534 (1.9754)	Arch Hard Loss 2.3502 (1.9720)	Arch Alpha Loss 0.0033 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
11/07 09:20:53午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 82.7600%
11/07 09:20:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.9463	Prec@(1,5) (53.3%, 81.5%)
11/07 09:21:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.9154	Prec@(1,5) (54.0%, 81.9%)
11/07 09:21:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9119	Prec@(1,5) (54.1%, 82.2%)
11/07 09:21:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9255	Prec@(1,5) (53.7%, 81.8%)
11/07 09:21:10午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 53.7440%
11/07 09:21:10午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:21:10午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7440%
11/07 09:21:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.7808 (0.5514)	Arch Loss 2.0674 (1.9633)	Arch Hard Loss 2.0633 (1.9596)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.9%, 97.9%)	
11/07 09:22:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.3902 (0.5547)	Arch Loss 1.5751 (1.9884)	Arch Hard Loss 1.5720 (1.9848)	Arch Alpha Loss 0.0032 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.9%)	
11/07 09:22:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6485 (0.5507)	Arch Loss 1.3702 (1.9973)	Arch Hard Loss 1.3662 (1.9937)	Arch Alpha Loss 0.0042 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.0%)	
11/07 09:23:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.6593 (0.5538)	Arch Loss 1.6361 (1.9894)	Arch Hard Loss 1.6325 (1.9858)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.0%)	
11/07 09:23:03午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 83.5800%
11/07 09:23:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.9220	Prec@(1,5) (53.0%, 82.4%)
11/07 09:23:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.9285	Prec@(1,5) (53.3%, 82.4%)
11/07 09:23:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.9235	Prec@(1,5) (53.7%, 82.3%)
11/07 09:23:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.9285	Prec@(1,5) (53.8%, 82.1%)
11/07 09:23:20午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 53.7640%
11/07 09:23:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:23:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7640%
11/07 09:23:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.3513 (0.5207)	Arch Loss 2.1573 (1.9861)	Arch Hard Loss 2.1535 (1.9825)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.1%)	
11/07 09:24:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5217 (0.5225)	Arch Loss 1.6249 (1.9993)	Arch Hard Loss 1.6214 (1.9958)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.1%)	
11/07 09:24:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6035 (0.5321)	Arch Loss 2.3147 (1.9929)	Arch Hard Loss 2.3109 (1.9893)	Arch Alpha Loss 0.0038 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.1%)	
11/07 09:25:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6472 (0.5360)	Arch Loss 2.0163 (1.9828)	Arch Hard Loss 2.0130 (1.9792)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.1%)	
11/07 09:25:14午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 84.3800%
11/07 09:25:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.9539	Prec@(1,5) (53.5%, 81.6%)
11/07 09:25:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.9441	Prec@(1,5) (53.4%, 81.8%)
11/07 09:25:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.9235	Prec@(1,5) (53.9%, 82.2%)
11/07 09:25:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9293	Prec@(1,5) (53.9%, 82.0%)
11/07 09:25:30午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 53.9120%
11/07 09:25:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:25:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.9120%
11/07 09:26:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.4209 (0.4983)	Arch Loss 2.0901 (1.9309)	Arch Hard Loss 2.0861 (1.9272)	Arch Alpha Loss 0.0040 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.3%)	
11/07 09:26:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5102 (0.5094)	Arch Loss 1.8751 (1.9721)	Arch Hard Loss 1.8719 (1.9684)	Arch Alpha Loss 0.0032 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.4%)	
11/07 09:26:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5809 (0.5126)	Arch Loss 1.9520 (1.9799)	Arch Hard Loss 1.9489 (1.9763)	Arch Alpha Loss 0.0032 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
11/07 09:27:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.4278 (0.5138)	Arch Loss 2.4573 (1.9855)	Arch Hard Loss 2.4539 (1.9819)	Arch Alpha Loss 0.0034 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.3%)	
11/07 09:27:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 84.8560%
11/07 09:27:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.9341	Prec@(1,5) (54.3%, 82.0%)
11/07 09:27:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.9255	Prec@(1,5) (54.1%, 82.1%)
11/07 09:27:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.9208	Prec@(1,5) (54.4%, 82.2%)
11/07 09:27:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.9273	Prec@(1,5) (54.3%, 82.1%)
11/07 09:27:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 54.2760%
11/07 09:27:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:27:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.2760%
11/07 09:28:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.6219 (0.5004)	Arch Loss 1.7614 (1.9863)	Arch Hard Loss 1.7575 (1.9827)	Arch Alpha Loss 0.0039 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
11/07 09:28:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5419 (0.5100)	Arch Loss 2.1091 (1.9884)	Arch Hard Loss 2.1055 (1.9847)	Arch Alpha Loss 0.0037 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
11/07 09:29:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.7315 (0.5104)	Arch Loss 2.2299 (1.9882)	Arch Hard Loss 2.2264 (1.9845)	Arch Alpha Loss 0.0035 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.2%)	
11/07 09:29:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.3732 (0.5113)	Arch Loss 2.3421 (1.9815)	Arch Hard Loss 2.3377 (1.9779)	Arch Alpha Loss 0.0044 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.3%)	
11/07 09:29:34午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 84.8200%
11/07 09:29:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.9656	Prec@(1,5) (53.6%, 81.5%)
11/07 09:29:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.9610	Prec@(1,5) (53.1%, 81.8%)
11/07 09:29:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.9373	Prec@(1,5) (53.6%, 82.1%)
11/07 09:29:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.9383	Prec@(1,5) (53.7%, 82.1%)
11/07 09:29:50午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 53.7000%
11/07 09:29:50午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:29:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.2760%
11/07 09:30:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.4668 (0.4734)	Arch Loss 1.2832 (1.9427)	Arch Hard Loss 1.2796 (1.9392)	Arch Alpha Loss 0.0037 (0.0036)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.8%)	
11/07 09:30:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5508 (0.4827)	Arch Loss 2.7321 (1.9796)	Arch Hard Loss 2.7285 (1.9760)	Arch Alpha Loss 0.0036 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.6%)	
11/07 09:31:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3775 (0.4909)	Arch Loss 1.9915 (1.9894)	Arch Hard Loss 1.9879 (1.9857)	Arch Alpha Loss 0.0035 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.5%)	
11/07 09:31:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.5777 (0.4941)	Arch Loss 1.9344 (1.9948)	Arch Hard Loss 1.9301 (1.9911)	Arch Alpha Loss 0.0044 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.5%)	
11/07 09:31:44午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 85.5320%
11/07 09:31:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.9486	Prec@(1,5) (53.9%, 81.6%)
11/07 09:31:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.9493	Prec@(1,5) (53.4%, 81.5%)
11/07 09:31:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.9481	Prec@(1,5) (53.3%, 81.6%)
11/07 09:32:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.9390	Prec@(1,5) (53.6%, 81.7%)
11/07 09:32:00午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 53.5560%
11/07 09:32:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:32:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.2760%
11/07 09:32:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4872 (0.4789)	Arch Loss 1.9690 (1.9958)	Arch Hard Loss 1.9653 (1.9921)	Arch Alpha Loss 0.0037 (0.0037)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.6%)	
11/07 09:33:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4887 (0.4824)	Arch Loss 2.2963 (2.0003)	Arch Hard Loss 2.2921 (1.9965)	Arch Alpha Loss 0.0042 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
11/07 09:33:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5528 (0.4850)	Arch Loss 1.8212 (1.9984)	Arch Hard Loss 1.8176 (1.9947)	Arch Alpha Loss 0.0036 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
11/07 09:33:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5321 (0.4898)	Arch Loss 2.0825 (1.9899)	Arch Hard Loss 2.0792 (1.9862)	Arch Alpha Loss 0.0034 (0.0038)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.4%)	
11/07 09:33:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 85.8360%
11/07 09:34:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.9278	Prec@(1,5) (54.0%, 82.4%)
11/07 09:34:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.9153	Prec@(1,5) (54.0%, 82.5%)
11/07 09:34:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.9276	Prec@(1,5) (54.1%, 82.2%)
11/07 09:34:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.9273	Prec@(1,5) (54.1%, 82.2%)
11/07 09:34:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 54.1280%
11/07 09:34:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
11/07 09:34:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.2760%
11/07 09:34:13午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 54.2760%
11/07 09:34:13午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=range(6, 8), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)]], DAG2_concat=range(6, 8), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=range(6, 8))
