11/16 07:46:57AM parser.py:28 [INFO] 
11/16 07:46:57AM parser.py:29 [INFO] Parameters:
11/16 07:46:57AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g0.5/DAG
11/16 07:46:57AM parser.py:31 [INFO] T=10.0
11/16 07:46:57AM parser.py:31 [INFO] ADVANCED=1
11/16 07:46:57AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/16 07:46:57AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/16 07:46:57AM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/16 07:46:57AM parser.py:31 [INFO] BATCH_SIZE=64
11/16 07:46:57AM parser.py:31 [INFO] CASCADE=0
11/16 07:46:57AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/16 07:46:57AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/16 07:46:57AM parser.py:31 [INFO] DATA_PATH=../data/
11/16 07:46:57AM parser.py:31 [INFO] DATASET=cifar100
11/16 07:46:57AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/16 07:46:57AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/16 07:46:57AM parser.py:31 [INFO] DISCRETE=0
11/16 07:46:57AM parser.py:31 [INFO] EPOCHS=50
11/16 07:46:57AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/16 07:46:57AM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g0.5
11/16 07:46:57AM parser.py:31 [INFO] FINAL_L=0.5
11/16 07:46:57AM parser.py:31 [INFO] G=0.5
11/16 07:46:57AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/16 07:46:57AM parser.py:31 [INFO] GPUS=[0]
11/16 07:46:57AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/16 07:46:57AM parser.py:31 [INFO] INIT_CHANNELS=16
11/16 07:46:57AM parser.py:31 [INFO] L=0.5
11/16 07:46:57AM parser.py:31 [INFO] LAYERS=32
11/16 07:46:57AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/16 07:46:57AM parser.py:31 [INFO] NAME=Pruning
11/16 07:46:57AM parser.py:31 [INFO] NONKD=1
11/16 07:46:57AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g0.5
11/16 07:46:57AM parser.py:31 [INFO] PCDARTS=0
11/16 07:46:57AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g0.5/plots
11/16 07:46:57AM parser.py:31 [INFO] PRINT_FREQ=100
11/16 07:46:57AM parser.py:31 [INFO] RESET=0
11/16 07:46:57AM parser.py:31 [INFO] RESUME_PATH=None
11/16 07:46:57AM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g0.5
11/16 07:46:57AM parser.py:31 [INFO] SEED=0
11/16 07:46:57AM parser.py:31 [INFO] SHARE_STAGE=0
11/16 07:46:57AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/16 07:46:57AM parser.py:31 [INFO] SPEC_CELL=1
11/16 07:46:57AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/16 07:46:57AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/16 07:46:57AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/16 07:46:57AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/16 07:46:57AM parser.py:31 [INFO] TYPE=ArchKD
11/16 07:46:57AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/16 07:46:57AM parser.py:31 [INFO] W_LR=0.025
11/16 07:46:57AM parser.py:31 [INFO] W_LR_MIN=0.001
11/16 07:46:57AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/16 07:46:57AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/16 07:46:57AM parser.py:31 [INFO] WORKERS=4
11/16 07:46:57AM parser.py:32 [INFO] 
11/16 07:46:58AM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/16 07:46:58AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/16 07:47:44AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.7044 (4.7409)	Arch Loss 4.6492 (4.7416)	Arch Hard Loss 4.6435 (4.7356)	Arch Alpha Loss 0.0114 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.0%, 6.1%)	
11/16 07:48:27AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2219 (4.5865)	Arch Loss 4.3428 (4.5930)	Arch Hard Loss 4.3370 (4.5873)	Arch Alpha Loss 0.0116 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.9%, 9.4%)	
11/16 07:49:11AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2307 (4.4759)	Arch Loss 4.4303 (4.4797)	Arch Hard Loss 4.4248 (4.4741)	Arch Alpha Loss 0.0111 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 12.1%)	
11/16 07:49:50AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2519 (4.4085)	Arch Loss 3.9964 (4.4083)	Arch Hard Loss 3.9909 (4.4027)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.1%, 13.7%)	
11/16 07:49:51AM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 3.1600%
11/16 07:49:58AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.1231	Prec@(1,5) (5.4%, 20.5%)
11/16 07:50:05AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.1149	Prec@(1,5) (5.5%, 20.6%)
11/16 07:50:11AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.1215	Prec@(1,5) (5.5%, 20.5%)
11/16 07:50:17AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.1212	Prec@(1,5) (5.5%, 20.6%)
11/16 07:50:17AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 5.4760%
11/16 07:50:17AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/16 07:50:18AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 5.4760%
11/16 07:51:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.2698 (4.1289)	Arch Loss 4.2666 (4.1274)	Arch Hard Loss 4.2615 (4.1221)	Arch Alpha Loss 0.0103 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.5%, 20.0%)	
11/16 07:51:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.1916 (4.0955)	Arch Loss 4.0138 (4.1011)	Arch Hard Loss 4.0086 (4.0959)	Arch Alpha Loss 0.0104 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.2%, 21.7%)	
11/16 07:52:29午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8790 (4.0678)	Arch Loss 3.7542 (4.0694)	Arch Hard Loss 3.7491 (4.0641)	Arch Alpha Loss 0.0103 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.6%, 22.8%)	
11/16 07:53:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7619 (4.0499)	Arch Loss 3.8669 (4.0444)	Arch Hard Loss 3.8617 (4.0391)	Arch Alpha Loss 0.0104 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.0%, 23.4%)	
11/16 07:53:08午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 6.0120%
11/16 07:53:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.8872	Prec@(1,5) (7.7%, 28.7%)
11/16 07:53:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.9165	Prec@(1,5) (7.9%, 27.9%)
11/16 07:53:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.9113	Prec@(1,5) (8.0%, 28.1%)
11/16 07:53:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.9122	Prec@(1,5) (8.1%, 28.3%)
11/16 07:53:34午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 8.0640%
11/16 07:53:34午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/16 07:53:35午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.0640%
11/16 07:54:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8782 (3.9286)	Arch Loss 3.9062 (3.9582)	Arch Hard Loss 3.9005 (3.9529)	Arch Alpha Loss 0.0114 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.3%, 27.7%)	
11/16 07:55:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8548 (3.9136)	Arch Loss 3.6794 (3.9230)	Arch Hard Loss 3.6736 (3.9177)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.2%, 28.1%)	
11/16 07:55:46午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 4.1284 (3.8975)	Arch Loss 4.0207 (3.9031)	Arch Hard Loss 4.0150 (3.8977)	Arch Alpha Loss 0.0115 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.6%, 28.7%)	
11/16 07:56:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.9002 (3.8832)	Arch Loss 3.7239 (3.8843)	Arch Hard Loss 3.7184 (3.8789)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.9%, 29.3%)	
11/16 07:56:26午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 8.8560%
11/16 07:56:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.8626	Prec@(1,5) (9.4%, 30.9%)
11/16 07:56:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.8615	Prec@(1,5) (9.3%, 30.9%)
11/16 07:56:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.8548	Prec@(1,5) (9.3%, 30.7%)
11/16 07:56:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.8467	Prec@(1,5) (9.5%, 30.8%)
11/16 07:56:52午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.4960%
11/16 07:56:52午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/16 07:56:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.4960%
11/16 07:57:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.6313 (3.7738)	Arch Loss 3.3584 (3.8004)	Arch Hard Loss 3.3530 (3.7950)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (10.5%, 32.9%)	
11/16 07:58:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7281 (3.7649)	Arch Loss 3.6398 (3.7830)	Arch Hard Loss 3.6343 (3.7775)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.8%, 33.5%)	
11/16 07:59:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.7668 (3.7435)	Arch Loss 3.9820 (3.7610)	Arch Hard Loss 3.9766 (3.7555)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (10.9%, 34.1%)	
11/16 07:59:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.7020 (3.7325)	Arch Loss 3.6051 (3.7428)	Arch Hard Loss 3.5997 (3.7373)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.1%, 34.4%)	
11/16 07:59:43午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 11.1040%
11/16 07:59:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.7433	Prec@(1,5) (10.7%, 35.0%)
11/16 07:59:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.7447	Prec@(1,5) (10.8%, 34.8%)
11/16 08:00:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.7355	Prec@(1,5) (10.8%, 34.6%)
11/16 08:00:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.7365	Prec@(1,5) (10.9%, 35.0%)
11/16 08:00:09午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 10.9240%
11/16 08:00:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/16 08:00:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 10.9240%
11/16 08:00:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.5318 (3.6185)	Arch Loss 3.8031 (3.6665)	Arch Hard Loss 3.7977 (3.6609)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.5%, 37.4%)	
11/16 08:01:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.5317 (3.6204)	Arch Loss 3.7384 (3.6318)	Arch Hard Loss 3.7329 (3.6263)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.7%, 37.5%)	
11/16 08:02:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.3563 (3.6120)	Arch Loss 3.3370 (3.6156)	Arch Hard Loss 3.3318 (3.6101)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.1%, 37.8%)	
11/16 08:02:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.7389 (3.5955)	Arch Loss 3.8502 (3.6039)	Arch Hard Loss 3.8444 (3.5984)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.4%, 38.5%)	
11/16 08:02:59午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.3600%
11/16 08:03:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5279	Prec@(1,5) (14.7%, 41.4%)
11/16 08:03:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5415	Prec@(1,5) (14.7%, 41.0%)
11/16 08:03:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5453	Prec@(1,5) (14.7%, 41.1%)
11/16 08:03:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5499	Prec@(1,5) (14.7%, 41.0%)
11/16 08:03:25午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.7080%
11/16 08:03:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/16 08:03:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.7080%
11/16 08:04:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.6381 (3.5160)	Arch Loss 3.7129 (3.5209)	Arch Hard Loss 3.7074 (3.5155)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.8%, 40.7%)	
11/16 08:04:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.6259 (3.5129)	Arch Loss 3.6791 (3.5083)	Arch Hard Loss 3.6739 (3.5029)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.8%, 40.8%)	
11/16 08:05:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.4351 (3.4891)	Arch Loss 3.8535 (3.4985)	Arch Hard Loss 3.8482 (3.4930)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.4%)	
11/16 08:06:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.4120 (3.4761)	Arch Loss 3.4757 (3.4930)	Arch Hard Loss 3.4703 (3.4876)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.6%, 41.8%)	
11/16 08:06:16午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 15.6480%
11/16 08:06:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.3960	Prec@(1,5) (17.1%, 45.4%)
11/16 08:06:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.4017	Prec@(1,5) (17.1%, 45.2%)
11/16 08:06:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.3926	Prec@(1,5) (17.2%, 45.5%)
11/16 08:06:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.4002	Prec@(1,5) (17.1%, 45.2%)
11/16 08:06:42午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 17.0560%
11/16 08:06:42午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/16 08:06:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.0560%
11/16 08:07:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.8941 (3.3705)	Arch Loss 3.5198 (3.4286)	Arch Hard Loss 3.5142 (3.4232)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.8%, 44.7%)	
11/16 08:08:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.2512 (3.3694)	Arch Loss 3.4952 (3.4137)	Arch Hard Loss 3.4896 (3.4084)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 45.0%)	
11/16 08:08:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.4891 (3.3603)	Arch Loss 3.5442 (3.3906)	Arch Hard Loss 3.5383 (3.3852)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.6%, 45.1%)	
11/16 08:09:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.4773 (3.3482)	Arch Loss 3.1550 (3.3833)	Arch Hard Loss 3.1494 (3.3779)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.7%, 45.4%)	
11/16 08:09:33午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.7040%
11/16 08:09:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.3029	Prec@(1,5) (18.9%, 47.1%)
11/16 08:09:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3249	Prec@(1,5) (18.8%, 46.6%)
11/16 08:09:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.3207	Prec@(1,5) (19.0%, 46.7%)
11/16 08:10:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.3188	Prec@(1,5) (18.8%, 46.9%)
11/16 08:10:00午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 18.8400%
11/16 08:10:00午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/16 08:10:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 18.8400%
11/16 08:10:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.1729 (3.2962)	Arch Loss 3.2805 (3.3272)	Arch Hard Loss 3.2749 (3.3217)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.8%, 47.5%)	
11/16 08:11:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.3921 (3.2770)	Arch Loss 3.5985 (3.3241)	Arch Hard Loss 3.5928 (3.3186)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.3%, 48.1%)	
11/16 08:12:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.3378 (3.2505)	Arch Loss 2.9645 (3.2979)	Arch Hard Loss 2.9585 (3.2924)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.7%, 48.6%)	
11/16 08:12:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.9955 (3.2405)	Arch Loss 3.4403 (3.2829)	Arch Hard Loss 3.4341 (3.2774)	Arch Alpha Loss 0.0124 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.0%, 48.9%)	
11/16 08:12:50午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 19.9680%
11/16 08:12:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.3127	Prec@(1,5) (18.7%, 47.2%)
11/16 08:13:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.3181	Prec@(1,5) (18.2%, 47.4%)
11/16 08:13:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.3109	Prec@(1,5) (18.3%, 47.4%)
11/16 08:13:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.3064	Prec@(1,5) (18.4%, 47.5%)
11/16 08:13:16午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 18.4080%
11/16 08:13:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/16 08:13:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 18.8400%
11/16 08:14:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.9650 (3.1086)	Arch Loss 3.4162 (3.1999)	Arch Hard Loss 3.4108 (3.1945)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 52.1%)	
11/16 08:14:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.2973 (3.1479)	Arch Loss 3.0697 (3.2102)	Arch Hard Loss 3.0642 (3.2048)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.0%, 51.3%)	
11/16 08:15:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.3120 (3.1443)	Arch Loss 3.0929 (3.2055)	Arch Hard Loss 3.0876 (3.2000)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.8%, 51.1%)	
11/16 08:16:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.1240 (3.1357)	Arch Loss 3.4322 (3.1906)	Arch Hard Loss 3.4272 (3.1851)	Arch Alpha Loss 0.0101 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.0%, 51.5%)	
11/16 08:16:07午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 21.9760%
11/16 08:16:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1117	Prec@(1,5) (23.0%, 52.3%)
11/16 08:16:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1097	Prec@(1,5) (23.0%, 52.5%)
11/16 08:16:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1141	Prec@(1,5) (22.9%, 52.4%)
11/16 08:16:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1191	Prec@(1,5) (22.5%, 52.2%)
11/16 08:16:33午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 22.5120%
11/16 08:16:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/16 08:16:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.5120%
11/16 08:17:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.8473 (3.0579)	Arch Loss 2.9953 (3.1361)	Arch Hard Loss 2.9899 (3.1307)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.1%, 54.6%)	
11/16 08:18:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.2154 (3.0485)	Arch Loss 3.0445 (3.1333)	Arch Hard Loss 3.0385 (3.1279)	Arch Alpha Loss 0.0120 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.6%, 54.0%)	
11/16 08:18:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.3516 (3.0414)	Arch Loss 3.1717 (3.1192)	Arch Hard Loss 3.1656 (3.1137)	Arch Alpha Loss 0.0121 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.9%, 54.1%)	
11/16 08:19:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.8519 (3.0404)	Arch Loss 2.9465 (3.1018)	Arch Hard Loss 2.9411 (3.0963)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.0%, 54.2%)	
11/16 08:19:24午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 24.0000%
11/16 08:19:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.9930	Prec@(1,5) (24.8%, 55.1%)
11/16 08:19:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.9818	Prec@(1,5) (25.2%, 56.1%)
11/16 08:19:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.9989	Prec@(1,5) (24.8%, 55.7%)
11/16 08:19:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.0028	Prec@(1,5) (24.8%, 55.5%)
11/16 08:19:50午前 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 24.8280%
11/16 08:19:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:19:51午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.8280%
11/16 08:20:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9226 (2.9332)	Arch Loss 3.1646 (3.0210)	Arch Hard Loss 3.1595 (3.0156)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 56.6%)	
11/16 08:21:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.9870 (2.9396)	Arch Loss 3.3165 (3.0359)	Arch Hard Loss 3.3114 (3.0305)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.0%, 56.6%)	
11/16 08:22:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.4564 (2.9366)	Arch Loss 2.6960 (3.0267)	Arch Hard Loss 2.6907 (3.0212)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 56.4%)	
11/16 08:22:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.7614 (2.9279)	Arch Loss 3.4523 (3.0189)	Arch Hard Loss 3.4468 (3.0134)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.0%, 56.6%)	
11/16 08:22:41午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 26.0320%
11/16 08:22:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.9642	Prec@(1,5) (26.3%, 56.3%)
11/16 08:22:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.9466	Prec@(1,5) (26.3%, 56.7%)
11/16 08:23:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.9429	Prec@(1,5) (26.6%, 56.7%)
11/16 08:23:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.9490	Prec@(1,5) (26.3%, 56.5%)
11/16 08:23:08午前 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 26.2920%
11/16 08:23:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:23:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.2920%
11/16 08:23:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.8524 (2.8438)	Arch Loss 2.8598 (2.9612)	Arch Hard Loss 2.8544 (2.9557)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 59.1%)	
11/16 08:24:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.9371 (2.8477)	Arch Loss 2.5714 (2.9546)	Arch Hard Loss 2.5659 (2.9491)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.4%, 58.9%)	
11/16 08:25:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.8191 (2.8409)	Arch Loss 2.8442 (2.9446)	Arch Hard Loss 2.8388 (2.9391)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.9%, 59.0%)	
11/16 08:25:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.8166 (2.8339)	Arch Loss 2.3265 (2.9404)	Arch Hard Loss 2.3211 (2.9348)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.1%, 59.1%)	
11/16 08:25:59午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 28.1600%
11/16 08:26:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.8894	Prec@(1,5) (27.6%, 58.2%)
11/16 08:26:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.8892	Prec@(1,5) (27.5%, 58.4%)
11/16 08:26:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.8823	Prec@(1,5) (27.3%, 58.5%)
11/16 08:26:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.8819	Prec@(1,5) (27.3%, 58.5%)
11/16 08:26:25午前 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 27.2600%
11/16 08:26:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:26:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.2600%
11/16 08:27:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4493 (2.7537)	Arch Loss 2.8867 (2.8651)	Arch Hard Loss 2.8813 (2.8598)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.5%, 61.3%)	
11/16 08:27:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.6672 (2.7407)	Arch Loss 2.8345 (2.8740)	Arch Hard Loss 2.8290 (2.8687)	Arch Alpha Loss 0.0109 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.8%, 61.6%)	
11/16 08:28:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.7940 (2.7439)	Arch Loss 3.0625 (2.8678)	Arch Hard Loss 3.0568 (2.8624)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 61.6%)	
11/16 08:29:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.9107 (2.7436)	Arch Loss 2.9963 (2.8664)	Arch Hard Loss 2.9908 (2.8611)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 61.7%)	
11/16 08:29:15午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 29.7360%
11/16 08:29:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.8150	Prec@(1,5) (28.2%, 59.9%)
11/16 08:29:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.8203	Prec@(1,5) (28.5%, 59.9%)
11/16 08:29:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.8237	Prec@(1,5) (28.6%, 59.8%)
11/16 08:29:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.8293	Prec@(1,5) (28.6%, 59.8%)
11/16 08:29:42午前 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 28.6240%
11/16 08:29:42午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:29:42午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.6240%
11/16 08:30:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.6444 (2.6684)	Arch Loss 2.8112 (2.8500)	Arch Hard Loss 2.8056 (2.8445)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.6%)	
11/16 08:31:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.8978 (2.6832)	Arch Loss 2.9187 (2.8406)	Arch Hard Loss 2.9129 (2.8351)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 63.1%)	
11/16 08:31:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.5786 (2.6766)	Arch Loss 2.3782 (2.8267)	Arch Hard Loss 2.3726 (2.8212)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.2%)	
11/16 08:32:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.1906 (2.6694)	Arch Loss 2.5937 (2.8171)	Arch Hard Loss 2.5887 (2.8116)	Arch Alpha Loss 0.0099 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.3%, 63.2%)	
11/16 08:32:32午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 31.2880%
11/16 08:32:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.8866	Prec@(1,5) (28.4%, 58.5%)
11/16 08:32:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8887	Prec@(1,5) (28.5%, 58.5%)
11/16 08:32:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.9005	Prec@(1,5) (28.1%, 58.3%)
11/16 08:32:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.9009	Prec@(1,5) (28.2%, 58.3%)
11/16 08:32:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 28.2240%
11/16 08:32:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:32:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.6240%
11/16 08:33:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.9135 (2.5615)	Arch Loss 3.0186 (2.7804)	Arch Hard Loss 3.0129 (2.7748)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 65.7%)	
11/16 08:34:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.7204 (2.5777)	Arch Loss 2.6507 (2.7742)	Arch Hard Loss 2.6448 (2.7687)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.4%, 65.4%)	
11/16 08:35:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.7413 (2.5816)	Arch Loss 2.6858 (2.7587)	Arch Hard Loss 2.6800 (2.7532)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.2%, 65.4%)	
11/16 08:35:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.6144 (2.5821)	Arch Loss 2.5798 (2.7521)	Arch Hard Loss 2.5743 (2.7466)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.1%, 65.4%)	
11/16 08:35:49午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 33.1080%
11/16 08:35:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.6454	Prec@(1,5) (31.6%, 63.8%)
11/16 08:36:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.6648	Prec@(1,5) (31.6%, 63.3%)
11/16 08:36:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.6648	Prec@(1,5) (31.5%, 63.4%)
11/16 08:36:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.6778	Prec@(1,5) (31.4%, 63.1%)
11/16 08:36:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 31.4160%
11/16 08:36:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:36:15午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.4160%
11/16 08:36:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.3963 (2.4541)	Arch Loss 2.6630 (2.7077)	Arch Hard Loss 2.6577 (2.7023)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 68.4%)	
11/16 08:37:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.2071 (2.4964)	Arch Loss 2.6724 (2.7147)	Arch Hard Loss 2.6666 (2.7092)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 67.4%)	
11/16 08:38:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.2787 (2.5041)	Arch Loss 2.6786 (2.7018)	Arch Hard Loss 2.6732 (2.6963)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 67.2%)	
11/16 08:39:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.2788 (2.5095)	Arch Loss 2.5057 (2.6976)	Arch Hard Loss 2.5005 (2.6921)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.1%, 67.1%)	
11/16 08:39:05午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 34.1360%
11/16 08:39:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.6813	Prec@(1,5) (30.9%, 63.3%)
11/16 08:39:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.6590	Prec@(1,5) (31.5%, 63.9%)
11/16 08:39:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.6626	Prec@(1,5) (31.5%, 63.7%)
11/16 08:39:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.6568	Prec@(1,5) (31.8%, 63.7%)
11/16 08:39:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 31.7720%
11/16 08:39:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:39:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.7720%
11/16 08:40:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.2531 (2.3774)	Arch Loss 2.8082 (2.6629)	Arch Hard Loss 2.8027 (2.6575)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 70.0%)	
11/16 08:40:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.4464 (2.4148)	Arch Loss 2.7975 (2.6540)	Arch Hard Loss 2.7920 (2.6486)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 69.0%)	
11/16 08:41:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.6355 (2.4232)	Arch Loss 2.4777 (2.6457)	Arch Hard Loss 2.4724 (2.6403)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.7%)	
11/16 08:42:22午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.6703 (2.4272)	Arch Loss 2.6090 (2.6309)	Arch Hard Loss 2.6038 (2.6255)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.6%)	
11/16 08:42:22午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 36.1680%
11/16 08:42:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.5626	Prec@(1,5) (34.5%, 66.2%)
11/16 08:42:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.5919	Prec@(1,5) (33.6%, 65.5%)
11/16 08:42:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.5887	Prec@(1,5) (33.6%, 65.6%)
11/16 08:42:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.5852	Prec@(1,5) (33.6%, 65.6%)
11/16 08:42:49午前 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 33.6000%
11/16 08:42:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 08:42:49午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.6000%
11/16 08:43:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.2690 (2.3924)	Arch Loss 2.9084 (2.6369)	Arch Hard Loss 2.9031 (2.6315)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.5%, 70.1%)	
11/16 08:44:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.2498 (2.3705)	Arch Loss 2.5584 (2.6202)	Arch Hard Loss 2.5531 (2.6148)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 70.3%)	
11/16 08:45:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.2457 (2.3588)	Arch Loss 2.5576 (2.6157)	Arch Hard Loss 2.5519 (2.6104)	Arch Alpha Loss 0.0114 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 70.2%)	
11/16 08:45:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.3774 (2.3632)	Arch Loss 2.7752 (2.6082)	Arch Hard Loss 2.7701 (2.6028)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 70.1%)	
11/16 08:45:40午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 37.7240%
11/16 08:45:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.5381	Prec@(1,5) (34.5%, 66.5%)
11/16 08:45:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.5427	Prec@(1,5) (34.3%, 66.3%)
11/16 08:46:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.5623	Prec@(1,5) (34.0%, 65.8%)
11/16 08:46:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.5670	Prec@(1,5) (33.8%, 65.6%)
11/16 08:46:06午前 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 33.8200%
11/16 08:46:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 08:46:06午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.8200%
11/16 08:46:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.3486 (2.2943)	Arch Loss 2.5991 (2.5636)	Arch Hard Loss 2.5936 (2.5582)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.0%, 72.1%)	
11/16 08:47:34午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.6043 (2.2957)	Arch Loss 2.5942 (2.5854)	Arch Hard Loss 2.5885 (2.5799)	Arch Alpha Loss 0.0115 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 71.7%)	
11/16 08:48:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.3891 (2.2957)	Arch Loss 2.2065 (2.5698)	Arch Hard Loss 2.2011 (2.5644)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 71.6%)	
11/16 08:48:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.9893 (2.3019)	Arch Loss 2.1130 (2.5573)	Arch Hard Loss 2.1076 (2.5519)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.0%, 71.3%)	
11/16 08:48:56午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 39.0160%
11/16 08:49:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5321	Prec@(1,5) (34.5%, 67.3%)
11/16 08:49:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5515	Prec@(1,5) (34.2%, 66.6%)
11/16 08:49:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5485	Prec@(1,5) (34.5%, 66.5%)
11/16 08:49:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5414	Prec@(1,5) (34.7%, 66.7%)
11/16 08:49:22午前 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 34.7120%
11/16 08:49:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 08:49:23午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.7120%
11/16 08:50:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.2626 (2.1891)	Arch Loss 2.7782 (2.5116)	Arch Hard Loss 2.7726 (2.5062)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.0%, 73.8%)	
11/16 08:50:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.8935 (2.2105)	Arch Loss 2.4761 (2.5082)	Arch Hard Loss 2.4704 (2.5026)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.6%, 73.4%)	
11/16 08:51:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.1515 (2.2241)	Arch Loss 2.2565 (2.5086)	Arch Hard Loss 2.2508 (2.5031)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 73.1%)	
11/16 08:52:12午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.1130 (2.2295)	Arch Loss 2.2421 (2.5114)	Arch Hard Loss 2.2364 (2.5059)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.3%, 72.9%)	
11/16 08:52:12午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 40.3040%
11/16 08:52:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.5344	Prec@(1,5) (35.2%, 67.9%)
11/16 08:52:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.5262	Prec@(1,5) (35.2%, 67.8%)
11/16 08:52:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.5215	Prec@(1,5) (35.4%, 67.5%)
11/16 08:52:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.5168	Prec@(1,5) (35.5%, 67.5%)
11/16 08:52:39午前 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 35.5320%
11/16 08:52:39午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 08:52:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.5320%
11/16 08:53:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.7918 (2.1108)	Arch Loss 2.3656 (2.4202)	Arch Hard Loss 2.3602 (2.4148)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.2%)	
11/16 08:54:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.7682 (2.1394)	Arch Loss 2.4300 (2.4554)	Arch Hard Loss 2.4246 (2.4500)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.1%, 75.0%)	
11/16 08:54:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.1578 (2.1567)	Arch Loss 2.1695 (2.4687)	Arch Hard Loss 2.1641 (2.4633)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.8%)	
11/16 08:55:29午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.9079 (2.1654)	Arch Loss 2.4546 (2.4667)	Arch Hard Loss 2.4493 (2.4613)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 74.5%)	
11/16 08:55:29午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 41.5080%
11/16 08:55:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.4481	Prec@(1,5) (36.8%, 69.1%)
11/16 08:55:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.4791	Prec@(1,5) (36.1%, 68.3%)
11/16 08:55:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.4733	Prec@(1,5) (36.1%, 68.4%)
11/16 08:55:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.4760	Prec@(1,5) (36.0%, 68.3%)
11/16 08:55:55午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 35.9600%
11/16 08:55:55午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 08:55:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.9600%
11/16 08:56:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.1954 (2.0237)	Arch Loss 2.5272 (2.4825)	Arch Hard Loss 2.5217 (2.4771)	Arch Alpha Loss 0.0109 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.2%, 77.2%)	
11/16 08:57:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.2480 (2.0696)	Arch Loss 2.6698 (2.4769)	Arch Hard Loss 2.6639 (2.4715)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 76.3%)	
11/16 08:58:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 2.0172 (2.0880)	Arch Loss 2.5020 (2.4554)	Arch Hard Loss 2.4961 (2.4499)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 76.0%)	
11/16 08:58:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.2020 (2.0919)	Arch Loss 2.6764 (2.4450)	Arch Hard Loss 2.6709 (2.4396)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 76.0%)	
11/16 08:58:45午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 42.8480%
11/16 08:58:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.4350	Prec@(1,5) (36.9%, 69.2%)
11/16 08:58:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4136	Prec@(1,5) (37.3%, 69.6%)
11/16 08:59:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4136	Prec@(1,5) (37.4%, 70.0%)
11/16 08:59:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4104	Prec@(1,5) (37.5%, 70.0%)
11/16 08:59:11午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 37.5440%
11/16 08:59:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 08:59:12午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.5440%
11/16 08:59:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.8810 (1.9952)	Arch Loss 2.5897 (2.4126)	Arch Hard Loss 2.5845 (2.4071)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.5%)	
11/16 09:00:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.9732 (2.0251)	Arch Loss 2.6176 (2.4169)	Arch Hard Loss 2.6125 (2.4113)	Arch Alpha Loss 0.0102 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.9%, 77.0%)	
11/16 09:01:22午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 2.0790 (2.0325)	Arch Loss 2.6070 (2.4092)	Arch Hard Loss 2.6014 (2.4037)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 77.1%)	
11/16 09:02:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.6581 (2.0392)	Arch Loss 2.2528 (2.3978)	Arch Hard Loss 2.2471 (2.3923)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 76.9%)	
11/16 09:02:01午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 44.3880%
11/16 09:02:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.3446	Prec@(1,5) (38.9%, 70.4%)
11/16 09:02:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.3347	Prec@(1,5) (39.0%, 70.7%)
11/16 09:02:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.3361	Prec@(1,5) (38.8%, 70.5%)
11/16 09:02:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.3358	Prec@(1,5) (38.9%, 70.5%)
11/16 09:02:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 38.9000%
11/16 09:02:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 09:02:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.9000%
11/16 09:03:12午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.8219 (1.8954)	Arch Loss 2.4783 (2.4061)	Arch Hard Loss 2.4730 (2.4006)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.5%)	
11/16 09:03:55午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 2.0223 (1.9284)	Arch Loss 1.8933 (2.3856)	Arch Hard Loss 1.8878 (2.3801)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.1%)	
11/16 09:04:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.0383 (1.9493)	Arch Loss 2.5116 (2.3784)	Arch Hard Loss 2.5063 (2.3730)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.6%)	
11/16 09:05:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.1026 (1.9567)	Arch Loss 2.3092 (2.3688)	Arch Hard Loss 2.3038 (2.3633)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.5%, 78.5%)	
11/16 09:05:19午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 46.4600%
11/16 09:05:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.3776	Prec@(1,5) (38.6%, 70.4%)
11/16 09:05:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.3738	Prec@(1,5) (38.7%, 70.2%)
11/16 09:05:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.3753	Prec@(1,5) (38.8%, 70.3%)
11/16 09:05:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.3700	Prec@(1,5) (39.0%, 70.4%)
11/16 09:05:45午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 39.0400%
11/16 09:05:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 09:05:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.0400%
11/16 09:06:30午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.8607 (1.8610)	Arch Loss 2.3154 (2.3599)	Arch Hard Loss 2.3100 (2.3545)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.2%)	
11/16 09:07:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 2.3519 (1.8859)	Arch Loss 2.0807 (2.3436)	Arch Hard Loss 2.0755 (2.3382)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 79.8%)	
11/16 09:07:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.7124 (1.9041)	Arch Loss 2.0739 (2.3519)	Arch Hard Loss 2.0685 (2.3465)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.5%)	
11/16 09:08:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.2210 (1.9143)	Arch Loss 2.2702 (2.3528)	Arch Hard Loss 2.2646 (2.3474)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.3%, 79.2%)	
11/16 09:08:37午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 47.3400%
11/16 09:08:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.2716	Prec@(1,5) (40.7%, 72.2%)
11/16 09:08:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.2814	Prec@(1,5) (40.5%, 71.9%)
11/16 09:08:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.2950	Prec@(1,5) (40.0%, 71.8%)
11/16 09:09:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.2908	Prec@(1,5) (40.2%, 72.0%)
11/16 09:09:03午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 40.2000%
11/16 09:09:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 09:09:04午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.2000%
11/16 09:09:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.7669 (1.7885)	Arch Loss 2.0561 (2.3003)	Arch Hard Loss 2.0504 (2.2948)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.6%)	
11/16 09:10:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.9184 (1.8126)	Arch Loss 2.5843 (2.3087)	Arch Hard Loss 2.5786 (2.3033)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 81.1%)	
11/16 09:11:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.5387 (1.8300)	Arch Loss 2.6131 (2.3211)	Arch Hard Loss 2.6075 (2.3157)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.9%)	
11/16 09:11:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.7309 (1.8452)	Arch Loss 2.7313 (2.3136)	Arch Hard Loss 2.7254 (2.3081)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.6%)	
11/16 09:11:55午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 48.5920%
11/16 09:12:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.2336	Prec@(1,5) (41.7%, 73.8%)
11/16 09:12:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.2660	Prec@(1,5) (41.1%, 73.1%)
11/16 09:12:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.2737	Prec@(1,5) (41.1%, 73.1%)
11/16 09:12:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.2673	Prec@(1,5) (41.1%, 73.2%)
11/16 09:12:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 41.1600%
11/16 09:12:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/16 09:12:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.1600%
11/16 09:13:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5860 (1.7458)	Arch Loss 2.8880 (2.3234)	Arch Hard Loss 2.8824 (2.3178)	Arch Alpha Loss 0.0112 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 82.5%)	
11/16 09:13:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.5836 (1.7674)	Arch Loss 2.5054 (2.3091)	Arch Hard Loss 2.5002 (2.3035)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 82.0%)	
11/16 09:14:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.7872 (1.7837)	Arch Loss 2.7234 (2.2991)	Arch Hard Loss 2.7179 (2.2936)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.6%)	
11/16 09:15:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.6978 (1.7852)	Arch Loss 2.3484 (2.3002)	Arch Hard Loss 2.3431 (2.2947)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.8%)	
11/16 09:15:12午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 50.0480%
11/16 09:15:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2369	Prec@(1,5) (41.8%, 73.3%)
11/16 09:15:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.2590	Prec@(1,5) (41.9%, 73.1%)
11/16 09:15:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.2810	Prec@(1,5) (41.5%, 72.9%)
11/16 09:15:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.2802	Prec@(1,5) (41.6%, 72.7%)
11/16 09:15:38午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 41.6160%
11/16 09:15:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:15:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.6160%
11/16 09:16:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.4883 (1.6666)	Arch Loss 2.2496 (2.2899)	Arch Hard Loss 2.2436 (2.2845)	Arch Alpha Loss 0.0122 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.7%)	
11/16 09:17:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 2.0444 (1.7094)	Arch Loss 2.2538 (2.2738)	Arch Hard Loss 2.2480 (2.2683)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 83.0%)	
11/16 09:17:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.6226 (1.7281)	Arch Loss 2.2987 (2.2893)	Arch Hard Loss 2.2938 (2.2838)	Arch Alpha Loss 0.0098 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.4%, 82.4%)	
11/16 09:18:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.8720 (1.7303)	Arch Loss 1.9545 (2.2845)	Arch Hard Loss 1.9493 (2.2790)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.5%)	
11/16 09:18:29午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 51.4440%
11/16 09:18:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.2679	Prec@(1,5) (41.3%, 73.4%)
11/16 09:18:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.2532	Prec@(1,5) (41.6%, 73.6%)
11/16 09:18:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.2716	Prec@(1,5) (41.4%, 73.3%)
11/16 09:18:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.2831	Prec@(1,5) (41.2%, 73.1%)
11/16 09:18:55午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 41.2360%
11/16 09:18:55午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:18:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.6160%
11/16 09:19:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.4168 (1.6231)	Arch Loss 2.3118 (2.2924)	Arch Hard Loss 2.3063 (2.2869)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.2%)	
11/16 09:20:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.6090 (1.6290)	Arch Loss 1.9730 (2.2728)	Arch Hard Loss 1.9675 (2.2673)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.2%)	
11/16 09:21:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.7921 (1.6447)	Arch Loss 2.1938 (2.2683)	Arch Hard Loss 2.1883 (2.2627)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 84.2%)	
11/16 09:21:46午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.5693 (1.6545)	Arch Loss 2.0421 (2.2627)	Arch Hard Loss 2.0370 (2.2571)	Arch Alpha Loss 0.0102 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.2%, 84.0%)	
11/16 09:21:47午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 53.2480%
11/16 09:21:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.2436	Prec@(1,5) (41.9%, 73.9%)
11/16 09:22:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.2228	Prec@(1,5) (42.4%, 74.1%)
11/16 09:22:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.2322	Prec@(1,5) (42.5%, 73.9%)
11/16 09:22:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.2314	Prec@(1,5) (42.5%, 73.8%)
11/16 09:22:13午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 42.5200%
11/16 09:22:13午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:22:13午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5200%
11/16 09:22:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.7013 (1.5367)	Arch Loss 2.0994 (2.2253)	Arch Hard Loss 2.0937 (2.2197)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.2%)	
11/16 09:23:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.5124 (1.5516)	Arch Loss 2.4340 (2.2649)	Arch Hard Loss 2.4287 (2.2594)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.8%)	
11/16 09:24:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.7527 (1.5719)	Arch Loss 2.4621 (2.2619)	Arch Hard Loss 2.4566 (2.2565)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 85.5%)	
11/16 09:25:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.3998 (1.5884)	Arch Loss 2.0836 (2.2528)	Arch Hard Loss 2.0777 (2.2473)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.0%)	
11/16 09:25:04午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 54.8160%
11/16 09:25:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.1973	Prec@(1,5) (44.0%, 74.8%)
11/16 09:25:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.1874	Prec@(1,5) (43.9%, 74.7%)
11/16 09:25:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2057	Prec@(1,5) (43.5%, 74.4%)
11/16 09:25:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2053	Prec@(1,5) (43.6%, 74.5%)
11/16 09:25:30午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 43.5560%
11/16 09:25:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:25:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.5560%
11/16 09:26:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.2733 (1.4763)	Arch Loss 2.1503 (2.2480)	Arch Hard Loss 2.1450 (2.2424)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.0%)	
11/16 09:26:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.7035 (1.5002)	Arch Loss 2.2036 (2.2454)	Arch Hard Loss 2.1981 (2.2399)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.6%)	
11/16 09:27:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.4655 (1.5140)	Arch Loss 2.4063 (2.2430)	Arch Hard Loss 2.4005 (2.2375)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.5%)	
11/16 09:28:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.5358 (1.5378)	Arch Loss 2.2508 (2.2420)	Arch Hard Loss 2.2455 (2.2365)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.0%)	
11/16 09:28:21午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 56.2880%
11/16 09:28:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.2299	Prec@(1,5) (43.0%, 74.6%)
11/16 09:28:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.2303	Prec@(1,5) (43.4%, 74.2%)
11/16 09:28:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.2237	Prec@(1,5) (43.5%, 74.2%)
11/16 09:28:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.2272	Prec@(1,5) (43.2%, 74.1%)
11/16 09:28:47午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 43.1800%
11/16 09:28:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:28:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.5560%
11/16 09:29:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.8215 (1.4333)	Arch Loss 1.9132 (2.2273)	Arch Hard Loss 1.9074 (2.2218)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.2%)	
11/16 09:30:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.8074 (1.4653)	Arch Loss 2.4649 (2.2241)	Arch Hard Loss 2.4594 (2.2186)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.9%)	
11/16 09:30:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.7116 (1.4744)	Arch Loss 2.2632 (2.2248)	Arch Hard Loss 2.2574 (2.2193)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.7%)	
11/16 09:31:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.6077 (1.4842)	Arch Loss 2.4071 (2.2246)	Arch Hard Loss 2.4020 (2.2191)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.7%)	
11/16 09:31:38午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 57.2680%
11/16 09:31:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1383	Prec@(1,5) (45.3%, 75.3%)
11/16 09:31:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1654	Prec@(1,5) (44.3%, 75.3%)
11/16 09:31:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.2011	Prec@(1,5) (43.8%, 74.6%)
11/16 09:32:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.2123	Prec@(1,5) (43.6%, 74.5%)
11/16 09:32:05午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 43.5840%
11/16 09:32:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:32:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.5840%
11/16 09:32:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.1574 (1.3740)	Arch Loss 2.8351 (2.2034)	Arch Hard Loss 2.8297 (2.1979)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.5%)	
11/16 09:33:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.3726 (1.3832)	Arch Loss 2.3645 (2.2177)	Arch Hard Loss 2.3589 (2.2122)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.3%)	
11/16 09:34:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.3405 (1.3942)	Arch Loss 2.0776 (2.2139)	Arch Hard Loss 2.0720 (2.2084)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.1%)	
11/16 09:34:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.7117 (1.4190)	Arch Loss 1.7736 (2.2143)	Arch Hard Loss 1.7679 (2.2088)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.7%)	
11/16 09:34:54午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 59.1440%
11/16 09:35:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.1755	Prec@(1,5) (45.0%, 75.7%)
11/16 09:35:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1798	Prec@(1,5) (44.9%, 75.3%)
11/16 09:35:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1998	Prec@(1,5) (44.2%, 75.0%)
11/16 09:35:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.2058	Prec@(1,5) (44.0%, 74.9%)
11/16 09:35:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 44.0480%
11/16 09:35:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:35:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.0480%
11/16 09:36:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.2863 (1.2822)	Arch Loss 1.7414 (2.1630)	Arch Hard Loss 1.7360 (2.1574)	Arch Alpha Loss 0.0107 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.9%)	
11/16 09:36:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.4216 (1.3085)	Arch Loss 2.2200 (2.1996)	Arch Hard Loss 2.2149 (2.1940)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.4%)	
11/16 09:37:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.8476 (1.3438)	Arch Loss 2.3152 (2.2020)	Arch Hard Loss 2.3094 (2.1965)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.7%)	
11/16 09:38:13午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.2246 (1.3571)	Arch Loss 1.8607 (2.2023)	Arch Hard Loss 1.8553 (2.1968)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.6%)	
11/16 09:38:13午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 60.8240%
11/16 09:38:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1417	Prec@(1,5) (46.4%, 75.9%)
11/16 09:38:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.1482	Prec@(1,5) (46.0%, 76.2%)
11/16 09:38:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.1494	Prec@(1,5) (45.8%, 76.5%)
11/16 09:38:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.1444	Prec@(1,5) (45.9%, 76.5%)
11/16 09:38:39午前 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 45.9120%
11/16 09:38:39午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:38:40午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.9120%
11/16 09:39:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8630 (1.2255)	Arch Loss 2.1973 (2.2344)	Arch Hard Loss 2.1920 (2.2289)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.3%)	
11/16 09:40:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.3374 (1.2744)	Arch Loss 1.9515 (2.2300)	Arch Hard Loss 1.9457 (2.2245)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.7%)	
11/16 09:40:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.2790 (1.2803)	Arch Loss 1.8928 (2.2160)	Arch Hard Loss 1.8875 (2.2106)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.8%)	
11/16 09:41:29午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.3816 (1.2835)	Arch Loss 2.3171 (2.2094)	Arch Hard Loss 2.3118 (2.2040)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.7%)	
11/16 09:41:29午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 62.9120%
11/16 09:41:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1774	Prec@(1,5) (45.4%, 76.0%)
11/16 09:41:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1951	Prec@(1,5) (45.3%, 75.7%)
11/16 09:41:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1852	Prec@(1,5) (45.6%, 76.1%)
11/16 09:41:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1762	Prec@(1,5) (45.6%, 76.2%)
11/16 09:41:56午前 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 45.6440%
11/16 09:41:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:41:56午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.9120%
11/16 09:42:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.1778 (1.1810)	Arch Loss 2.0784 (2.1838)	Arch Hard Loss 2.0727 (2.1783)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.3%)	
11/16 09:43:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.1311 (1.1873)	Arch Loss 1.7516 (2.2058)	Arch Hard Loss 1.7458 (2.2003)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.3%)	
11/16 09:44:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0944 (1.2024)	Arch Loss 2.5881 (2.2188)	Arch Hard Loss 2.5824 (2.2133)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 91.2%)	
11/16 09:44:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.9642 (1.2194)	Arch Loss 1.6398 (2.2018)	Arch Hard Loss 1.6345 (2.1963)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.9%)	
11/16 09:44:47午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 64.1120%
11/16 09:44:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.1821	Prec@(1,5) (45.7%, 75.8%)
11/16 09:45:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.2035	Prec@(1,5) (45.4%, 75.4%)
11/16 09:45:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.1989	Prec@(1,5) (45.4%, 75.7%)
11/16 09:45:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.1883	Prec@(1,5) (45.7%, 75.9%)
11/16 09:45:14午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 45.7040%
11/16 09:45:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:45:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.9120%
11/16 09:45:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.1203 (1.1074)	Arch Loss 2.7048 (2.1778)	Arch Hard Loss 2.6990 (2.1722)	Arch Alpha Loss 0.0117 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.1%)	
11/16 09:46:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.0921 (1.1256)	Arch Loss 2.3421 (2.2030)	Arch Hard Loss 2.3368 (2.1975)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.9%)	
11/16 09:47:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.2765 (1.1459)	Arch Loss 1.9986 (2.2015)	Arch Hard Loss 1.9932 (2.1960)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.6%)	
11/16 09:48:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.1289 (1.1591)	Arch Loss 2.6791 (2.2115)	Arch Hard Loss 2.6741 (2.2060)	Arch Alpha Loss 0.0101 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.4%)	
11/16 09:48:05午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 65.8840%
11/16 09:48:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.1366	Prec@(1,5) (47.3%, 77.3%)
11/16 09:48:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.1431	Prec@(1,5) (47.0%, 77.1%)
11/16 09:48:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.1290	Prec@(1,5) (47.3%, 77.4%)
11/16 09:48:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.1367	Prec@(1,5) (47.1%, 77.2%)
11/16 09:48:31午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 47.1040%
11/16 09:48:31午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:48:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1040%
11/16 09:49:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.0805 (1.0420)	Arch Loss 2.0644 (2.2130)	Arch Hard Loss 2.0585 (2.2075)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.4%)	
11/16 09:49:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.4046 (1.0573)	Arch Loss 2.5868 (2.2212)	Arch Hard Loss 2.5805 (2.2157)	Arch Alpha Loss 0.0126 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 93.1%)	
11/16 09:50:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0672 (1.0725)	Arch Loss 2.4722 (2.2193)	Arch Hard Loss 2.4663 (2.2138)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.7%)	
11/16 09:51:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.1106 (1.0857)	Arch Loss 2.5518 (2.2236)	Arch Hard Loss 2.5462 (2.2181)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.5%)	
11/16 09:51:21午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 67.5760%
11/16 09:51:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1773	Prec@(1,5) (45.9%, 76.7%)
11/16 09:51:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1733	Prec@(1,5) (46.5%, 76.9%)
11/16 09:51:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1839	Prec@(1,5) (46.4%, 76.8%)
11/16 09:51:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1716	Prec@(1,5) (46.7%, 77.1%)
11/16 09:51:48午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 46.6960%
11/16 09:51:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:51:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1040%
11/16 09:52:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 1.1656 (0.9833)	Arch Loss 2.4004 (2.2207)	Arch Hard Loss 2.3952 (2.2152)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.9%)	
11/16 09:53:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8778 (0.9897)	Arch Loss 2.0238 (2.2387)	Arch Hard Loss 2.0186 (2.2332)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.8%)	
11/16 09:53:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.4214 (1.0140)	Arch Loss 2.1901 (2.2530)	Arch Hard Loss 2.1850 (2.2475)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.5%)	
11/16 09:54:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.1009 (1.0224)	Arch Loss 2.3214 (2.2403)	Arch Hard Loss 2.3158 (2.2348)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
11/16 09:54:37午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 69.7920%
11/16 09:54:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.1378	Prec@(1,5) (47.4%, 77.6%)
11/16 09:54:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.1506	Prec@(1,5) (47.1%, 77.5%)
11/16 09:54:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.1507	Prec@(1,5) (47.1%, 77.3%)
11/16 09:55:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.1671	Prec@(1,5) (46.9%, 77.2%)
11/16 09:55:03午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 46.8960%
11/16 09:55:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:55:04午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1040%
11/16 09:55:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.9202 (0.9341)	Arch Loss 2.4210 (2.2446)	Arch Hard Loss 2.4151 (2.2390)	Arch Alpha Loss 0.0119 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.6%)	
11/16 09:56:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.9600 (0.9337)	Arch Loss 1.9359 (2.2537)	Arch Hard Loss 1.9305 (2.2482)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.5%)	
11/16 09:57:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 1.2093 (0.9460)	Arch Loss 1.7521 (2.2350)	Arch Hard Loss 1.7463 (2.2295)	Arch Alpha Loss 0.0117 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.3%)	
11/16 09:57:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8691 (0.9532)	Arch Loss 2.1577 (2.2260)	Arch Hard Loss 2.1524 (2.2204)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.2%)	
11/16 09:57:54午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 71.3960%
11/16 09:58:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1330	Prec@(1,5) (48.1%, 78.3%)
11/16 09:58:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1435	Prec@(1,5) (47.7%, 77.7%)
11/16 09:58:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1483	Prec@(1,5) (47.7%, 77.7%)
11/16 09:58:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1609	Prec@(1,5) (47.6%, 77.4%)
11/16 09:58:20午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 47.5960%
11/16 09:58:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 09:58:21午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.5960%
11/16 09:59:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.9046 (0.8512)	Arch Loss 2.2289 (2.2003)	Arch Hard Loss 2.2234 (2.1947)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.2%)	
11/16 09:59:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.8612 (0.8827)	Arch Loss 1.8869 (2.2339)	Arch Hard Loss 1.8817 (2.2283)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.8%)	
11/16 10:00:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.8913 (0.9005)	Arch Loss 1.9934 (2.2471)	Arch Hard Loss 1.9875 (2.2416)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
11/16 10:01:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.0861 (0.9080)	Arch Loss 2.5190 (2.2420)	Arch Hard Loss 2.5135 (2.2364)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.5%)	
11/16 10:01:11午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 72.9600%
11/16 10:01:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.2302	Prec@(1,5) (47.0%, 77.2%)
11/16 10:01:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.2025	Prec@(1,5) (47.0%, 77.1%)
11/16 10:01:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.1913	Prec@(1,5) (47.4%, 77.4%)
11/16 10:01:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.1856	Prec@(1,5) (47.5%, 77.5%)
11/16 10:01:38午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 47.4640%
11/16 10:01:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:01:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.5960%
11/16 10:02:22午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7534 (0.8220)	Arch Loss 2.3519 (2.3000)	Arch Hard Loss 2.3464 (2.2944)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.5%)	
11/16 10:03:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.9648 (0.8388)	Arch Loss 2.3755 (2.2660)	Arch Hard Loss 2.3699 (2.2605)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.3%)	
11/16 10:03:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.8178 (0.8510)	Arch Loss 2.0780 (2.2439)	Arch Hard Loss 2.0727 (2.2383)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.1%)	
11/16 10:04:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7204 (0.8559)	Arch Loss 2.3889 (2.2542)	Arch Hard Loss 2.3833 (2.2487)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.0%)	
11/16 10:04:27午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 74.3800%
11/16 10:04:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.2466	Prec@(1,5) (47.2%, 77.1%)
11/16 10:04:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.2382	Prec@(1,5) (47.4%, 77.1%)
11/16 10:04:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.2206	Prec@(1,5) (47.7%, 77.4%)
11/16 10:04:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.2072	Prec@(1,5) (47.7%, 77.5%)
11/16 10:04:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 47.7400%
11/16 10:04:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:04:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.7400%
11/16 10:05:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6825 (0.7852)	Arch Loss 1.7680 (2.2671)	Arch Hard Loss 1.7626 (2.2616)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.1%)	
11/16 10:06:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6542 (0.7971)	Arch Loss 2.4243 (2.2833)	Arch Hard Loss 2.4186 (2.2778)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.9%)	
11/16 10:07:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.9715 (0.8038)	Arch Loss 2.7983 (2.2740)	Arch Hard Loss 2.7927 (2.2685)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.8%)	
11/16 10:07:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.7213 (0.8038)	Arch Loss 2.3911 (2.2653)	Arch Hard Loss 2.3858 (2.2598)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
11/16 10:07:43午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 75.8280%
11/16 10:07:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.2184	Prec@(1,5) (47.9%, 76.9%)
11/16 10:07:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.2056	Prec@(1,5) (47.8%, 77.4%)
11/16 10:08:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.1898	Prec@(1,5) (48.3%, 77.6%)
11/16 10:08:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.2038	Prec@(1,5) (47.8%, 77.6%)
11/16 10:08:09午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 47.8080%
11/16 10:08:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:08:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8080%
11/16 10:08:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.8523 (0.7518)	Arch Loss 2.5779 (2.3194)	Arch Hard Loss 2.5718 (2.3139)	Arch Alpha Loss 0.0122 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.0%)	
11/16 10:09:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.8783 (0.7570)	Arch Loss 2.3810 (2.2626)	Arch Hard Loss 2.3753 (2.2571)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.0%)	
11/16 10:10:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7748 (0.7629)	Arch Loss 2.2285 (2.2755)	Arch Hard Loss 2.2232 (2.2700)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.0%)	
11/16 10:11:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.7749 (0.7677)	Arch Loss 2.3092 (2.2728)	Arch Hard Loss 2.3038 (2.2673)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.0%)	
11/16 10:11:00午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 77.0800%
11/16 10:11:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.2376	Prec@(1,5) (47.8%, 77.4%)
11/16 10:11:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.2351	Prec@(1,5) (48.3%, 77.4%)
11/16 10:11:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.2403	Prec@(1,5) (48.0%, 77.2%)
11/16 10:11:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.2220	Prec@(1,5) (48.2%, 77.6%)
11/16 10:11:27午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 48.1920%
11/16 10:11:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:11:27午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.1920%
11/16 10:12:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.6689 (0.7160)	Arch Loss 2.4377 (2.2492)	Arch Hard Loss 2.4324 (2.2437)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.7%)	
11/16 10:12:55午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.5809 (0.7062)	Arch Loss 1.6233 (2.2746)	Arch Hard Loss 1.6179 (2.2691)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.7%)	
11/16 10:13:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.7979 (0.7083)	Arch Loss 2.1150 (2.2932)	Arch Hard Loss 2.1095 (2.2876)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/16 10:14:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.8629 (0.7240)	Arch Loss 2.5834 (2.2972)	Arch Hard Loss 2.5782 (2.2917)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.5%)	
11/16 10:14:17午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 78.3080%
11/16 10:14:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.1470	Prec@(1,5) (49.2%, 78.5%)
11/16 10:14:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.1799	Prec@(1,5) (48.4%, 78.0%)
11/16 10:14:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.1890	Prec@(1,5) (48.3%, 78.0%)
11/16 10:14:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.2110	Prec@(1,5) (48.4%, 77.6%)
11/16 10:14:44午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 48.3760%
11/16 10:14:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:14:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3760%
11/16 10:15:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.6756 (0.6818)	Arch Loss 2.4367 (2.3461)	Arch Hard Loss 2.4308 (2.3406)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.1%)	
11/16 10:16:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5241 (0.6718)	Arch Loss 2.0998 (2.3081)	Arch Hard Loss 2.0945 (2.3026)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
11/16 10:16:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6532 (0.6790)	Arch Loss 2.3695 (2.3014)	Arch Hard Loss 2.3639 (2.2959)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
11/16 10:17:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.5832 (0.6820)	Arch Loss 2.3741 (2.2893)	Arch Hard Loss 2.3685 (2.2838)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.8%)	
11/16 10:17:33午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 79.7880%
11/16 10:17:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.2180	Prec@(1,5) (47.7%, 77.7%)
11/16 10:17:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.2211	Prec@(1,5) (48.2%, 77.6%)
11/16 10:17:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.2195	Prec@(1,5) (48.4%, 77.7%)
11/16 10:17:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.2368	Prec@(1,5) (48.1%, 77.7%)
11/16 10:17:59午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 48.0960%
11/16 10:17:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:17:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3760%
11/16 10:18:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.5350 (0.6469)	Arch Loss 2.2424 (2.2694)	Arch Hard Loss 2.2368 (2.2638)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.5%)	
11/16 10:19:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.8610 (0.6490)	Arch Loss 2.7324 (2.3047)	Arch Hard Loss 2.7269 (2.2992)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.4%)	
11/16 10:20:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5590 (0.6605)	Arch Loss 2.3595 (2.3080)	Arch Hard Loss 2.3541 (2.3025)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.2%)	
11/16 10:20:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6619 (0.6624)	Arch Loss 1.8079 (2.3072)	Arch Hard Loss 1.8028 (2.3016)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
11/16 10:20:49午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 80.0320%
11/16 10:20:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.2177	Prec@(1,5) (48.6%, 77.9%)
11/16 10:21:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.2666	Prec@(1,5) (47.9%, 77.4%)
11/16 10:21:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.2571	Prec@(1,5) (48.1%, 77.6%)
11/16 10:21:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.2518	Prec@(1,5) (48.1%, 77.7%)
11/16 10:21:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 48.0520%
11/16 10:21:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:21:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3760%
11/16 10:22:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.6236 (0.6171)	Arch Loss 1.8753 (2.3059)	Arch Hard Loss 1.8699 (2.3004)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.5%)	
11/16 10:22:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5061 (0.6183)	Arch Loss 2.7424 (2.3099)	Arch Hard Loss 2.7370 (2.3044)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.6%)	
11/16 10:23:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.6353 (0.6272)	Arch Loss 2.6252 (2.3302)	Arch Hard Loss 2.6200 (2.3246)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/16 10:24:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7475 (0.6381)	Arch Loss 2.0557 (2.3371)	Arch Hard Loss 2.0492 (2.3316)	Arch Alpha Loss 0.0131 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.3%)	
11/16 10:24:06午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 81.0480%
11/16 10:24:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.2357	Prec@(1,5) (48.8%, 77.7%)
11/16 10:24:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.2536	Prec@(1,5) (48.5%, 77.6%)
11/16 10:24:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.2591	Prec@(1,5) (48.1%, 77.7%)
11/16 10:24:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.2545	Prec@(1,5) (48.1%, 77.8%)
11/16 10:24:33午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 48.1200%
11/16 10:24:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:24:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3760%
11/16 10:25:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5341 (0.6035)	Arch Loss 1.7729 (2.2946)	Arch Hard Loss 1.7674 (2.2890)	Arch Alpha Loss 0.0108 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
11/16 10:26:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5188 (0.6127)	Arch Loss 2.1029 (2.3287)	Arch Hard Loss 2.0976 (2.3232)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/16 10:26:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.4677 (0.6171)	Arch Loss 2.3809 (2.3305)	Arch Hard Loss 2.3752 (2.3249)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.4%)	
11/16 10:27:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.7008 (0.6201)	Arch Loss 2.5328 (2.3340)	Arch Hard Loss 2.5270 (2.3284)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/16 10:27:25午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 81.4960%
11/16 10:27:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.2332	Prec@(1,5) (49.5%, 78.5%)
11/16 10:27:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.2493	Prec@(1,5) (49.1%, 77.9%)
11/16 10:27:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.2542	Prec@(1,5) (48.9%, 77.8%)
11/16 10:27:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.2668	Prec@(1,5) (48.5%, 77.7%)
11/16 10:27:52午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 48.5080%
11/16 10:27:52午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:27:52午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5080%
11/16 10:28:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4341 (0.5683)	Arch Loss 2.8698 (2.3409)	Arch Hard Loss 2.8645 (2.3354)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.7%)	
11/16 10:29:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.6866 (0.5939)	Arch Loss 2.7284 (2.3382)	Arch Hard Loss 2.7232 (2.3327)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.5%)	
11/16 10:30:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.6783 (0.5983)	Arch Loss 2.1707 (2.3587)	Arch Hard Loss 2.1651 (2.3532)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.5%)	
11/16 10:30:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.4341 (0.6012)	Arch Loss 2.2474 (2.3492)	Arch Hard Loss 2.2419 (2.3437)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.5%)	
11/16 10:30:44午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 82.1400%
11/16 10:30:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.2762	Prec@(1,5) (48.1%, 77.1%)
11/16 10:30:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.3026	Prec@(1,5) (48.0%, 77.2%)
11/16 10:31:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.2932	Prec@(1,5) (48.3%, 77.3%)
11/16 10:31:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.2755	Prec@(1,5) (48.4%, 77.5%)
11/16 10:31:10午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 48.3800%
11/16 10:31:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 10:31:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5080%
11/16 10:31:10午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 48.5080%
11/16 10:31:10午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
