11/15 10:02:56PM parser.py:28 [INFO] 
11/15 10:02:56PM parser.py:29 [INFO] Parameters:
11/15 10:02:56PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g1/DAG
11/15 10:02:56PM parser.py:31 [INFO] T=10.0
11/15 10:02:56PM parser.py:31 [INFO] ADVANCED=1
11/15 10:02:56PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/15 10:02:56PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/15 10:02:56PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/15 10:02:56PM parser.py:31 [INFO] BATCH_SIZE=64
11/15 10:02:56PM parser.py:31 [INFO] CASCADE=0
11/15 10:02:56PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/15 10:02:56PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/15 10:02:56PM parser.py:31 [INFO] DATA_PATH=../data/
11/15 10:02:56PM parser.py:31 [INFO] DATASET=cifar100
11/15 10:02:56PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/15 10:02:56PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/15 10:02:56PM parser.py:31 [INFO] DISCRETE=0
11/15 10:02:56PM parser.py:31 [INFO] EPOCHS=50
11/15 10:02:56PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/15 10:02:56PM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g1
11/15 10:02:56PM parser.py:31 [INFO] FINAL_L=1.0
11/15 10:02:56PM parser.py:31 [INFO] G=1.0
11/15 10:02:56PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/15 10:02:56PM parser.py:31 [INFO] GPUS=[0]
11/15 10:02:56PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/15 10:02:56PM parser.py:31 [INFO] INIT_CHANNELS=16
11/15 10:02:56PM parser.py:31 [INFO] L=1.0
11/15 10:02:56PM parser.py:31 [INFO] LAYERS=32
11/15 10:02:56PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/15 10:02:56PM parser.py:31 [INFO] NAME=Pruning
11/15 10:02:56PM parser.py:31 [INFO] NONKD=1
11/15 10:02:56PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g1
11/15 10:02:56PM parser.py:31 [INFO] PCDARTS=0
11/15 10:02:56PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g1/plots
11/15 10:02:56PM parser.py:31 [INFO] PRINT_FREQ=100
11/15 10:02:56PM parser.py:31 [INFO] RESET=0
11/15 10:02:56PM parser.py:31 [INFO] RESUME_PATH=None
11/15 10:02:56PM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g1
11/15 10:02:56PM parser.py:31 [INFO] SEED=0
11/15 10:02:56PM parser.py:31 [INFO] SHARE_STAGE=0
11/15 10:02:56PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/15 10:02:56PM parser.py:31 [INFO] SPEC_CELL=1
11/15 10:02:56PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/15 10:02:56PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/15 10:02:56PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/15 10:02:56PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/15 10:02:56PM parser.py:31 [INFO] TYPE=ArchKD
11/15 10:02:56PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/15 10:02:56PM parser.py:31 [INFO] W_LR=0.025
11/15 10:02:56PM parser.py:31 [INFO] W_LR_MIN=0.001
11/15 10:02:56PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/15 10:02:56PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/15 10:02:56PM parser.py:31 [INFO] WORKERS=4
11/15 10:02:56PM parser.py:32 [INFO] 
11/15 10:02:58PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/15 10:02:58PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/15 10:03:43PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6083 (4.7092)	Arch Loss 4.6353 (4.7189)	Arch Hard Loss 4.6242 (4.7070)	Arch Alpha Loss 0.0111 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.5%, 6.9%)	
11/15 10:04:26PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.3391 (4.6134)	Arch Loss 4.3760 (4.6251)	Arch Hard Loss 4.3646 (4.6137)	Arch Alpha Loss 0.0114 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 8.7%)	
11/15 10:05:10PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2910 (4.5217)	Arch Loss 4.5005 (4.5337)	Arch Hard Loss 4.4893 (4.5225)	Arch Alpha Loss 0.0112 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 10.8%)	
11/15 10:05:49PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2488 (4.4608)	Arch Loss 3.9801 (4.4677)	Arch Hard Loss 3.9694 (4.4566)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 12.3%)	
11/15 10:05:50PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 2.8080%
11/15 10:05:57PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.1921	Prec@(1,5) (4.8%, 18.0%)
11/15 10:06:04PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.1801	Prec@(1,5) (4.9%, 18.5%)
11/15 10:06:11PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.1893	Prec@(1,5) (4.9%, 18.6%)
11/15 10:06:17PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.1852	Prec@(1,5) (5.0%, 18.7%)
11/15 10:06:17PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 4.9560%
11/15 10:06:17PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:06:17PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 4.9560%
11/15 10:07:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.2955 (4.1776)	Arch Loss 4.2817 (4.1842)	Arch Hard Loss 4.2706 (4.1734)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.7%, 19.2%)	
11/15 10:07:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.1702 (4.1376)	Arch Loss 4.0841 (4.1525)	Arch Hard Loss 4.0732 (4.1416)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 20.8%)	
11/15 10:08:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9935 (4.1040)	Arch Loss 3.7886 (4.1122)	Arch Hard Loss 3.7777 (4.1013)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.9%, 21.9%)	
11/15 10:09:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.9139 (4.0876)	Arch Loss 3.8837 (4.0901)	Arch Hard Loss 3.8732 (4.0792)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.2%, 22.5%)	
11/15 10:09:09午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 6.1920%
11/15 10:09:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 4.0011	Prec@(1,5) (6.6%, 26.5%)
11/15 10:09:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 4.0343	Prec@(1,5) (6.5%, 25.9%)
11/15 10:09:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 4.0286	Prec@(1,5) (6.6%, 26.1%)
11/15 10:09:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 4.0287	Prec@(1,5) (6.8%, 26.2%)
11/15 10:09:36午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 6.7640%
11/15 10:09:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/15 10:09:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 6.7640%
11/15 10:10:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.9779 (3.9491)	Arch Loss 4.1057 (3.9986)	Arch Hard Loss 4.0949 (3.9878)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.8%, 26.9%)	
11/15 10:11:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8944 (3.9389)	Arch Loss 3.7784 (3.9529)	Arch Hard Loss 3.7675 (3.9421)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.0%, 27.4%)	
11/15 10:11:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.9986 (3.9237)	Arch Loss 3.9371 (3.9239)	Arch Hard Loss 3.9259 (3.9131)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.2%, 28.2%)	
11/15 10:12:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.8423 (3.9001)	Arch Loss 3.6776 (3.9016)	Arch Hard Loss 3.6668 (3.8908)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.5%, 29.1%)	
11/15 10:12:28午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 8.5560%
11/15 10:12:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.8344	Prec@(1,5) (9.1%, 32.4%)
11/15 10:12:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.8319	Prec@(1,5) (9.2%, 32.4%)
11/15 10:12:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.8303	Prec@(1,5) (9.1%, 32.1%)
11/15 10:12:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.8270	Prec@(1,5) (9.3%, 32.2%)
11/15 10:12:55午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.2560%
11/15 10:12:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/15 10:12:55午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.2560%
11/15 10:13:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5570 (3.7729)	Arch Loss 3.6151 (3.8156)	Arch Hard Loss 3.6047 (3.8049)	Arch Alpha Loss 0.0104 (0.0107)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (10.5%, 33.3%)	
11/15 10:14:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7422 (3.7721)	Arch Loss 3.6453 (3.7932)	Arch Hard Loss 3.6349 (3.7825)	Arch Alpha Loss 0.0104 (0.0107)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (10.7%, 33.3%)	
11/15 10:15:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.7734 (3.7568)	Arch Loss 4.1548 (3.7734)	Arch Hard Loss 4.1445 (3.7627)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.9%, 33.8%)	
11/15 10:15:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6972 (3.7461)	Arch Loss 3.7734 (3.7548)	Arch Hard Loss 3.7630 (3.7441)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.0%, 34.1%)	
11/15 10:15:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 11.0400%
11/15 10:15:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.7306	Prec@(1,5) (11.9%, 35.4%)
11/15 10:16:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.7211	Prec@(1,5) (11.8%, 35.4%)
11/15 10:16:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.7110	Prec@(1,5) (11.6%, 35.5%)
11/15 10:16:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.7121	Prec@(1,5) (11.7%, 35.5%)
11/15 10:16:13午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 11.7000%
11/15 10:16:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/15 10:16:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 11.7000%
11/15 10:16:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.5261 (3.6357)	Arch Loss 4.0455 (3.6556)	Arch Hard Loss 4.0340 (3.6446)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.2%, 37.3%)	
11/15 10:17:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.8354 (3.6355)	Arch Loss 3.7542 (3.6341)	Arch Hard Loss 3.7428 (3.6232)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.0%, 37.1%)	
11/15 10:18:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.3832 (3.6180)	Arch Loss 3.3542 (3.6178)	Arch Hard Loss 3.3425 (3.6069)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.4%, 37.8%)	
11/15 10:19:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.8324 (3.6042)	Arch Loss 3.8441 (3.6117)	Arch Hard Loss 3.8320 (3.6008)	Arch Alpha Loss 0.0121 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.5%, 38.3%)	
11/15 10:19:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.5280%
11/15 10:19:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5232	Prec@(1,5) (14.7%, 41.7%)
11/15 10:19:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5335	Prec@(1,5) (14.7%, 41.0%)
11/15 10:19:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5436	Prec@(1,5) (14.7%, 40.7%)
11/15 10:19:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5436	Prec@(1,5) (14.7%, 40.9%)
11/15 10:19:31午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.7400%
11/15 10:19:31午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 10:19:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.7400%
11/15 10:20:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.7442 (3.5265)	Arch Loss 3.6715 (3.5440)	Arch Hard Loss 3.6617 (3.5330)	Arch Alpha Loss 0.0097 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.4%, 41.3%)	
11/15 10:20:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.4943 (3.5288)	Arch Loss 3.5263 (3.5401)	Arch Hard Loss 3.5165 (3.5293)	Arch Alpha Loss 0.0099 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.2%, 40.8%)	
11/15 10:21:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.2724 (3.5055)	Arch Loss 3.7377 (3.5201)	Arch Hard Loss 3.7276 (3.5093)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 41.6%)	
11/15 10:22:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.5102 (3.4932)	Arch Loss 3.4920 (3.5130)	Arch Hard Loss 3.4821 (3.5022)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.8%)	
11/15 10:22:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 15.2360%
11/15 10:22:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.5646	Prec@(1,5) (14.5%, 41.2%)
11/15 10:22:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.5713	Prec@(1,5) (14.4%, 40.6%)
11/15 10:22:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.5658	Prec@(1,5) (14.5%, 40.7%)
11/15 10:22:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.5725	Prec@(1,5) (14.5%, 40.5%)
11/15 10:22:49午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 14.4920%
11/15 10:22:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 10:22:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.7400%
11/15 10:23:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.9854 (3.3910)	Arch Loss 3.4074 (3.4414)	Arch Hard Loss 3.3961 (3.4306)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.5%, 43.9%)	
11/15 10:24:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.3537 (3.3964)	Arch Loss 3.6904 (3.4406)	Arch Hard Loss 3.6788 (3.4298)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 43.7%)	
11/15 10:25:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.4117 (3.3916)	Arch Loss 3.5470 (3.4199)	Arch Hard Loss 3.5353 (3.4091)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 43.9%)	
11/15 10:25:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.5997 (3.3792)	Arch Loss 3.2392 (3.4060)	Arch Hard Loss 3.2274 (3.3952)	Arch Alpha Loss 0.0118 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.7%, 44.3%)	
11/15 10:25:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.6600%
11/15 10:25:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.3814	Prec@(1,5) (17.5%, 44.7%)
11/15 10:25:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3914	Prec@(1,5) (17.5%, 44.8%)
11/15 10:26:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.4016	Prec@(1,5) (17.4%, 44.7%)
11/15 10:26:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.3977	Prec@(1,5) (17.4%, 45.0%)
11/15 10:26:07午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 17.4320%
11/15 10:26:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 10:26:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.4320%
11/15 10:26:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.3819 (3.3005)	Arch Loss 3.4950 (3.3566)	Arch Hard Loss 3.4856 (3.3460)	Arch Alpha Loss 0.0094 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.7%, 47.5%)	
11/15 10:27:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.5394 (3.2916)	Arch Loss 3.4356 (3.3606)	Arch Hard Loss 3.4260 (3.3500)	Arch Alpha Loss 0.0096 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 47.5%)	
11/15 10:28:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.3257 (3.2768)	Arch Loss 2.9226 (3.3362)	Arch Hard Loss 2.9127 (3.3256)	Arch Alpha Loss 0.0100 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.4%, 47.8%)	
11/15 10:28:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.1396 (3.2677)	Arch Loss 3.4688 (3.3266)	Arch Hard Loss 3.4593 (3.3160)	Arch Alpha Loss 0.0095 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 48.0%)	
11/15 10:28:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 19.5120%
11/15 10:29:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.2727	Prec@(1,5) (19.9%, 47.4%)
11/15 10:29:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.2664	Prec@(1,5) (19.7%, 47.8%)
11/15 10:29:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.2638	Prec@(1,5) (19.5%, 48.1%)
11/15 10:29:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.2607	Prec@(1,5) (19.7%, 48.3%)
11/15 10:29:25午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 19.6960%
11/15 10:29:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/15 10:29:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.6960%
11/15 10:30:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.0809 (3.1676)	Arch Loss 3.3110 (3.2644)	Arch Hard Loss 3.2985 (3.2535)	Arch Alpha Loss 0.0125 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.2%, 50.9%)	
11/15 10:30:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.2165 (3.1911)	Arch Loss 3.0181 (3.2608)	Arch Hard Loss 3.0058 (3.2499)	Arch Alpha Loss 0.0124 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.4%)	
11/15 10:31:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.1303 (3.1811)	Arch Loss 3.2652 (3.2569)	Arch Hard Loss 3.2527 (3.2460)	Arch Alpha Loss 0.0125 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.1%)	
11/15 10:32:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.2330 (3.1738)	Arch Loss 3.2455 (3.2378)	Arch Hard Loss 3.2331 (3.2270)	Arch Alpha Loss 0.0124 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.1%, 50.4%)	
11/15 10:32:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 21.1240%
11/15 10:32:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1898	Prec@(1,5) (21.3%, 49.6%)
11/15 10:32:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1979	Prec@(1,5) (21.1%, 50.0%)
11/15 10:32:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1929	Prec@(1,5) (21.2%, 50.2%)
11/15 10:32:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1973	Prec@(1,5) (21.1%, 50.0%)
11/15 10:32:42午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 21.0880%
11/15 10:32:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/15 10:32:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.0880%
11/15 10:33:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.8960 (3.0774)	Arch Loss 2.9746 (3.1824)	Arch Hard Loss 2.9647 (3.1714)	Arch Alpha Loss 0.0099 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 53.4%)	
11/15 10:34:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.2691 (3.0737)	Arch Loss 2.9992 (3.1769)	Arch Hard Loss 2.9887 (3.1659)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.7%, 53.0%)	
11/15 10:34:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.3750 (3.0724)	Arch Loss 3.1304 (3.1643)	Arch Hard Loss 3.1200 (3.1534)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 53.2%)	
11/15 10:35:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.9007 (3.0764)	Arch Loss 2.9197 (3.1511)	Arch Hard Loss 2.9087 (3.1401)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 53.1%)	
11/15 10:35:34午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 22.7680%
11/15 10:35:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.1238	Prec@(1,5) (22.1%, 52.3%)
11/15 10:35:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.1041	Prec@(1,5) (22.3%, 53.0%)
11/15 10:35:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.1215	Prec@(1,5) (22.0%, 52.6%)
11/15 10:36:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.1308	Prec@(1,5) (22.1%, 52.3%)
11/15 10:36:00午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 22.0880%
11/15 10:36:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/15 10:36:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.0880%
11/15 10:36:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9460 (2.9756)	Arch Loss 2.9529 (3.0876)	Arch Hard Loss 2.9415 (3.0766)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.9%, 55.8%)	
11/15 10:37:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 3.0964 (2.9910)	Arch Loss 3.2711 (3.0953)	Arch Hard Loss 3.2596 (3.0843)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.6%)	
11/15 10:38:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.6356 (2.9946)	Arch Loss 2.7433 (3.0924)	Arch Hard Loss 2.7322 (3.0814)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.4%)	
11/15 10:38:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.7675 (2.9845)	Arch Loss 3.1208 (3.0776)	Arch Hard Loss 3.1099 (3.0667)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.0%, 55.5%)	
11/15 10:38:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 24.9560%
11/15 10:38:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.0774	Prec@(1,5) (24.6%, 54.0%)
11/15 10:39:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.0400	Prec@(1,5) (24.9%, 54.7%)
11/15 10:39:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 3.0365	Prec@(1,5) (25.2%, 54.8%)
11/15 10:39:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 3.0415	Prec@(1,5) (25.1%, 54.8%)
11/15 10:39:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 25.0760%
11/15 10:39:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:39:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.0760%
11/15 10:40:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.9432 (2.8914)	Arch Loss 3.0397 (3.0286)	Arch Hard Loss 3.0292 (3.0180)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 57.8%)	
11/15 10:40:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.9337 (2.9026)	Arch Loss 2.8351 (3.0099)	Arch Hard Loss 2.8243 (2.9993)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.3%, 57.5%)	
11/15 10:41:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 3.0453 (2.9033)	Arch Loss 2.9811 (3.0049)	Arch Hard Loss 2.9701 (2.9941)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.6%, 57.5%)	
11/15 10:42:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 3.0382 (2.8962)	Arch Loss 2.4966 (2.9940)	Arch Hard Loss 2.4857 (2.9832)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 57.6%)	
11/15 10:42:09午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 26.7080%
11/15 10:42:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.9160	Prec@(1,5) (27.0%, 57.5%)
11/15 10:42:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.9306	Prec@(1,5) (26.7%, 57.0%)
11/15 10:42:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9245	Prec@(1,5) (26.7%, 57.1%)
11/15 10:42:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.9188	Prec@(1,5) (26.7%, 57.3%)
11/15 10:42:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 26.6880%
11/15 10:42:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:42:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.6880%
11/15 10:43:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4510 (2.8140)	Arch Loss 2.7666 (2.9574)	Arch Hard Loss 2.7555 (2.9464)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.6%, 60.0%)	
11/15 10:44:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.8716 (2.8023)	Arch Loss 2.7369 (2.9491)	Arch Hard Loss 2.7260 (2.9381)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 60.0%)	
11/15 10:44:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.7502 (2.8081)	Arch Loss 3.1886 (2.9419)	Arch Hard Loss 3.1775 (2.9309)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.1%, 59.9%)	
11/15 10:45:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.9408 (2.8081)	Arch Loss 2.7992 (2.9369)	Arch Hard Loss 2.7886 (2.9259)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.2%, 59.9%)	
11/15 10:45:27午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 28.2080%
11/15 10:45:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.9265	Prec@(1,5) (26.6%, 57.6%)
11/15 10:45:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.9408	Prec@(1,5) (26.6%, 57.2%)
11/15 10:45:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.9433	Prec@(1,5) (26.6%, 57.2%)
11/15 10:45:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.9509	Prec@(1,5) (26.4%, 57.1%)
11/15 10:45:54午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 26.4440%
11/15 10:45:54午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:45:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.6880%
11/15 10:46:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.5884 (2.7295)	Arch Loss 2.8866 (2.9007)	Arch Hard Loss 2.8751 (2.8897)	Arch Alpha Loss 0.0115 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.9%, 62.0%)	
11/15 10:47:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.9600 (2.7419)	Arch Loss 2.8568 (2.8934)	Arch Hard Loss 2.8456 (2.8824)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 61.4%)	
11/15 10:48:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.7957 (2.7307)	Arch Loss 2.4775 (2.8825)	Arch Hard Loss 2.4668 (2.8715)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.8%, 61.8%)	
11/15 10:48:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.2549 (2.7273)	Arch Loss 2.7954 (2.8836)	Arch Hard Loss 2.7845 (2.8726)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 61.7%)	
11/15 10:48:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 30.1200%
11/15 10:48:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.8427	Prec@(1,5) (28.9%, 59.3%)
11/15 10:49:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8412	Prec@(1,5) (29.0%, 59.6%)
11/15 10:49:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.8488	Prec@(1,5) (28.7%, 59.3%)
11/15 10:49:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.8432	Prec@(1,5) (28.7%, 59.5%)
11/15 10:49:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 28.7560%
11/15 10:49:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:49:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.7560%
11/15 10:49:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 3.0165 (2.6253)	Arch Loss 2.9674 (2.8425)	Arch Hard Loss 2.9569 (2.8314)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.5%, 63.9%)	
11/15 10:50:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.9449 (2.6363)	Arch Loss 2.9187 (2.8446)	Arch Hard Loss 2.9080 (2.8336)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.9%, 63.8%)	
11/15 10:51:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.7419 (2.6468)	Arch Loss 2.7030 (2.8335)	Arch Hard Loss 2.6919 (2.8225)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.5%, 63.7%)	
11/15 10:52:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.8256 (2.6472)	Arch Loss 2.7415 (2.8309)	Arch Hard Loss 2.7301 (2.8198)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 63.8%)	
11/15 10:52:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 31.4240%
11/15 10:52:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.7639	Prec@(1,5) (29.0%, 60.9%)
11/15 10:52:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.7649	Prec@(1,5) (29.6%, 60.8%)
11/15 10:52:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.7662	Prec@(1,5) (29.6%, 60.7%)
11/15 10:52:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.7740	Prec@(1,5) (29.5%, 60.6%)
11/15 10:52:32午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 29.5320%
11/15 10:52:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:52:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.5320%
11/15 10:53:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.4108 (2.5405)	Arch Loss 2.7915 (2.7982)	Arch Hard Loss 2.7816 (2.7873)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.3%, 66.1%)	
11/15 10:53:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.2330 (2.5667)	Arch Loss 2.7469 (2.7872)	Arch Hard Loss 2.7366 (2.7763)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.7%, 65.4%)	
11/15 10:54:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.2857 (2.5738)	Arch Loss 2.7691 (2.7749)	Arch Hard Loss 2.7594 (2.7640)	Arch Alpha Loss 0.0096 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.4%, 65.2%)	
11/15 10:55:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.4119 (2.5798)	Arch Loss 2.5205 (2.7707)	Arch Hard Loss 2.5105 (2.7599)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.2%, 65.1%)	
11/15 10:55:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 33.2000%
11/15 10:55:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.8224	Prec@(1,5) (28.8%, 60.4%)
11/15 10:55:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.7954	Prec@(1,5) (29.2%, 60.9%)
11/15 10:55:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.7986	Prec@(1,5) (29.2%, 60.6%)
11/15 10:55:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.7932	Prec@(1,5) (29.3%, 60.6%)
11/15 10:55:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 29.2920%
11/15 10:55:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:55:50午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.5320%
11/15 10:56:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.3826 (2.4432)	Arch Loss 2.8557 (2.7376)	Arch Hard Loss 2.8440 (2.7265)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 68.5%)	
11/15 10:57:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.2833 (2.4762)	Arch Loss 2.8414 (2.7288)	Arch Hard Loss 2.8301 (2.7177)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.7%)	
11/15 10:58:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.8030 (2.4938)	Arch Loss 2.5159 (2.7246)	Arch Hard Loss 2.5040 (2.7136)	Arch Alpha Loss 0.0119 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.3%)	
11/15 10:58:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.5484 (2.4966)	Arch Loss 2.6644 (2.7168)	Arch Hard Loss 2.6524 (2.7057)	Arch Alpha Loss 0.0120 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.6%, 67.2%)	
11/15 10:58:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 34.6160%
11/15 10:58:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.7334	Prec@(1,5) (30.7%, 62.1%)
11/15 10:58:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.7574	Prec@(1,5) (30.4%, 61.7%)
11/15 10:58:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.7520	Prec@(1,5) (30.5%, 61.9%)
11/15 10:59:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.7500	Prec@(1,5) (30.5%, 61.9%)
11/15 10:59:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 30.5120%
11/15 10:59:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 10:59:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.5120%
11/15 10:59:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.1804 (2.4474)	Arch Loss 2.8551 (2.7216)	Arch Hard Loss 2.8447 (2.7102)	Arch Alpha Loss 0.0104 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 68.0%)	
11/15 11:00:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.2698 (2.4413)	Arch Loss 2.8202 (2.6985)	Arch Hard Loss 2.8096 (2.6873)	Arch Alpha Loss 0.0106 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.5%)	
11/15 11:01:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.2906 (2.4335)	Arch Loss 2.4117 (2.6953)	Arch Hard Loss 2.4011 (2.6842)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 68.5%)	
11/15 11:01:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.2710 (2.4369)	Arch Loss 2.7311 (2.6816)	Arch Hard Loss 2.7206 (2.6706)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.4%)	
11/15 11:01:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 36.2320%
11/15 11:02:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.6028	Prec@(1,5) (33.5%, 64.9%)
11/15 11:02:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.6029	Prec@(1,5) (33.7%, 65.2%)
11/15 11:02:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.6269	Prec@(1,5) (33.0%, 64.8%)
11/15 11:02:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.6360	Prec@(1,5) (32.8%, 64.5%)
11/15 11:02:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 32.7760%
11/15 11:02:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:02:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.7760%
11/15 11:03:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.5307 (2.3684)	Arch Loss 2.6270 (2.6461)	Arch Hard Loss 2.6163 (2.6352)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.7%)	
11/15 11:03:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.5048 (2.3645)	Arch Loss 2.5764 (2.6609)	Arch Hard Loss 2.5664 (2.6501)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.2%)	
11/15 11:04:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.3643 (2.3651)	Arch Loss 2.0936 (2.6402)	Arch Hard Loss 2.0829 (2.6293)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 70.0%)	
11/15 11:05:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.3447 (2.3765)	Arch Loss 2.2845 (2.6279)	Arch Hard Loss 2.2734 (2.6170)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.7%)	
11/15 11:05:14午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 37.4960%
11/15 11:05:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5318	Prec@(1,5) (34.7%, 66.8%)
11/15 11:05:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5601	Prec@(1,5) (34.4%, 66.1%)
11/15 11:05:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5560	Prec@(1,5) (34.3%, 66.0%)
11/15 11:05:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5455	Prec@(1,5) (34.5%, 66.3%)
11/15 11:05:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 34.5280%
11/15 11:05:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:05:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5280%
11/15 11:06:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.2467 (2.2460)	Arch Loss 2.7266 (2.6021)	Arch Hard Loss 2.7153 (2.5912)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.3%)	
11/15 11:07:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.9940 (2.2692)	Arch Loss 2.4960 (2.5813)	Arch Hard Loss 2.4848 (2.5704)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.2%)	
11/15 11:07:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.3508 (2.2873)	Arch Loss 2.3445 (2.5905)	Arch Hard Loss 2.3335 (2.5795)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.7%)	
11/15 11:08:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.3256 (2.3010)	Arch Loss 2.2118 (2.5928)	Arch Hard Loss 2.2004 (2.5818)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 71.4%)	
11/15 11:08:32午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 38.4520%
11/15 11:08:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.5756	Prec@(1,5) (34.3%, 65.5%)
11/15 11:08:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.5705	Prec@(1,5) (34.3%, 65.5%)
11/15 11:08:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.5671	Prec@(1,5) (34.1%, 65.7%)
11/15 11:08:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.5682	Prec@(1,5) (34.2%, 65.6%)
11/15 11:08:59午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 34.1800%
11/15 11:08:59午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:08:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5280%
11/15 11:09:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 2.0417 (2.2059)	Arch Loss 2.6911 (2.5362)	Arch Hard Loss 2.6798 (2.5252)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 72.9%)	
11/15 11:10:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.7386 (2.2215)	Arch Loss 2.5225 (2.5488)	Arch Hard Loss 2.5113 (2.5379)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 72.8%)	
11/15 11:11:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.2353 (2.2296)	Arch Loss 2.4816 (2.5519)	Arch Hard Loss 2.4704 (2.5410)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 72.8%)	
11/15 11:11:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.8267 (2.2414)	Arch Loss 2.6335 (2.5472)	Arch Hard Loss 2.6228 (2.5363)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.6%)	
11/15 11:11:49午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 40.0240%
11/15 11:11:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.4823	Prec@(1,5) (35.7%, 68.3%)
11/15 11:12:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.5186	Prec@(1,5) (35.6%, 67.5%)
11/15 11:12:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.5195	Prec@(1,5) (35.4%, 67.5%)
11/15 11:12:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.5168	Prec@(1,5) (35.4%, 67.4%)
11/15 11:12:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 35.3480%
11/15 11:12:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:12:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.3480%
11/15 11:13:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.4405 (2.0907)	Arch Loss 2.3428 (2.5713)	Arch Hard Loss 2.3312 (2.5603)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.5%)	
11/15 11:13:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.3168 (2.1465)	Arch Loss 2.4484 (2.5604)	Arch Hard Loss 2.4366 (2.5494)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 74.4%)	
11/15 11:14:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 2.0085 (2.1643)	Arch Loss 2.4425 (2.5409)	Arch Hard Loss 2.4312 (2.5298)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.2%)	
11/15 11:15:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.3209 (2.1650)	Arch Loss 2.6460 (2.5257)	Arch Hard Loss 2.6349 (2.5146)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.2%)	
11/15 11:15:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 41.6800%
11/15 11:15:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.4903	Prec@(1,5) (36.1%, 67.5%)
11/15 11:15:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4653	Prec@(1,5) (36.5%, 68.1%)
11/15 11:15:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4622	Prec@(1,5) (36.5%, 68.3%)
11/15 11:15:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4583	Prec@(1,5) (36.5%, 68.3%)
11/15 11:15:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 36.4720%
11/15 11:15:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:15:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.4720%
11/15 11:16:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 2.1213 (2.0833)	Arch Loss 2.4640 (2.4932)	Arch Hard Loss 2.4530 (2.4822)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.5%)	
11/15 11:17:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.9023 (2.0917)	Arch Loss 2.5487 (2.4993)	Arch Hard Loss 2.5375 (2.4883)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.0%)	
11/15 11:17:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 2.2546 (2.1031)	Arch Loss 2.3910 (2.4978)	Arch Hard Loss 2.3791 (2.4869)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.6%)	
11/15 11:18:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7136 (2.1168)	Arch Loss 2.3653 (2.4906)	Arch Hard Loss 2.3544 (2.4796)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.3%)	
11/15 11:18:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 42.9760%
11/15 11:18:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.4839	Prec@(1,5) (37.0%, 68.4%)
11/15 11:18:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.4634	Prec@(1,5) (37.5%, 68.7%)
11/15 11:18:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.4600	Prec@(1,5) (37.3%, 68.6%)
11/15 11:18:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.4493	Prec@(1,5) (37.3%, 68.8%)
11/15 11:18:50午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 37.3200%
11/15 11:18:50午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:18:50午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.3200%
11/15 11:19:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 2.0695 (1.9848)	Arch Loss 2.3380 (2.4672)	Arch Hard Loss 2.3270 (2.4564)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 77.9%)	
11/15 11:20:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.9921 (2.0133)	Arch Loss 2.1107 (2.4568)	Arch Hard Loss 2.0999 (2.4460)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 77.5%)	
11/15 11:21:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.0512 (2.0374)	Arch Loss 2.4799 (2.4602)	Arch Hard Loss 2.4687 (2.4494)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.0%)	
11/15 11:21:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.1031 (2.0449)	Arch Loss 2.4781 (2.4573)	Arch Hard Loss 2.4679 (2.4466)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 76.9%)	
11/15 11:21:42午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 44.6320%
11/15 11:21:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.4175	Prec@(1,5) (38.1%, 69.7%)
11/15 11:21:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.4140	Prec@(1,5) (38.0%, 69.6%)
11/15 11:22:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.4150	Prec@(1,5) (38.1%, 69.4%)
11/15 11:22:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.4103	Prec@(1,5) (38.2%, 69.5%)
11/15 11:22:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 38.2120%
11/15 11:22:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:22:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2120%
11/15 11:22:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.9279 (1.9288)	Arch Loss 2.3360 (2.4094)	Arch Hard Loss 2.3248 (2.3987)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 79.0%)	
11/15 11:23:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 2.6402 (1.9526)	Arch Loss 2.2641 (2.4178)	Arch Hard Loss 2.2527 (2.4071)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.4%)	
11/15 11:24:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.8383 (1.9709)	Arch Loss 2.2469 (2.4232)	Arch Hard Loss 2.2360 (2.4125)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 77.9%)	
11/15 11:24:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.1623 (1.9813)	Arch Loss 2.2734 (2.4282)	Arch Hard Loss 2.2623 (2.4174)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.7%, 77.7%)	
11/15 11:25:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 45.6840%
11/15 11:25:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.4290	Prec@(1,5) (37.0%, 69.1%)
11/15 11:25:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.4296	Prec@(1,5) (37.3%, 68.8%)
11/15 11:25:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.4372	Prec@(1,5) (37.5%, 68.9%)
11/15 11:25:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.4290	Prec@(1,5) (37.8%, 69.1%)
11/15 11:25:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 37.8160%
11/15 11:25:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:25:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2120%
11/15 11:26:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.8437 (1.8719)	Arch Loss 1.9515 (2.3950)	Arch Hard Loss 1.9412 (2.3841)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 79.8%)	
11/15 11:26:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 2.1043 (1.9000)	Arch Loss 2.7281 (2.3980)	Arch Hard Loss 2.7178 (2.3873)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.5%)	
11/15 11:27:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.7606 (1.9085)	Arch Loss 2.7775 (2.4060)	Arch Hard Loss 2.7668 (2.3952)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.3%)	
11/15 11:28:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.9080 (1.9232)	Arch Loss 2.8889 (2.3973)	Arch Hard Loss 2.8781 (2.3864)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.4%, 79.0%)	
11/15 11:28:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 47.3240%
11/15 11:28:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.3478	Prec@(1,5) (39.4%, 71.2%)
11/15 11:28:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.3776	Prec@(1,5) (38.9%, 70.4%)
11/15 11:28:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.3799	Prec@(1,5) (38.9%, 70.5%)
11/15 11:28:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.3722	Prec@(1,5) (39.1%, 70.6%)
11/15 11:28:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 39.0680%
11/15 11:28:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:28:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.0680%
11/15 11:29:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.4808 (1.8385)	Arch Loss 2.7345 (2.4059)	Arch Hard Loss 2.7236 (2.3950)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.2%)	
11/15 11:30:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.8490 (1.8427)	Arch Loss 2.5351 (2.3987)	Arch Hard Loss 2.5244 (2.3879)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.3%)	
11/15 11:30:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 2.0065 (1.8634)	Arch Loss 2.7640 (2.3799)	Arch Hard Loss 2.7530 (2.3692)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.0%)	
11/15 11:31:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.5482 (1.8688)	Arch Loss 2.3672 (2.3753)	Arch Hard Loss 2.3561 (2.3646)	Arch Alpha Loss 0.0111 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.0%)	
11/15 11:31:34午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 48.5360%
11/15 11:31:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2632	Prec@(1,5) (40.8%, 72.8%)
11/15 11:31:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.2900	Prec@(1,5) (40.9%, 72.3%)
11/15 11:31:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.3077	Prec@(1,5) (40.6%, 72.0%)
11/15 11:32:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.3077	Prec@(1,5) (40.6%, 72.0%)
11/15 11:32:00午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 40.6000%
11/15 11:32:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:32:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.6000%
11/15 11:32:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.4753 (1.7202)	Arch Loss 2.3164 (2.3750)	Arch Hard Loss 2.3056 (2.3641)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.5%)	
11/15 11:33:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 2.2233 (1.7541)	Arch Loss 2.2686 (2.3538)	Arch Hard Loss 2.2579 (2.3429)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
11/15 11:34:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.7012 (1.7747)	Arch Loss 1.9704 (2.3618)	Arch Hard Loss 1.9593 (2.3510)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.8%)	
11/15 11:34:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.8230 (1.7904)	Arch Loss 2.0833 (2.3675)	Arch Hard Loss 2.0719 (2.3566)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.6%)	
11/15 11:34:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 50.0760%
11/15 11:34:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.3105	Prec@(1,5) (41.2%, 72.0%)
11/15 11:35:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.2854	Prec@(1,5) (41.3%, 72.4%)
11/15 11:35:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.3065	Prec@(1,5) (41.0%, 72.2%)
11/15 11:35:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.3213	Prec@(1,5) (40.6%, 71.9%)
11/15 11:35:17午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 40.5280%
11/15 11:35:17午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:35:17午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.6000%
11/15 11:36:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.5062 (1.6969)	Arch Loss 2.7451 (2.3645)	Arch Hard Loss 2.7336 (2.3536)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 82.9%)	
11/15 11:36:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5600 (1.7026)	Arch Loss 2.3060 (2.3472)	Arch Hard Loss 2.2945 (2.3363)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.1%)	
11/15 11:37:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.9714 (1.7162)	Arch Loss 2.4549 (2.3418)	Arch Hard Loss 2.4438 (2.3309)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 82.8%)	
11/15 11:38:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.6641 (1.7311)	Arch Loss 2.1279 (2.3331)	Arch Hard Loss 2.1163 (2.3223)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.6%, 82.5%)	
11/15 11:38:07午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 51.6520%
11/15 11:38:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.3350	Prec@(1,5) (40.7%, 72.3%)
11/15 11:38:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.3176	Prec@(1,5) (40.7%, 72.4%)
11/15 11:38:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.3215	Prec@(1,5) (40.7%, 72.3%)
11/15 11:38:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.3200	Prec@(1,5) (40.7%, 72.3%)
11/15 11:38:34午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 40.6680%
11/15 11:38:34午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:38:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.6680%
11/15 11:39:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.7953 (1.6149)	Arch Loss 1.8695 (2.3287)	Arch Hard Loss 1.8593 (2.3179)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 85.2%)	
11/15 11:40:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.4548 (1.6217)	Arch Loss 2.4123 (2.3476)	Arch Hard Loss 2.4007 (2.3367)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.8%)	
11/15 11:40:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.7235 (1.6485)	Arch Loss 2.4308 (2.3475)	Arch Hard Loss 2.4189 (2.3365)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.3%, 84.3%)	
11/15 11:41:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.5313 (1.6683)	Arch Loss 2.3385 (2.3309)	Arch Hard Loss 2.3266 (2.3200)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.8%)	
11/15 11:41:25午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 52.8320%
11/15 11:41:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.2538	Prec@(1,5) (42.5%, 73.1%)
11/15 11:41:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.2551	Prec@(1,5) (42.5%, 73.0%)
11/15 11:41:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2736	Prec@(1,5) (42.1%, 72.6%)
11/15 11:41:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2669	Prec@(1,5) (42.1%, 72.7%)
11/15 11:41:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 42.1120%
11/15 11:41:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:41:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.1120%
11/15 11:42:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.3840 (1.5500)	Arch Loss 2.4523 (2.3078)	Arch Hard Loss 2.4416 (2.2969)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.4%, 85.6%)	
11/15 11:43:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.6636 (1.5712)	Arch Loss 2.1630 (2.3039)	Arch Hard Loss 2.1522 (2.2929)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.2%)	
11/15 11:44:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.5163 (1.5868)	Arch Loss 2.1377 (2.2934)	Arch Hard Loss 2.1273 (2.2824)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.8%)	
11/15 11:44:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.6253 (1.6071)	Arch Loss 2.1100 (2.2957)	Arch Hard Loss 2.0993 (2.2848)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.3%, 84.5%)	
11/15 11:44:42午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 54.3360%
11/15 11:44:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.2670	Prec@(1,5) (42.2%, 73.5%)
11/15 11:44:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.2717	Prec@(1,5) (42.0%, 73.5%)
11/15 11:45:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.2621	Prec@(1,5) (42.2%, 73.4%)
11/15 11:45:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.2679	Prec@(1,5) (42.1%, 73.3%)
11/15 11:45:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 42.0480%
11/15 11:45:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:45:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.1120%
11/15 11:45:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.7238 (1.4805)	Arch Loss 1.9922 (2.2656)	Arch Hard Loss 1.9813 (2.2548)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 87.2%)	
11/15 11:46:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 2.0433 (1.5204)	Arch Loss 2.0673 (2.2830)	Arch Hard Loss 2.0557 (2.2722)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.5%)	
11/15 11:47:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.8633 (1.5349)	Arch Loss 2.2483 (2.3006)	Arch Hard Loss 2.2374 (2.2898)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.2%)	
11/15 11:47:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.5404 (1.5495)	Arch Loss 2.2695 (2.2952)	Arch Hard Loss 2.2594 (2.2844)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 86.0%)	
11/15 11:48:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 55.8840%
11/15 11:48:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1822	Prec@(1,5) (44.5%, 74.6%)
11/15 11:48:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.2106	Prec@(1,5) (43.5%, 74.2%)
11/15 11:48:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.2370	Prec@(1,5) (43.0%, 74.1%)
11/15 11:48:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.2446	Prec@(1,5) (43.1%, 73.8%)
11/15 11:48:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 43.0680%
11/15 11:48:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:48:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0680%
11/15 11:49:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.5078 (1.4225)	Arch Loss 2.6900 (2.2771)	Arch Hard Loss 2.6783 (2.2661)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 88.2%)	
11/15 11:49:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.3895 (1.4320)	Arch Loss 2.5547 (2.2864)	Arch Hard Loss 2.5437 (2.2755)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.9%)	
11/15 11:50:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.5029 (1.4511)	Arch Loss 2.2089 (2.2887)	Arch Hard Loss 2.1976 (2.2778)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.6%)	
11/15 11:51:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.9106 (1.4770)	Arch Loss 2.0039 (2.2963)	Arch Hard Loss 1.9929 (2.2855)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 87.1%)	
11/15 11:51:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 57.8760%
11/15 11:51:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.2375	Prec@(1,5) (43.2%, 73.9%)
11/15 11:51:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.2397	Prec@(1,5) (43.4%, 73.9%)
11/15 11:51:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.2473	Prec@(1,5) (43.0%, 73.9%)
11/15 11:51:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.2541	Prec@(1,5) (42.9%, 73.7%)
11/15 11:51:44午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 42.9200%
11/15 11:51:44午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:51:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0680%
11/15 11:52:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.3844 (1.3579)	Arch Loss 2.0595 (2.2453)	Arch Hard Loss 2.0484 (2.2345)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 89.1%)	
11/15 11:53:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.3614 (1.3756)	Arch Loss 2.5430 (2.2631)	Arch Hard Loss 2.5318 (2.2523)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.6%)	
11/15 11:53:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.9101 (1.3973)	Arch Loss 2.4558 (2.2650)	Arch Hard Loss 2.4458 (2.2542)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.1%)	
11/15 11:54:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.2706 (1.4048)	Arch Loss 1.8917 (2.2669)	Arch Hard Loss 1.8815 (2.2561)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 88.0%)	
11/15 11:54:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 59.4760%
11/15 11:54:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.2195	Prec@(1,5) (44.5%, 75.4%)
11/15 11:54:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.2167	Prec@(1,5) (44.1%, 75.0%)
11/15 11:54:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.2153	Prec@(1,5) (44.2%, 75.0%)
11/15 11:55:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.2127	Prec@(1,5) (44.4%, 74.9%)
11/15 11:55:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 44.3800%
11/15 11:55:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:55:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.3800%
11/15 11:55:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.0223 (1.2739)	Arch Loss 2.3238 (2.2858)	Arch Hard Loss 2.3115 (2.2747)	Arch Alpha Loss 0.0123 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.7%)	
11/15 11:56:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.5331 (1.3237)	Arch Loss 2.0413 (2.2857)	Arch Hard Loss 2.0297 (2.2746)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.1%)	
11/15 11:57:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.2286 (1.3410)	Arch Loss 1.9457 (2.2845)	Arch Hard Loss 1.9344 (2.2735)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 89.0%)	
11/15 11:57:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.4510 (1.3461)	Arch Loss 2.1589 (2.2825)	Arch Hard Loss 2.1486 (2.2715)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.9%)	
11/15 11:57:53午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 60.9560%
11/15 11:58:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.2750	Prec@(1,5) (44.5%, 74.5%)
11/15 11:58:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.2878	Prec@(1,5) (43.6%, 74.0%)
11/15 11:58:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.2814	Prec@(1,5) (43.8%, 74.1%)
11/15 11:58:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.2666	Prec@(1,5) (44.0%, 74.3%)
11/15 11:58:20午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 43.9840%
11/15 11:58:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 11:58:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.3800%
11/15 11:59:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.1803 (1.2304)	Arch Loss 2.3532 (2.2499)	Arch Hard Loss 2.3418 (2.2387)	Arch Alpha Loss 0.0115 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.7%)	
11/15 11:59:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.2177 (1.2454)	Arch Loss 1.8200 (2.2726)	Arch Hard Loss 1.8081 (2.2615)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.4%)	
11/16 12:00:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0748 (1.2511)	Arch Loss 2.6738 (2.2843)	Arch Hard Loss 2.6623 (2.2733)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.4%)	
11/16 12:01:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.0373 (1.2679)	Arch Loss 1.7702 (2.2751)	Arch Hard Loss 1.7586 (2.2641)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.1%)	
11/16 12:01:10午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 63.2000%
11/16 12:01:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.2137	Prec@(1,5) (45.2%, 75.0%)
11/16 12:01:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.2514	Prec@(1,5) (44.9%, 74.2%)
11/16 12:01:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.2602	Prec@(1,5) (44.6%, 74.0%)
11/16 12:01:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.2490	Prec@(1,5) (44.6%, 74.2%)
11/16 12:01:36午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 44.5840%
11/16 12:01:36午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:01:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.5840%
11/16 12:02:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.3105 (1.1581)	Arch Loss 2.6205 (2.2575)	Arch Hard Loss 2.6099 (2.2466)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.4%)	
11/16 12:03:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.2140 (1.1771)	Arch Loss 2.5347 (2.2724)	Arch Hard Loss 2.5244 (2.2613)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.1%)	
11/16 12:03:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.3397 (1.1958)	Arch Loss 2.0750 (2.2770)	Arch Hard Loss 2.0639 (2.2659)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.9%)	
11/16 12:04:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.1582 (1.2036)	Arch Loss 2.4668 (2.2914)	Arch Hard Loss 2.4554 (2.2804)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.7%)	
11/16 12:04:27午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 64.9280%
11/16 12:04:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.2034	Prec@(1,5) (45.9%, 75.7%)
11/16 12:04:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.2073	Prec@(1,5) (45.6%, 75.9%)
11/16 12:04:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.2034	Prec@(1,5) (45.9%, 75.8%)
11/16 12:04:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.2029	Prec@(1,5) (45.8%, 75.7%)
11/16 12:04:54午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 45.7880%
11/16 12:04:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:04:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7880%
11/16 12:05:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.3020 (1.0974)	Arch Loss 1.9721 (2.2776)	Arch Hard Loss 1.9611 (2.2665)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.5%)	
11/16 12:06:22午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.3806 (1.1092)	Arch Loss 2.8520 (2.2672)	Arch Hard Loss 2.8408 (2.2560)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.2%)	
11/16 12:07:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0959 (1.1261)	Arch Loss 2.2777 (2.2793)	Arch Hard Loss 2.2672 (2.2682)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.9%)	
11/16 12:07:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.1762 (1.1401)	Arch Loss 2.9787 (2.2870)	Arch Hard Loss 2.9673 (2.2760)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.7%)	
11/16 12:07:45午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 66.5200%
11/16 12:07:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.2423	Prec@(1,5) (45.1%, 75.1%)
11/16 12:07:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.2387	Prec@(1,5) (45.6%, 74.9%)
11/16 12:08:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.2480	Prec@(1,5) (45.2%, 75.0%)
11/16 12:08:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.2414	Prec@(1,5) (45.3%, 75.3%)
11/16 12:08:12午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 45.2520%
11/16 12:08:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:08:12午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7880%
11/16 12:08:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.9684 (1.0208)	Arch Loss 2.2756 (2.2738)	Arch Hard Loss 2.2640 (2.2628)	Arch Alpha Loss 0.0117 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.4%)	
11/16 12:09:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8066 (1.0317)	Arch Loss 2.0457 (2.2811)	Arch Hard Loss 2.0346 (2.2701)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.4%)	
11/16 12:10:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.2758 (1.0553)	Arch Loss 2.3725 (2.3003)	Arch Hard Loss 2.3615 (2.2893)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.9%)	
11/16 12:11:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.2839 (1.0690)	Arch Loss 2.4068 (2.2998)	Arch Hard Loss 2.3958 (2.2887)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
11/16 12:11:02午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 68.4000%
11/16 12:11:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.2306	Prec@(1,5) (45.5%, 76.4%)
11/16 12:11:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.2603	Prec@(1,5) (45.2%, 75.5%)
11/16 12:11:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.2474	Prec@(1,5) (45.2%, 75.7%)
11/16 12:11:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.2623	Prec@(1,5) (45.0%, 75.3%)
11/16 12:11:29午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 45.0360%
11/16 12:11:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:11:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7880%
11/16 12:12:13午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 1.0571 (0.9795)	Arch Loss 2.6910 (2.3562)	Arch Hard Loss 2.6798 (2.3453)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 94.2%)	
11/16 12:12:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 1.1936 (0.9932)	Arch Loss 2.2916 (2.3521)	Arch Hard Loss 2.2810 (2.3413)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.8%)	
11/16 12:13:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 1.1699 (0.9999)	Arch Loss 1.9011 (2.3142)	Arch Hard Loss 1.8906 (2.3034)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.6%)	
11/16 12:14:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8201 (1.0072)	Arch Loss 2.1132 (2.3077)	Arch Hard Loss 2.1023 (2.2968)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.4%)	
11/16 12:14:20午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 70.2360%
11/16 12:14:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.2343	Prec@(1,5) (45.8%, 76.1%)
11/16 12:14:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.2210	Prec@(1,5) (46.4%, 76.3%)
11/16 12:14:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.2211	Prec@(1,5) (46.2%, 76.1%)
11/16 12:14:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.2304	Prec@(1,5) (46.1%, 75.9%)
11/16 12:14:47午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 46.0760%
11/16 12:14:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:14:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.0760%
11/16 12:15:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 1.1978 (0.9127)	Arch Loss 2.4877 (2.2827)	Arch Hard Loss 2.4770 (2.2716)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.5%)	
11/16 12:16:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 1.3332 (0.9344)	Arch Loss 1.9933 (2.3182)	Arch Hard Loss 1.9828 (2.3071)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.4%)	
11/16 12:16:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.9350 (0.9417)	Arch Loss 1.9231 (2.3157)	Arch Hard Loss 1.9130 (2.3047)	Arch Alpha Loss 0.0101 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.3%)	
11/16 12:17:39午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.0325 (0.9468)	Arch Loss 2.8103 (2.3221)	Arch Hard Loss 2.8001 (2.3111)	Arch Alpha Loss 0.0102 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.2%)	
11/16 12:17:39午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 71.8760%
11/16 12:17:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.2588	Prec@(1,5) (46.7%, 75.6%)
11/16 12:17:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.2568	Prec@(1,5) (46.2%, 75.6%)
11/16 12:17:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.2441	Prec@(1,5) (46.4%, 75.9%)
11/16 12:18:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.2430	Prec@(1,5) (46.5%, 76.0%)
11/16 12:18:06午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 46.4760%
11/16 12:18:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:18:06午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.4760%
11/16 12:18:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7868 (0.8524)	Arch Loss 2.6818 (2.3536)	Arch Hard Loss 2.6701 (2.3428)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.5%)	
11/16 12:19:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.7796 (0.8799)	Arch Loss 2.4711 (2.3347)	Arch Hard Loss 2.4595 (2.3239)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.2%)	
11/16 12:20:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.9804 (0.8908)	Arch Loss 2.2432 (2.3281)	Arch Hard Loss 2.2303 (2.3172)	Arch Alpha Loss 0.0128 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.0%)	
11/16 12:20:55午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9129 (0.8987)	Arch Loss 2.6141 (2.3286)	Arch Hard Loss 2.6022 (2.3176)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
11/16 12:20:56午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 73.2000%
11/16 12:21:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.3267	Prec@(1,5) (45.7%, 75.5%)
11/16 12:21:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.3341	Prec@(1,5) (45.2%, 75.3%)
11/16 12:21:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.3009	Prec@(1,5) (45.4%, 75.7%)
11/16 12:21:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.2858	Prec@(1,5) (45.8%, 76.0%)
11/16 12:21:22午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 45.8200%
11/16 12:21:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:21:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.4760%
11/16 12:22:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.8602 (0.8288)	Arch Loss 2.0167 (2.3356)	Arch Hard Loss 2.0072 (2.3246)	Arch Alpha Loss 0.0095 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.4%)	
11/16 12:22:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.6670 (0.8325)	Arch Loss 2.5128 (2.3482)	Arch Hard Loss 2.5027 (2.3374)	Arch Alpha Loss 0.0101 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.5%)	
11/16 12:23:34午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.8611 (0.8377)	Arch Loss 2.7676 (2.3429)	Arch Hard Loss 2.7570 (2.3320)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.3%)	
11/16 12:24:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.7506 (0.8435)	Arch Loss 2.7362 (2.3355)	Arch Hard Loss 2.7261 (2.3246)	Arch Alpha Loss 0.0101 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.3%)	
11/16 12:24:14午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 74.9400%
11/16 12:24:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.2731	Prec@(1,5) (46.9%, 76.3%)
11/16 12:24:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.2508	Prec@(1,5) (47.4%, 76.4%)
11/16 12:24:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.2416	Prec@(1,5) (47.5%, 76.7%)
11/16 12:24:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.2588	Prec@(1,5) (46.9%, 76.4%)
11/16 12:24:41午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 46.9280%
11/16 12:24:41午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:24:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.9280%
11/16 12:25:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7287 (0.7915)	Arch Loss 2.3474 (2.3926)	Arch Hard Loss 2.3366 (2.3817)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 95.7%)	
11/16 12:26:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.8936 (0.8038)	Arch Loss 2.6307 (2.3580)	Arch Hard Loss 2.6203 (2.3471)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.7%)	
11/16 12:26:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6408 (0.8048)	Arch Loss 1.8410 (2.3555)	Arch Hard Loss 1.8300 (2.3447)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.6%)	
11/16 12:27:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.7722 (0.8107)	Arch Loss 2.1640 (2.3456)	Arch Hard Loss 2.1532 (2.3348)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.5%)	
11/16 12:27:32午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 76.2480%
11/16 12:27:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.3183	Prec@(1,5) (46.1%, 75.8%)
11/16 12:27:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.3185	Prec@(1,5) (46.4%, 76.0%)
11/16 12:27:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.3126	Prec@(1,5) (46.3%, 75.9%)
11/16 12:27:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.3044	Prec@(1,5) (46.5%, 76.0%)
11/16 12:27:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 46.4680%
11/16 12:27:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:27:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.9280%
11/16 12:28:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.6698 (0.7586)	Arch Loss 2.5581 (2.3718)	Arch Hard Loss 2.5472 (2.3607)	Arch Alpha Loss 0.0110 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 95.9%)	
11/16 12:29:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6050 (0.7572)	Arch Loss 1.8701 (2.3789)	Arch Hard Loss 1.8607 (2.3678)	Arch Alpha Loss 0.0095 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.0%)	
11/16 12:30:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.7303 (0.7534)	Arch Loss 2.3300 (2.3792)	Arch Hard Loss 2.3201 (2.3681)	Arch Alpha Loss 0.0099 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.1%)	
11/16 12:30:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.9621 (0.7595)	Arch Loss 2.7521 (2.3787)	Arch Hard Loss 2.7410 (2.3676)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.0%)	
11/16 12:30:49午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 77.5280%
11/16 12:30:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.2670	Prec@(1,5) (47.7%, 76.5%)
11/16 12:31:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.2718	Prec@(1,5) (47.3%, 76.4%)
11/16 12:31:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.2700	Prec@(1,5) (47.2%, 76.5%)
11/16 12:31:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.2821	Prec@(1,5) (47.2%, 76.3%)
11/16 12:31:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 47.2280%
11/16 12:31:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:31:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2280%
11/16 12:32:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.6048 (0.7009)	Arch Loss 2.3587 (2.4581)	Arch Hard Loss 2.3481 (2.4472)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 97.3%)	
11/16 12:32:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.4836 (0.7054)	Arch Loss 2.3131 (2.3962)	Arch Hard Loss 2.3019 (2.3853)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 97.0%)	
11/16 12:33:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7960 (0.7140)	Arch Loss 2.3795 (2.3768)	Arch Hard Loss 2.3676 (2.3658)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.8%)	
11/16 12:34:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7766 (0.7198)	Arch Loss 2.8761 (2.3752)	Arch Hard Loss 2.8643 (2.3641)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.7%)	
11/16 12:34:07午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 78.5920%
11/16 12:34:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.3011	Prec@(1,5) (47.0%, 76.1%)
11/16 12:34:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.3077	Prec@(1,5) (47.3%, 76.2%)
11/16 12:34:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.2904	Prec@(1,5) (47.5%, 76.4%)
11/16 12:34:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.3024	Prec@(1,5) (47.3%, 76.2%)
11/16 12:34:33午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 47.2600%
11/16 12:34:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:34:34午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2600%
11/16 12:35:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6766 (0.6741)	Arch Loss 1.8759 (2.3160)	Arch Hard Loss 1.8657 (2.3051)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
11/16 12:36:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.8503 (0.6822)	Arch Loss 2.8271 (2.3578)	Arch Hard Loss 2.8165 (2.3469)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.1%)	
11/16 12:36:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.7521 (0.6963)	Arch Loss 2.6940 (2.3677)	Arch Hard Loss 2.6829 (2.3568)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.8%)	
11/16 12:37:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6203 (0.6987)	Arch Loss 1.7370 (2.3714)	Arch Hard Loss 1.7257 (2.3604)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.8%)	
11/16 12:37:24午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 79.0560%
11/16 12:37:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.3500	Prec@(1,5) (46.7%, 75.7%)
11/16 12:37:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.3279	Prec@(1,5) (46.9%, 75.9%)
11/16 12:37:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.3292	Prec@(1,5) (46.8%, 75.9%)
11/16 12:37:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.3221	Prec@(1,5) (46.9%, 76.2%)
11/16 12:37:50午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 46.8880%
11/16 12:37:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:37:51午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2600%
11/16 12:38:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.8113 (0.6521)	Arch Loss 2.2728 (2.3841)	Arch Hard Loss 2.2616 (2.3730)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
11/16 12:39:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6743 (0.6630)	Arch Loss 2.8152 (2.3641)	Arch Hard Loss 2.8039 (2.3531)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.1%)	
11/16 12:40:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.7561 (0.6706)	Arch Loss 2.4362 (2.3864)	Arch Hard Loss 2.4248 (2.3754)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 96.9%)	
11/16 12:40:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.5948 (0.6729)	Arch Loss 2.1693 (2.3914)	Arch Hard Loss 2.1585 (2.3804)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 96.9%)	
11/16 12:40:41午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 80.1600%
11/16 12:40:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.3114	Prec@(1,5) (47.4%, 76.5%)
11/16 12:40:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.3358	Prec@(1,5) (47.1%, 76.0%)
11/16 12:41:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.3178	Prec@(1,5) (47.1%, 76.1%)
11/16 12:41:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.3209	Prec@(1,5) (47.0%, 76.3%)
11/16 12:41:07午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 47.0040%
11/16 12:41:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:41:07午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2600%
11/16 12:41:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6659 (0.6354)	Arch Loss 2.1690 (2.3522)	Arch Hard Loss 2.1566 (2.3413)	Arch Alpha Loss 0.0124 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.0%)	
11/16 12:42:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5637 (0.6446)	Arch Loss 2.2020 (2.3851)	Arch Hard Loss 2.1907 (2.3742)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.0%)	
11/16 12:43:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5999 (0.6501)	Arch Loss 2.4961 (2.3937)	Arch Hard Loss 2.4857 (2.3827)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.0%)	
11/16 12:43:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6818 (0.6541)	Arch Loss 2.5986 (2.4019)	Arch Hard Loss 2.5881 (2.3910)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.0%)	
11/16 12:43:59午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 80.7360%
11/16 12:44:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.3174	Prec@(1,5) (47.5%, 76.4%)
11/16 12:44:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.3370	Prec@(1,5) (47.4%, 76.5%)
11/16 12:44:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.3391	Prec@(1,5) (47.3%, 76.2%)
11/16 12:44:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.3427	Prec@(1,5) (46.9%, 76.2%)
11/16 12:44:26午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 46.8720%
11/16 12:44:26午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:44:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2600%
11/16 12:45:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4785 (0.5991)	Arch Loss 2.7174 (2.4054)	Arch Hard Loss 2.7055 (2.3944)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 98.0%)	
11/16 12:45:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5322 (0.6242)	Arch Loss 2.4383 (2.4021)	Arch Hard Loss 2.4265 (2.3910)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.6%)	
11/16 12:46:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.8610 (0.6286)	Arch Loss 2.5551 (2.4242)	Arch Hard Loss 2.5429 (2.4132)	Arch Alpha Loss 0.0121 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
11/16 12:47:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6451 (0.6369)	Arch Loss 2.1433 (2.4087)	Arch Hard Loss 2.1322 (2.3976)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
11/16 12:47:18午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 81.1720%
11/16 12:47:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.3232	Prec@(1,5) (47.0%, 76.4%)
11/16 12:47:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.3589	Prec@(1,5) (46.6%, 76.3%)
11/16 12:47:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.3460	Prec@(1,5) (46.8%, 76.3%)
11/16 12:47:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.3350	Prec@(1,5) (46.9%, 76.4%)
11/16 12:47:45午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 46.9280%
11/16 12:47:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/16 12:47:45午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2600%
11/16 12:47:45午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 47.2600%
11/16 12:47:45午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 11:02:28AM parser.py:28 [INFO] 
11/18 11:02:28AM parser.py:29 [INFO] Parameters:
11/18 11:02:28AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g1/DAG
11/18 11:02:28AM parser.py:31 [INFO] T=10.0
11/18 11:02:28AM parser.py:31 [INFO] ADVANCED=1
11/18 11:02:28AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/18 11:02:28AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/18 11:02:28AM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/18 11:02:28AM parser.py:31 [INFO] BATCH_SIZE=64
11/18 11:02:28AM parser.py:31 [INFO] CASCADE=0
11/18 11:02:28AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/18 11:02:28AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/18 11:02:28AM parser.py:31 [INFO] DATA_PATH=../data/
11/18 11:02:28AM parser.py:31 [INFO] DATASET=cifar100
11/18 11:02:28AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/18 11:02:28AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/18 11:02:28AM parser.py:31 [INFO] DISCRETE=0
11/18 11:02:28AM parser.py:31 [INFO] EPOCHS=50
11/18 11:02:28AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/18 11:02:28AM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g1
11/18 11:02:28AM parser.py:31 [INFO] FINAL_L=1.0
11/18 11:02:28AM parser.py:31 [INFO] G=1.0
11/18 11:02:28AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/18 11:02:28AM parser.py:31 [INFO] GPUS=[0]
11/18 11:02:28AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/18 11:02:28AM parser.py:31 [INFO] INIT_CHANNELS=16
11/18 11:02:28AM parser.py:31 [INFO] L=1.0
11/18 11:02:28AM parser.py:31 [INFO] LAYERS=32
11/18 11:02:28AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/18 11:02:28AM parser.py:31 [INFO] NAME=Pruning
11/18 11:02:28AM parser.py:31 [INFO] NONKD=1
11/18 11:02:28AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g1
11/18 11:02:28AM parser.py:31 [INFO] PCDARTS=0
11/18 11:02:28AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g1/plots
11/18 11:02:28AM parser.py:31 [INFO] PRINT_FREQ=100
11/18 11:02:28AM parser.py:31 [INFO] RESET=0
11/18 11:02:28AM parser.py:31 [INFO] RESUME_PATH=None
11/18 11:02:28AM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g1
11/18 11:02:28AM parser.py:31 [INFO] SEED=0
11/18 11:02:28AM parser.py:31 [INFO] SHARE_STAGE=0
11/18 11:02:28AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/18 11:02:28AM parser.py:31 [INFO] SPEC_CELL=1
11/18 11:02:28AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/18 11:02:28AM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/18 11:02:28AM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/18 11:02:28AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/18 11:02:28AM parser.py:31 [INFO] TYPE=ArchKD
11/18 11:02:28AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/18 11:02:28AM parser.py:31 [INFO] W_LR=0.025
11/18 11:02:28AM parser.py:31 [INFO] W_LR_MIN=0.001
11/18 11:02:28AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/18 11:02:28AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/18 11:02:28AM parser.py:31 [INFO] WORKERS=4
11/18 11:02:28AM parser.py:32 [INFO] 
11/18 11:02:33AM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/18 11:02:42AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/18 11:04:19AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6083 (4.7092)	Arch Loss 4.6353 (4.7189)	Arch Hard Loss 4.6242 (4.7070)	Arch Alpha Loss 0.0111 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.5%, 6.9%)	
11/18 11:05:53AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.3391 (4.6134)	Arch Loss 4.3760 (4.6251)	Arch Hard Loss 4.3646 (4.6137)	Arch Alpha Loss 0.0114 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 8.7%)	
11/18 11:07:26AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2910 (4.5217)	Arch Loss 4.5005 (4.5337)	Arch Hard Loss 4.4893 (4.5225)	Arch Alpha Loss 0.0112 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.6%, 10.8%)	
11/18 11:08:50AM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2488 (4.4608)	Arch Loss 3.9801 (4.4677)	Arch Hard Loss 3.9694 (4.4566)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 12.3%)	
11/18 11:08:53AM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 2.8080%
11/18 11:09:08AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.1921	Prec@(1,5) (4.8%, 18.0%)
11/18 11:09:22AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.1801	Prec@(1,5) (4.9%, 18.5%)
11/18 11:09:37AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.1893	Prec@(1,5) (4.9%, 18.6%)
11/18 11:09:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.1852	Prec@(1,5) (5.0%, 18.7%)
11/18 11:09:50AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 4.9560%
11/18 11:09:50AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 11:09:51AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 4.9560%
11/18 11:11:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.2955 (4.1776)	Arch Loss 4.2817 (4.1842)	Arch Hard Loss 4.2706 (4.1734)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.7%, 19.2%)	
11/18 11:12:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.1702 (4.1376)	Arch Loss 4.0841 (4.1525)	Arch Hard Loss 4.0732 (4.1416)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 20.8%)	
11/18 11:14:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9935 (4.1040)	Arch Loss 3.7886 (4.1122)	Arch Hard Loss 3.7777 (4.1013)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.9%, 21.9%)	
11/18 11:15:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.9139 (4.0876)	Arch Loss 3.8837 (4.0901)	Arch Hard Loss 3.8732 (4.0792)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.2%, 22.5%)	
11/18 11:15:57午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 6.1920%
11/18 11:16:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 4.0011	Prec@(1,5) (6.6%, 26.5%)
11/18 11:16:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 4.0343	Prec@(1,5) (6.5%, 25.9%)
11/18 11:16:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 4.0286	Prec@(1,5) (6.6%, 26.1%)
11/18 11:16:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 4.0287	Prec@(1,5) (6.8%, 26.2%)
11/18 11:16:53午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 6.7640%
11/18 11:16:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/18 11:16:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 6.7640%
11/18 11:18:28午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.9779 (3.9491)	Arch Loss 4.1057 (3.9986)	Arch Hard Loss 4.0949 (3.9878)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.8%, 26.9%)	
11/18 11:20:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8944 (3.9389)	Arch Loss 3.7784 (3.9529)	Arch Hard Loss 3.7675 (3.9421)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.0%, 27.4%)	
11/18 11:21:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.9986 (3.9237)	Arch Loss 3.9371 (3.9239)	Arch Hard Loss 3.9259 (3.9131)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.2%, 28.2%)	
11/18 11:22:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.8423 (3.9001)	Arch Loss 3.6776 (3.9016)	Arch Hard Loss 3.6668 (3.8908)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.5%, 29.1%)	
11/18 11:23:00午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 8.5560%
11/18 11:23:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.8344	Prec@(1,5) (9.1%, 32.4%)
11/18 11:23:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.8319	Prec@(1,5) (9.2%, 32.4%)
11/18 11:23:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.8303	Prec@(1,5) (9.1%, 32.1%)
11/18 11:23:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.8270	Prec@(1,5) (9.3%, 32.2%)
11/18 11:23:57午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.2560%
11/18 11:23:57午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/18 11:23:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.2560%
11/18 11:25:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5570 (3.7729)	Arch Loss 3.6151 (3.8156)	Arch Hard Loss 3.6047 (3.8049)	Arch Alpha Loss 0.0104 (0.0107)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (10.5%, 33.3%)	
11/18 11:27:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7422 (3.7721)	Arch Loss 3.6453 (3.7932)	Arch Hard Loss 3.6349 (3.7825)	Arch Alpha Loss 0.0104 (0.0107)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (10.7%, 33.3%)	
11/18 11:28:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.7734 (3.7568)	Arch Loss 4.1548 (3.7734)	Arch Hard Loss 4.1445 (3.7627)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.9%, 33.8%)	
11/18 11:30:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6972 (3.7461)	Arch Loss 3.7734 (3.7548)	Arch Hard Loss 3.7630 (3.7441)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.0%, 34.1%)	
11/18 11:30:03午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 11.0400%
11/18 11:30:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.7306	Prec@(1,5) (11.9%, 35.4%)
11/18 11:30:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.7211	Prec@(1,5) (11.8%, 35.4%)
11/18 11:30:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.7110	Prec@(1,5) (11.6%, 35.5%)
11/18 11:30:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.7121	Prec@(1,5) (11.7%, 35.5%)
11/18 11:31:00午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 11.7000%
11/18 11:31:00午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/18 11:31:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 11.7000%
11/18 11:32:34午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.5261 (3.6357)	Arch Loss 4.0455 (3.6556)	Arch Hard Loss 4.0340 (3.6446)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.2%, 37.3%)	
11/18 11:34:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.8354 (3.6355)	Arch Loss 3.7542 (3.6341)	Arch Hard Loss 3.7428 (3.6232)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.0%, 37.1%)	
11/18 11:35:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.3832 (3.6180)	Arch Loss 3.3542 (3.6178)	Arch Hard Loss 3.3425 (3.6069)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.4%, 37.8%)	
11/18 11:37:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.8324 (3.6042)	Arch Loss 3.8441 (3.6117)	Arch Hard Loss 3.8320 (3.6008)	Arch Alpha Loss 0.0121 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.5%, 38.3%)	
11/18 11:37:06午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.5280%
11/18 11:37:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5232	Prec@(1,5) (14.7%, 41.7%)
11/18 11:37:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5335	Prec@(1,5) (14.7%, 41.0%)
11/18 11:37:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5436	Prec@(1,5) (14.7%, 40.7%)
11/18 11:38:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5436	Prec@(1,5) (14.7%, 40.9%)
11/18 11:38:03午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.7400%
11/18 11:38:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/18 11:38:03午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.7400%
11/18 11:39:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.7442 (3.5265)	Arch Loss 3.6715 (3.5440)	Arch Hard Loss 3.6617 (3.5330)	Arch Alpha Loss 0.0097 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.4%, 41.3%)	
11/18 11:41:11午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.4943 (3.5288)	Arch Loss 3.5263 (3.5401)	Arch Hard Loss 3.5165 (3.5293)	Arch Alpha Loss 0.0099 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.2%, 40.8%)	
11/18 11:42:45午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.2724 (3.5055)	Arch Loss 3.7377 (3.5201)	Arch Hard Loss 3.7276 (3.5093)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 41.6%)	
11/18 11:44:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.5102 (3.4932)	Arch Loss 3.4920 (3.5130)	Arch Hard Loss 3.4821 (3.5022)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.8%)	
11/18 11:44:10午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 15.2360%
11/18 11:44:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.5646	Prec@(1,5) (14.5%, 41.2%)
11/18 11:44:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.5713	Prec@(1,5) (14.4%, 40.6%)
11/18 11:44:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.5658	Prec@(1,5) (14.5%, 40.7%)
11/18 11:45:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.5725	Prec@(1,5) (14.5%, 40.5%)
11/18 11:45:06午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 14.4920%
11/18 11:45:06午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/18 11:45:06午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.7400%
11/18 11:46:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.9854 (3.3910)	Arch Loss 3.4074 (3.4414)	Arch Hard Loss 3.3961 (3.4306)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.5%, 43.9%)	
11/18 11:48:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.3537 (3.3964)	Arch Loss 3.6904 (3.4406)	Arch Hard Loss 3.6788 (3.4298)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 43.7%)	
11/18 11:49:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.4117 (3.3916)	Arch Loss 3.5470 (3.4199)	Arch Hard Loss 3.5353 (3.4091)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 43.9%)	
11/18 11:51:12午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.5997 (3.3792)	Arch Loss 3.2392 (3.4060)	Arch Hard Loss 3.2274 (3.3952)	Arch Alpha Loss 0.0118 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.7%, 44.3%)	
11/18 11:51:13午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.6600%
11/18 11:51:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.3814	Prec@(1,5) (17.5%, 44.7%)
11/18 11:51:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3914	Prec@(1,5) (17.5%, 44.8%)
11/18 11:51:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.4016	Prec@(1,5) (17.4%, 44.7%)
11/18 11:52:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.3977	Prec@(1,5) (17.4%, 45.0%)
11/18 11:52:10午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 17.4320%
11/18 11:52:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/18 11:52:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.4320%
11/18 11:53:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.3819 (3.3005)	Arch Loss 3.4950 (3.3566)	Arch Hard Loss 3.4856 (3.3460)	Arch Alpha Loss 0.0094 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.7%, 47.5%)	
11/18 11:55:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.5394 (3.2916)	Arch Loss 3.4356 (3.3606)	Arch Hard Loss 3.4260 (3.3500)	Arch Alpha Loss 0.0096 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 47.5%)	
11/18 11:56:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.3257 (3.2768)	Arch Loss 2.9226 (3.3362)	Arch Hard Loss 2.9127 (3.3256)	Arch Alpha Loss 0.0100 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.4%, 47.8%)	
11/18 11:58:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.1396 (3.2677)	Arch Loss 3.4688 (3.3266)	Arch Hard Loss 3.4593 (3.3160)	Arch Alpha Loss 0.0095 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 48.0%)	
11/18 11:58:15午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 19.5120%
11/18 11:58:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.2727	Prec@(1,5) (19.9%, 47.4%)
11/18 11:58:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.2664	Prec@(1,5) (19.7%, 47.8%)
11/18 11:58:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.2638	Prec@(1,5) (19.5%, 48.1%)
11/18 11:59:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.2607	Prec@(1,5) (19.7%, 48.3%)
11/18 11:59:13午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 19.6960%
11/18 11:59:13午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/18 11:59:13午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.6960%
11/18 12:00:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.0809 (3.1676)	Arch Loss 3.3110 (3.2644)	Arch Hard Loss 3.2985 (3.2535)	Arch Alpha Loss 0.0125 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.2%, 50.9%)	
11/18 12:02:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.2165 (3.1911)	Arch Loss 3.0181 (3.2608)	Arch Hard Loss 3.0058 (3.2499)	Arch Alpha Loss 0.0124 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.4%)	
11/18 12:03:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.1303 (3.1811)	Arch Loss 3.2652 (3.2569)	Arch Hard Loss 3.2527 (3.2460)	Arch Alpha Loss 0.0125 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.1%)	
11/18 12:05:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.2330 (3.1738)	Arch Loss 3.2455 (3.2378)	Arch Hard Loss 3.2331 (3.2270)	Arch Alpha Loss 0.0124 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.1%, 50.4%)	
11/18 12:05:19午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 21.1240%
11/18 12:05:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1898	Prec@(1,5) (21.3%, 49.6%)
11/18 12:05:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1979	Prec@(1,5) (21.1%, 50.0%)
11/18 12:06:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1929	Prec@(1,5) (21.2%, 50.2%)
11/18 12:06:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1973	Prec@(1,5) (21.1%, 50.0%)
11/18 12:06:16午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 21.0880%
11/18 12:06:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/18 12:06:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.0880%
11/18 12:07:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.8960 (3.0774)	Arch Loss 2.9746 (3.1824)	Arch Hard Loss 2.9647 (3.1714)	Arch Alpha Loss 0.0099 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 53.4%)	
11/18 12:09:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.2691 (3.0737)	Arch Loss 2.9992 (3.1769)	Arch Hard Loss 2.9887 (3.1659)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.7%, 53.0%)	
11/18 12:10:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.3750 (3.0724)	Arch Loss 3.1304 (3.1643)	Arch Hard Loss 3.1200 (3.1534)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 53.2%)	
11/18 12:12:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.9007 (3.0764)	Arch Loss 2.9197 (3.1511)	Arch Hard Loss 2.9087 (3.1401)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 53.1%)	
11/18 12:12:22午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 22.7680%
11/18 12:12:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.1238	Prec@(1,5) (22.1%, 52.3%)
11/18 12:12:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.1041	Prec@(1,5) (22.3%, 53.0%)
11/18 12:13:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.1215	Prec@(1,5) (22.0%, 52.6%)
11/18 12:13:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.1308	Prec@(1,5) (22.1%, 52.3%)
11/18 12:13:19午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 22.0880%
11/18 12:13:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=range(10, 12))
11/18 12:13:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.0880%
11/18 12:14:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9460 (2.9756)	Arch Loss 2.9529 (3.0876)	Arch Hard Loss 2.9415 (3.0766)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.9%, 55.8%)	
11/18 12:16:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 3.0964 (2.9910)	Arch Loss 3.2711 (3.0953)	Arch Hard Loss 3.2596 (3.0843)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.6%)	
11/18 12:18:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.6356 (2.9946)	Arch Loss 2.7433 (3.0924)	Arch Hard Loss 2.7322 (3.0814)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.7%, 55.4%)	
11/18 12:19:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.7675 (2.9845)	Arch Loss 3.1208 (3.0776)	Arch Hard Loss 3.1099 (3.0667)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.0%, 55.5%)	
11/18 12:19:26午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 24.9560%
11/18 12:19:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.0774	Prec@(1,5) (24.6%, 54.0%)
11/18 12:19:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.0400	Prec@(1,5) (24.9%, 54.7%)
11/18 12:20:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 3.0365	Prec@(1,5) (25.2%, 54.8%)
11/18 12:20:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 3.0415	Prec@(1,5) (25.1%, 54.8%)
11/18 12:20:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 25.0760%
11/18 12:20:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 12:20:24午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.0760%
11/18 12:21:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.9432 (2.8914)	Arch Loss 3.0397 (3.0286)	Arch Hard Loss 3.0292 (3.0180)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 57.8%)	
11/18 12:23:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.9337 (2.9026)	Arch Loss 2.8351 (3.0099)	Arch Hard Loss 2.8243 (2.9993)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.3%, 57.5%)	
11/18 12:25:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 3.0453 (2.9033)	Arch Loss 2.9811 (3.0049)	Arch Hard Loss 2.9701 (2.9941)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.6%, 57.5%)	
11/18 12:26:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 3.0382 (2.8962)	Arch Loss 2.4966 (2.9940)	Arch Hard Loss 2.4857 (2.9832)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.7%, 57.6%)	
11/18 12:26:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 26.7080%
11/18 12:26:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.9160	Prec@(1,5) (27.0%, 57.5%)
11/18 12:26:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.9306	Prec@(1,5) (26.7%, 57.0%)
11/18 12:27:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9245	Prec@(1,5) (26.7%, 57.1%)
11/18 12:27:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.9188	Prec@(1,5) (26.7%, 57.3%)
11/18 12:27:27午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 26.6880%
11/18 12:27:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 12:27:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.6880%
11/18 12:29:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4510 (2.8140)	Arch Loss 2.7666 (2.9574)	Arch Hard Loss 2.7555 (2.9464)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.6%, 60.0%)	
11/18 12:30:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.8716 (2.8023)	Arch Loss 2.7369 (2.9491)	Arch Hard Loss 2.7260 (2.9381)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 60.0%)	
11/18 12:32:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.7502 (2.8081)	Arch Loss 3.1886 (2.9419)	Arch Hard Loss 3.1775 (2.9309)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.1%, 59.9%)	
11/18 12:33:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.9408 (2.8081)	Arch Loss 2.7992 (2.9369)	Arch Hard Loss 2.7886 (2.9259)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.2%, 59.9%)	
11/18 12:33:33午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 28.2080%
11/18 12:33:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.9265	Prec@(1,5) (26.6%, 57.6%)
11/18 12:34:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.9408	Prec@(1,5) (26.6%, 57.2%)
11/18 12:34:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.9433	Prec@(1,5) (26.6%, 57.2%)
11/18 12:34:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.9509	Prec@(1,5) (26.4%, 57.1%)
11/18 12:34:30午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 26.4440%
11/18 12:34:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 12:34:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.6880%
11/18 12:36:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.5884 (2.7295)	Arch Loss 2.8866 (2.9007)	Arch Hard Loss 2.8751 (2.8897)	Arch Alpha Loss 0.0115 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.9%, 62.0%)	
11/18 12:37:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.9600 (2.7419)	Arch Loss 2.8568 (2.8934)	Arch Hard Loss 2.8456 (2.8824)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 61.4%)	
11/18 12:39:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.7957 (2.7307)	Arch Loss 2.4775 (2.8825)	Arch Hard Loss 2.4668 (2.8715)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.8%, 61.8%)	
11/18 12:40:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.2549 (2.7273)	Arch Loss 2.7954 (2.8836)	Arch Hard Loss 2.7845 (2.8726)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 61.7%)	
11/18 12:40:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 30.1200%
11/18 12:40:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.8427	Prec@(1,5) (28.9%, 59.3%)
11/18 12:41:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8412	Prec@(1,5) (29.0%, 59.6%)
11/18 12:41:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.8488	Prec@(1,5) (28.7%, 59.3%)
11/18 12:41:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.8432	Prec@(1,5) (28.7%, 59.5%)
11/18 12:41:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 28.7560%
11/18 12:41:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 12:41:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.7560%
11/18 12:43:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 3.0165 (2.6253)	Arch Loss 2.9674 (2.8425)	Arch Hard Loss 2.9569 (2.8314)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.5%, 63.9%)	
11/18 12:44:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.9449 (2.6363)	Arch Loss 2.9187 (2.8446)	Arch Hard Loss 2.9080 (2.8336)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.9%, 63.8%)	
11/18 12:46:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.7419 (2.6468)	Arch Loss 2.7030 (2.8335)	Arch Hard Loss 2.6919 (2.8225)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.5%, 63.7%)	
11/18 12:47:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.8256 (2.6472)	Arch Loss 2.7415 (2.8309)	Arch Hard Loss 2.7301 (2.8198)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 63.8%)	
11/18 12:47:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 31.4240%
11/18 12:47:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.7639	Prec@(1,5) (29.0%, 60.9%)
11/18 12:48:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.7649	Prec@(1,5) (29.6%, 60.8%)
11/18 12:48:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.7662	Prec@(1,5) (29.6%, 60.7%)
11/18 12:48:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.7740	Prec@(1,5) (29.5%, 60.6%)
11/18 12:48:38午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 29.5320%
11/18 12:48:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 12:48:39午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.5320%
11/18 12:50:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.4108 (2.5405)	Arch Loss 2.7915 (2.7982)	Arch Hard Loss 2.7816 (2.7873)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.3%, 66.1%)	
11/18 12:51:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.2330 (2.5667)	Arch Loss 2.7469 (2.7872)	Arch Hard Loss 2.7366 (2.7763)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.7%, 65.4%)	
11/18 12:53:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.2857 (2.5738)	Arch Loss 2.7691 (2.7749)	Arch Hard Loss 2.7594 (2.7640)	Arch Alpha Loss 0.0096 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.4%, 65.2%)	
11/18 12:54:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.4119 (2.5798)	Arch Loss 2.5205 (2.7707)	Arch Hard Loss 2.5105 (2.7599)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.2%, 65.1%)	
11/18 12:54:45午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 33.2000%
11/18 12:54:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.8224	Prec@(1,5) (28.8%, 60.4%)
11/18 12:55:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.7954	Prec@(1,5) (29.2%, 60.9%)
11/18 12:55:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.7986	Prec@(1,5) (29.2%, 60.6%)
11/18 12:55:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.7932	Prec@(1,5) (29.3%, 60.6%)
11/18 12:55:42午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 29.2920%
11/18 12:55:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 12:55:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.5320%
11/18 12:57:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.3826 (2.4432)	Arch Loss 2.8557 (2.7376)	Arch Hard Loss 2.8440 (2.7265)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 68.5%)	
11/18 12:58:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.2833 (2.4762)	Arch Loss 2.8414 (2.7288)	Arch Hard Loss 2.8301 (2.7177)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.7%)	
11/18 01:00:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.8030 (2.4938)	Arch Loss 2.5159 (2.7246)	Arch Hard Loss 2.5040 (2.7136)	Arch Alpha Loss 0.0119 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.3%)	
11/18 01:01:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.5484 (2.4966)	Arch Loss 2.6644 (2.7168)	Arch Hard Loss 2.6524 (2.7057)	Arch Alpha Loss 0.0120 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.6%, 67.2%)	
11/18 01:01:48午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 34.6160%
11/18 01:02:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.7334	Prec@(1,5) (30.7%, 62.1%)
11/18 01:02:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.7574	Prec@(1,5) (30.4%, 61.7%)
11/18 01:02:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.7520	Prec@(1,5) (30.5%, 61.9%)
11/18 01:02:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.7500	Prec@(1,5) (30.5%, 61.9%)
11/18 01:02:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 30.5120%
11/18 01:02:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:02:45午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.5120%
11/18 01:04:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.1804 (2.4474)	Arch Loss 2.8551 (2.7216)	Arch Hard Loss 2.8447 (2.7102)	Arch Alpha Loss 0.0104 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 68.0%)	
11/18 01:05:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.2698 (2.4413)	Arch Loss 2.8202 (2.6985)	Arch Hard Loss 2.8096 (2.6873)	Arch Alpha Loss 0.0106 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.5%)	
11/18 01:07:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.2906 (2.4335)	Arch Loss 2.4117 (2.6953)	Arch Hard Loss 2.4011 (2.6842)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 68.5%)	
11/18 01:08:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.2710 (2.4369)	Arch Loss 2.7311 (2.6816)	Arch Hard Loss 2.7206 (2.6706)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 68.4%)	
11/18 01:08:51午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 36.2320%
11/18 01:09:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.6028	Prec@(1,5) (33.5%, 64.9%)
11/18 01:09:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.6029	Prec@(1,5) (33.7%, 65.2%)
11/18 01:09:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.6269	Prec@(1,5) (33.0%, 64.8%)
11/18 01:09:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.6360	Prec@(1,5) (32.8%, 64.5%)
11/18 01:09:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 32.7760%
11/18 01:09:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:09:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.7760%
11/18 01:11:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.5307 (2.3684)	Arch Loss 2.6270 (2.6461)	Arch Hard Loss 2.6163 (2.6352)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.7%)	
11/18 01:12:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.5048 (2.3645)	Arch Loss 2.5764 (2.6609)	Arch Hard Loss 2.5664 (2.6501)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.2%)	
11/18 01:14:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.3643 (2.3651)	Arch Loss 2.0936 (2.6402)	Arch Hard Loss 2.0829 (2.6293)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 70.0%)	
11/18 01:15:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.3447 (2.3765)	Arch Loss 2.2845 (2.6279)	Arch Hard Loss 2.2734 (2.6170)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 69.7%)	
11/18 01:15:57午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 37.4960%
11/18 01:16:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5318	Prec@(1,5) (34.7%, 66.8%)
11/18 01:16:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5601	Prec@(1,5) (34.4%, 66.1%)
11/18 01:16:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5560	Prec@(1,5) (34.3%, 66.0%)
11/18 01:16:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5455	Prec@(1,5) (34.5%, 66.3%)
11/18 01:16:52午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 34.5280%
11/18 01:16:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:16:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5280%
11/18 01:18:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.2467 (2.2460)	Arch Loss 2.7266 (2.6021)	Arch Hard Loss 2.7153 (2.5912)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.3%)	
11/18 01:20:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.9940 (2.2692)	Arch Loss 2.4960 (2.5813)	Arch Hard Loss 2.4848 (2.5704)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.2%)	
11/18 01:21:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.3508 (2.2873)	Arch Loss 2.3445 (2.5905)	Arch Hard Loss 2.3335 (2.5795)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.7%)	
11/18 01:23:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.3256 (2.3010)	Arch Loss 2.2118 (2.5928)	Arch Hard Loss 2.2004 (2.5818)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 71.4%)	
11/18 01:23:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 38.4520%
11/18 01:23:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.5756	Prec@(1,5) (34.3%, 65.5%)
11/18 01:23:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.5705	Prec@(1,5) (34.3%, 65.5%)
11/18 01:23:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.5671	Prec@(1,5) (34.1%, 65.7%)
11/18 01:23:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.5682	Prec@(1,5) (34.2%, 65.6%)
11/18 01:23:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 34.1800%
11/18 01:23:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:23:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5280%
11/18 01:25:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 2.0417 (2.2059)	Arch Loss 2.6911 (2.5362)	Arch Hard Loss 2.6798 (2.5252)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 72.9%)	
11/18 01:27:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.7386 (2.2215)	Arch Loss 2.5225 (2.5488)	Arch Hard Loss 2.5113 (2.5379)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 72.8%)	
11/18 01:28:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.2353 (2.2296)	Arch Loss 2.4816 (2.5519)	Arch Hard Loss 2.4704 (2.5410)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.2%, 72.8%)	
11/18 01:30:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.8267 (2.2414)	Arch Loss 2.6335 (2.5472)	Arch Hard Loss 2.6228 (2.5363)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.6%)	
11/18 01:30:04午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 40.0240%
11/18 01:30:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.4823	Prec@(1,5) (35.7%, 68.3%)
11/18 01:30:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.5186	Prec@(1,5) (35.6%, 67.5%)
11/18 01:30:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.5195	Prec@(1,5) (35.4%, 67.5%)
11/18 01:31:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.5168	Prec@(1,5) (35.4%, 67.4%)
11/18 01:31:01午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 35.3480%
11/18 01:31:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:31:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.3480%
11/18 01:32:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.4405 (2.0907)	Arch Loss 2.3428 (2.5713)	Arch Hard Loss 2.3312 (2.5603)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.5%)	
11/18 01:34:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.3168 (2.1465)	Arch Loss 2.4484 (2.5604)	Arch Hard Loss 2.4366 (2.5494)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 74.4%)	
11/18 01:35:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 2.0085 (2.1643)	Arch Loss 2.4425 (2.5409)	Arch Hard Loss 2.4312 (2.5298)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.2%)	
11/18 01:37:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.3209 (2.1650)	Arch Loss 2.6460 (2.5257)	Arch Hard Loss 2.6349 (2.5146)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 74.2%)	
11/18 01:37:08午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 41.6800%
11/18 01:37:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.4903	Prec@(1,5) (36.1%, 67.5%)
11/18 01:37:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4653	Prec@(1,5) (36.5%, 68.1%)
11/18 01:37:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4622	Prec@(1,5) (36.5%, 68.3%)
11/18 01:38:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4583	Prec@(1,5) (36.5%, 68.3%)
11/18 01:38:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 36.4720%
11/18 01:38:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:38:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.4720%
11/18 01:39:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 2.1213 (2.0833)	Arch Loss 2.4640 (2.4932)	Arch Hard Loss 2.4530 (2.4822)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.5%)	
11/18 01:41:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.9023 (2.0917)	Arch Loss 2.5487 (2.4993)	Arch Hard Loss 2.5375 (2.4883)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.0%)	
11/18 01:42:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 2.2546 (2.1031)	Arch Loss 2.3910 (2.4978)	Arch Hard Loss 2.3791 (2.4869)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.6%)	
11/18 01:44:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7136 (2.1168)	Arch Loss 2.3653 (2.4906)	Arch Hard Loss 2.3544 (2.4796)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.3%)	
11/18 01:44:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 42.9760%
11/18 01:44:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.4839	Prec@(1,5) (37.0%, 68.4%)
11/18 01:44:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.4634	Prec@(1,5) (37.5%, 68.7%)
11/18 01:44:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.4600	Prec@(1,5) (37.3%, 68.6%)
11/18 01:45:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.4493	Prec@(1,5) (37.3%, 68.8%)
11/18 01:45:09午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 37.3200%
11/18 01:45:09午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:45:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.3200%
11/18 01:46:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 2.0695 (1.9848)	Arch Loss 2.3380 (2.4672)	Arch Hard Loss 2.3270 (2.4564)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 77.9%)	
11/18 01:48:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.9921 (2.0133)	Arch Loss 2.1107 (2.4568)	Arch Hard Loss 2.0999 (2.4460)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 77.5%)	
11/18 01:49:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.0512 (2.0374)	Arch Loss 2.4799 (2.4602)	Arch Hard Loss 2.4687 (2.4494)	Arch Alpha Loss 0.0112 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.0%)	
11/18 01:51:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.1031 (2.0449)	Arch Loss 2.4781 (2.4573)	Arch Hard Loss 2.4679 (2.4466)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 76.9%)	
11/18 01:51:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 44.6320%
11/18 01:51:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.4175	Prec@(1,5) (38.1%, 69.7%)
11/18 01:51:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.4140	Prec@(1,5) (38.0%, 69.6%)
11/18 01:52:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.4150	Prec@(1,5) (38.1%, 69.4%)
11/18 01:52:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.4103	Prec@(1,5) (38.2%, 69.5%)
11/18 01:52:14午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 38.2120%
11/18 01:52:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:52:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2120%
11/18 01:53:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.9279 (1.9288)	Arch Loss 2.3360 (2.4094)	Arch Hard Loss 2.3248 (2.3987)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.0%, 79.0%)	
11/18 01:54:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 2.6402 (1.9526)	Arch Loss 2.2641 (2.4178)	Arch Hard Loss 2.2527 (2.4071)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.4%)	
11/18 01:56:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.8383 (1.9709)	Arch Loss 2.2469 (2.4232)	Arch Hard Loss 2.2360 (2.4125)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 77.9%)	
11/18 01:57:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.1623 (1.9813)	Arch Loss 2.2734 (2.4282)	Arch Hard Loss 2.2623 (2.4174)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.7%, 77.7%)	
11/18 01:57:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 45.6840%
11/18 01:58:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.4290	Prec@(1,5) (37.0%, 69.1%)
11/18 01:58:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.4296	Prec@(1,5) (37.3%, 68.8%)
11/18 01:58:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.4372	Prec@(1,5) (37.5%, 68.9%)
11/18 01:58:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.4290	Prec@(1,5) (37.8%, 69.1%)
11/18 01:58:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 37.8160%
11/18 01:58:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 01:58:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2120%
11/18 02:00:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.8437 (1.8719)	Arch Loss 1.9515 (2.3950)	Arch Hard Loss 1.9412 (2.3841)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 79.8%)	
11/18 02:01:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 2.1043 (1.9000)	Arch Loss 2.7281 (2.3980)	Arch Hard Loss 2.7178 (2.3873)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.5%)	
11/18 02:03:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.7606 (1.9085)	Arch Loss 2.7775 (2.4060)	Arch Hard Loss 2.7668 (2.3952)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.3%)	
11/18 02:04:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.9080 (1.9232)	Arch Loss 2.8889 (2.3973)	Arch Hard Loss 2.8781 (2.3864)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.4%, 79.0%)	
11/18 02:04:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 47.3240%
11/18 02:05:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.3478	Prec@(1,5) (39.4%, 71.2%)
11/18 02:05:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.3776	Prec@(1,5) (38.9%, 70.4%)
11/18 02:05:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.3799	Prec@(1,5) (38.9%, 70.5%)
11/18 02:05:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.3722	Prec@(1,5) (39.1%, 70.6%)
11/18 02:05:55午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 39.0680%
11/18 02:05:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 02:05:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.0680%
11/18 02:07:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.4808 (1.8385)	Arch Loss 2.7345 (2.4059)	Arch Hard Loss 2.7236 (2.3950)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.2%)	
11/18 02:09:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.8490 (1.8427)	Arch Loss 2.5351 (2.3987)	Arch Hard Loss 2.5244 (2.3879)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.3%)	
11/18 02:10:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 2.0065 (1.8634)	Arch Loss 2.7640 (2.3799)	Arch Hard Loss 2.7530 (2.3692)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.0%)	
11/18 02:12:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.5482 (1.8688)	Arch Loss 2.3672 (2.3753)	Arch Hard Loss 2.3561 (2.3646)	Arch Alpha Loss 0.0111 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.0%)	
11/18 02:12:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 48.5360%
11/18 02:12:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2632	Prec@(1,5) (40.8%, 72.8%)
11/18 02:12:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.2900	Prec@(1,5) (40.9%, 72.3%)
11/18 02:12:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.3077	Prec@(1,5) (40.6%, 72.0%)
11/18 02:12:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.3077	Prec@(1,5) (40.6%, 72.0%)
11/18 02:12:59午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 40.6000%
11/18 02:13:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 02:13:00午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.6000%
11/18 02:14:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.4753 (1.7202)	Arch Loss 2.3164 (2.3750)	Arch Hard Loss 2.3056 (2.3641)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.9%, 82.5%)	
11/18 02:16:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 2.2233 (1.7541)	Arch Loss 2.2686 (2.3538)	Arch Hard Loss 2.2579 (2.3429)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
11/18 02:17:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.7012 (1.7747)	Arch Loss 1.9704 (2.3618)	Arch Hard Loss 1.9593 (2.3510)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.8%)	
11/18 02:19:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.8230 (1.7904)	Arch Loss 2.0833 (2.3675)	Arch Hard Loss 2.0719 (2.3566)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.6%)	
11/18 02:19:07午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 50.0760%
11/18 02:19:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.3105	Prec@(1,5) (41.2%, 72.0%)
11/18 02:19:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.2854	Prec@(1,5) (41.3%, 72.4%)
11/18 02:19:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.3065	Prec@(1,5) (41.0%, 72.2%)
11/18 02:20:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.3213	Prec@(1,5) (40.6%, 71.9%)
11/18 02:20:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 40.5280%
11/18 02:20:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/18 02:20:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.6000%
11/18 02:21:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.5062 (1.6969)	Arch Loss 2.7451 (2.3645)	Arch Hard Loss 2.7336 (2.3536)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 82.9%)	
11/18 02:23:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5600 (1.7026)	Arch Loss 2.3060 (2.3472)	Arch Hard Loss 2.2945 (2.3363)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.1%)	
11/18 02:24:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.9714 (1.7162)	Arch Loss 2.4549 (2.3418)	Arch Hard Loss 2.4438 (2.3309)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 82.8%)	
