11/19 12:59:26PM parser.py:28 [INFO] 
11/19 12:59:26PM parser.py:29 [INFO] Parameters:
11/19 12:59:26PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g0.1/DAG
11/19 12:59:26PM parser.py:31 [INFO] T=10.0
11/19 12:59:26PM parser.py:31 [INFO] ADVANCED=1
11/19 12:59:26PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/19 12:59:26PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/19 12:59:26PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/19 12:59:26PM parser.py:31 [INFO] BATCH_SIZE=64
11/19 12:59:26PM parser.py:31 [INFO] CASCADE=0
11/19 12:59:26PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/19 12:59:26PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/19 12:59:26PM parser.py:31 [INFO] DATA_PATH=../data/
11/19 12:59:26PM parser.py:31 [INFO] DATASET=cifar100
11/19 12:59:26PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/19 12:59:26PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/19 12:59:26PM parser.py:31 [INFO] DISCRETE=0
11/19 12:59:26PM parser.py:31 [INFO] EPOCHS=50
11/19 12:59:26PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/19 12:59:26PM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g0.1
11/19 12:59:26PM parser.py:31 [INFO] FINAL_L=0.1
11/19 12:59:26PM parser.py:31 [INFO] G=0.1
11/19 12:59:26PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/19 12:59:26PM parser.py:31 [INFO] GPUS=[0]
11/19 12:59:26PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/19 12:59:26PM parser.py:31 [INFO] INIT_CHANNELS=16
11/19 12:59:26PM parser.py:31 [INFO] L=0.1
11/19 12:59:26PM parser.py:31 [INFO] LAYERS=32
11/19 12:59:26PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/19 12:59:26PM parser.py:31 [INFO] NAME=Pruning
11/19 12:59:26PM parser.py:31 [INFO] NONKD=1
11/19 12:59:26PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g0.1
11/19 12:59:26PM parser.py:31 [INFO] PCDARTS=0
11/19 12:59:26PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g0.1/plots
11/19 12:59:26PM parser.py:31 [INFO] PRINT_FREQ=100
11/19 12:59:26PM parser.py:31 [INFO] RESET=0
11/19 12:59:26PM parser.py:31 [INFO] RESUME_PATH=None
11/19 12:59:26PM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g0.1
11/19 12:59:26PM parser.py:31 [INFO] SEED=0
11/19 12:59:26PM parser.py:31 [INFO] SHARE_STAGE=0
11/19 12:59:26PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/19 12:59:26PM parser.py:31 [INFO] SPEC_CELL=1
11/19 12:59:26PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/19 12:59:26PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/19 12:59:26PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/19 12:59:26PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/19 12:59:26PM parser.py:31 [INFO] TYPE=ArchKD
11/19 12:59:26PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/19 12:59:26PM parser.py:31 [INFO] W_LR=0.025
11/19 12:59:26PM parser.py:31 [INFO] W_LR_MIN=0.001
11/19 12:59:26PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/19 12:59:26PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/19 12:59:26PM parser.py:31 [INFO] WORKERS=4
11/19 12:59:26PM parser.py:32 [INFO] 
11/19 12:59:28PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/19 12:59:28PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/19 01:00:14PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6145 (4.7197)	Arch Loss 4.4215 (4.7183)	Arch Hard Loss 4.4205 (4.7169)	Arch Alpha Loss 0.0094 (0.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.3%, 6.2%)	
11/19 01:00:57PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2034 (4.5438)	Arch Loss 4.3140 (4.5432)	Arch Hard Loss 4.3130 (4.5420)	Arch Alpha Loss 0.0101 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 10.5%)	
11/19 01:01:41PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2211 (4.4279)	Arch Loss 4.2731 (4.4234)	Arch Hard Loss 4.2721 (4.4223)	Arch Alpha Loss 0.0107 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.1%, 13.5%)	
11/19 01:02:20PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.3097 (4.3568)	Arch Loss 3.9795 (4.3491)	Arch Hard Loss 3.9784 (4.3480)	Arch Alpha Loss 0.0104 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.7%, 15.4%)	
11/19 01:02:21PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 3.7400%
11/19 01:02:28PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0760	Prec@(1,5) (6.2%, 22.8%)
11/19 01:02:35PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.0767	Prec@(1,5) (6.2%, 22.7%)
11/19 01:02:42PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0835	Prec@(1,5) (6.2%, 22.7%)
11/19 01:02:48PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0822	Prec@(1,5) (6.2%, 22.9%)
11/19 01:02:48PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 6.2240%
11/19 01:02:48PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('skip_connect', 1), ('avg_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 01:02:48PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 6.2240%
11/19 01:03:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.1915 (4.0599)	Arch Loss 4.1559 (4.0630)	Arch Hard Loss 4.1549 (4.0620)	Arch Alpha Loss 0.0102 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.5%, 23.5%)	
11/19 01:04:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.9811 (4.0291)	Arch Loss 4.0056 (4.0426)	Arch Hard Loss 4.0046 (4.0416)	Arch Alpha Loss 0.0100 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.8%, 24.6%)	
11/19 01:04:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7545 (4.0077)	Arch Loss 3.6354 (4.0141)	Arch Hard Loss 3.6344 (4.0130)	Arch Alpha Loss 0.0104 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.1%, 25.3%)	
11/19 01:05:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7697 (3.9930)	Arch Loss 3.8922 (3.9913)	Arch Hard Loss 3.8912 (3.9903)	Arch Alpha Loss 0.0096 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.4%, 25.9%)	
11/19 01:05:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 7.4280%
11/19 01:05:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.9557	Prec@(1,5) (7.7%, 28.5%)
11/19 01:05:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.9900	Prec@(1,5) (7.5%, 27.8%)
11/19 01:05:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.9799	Prec@(1,5) (7.8%, 28.1%)
11/19 01:06:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.9794	Prec@(1,5) (7.9%, 28.1%)
11/19 01:06:05午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 7.9280%
11/19 01:06:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 0)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:06:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.9280%
11/19 01:06:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.7614 (3.8559)	Arch Loss 3.9207 (3.9294)	Arch Hard Loss 3.9196 (3.9283)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.2%, 30.1%)	
11/19 01:07:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8591 (3.8538)	Arch Loss 3.8041 (3.8770)	Arch Hard Loss 3.8030 (3.8759)	Arch Alpha Loss 0.0115 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.5%, 30.7%)	
11/19 01:08:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 4.0430 (3.8450)	Arch Loss 3.9159 (3.8550)	Arch Hard Loss 3.9149 (3.8539)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.5%, 31.0%)	
11/19 01:08:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.8933 (3.8317)	Arch Loss 3.6026 (3.8329)	Arch Hard Loss 3.6016 (3.8319)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.7%, 31.4%)	
11/19 01:08:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 9.6760%
11/19 01:09:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.7562	Prec@(1,5) (10.7%, 34.7%)
11/19 01:09:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.7548	Prec@(1,5) (10.5%, 34.7%)
11/19 01:09:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.7433	Prec@(1,5) (10.5%, 34.9%)
11/19 01:09:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.7399	Prec@(1,5) (10.6%, 34.8%)
11/19 01:09:22午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 10.6000%
11/19 01:09:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/19 01:09:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 10.6000%
11/19 01:10:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5592 (3.7154)	Arch Loss 3.3779 (3.7468)	Arch Hard Loss 3.3769 (3.7457)	Arch Alpha Loss 0.0101 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.6%, 34.3%)	
11/19 01:10:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.6357 (3.7056)	Arch Loss 3.6921 (3.7130)	Arch Hard Loss 3.6910 (3.7119)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.2%, 34.9%)	
11/19 01:11:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.7296 (3.6944)	Arch Loss 3.7278 (3.6982)	Arch Hard Loss 3.7267 (3.6971)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.3%, 35.2%)	
11/19 01:12:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6974 (3.6874)	Arch Loss 3.7955 (3.6845)	Arch Hard Loss 3.7945 (3.6834)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.5%, 35.5%)	
11/19 01:12:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 12.5000%
11/19 01:12:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.6916	Prec@(1,5) (12.7%, 36.0%)
11/19 01:12:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.6943	Prec@(1,5) (12.7%, 36.2%)
11/19 01:12:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.6873	Prec@(1,5) (12.7%, 36.1%)
11/19 01:12:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.6819	Prec@(1,5) (12.8%, 36.3%)
11/19 01:12:38午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 12.8360%
11/19 01:12:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/19 01:12:39午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.8360%
11/19 01:13:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.4234 (3.5486)	Arch Loss 3.9605 (3.5971)	Arch Hard Loss 3.9594 (3.5960)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.0%, 39.7%)	
11/19 01:14:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.7527 (3.5672)	Arch Loss 3.6911 (3.5799)	Arch Hard Loss 3.6900 (3.5788)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.6%, 39.1%)	
11/19 01:14:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.2590 (3.5503)	Arch Loss 3.1377 (3.5550)	Arch Hard Loss 3.1365 (3.5539)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.6%, 39.7%)	
11/19 01:15:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.6651 (3.5393)	Arch Loss 3.5778 (3.5469)	Arch Hard Loss 3.5767 (3.5457)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 40.1%)	
11/19 01:15:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 14.9320%
11/19 01:15:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5764	Prec@(1,5) (14.4%, 39.4%)
11/19 01:15:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5723	Prec@(1,5) (14.2%, 39.4%)
11/19 01:15:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5796	Prec@(1,5) (14.0%, 39.3%)
11/19 01:15:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5781	Prec@(1,5) (14.0%, 39.4%)
11/19 01:15:55午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 13.9640%
11/19 01:15:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/19 01:15:55午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.9640%
11/19 01:16:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.6022 (3.4482)	Arch Loss 3.7670 (3.4778)	Arch Hard Loss 3.7658 (3.4767)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.0%, 43.3%)	
11/19 01:17:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.6084 (3.4567)	Arch Loss 3.6334 (3.4717)	Arch Hard Loss 3.6322 (3.4706)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.4%, 43.0%)	
11/19 01:18:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.2656 (3.4330)	Arch Loss 3.9191 (3.4475)	Arch Hard Loss 3.9180 (3.4465)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.8%, 43.5%)	
11/19 01:18:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.3593 (3.4259)	Arch Loss 3.5040 (3.4397)	Arch Hard Loss 3.5028 (3.4386)	Arch Alpha Loss 0.0124 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.8%, 43.7%)	
11/19 01:18:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 16.8520%
11/19 01:18:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.5061	Prec@(1,5) (14.5%, 41.8%)
11/19 01:18:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.5356	Prec@(1,5) (14.1%, 41.5%)
11/19 01:19:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.5334	Prec@(1,5) (14.4%, 41.8%)
11/19 01:19:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.5396	Prec@(1,5) (14.4%, 41.8%)
11/19 01:19:12午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 14.3920%
11/19 01:19:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/19 01:19:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.3920%
11/19 01:19:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.0688 (3.3376)	Arch Loss 3.3823 (3.3874)	Arch Hard Loss 3.3813 (3.3863)	Arch Alpha Loss 0.0102 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.0%, 45.6%)	
11/19 01:20:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.3396 (3.3262)	Arch Loss 3.6113 (3.3801)	Arch Hard Loss 3.6101 (3.3790)	Arch Alpha Loss 0.0122 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.6%, 45.9%)	
11/19 01:21:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.4254 (3.3107)	Arch Loss 3.4093 (3.3517)	Arch Hard Loss 3.4081 (3.3506)	Arch Alpha Loss 0.0117 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.9%, 46.3%)	
11/19 01:22:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.3421 (3.3034)	Arch Loss 3.1797 (3.3460)	Arch Hard Loss 3.1786 (3.3448)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 46.6%)	
11/19 01:22:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 19.0080%
11/19 01:22:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.2852	Prec@(1,5) (19.4%, 47.7%)
11/19 01:22:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3201	Prec@(1,5) (19.2%, 47.0%)
11/19 01:22:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.3103	Prec@(1,5) (19.3%, 47.2%)
11/19 01:22:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.3087	Prec@(1,5) (19.3%, 47.4%)
11/19 01:22:31午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 19.3160%
11/19 01:22:31午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/19 01:22:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.3160%
11/19 01:23:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.1355 (3.2489)	Arch Loss 3.2260 (3.2921)	Arch Hard Loss 3.2249 (3.2910)	Arch Alpha Loss 0.0108 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.6%, 48.9%)	
11/19 01:24:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.5508 (3.2326)	Arch Loss 3.5377 (3.2922)	Arch Hard Loss 3.5365 (3.2911)	Arch Alpha Loss 0.0119 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.0%, 49.2%)	
11/19 01:24:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.2136 (3.2144)	Arch Loss 2.9583 (3.2661)	Arch Hard Loss 2.9571 (3.2650)	Arch Alpha Loss 0.0115 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.4%, 49.4%)	
11/19 01:25:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.9975 (3.2052)	Arch Loss 3.5463 (3.2542)	Arch Hard Loss 3.5452 (3.2531)	Arch Alpha Loss 0.0102 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.8%)	
11/19 01:25:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 20.6000%
11/19 01:25:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.2578	Prec@(1,5) (20.5%, 49.2%)
11/19 01:25:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.2551	Prec@(1,5) (20.2%, 49.2%)
11/19 01:25:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.2532	Prec@(1,5) (19.9%, 49.2%)
11/19 01:25:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.2559	Prec@(1,5) (19.9%, 49.0%)
11/19 01:25:55午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 19.9240%
11/19 01:25:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 01:25:55午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.9240%
11/19 01:26:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.1267 (3.0853)	Arch Loss 3.3966 (3.1870)	Arch Hard Loss 3.3954 (3.1859)	Arch Alpha Loss 0.0120 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.9%, 52.9%)	
11/19 01:27:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.4283 (3.1122)	Arch Loss 2.9458 (3.1745)	Arch Hard Loss 2.9446 (3.1734)	Arch Alpha Loss 0.0112 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 52.2%)	
11/19 01:28:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.5034 (3.1125)	Arch Loss 3.1049 (3.1725)	Arch Hard Loss 3.1039 (3.1714)	Arch Alpha Loss 0.0104 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 52.2%)	
11/19 01:28:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.0920 (3.1076)	Arch Loss 3.4107 (3.1620)	Arch Hard Loss 3.4096 (3.1609)	Arch Alpha Loss 0.0104 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.9%, 52.4%)	
11/19 01:28:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 22.9360%
11/19 01:28:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1777	Prec@(1,5) (22.0%, 50.6%)
11/19 01:29:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1800	Prec@(1,5) (21.7%, 50.7%)
11/19 01:29:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1803	Prec@(1,5) (22.0%, 50.9%)
11/19 01:29:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1815	Prec@(1,5) (21.8%, 50.9%)
11/19 01:29:14午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 21.7680%
11/19 01:29:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 01:29:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.7680%
11/19 01:29:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.7799 (3.0050)	Arch Loss 3.0564 (3.1303)	Arch Hard Loss 3.0553 (3.1292)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.3%, 54.9%)	
11/19 01:30:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.2862 (3.0043)	Arch Loss 3.0371 (3.1084)	Arch Hard Loss 3.0359 (3.1072)	Arch Alpha Loss 0.0119 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.1%, 54.7%)	
11/19 01:31:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.3891 (2.9992)	Arch Loss 3.1651 (3.0915)	Arch Hard Loss 3.1639 (3.0904)	Arch Alpha Loss 0.0112 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.4%, 55.0%)	
11/19 01:32:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.8881 (3.0010)	Arch Loss 2.8143 (3.0731)	Arch Hard Loss 2.8132 (3.0720)	Arch Alpha Loss 0.0119 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.4%, 55.2%)	
11/19 01:32:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 24.4440%
11/19 01:32:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.0175	Prec@(1,5) (24.6%, 54.7%)
11/19 01:32:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.0026	Prec@(1,5) (24.6%, 55.2%)
11/19 01:32:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.0208	Prec@(1,5) (24.5%, 54.6%)
11/19 01:32:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.0237	Prec@(1,5) (24.5%, 54.5%)
11/19 01:32:32午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 24.4680%
11/19 01:32:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/19 01:32:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.4680%
11/19 01:33:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 3.0012 (2.9103)	Arch Loss 2.8059 (3.0027)	Arch Hard Loss 2.8049 (3.0016)	Arch Alpha Loss 0.0099 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.3%, 57.3%)	
11/19 01:34:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.9509 (2.9127)	Arch Loss 3.2679 (3.0120)	Arch Hard Loss 3.2668 (3.0109)	Arch Alpha Loss 0.0109 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.4%, 57.6%)	
11/19 01:34:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.6235 (2.9100)	Arch Loss 2.6828 (3.0040)	Arch Hard Loss 2.6817 (3.0029)	Arch Alpha Loss 0.0115 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 57.6%)	
11/19 01:35:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.8151 (2.9085)	Arch Loss 3.1632 (2.9929)	Arch Hard Loss 3.1621 (2.9918)	Arch Alpha Loss 0.0114 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 57.6%)	
11/19 01:35:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 26.5240%
11/19 01:35:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.0294	Prec@(1,5) (23.9%, 55.0%)
11/19 01:35:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.0027	Prec@(1,5) (24.9%, 55.5%)
11/19 01:36:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.9938	Prec@(1,5) (25.1%, 55.7%)
11/19 01:36:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.9984	Prec@(1,5) (25.0%, 55.7%)
11/19 01:36:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 25.0160%
11/19 01:36:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/19 01:36:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.0160%
11/19 01:36:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.7329 (2.8239)	Arch Loss 2.8798 (2.9627)	Arch Hard Loss 2.8787 (2.9616)	Arch Alpha Loss 0.0109 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.8%, 59.7%)	
11/19 01:37:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 3.0521 (2.8230)	Arch Loss 2.6265 (2.9406)	Arch Hard Loss 2.6256 (2.9394)	Arch Alpha Loss 0.0096 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 59.7%)	
11/19 01:38:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.7425 (2.8202)	Arch Loss 2.9991 (2.9229)	Arch Hard Loss 2.9979 (2.9218)	Arch Alpha Loss 0.0123 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.4%, 59.7%)	
11/19 01:39:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.9090 (2.8151)	Arch Loss 2.2047 (2.9158)	Arch Hard Loss 2.2036 (2.9147)	Arch Alpha Loss 0.0109 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.6%, 59.8%)	
11/19 01:39:18午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 28.6680%
11/19 01:39:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 3.0062	Prec@(1,5) (25.8%, 55.3%)
11/19 01:39:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 3.0108	Prec@(1,5) (25.7%, 55.2%)
11/19 01:39:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9986	Prec@(1,5) (25.6%, 55.3%)
11/19 01:39:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 3.0026	Prec@(1,5) (25.4%, 55.3%)
11/19 01:39:46午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 25.3920%
11/19 01:39:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:39:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.3920%
11/19 01:40:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.3760 (2.7473)	Arch Loss 2.7134 (2.8579)	Arch Hard Loss 2.7123 (2.8568)	Arch Alpha Loss 0.0110 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.6%, 61.1%)	
11/19 01:41:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.6591 (2.7379)	Arch Loss 2.4938 (2.8672)	Arch Hard Loss 2.4927 (2.8661)	Arch Alpha Loss 0.0104 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 61.5%)	
11/19 01:42:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.8238 (2.7368)	Arch Loss 2.8968 (2.8537)	Arch Hard Loss 2.8957 (2.8526)	Arch Alpha Loss 0.0112 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.0%, 61.6%)	
11/19 01:42:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 3.0146 (2.7372)	Arch Loss 2.8969 (2.8506)	Arch Hard Loss 2.8958 (2.8495)	Arch Alpha Loss 0.0109 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.1%, 61.6%)	
11/19 01:42:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 30.1080%
11/19 01:43:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.9504	Prec@(1,5) (25.8%, 58.0%)
11/19 01:43:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.9526	Prec@(1,5) (26.0%, 57.8%)
11/19 01:43:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.9632	Prec@(1,5) (26.2%, 57.4%)
11/19 01:43:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.9613	Prec@(1,5) (26.2%, 57.5%)
11/19 01:43:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 26.2520%
11/19 01:43:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:43:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.2520%
11/19 01:44:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.4695 (2.6467)	Arch Loss 2.8083 (2.8036)	Arch Hard Loss 2.8073 (2.8025)	Arch Alpha Loss 0.0097 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.8%)	
11/19 01:45:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 3.1683 (2.6649)	Arch Loss 2.9566 (2.8158)	Arch Hard Loss 2.9555 (2.8147)	Arch Alpha Loss 0.0113 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.5%)	
11/19 01:45:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.8460 (2.6558)	Arch Loss 2.3363 (2.8008)	Arch Hard Loss 2.3352 (2.7997)	Arch Alpha Loss 0.0111 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.6%)	
11/19 01:46:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.3708 (2.6606)	Arch Loss 2.6905 (2.8004)	Arch Hard Loss 2.6894 (2.7992)	Arch Alpha Loss 0.0115 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.6%)	
11/19 01:46:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 31.1480%
11/19 01:46:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.7226	Prec@(1,5) (30.1%, 62.1%)
11/19 01:46:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.7333	Prec@(1,5) (30.5%, 61.5%)
11/19 01:46:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.7412	Prec@(1,5) (30.3%, 61.3%)
11/19 01:47:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.7412	Prec@(1,5) (30.4%, 61.5%)
11/19 01:47:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 30.4640%
11/19 01:47:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:47:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.4640%
11/19 01:47:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.8343 (2.5536)	Arch Loss 2.7452 (2.7480)	Arch Hard Loss 2.7440 (2.7469)	Arch Alpha Loss 0.0114 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.2%, 65.5%)	
11/19 01:48:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.6531 (2.5649)	Arch Loss 2.6380 (2.7470)	Arch Hard Loss 2.6369 (2.7459)	Arch Alpha Loss 0.0111 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.5%, 65.6%)	
11/19 01:49:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.6973 (2.5726)	Arch Loss 2.5325 (2.7409)	Arch Hard Loss 2.5313 (2.7398)	Arch Alpha Loss 0.0122 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.3%, 65.3%)	
11/19 01:50:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.8408 (2.5760)	Arch Loss 2.6487 (2.7382)	Arch Hard Loss 2.6474 (2.7370)	Arch Alpha Loss 0.0122 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.0%, 65.3%)	
11/19 01:50:15午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 33.0280%
11/19 01:50:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.6719	Prec@(1,5) (31.2%, 63.1%)
11/19 01:50:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.6818	Prec@(1,5) (31.4%, 62.8%)
11/19 01:50:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.6787	Prec@(1,5) (31.3%, 63.0%)
11/19 01:50:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.6876	Prec@(1,5) (31.2%, 62.9%)
11/19 01:50:44午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 31.2480%
11/19 01:50:44午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:50:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.2480%
11/19 01:51:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.1606 (2.4818)	Arch Loss 2.8569 (2.7060)	Arch Hard Loss 2.8557 (2.7048)	Arch Alpha Loss 0.0116 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 67.8%)	
11/19 01:52:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.1048 (2.5035)	Arch Loss 2.6051 (2.6892)	Arch Hard Loss 2.6040 (2.6880)	Arch Alpha Loss 0.0115 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 67.1%)	
11/19 01:53:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.2851 (2.5082)	Arch Loss 2.7854 (2.6804)	Arch Hard Loss 2.7843 (2.6793)	Arch Alpha Loss 0.0107 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 67.1%)	
11/19 01:53:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.1335 (2.5164)	Arch Loss 2.5052 (2.6787)	Arch Hard Loss 2.5041 (2.6776)	Arch Alpha Loss 0.0113 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.8%, 66.8%)	
11/19 01:53:53午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 34.7840%
11/19 01:54:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.6470	Prec@(1,5) (32.2%, 63.5%)
11/19 01:54:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.6279	Prec@(1,5) (32.6%, 63.9%)
11/19 01:54:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.6283	Prec@(1,5) (32.5%, 63.9%)
11/19 01:54:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.6231	Prec@(1,5) (32.6%, 63.9%)
11/19 01:54:20午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 32.5760%
11/19 01:54:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:54:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.5760%
11/19 01:55:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.3263 (2.3825)	Arch Loss 2.8597 (2.6568)	Arch Hard Loss 2.8585 (2.6557)	Arch Alpha Loss 0.0116 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 69.7%)	
11/19 01:55:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.3395 (2.4200)	Arch Loss 2.6144 (2.6409)	Arch Hard Loss 2.6132 (2.6397)	Arch Alpha Loss 0.0118 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.7%)	
11/19 01:56:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.6573 (2.4308)	Arch Loss 2.4832 (2.6381)	Arch Hard Loss 2.4821 (2.6369)	Arch Alpha Loss 0.0111 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.4%)	
11/19 01:57:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.5154 (2.4371)	Arch Loss 2.5574 (2.6307)	Arch Hard Loss 2.5564 (2.6295)	Arch Alpha Loss 0.0103 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.3%)	
11/19 01:57:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 35.5800%
11/19 01:57:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.6495	Prec@(1,5) (31.8%, 63.2%)
11/19 01:57:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.6747	Prec@(1,5) (31.6%, 62.8%)
11/19 01:57:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.6701	Prec@(1,5) (31.6%, 63.0%)
11/19 01:57:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.6675	Prec@(1,5) (31.7%, 63.4%)
11/19 01:57:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 31.6760%
11/19 01:57:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 01:57:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.5760%
11/19 01:58:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.1063 (2.3754)	Arch Loss 2.8739 (2.6281)	Arch Hard Loss 2.8727 (2.6270)	Arch Alpha Loss 0.0117 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.7%)	
11/19 01:59:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.1929 (2.3768)	Arch Loss 2.4363 (2.6007)	Arch Hard Loss 2.4351 (2.5996)	Arch Alpha Loss 0.0113 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 69.7%)	
11/19 02:00:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.1941 (2.3675)	Arch Loss 2.4106 (2.6024)	Arch Hard Loss 2.4095 (2.6013)	Arch Alpha Loss 0.0107 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.2%, 69.9%)	
11/19 02:01:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.3097 (2.3710)	Arch Loss 2.6925 (2.5964)	Arch Hard Loss 2.6915 (2.5953)	Arch Alpha Loss 0.0104 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.1%, 69.9%)	
11/19 02:01:03午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 37.1360%
11/19 02:01:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.5179	Prec@(1,5) (35.1%, 66.7%)
11/19 02:01:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.5024	Prec@(1,5) (35.5%, 67.1%)
11/19 02:01:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.5270	Prec@(1,5) (35.1%, 66.6%)
11/19 02:01:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.5346	Prec@(1,5) (34.9%, 66.3%)
11/19 02:01:32午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 34.8480%
11/19 02:01:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:01:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.8480%
11/19 02:02:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.2785 (2.3219)	Arch Loss 2.4940 (2.5648)	Arch Hard Loss 2.4929 (2.5637)	Arch Alpha Loss 0.0106 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.0%, 71.2%)	
11/19 02:03:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.6162 (2.3011)	Arch Loss 2.5559 (2.5716)	Arch Hard Loss 2.5547 (2.5705)	Arch Alpha Loss 0.0117 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.5%)	
11/19 02:03:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.3199 (2.3112)	Arch Loss 2.1234 (2.5545)	Arch Hard Loss 2.1224 (2.5534)	Arch Alpha Loss 0.0103 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.4%, 71.2%)	
11/19 02:04:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.2460 (2.3164)	Arch Loss 2.1611 (2.5389)	Arch Hard Loss 2.1599 (2.5378)	Arch Alpha Loss 0.0123 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.0%)	
11/19 02:04:40午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 38.5040%
11/19 02:04:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5230	Prec@(1,5) (35.0%, 67.2%)
11/19 02:04:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5433	Prec@(1,5) (34.7%, 66.7%)
11/19 02:05:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5376	Prec@(1,5) (34.6%, 67.0%)
11/19 02:05:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5299	Prec@(1,5) (34.7%, 67.0%)
11/19 02:05:07午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 34.7480%
11/19 02:05:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:05:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.8480%
11/19 02:05:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.2644 (2.1865)	Arch Loss 2.6322 (2.5033)	Arch Hard Loss 2.6310 (2.5021)	Arch Alpha Loss 0.0113 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.2%, 74.1%)	
11/19 02:06:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 2.0494 (2.2093)	Arch Loss 2.5068 (2.4993)	Arch Hard Loss 2.5055 (2.4981)	Arch Alpha Loss 0.0127 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.3%, 73.4%)	
11/19 02:07:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.0166 (2.2328)	Arch Loss 2.3639 (2.5010)	Arch Hard Loss 2.3628 (2.4998)	Arch Alpha Loss 0.0111 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 73.0%)	
11/19 02:08:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.2167 (2.2362)	Arch Loss 2.1654 (2.5008)	Arch Hard Loss 2.1643 (2.4996)	Arch Alpha Loss 0.0109 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.0%, 72.8%)	
11/19 02:08:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 40.0160%
11/19 02:08:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.4380	Prec@(1,5) (37.3%, 69.0%)
11/19 02:08:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.4350	Prec@(1,5) (37.2%, 68.8%)
11/19 02:08:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.4337	Prec@(1,5) (37.0%, 68.6%)
11/19 02:08:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.4316	Prec@(1,5) (36.9%, 68.8%)
11/19 02:08:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 36.9000%
11/19 02:08:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:08:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.9000%
11/19 02:09:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.8272 (2.1363)	Arch Loss 2.3257 (2.4266)	Arch Hard Loss 2.3246 (2.4254)	Arch Alpha Loss 0.0106 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.0%, 74.5%)	
11/19 02:10:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.8447 (2.1575)	Arch Loss 2.2554 (2.4569)	Arch Hard Loss 2.2542 (2.4558)	Arch Alpha Loss 0.0118 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 74.2%)	
11/19 02:11:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.3755 (2.1668)	Arch Loss 2.1888 (2.4665)	Arch Hard Loss 2.1876 (2.4654)	Arch Alpha Loss 0.0114 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.2%)	
11/19 02:11:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.8610 (2.1781)	Arch Loss 2.4933 (2.4605)	Arch Hard Loss 2.4921 (2.4594)	Arch Alpha Loss 0.0114 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.6%, 74.0%)	
11/19 02:11:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 41.5600%
11/19 02:11:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.3691	Prec@(1,5) (38.2%, 70.1%)
11/19 02:12:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.3953	Prec@(1,5) (37.7%, 69.6%)
11/19 02:12:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.3883	Prec@(1,5) (37.9%, 69.7%)
11/19 02:12:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.3896	Prec@(1,5) (37.9%, 69.8%)
11/19 02:12:21午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 37.9080%
11/19 02:12:21午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:12:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.9080%
11/19 02:13:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.4366 (2.0352)	Arch Loss 2.1855 (2.4524)	Arch Hard Loss 2.1844 (2.4513)	Arch Alpha Loss 0.0110 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 76.4%)	
11/19 02:14:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.4145 (2.0731)	Arch Loss 2.6762 (2.4452)	Arch Hard Loss 2.6750 (2.4441)	Arch Alpha Loss 0.0115 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 75.8%)	
11/19 02:14:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.9632 (2.0990)	Arch Loss 2.6893 (2.4314)	Arch Hard Loss 2.6882 (2.4302)	Arch Alpha Loss 0.0117 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.4%)	
11/19 02:15:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.0954 (2.1017)	Arch Loss 2.4679 (2.4205)	Arch Hard Loss 2.4667 (2.4193)	Arch Alpha Loss 0.0123 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 75.4%)	
11/19 02:15:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 43.1880%
11/19 02:15:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.4738	Prec@(1,5) (37.0%, 67.8%)
11/19 02:15:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4367	Prec@(1,5) (37.3%, 68.6%)
11/19 02:15:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4308	Prec@(1,5) (37.3%, 68.9%)
11/19 02:16:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4265	Prec@(1,5) (37.2%, 69.2%)
11/19 02:16:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 37.2560%
11/19 02:16:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:16:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.9080%
11/19 02:16:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.9387 (2.0240)	Arch Loss 2.6115 (2.3990)	Arch Hard Loss 2.6104 (2.3978)	Arch Alpha Loss 0.0112 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.0%)	
11/19 02:17:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 2.0412 (2.0436)	Arch Loss 2.5343 (2.4057)	Arch Hard Loss 2.5331 (2.4046)	Arch Alpha Loss 0.0119 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 76.7%)	
11/19 02:18:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.9116 (2.0493)	Arch Loss 2.4157 (2.4007)	Arch Hard Loss 2.4147 (2.3995)	Arch Alpha Loss 0.0105 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.2%, 76.6%)	
11/19 02:18:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7643 (2.0634)	Arch Loss 2.1958 (2.3925)	Arch Hard Loss 2.1947 (2.3914)	Arch Alpha Loss 0.0113 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.4%)	
11/19 02:18:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 43.8960%
11/19 02:19:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.4257	Prec@(1,5) (37.1%, 69.2%)
11/19 02:19:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.4027	Prec@(1,5) (37.8%, 69.5%)
11/19 02:19:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.3873	Prec@(1,5) (38.0%, 69.8%)
11/19 02:19:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.3873	Prec@(1,5) (38.0%, 69.8%)
11/19 02:19:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 37.9960%
11/19 02:19:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:19:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.9960%
11/19 02:20:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.8220 (1.9022)	Arch Loss 2.4816 (2.3556)	Arch Hard Loss 2.4804 (2.3545)	Arch Alpha Loss 0.0123 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.7%)	
11/19 02:20:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.8210 (1.9480)	Arch Loss 1.8397 (2.3522)	Arch Hard Loss 1.8385 (2.3510)	Arch Alpha Loss 0.0112 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.6%, 78.7%)	
11/19 02:21:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.1085 (1.9728)	Arch Loss 2.3081 (2.3660)	Arch Hard Loss 2.3070 (2.3648)	Arch Alpha Loss 0.0115 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 78.2%)	
11/19 02:22:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.1689 (1.9787)	Arch Loss 2.2820 (2.3573)	Arch Hard Loss 2.2807 (2.3562)	Arch Alpha Loss 0.0125 (0.0115)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.9%, 78.0%)	
11/19 02:22:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 45.9240%
11/19 02:22:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.3544	Prec@(1,5) (39.1%, 71.8%)
11/19 02:22:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.3467	Prec@(1,5) (39.1%, 71.3%)
11/19 02:22:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.3537	Prec@(1,5) (39.3%, 71.4%)
11/19 02:22:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.3518	Prec@(1,5) (39.5%, 71.3%)
11/19 02:22:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 39.4840%
11/19 02:22:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:22:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.4840%
11/19 02:23:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.7578 (1.8880)	Arch Loss 2.3513 (2.3258)	Arch Hard Loss 2.3501 (2.3246)	Arch Alpha Loss 0.0122 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.7%)	
11/19 02:24:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 2.4815 (1.9070)	Arch Loss 2.0632 (2.3137)	Arch Hard Loss 2.0620 (2.3125)	Arch Alpha Loss 0.0123 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.6%)	
11/19 02:25:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6937 (1.9192)	Arch Loss 2.3510 (2.3157)	Arch Hard Loss 2.3498 (2.3145)	Arch Alpha Loss 0.0118 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.2%)	
11/19 02:25:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.2651 (1.9296)	Arch Loss 2.2358 (2.3264)	Arch Hard Loss 2.2347 (2.3252)	Arch Alpha Loss 0.0115 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 78.8%)	
11/19 02:25:44午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 46.7120%
11/19 02:25:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.2944	Prec@(1,5) (39.4%, 71.4%)
11/19 02:25:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.3092	Prec@(1,5) (39.6%, 71.8%)
11/19 02:26:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.3244	Prec@(1,5) (39.4%, 71.6%)
11/19 02:26:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.3239	Prec@(1,5) (39.5%, 71.6%)
11/19 02:26:11午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 39.4680%
11/19 02:26:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:26:11午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.4840%
11/19 02:26:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.8578 (1.8265)	Arch Loss 2.0650 (2.2958)	Arch Hard Loss 2.0637 (2.2947)	Arch Alpha Loss 0.0127 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.9%)	
11/19 02:27:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.9416 (1.8465)	Arch Loss 2.7806 (2.3019)	Arch Hard Loss 2.7793 (2.3007)	Arch Alpha Loss 0.0129 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.7%)	
11/19 02:28:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.4506 (1.8507)	Arch Loss 2.4683 (2.3042)	Arch Hard Loss 2.4671 (2.3030)	Arch Alpha Loss 0.0122 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.6%)	
11/19 02:29:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.9298 (1.8674)	Arch Loss 2.7589 (2.2968)	Arch Hard Loss 2.7578 (2.2957)	Arch Alpha Loss 0.0111 (0.0117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 80.2%)	
11/19 02:29:09午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 48.0680%
11/19 02:29:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.2230	Prec@(1,5) (41.7%, 73.7%)
11/19 02:29:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.2659	Prec@(1,5) (41.1%, 72.7%)
11/19 02:29:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.2709	Prec@(1,5) (41.2%, 72.9%)
11/19 02:29:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.2691	Prec@(1,5) (41.3%, 72.8%)
11/19 02:29:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 41.2720%
11/19 02:29:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:29:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.2720%
11/19 02:30:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5372 (1.7720)	Arch Loss 2.6617 (2.3018)	Arch Hard Loss 2.6605 (2.3006)	Arch Alpha Loss 0.0118 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 82.0%)	
11/19 02:31:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.7864 (1.7864)	Arch Loss 2.4504 (2.2886)	Arch Hard Loss 2.4493 (2.2875)	Arch Alpha Loss 0.0116 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.8%)	
11/19 02:31:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.7933 (1.7990)	Arch Loss 2.7342 (2.2771)	Arch Hard Loss 2.7329 (2.2760)	Arch Alpha Loss 0.0128 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.4%)	
11/19 02:32:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.7391 (1.8060)	Arch Loss 2.4253 (2.2765)	Arch Hard Loss 2.4243 (2.2753)	Arch Alpha Loss 0.0104 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 81.4%)	
11/19 02:32:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 49.7920%
11/19 02:32:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2170	Prec@(1,5) (41.8%, 74.1%)
11/19 02:32:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.2455	Prec@(1,5) (41.7%, 73.3%)
11/19 02:32:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.2625	Prec@(1,5) (41.3%, 73.0%)
11/19 02:33:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.2533	Prec@(1,5) (41.5%, 73.2%)
11/19 02:33:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 41.4760%
11/19 02:33:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:33:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.4760%
11/19 02:33:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.4616 (1.7047)	Arch Loss 2.0645 (2.2377)	Arch Hard Loss 2.0633 (2.2365)	Arch Alpha Loss 0.0118 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.8%, 83.2%)	
11/19 02:34:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 2.1434 (1.7270)	Arch Loss 2.1661 (2.2328)	Arch Hard Loss 2.1649 (2.2316)	Arch Alpha Loss 0.0120 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.9%)	
11/19 02:35:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.6126 (1.7478)	Arch Loss 2.1904 (2.2508)	Arch Hard Loss 2.1892 (2.2496)	Arch Alpha Loss 0.0122 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.4%)	
11/19 02:36:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.6194 (1.7531)	Arch Loss 2.1542 (2.2507)	Arch Hard Loss 2.1530 (2.2495)	Arch Alpha Loss 0.0125 (0.0118)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 82.2%)	
11/19 02:36:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 50.9040%
11/19 02:36:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.2964	Prec@(1,5) (42.3%, 72.6%)
11/19 02:36:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.2870	Prec@(1,5) (41.9%, 73.2%)
11/19 02:36:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.3076	Prec@(1,5) (41.7%, 72.9%)
11/19 02:36:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.3146	Prec@(1,5) (41.6%, 72.8%)
11/19 02:36:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 41.5880%
11/19 02:36:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:36:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.5880%
11/19 02:37:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.6930 (1.6523)	Arch Loss 2.7600 (2.2851)	Arch Hard Loss 2.7588 (2.2839)	Arch Alpha Loss 0.0118 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.0%, 83.4%)	
11/19 02:38:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5672 (1.6569)	Arch Loss 2.0307 (2.2538)	Arch Hard Loss 2.0295 (2.2526)	Arch Alpha Loss 0.0117 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.6%, 83.4%)	
11/19 02:38:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.6411 (1.6735)	Arch Loss 2.4201 (2.2510)	Arch Hard Loss 2.4190 (2.2498)	Arch Alpha Loss 0.0112 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.5%)	
11/19 02:39:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.7414 (1.6826)	Arch Loss 1.9656 (2.2400)	Arch Hard Loss 1.9644 (2.2388)	Arch Alpha Loss 0.0112 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.2%)	
11/19 02:39:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 52.8920%
11/19 02:39:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.1942	Prec@(1,5) (43.5%, 74.1%)
11/19 02:39:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.1842	Prec@(1,5) (43.1%, 74.5%)
11/19 02:39:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.1905	Prec@(1,5) (43.0%, 74.3%)
11/19 02:40:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.1950	Prec@(1,5) (43.0%, 74.4%)
11/19 02:40:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 42.9480%
11/19 02:40:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:40:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.9480%
11/19 02:40:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.6542 (1.5827)	Arch Loss 1.8625 (2.2197)	Arch Hard Loss 1.8613 (2.2186)	Arch Alpha Loss 0.0128 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.4%)	
11/19 02:41:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.4394 (1.5880)	Arch Loss 2.2672 (2.2365)	Arch Hard Loss 2.2660 (2.2353)	Arch Alpha Loss 0.0122 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.0%)	
11/19 02:42:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.7983 (1.6016)	Arch Loss 2.3294 (2.2325)	Arch Hard Loss 2.3282 (2.2313)	Arch Alpha Loss 0.0118 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.8%)	
11/19 02:42:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.4340 (1.6144)	Arch Loss 1.9762 (2.2160)	Arch Hard Loss 1.9751 (2.2148)	Arch Alpha Loss 0.0112 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.5%)	
11/19 02:42:58午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 54.3600%
11/19 02:43:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.1953	Prec@(1,5) (44.1%, 75.0%)
11/19 02:43:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.1990	Prec@(1,5) (43.8%, 74.5%)
11/19 02:43:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2087	Prec@(1,5) (43.6%, 74.6%)
11/19 02:43:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2042	Prec@(1,5) (43.6%, 74.5%)
11/19 02:43:24午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 43.5680%
11/19 02:43:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:43:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.5680%
11/19 02:44:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.1942 (1.4944)	Arch Loss 2.1779 (2.2213)	Arch Hard Loss 2.1766 (2.2201)	Arch Alpha Loss 0.0128 (0.0121)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 87.1%)	
11/19 02:44:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.6097 (1.5257)	Arch Loss 2.0048 (2.2058)	Arch Hard Loss 2.0037 (2.2046)	Arch Alpha Loss 0.0108 (0.0121)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.2%)	
11/19 02:45:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.3999 (1.5401)	Arch Loss 2.2502 (2.1976)	Arch Hard Loss 2.2491 (2.1964)	Arch Alpha Loss 0.0117 (0.0121)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.8%)	
11/19 02:46:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.6188 (1.5608)	Arch Loss 2.2940 (2.1980)	Arch Hard Loss 2.2928 (2.1968)	Arch Alpha Loss 0.0121 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.3%)	
11/19 02:46:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 55.7560%
11/19 02:46:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.1183	Prec@(1,5) (44.4%, 76.3%)
11/19 02:46:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.1256	Prec@(1,5) (44.6%, 75.6%)
11/19 02:46:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.1218	Prec@(1,5) (44.8%, 75.9%)
11/19 02:46:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.1319	Prec@(1,5) (44.6%, 75.6%)
11/19 02:46:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 44.5560%
11/19 02:46:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:46:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.5560%
11/19 02:47:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.7277 (1.4592)	Arch Loss 1.8792 (2.1625)	Arch Hard Loss 1.8779 (2.1613)	Arch Alpha Loss 0.0125 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 86.8%)	
11/19 02:48:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.9253 (1.4916)	Arch Loss 2.1328 (2.1831)	Arch Hard Loss 2.1316 (2.1819)	Arch Alpha Loss 0.0121 (0.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.4%)	
11/19 02:49:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 2.0706 (1.5020)	Arch Loss 2.4051 (2.1903)	Arch Hard Loss 2.4038 (2.1891)	Arch Alpha Loss 0.0129 (0.0121)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.2%)	
11/19 02:49:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.6486 (1.5112)	Arch Loss 2.2110 (2.1837)	Arch Hard Loss 2.2098 (2.1825)	Arch Alpha Loss 0.0119 (0.0121)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.8%, 86.2%)	
11/19 02:49:53午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 56.7280%
11/19 02:50:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1136	Prec@(1,5) (44.8%, 76.2%)
11/19 02:50:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1226	Prec@(1,5) (45.1%, 76.0%)
11/19 02:50:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.1536	Prec@(1,5) (44.4%, 75.6%)
11/19 02:50:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.1575	Prec@(1,5) (44.4%, 75.6%)
11/19 02:50:21午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 44.3520%
11/19 02:50:21午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/19 02:50:21午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.5560%
11/19 02:51:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.1944 (1.3992)	Arch Loss 2.7985 (2.1967)	Arch Hard Loss 2.7974 (2.1954)	Arch Alpha Loss 0.0113 (0.0122)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.3%)	
11/19 02:51:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.6232 (1.4213)	Arch Loss 2.0783 (2.1983)	Arch Hard Loss 2.0772 (2.1970)	Arch Alpha Loss 0.0115 (0.0122)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.8%)	
11/19 02:52:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.5382 (1.4312)	Arch Loss 2.0915 (2.1940)	Arch Hard Loss 2.0903 (2.1928)	Arch Alpha Loss 0.0121 (0.0122)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.7%)	
11/19 02:53:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.6440 (1.4505)	Arch Loss 1.8568 (2.1918)	Arch Hard Loss 1.8555 (2.1906)	Arch Alpha Loss 0.0127 (0.0122)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.3%)	
11/19 02:53:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 58.0640%
11/19 02:53:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.1964	Prec@(1,5) (45.2%, 75.6%)
11/19 02:53:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1922	Prec@(1,5) (44.6%, 75.1%)
11/19 02:53:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1976	Prec@(1,5) (44.1%, 75.0%)
11/19 02:53:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.1973	Prec@(1,5) (44.1%, 75.0%)
11/19 02:53:48午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 44.1560%
11/19 02:53:48午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 02:53:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.5560%
11/19 02:54:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.1694 (1.3326)	Arch Loss 1.8997 (2.1206)	Arch Hard Loss 1.8986 (2.1194)	Arch Alpha Loss 0.0115 (0.0123)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 89.0%)	
11/19 02:55:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.6741 (1.3605)	Arch Loss 2.3083 (2.1536)	Arch Hard Loss 2.3072 (2.1523)	Arch Alpha Loss 0.0113 (0.0124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.6%)	
11/19 02:56:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.9240 (1.3857)	Arch Loss 1.9451 (2.1567)	Arch Hard Loss 1.9438 (2.1554)	Arch Alpha Loss 0.0130 (0.0124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.3%)	
11/19 02:56:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1334 (1.3928)	Arch Loss 1.9762 (2.1593)	Arch Hard Loss 1.9749 (2.1581)	Arch Alpha Loss 0.0129 (0.0124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.2%)	
11/19 02:56:48午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 59.6680%
11/19 02:56:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.0962	Prec@(1,5) (46.3%, 76.8%)
11/19 02:57:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.0975	Prec@(1,5) (46.4%, 76.7%)
11/19 02:57:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.0967	Prec@(1,5) (46.5%, 76.6%)
11/19 02:57:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.0975	Prec@(1,5) (46.6%, 76.5%)
11/19 02:57:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 46.6160%
11/19 02:57:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 02:57:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6160%
11/19 02:58:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.2049 (1.2726)	Arch Loss 2.1513 (2.1787)	Arch Hard Loss 2.1502 (2.1775)	Arch Alpha Loss 0.0111 (0.0123)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 90.1%)	
11/19 02:58:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.4849 (1.3149)	Arch Loss 1.8226 (2.1825)	Arch Hard Loss 1.8212 (2.1812)	Arch Alpha Loss 0.0133 (0.0124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.3%)	
11/19 02:59:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.2951 (1.3182)	Arch Loss 1.5691 (2.1606)	Arch Hard Loss 1.5678 (2.1594)	Arch Alpha Loss 0.0123 (0.0123)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.2%)	
11/19 03:00:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0976 (1.3227)	Arch Loss 2.2810 (2.1584)	Arch Hard Loss 2.2797 (2.1571)	Arch Alpha Loss 0.0128 (0.0124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 89.3%)	
11/19 03:00:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 61.4160%
11/19 03:00:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1377	Prec@(1,5) (45.4%, 76.5%)
11/19 03:00:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1516	Prec@(1,5) (45.2%, 76.5%)
11/19 03:00:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1349	Prec@(1,5) (45.7%, 76.7%)
11/19 03:00:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1291	Prec@(1,5) (45.9%, 76.6%)
11/19 03:00:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 45.8920%
11/19 03:00:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:00:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6160%
11/19 03:01:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.0861 (1.2169)	Arch Loss 2.2644 (2.1547)	Arch Hard Loss 2.2631 (2.1535)	Arch Alpha Loss 0.0126 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.7%)	
11/19 03:02:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.2698 (1.2344)	Arch Loss 1.6622 (2.1718)	Arch Hard Loss 1.6609 (2.1706)	Arch Alpha Loss 0.0132 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.4%)	
11/19 03:03:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.2620 (1.2524)	Arch Loss 2.4156 (2.1855)	Arch Hard Loss 2.4143 (2.1842)	Arch Alpha Loss 0.0126 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.3%)	
11/19 03:03:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.2487 (1.2612)	Arch Loss 1.4982 (2.1720)	Arch Hard Loss 1.4970 (2.1708)	Arch Alpha Loss 0.0125 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.1%)	
11/19 03:03:45午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 63.0000%
11/19 03:03:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.1506	Prec@(1,5) (46.2%, 76.7%)
11/19 03:04:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.1628	Prec@(1,5) (46.2%, 76.4%)
11/19 03:04:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.1548	Prec@(1,5) (46.3%, 76.5%)
11/19 03:04:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.1491	Prec@(1,5) (46.4%, 76.6%)
11/19 03:04:14午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 46.3960%
11/19 03:04:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:04:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6160%
11/19 03:05:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.2880 (1.1631)	Arch Loss 2.4580 (2.1253)	Arch Hard Loss 2.4567 (2.1241)	Arch Alpha Loss 0.0128 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.2%)	
11/19 03:05:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.1743 (1.1760)	Arch Loss 2.1335 (2.1291)	Arch Hard Loss 2.1323 (2.1279)	Arch Alpha Loss 0.0127 (0.0125)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.4%)	
11/19 03:06:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.3831 (1.2098)	Arch Loss 2.0011 (2.1473)	Arch Hard Loss 1.9999 (2.1460)	Arch Alpha Loss 0.0127 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.7%)	
11/19 03:07:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.0828 (1.2111)	Arch Loss 2.7165 (2.1537)	Arch Hard Loss 2.7153 (2.1524)	Arch Alpha Loss 0.0119 (0.0126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.6%)	
11/19 03:07:18午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 64.1280%
11/19 03:07:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.1195	Prec@(1,5) (46.8%, 77.4%)
11/19 03:07:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.1045	Prec@(1,5) (47.3%, 77.4%)
11/19 03:07:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.0991	Prec@(1,5) (47.5%, 77.4%)
11/19 03:07:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.1123	Prec@(1,5) (47.1%, 77.3%)
11/19 03:07:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 47.0800%
11/19 03:07:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:07:45午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0800%
11/19 03:08:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.2179 (1.1070)	Arch Loss 1.9471 (2.1576)	Arch Hard Loss 1.9458 (2.1563)	Arch Alpha Loss 0.0134 (0.0128)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.1%)	
11/19 03:09:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.3613 (1.1102)	Arch Loss 2.5289 (2.1630)	Arch Hard Loss 2.5276 (2.1618)	Arch Alpha Loss 0.0125 (0.0128)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.0%)	
11/19 03:10:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.3783 (1.1260)	Arch Loss 2.2557 (2.1534)	Arch Hard Loss 2.2543 (2.1521)	Arch Alpha Loss 0.0132 (0.0128)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.9%)	
11/19 03:10:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.1810 (1.1404)	Arch Loss 2.7295 (2.1540)	Arch Hard Loss 2.7282 (2.1527)	Arch Alpha Loss 0.0130 (0.0128)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.6%)	
11/19 03:10:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 66.3800%
11/19 03:10:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1208	Prec@(1,5) (46.6%, 77.6%)
11/19 03:11:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1263	Prec@(1,5) (46.6%, 77.3%)
11/19 03:11:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1444	Prec@(1,5) (46.4%, 77.1%)
11/19 03:11:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1434	Prec@(1,5) (46.6%, 77.1%)
11/19 03:11:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 46.6200%
11/19 03:11:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:11:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0800%
11/19 03:12:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 1.0095 (1.0466)	Arch Loss 2.1331 (2.1938)	Arch Hard Loss 2.1318 (2.1925)	Arch Alpha Loss 0.0124 (0.0129)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.0%)	
11/19 03:12:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7712 (1.0575)	Arch Loss 1.9902 (2.1745)	Arch Hard Loss 1.9887 (2.1733)	Arch Alpha Loss 0.0150 (0.0129)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.8%)	
11/19 03:13:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.2350 (1.0696)	Arch Loss 2.3902 (2.1790)	Arch Hard Loss 2.3889 (2.1777)	Arch Alpha Loss 0.0133 (0.0129)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
11/19 03:14:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.2382 (1.0794)	Arch Loss 2.1101 (2.1712)	Arch Hard Loss 2.1088 (2.1699)	Arch Alpha Loss 0.0134 (0.0129)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.4%)	
11/19 03:14:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 67.7680%
11/19 03:14:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.0728	Prec@(1,5) (48.4%, 78.3%)
11/19 03:14:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.0922	Prec@(1,5) (48.2%, 77.9%)
11/19 03:14:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.0979	Prec@(1,5) (48.1%, 77.9%)
11/19 03:14:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.1181	Prec@(1,5) (47.8%, 77.6%)
11/19 03:14:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 47.7960%
11/19 03:14:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:14:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.7960%
11/19 03:15:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 1.2292 (0.9836)	Arch Loss 2.2131 (2.1900)	Arch Hard Loss 2.2118 (2.1886)	Arch Alpha Loss 0.0131 (0.0131)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.8%)	
11/19 03:16:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 1.1998 (0.9918)	Arch Loss 1.5180 (2.1946)	Arch Hard Loss 1.5167 (2.1933)	Arch Alpha Loss 0.0128 (0.0130)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.7%)	
11/19 03:16:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 1.2835 (1.0035)	Arch Loss 1.8785 (2.1788)	Arch Hard Loss 1.8771 (2.1775)	Arch Alpha Loss 0.0140 (0.0131)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.5%)	
11/19 03:17:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.9431 (1.0091)	Arch Loss 2.1829 (2.1684)	Arch Hard Loss 2.1816 (2.1671)	Arch Alpha Loss 0.0130 (0.0130)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.3%)	
11/19 03:17:40午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 69.9400%
11/19 03:17:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1062	Prec@(1,5) (47.9%, 78.2%)
11/19 03:17:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.0940	Prec@(1,5) (48.0%, 78.1%)
11/19 03:18:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1017	Prec@(1,5) (47.9%, 78.0%)
11/19 03:18:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1046	Prec@(1,5) (47.9%, 77.9%)
11/19 03:18:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 47.9200%
11/19 03:18:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:18:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9200%
11/19 03:18:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 1.0116 (0.9192)	Arch Loss 2.0347 (2.1445)	Arch Hard Loss 2.0334 (2.1432)	Arch Alpha Loss 0.0128 (0.0133)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/19 03:19:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 1.0844 (0.9454)	Arch Loss 2.0275 (2.1610)	Arch Hard Loss 2.0262 (2.1596)	Arch Alpha Loss 0.0128 (0.0132)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.1%)	
11/19 03:20:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 1.1147 (0.9600)	Arch Loss 2.0687 (2.1664)	Arch Hard Loss 2.0673 (2.1651)	Arch Alpha Loss 0.0137 (0.0133)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
11/19 03:21:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.0759 (0.9682)	Arch Loss 2.3349 (2.1632)	Arch Hard Loss 2.3333 (2.1619)	Arch Alpha Loss 0.0158 (0.0133)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.8%)	
11/19 03:21:04午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 70.9600%
11/19 03:21:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.1317	Prec@(1,5) (48.3%, 77.5%)
11/19 03:21:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.1131	Prec@(1,5) (48.3%, 77.7%)
11/19 03:21:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.0962	Prec@(1,5) (48.7%, 78.1%)
11/19 03:21:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.0953	Prec@(1,5) (48.5%, 78.1%)
11/19 03:21:30午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 48.5200%
11/19 03:21:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:21:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5200%
11/19 03:22:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 1.1041 (0.8757)	Arch Loss 2.1951 (2.1980)	Arch Hard Loss 2.1938 (2.1967)	Arch Alpha Loss 0.0129 (0.0134)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.9%)	
11/19 03:23:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.8491 (0.8934)	Arch Loss 2.6165 (2.1853)	Arch Hard Loss 2.6154 (2.1840)	Arch Alpha Loss 0.0113 (0.0134)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.5%)	
11/19 03:23:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 1.0228 (0.9009)	Arch Loss 1.9446 (2.1701)	Arch Hard Loss 1.9433 (2.1688)	Arch Alpha Loss 0.0129 (0.0134)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.6%)	
11/19 03:24:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.8266 (0.9134)	Arch Loss 2.4274 (2.1774)	Arch Hard Loss 2.4261 (2.1761)	Arch Alpha Loss 0.0128 (0.0134)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.4%)	
11/19 03:24:26午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 72.5040%
11/19 03:24:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.1616	Prec@(1,5) (47.2%, 77.4%)
11/19 03:24:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.1533	Prec@(1,5) (48.0%, 77.6%)
11/19 03:24:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.1477	Prec@(1,5) (48.1%, 77.7%)
11/19 03:24:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.1317	Prec@(1,5) (48.4%, 77.9%)
11/19 03:24:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 48.4280%
11/19 03:24:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:24:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5200%
11/19 03:25:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7066 (0.8442)	Arch Loss 1.7588 (2.2122)	Arch Hard Loss 1.7574 (2.2108)	Arch Alpha Loss 0.0140 (0.0135)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.8%)	
11/19 03:26:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7343 (0.8525)	Arch Loss 2.3234 (2.2338)	Arch Hard Loss 2.3221 (2.2324)	Arch Alpha Loss 0.0133 (0.0137)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.5%)	
11/19 03:27:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6797 (0.8556)	Arch Loss 2.5475 (2.2139)	Arch Hard Loss 2.5460 (2.2125)	Arch Alpha Loss 0.0148 (0.0136)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.4%)	
11/19 03:27:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.8521 (0.8613)	Arch Loss 2.2949 (2.1882)	Arch Hard Loss 2.2936 (2.1869)	Arch Alpha Loss 0.0125 (0.0136)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.3%)	
11/19 03:27:49午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 74.2920%
11/19 03:27:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.0934	Prec@(1,5) (49.2%, 78.9%)
11/19 03:28:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.1044	Prec@(1,5) (49.5%, 78.7%)
11/19 03:28:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.0916	Prec@(1,5) (49.7%, 78.8%)
11/19 03:28:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.1135	Prec@(1,5) (49.1%, 78.4%)
11/19 03:28:16午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 49.1280%
11/19 03:28:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:28:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1280%
11/19 03:29:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7319 (0.8143)	Arch Loss 2.2591 (2.2243)	Arch Hard Loss 2.2577 (2.2230)	Arch Alpha Loss 0.0136 (0.0138)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.6%)	
11/19 03:29:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.9348 (0.8136)	Arch Loss 2.3198 (2.1878)	Arch Hard Loss 2.3185 (2.1865)	Arch Alpha Loss 0.0137 (0.0137)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.7%)	
11/19 03:30:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6962 (0.8180)	Arch Loss 1.9374 (2.1963)	Arch Hard Loss 1.9361 (2.1949)	Arch Alpha Loss 0.0127 (0.0137)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.6%)	
11/19 03:31:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.6082 (0.8200)	Arch Loss 2.0552 (2.1905)	Arch Hard Loss 2.0538 (2.1891)	Arch Alpha Loss 0.0143 (0.0137)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.6%)	
11/19 03:31:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 75.3920%
11/19 03:31:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.1450	Prec@(1,5) (47.7%, 78.9%)
11/19 03:31:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.1527	Prec@(1,5) (48.4%, 78.6%)
11/19 03:31:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.1608	Prec@(1,5) (48.5%, 78.2%)
11/19 03:31:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.1507	Prec@(1,5) (48.5%, 78.2%)
11/19 03:31:38午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 48.5440%
11/19 03:31:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:31:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1280%
11/19 03:32:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.9209 (0.7878)	Arch Loss 2.6673 (2.1847)	Arch Hard Loss 2.6659 (2.1833)	Arch Alpha Loss 0.0139 (0.0140)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.1%)	
11/19 03:33:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6406 (0.7721)	Arch Loss 1.7860 (2.2046)	Arch Hard Loss 1.7846 (2.2032)	Arch Alpha Loss 0.0143 (0.0140)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.3%)	
11/19 03:33:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6739 (0.7683)	Arch Loss 2.0918 (2.2103)	Arch Hard Loss 2.0903 (2.2089)	Arch Alpha Loss 0.0148 (0.0139)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.2%)	
11/19 03:34:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.7964 (0.7766)	Arch Loss 2.5974 (2.2088)	Arch Hard Loss 2.5959 (2.2074)	Arch Alpha Loss 0.0148 (0.0139)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
11/19 03:34:33午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 76.8560%
11/19 03:34:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.1198	Prec@(1,5) (49.5%, 78.3%)
11/19 03:34:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.1348	Prec@(1,5) (48.9%, 78.0%)
11/19 03:34:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.1336	Prec@(1,5) (49.0%, 78.0%)
11/19 03:34:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.1458	Prec@(1,5) (48.9%, 78.0%)
11/19 03:34:59午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 48.9480%
11/19 03:34:59午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:34:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1280%
11/19 03:35:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5677 (0.7489)	Arch Loss 2.2788 (2.2520)	Arch Hard Loss 2.2774 (2.2506)	Arch Alpha Loss 0.0146 (0.0143)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.2%)	
11/19 03:36:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5979 (0.7383)	Arch Loss 1.9147 (2.2246)	Arch Hard Loss 1.9133 (2.2232)	Arch Alpha Loss 0.0141 (0.0141)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.3%)	
11/19 03:37:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6217 (0.7430)	Arch Loss 2.1665 (2.2047)	Arch Hard Loss 2.1651 (2.2033)	Arch Alpha Loss 0.0136 (0.0140)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.2%)	
11/19 03:37:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6549 (0.7511)	Arch Loss 2.5265 (2.2065)	Arch Hard Loss 2.5249 (2.2051)	Arch Alpha Loss 0.0159 (0.0141)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.1%)	
11/19 03:37:53午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 77.7080%
11/19 03:38:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.1603	Prec@(1,5) (48.8%, 77.7%)
11/19 03:38:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.1536	Prec@(1,5) (48.8%, 78.0%)
11/19 03:38:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.1459	Prec@(1,5) (49.0%, 78.1%)
11/19 03:38:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.1566	Prec@(1,5) (48.9%, 78.0%)
11/19 03:38:20午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 48.8640%
11/19 03:38:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:38:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1280%
11/19 03:39:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6563 (0.7044)	Arch Loss 2.2205 (2.1762)	Arch Hard Loss 2.2192 (2.1748)	Arch Alpha Loss 0.0133 (0.0139)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.8%)	
11/19 03:39:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.8912 (0.7136)	Arch Loss 2.6375 (2.2017)	Arch Hard Loss 2.6360 (2.2003)	Arch Alpha Loss 0.0150 (0.0143)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.6%)	
11/19 03:40:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5969 (0.7293)	Arch Loss 2.3353 (2.2051)	Arch Hard Loss 2.3340 (2.2037)	Arch Alpha Loss 0.0128 (0.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.6%)	
11/19 03:41:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.8884 (0.7308)	Arch Loss 1.9229 (2.2121)	Arch Hard Loss 1.9213 (2.2107)	Arch Alpha Loss 0.0161 (0.0143)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.6%)	
11/19 03:41:14午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 78.1040%
11/19 03:41:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.1506	Prec@(1,5) (49.1%, 78.2%)
11/19 03:41:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.1739	Prec@(1,5) (48.8%, 77.9%)
11/19 03:41:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.1744	Prec@(1,5) (48.8%, 77.9%)
11/19 03:41:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.1646	Prec@(1,5) (48.7%, 78.2%)
11/19 03:41:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 48.7520%
11/19 03:41:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:41:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.1280%
11/19 03:42:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.5353 (0.6816)	Arch Loss 2.1478 (2.2053)	Arch Hard Loss 2.1465 (2.2039)	Arch Alpha Loss 0.0128 (0.0144)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 97.0%)	
11/19 03:43:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5595 (0.6927)	Arch Loss 2.7278 (2.2085)	Arch Hard Loss 2.7266 (2.2071)	Arch Alpha Loss 0.0125 (0.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.7%)	
11/19 03:43:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.8884 (0.6996)	Arch Loss 2.3270 (2.2171)	Arch Hard Loss 2.3256 (2.2157)	Arch Alpha Loss 0.0137 (0.0141)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.6%)	
11/19 03:44:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7575 (0.7024)	Arch Loss 2.3796 (2.2266)	Arch Hard Loss 2.3781 (2.2252)	Arch Alpha Loss 0.0155 (0.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
11/19 03:44:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 78.7880%
11/19 03:44:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.1284	Prec@(1,5) (49.5%, 79.0%)
11/19 03:44:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.1548	Prec@(1,5) (49.3%, 78.7%)
11/19 03:44:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.1598	Prec@(1,5) (49.2%, 78.6%)
11/19 03:45:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.1587	Prec@(1,5) (49.2%, 78.5%)
11/19 03:45:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 49.2120%
11/19 03:45:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:45:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2120%
11/19 03:45:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.5706 (0.6451)	Arch Loss 2.0352 (2.1643)	Arch Hard Loss 2.0337 (2.1629)	Arch Alpha Loss 0.0148 (0.0143)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
11/19 03:46:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.2966 (0.6667)	Arch Loss 2.1644 (2.2049)	Arch Hard Loss 2.1629 (2.2035)	Arch Alpha Loss 0.0149 (0.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 96.9%)	
11/19 03:47:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.5266 (0.6733)	Arch Loss 2.3987 (2.2154)	Arch Hard Loss 2.3972 (2.2140)	Arch Alpha Loss 0.0148 (0.0143)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 96.9%)	
11/19 03:47:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.8402 (0.6793)	Arch Loss 2.4970 (2.2246)	Arch Hard Loss 2.4957 (2.2231)	Arch Alpha Loss 0.0122 (0.0142)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.8%)	
11/19 03:48:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 79.7080%
11/19 03:48:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.1225	Prec@(1,5) (49.8%, 78.8%)
11/19 03:48:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.1254	Prec@(1,5) (49.8%, 78.7%)
11/19 03:48:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.1429	Prec@(1,5) (49.3%, 78.6%)
11/19 03:48:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.1519	Prec@(1,5) (49.2%, 78.4%)
11/19 03:48:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 49.1400%
11/19 03:48:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:48:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2120%
11/19 03:49:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4778 (0.6273)	Arch Loss 2.6556 (2.2339)	Arch Hard Loss 2.6541 (2.2324)	Arch Alpha Loss 0.0149 (0.0146)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.5%)	
11/19 03:49:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.6886 (0.6445)	Arch Loss 2.4611 (2.2148)	Arch Hard Loss 2.4597 (2.2133)	Arch Alpha Loss 0.0141 (0.0144)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.3%)	
11/19 03:50:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.9432 (0.6561)	Arch Loss 2.3158 (2.2373)	Arch Hard Loss 2.3142 (2.2359)	Arch Alpha Loss 0.0162 (0.0145)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.2%)	
11/19 03:51:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5897 (0.6637)	Arch Loss 1.7060 (2.2387)	Arch Hard Loss 1.7044 (2.2372)	Arch Alpha Loss 0.0160 (0.0146)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.2%)	
11/19 03:51:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 80.1880%
11/19 03:51:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.1746	Prec@(1,5) (49.4%, 78.3%)
11/19 03:51:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.1956	Prec@(1,5) (49.0%, 78.2%)
11/19 03:51:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.1871	Prec@(1,5) (49.1%, 78.3%)
11/19 03:51:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.1788	Prec@(1,5) (49.1%, 78.3%)
11/19 03:51:48午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 49.1280%
11/19 03:51:48午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 03:51:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2120%
11/19 03:51:48午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 49.2120%
11/19 03:51:48午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
