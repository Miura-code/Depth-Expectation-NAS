11/10 01:16:22AM parser.py:28 [INFO] 
11/10 01:16:22AM parser.py:29 [INFO] Parameters:
11/10 01:16:22AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s3-LengthBeta-sw3/DAG
11/10 01:16:22AM parser.py:31 [INFO] T=10.0
11/10 01:16:22AM parser.py:31 [INFO] ADVANCED=1
11/10 01:16:22AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/10 01:16:22AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/10 01:16:22AM parser.py:31 [INFO] ARCH_CRITERION=length
11/10 01:16:22AM parser.py:31 [INFO] BATCH_SIZE=64
11/10 01:16:22AM parser.py:31 [INFO] CASCADE=0
11/10 01:16:22AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/10 01:16:22AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/10 01:16:22AM parser.py:31 [INFO] DATA_PATH=../data/
11/10 01:16:22AM parser.py:31 [INFO] DATASET=cifar100
11/10 01:16:22AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/10 01:16:22AM parser.py:31 [INFO] DESCRIPTION=search_wtih_beta-cell-length-constriction
11/10 01:16:22AM parser.py:31 [INFO] DISCRETE=0
11/10 01:16:22AM parser.py:31 [INFO] EPOCHS=50
11/10 01:16:22AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/10 01:16:22AM parser.py:31 [INFO] EXP_NAME=s3-LengthBeta-sw3
11/10 01:16:22AM parser.py:31 [INFO] FINAL_L=1.0
11/10 01:16:22AM parser.py:31 [INFO] G=1.0
11/10 01:16:22AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/10 01:16:22AM parser.py:31 [INFO] GPUS=[0]
11/10 01:16:22AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/10 01:16:22AM parser.py:31 [INFO] INIT_CHANNELS=16
11/10 01:16:22AM parser.py:31 [INFO] L=0.0
11/10 01:16:22AM parser.py:31 [INFO] LAYERS=20
11/10 01:16:22AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/10 01:16:22AM parser.py:31 [INFO] NAME=Pruning
11/10 01:16:22AM parser.py:31 [INFO] NONKD=1
11/10 01:16:22AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s3-LengthBeta-sw3
11/10 01:16:22AM parser.py:31 [INFO] PCDARTS=0
11/10 01:16:22AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s3-LengthBeta-sw3/plots
11/10 01:16:22AM parser.py:31 [INFO] PRINT_FREQ=100
11/10 01:16:22AM parser.py:31 [INFO] RESET=0
11/10 01:16:22AM parser.py:31 [INFO] RESUME_PATH=None
11/10 01:16:22AM parser.py:31 [INFO] SAVE=s3-LengthBeta-sw3
11/10 01:16:22AM parser.py:31 [INFO] SEED=3
11/10 01:16:22AM parser.py:31 [INFO] SHARE_STAGE=0
11/10 01:16:22AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/10 01:16:22AM parser.py:31 [INFO] SPEC_CELL=1
11/10 01:16:22AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/10 01:16:22AM parser.py:31 [INFO] TEACHER_NAME=none
11/10 01:16:22AM parser.py:31 [INFO] TEACHER_PATH=none
11/10 01:16:22AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/10 01:16:22AM parser.py:31 [INFO] TYPE=Pruning
11/10 01:16:22AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/10 01:16:22AM parser.py:31 [INFO] W_LR=0.025
11/10 01:16:22AM parser.py:31 [INFO] W_LR_MIN=0.001
11/10 01:16:22AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/10 01:16:22AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/10 01:16:22AM parser.py:31 [INFO] WORKERS=4
11/10 01:16:22AM parser.py:32 [INFO] 
11/10 01:16:24AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/10 01:16:57AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3143 (4.5114)	Arch Loss 4.3076 (4.5127)	Arch Hard Loss 4.3076 (4.5127)	Arch Beta Loss 0.1006 (0.0667)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 11.0%)	
11/10 01:17:27AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 3.9773 (4.3479)	Arch Loss 4.1682 (4.3449)	Arch Hard Loss 4.1682 (4.3449)	Arch Beta Loss 0.1015 (0.0783)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 16.0%)	
11/10 01:17:57AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.8178 (4.2472)	Arch Loss 3.8638 (4.2341)	Arch Hard Loss 3.8638 (4.2341)	Arch Beta Loss 0.1309 (0.0950)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.9%, 18.9%)	
11/10 01:18:24AM searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8733 (4.1783)	Arch Loss 3.9560 (4.1601)	Arch Hard Loss 3.9560 (4.1601)	Arch Beta Loss 0.1723 (0.1094)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.7%, 21.0%)	
11/10 01:18:25AM searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  0/49] Final Prec@1 5.7200%
11/10 01:18:30AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9360	Prec@(1,5) (8.6%, 28.1%)
11/10 01:18:34AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9313	Prec@(1,5) (8.4%, 28.6%)
11/10 01:18:38AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9387	Prec@(1,5) (8.2%, 28.4%)
11/10 01:18:42AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9425	Prec@(1,5) (8.2%, 28.4%)
11/10 01:18:43AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 8.2480%
11/10 01:18:43AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 4)]], DAG2_concat=[4, 6], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)]], DAG3_concat=[2, 4])
11/10 01:18:43AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.2480%
11/10 01:19:15午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9953 (3.8334)	Arch Loss 3.7720 (3.8540)	Arch Hard Loss 3.7719 (3.8539)	Arch Beta Loss 0.0927 (0.1154)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.1%, 31.5%)	
11/10 01:19:46午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.5363 (3.7860)	Arch Loss 3.8744 (3.7782)	Arch Hard Loss 3.8743 (3.7781)	Arch Beta Loss 0.1147 (0.1107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.7%, 32.6%)	
11/10 01:20:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8781 (3.7362)	Arch Loss 3.9540 (3.7273)	Arch Hard Loss 3.9539 (3.7272)	Arch Beta Loss 0.1051 (0.1120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.4%, 34.1%)	
11/10 01:20:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.4566 (3.6996)	Arch Loss 3.6910 (3.6937)	Arch Hard Loss 3.6908 (3.6936)	Arch Beta Loss 0.1125 (0.1064)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.1%, 35.4%)	
11/10 01:20:44午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  1/49] Final Prec@1 12.0640%
11/10 01:20:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5813	Prec@(1,5) (14.1%, 39.0%)
11/10 01:20:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5907	Prec@(1,5) (13.7%, 38.9%)
11/10 01:20:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5982	Prec@(1,5) (13.7%, 38.9%)
11/10 01:21:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5944	Prec@(1,5) (13.9%, 39.2%)
11/10 01:21:03午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 13.8920%
11/10 01:21:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)]], DAG3_concat=[2, 4])
11/10 01:21:03午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.8920%
11/10 01:21:36午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.3850 (3.4483)	Arch Loss 3.4254 (3.4963)	Arch Hard Loss 3.4251 (3.4960)	Arch Beta Loss 0.0579 (0.0700)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.4%, 43.0%)	
11/10 01:22:07午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4464 (3.4290)	Arch Loss 3.4621 (3.4505)	Arch Hard Loss 3.4619 (3.4503)	Arch Beta Loss 0.0489 (0.0627)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.6%, 43.5%)	
11/10 01:22:38午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.3575 (3.4072)	Arch Loss 3.2115 (3.4287)	Arch Hard Loss 3.2113 (3.4285)	Arch Beta Loss 0.0416 (0.0581)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.0%, 44.3%)	
11/10 01:23:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.2905 (3.3884)	Arch Loss 3.1676 (3.3977)	Arch Hard Loss 3.1675 (3.3975)	Arch Beta Loss 0.0475 (0.0545)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 44.8%)	
11/10 01:23:07午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  2/49] Final Prec@1 17.3120%
11/10 01:23:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3056	Prec@(1,5) (18.6%, 47.4%)
11/10 01:23:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.2853	Prec@(1,5) (19.1%, 47.6%)
11/10 01:23:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.2847	Prec@(1,5) (19.1%, 47.7%)
11/10 01:23:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.2790	Prec@(1,5) (19.2%, 47.8%)
11/10 01:23:25午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 19.1960%
11/10 01:23:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 4)]], DAG2_concat=[3, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)]], DAG3_concat=[2, 4])
11/10 01:23:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.1960%
11/10 01:23:58午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.1099 (3.1892)	Arch Loss 3.2697 (3.2675)	Arch Hard Loss 3.2695 (3.2672)	Arch Beta Loss 0.0299 (0.0358)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.7%, 50.9%)	
11/10 01:24:29午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.2821 (3.1763)	Arch Loss 3.3731 (3.2260)	Arch Hard Loss 3.3729 (3.2257)	Arch Beta Loss 0.0213 (0.0310)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 50.9%)	
11/10 01:25:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 2.8701 (3.1680)	Arch Loss 3.0280 (3.1981)	Arch Hard Loss 3.0279 (3.1979)	Arch Beta Loss 0.0111 (0.0260)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.9%, 51.2%)	
11/10 01:25:29午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.2230 (3.1510)	Arch Loss 2.8724 (3.1666)	Arch Hard Loss 2.8723 (3.1664)	Arch Beta Loss 0.0133 (0.0229)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.4%, 51.4%)	
11/10 01:25:29午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  3/49] Final Prec@1 21.3600%
11/10 01:25:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1092	Prec@(1,5) (22.5%, 53.4%)
11/10 01:25:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1063	Prec@(1,5) (22.9%, 53.2%)
11/10 01:25:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1082	Prec@(1,5) (23.0%, 53.0%)
11/10 01:25:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.0945	Prec@(1,5) (23.0%, 53.0%)
11/10 01:25:48午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 23.0480%
11/10 01:25:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)]], DAG2_concat=[3, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[2, 3])
11/10 01:25:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.0480%
11/10 01:26:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.8766 (2.9715)	Arch Loss 3.1752 (3.0774)	Arch Hard Loss 3.1751 (3.0772)	Arch Beta Loss 0.0073 (0.0097)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.9%, 56.1%)	
11/10 01:26:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.7762 (2.9637)	Arch Loss 2.7277 (3.0378)	Arch Hard Loss 2.7277 (3.0377)	Arch Beta Loss 0.0025 (0.0075)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.2%, 56.0%)	
11/10 01:27:23午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.0393 (2.9500)	Arch Loss 2.7432 (3.0013)	Arch Hard Loss 2.7432 (3.0012)	Arch Beta Loss 0.0042 (0.0065)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.4%, 56.4%)	
11/10 01:27:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.6992 (2.9285)	Arch Loss 3.0989 (2.9813)	Arch Hard Loss 3.0989 (2.9812)	Arch Beta Loss 0.0053 (0.0060)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.9%)	
11/10 01:27:52午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  4/49] Final Prec@1 25.7360%
11/10 01:27:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 2.8727	Prec@(1,5) (26.6%, 59.2%)
11/10 01:28:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.8817	Prec@(1,5) (26.6%, 58.9%)
11/10 01:28:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.8934	Prec@(1,5) (26.4%, 58.4%)
11/10 01:28:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9027	Prec@(1,5) (26.2%, 58.1%)
11/10 01:28:10午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 26.1800%
11/10 01:28:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:28:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.1800%
11/10 01:28:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.2676 (2.7631)	Arch Loss 2.8253 (2.8721)	Arch Hard Loss 2.8252 (2.8720)	Arch Beta Loss 0.0052 (0.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.2%, 61.6%)	
11/10 01:29:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.9639 (2.7583)	Arch Loss 3.1006 (2.8532)	Arch Hard Loss 3.1005 (2.8531)	Arch Beta Loss 0.0047 (0.0044)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.6%, 61.5%)	
11/10 01:29:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8200 (2.7467)	Arch Loss 2.6006 (2.8239)	Arch Hard Loss 2.6004 (2.8238)	Arch Beta Loss 0.0051 (0.0042)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.1%, 61.5%)	
11/10 01:30:12午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.5684 (2.7408)	Arch Loss 3.1759 (2.8153)	Arch Hard Loss 3.1758 (2.8152)	Arch Beta Loss 0.0027 (0.0041)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 61.6%)	
11/10 01:30:12午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  5/49] Final Prec@1 29.2120%
11/10 01:30:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.7621	Prec@(1,5) (29.1%, 61.8%)
11/10 01:30:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.7508	Prec@(1,5) (29.1%, 62.1%)
11/10 01:30:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.7681	Prec@(1,5) (28.9%, 61.5%)
11/10 01:30:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.7615	Prec@(1,5) (28.9%, 61.7%)
11/10 01:30:31午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 28.8760%
11/10 01:30:31午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:30:31午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.8760%
11/10 01:31:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.5381 (2.6144)	Arch Loss 2.6894 (2.7387)	Arch Hard Loss 2.6893 (2.7385)	Arch Beta Loss 0.0034 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.2%, 64.4%)	
11/10 01:31:35午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.6186 (2.6020)	Arch Loss 2.4738 (2.7063)	Arch Hard Loss 2.4737 (2.7062)	Arch Beta Loss 0.0033 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 64.8%)	
11/10 01:32:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.1864 (2.5991)	Arch Loss 2.2797 (2.6908)	Arch Hard Loss 2.2796 (2.6906)	Arch Beta Loss 0.0033 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 64.8%)	
11/10 01:32:34午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.1563 (2.5865)	Arch Loss 2.4607 (2.6721)	Arch Hard Loss 2.4606 (2.6720)	Arch Beta Loss 0.0026 (0.0036)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 65.4%)	
11/10 01:32:34午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  6/49] Final Prec@1 32.7520%
11/10 01:32:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6492	Prec@(1,5) (31.1%, 63.6%)
11/10 01:32:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6438	Prec@(1,5) (31.3%, 64.1%)
11/10 01:32:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6414	Prec@(1,5) (31.3%, 64.3%)
11/10 01:32:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6400	Prec@(1,5) (31.4%, 64.4%)
11/10 01:32:52午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 31.4400%
11/10 01:32:52午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:32:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.4400%
11/10 01:33:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.4965 (2.4327)	Arch Loss 2.6025 (2.5781)	Arch Hard Loss 2.6023 (2.5779)	Arch Beta Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.8%)	
11/10 01:33:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.5761 (2.4456)	Arch Loss 2.7764 (2.5914)	Arch Hard Loss 2.7763 (2.5912)	Arch Beta Loss 0.0028 (0.0037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.6%, 68.4%)	
11/10 01:34:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.6575 (2.4531)	Arch Loss 2.6696 (2.5799)	Arch Hard Loss 2.6694 (2.5797)	Arch Beta Loss 0.0036 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 68.3%)	
11/10 01:34:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.3869 (2.4465)	Arch Loss 2.2747 (2.5690)	Arch Hard Loss 2.2746 (2.5688)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.4%)	
11/10 01:34:55午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  7/49] Final Prec@1 35.5280%
11/10 01:35:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.4270	Prec@(1,5) (36.4%, 69.0%)
11/10 01:35:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.4693	Prec@(1,5) (35.6%, 68.1%)
11/10 01:35:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.4750	Prec@(1,5) (35.4%, 67.9%)
11/10 01:35:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.4776	Prec@(1,5) (35.3%, 67.7%)
11/10 01:35:14午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 35.2960%
11/10 01:35:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:35:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.2960%
11/10 01:35:46午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.6344 (2.3225)	Arch Loss 2.6190 (2.4851)	Arch Hard Loss 2.6188 (2.4849)	Arch Beta Loss 0.0031 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.6%, 71.7%)	
11/10 01:36:18午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.0744 (2.3196)	Arch Loss 2.5199 (2.4815)	Arch Hard Loss 2.5197 (2.4813)	Arch Beta Loss 0.0021 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 71.5%)	
11/10 01:36:49午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.2518 (2.3148)	Arch Loss 2.3868 (2.4631)	Arch Hard Loss 2.3866 (2.4629)	Arch Beta Loss 0.0038 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.1%, 71.5%)	
11/10 01:37:17午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.6864 (2.3203)	Arch Loss 1.9469 (2.4619)	Arch Hard Loss 1.9468 (2.4617)	Arch Beta Loss 0.0027 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.1%, 71.2%)	
11/10 01:37:18午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  8/49] Final Prec@1 38.1120%
11/10 01:37:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.3773	Prec@(1,5) (37.4%, 69.9%)
11/10 01:37:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4037	Prec@(1,5) (36.9%, 69.2%)
11/10 01:37:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4138	Prec@(1,5) (36.7%, 69.0%)
11/10 01:37:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4120	Prec@(1,5) (36.9%, 69.2%)
11/10 01:37:36午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 36.9080%
11/10 01:37:36午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:37:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.9080%
11/10 01:38:09午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.2512 (2.1869)	Arch Loss 2.4233 (2.4169)	Arch Hard Loss 2.4231 (2.4166)	Arch Beta Loss 0.0029 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.7%, 73.6%)	
11/10 01:38:41午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.1835 (2.2062)	Arch Loss 2.2636 (2.3972)	Arch Hard Loss 2.2634 (2.3969)	Arch Beta Loss 0.0026 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 73.4%)	
11/10 01:39:12午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 1.7844 (2.2195)	Arch Loss 2.2463 (2.3761)	Arch Hard Loss 2.2460 (2.3759)	Arch Beta Loss 0.0028 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.3%)	
11/10 01:39:40午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1717 (2.2282)	Arch Loss 2.5363 (2.3645)	Arch Hard Loss 2.5360 (2.3643)	Arch Beta Loss 0.0031 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 73.1%)	
11/10 01:39:41午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [  9/49] Final Prec@1 40.4360%
11/10 01:39:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4829	Prec@(1,5) (35.4%, 68.3%)
11/10 01:39:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4902	Prec@(1,5) (35.4%, 68.5%)
11/10 01:39:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4854	Prec@(1,5) (35.9%, 68.3%)
11/10 01:39:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4765	Prec@(1,5) (36.0%, 68.5%)
11/10 01:39:59午前 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 35.9640%
11/10 01:39:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:39:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.9080%
11/10 01:40:32午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.0333 (2.0983)	Arch Loss 2.3501 (2.3562)	Arch Hard Loss 2.3499 (2.3559)	Arch Beta Loss 0.0028 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 76.3%)	
11/10 01:41:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4168 (2.1157)	Arch Loss 1.9928 (2.3228)	Arch Hard Loss 1.9926 (2.3225)	Arch Beta Loss 0.0023 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.5%, 75.7%)	
11/10 01:41:35午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3027 (2.1080)	Arch Loss 2.1283 (2.3121)	Arch Hard Loss 2.1281 (2.3118)	Arch Beta Loss 0.0022 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.7%)	
11/10 01:42:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 1.7623 (2.1144)	Arch Loss 2.2780 (2.3180)	Arch Hard Loss 2.2777 (2.3177)	Arch Beta Loss 0.0031 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 75.5%)	
11/10 01:42:03午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 10/49] Final Prec@1 42.6680%
11/10 01:42:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.2753	Prec@(1,5) (40.1%, 72.6%)
11/10 01:42:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.2674	Prec@(1,5) (40.2%, 72.5%)
11/10 01:42:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.2758	Prec@(1,5) (39.9%, 72.4%)
11/10 01:42:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.2722	Prec@(1,5) (40.0%, 72.4%)
11/10 01:42:21午前 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 39.9920%
11/10 01:42:21午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:42:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.9920%
11/10 01:42:53午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.0890 (2.0448)	Arch Loss 2.2328 (2.3015)	Arch Hard Loss 2.2325 (2.3011)	Arch Beta Loss 0.0025 (0.0031)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.2%, 76.6%)	
11/10 01:43:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 1.9888 (2.0349)	Arch Loss 2.2991 (2.2665)	Arch Hard Loss 2.2988 (2.2661)	Arch Beta Loss 0.0028 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.0%)	
11/10 01:43:54午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 1.9965 (2.0325)	Arch Loss 2.7164 (2.2671)	Arch Hard Loss 2.7161 (2.2668)	Arch Beta Loss 0.0029 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 77.1%)	
11/10 01:44:22午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.8008 (2.0334)	Arch Loss 2.3878 (2.2490)	Arch Hard Loss 2.3875 (2.2487)	Arch Beta Loss 0.0028 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.3%)	
11/10 01:44:23午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 11/49] Final Prec@1 44.4680%
11/10 01:44:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.2092	Prec@(1,5) (41.1%, 73.4%)
11/10 01:44:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2234	Prec@(1,5) (40.5%, 73.6%)
11/10 01:44:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2266	Prec@(1,5) (40.8%, 73.5%)
11/10 01:44:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2231	Prec@(1,5) (40.8%, 73.7%)
11/10 01:44:41午前 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 40.8400%
11/10 01:44:41午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:44:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.8400%
11/10 01:45:13午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.0187 (1.9562)	Arch Loss 1.8575 (2.2233)	Arch Hard Loss 1.8572 (2.2229)	Arch Beta Loss 0.0024 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 79.0%)	
11/10 01:45:45午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.0873 (1.9485)	Arch Loss 2.4637 (2.2107)	Arch Hard Loss 2.4634 (2.2103)	Arch Beta Loss 0.0024 (0.0027)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 79.1%)	
11/10 01:46:15午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.1028 (1.9578)	Arch Loss 2.2952 (2.2030)	Arch Hard Loss 2.2950 (2.2027)	Arch Beta Loss 0.0020 (0.0026)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.0%, 78.8%)	
11/10 01:46:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.0146 (1.9525)	Arch Loss 1.9800 (2.1846)	Arch Hard Loss 1.9797 (2.1842)	Arch Beta Loss 0.0019 (0.0025)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 78.8%)	
11/10 01:46:44午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 12/49] Final Prec@1 46.0840%
11/10 01:46:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.1906	Prec@(1,5) (41.4%, 74.2%)
11/10 01:46:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2055	Prec@(1,5) (41.5%, 73.7%)
11/10 01:46:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1963	Prec@(1,5) (41.8%, 73.9%)
11/10 01:47:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2077	Prec@(1,5) (41.7%, 73.7%)
11/10 01:47:02午前 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 41.6680%
11/10 01:47:02午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:47:03午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.6680%
11/10 01:47:35午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.9167 (1.8447)	Arch Loss 2.1463 (2.1392)	Arch Hard Loss 2.1457 (2.1388)	Arch Beta Loss 0.0036 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.2%, 80.5%)	
11/10 01:48:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.9151 (1.8863)	Arch Loss 1.7131 (2.1468)	Arch Hard Loss 1.7128 (2.1464)	Arch Beta Loss 0.0021 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 79.9%)	
11/10 01:48:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.7123 (1.8882)	Arch Loss 2.3990 (2.1525)	Arch Hard Loss 2.3986 (2.1521)	Arch Beta Loss 0.0024 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.8%, 80.0%)	
11/10 01:49:05午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.8071 (1.8794)	Arch Loss 2.0550 (2.1431)	Arch Hard Loss 2.0545 (2.1426)	Arch Beta Loss 0.0033 (0.0028)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 80.1%)	
11/10 01:49:06午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 13/49] Final Prec@1 48.0040%
11/10 01:49:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1278	Prec@(1,5) (43.4%, 75.3%)
11/10 01:49:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1173	Prec@(1,5) (43.9%, 75.6%)
11/10 01:49:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1123	Prec@(1,5) (44.0%, 75.6%)
11/10 01:49:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1078	Prec@(1,5) (43.9%, 75.7%)
11/10 01:49:25午前 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 43.9360%
11/10 01:49:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:49:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.9360%
11/10 01:49:58午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8975 (1.7905)	Arch Loss 1.9062 (2.1314)	Arch Hard Loss 1.9056 (2.1309)	Arch Beta Loss 0.0034 (0.0030)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.1%)	
11/10 01:50:29午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.1277 (1.7955)	Arch Loss 1.8338 (2.1043)	Arch Hard Loss 1.8333 (2.1038)	Arch Beta Loss 0.0028 (0.0029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.2%)	
11/10 01:51:01午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.0659 (1.8223)	Arch Loss 2.0529 (2.1037)	Arch Hard Loss 2.0525 (2.1032)	Arch Beta Loss 0.0021 (0.0028)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.8%)	
11/10 01:51:28午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.9766 (1.8197)	Arch Loss 2.2581 (2.0955)	Arch Hard Loss 2.2575 (2.0950)	Arch Beta Loss 0.0034 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.1%, 81.0%)	
11/10 01:51:29午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 14/49] Final Prec@1 49.0560%
11/10 01:51:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.0503	Prec@(1,5) (44.9%, 77.0%)
11/10 01:51:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.0618	Prec@(1,5) (44.6%, 76.7%)
11/10 01:51:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0568	Prec@(1,5) (44.8%, 76.8%)
11/10 01:51:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0589	Prec@(1,5) (44.9%, 76.8%)
11/10 01:51:47午前 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 44.8800%
11/10 01:51:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)]], DAG3_concat=[3, 5])
11/10 01:51:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.8800%
11/10 01:52:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.6790 (1.7078)	Arch Loss 1.7592 (2.0552)	Arch Hard Loss 1.7587 (2.0547)	Arch Beta Loss 0.0024 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.9%)	
11/10 01:52:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.4859 (1.7189)	Arch Loss 2.3948 (2.0471)	Arch Hard Loss 2.3942 (2.0465)	Arch Beta Loss 0.0029 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.8%)	
11/10 01:53:23午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.5319 (1.7437)	Arch Loss 2.4919 (2.0543)	Arch Hard Loss 2.4914 (2.0538)	Arch Beta Loss 0.0024 (0.0027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.9%, 82.5%)	
11/10 01:53:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.6084 (1.7483)	Arch Loss 2.0974 (2.0556)	Arch Hard Loss 2.0968 (2.0550)	Arch Beta Loss 0.0028 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.8%, 82.6%)	
11/10 01:53:51午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 15/49] Final Prec@1 50.7800%
11/10 01:53:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0293	Prec@(1,5) (45.8%, 77.5%)
11/10 01:54:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0382	Prec@(1,5) (45.7%, 77.2%)
11/10 01:54:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0194	Prec@(1,5) (46.1%, 77.4%)
11/10 01:54:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0246	Prec@(1,5) (45.8%, 77.3%)
11/10 01:54:10午前 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 45.8160%
11/10 01:54:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 01:54:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.8160%
11/10 01:54:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.8272 (1.6285)	Arch Loss 1.7394 (2.0123)	Arch Hard Loss 1.7388 (2.0117)	Arch Beta Loss 0.0026 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.1%)	
11/10 01:55:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.7004 (1.6602)	Arch Loss 2.0801 (2.0328)	Arch Hard Loss 2.0794 (2.0322)	Arch Beta Loss 0.0028 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.4%, 83.5%)	
11/10 01:55:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.9635 (1.6744)	Arch Loss 2.4960 (2.0223)	Arch Hard Loss 2.4954 (2.0217)	Arch Beta Loss 0.0026 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.2%)	
11/10 01:56:12午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7774 (1.6794)	Arch Loss 2.0891 (2.0163)	Arch Hard Loss 2.0886 (2.0157)	Arch Beta Loss 0.0023 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.4%)	
11/10 01:56:12午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 16/49] Final Prec@1 52.9480%
11/10 01:56:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 1.9661	Prec@(1,5) (47.3%, 78.7%)
11/10 01:56:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 1.9790	Prec@(1,5) (46.9%, 78.3%)
11/10 01:56:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 1.9929	Prec@(1,5) (46.9%, 78.2%)
11/10 01:56:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 1.9889	Prec@(1,5) (47.0%, 78.1%)
11/10 01:56:30午前 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 46.9560%
11/10 01:56:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 5], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 01:56:31午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.9560%
11/10 01:57:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.3499 (1.5826)	Arch Loss 1.6573 (2.0013)	Arch Hard Loss 1.6567 (2.0007)	Arch Beta Loss 0.0025 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.3%, 85.3%)	
11/10 01:57:34午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.7612 (1.6034)	Arch Loss 2.4009 (2.0370)	Arch Hard Loss 2.4003 (2.0363)	Arch Beta Loss 0.0023 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.8%)	
11/10 01:58:04午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.7593 (1.6196)	Arch Loss 1.8221 (2.0123)	Arch Hard Loss 1.8214 (2.0117)	Arch Beta Loss 0.0024 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.6%)	
11/10 01:58:31午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.8996 (1.6364)	Arch Loss 2.0088 (2.0087)	Arch Hard Loss 2.0082 (2.0081)	Arch Beta Loss 0.0022 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.7%, 84.3%)	
11/10 01:58:32午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 17/49] Final Prec@1 53.7320%
11/10 01:58:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 1.9428	Prec@(1,5) (48.2%, 78.9%)
11/10 01:58:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9421	Prec@(1,5) (48.1%, 79.0%)
11/10 01:58:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9504	Prec@(1,5) (47.9%, 78.8%)
11/10 01:58:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9485	Prec@(1,5) (47.8%, 78.8%)
11/10 01:58:49午前 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 47.8480%
11/10 01:58:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 01:58:49午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8480%
11/10 01:59:22午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4969 (1.5235)	Arch Loss 2.1585 (2.0002)	Arch Hard Loss 2.1576 (1.9995)	Arch Beta Loss 0.0029 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 86.7%)	
11/10 01:59:53午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.6498 (1.5442)	Arch Loss 1.7464 (1.9678)	Arch Hard Loss 1.7456 (1.9670)	Arch Beta Loss 0.0029 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 86.1%)	
11/10 02:00:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6201 (1.5589)	Arch Loss 1.9308 (1.9659)	Arch Hard Loss 1.9300 (1.9652)	Arch Beta Loss 0.0031 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.4%, 85.7%)	
11/10 02:00:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.2869 (1.5727)	Arch Loss 2.0816 (1.9665)	Arch Hard Loss 2.0810 (1.9657)	Arch Beta Loss 0.0022 (0.0026)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.5%)	
11/10 02:00:53午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 18/49] Final Prec@1 55.1600%
11/10 02:00:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0149	Prec@(1,5) (46.3%, 78.1%)
11/10 02:01:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0060	Prec@(1,5) (46.7%, 78.1%)
11/10 02:01:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0052	Prec@(1,5) (46.5%, 77.9%)
11/10 02:01:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0104	Prec@(1,5) (46.4%, 77.7%)
11/10 02:01:11午前 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 46.4200%
11/10 02:01:11午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:01:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8480%
11/10 02:01:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.5602 (1.4888)	Arch Loss 2.2414 (1.9577)	Arch Hard Loss 2.2406 (1.9569)	Arch Beta Loss 0.0024 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.7%)	
11/10 02:02:15午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.3863 (1.4962)	Arch Loss 1.5141 (1.9443)	Arch Hard Loss 1.5135 (1.9436)	Arch Beta Loss 0.0018 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.5%)	
11/10 02:02:47午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.5707 (1.5119)	Arch Loss 2.0034 (1.9411)	Arch Hard Loss 2.0028 (1.9404)	Arch Beta Loss 0.0018 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.7%, 86.3%)	
11/10 02:03:15午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.3255 (1.5195)	Arch Loss 1.7855 (1.9334)	Arch Hard Loss 1.7848 (1.9326)	Arch Beta Loss 0.0023 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.3%)	
11/10 02:03:15午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 19/49] Final Prec@1 56.4520%
11/10 02:03:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9225	Prec@(1,5) (48.0%, 79.4%)
11/10 02:03:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9372	Prec@(1,5) (48.3%, 79.1%)
11/10 02:03:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9349	Prec@(1,5) (48.3%, 79.2%)
11/10 02:03:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9315	Prec@(1,5) (48.6%, 79.3%)
11/10 02:03:33午前 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 48.6080%
11/10 02:03:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG2_concat=[2, 3], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:03:34午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.6080%
11/10 02:04:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6490 (1.4238)	Arch Loss 1.7485 (1.9299)	Arch Hard Loss 1.7478 (1.9291)	Arch Beta Loss 0.0019 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.4%)	
11/10 02:04:38午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.7628 (1.4450)	Arch Loss 1.9356 (1.9236)	Arch Hard Loss 1.9349 (1.9228)	Arch Beta Loss 0.0021 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.2%)	
11/10 02:05:09午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.4202 (1.4522)	Arch Loss 1.9932 (1.9192)	Arch Hard Loss 1.9923 (1.9184)	Arch Beta Loss 0.0028 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.2%)	
11/10 02:05:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6215 (1.4632)	Arch Loss 2.2434 (1.9179)	Arch Hard Loss 2.2425 (1.9171)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 86.9%)	
11/10 02:05:37午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 20/49] Final Prec@1 58.3240%
11/10 02:05:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9357	Prec@(1,5) (48.5%, 79.5%)
11/10 02:05:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9127	Prec@(1,5) (49.0%, 79.7%)
11/10 02:05:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9110	Prec@(1,5) (49.1%, 79.6%)
11/10 02:05:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9124	Prec@(1,5) (49.1%, 79.5%)
11/10 02:05:56午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 49.0800%
11/10 02:05:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:05:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.0800%
11/10 02:06:29午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.3766 (1.3899)	Arch Loss 1.8931 (1.9490)	Arch Hard Loss 1.8921 (1.9481)	Arch Beta Loss 0.0027 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.2%)	
11/10 02:07:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.4649 (1.3950)	Arch Loss 2.1266 (1.9157)	Arch Hard Loss 2.1257 (1.9148)	Arch Beta Loss 0.0025 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.2%)	
11/10 02:07:31午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.2934 (1.4067)	Arch Loss 1.9177 (1.9106)	Arch Hard Loss 1.9169 (1.9097)	Arch Beta Loss 0.0020 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 88.1%)	
11/10 02:07:59午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.3286 (1.4236)	Arch Loss 1.4479 (1.9073)	Arch Hard Loss 1.4471 (1.9064)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.7%)	
11/10 02:07:59午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 21/49] Final Prec@1 58.8800%
11/10 02:08:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.8754	Prec@(1,5) (50.1%, 80.3%)
11/10 02:08:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.8646	Prec@(1,5) (50.1%, 80.6%)
11/10 02:08:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.8580	Prec@(1,5) (50.6%, 80.7%)
11/10 02:08:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.8615	Prec@(1,5) (50.6%, 80.7%)
11/10 02:08:18午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 50.6120%
11/10 02:08:18午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:08:18午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.6120%
11/10 02:08:50午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.4678 (1.3356)	Arch Loss 2.3034 (1.9122)	Arch Hard Loss 2.3027 (1.9112)	Arch Beta Loss 0.0018 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.6%)	
11/10 02:09:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4948 (1.3626)	Arch Loss 1.8415 (1.8986)	Arch Hard Loss 1.8404 (1.8976)	Arch Beta Loss 0.0028 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.4%)	
11/10 02:09:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3424 (1.3850)	Arch Loss 1.4722 (1.9008)	Arch Hard Loss 1.4713 (1.8998)	Arch Beta Loss 0.0021 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.2%)	
11/10 02:10:19午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.6913 (1.3871)	Arch Loss 1.6539 (1.8846)	Arch Hard Loss 1.6528 (1.8836)	Arch Beta Loss 0.0029 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.2%)	
11/10 02:10:19午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 22/49] Final Prec@1 60.0600%
11/10 02:10:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8101	Prec@(1,5) (51.6%, 81.2%)
11/10 02:10:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8057	Prec@(1,5) (51.4%, 81.6%)
11/10 02:10:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8148	Prec@(1,5) (51.1%, 81.3%)
11/10 02:10:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8157	Prec@(1,5) (51.0%, 81.2%)
11/10 02:10:37午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 51.0280%
11/10 02:10:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:10:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0280%
11/10 02:11:09午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.1376 (1.2606)	Arch Loss 2.0964 (1.8357)	Arch Hard Loss 2.0951 (1.8346)	Arch Beta Loss 0.0029 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.1%, 90.2%)	
11/10 02:11:40午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.4009 (1.2769)	Arch Loss 1.9292 (1.8730)	Arch Hard Loss 1.9283 (1.8720)	Arch Beta Loss 0.0021 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.7%, 90.1%)	
11/10 02:12:10午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.1829 (1.2991)	Arch Loss 2.0483 (1.8662)	Arch Hard Loss 2.0474 (1.8651)	Arch Beta Loss 0.0021 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.7%)	
11/10 02:12:38午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.3168 (1.3138)	Arch Loss 2.3639 (1.8600)	Arch Hard Loss 2.3631 (1.8589)	Arch Beta Loss 0.0020 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.5%)	
11/10 02:12:39午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 23/49] Final Prec@1 61.9800%
11/10 02:12:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9355	Prec@(1,5) (49.0%, 79.3%)
11/10 02:12:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9361	Prec@(1,5) (49.1%, 79.3%)
11/10 02:12:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9162	Prec@(1,5) (49.4%, 79.7%)
11/10 02:12:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9040	Prec@(1,5) (49.5%, 79.9%)
11/10 02:12:57午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 49.4840%
11/10 02:12:57午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:12:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0280%
11/10 02:13:30午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0630 (1.2300)	Arch Loss 1.7661 (1.8725)	Arch Hard Loss 1.7649 (1.8714)	Arch Beta Loss 0.0024 (0.0025)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 91.0%)	
11/10 02:14:01午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.2739 (1.2520)	Arch Loss 1.2748 (1.8570)	Arch Hard Loss 1.2736 (1.8558)	Arch Beta Loss 0.0026 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.4%, 90.6%)	
11/10 02:14:32午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6695 (1.2706)	Arch Loss 1.6013 (1.8577)	Arch Hard Loss 1.6001 (1.8566)	Arch Beta Loss 0.0026 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.4%)	
11/10 02:15:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.4380 (1.2800)	Arch Loss 1.9373 (1.8539)	Arch Hard Loss 1.9359 (1.8528)	Arch Beta Loss 0.0029 (0.0024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 90.2%)	
11/10 02:15:01午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 24/49] Final Prec@1 62.6320%
11/10 02:15:06午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8111	Prec@(1,5) (51.1%, 81.4%)
11/10 02:15:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8315	Prec@(1,5) (51.3%, 81.0%)
11/10 02:15:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8253	Prec@(1,5) (51.3%, 81.2%)
11/10 02:15:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8349	Prec@(1,5) (51.1%, 81.0%)
11/10 02:15:19午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 51.0680%
11/10 02:15:19午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:15:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0680%
11/10 02:15:52午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.2746 (1.2032)	Arch Loss 1.6620 (1.8834)	Arch Hard Loss 1.6610 (1.8823)	Arch Beta Loss 0.0020 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.2%, 91.2%)	
11/10 02:16:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 0.9448 (1.2076)	Arch Loss 2.0263 (1.8334)	Arch Hard Loss 2.0254 (1.8323)	Arch Beta Loss 0.0018 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 91.0%)	
11/10 02:16:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.2375 (1.2269)	Arch Loss 1.8771 (1.8349)	Arch Hard Loss 1.8761 (1.8338)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.8%)	
11/10 02:17:23午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.1303 (1.2385)	Arch Loss 1.7042 (1.8302)	Arch Hard Loss 1.7034 (1.8291)	Arch Beta Loss 0.0016 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.6%)	
11/10 02:17:24午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 25/49] Final Prec@1 63.8280%
11/10 02:17:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8668	Prec@(1,5) (51.0%, 80.6%)
11/10 02:17:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8471	Prec@(1,5) (51.2%, 81.0%)
11/10 02:17:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8303	Prec@(1,5) (51.6%, 81.2%)
11/10 02:17:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8184	Prec@(1,5) (51.8%, 81.4%)
11/10 02:17:42午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 51.7560%
11/10 02:17:42午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:17:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.7560%
11/10 02:18:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.2259 (1.1607)	Arch Loss 2.0037 (1.7947)	Arch Hard Loss 2.0026 (1.7935)	Arch Beta Loss 0.0020 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.8%)	
11/10 02:18:47午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.6476 (1.1710)	Arch Loss 1.9022 (1.8082)	Arch Hard Loss 1.9009 (1.8070)	Arch Beta Loss 0.0024 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.5%)	
11/10 02:19:18午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.5489 (1.1918)	Arch Loss 1.8592 (1.8204)	Arch Hard Loss 1.8583 (1.8193)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.1%)	
11/10 02:19:46午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.2999 (1.2007)	Arch Loss 1.6073 (1.8240)	Arch Hard Loss 1.6061 (1.8229)	Arch Beta Loss 0.0022 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 91.0%)	
11/10 02:19:47午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 26/49] Final Prec@1 64.7280%
11/10 02:19:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.7659	Prec@(1,5) (52.7%, 82.7%)
11/10 02:19:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.7651	Prec@(1,5) (52.8%, 82.5%)
11/10 02:20:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.7739	Prec@(1,5) (52.7%, 82.2%)
11/10 02:20:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.7775	Prec@(1,5) (52.7%, 82.1%)
11/10 02:20:05午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 52.7160%
11/10 02:20:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:20:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.7160%
11/10 02:20:37午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.3033 (1.0843)	Arch Loss 2.0814 (1.8015)	Arch Hard Loss 2.0803 (1.8003)	Arch Beta Loss 0.0019 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.7%)	
11/10 02:21:09午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.3278 (1.1111)	Arch Loss 1.4501 (1.8114)	Arch Hard Loss 1.4490 (1.8101)	Arch Beta Loss 0.0018 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.2%)	
11/10 02:21:38午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.2165 (1.1246)	Arch Loss 2.0039 (1.8099)	Arch Hard Loss 2.0028 (1.8086)	Arch Beta Loss 0.0020 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.0%)	
11/10 02:22:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.2334 (1.1495)	Arch Loss 1.6362 (1.8056)	Arch Hard Loss 1.6349 (1.8043)	Arch Beta Loss 0.0023 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.7%)	
11/10 02:22:06午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 27/49] Final Prec@1 66.3920%
11/10 02:22:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.7293	Prec@(1,5) (53.3%, 82.6%)
11/10 02:22:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.7470	Prec@(1,5) (52.9%, 82.5%)
11/10 02:22:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.7689	Prec@(1,5) (52.5%, 82.3%)
11/10 02:22:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.7781	Prec@(1,5) (52.5%, 82.0%)
11/10 02:22:24午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 52.5000%
11/10 02:22:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:22:24午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.7160%
11/10 02:22:56午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9884 (1.0540)	Arch Loss 2.0185 (1.7813)	Arch Hard Loss 2.0173 (1.7799)	Arch Beta Loss 0.0020 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.0%)	
11/10 02:23:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1460 (1.0796)	Arch Loss 1.4625 (1.7970)	Arch Hard Loss 1.4609 (1.7957)	Arch Beta Loss 0.0028 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.5%)	
11/10 02:23:58午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.9482 (1.0953)	Arch Loss 1.8894 (1.7950)	Arch Hard Loss 1.8881 (1.7937)	Arch Beta Loss 0.0022 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.2%)	
11/10 02:24:26午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.0398 (1.1166)	Arch Loss 1.8275 (1.7911)	Arch Hard Loss 1.8262 (1.7898)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.0%)	
11/10 02:24:26午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 28/49] Final Prec@1 67.3080%
11/10 02:24:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.7836	Prec@(1,5) (52.9%, 81.8%)
11/10 02:24:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.7689	Prec@(1,5) (53.1%, 82.2%)
11/10 02:24:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.7645	Prec@(1,5) (53.2%, 82.2%)
11/10 02:24:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7619	Prec@(1,5) (53.2%, 82.3%)
11/10 02:24:44午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 53.1600%
11/10 02:24:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:24:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.1600%
11/10 02:25:17午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.6377 (1.0284)	Arch Loss 1.6391 (1.7741)	Arch Hard Loss 1.6374 (1.7727)	Arch Beta Loss 0.0027 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.3%)	
11/10 02:25:48午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.8517 (1.0442)	Arch Loss 2.1885 (1.7978)	Arch Hard Loss 2.1874 (1.7964)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.2%)	
11/10 02:26:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.2222 (1.0641)	Arch Loss 1.8307 (1.7956)	Arch Hard Loss 1.8294 (1.7943)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.8%)	
11/10 02:26:48午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0875 (1.0760)	Arch Loss 1.8345 (1.7827)	Arch Hard Loss 1.8334 (1.7813)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.6%)	
11/10 02:26:48午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 29/49] Final Prec@1 68.2560%
11/10 02:26:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7691	Prec@(1,5) (53.7%, 81.9%)
11/10 02:26:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7599	Prec@(1,5) (53.6%, 82.3%)
11/10 02:27:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7465	Prec@(1,5) (53.5%, 82.5%)
11/10 02:27:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7405	Prec@(1,5) (53.6%, 82.7%)
11/10 02:27:07午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 53.6000%
11/10 02:27:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:27:07午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.6000%
11/10 02:27:40午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 0.9218 (0.9878)	Arch Loss 1.6033 (1.7537)	Arch Hard Loss 1.6016 (1.7523)	Arch Beta Loss 0.0025 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 94.0%)	
11/10 02:28:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 0.9807 (1.0014)	Arch Loss 1.8189 (1.7489)	Arch Hard Loss 1.8177 (1.7475)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.6%)	
11/10 02:28:42午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.0345 (1.0235)	Arch Loss 1.9081 (1.7620)	Arch Hard Loss 1.9067 (1.7605)	Arch Beta Loss 0.0022 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.3%)	
11/10 02:29:10午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.1529 (1.0327)	Arch Loss 1.7423 (1.7709)	Arch Hard Loss 1.7409 (1.7695)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.3%, 93.1%)	
11/10 02:29:11午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 30/49] Final Prec@1 69.2880%
11/10 02:29:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7743	Prec@(1,5) (53.4%, 81.8%)
11/10 02:29:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7542	Prec@(1,5) (53.5%, 82.2%)
11/10 02:29:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7483	Prec@(1,5) (53.7%, 82.4%)
11/10 02:29:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7364	Prec@(1,5) (54.0%, 82.6%)
11/10 02:29:29午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 54.0120%
11/10 02:29:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:29:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.0120%
11/10 02:30:02午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9665 (0.9441)	Arch Loss 1.8041 (1.7748)	Arch Hard Loss 1.8027 (1.7733)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.4%)	
11/10 02:30:33午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.0192 (0.9704)	Arch Loss 1.9680 (1.7959)	Arch Hard Loss 1.9665 (1.7944)	Arch Beta Loss 0.0023 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.8%)	
11/10 02:31:04午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 0.8184 (0.9841)	Arch Loss 1.7942 (1.7750)	Arch Hard Loss 1.7926 (1.7735)	Arch Beta Loss 0.0023 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.6%)	
11/10 02:31:32午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.1751 (0.9934)	Arch Loss 1.7224 (1.7667)	Arch Hard Loss 1.7213 (1.7652)	Arch Beta Loss 0.0016 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.5%)	
11/10 02:31:33午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 31/49] Final Prec@1 70.6880%
11/10 02:31:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7134	Prec@(1,5) (54.3%, 82.8%)
11/10 02:31:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7359	Prec@(1,5) (54.0%, 82.8%)
11/10 02:31:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7266	Prec@(1,5) (54.4%, 82.9%)
11/10 02:31:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7327	Prec@(1,5) (54.4%, 82.8%)
11/10 02:31:51午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 54.4000%
11/10 02:31:51午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:31:51午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4000%
11/10 02:32:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.9744 (0.9272)	Arch Loss 1.6192 (1.7461)	Arch Hard Loss 1.6175 (1.7446)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.1%)	
11/10 02:32:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9269 (0.9343)	Arch Loss 1.8172 (1.7536)	Arch Hard Loss 1.8155 (1.7521)	Arch Beta Loss 0.0024 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
11/10 02:33:26午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.0869 (0.9467)	Arch Loss 1.7720 (1.7437)	Arch Hard Loss 1.7704 (1.7423)	Arch Beta Loss 0.0022 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.2%)	
11/10 02:33:54午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.1692 (0.9594)	Arch Loss 1.6283 (1.7499)	Arch Hard Loss 1.6267 (1.7484)	Arch Beta Loss 0.0022 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.1%)	
11/10 02:33:55午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 32/49] Final Prec@1 71.6960%
11/10 02:34:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.6926	Prec@(1,5) (54.4%, 83.4%)
11/10 02:34:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7102	Prec@(1,5) (54.1%, 83.1%)
11/10 02:34:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7371	Prec@(1,5) (53.7%, 82.8%)
11/10 02:34:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7382	Prec@(1,5) (53.8%, 82.8%)
11/10 02:34:12午前 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 53.8080%
11/10 02:34:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:34:13午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4000%
11/10 02:34:45午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.9615 (0.8784)	Arch Loss 1.3518 (1.7216)	Arch Hard Loss 1.3506 (1.7200)	Arch Beta Loss 0.0017 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.0%)	
11/10 02:35:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.9766 (0.8987)	Arch Loss 1.9496 (1.7348)	Arch Hard Loss 1.9483 (1.7333)	Arch Beta Loss 0.0018 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.7%)	
11/10 02:35:47午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.0024 (0.9027)	Arch Loss 1.9485 (1.7406)	Arch Hard Loss 1.9469 (1.7391)	Arch Beta Loss 0.0022 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/10 02:36:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1533 (0.9190)	Arch Loss 1.6908 (1.7437)	Arch Hard Loss 1.6892 (1.7422)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.4%)	
11/10 02:36:15午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 33/49] Final Prec@1 72.9200%
11/10 02:36:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7024	Prec@(1,5) (55.1%, 83.5%)
11/10 02:36:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7059	Prec@(1,5) (54.5%, 83.4%)
11/10 02:36:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7063	Prec@(1,5) (54.4%, 83.4%)
11/10 02:36:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7088	Prec@(1,5) (54.4%, 83.5%)
11/10 02:36:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 54.4080%
11/10 02:36:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:36:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4080%
11/10 02:37:05午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7090 (0.8202)	Arch Loss 1.9909 (1.7450)	Arch Hard Loss 1.9892 (1.7433)	Arch Beta Loss 0.0023 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 96.1%)	
11/10 02:37:36午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.0501 (0.8544)	Arch Loss 1.4366 (1.7455)	Arch Hard Loss 1.4345 (1.7438)	Arch Beta Loss 0.0028 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.7%)	
11/10 02:38:06午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 0.8220 (0.8702)	Arch Loss 1.5190 (1.7643)	Arch Hard Loss 1.5174 (1.7626)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.3%)	
11/10 02:38:35午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9293 (0.8747)	Arch Loss 1.7854 (1.7487)	Arch Hard Loss 1.7839 (1.7470)	Arch Beta Loss 0.0021 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.2%)	
11/10 02:38:35午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 34/49] Final Prec@1 74.0240%
11/10 02:38:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7088	Prec@(1,5) (55.5%, 83.0%)
11/10 02:38:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7090	Prec@(1,5) (55.4%, 83.0%)
11/10 02:38:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7114	Prec@(1,5) (55.2%, 83.1%)
11/10 02:38:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7078	Prec@(1,5) (55.2%, 83.2%)
11/10 02:38:54午前 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 55.1520%
11/10 02:38:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:38:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.1520%
11/10 02:39:26午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.7536 (0.8037)	Arch Loss 1.8429 (1.7549)	Arch Hard Loss 1.8409 (1.7532)	Arch Beta Loss 0.0025 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.6%)	
11/10 02:39:57午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9496 (0.8277)	Arch Loss 1.8302 (1.7546)	Arch Hard Loss 1.8286 (1.7529)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.6%)	
11/10 02:40:28午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.9294 (0.8404)	Arch Loss 1.7152 (1.7502)	Arch Hard Loss 1.7137 (1.7485)	Arch Beta Loss 0.0019 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.4%)	
11/10 02:40:56午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.9021 (0.8430)	Arch Loss 1.8445 (1.7438)	Arch Hard Loss 1.8425 (1.7421)	Arch Beta Loss 0.0025 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.3%)	
11/10 02:40:57午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 35/49] Final Prec@1 75.2960%
11/10 02:41:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.6810	Prec@(1,5) (55.0%, 84.1%)
11/10 02:41:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.6914	Prec@(1,5) (54.9%, 83.8%)
11/10 02:41:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.6830	Prec@(1,5) (55.4%, 83.7%)
11/10 02:41:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.6848	Prec@(1,5) (55.5%, 83.7%)
11/10 02:41:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 55.4760%
11/10 02:41:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:41:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.4760%
11/10 02:41:48午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8228 (0.7616)	Arch Loss 1.3795 (1.7236)	Arch Hard Loss 1.3771 (1.7217)	Arch Beta Loss 0.0030 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.2%)	
11/10 02:42:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.9159 (0.7736)	Arch Loss 1.1738 (1.7310)	Arch Hard Loss 1.1720 (1.7292)	Arch Beta Loss 0.0021 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.1%)	
11/10 02:42:51午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.9509 (0.7905)	Arch Loss 1.8214 (1.7254)	Arch Hard Loss 1.8190 (1.7236)	Arch Beta Loss 0.0030 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.0%)	
11/10 02:43:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.7185 (0.8094)	Arch Loss 1.5513 (1.7324)	Arch Hard Loss 1.5495 (1.7306)	Arch Beta Loss 0.0022 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
11/10 02:43:20午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 36/49] Final Prec@1 76.5520%
11/10 02:43:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7138	Prec@(1,5) (54.5%, 83.4%)
11/10 02:43:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7057	Prec@(1,5) (54.7%, 83.5%)
11/10 02:43:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7065	Prec@(1,5) (54.7%, 83.5%)
11/10 02:43:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7066	Prec@(1,5) (54.8%, 83.5%)
11/10 02:43:39午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 54.8080%
11/10 02:43:39午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG3_concat=[4, 5])
11/10 02:43:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.4760%
11/10 02:44:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.6698 (0.7500)	Arch Loss 1.7269 (1.7160)	Arch Hard Loss 1.7249 (1.7143)	Arch Beta Loss 0.0023 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
11/10 02:44:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.6104 (0.7525)	Arch Loss 1.8201 (1.7236)	Arch Hard Loss 1.8184 (1.7219)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.3%)	
11/10 02:45:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8716 (0.7670)	Arch Loss 1.7960 (1.7378)	Arch Hard Loss 1.7941 (1.7361)	Arch Beta Loss 0.0023 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
11/10 02:45:43午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.1196 (0.7819)	Arch Loss 1.9561 (1.7385)	Arch Hard Loss 1.9544 (1.7368)	Arch Beta Loss 0.0020 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.0%)	
11/10 02:45:43午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 37/49] Final Prec@1 76.9920%
11/10 02:45:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.6470	Prec@(1,5) (56.2%, 84.3%)
11/10 02:45:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.6805	Prec@(1,5) (56.1%, 83.5%)
11/10 02:45:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.6704	Prec@(1,5) (56.1%, 83.8%)
11/10 02:46:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.6857	Prec@(1,5) (55.7%, 83.6%)
11/10 02:46:02午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 55.7280%
11/10 02:46:02午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 02:46:02午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.7280%
11/10 02:46:35午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.5379 (0.7376)	Arch Loss 1.8412 (1.7365)	Arch Hard Loss 1.8390 (1.7348)	Arch Beta Loss 0.0026 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.7%)	
11/10 02:47:05午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7019 (0.7418)	Arch Loss 1.7919 (1.7293)	Arch Hard Loss 1.7900 (1.7275)	Arch Beta Loss 0.0022 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
11/10 02:47:36午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8686 (0.7471)	Arch Loss 1.4648 (1.7342)	Arch Hard Loss 1.4619 (1.7324)	Arch Beta Loss 0.0034 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
11/10 02:48:04午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.7302 (0.7585)	Arch Loss 2.2382 (1.7313)	Arch Hard Loss 2.2357 (1.7294)	Arch Beta Loss 0.0028 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.5%)	
11/10 02:48:05午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 38/49] Final Prec@1 77.8920%
11/10 02:48:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.6546	Prec@(1,5) (56.7%, 84.3%)
11/10 02:48:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.6653	Prec@(1,5) (56.1%, 83.9%)
11/10 02:48:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.6738	Prec@(1,5) (56.0%, 84.0%)
11/10 02:48:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.6727	Prec@(1,5) (56.1%, 84.0%)
11/10 02:48:23午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 56.1160%
11/10 02:48:23午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 02:48:23午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1160%
11/10 02:48:56午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.7347 (0.7099)	Arch Loss 1.7033 (1.7185)	Arch Hard Loss 1.7017 (1.7165)	Arch Beta Loss 0.0018 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 97.0%)	
11/10 02:49:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7071 (0.7120)	Arch Loss 1.7817 (1.7017)	Arch Hard Loss 1.7796 (1.6997)	Arch Beta Loss 0.0024 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.8%)	
11/10 02:49:59午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.5018 (0.7152)	Arch Loss 2.1412 (1.7125)	Arch Hard Loss 2.1393 (1.7104)	Arch Beta Loss 0.0022 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.9%)	
11/10 02:50:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.6852 (0.7250)	Arch Loss 1.8175 (1.7250)	Arch Hard Loss 1.8157 (1.7230)	Arch Beta Loss 0.0020 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
11/10 02:50:27午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 39/49] Final Prec@1 78.8600%
11/10 02:50:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.6292	Prec@(1,5) (57.0%, 85.2%)
11/10 02:50:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.6664	Prec@(1,5) (56.1%, 84.5%)
11/10 02:50:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.6811	Prec@(1,5) (55.9%, 84.2%)
11/10 02:50:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.6893	Prec@(1,5) (55.8%, 83.9%)
11/10 02:50:45午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 55.7600%
11/10 02:50:45午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 02:50:45午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1160%
11/10 02:51:18午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.5558 (0.6598)	Arch Loss 1.8199 (1.7532)	Arch Hard Loss 1.8174 (1.7511)	Arch Beta Loss 0.0028 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.2%)	
11/10 02:51:49午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5466 (0.6816)	Arch Loss 2.4784 (1.7308)	Arch Hard Loss 2.4769 (1.7288)	Arch Beta Loss 0.0017 (0.0023)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.1%)	
11/10 02:52:20午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6259 (0.6931)	Arch Loss 1.9421 (1.7371)	Arch Hard Loss 1.9403 (1.7351)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/10 02:52:49午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.8045 (0.7010)	Arch Loss 1.8678 (1.7268)	Arch Hard Loss 1.8664 (1.7249)	Arch Beta Loss 0.0016 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
11/10 02:52:49午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 40/49] Final Prec@1 79.5560%
11/10 02:52:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.6549	Prec@(1,5) (56.9%, 84.4%)
11/10 02:52:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.6826	Prec@(1,5) (56.1%, 84.1%)
11/10 02:53:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.6788	Prec@(1,5) (56.3%, 84.1%)
11/10 02:53:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.6756	Prec@(1,5) (56.2%, 84.2%)
11/10 02:53:08午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 56.2200%
11/10 02:53:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 02:53:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2200%
11/10 02:53:40午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.8336 (0.6810)	Arch Loss 1.1651 (1.7000)	Arch Hard Loss 1.1633 (1.6983)	Arch Beta Loss 0.0020 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.0%)	
11/10 02:54:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.7948 (0.6840)	Arch Loss 1.6553 (1.7215)	Arch Hard Loss 1.6533 (1.7198)	Arch Beta Loss 0.0022 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
11/10 02:54:42午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.7585 (0.6835)	Arch Loss 1.8320 (1.7217)	Arch Hard Loss 1.8305 (1.7200)	Arch Beta Loss 0.0017 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
11/10 02:55:10午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.6905 (0.6852)	Arch Loss 2.0810 (1.7249)	Arch Hard Loss 2.0801 (1.7232)	Arch Beta Loss 0.0010 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.2%)	
11/10 02:55:11午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 41/49] Final Prec@1 80.1520%
11/10 02:55:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.6720	Prec@(1,5) (56.2%, 84.6%)
11/10 02:55:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.6788	Prec@(1,5) (56.1%, 84.3%)
11/10 02:55:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.6860	Prec@(1,5) (55.9%, 84.3%)
11/10 02:55:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.6835	Prec@(1,5) (56.0%, 84.2%)
11/10 02:55:29午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 56.0480%
11/10 02:55:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 02:55:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2200%
11/10 02:56:02午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6037 (0.6533)	Arch Loss 1.8904 (1.7046)	Arch Hard Loss 1.8887 (1.7029)	Arch Beta Loss 0.0018 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.6%)	
11/10 02:56:33午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.5373 (0.6666)	Arch Loss 1.5651 (1.7204)	Arch Hard Loss 1.5638 (1.7187)	Arch Beta Loss 0.0014 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.4%)	
11/10 02:57:04午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.4704 (0.6641)	Arch Loss 1.3503 (1.7187)	Arch Hard Loss 1.3487 (1.7169)	Arch Beta Loss 0.0017 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.3%)	
11/10 02:57:33午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.7783 (0.6670)	Arch Loss 1.8920 (1.7140)	Arch Hard Loss 1.8899 (1.7122)	Arch Beta Loss 0.0022 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.2%)	
11/10 02:57:33午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 42/49] Final Prec@1 80.7360%
11/10 02:57:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6919	Prec@(1,5) (56.3%, 83.6%)
11/10 02:57:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.6779	Prec@(1,5) (56.7%, 84.0%)
11/10 02:57:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.6744	Prec@(1,5) (56.3%, 84.1%)
11/10 02:57:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.6725	Prec@(1,5) (56.2%, 84.1%)
11/10 02:57:51午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 56.2480%
11/10 02:57:51午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 02:57:52午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2480%
11/10 02:58:24午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7134 (0.6241)	Arch Loss 1.7703 (1.7084)	Arch Hard Loss 1.7686 (1.7064)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.8%)	
11/10 02:58:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.5650 (0.6335)	Arch Loss 1.4200 (1.7213)	Arch Hard Loss 1.4175 (1.7193)	Arch Beta Loss 0.0026 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.7%)	
11/10 02:59:27午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.5530 (0.6443)	Arch Loss 1.6264 (1.7222)	Arch Hard Loss 1.6245 (1.7202)	Arch Beta Loss 0.0019 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.5%)	
11/10 02:59:55午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.7413 (0.6482)	Arch Loss 1.9520 (1.7154)	Arch Hard Loss 1.9502 (1.7135)	Arch Beta Loss 0.0019 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.5%)	
11/10 02:59:55午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 43/49] Final Prec@1 81.6160%
11/10 03:00:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6566	Prec@(1,5) (55.9%, 84.2%)
11/10 03:00:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6672	Prec@(1,5) (55.6%, 84.2%)
11/10 03:00:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6651	Prec@(1,5) (56.0%, 84.3%)
11/10 03:00:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.6623	Prec@(1,5) (56.2%, 84.4%)
11/10 03:00:12午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 56.1680%
11/10 03:00:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:00:13午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2480%
11/10 03:00:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.7900 (0.6055)	Arch Loss 1.8605 (1.7652)	Arch Hard Loss 1.8587 (1.7632)	Arch Beta Loss 0.0018 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.1%)	
11/10 03:01:14午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6450 (0.6188)	Arch Loss 1.4509 (1.7148)	Arch Hard Loss 1.4476 (1.7127)	Arch Beta Loss 0.0034 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.7%)	
11/10 03:01:44午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6241 (0.6232)	Arch Loss 1.8315 (1.7004)	Arch Hard Loss 1.8298 (1.6983)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.8%)	
11/10 03:02:11午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.7078 (0.6297)	Arch Loss 1.5017 (1.7118)	Arch Hard Loss 1.4997 (1.7098)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
11/10 03:02:11午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 44/49] Final Prec@1 82.2040%
11/10 03:02:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6943	Prec@(1,5) (56.1%, 83.7%)
11/10 03:02:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6529	Prec@(1,5) (56.5%, 84.2%)
11/10 03:02:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6473	Prec@(1,5) (56.6%, 84.4%)
11/10 03:02:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.6453	Prec@(1,5) (56.6%, 84.4%)
11/10 03:02:29午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 56.6480%
11/10 03:02:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:02:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6480%
11/10 03:03:02午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5794 (0.6119)	Arch Loss 1.1656 (1.6958)	Arch Hard Loss 1.1641 (1.6940)	Arch Beta Loss 0.0016 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
11/10 03:03:32午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5967 (0.6097)	Arch Loss 2.0190 (1.7159)	Arch Hard Loss 2.0177 (1.7140)	Arch Beta Loss 0.0013 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.7%)	
11/10 03:04:03午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.6931 (0.6159)	Arch Loss 1.1784 (1.7132)	Arch Hard Loss 1.1760 (1.7113)	Arch Beta Loss 0.0025 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
11/10 03:04:31午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6799 (0.6193)	Arch Loss 1.8909 (1.7178)	Arch Hard Loss 1.8884 (1.7158)	Arch Beta Loss 0.0025 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.6%)	
11/10 03:04:31午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 45/49] Final Prec@1 82.5040%
11/10 03:04:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6277	Prec@(1,5) (56.5%, 84.7%)
11/10 03:04:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.6495	Prec@(1,5) (56.5%, 84.6%)
11/10 03:04:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.6495	Prec@(1,5) (56.6%, 84.5%)
11/10 03:04:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.6544	Prec@(1,5) (56.5%, 84.5%)
11/10 03:04:50午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 56.4920%
11/10 03:04:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:04:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6480%
11/10 03:05:22午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.5588 (0.6017)	Arch Loss 1.3757 (1.7219)	Arch Hard Loss 1.3737 (1.7198)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.8%)	
11/10 03:05:54午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5766 (0.5988)	Arch Loss 1.3340 (1.6976)	Arch Hard Loss 1.3320 (1.6956)	Arch Beta Loss 0.0021 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
11/10 03:06:25午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.8291 (0.6036)	Arch Loss 1.7258 (1.6977)	Arch Hard Loss 1.7239 (1.6956)	Arch Beta Loss 0.0020 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
11/10 03:06:53午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.7038 (0.6063)	Arch Loss 2.0752 (1.6968)	Arch Hard Loss 2.0734 (1.6947)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.9%)	
11/10 03:06:53午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 46/49] Final Prec@1 82.8360%
11/10 03:06:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.6621	Prec@(1,5) (56.2%, 84.7%)
11/10 03:07:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6498	Prec@(1,5) (56.6%, 84.4%)
11/10 03:07:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6581	Prec@(1,5) (56.5%, 84.2%)
11/10 03:07:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.6536	Prec@(1,5) (56.4%, 84.5%)
11/10 03:07:12午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 56.4320%
11/10 03:07:12午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:07:12午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6480%
11/10 03:07:45午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.5302 (0.5813)	Arch Loss 1.9674 (1.7089)	Arch Hard Loss 1.9658 (1.7068)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
11/10 03:08:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5919 (0.5913)	Arch Loss 2.0928 (1.7070)	Arch Hard Loss 2.0910 (1.7049)	Arch Beta Loss 0.0019 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 97.9%)	
11/10 03:08:48午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5361 (0.5937)	Arch Loss 1.2771 (1.7119)	Arch Hard Loss 1.2754 (1.7098)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/10 03:09:16午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.6867 (0.5989)	Arch Loss 1.3400 (1.7117)	Arch Hard Loss 1.3373 (1.7096)	Arch Beta Loss 0.0027 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/10 03:09:16午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 47/49] Final Prec@1 83.1440%
11/10 03:09:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6775	Prec@(1,5) (56.9%, 83.8%)
11/10 03:09:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6553	Prec@(1,5) (56.8%, 84.3%)
11/10 03:09:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6532	Prec@(1,5) (57.1%, 84.2%)
11/10 03:09:34午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6488	Prec@(1,5) (56.9%, 84.5%)
11/10 03:09:35午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 56.8880%
11/10 03:09:35午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:09:35午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.8880%
11/10 03:10:07午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.7217 (0.5788)	Arch Loss 1.8603 (1.7191)	Arch Hard Loss 1.8579 (1.7169)	Arch Beta Loss 0.0024 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
11/10 03:10:39午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6519 (0.5715)	Arch Loss 1.6518 (1.7039)	Arch Hard Loss 1.6493 (1.7017)	Arch Beta Loss 0.0025 (0.0022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
11/10 03:11:10午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.4836 (0.5886)	Arch Loss 1.0805 (1.7088)	Arch Hard Loss 1.0788 (1.7067)	Arch Beta Loss 0.0017 (0.0021)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/10 03:11:38午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6303 (0.5986)	Arch Loss 1.6957 (1.7061)	Arch Hard Loss 1.6943 (1.7041)	Arch Beta Loss 0.0014 (0.0020)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/10 03:11:38午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 48/49] Final Prec@1 83.2120%
11/10 03:11:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.6766	Prec@(1,5) (56.3%, 83.9%)
11/10 03:11:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6570	Prec@(1,5) (56.4%, 84.4%)
11/10 03:11:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6671	Prec@(1,5) (56.5%, 84.1%)
11/10 03:11:57午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6656	Prec@(1,5) (56.4%, 84.1%)
11/10 03:11:57午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 56.4440%
11/10 03:11:57午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:11:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.8880%
11/10 03:12:30午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.3691 (0.5751)	Arch Loss 1.6128 (1.6932)	Arch Hard Loss 1.6110 (1.6915)	Arch Beta Loss 0.0019 (0.0017)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.3%)	
11/10 03:13:00午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4586 (0.5860)	Arch Loss 1.7139 (1.7067)	Arch Hard Loss 1.7121 (1.7050)	Arch Beta Loss 0.0018 (0.0017)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.1%)	
11/10 03:13:30午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.4746 (0.5959)	Arch Loss 1.9588 (1.7115)	Arch Hard Loss 1.9561 (1.7097)	Arch Beta Loss 0.0027 (0.0018)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.6%, 97.9%)	
11/10 03:13:57午前 searchStage_BetaConcat_trainer.py:132 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5513 (0.5981)	Arch Loss 1.3603 (1.7092)	Arch Hard Loss 1.3583 (1.7073)	Arch Beta Loss 0.0020 (0.0019)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.9%)	
11/10 03:13:58午前 searchStage_BetaConcat_trainer.py:146 [INFO] Train: [ 49/49] Final Prec@1 83.4480%
11/10 03:14:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6886	Prec@(1,5) (56.0%, 83.7%)
11/10 03:14:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6720	Prec@(1,5) (56.1%, 84.0%)
11/10 03:14:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6508	Prec@(1,5) (56.4%, 84.4%)
11/10 03:14:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6498	Prec@(1,5) (56.6%, 84.4%)
11/10 03:14:16午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 56.6040%
11/10 03:14:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[2, 5], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
11/10 03:14:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.8880%
11/10 03:14:16午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 56.8880%
11/10 03:14:16午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)]], DAG3_concat=[4, 5])
