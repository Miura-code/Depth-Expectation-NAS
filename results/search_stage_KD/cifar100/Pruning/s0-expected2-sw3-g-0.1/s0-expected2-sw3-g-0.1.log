12/04 09:58:59AM parser.py:28 [INFO] 
12/04 09:58:59AM parser.py:29 [INFO] Parameters:
12/04 09:58:59AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g-0.1/DAG
12/04 09:58:59AM parser.py:31 [INFO] T=10.0
12/04 09:58:59AM parser.py:31 [INFO] ADVANCED=1
12/04 09:58:59AM parser.py:31 [INFO] ALPHA_LR=0.0003
12/04 09:58:59AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/04 09:58:59AM parser.py:31 [INFO] ARCH_CRITERION=expected
12/04 09:58:59AM parser.py:31 [INFO] BATCH_SIZE=64
12/04 09:58:59AM parser.py:31 [INFO] CASCADE=0
12/04 09:58:59AM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/04 09:58:59AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 20]
12/04 09:58:59AM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/04 09:58:59AM parser.py:31 [INFO] DATA_PATH=../data/
12/04 09:58:59AM parser.py:31 [INFO] DATASET=cifar100
12/04 09:58:59AM parser.py:31 [INFO] DEPTH_COEF=0.0
12/04 09:58:59AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/04 09:58:59AM parser.py:31 [INFO] DISCRETE=1
12/04 09:58:59AM parser.py:31 [INFO] EPOCHS=50
12/04 09:58:59AM parser.py:31 [INFO] EVAL_EPOCHS=100
12/04 09:58:59AM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g-0.1
12/04 09:58:59AM parser.py:31 [INFO] FINAL_L=0.0
12/04 09:58:59AM parser.py:31 [INFO] G=-0.1
12/04 09:58:59AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/04 09:58:59AM parser.py:31 [INFO] GPUS=[0]
12/04 09:58:59AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/04 09:58:59AM parser.py:31 [INFO] INIT_CHANNELS=16
12/04 09:58:59AM parser.py:31 [INFO] L=0.0
12/04 09:58:59AM parser.py:31 [INFO] LAYERS=32
12/04 09:58:59AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/04 09:58:59AM parser.py:31 [INFO] NAME=Pruning
12/04 09:58:59AM parser.py:31 [INFO] NONKD=1
12/04 09:58:59AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g-0.1
12/04 09:58:59AM parser.py:31 [INFO] PCDARTS=0
12/04 09:58:59AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected2-sw3-g-0.1/plots
12/04 09:58:59AM parser.py:31 [INFO] PRINT_FREQ=100
12/04 09:58:59AM parser.py:31 [INFO] RESET=0
12/04 09:58:59AM parser.py:31 [INFO] RESUME_PATH=None
12/04 09:58:59AM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g-0.1
12/04 09:58:59AM parser.py:31 [INFO] SEED=0
12/04 09:58:59AM parser.py:31 [INFO] SHARE_STAGE=0
12/04 09:58:59AM parser.py:31 [INFO] SLIDE_WINDOW=3
12/04 09:58:59AM parser.py:31 [INFO] SPEC_CELL=1
12/04 09:58:59AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/04 09:58:59AM parser.py:31 [INFO] TEACHER_NAME=none
12/04 09:58:59AM parser.py:31 [INFO] TEACHER_PATH=none
12/04 09:58:59AM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/04 09:58:59AM parser.py:31 [INFO] TYPE=Pruning
12/04 09:58:59AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/04 09:58:59AM parser.py:31 [INFO] W_LR=0.025
12/04 09:58:59AM parser.py:31 [INFO] W_LR_MIN=0.001
12/04 09:58:59AM parser.py:31 [INFO] W_MOMENTUM=0.9
12/04 09:58:59AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/04 09:58:59AM parser.py:31 [INFO] WORKERS=4
12/04 09:58:59AM parser.py:32 [INFO] 
12/04 09:59:00AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/04 09:59:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.4986 (4.5726)	Arch Loss 3.8077 (3.9520)	Arch Hard Loss 4.4332 (4.5743)	Arch Beta Loss 6.2550 (6.2236)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 9.1%)	
12/04 10:00:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1179 (4.4474)	Arch Loss 3.6995 (3.8152)	Arch Hard Loss 4.3325 (4.4409)	Arch Beta Loss 6.3299 (6.2577)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.4%, 13.0%)	
12/04 10:01:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0775 (4.3540)	Arch Loss 3.5090 (3.7195)	Arch Hard Loss 4.1501 (4.3491)	Arch Beta Loss 6.4116 (6.2953)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.3%, 15.7%)	
12/04 10:02:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8899 (4.2886)	Arch Loss 3.2158 (3.6508)	Arch Hard Loss 3.8642 (4.2839)	Arch Beta Loss 6.4839 (6.3304)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.8%, 17.6%)	
12/04 10:02:07AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  0/49] Final Prec@1 4.8480%
12/04 10:02:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9943	Prec@(1,5) (8.2%, 26.6%)
12/04 10:02:21AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9866	Prec@(1,5) (8.2%, 26.5%)
12/04 10:02:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9859	Prec@(1,5) (8.2%, 26.5%)
12/04 10:02:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9849	Prec@(1,5) (8.1%, 26.5%)
12/04 10:02:33AM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 8.1360%
12/04 10:02:33AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/04 10:02:34AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.1360%
12/04 10:03:23AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8722 (3.9643)	Arch Loss 3.4102 (3.2886)	Arch Hard Loss 4.0673 (3.9414)	Arch Beta Loss 6.5706 (6.5276)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.7%, 27.5%)	
12/04 10:04:12AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.8877 (3.9206)	Arch Loss 3.2996 (3.2426)	Arch Hard Loss 3.9657 (3.8998)	Arch Beta Loss 6.6612 (6.5719)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.1%, 29.0%)	
12/04 10:05:01AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7603 (3.8762)	Arch Loss 2.9769 (3.1946)	Arch Hard Loss 3.6519 (3.8563)	Arch Beta Loss 6.7496 (6.6165)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.7%, 30.3%)	
12/04 10:05:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8608 (3.8346)	Arch Loss 3.4614 (3.1610)	Arch Hard Loss 4.1448 (3.8267)	Arch Beta Loss 6.8338 (6.6570)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.3%, 31.5%)	
12/04 10:05:45AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  1/49] Final Prec@1 10.2760%
12/04 10:05:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6512	Prec@(1,5) (12.6%, 37.4%)
12/04 10:05:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6447	Prec@(1,5) (12.9%, 37.6%)
12/04 10:06:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6471	Prec@(1,5) (12.8%, 37.3%)
12/04 10:06:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6424	Prec@(1,5) (12.9%, 37.5%)
12/04 10:06:12AM searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 12.9000%
12/04 10:06:12AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/04 10:06:12AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.9000%
12/04 10:07:02AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.9007 (3.6360)	Arch Loss 2.9906 (2.9415)	Arch Hard Loss 3.6835 (3.6297)	Arch Beta Loss 6.9281 (6.8819)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.7%, 37.7%)	
12/04 10:07:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5524 (3.5988)	Arch Loss 2.7388 (2.9124)	Arch Hard Loss 3.4407 (3.6052)	Arch Beta Loss 7.0184 (6.9278)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.7%, 38.4%)	
12/04 10:08:39AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.4320 (3.5629)	Arch Loss 2.8204 (2.8749)	Arch Hard Loss 3.5320 (3.5723)	Arch Beta Loss 7.1160 (6.9744)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.5%, 39.8%)	
12/04 10:09:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4884 (3.5400)	Arch Loss 2.7878 (2.8462)	Arch Hard Loss 3.5078 (3.5479)	Arch Beta Loss 7.1998 (7.0167)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.7%, 40.5%)	
12/04 10:09:23AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  2/49] Final Prec@1 14.7320%
12/04 10:09:30AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4454	Prec@(1,5) (15.7%, 43.3%)
12/04 10:09:37AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4605	Prec@(1,5) (15.5%, 42.7%)
12/04 10:09:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4581	Prec@(1,5) (15.5%, 42.7%)
12/04 10:09:49AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4574	Prec@(1,5) (15.6%, 42.9%)
12/04 10:09:49AM searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 15.6360%
12/04 10:09:49AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/04 10:09:50AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 15.6360%
12/04 10:10:40AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.7200 (3.4026)	Arch Loss 2.4931 (2.6651)	Arch Hard Loss 3.2229 (3.3901)	Arch Beta Loss 7.2976 (7.2499)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.9%, 44.2%)	
12/04 10:11:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1186 (3.3554)	Arch Loss 2.7225 (2.6306)	Arch Hard Loss 3.4619 (3.3604)	Arch Beta Loss 7.3946 (7.2984)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.0%, 45.8%)	
12/04 10:12:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.0374 (3.3177)	Arch Loss 2.6181 (2.5954)	Arch Hard Loss 3.3674 (3.3300)	Arch Beta Loss 7.4932 (7.3468)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.6%, 46.7%)	
12/04 10:13:01AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9835 (3.2976)	Arch Loss 2.4496 (2.5762)	Arch Hard Loss 3.2080 (3.3153)	Arch Beta Loss 7.5836 (7.3911)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.9%, 47.2%)	
12/04 10:13:02AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  3/49] Final Prec@1 18.9040%
12/04 10:13:09AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2968	Prec@(1,5) (20.1%, 47.4%)
12/04 10:13:15AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2960	Prec@(1,5) (19.8%, 47.4%)
12/04 10:13:22AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2969	Prec@(1,5) (19.5%, 47.2%)
12/04 10:13:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2994	Prec@(1,5) (19.5%, 47.2%)
12/04 10:13:27AM searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 19.4760%
12/04 10:13:27AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/04 10:13:28AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.4760%
12/04 10:14:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.1984 (3.1197)	Arch Loss 2.1855 (2.4614)	Arch Hard Loss 2.9539 (3.2248)	Arch Beta Loss 7.6835 (7.6341)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 52.7%)	
12/04 10:15:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.1486 (3.1047)	Arch Loss 2.3118 (2.4231)	Arch Hard Loss 3.0904 (3.1916)	Arch Beta Loss 7.7863 (7.6845)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.3%, 52.9%)	
12/04 10:15:57AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.6532 (3.0954)	Arch Loss 2.3565 (2.3968)	Arch Hard Loss 3.1450 (3.1703)	Arch Beta Loss 7.8848 (7.7349)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.4%, 53.0%)	
12/04 10:16:41AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.9027 (3.0889)	Arch Loss 2.0695 (2.3648)	Arch Hard Loss 2.8672 (3.1428)	Arch Beta Loss 7.9772 (7.7802)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 53.1%)	
12/04 10:16:42AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  4/49] Final Prec@1 22.5720%
12/04 10:16:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1286	Prec@(1,5) (22.6%, 52.4%)
12/04 10:16:55AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0965	Prec@(1,5) (23.2%, 53.4%)
12/04 10:17:01AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0856	Prec@(1,5) (23.4%, 53.8%)
12/04 10:17:07AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0851	Prec@(1,5) (23.7%, 53.9%)
12/04 10:17:08AM searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 23.7040%
12/04 10:17:08AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[8, 9])
12/04 10:17:08AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.7040%
12/04 10:17:58AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.0426 (2.9491)	Arch Loss 2.0973 (2.1982)	Arch Hard Loss 2.9058 (3.0015)	Arch Beta Loss 8.0850 (8.0334)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.2%, 55.7%)	
12/04 10:18:46AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0922 (2.9286)	Arch Loss 2.6225 (2.2012)	Arch Hard Loss 3.4412 (3.0097)	Arch Beta Loss 8.1871 (8.0850)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.0%, 56.9%)	
12/04 10:19:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.8519 (2.9209)	Arch Loss 1.8368 (2.1748)	Arch Hard Loss 2.6655 (2.9883)	Arch Beta Loss 8.2868 (8.1356)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.1%, 57.1%)	
12/04 10:20:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6432 (2.9079)	Arch Loss 2.0617 (2.1487)	Arch Hard Loss 2.8997 (2.9668)	Arch Beta Loss 8.3803 (8.1815)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.4%, 57.5%)	
12/04 10:20:19AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  5/49] Final Prec@1 26.3600%
12/04 10:20:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8936	Prec@(1,5) (27.1%, 58.2%)
12/04 10:20:32AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8981	Prec@(1,5) (26.8%, 58.2%)
12/04 10:20:38AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8973	Prec@(1,5) (26.9%, 58.4%)
12/04 10:20:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8959	Prec@(1,5) (26.9%, 58.4%)
12/04 10:20:44AM searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 26.8960%
12/04 10:20:44AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[8, 9])
12/04 10:20:45AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.8960%
12/04 10:21:35AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.6777 (2.7621)	Arch Loss 2.1829 (2.0341)	Arch Hard Loss 3.0312 (2.8774)	Arch Beta Loss 8.4834 (8.4327)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.1%, 61.1%)	
12/04 10:22:24AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.9357 (2.7684)	Arch Loss 2.3427 (2.0122)	Arch Hard Loss 3.2011 (2.8605)	Arch Beta Loss 8.5836 (8.4838)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.1%, 60.8%)	
12/04 10:23:13AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.0274 (2.7630)	Arch Loss 1.8448 (1.9855)	Arch Hard Loss 2.7134 (2.8390)	Arch Beta Loss 8.6864 (8.5345)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.0%, 61.1%)	
12/04 10:23:57AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7243 (2.7575)	Arch Loss 2.0358 (1.9812)	Arch Hard Loss 2.9138 (2.8392)	Arch Beta Loss 8.7798 (8.5804)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.2%, 61.2%)	
12/04 10:23:57AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  6/49] Final Prec@1 29.1880%
12/04 10:24:04AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7693	Prec@(1,5) (29.8%, 61.0%)
12/04 10:24:11AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7554	Prec@(1,5) (29.9%, 61.1%)
12/04 10:24:17AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7582	Prec@(1,5) (29.7%, 61.3%)
12/04 10:24:23AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7603	Prec@(1,5) (29.7%, 61.3%)
12/04 10:24:23AM searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 29.7200%
12/04 10:24:23AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[8, 9])
12/04 10:24:24AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.7200%
12/04 10:25:13AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.9448 (2.6253)	Arch Loss 1.8491 (1.8825)	Arch Hard Loss 2.7373 (2.7658)	Arch Beta Loss 8.8820 (8.8331)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 64.6%)	
12/04 10:26:02AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.5231 (2.6300)	Arch Loss 1.6963 (1.8608)	Arch Hard Loss 2.5941 (2.7490)	Arch Beta Loss 8.9781 (8.8821)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.6%, 64.1%)	
12/04 10:26:51AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.8740 (2.6205)	Arch Loss 2.3638 (1.8523)	Arch Hard Loss 3.2716 (2.7454)	Arch Beta Loss 9.0780 (8.9309)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.4%)	
12/04 10:27:35AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.5369 (2.6145)	Arch Loss 1.8140 (1.8307)	Arch Hard Loss 2.7305 (2.7282)	Arch Beta Loss 9.1652 (8.9750)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.0%, 64.7%)	
12/04 10:27:35AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  7/49] Final Prec@1 31.9600%
12/04 10:27:42AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6294	Prec@(1,5) (32.2%, 64.8%)
12/04 10:27:49AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6139	Prec@(1,5) (32.3%, 64.9%)
12/04 10:27:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6198	Prec@(1,5) (31.9%, 65.2%)
12/04 10:28:02AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6277	Prec@(1,5) (31.6%, 64.9%)
12/04 10:28:02AM searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 31.5880%
12/04 10:28:02AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[8, 9])
12/04 10:28:02AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.5880%
12/04 10:28:52AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.5613 (2.4955)	Arch Loss 2.1321 (1.7431)	Arch Hard Loss 3.0579 (2.6643)	Arch Beta Loss 9.2579 (9.2116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.8%, 67.2%)	
12/04 10:29:41AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.0550 (2.4984)	Arch Loss 2.1864 (1.7363)	Arch Hard Loss 3.1213 (2.6621)	Arch Beta Loss 9.3489 (9.2580)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.1%, 67.1%)	
12/04 10:30:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.5248 (2.4984)	Arch Loss 1.6211 (1.7211)	Arch Hard Loss 2.5658 (2.6516)	Arch Beta Loss 9.4474 (9.3049)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 67.2%)	
12/04 10:31:14AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.4530 (2.4968)	Arch Loss 1.6786 (1.6994)	Arch Hard Loss 2.6320 (2.6342)	Arch Beta Loss 9.5341 (9.3481)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.7%, 67.3%)	
12/04 10:31:14AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  8/49] Final Prec@1 34.6720%
12/04 10:31:21AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5051	Prec@(1,5) (34.1%, 67.3%)
12/04 10:31:28AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5266	Prec@(1,5) (33.7%, 66.7%)
12/04 10:31:34AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5355	Prec@(1,5) (33.8%, 66.2%)
12/04 10:31:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5345	Prec@(1,5) (33.8%, 66.4%)
12/04 10:31:40AM searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 33.7960%
12/04 10:31:40AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:31:40AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.7960%
12/04 10:32:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.3774 (2.3935)	Arch Loss 1.9147 (1.6341)	Arch Hard Loss 2.8773 (2.5922)	Arch Beta Loss 9.6258 (9.5807)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.7%, 69.8%)	
12/04 10:33:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.3963 (2.3991)	Arch Loss 1.5866 (1.5957)	Arch Hard Loss 2.5576 (2.5582)	Arch Beta Loss 9.7106 (9.6248)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.7%, 69.6%)	
12/04 10:34:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.3887 (2.3894)	Arch Loss 1.3352 (1.5801)	Arch Hard Loss 2.3152 (2.5469)	Arch Beta Loss 9.8001 (9.6683)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.1%, 69.6%)	
12/04 10:34:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.3174 (2.3854)	Arch Loss 1.7328 (1.5726)	Arch Hard Loss 2.7206 (2.5434)	Arch Beta Loss 9.8786 (9.7079)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.9%)	
12/04 10:34:49AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  9/49] Final Prec@1 36.9920%
12/04 10:34:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.5066	Prec@(1,5) (34.2%, 67.7%)
12/04 10:35:02AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4910	Prec@(1,5) (34.9%, 67.7%)
12/04 10:35:09AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.5059	Prec@(1,5) (34.7%, 67.6%)
12/04 10:35:14AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.5074	Prec@(1,5) (34.6%, 67.5%)
12/04 10:35:15AM searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 34.6440%
12/04 10:35:15AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:35:15AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.6440%
12/04 10:36:05AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.5168 (2.2789)	Arch Loss 1.4765 (1.5215)	Arch Hard Loss 2.4728 (2.5136)	Arch Beta Loss 9.9633 (9.9210)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.7%, 72.6%)	
12/04 10:36:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.5233 (2.2999)	Arch Loss 1.3047 (1.4853)	Arch Hard Loss 2.3091 (2.4815)	Arch Beta Loss 10.0444 (9.9624)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 71.9%)	
12/04 10:37:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.2726 (2.2995)	Arch Loss 1.2085 (1.4661)	Arch Hard Loss 2.2212 (2.4664)	Arch Beta Loss 10.1268 (10.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.7%)	
12/04 10:38:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.5350 (2.2937)	Arch Loss 1.3263 (1.4581)	Arch Hard Loss 2.3463 (2.4621)	Arch Beta Loss 10.1996 (10.0402)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.8%)	
12/04 10:38:27AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 10/49] Final Prec@1 38.6360%
12/04 10:38:34AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4877	Prec@(1,5) (36.2%, 68.0%)
12/04 10:38:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.4701	Prec@(1,5) (36.2%, 68.2%)
12/04 10:38:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.4859	Prec@(1,5) (36.1%, 68.0%)
12/04 10:38:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.4807	Prec@(1,5) (36.2%, 68.1%)
12/04 10:38:52AM searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 36.2080%
12/04 10:38:52AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:38:53AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.2080%
12/04 10:39:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.0835 (2.2055)	Arch Loss 1.8392 (1.4132)	Arch Hard Loss 2.8670 (2.4372)	Arch Beta Loss 10.2784 (10.2403)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.4%)	
12/04 10:40:31AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.3847 (2.1963)	Arch Loss 1.7535 (1.3920)	Arch Hard Loss 2.7893 (2.4199)	Arch Beta Loss 10.3576 (10.2793)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 73.6%)	
12/04 10:41:19AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.3410 (2.1958)	Arch Loss 1.2302 (1.3725)	Arch Hard Loss 2.2731 (2.4043)	Arch Beta Loss 10.4291 (10.3176)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.6%)	
12/04 10:42:03AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.9529 (2.2039)	Arch Loss 1.1984 (1.3624)	Arch Hard Loss 2.2484 (2.3976)	Arch Beta Loss 10.5001 (10.3517)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.4%, 73.6%)	
12/04 10:42:04AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 11/49] Final Prec@1 40.4520%
12/04 10:42:11AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3599	Prec@(1,5) (38.0%, 70.7%)
12/04 10:42:17AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3436	Prec@(1,5) (38.3%, 71.0%)
12/04 10:42:23AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3304	Prec@(1,5) (38.8%, 71.3%)
12/04 10:42:29AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3244	Prec@(1,5) (38.9%, 71.4%)
12/04 10:42:29AM searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 38.8800%
12/04 10:42:29AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:42:30AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.8800%
12/04 10:43:20AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.9439 (2.0801)	Arch Loss 1.0950 (1.3013)	Arch Hard Loss 2.1524 (2.3550)	Arch Beta Loss 10.5741 (10.5373)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 75.8%)	
12/04 10:44:08AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.3372 (2.1066)	Arch Loss 1.1837 (1.3060)	Arch Hard Loss 2.2491 (2.3635)	Arch Beta Loss 10.6533 (10.5751)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 75.5%)	
12/04 10:44:57AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9008 (2.1054)	Arch Loss 1.2950 (1.2828)	Arch Hard Loss 2.3670 (2.3440)	Arch Beta Loss 10.7200 (10.6126)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 75.6%)	
12/04 10:45:40AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.8969 (2.1113)	Arch Loss 1.3155 (1.2722)	Arch Hard Loss 2.3936 (2.3367)	Arch Beta Loss 10.7811 (10.6446)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.5%)	
12/04 10:45:41AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 12/49] Final Prec@1 43.0600%
12/04 10:45:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3020	Prec@(1,5) (39.4%, 72.1%)
12/04 10:45:54AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2943	Prec@(1,5) (39.2%, 72.1%)
12/04 10:46:00AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2858	Prec@(1,5) (39.6%, 72.2%)
12/04 10:46:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2944	Prec@(1,5) (39.4%, 71.8%)
12/04 10:46:06AM searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 39.3360%
12/04 10:46:06AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:46:07AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.3360%
12/04 10:46:57AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.0485 (1.9994)	Arch Loss 1.2838 (1.2163)	Arch Hard Loss 2.3684 (2.2979)	Arch Beta Loss 10.8460 (10.8153)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.0%)	
12/04 10:47:45AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.8138 (2.0436)	Arch Loss 1.0833 (1.2052)	Arch Hard Loss 2.1741 (2.2898)	Arch Beta Loss 10.9075 (10.8465)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.3%, 77.2%)	
12/04 10:48:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.9116 (2.0450)	Arch Loss 1.0288 (1.1968)	Arch Hard Loss 2.1260 (2.2846)	Arch Beta Loss 10.9727 (10.8778)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.5%, 77.1%)	
12/04 10:49:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.8341 (2.0452)	Arch Loss 0.8928 (1.1880)	Arch Hard Loss 1.9959 (2.2787)	Arch Beta Loss 11.0308 (10.9065)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 77.0%)	
12/04 10:49:18AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 13/49] Final Prec@1 44.3600%
12/04 10:49:25AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2507	Prec@(1,5) (40.8%, 72.9%)
12/04 10:49:31AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2763	Prec@(1,5) (40.0%, 72.2%)
12/04 10:49:38AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2455	Prec@(1,5) (40.8%, 72.7%)
12/04 10:49:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2470	Prec@(1,5) (40.5%, 72.8%)
12/04 10:49:44AM searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 40.5000%
12/04 10:49:44AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:49:45AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.5000%
12/04 10:50:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8473 (1.9207)	Arch Loss 1.3164 (1.1373)	Arch Hard Loss 2.4259 (2.2437)	Arch Beta Loss 11.0953 (11.0640)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.3%)	
12/04 10:51:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.0571 (1.9540)	Arch Loss 1.0937 (1.1421)	Arch Hard Loss 2.2092 (2.2516)	Arch Beta Loss 11.1546 (11.0950)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.6%, 78.5%)	
12/04 10:52:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.1462 (1.9607)	Arch Loss 1.0202 (1.1265)	Arch Hard Loss 2.1418 (2.2390)	Arch Beta Loss 11.2159 (11.1256)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.2%, 78.3%)	
12/04 10:52:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.8113 (1.9645)	Arch Loss 0.9140 (1.1145)	Arch Hard Loss 2.0411 (2.2298)	Arch Beta Loss 11.2710 (11.1528)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.2%, 78.3%)	
12/04 10:52:55AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 14/49] Final Prec@1 46.1800%
12/04 10:53:02AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.2325	Prec@(1,5) (41.8%, 73.3%)
12/04 10:53:08AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.2440	Prec@(1,5) (41.1%, 73.3%)
12/04 10:53:15AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.2540	Prec@(1,5) (40.9%, 73.1%)
12/04 10:53:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.2574	Prec@(1,5) (40.6%, 72.9%)
12/04 10:53:20AM searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 40.5960%
12/04 10:53:20AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG3_concat=[8, 9])
12/04 10:53:21AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.5960%
12/04 10:54:11AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.1021 (1.8643)	Arch Loss 1.0516 (1.0907)	Arch Hard Loss 2.1847 (2.2209)	Arch Beta Loss 11.3305 (11.3013)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.1%)	
12/04 10:55:01AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.6442 (1.8742)	Arch Loss 0.9585 (1.0821)	Arch Hard Loss 2.0975 (2.2152)	Arch Beta Loss 11.3903 (11.3310)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 79.8%)	
12/04 10:55:50AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9063 (1.8777)	Arch Loss 0.8909 (1.0764)	Arch Hard Loss 2.0352 (2.2123)	Arch Beta Loss 11.4434 (11.3596)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.1%)	
12/04 10:56:34AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.6899 (1.8896)	Arch Loss 0.8467 (1.0629)	Arch Hard Loss 1.9961 (2.2014)	Arch Beta Loss 11.4932 (11.3848)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 79.9%)	
12/04 10:56:35AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 15/49] Final Prec@1 48.2160%
12/04 10:56:41AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.2052	Prec@(1,5) (42.1%, 74.4%)
12/04 10:56:48AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1966	Prec@(1,5) (42.2%, 73.9%)
12/04 10:56:55AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.2069	Prec@(1,5) (41.7%, 73.9%)
12/04 10:57:01AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1996	Prec@(1,5) (41.8%, 74.1%)
12/04 10:57:01AM searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 41.8240%
12/04 10:57:01AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG3_concat=[8, 9])
12/04 10:57:01AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.8240%
12/04 10:57:51AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.7322 (1.8044)	Arch Loss 0.6045 (1.0220)	Arch Hard Loss 1.7589 (2.1739)	Arch Beta Loss 11.5438 (11.5192)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 80.7%)	
12/04 10:58:40AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.8443 (1.8231)	Arch Loss 1.1009 (1.0042)	Arch Hard Loss 2.2604 (2.1587)	Arch Beta Loss 11.5944 (11.5447)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.4%, 81.1%)	
12/04 10:59:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.8219 (1.8393)	Arch Loss 1.2014 (1.0099)	Arch Hard Loss 2.3660 (2.1669)	Arch Beta Loss 11.6458 (11.5698)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 80.8%)	
12/04 11:00:13AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7566 (1.8376)	Arch Loss 0.8241 (0.9960)	Arch Hard Loss 1.9935 (2.1553)	Arch Beta Loss 11.6939 (11.5929)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.1%, 80.8%)	
12/04 11:00:13AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 16/49] Final Prec@1 49.1160%
12/04 11:00:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1461	Prec@(1,5) (43.0%, 74.6%)
12/04 11:00:27AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1227	Prec@(1,5) (43.2%, 75.1%)
12/04 11:00:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1219	Prec@(1,5) (43.2%, 75.2%)
12/04 11:00:39AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1142	Prec@(1,5) (43.3%, 75.5%)
12/04 11:00:39AM searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 43.3320%
12/04 11:00:39AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG3_concat=[8, 9])
12/04 11:00:40AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.3320%
12/04 11:01:29AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.6151 (1.7317)	Arch Loss 0.8383 (0.9448)	Arch Hard Loss 2.0126 (2.1168)	Arch Beta Loss 11.7437 (11.7195)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.6%)	
12/04 11:02:18AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.8168 (1.7578)	Arch Loss 0.8841 (0.9467)	Arch Hard Loss 2.0629 (2.1210)	Arch Beta Loss 11.7883 (11.7428)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.9%)	
12/04 11:03:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.9340 (1.7671)	Arch Loss 0.5717 (0.9573)	Arch Hard Loss 1.7551 (2.1338)	Arch Beta Loss 11.8340 (11.7654)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.7%)	
12/04 11:03:51AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.4154 (1.7791)	Arch Loss 0.7123 (0.9512)	Arch Hard Loss 1.8997 (2.1298)	Arch Beta Loss 11.8745 (11.7858)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.7%)	
12/04 11:03:51AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 17/49] Final Prec@1 50.3720%
12/04 11:03:58AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.1255	Prec@(1,5) (43.4%, 75.5%)
12/04 11:04:05AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.1144	Prec@(1,5) (43.7%, 75.7%)
12/04 11:04:11AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.1221	Prec@(1,5) (43.4%, 75.5%)
12/04 11:04:17AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.1215	Prec@(1,5) (43.5%, 75.4%)
12/04 11:04:17AM searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 43.4880%
12/04 11:04:17AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG3_concat=[8, 9])
12/04 11:04:18AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.4880%
12/04 11:05:07AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4719 (1.6827)	Arch Loss 1.2048 (0.8920)	Arch Hard Loss 2.3968 (2.0818)	Arch Beta Loss 11.9194 (11.8972)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.7%)	
12/04 11:05:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4467 (1.7040)	Arch Loss 0.6934 (0.9028)	Arch Hard Loss 1.8892 (2.0946)	Arch Beta Loss 11.9577 (11.9178)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 83.2%)	
12/04 11:06:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.9550 (1.7147)	Arch Loss 0.9212 (0.9117)	Arch Hard Loss 2.1215 (2.1056)	Arch Beta Loss 12.0035 (11.9390)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.8%)	
12/04 11:07:24AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.7979 (1.7249)	Arch Loss 0.4044 (0.8941)	Arch Hard Loss 1.6089 (2.0900)	Arch Beta Loss 12.0451 (11.9587)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.6%)	
12/04 11:07:25AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 18/49] Final Prec@1 51.5160%
12/04 11:07:32AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1576	Prec@(1,5) (44.0%, 74.6%)
12/04 11:07:38AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1441	Prec@(1,5) (44.1%, 75.0%)
12/04 11:07:45AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1361	Prec@(1,5) (44.2%, 75.0%)
12/04 11:07:50AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1415	Prec@(1,5) (43.7%, 74.9%)
12/04 11:07:51AM searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 43.7360%
12/04 11:07:51AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG3_concat=[8, 9])
12/04 11:07:51AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.7360%
12/04 11:08:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.3285 (1.6151)	Arch Loss 1.0330 (0.8607)	Arch Hard Loss 2.2416 (2.0672)	Arch Beta Loss 12.0857 (12.0657)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.9%)	
12/04 11:09:31AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.9598 (1.6498)	Arch Loss 1.1413 (0.8678)	Arch Hard Loss 2.3539 (2.0763)	Arch Beta Loss 12.1257 (12.0855)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 84.1%)	
12/04 11:10:20AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.1089 (1.6601)	Arch Loss 0.5254 (0.8505)	Arch Hard Loss 1.7416 (2.0610)	Arch Beta Loss 12.1626 (12.1050)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.4%, 83.9%)	
12/04 11:11:04AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.7094 (1.6723)	Arch Loss 0.8790 (0.8470)	Arch Hard Loss 2.0990 (2.0592)	Arch Beta Loss 12.1997 (12.1221)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.6%)	
12/04 11:11:05AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 19/49] Final Prec@1 53.0280%
12/04 11:11:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0581	Prec@(1,5) (46.1%, 76.9%)
12/04 11:11:18AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0698	Prec@(1,5) (45.3%, 76.6%)
12/04 11:11:24AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0625	Prec@(1,5) (45.4%, 76.8%)
12/04 11:11:30AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0555	Prec@(1,5) (45.4%, 76.9%)
12/04 11:11:30AM searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 45.4320%
12/04 11:11:30AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG3_concat=[8, 9])
12/04 11:11:31AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.4320%
12/04 11:12:20AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.5904 (1.5750)	Arch Loss 0.5959 (0.8272)	Arch Hard Loss 1.8196 (2.0490)	Arch Beta Loss 12.2365 (12.2187)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.8%)	
12/04 11:13:09AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.5164 (1.5882)	Arch Loss 1.3726 (0.8152)	Arch Hard Loss 2.6005 (2.0390)	Arch Beta Loss 12.2792 (12.2385)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.5%)	
12/04 11:13:58AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.1559 (1.5970)	Arch Loss 0.5493 (0.8084)	Arch Hard Loss 1.7802 (2.0341)	Arch Beta Loss 12.3085 (12.2573)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.6%, 85.3%)	
12/04 11:14:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6769 (1.6143)	Arch Loss 0.3947 (0.8080)	Arch Hard Loss 1.6286 (2.0353)	Arch Beta Loss 12.3390 (12.2726)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.8%)	
12/04 11:14:43AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 20/49] Final Prec@1 54.3400%
12/04 11:14:50AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.0470	Prec@(1,5) (46.2%, 77.5%)
12/04 11:14:56AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.0413	Prec@(1,5) (46.2%, 77.5%)
12/04 11:15:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.0417	Prec@(1,5) (46.1%, 77.6%)
12/04 11:15:09AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.0499	Prec@(1,5) (46.0%, 77.4%)
12/04 11:15:09AM searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 45.9720%
12/04 11:15:09AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG3_concat=[8, 9])
12/04 11:15:09AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.9720%
12/04 11:15:59AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5076 (1.5080)	Arch Loss 0.9991 (0.7960)	Arch Hard Loss 2.2364 (2.0316)	Arch Beta Loss 12.3726 (12.3565)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.7%)	
12/04 11:16:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.3814 (1.5423)	Arch Loss 1.0806 (0.7936)	Arch Hard Loss 2.3211 (2.0308)	Arch Beta Loss 12.4043 (12.3723)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 86.1%)	
12/04 11:17:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.7873 (1.5618)	Arch Loss 0.6110 (0.7842)	Arch Hard Loss 1.8543 (2.0230)	Arch Beta Loss 12.4331 (12.3881)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.7%)	
12/04 11:18:21AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.6152 (1.5739)	Arch Loss 0.5201 (0.7756)	Arch Hard Loss 1.7669 (2.0159)	Arch Beta Loss 12.4678 (12.4025)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 85.4%)	
12/04 11:18:21AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 21/49] Final Prec@1 55.2040%
12/04 11:18:28AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9368	Prec@(1,5) (48.3%, 78.2%)
12/04 11:18:35AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9491	Prec@(1,5) (47.6%, 78.8%)
12/04 11:18:41AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9531	Prec@(1,5) (47.8%, 78.6%)
12/04 11:18:47AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9453	Prec@(1,5) (47.9%, 78.7%)
12/04 11:18:47AM searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 47.9320%
12/04 11:18:47AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[8, 9])
12/04 11:18:48AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9320%
12/04 11:19:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.7650 (1.4436)	Arch Loss 0.9513 (0.7528)	Arch Hard Loss 2.2010 (2.0010)	Arch Beta Loss 12.4970 (12.4820)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.5%)	
12/04 11:20:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.4877 (1.4740)	Arch Loss 0.5644 (0.7356)	Arch Hard Loss 1.8174 (1.9854)	Arch Beta Loss 12.5307 (12.4983)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.9%)	
12/04 11:21:14AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.4061 (1.4981)	Arch Loss 1.0039 (0.7315)	Arch Hard Loss 2.2600 (1.9829)	Arch Beta Loss 12.5614 (12.5138)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.4%)	
12/04 11:21:58AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.6690 (1.5133)	Arch Loss 0.6772 (0.7312)	Arch Hard Loss 1.9360 (1.9840)	Arch Beta Loss 12.5880 (12.5279)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.1%)	
12/04 11:21:59AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 22/49] Final Prec@1 56.8880%
12/04 11:22:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9809	Prec@(1,5) (47.9%, 78.4%)
12/04 11:22:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9937	Prec@(1,5) (47.4%, 77.9%)
12/04 11:22:19AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9910	Prec@(1,5) (47.3%, 78.0%)
12/04 11:22:24AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9927	Prec@(1,5) (47.2%, 78.0%)
12/04 11:22:25AM searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 47.1680%
12/04 11:22:25AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[8, 9])
12/04 11:22:25AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9320%
12/04 11:23:15AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.5054 (1.3918)	Arch Loss 0.4084 (0.7185)	Arch Hard Loss 1.6700 (1.9787)	Arch Beta Loss 12.6158 (12.6019)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 88.6%)	
12/04 11:24:04AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.2938 (1.4289)	Arch Loss 0.8429 (0.7132)	Arch Hard Loss 2.1071 (1.9747)	Arch Beta Loss 12.6422 (12.6152)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.9%)	
12/04 11:24:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.4974 (1.4398)	Arch Loss 0.5672 (0.7192)	Arch Hard Loss 1.8341 (1.9821)	Arch Beta Loss 12.6691 (12.6289)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.7%)	
12/04 11:25:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.5280 (1.4561)	Arch Loss 0.8212 (0.7147)	Arch Hard Loss 2.0904 (1.9788)	Arch Beta Loss 12.6924 (12.6409)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.2%, 87.3%)	
12/04 11:25:38AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 23/49] Final Prec@1 58.1640%
12/04 11:25:44AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.0197	Prec@(1,5) (46.5%, 77.0%)
12/04 11:25:51AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.0194	Prec@(1,5) (46.4%, 77.5%)
12/04 11:25:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.0234	Prec@(1,5) (46.5%, 77.5%)
12/04 11:26:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.0289	Prec@(1,5) (46.5%, 77.6%)
12/04 11:26:03AM searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 46.5120%
12/04 11:26:03AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[7, 8])
12/04 11:26:04AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9320%
12/04 11:26:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0318 (1.3525)	Arch Loss 1.0844 (0.6871)	Arch Hard Loss 2.3559 (1.9576)	Arch Beta Loss 12.7152 (12.7047)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.7%, 89.4%)	
12/04 11:27:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.4623 (1.3892)	Arch Loss 1.0272 (0.6819)	Arch Hard Loss 2.3011 (1.9535)	Arch Beta Loss 12.7389 (12.7158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.5%)	
12/04 11:28:32AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6476 (1.4022)	Arch Loss 0.8106 (0.6772)	Arch Hard Loss 2.0870 (1.9500)	Arch Beta Loss 12.7643 (12.7280)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.2%)	
12/04 11:29:16AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.4212 (1.4156)	Arch Loss 0.4854 (0.6761)	Arch Hard Loss 1.7640 (1.9500)	Arch Beta Loss 12.7866 (12.7390)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.9%)	
12/04 11:29:16AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 24/49] Final Prec@1 59.3480%
12/04 11:29:23AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9593	Prec@(1,5) (48.2%, 78.6%)
12/04 11:29:30AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9533	Prec@(1,5) (48.5%, 78.8%)
12/04 11:29:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9535	Prec@(1,5) (48.5%, 78.6%)
12/04 11:29:43AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9436	Prec@(1,5) (48.6%, 78.8%)
12/04 11:29:43AM searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 48.5680%
12/04 11:29:43AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[7, 8])
12/04 11:29:43AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.5680%
12/04 11:30:33AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3439 (1.3248)	Arch Loss 0.7115 (0.6316)	Arch Hard Loss 1.9924 (1.9115)	Arch Beta Loss 12.8091 (12.7988)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.4%)	
12/04 11:31:22AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.5294 (1.3437)	Arch Loss 1.0737 (0.6261)	Arch Hard Loss 2.3574 (1.9072)	Arch Beta Loss 12.8365 (12.8113)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.1%, 89.1%)	
12/04 11:32:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.2745 (1.3505)	Arch Loss 0.0562 (0.6350)	Arch Hard Loss 1.3419 (1.9173)	Arch Beta Loss 12.8569 (12.8230)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.0%, 89.0%)	
12/04 11:32:54AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.0906 (1.3582)	Arch Loss 0.3111 (0.6324)	Arch Hard Loss 1.5985 (1.9157)	Arch Beta Loss 12.8741 (12.8329)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.9%)	
12/04 11:32:55AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 25/49] Final Prec@1 60.8560%
12/04 11:33:02AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9118	Prec@(1,5) (48.4%, 79.7%)
12/04 11:33:08AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9154	Prec@(1,5) (48.8%, 79.7%)
12/04 11:33:15AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8953	Prec@(1,5) (49.4%, 80.0%)
12/04 11:33:20AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.9006	Prec@(1,5) (49.5%, 79.9%)
12/04 11:33:20AM searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 49.4760%
12/04 11:33:20AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[7, 8])
12/04 11:33:21AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.4760%
12/04 11:34:11AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5576 (1.2961)	Arch Loss 0.4209 (0.5789)	Arch Hard Loss 1.7104 (1.8673)	Arch Beta Loss 12.8955 (12.8844)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.0%)	
12/04 11:35:00AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.9373 (1.3031)	Arch Loss 0.8749 (0.5957)	Arch Hard Loss 2.1667 (1.8853)	Arch Beta Loss 12.9174 (12.8955)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.9%)	
12/04 11:35:49AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.3137 (1.3050)	Arch Loss 0.4208 (0.6060)	Arch Hard Loss 1.7149 (1.8967)	Arch Beta Loss 12.9404 (12.9064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.8%)	
12/04 11:36:32AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0655 (1.3205)	Arch Loss 0.9308 (0.6203)	Arch Hard Loss 2.2268 (1.9120)	Arch Beta Loss 12.9594 (12.9164)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.5%)	
12/04 11:36:33AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 26/49] Final Prec@1 61.8160%
12/04 11:36:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8860	Prec@(1,5) (49.6%, 80.2%)
12/04 11:36:47AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8620	Prec@(1,5) (50.3%, 80.4%)
12/04 11:36:55AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8677	Prec@(1,5) (50.2%, 80.3%)
12/04 11:37:01AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8676	Prec@(1,5) (50.0%, 80.3%)
12/04 11:37:01AM searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 50.0600%
12/04 11:37:01AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[7, 8])
12/04 11:37:02AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.0600%
12/04 11:37:52AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0560 (1.1963)	Arch Loss 1.2458 (0.6203)	Arch Hard Loss 2.5437 (1.9173)	Arch Beta Loss 12.9793 (12.9696)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.5%)	
12/04 11:38:41AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.5070 (1.2339)	Arch Loss 0.3722 (0.5963)	Arch Hard Loss 1.6723 (1.8943)	Arch Beta Loss 13.0015 (12.9797)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.7%)	
12/04 11:39:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.2376 (1.2507)	Arch Loss 0.9839 (0.5985)	Arch Hard Loss 2.2860 (1.8975)	Arch Beta Loss 13.0207 (12.9905)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.5%)	
12/04 11:40:14AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.2850 (1.2675)	Arch Loss 0.2359 (0.5952)	Arch Hard Loss 1.5396 (1.8952)	Arch Beta Loss 13.0374 (12.9993)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.3%)	
12/04 11:40:14AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 27/49] Final Prec@1 63.4800%
12/04 11:40:21AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8836	Prec@(1,5) (49.9%, 80.0%)
12/04 11:40:28AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8587	Prec@(1,5) (50.4%, 80.5%)
12/04 11:40:34AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8677	Prec@(1,5) (50.4%, 80.3%)
12/04 11:40:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8643	Prec@(1,5) (50.5%, 80.4%)
12/04 11:40:40AM searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 50.5160%
12/04 11:40:40AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 11:40:41AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.5160%
12/04 11:41:30AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.3492 (1.1767)	Arch Loss 0.6979 (0.5450)	Arch Hard Loss 2.0035 (1.8497)	Arch Beta Loss 13.0558 (13.0468)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.4%)	
12/04 11:42:19AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.1058 (1.2017)	Arch Loss 0.1049 (0.5582)	Arch Hard Loss 1.4121 (1.8637)	Arch Beta Loss 13.0713 (13.0551)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 91.1%)	
12/04 11:43:08AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.3430 (1.2076)	Arch Loss 0.4988 (0.5689)	Arch Hard Loss 1.8082 (1.8754)	Arch Beta Loss 13.0939 (13.0642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 91.1%)	
12/04 11:43:52AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.2669 (1.2299)	Arch Loss 0.2154 (0.5819)	Arch Hard Loss 1.5262 (1.8892)	Arch Beta Loss 13.1082 (13.0724)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.7%)	
12/04 11:43:52AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 28/49] Final Prec@1 64.1280%
12/04 11:43:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8740	Prec@(1,5) (50.3%, 80.3%)
12/04 11:44:06AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8879	Prec@(1,5) (49.8%, 80.4%)
12/04 11:44:12AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8686	Prec@(1,5) (50.5%, 80.7%)
12/04 11:44:18AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8613	Prec@(1,5) (50.7%, 80.7%)
12/04 11:44:18AM searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 50.6800%
12/04 11:44:18AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 11:44:18AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.6800%
12/04 11:45:09AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1877 (1.1309)	Arch Loss 0.4537 (0.5806)	Arch Hard Loss 1.7664 (1.8923)	Arch Beta Loss 13.1261 (13.1173)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.9%)	
12/04 11:45:58AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9225 (1.1474)	Arch Loss 0.3974 (0.5824)	Arch Hard Loss 1.7116 (1.8949)	Arch Beta Loss 13.1420 (13.1251)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.9%)	
12/04 11:46:47AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.2015 (1.1706)	Arch Loss 0.7134 (0.5748)	Arch Hard Loss 2.0289 (1.8882)	Arch Beta Loss 13.1553 (13.1331)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.4%)	
12/04 11:47:31AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0710 (1.1839)	Arch Loss 0.7000 (0.5646)	Arch Hard Loss 2.0168 (1.8786)	Arch Beta Loss 13.1682 (13.1397)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.3%)	
12/04 11:47:32AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 29/49] Final Prec@1 65.5680%
12/04 11:47:39AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8420	Prec@(1,5) (51.4%, 80.9%)
12/04 11:47:45AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8400	Prec@(1,5) (51.7%, 81.1%)
12/04 11:47:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8440	Prec@(1,5) (51.5%, 81.0%)
12/04 11:47:58AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8338	Prec@(1,5) (51.6%, 81.3%)
12/04 11:47:58AM searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 51.6360%
12/04 11:47:58AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 11:47:58AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.6360%
12/04 11:48:48AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.2577 (1.0985)	Arch Loss 0.2205 (0.5225)	Arch Hard Loss 1.5388 (1.8401)	Arch Beta Loss 13.1824 (13.1756)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
12/04 11:49:37AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.4011 (1.0978)	Arch Loss 0.6432 (0.5469)	Arch Hard Loss 1.9630 (1.8653)	Arch Beta Loss 13.1982 (13.1833)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.6%)	
12/04 11:50:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1872 (1.1200)	Arch Loss 0.2388 (0.5369)	Arch Hard Loss 1.5602 (1.8560)	Arch Beta Loss 13.2134 (13.1907)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.3%)	
12/04 11:51:10AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.3303 (1.1435)	Arch Loss 1.0980 (0.5382)	Arch Hard Loss 2.4208 (1.8579)	Arch Beta Loss 13.2280 (13.1976)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 92.0%)	
12/04 11:51:11AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 30/49] Final Prec@1 66.5520%
12/04 11:51:18AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8602	Prec@(1,5) (51.2%, 80.3%)
12/04 11:51:24AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8435	Prec@(1,5) (51.0%, 80.8%)
12/04 11:51:31AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8537	Prec@(1,5) (50.8%, 80.7%)
12/04 11:51:36AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8465	Prec@(1,5) (50.8%, 80.8%)
12/04 11:51:37AM searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 50.8320%
12/04 11:51:37AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 11:51:37AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.6360%
12/04 11:52:27AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9888 (1.0724)	Arch Loss 0.6589 (0.5183)	Arch Hard Loss 1.9833 (1.8420)	Arch Beta Loss 13.2442 (13.2371)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.6%)	
12/04 11:53:17AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9635 (1.0757)	Arch Loss 0.5040 (0.5257)	Arch Hard Loss 1.8299 (1.8501)	Arch Beta Loss 13.2595 (13.2442)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.7%)	
12/04 11:54:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.2852 (1.0996)	Arch Loss 0.9299 (0.5249)	Arch Hard Loss 2.2573 (1.8501)	Arch Beta Loss 13.2740 (13.2516)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.5%)	
12/04 11:54:49AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.2046 (1.1114)	Arch Loss 0.3757 (0.5188)	Arch Hard Loss 1.7046 (1.8446)	Arch Beta Loss 13.2893 (13.2587)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.4%)	
12/04 11:54:50AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 31/49] Final Prec@1 67.6840%
12/04 11:54:57AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7401	Prec@(1,5) (53.4%, 82.6%)
12/04 11:55:03AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7560	Prec@(1,5) (53.2%, 82.2%)
12/04 11:55:10AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7730	Prec@(1,5) (52.8%, 82.1%)
12/04 11:55:16AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7808	Prec@(1,5) (52.7%, 82.1%)
12/04 11:55:16AM searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 52.6600%
12/04 11:55:16AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 11:55:17AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6600%
12/04 11:56:06AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.3033 (1.0311)	Arch Loss 0.1477 (0.4953)	Arch Hard Loss 1.4781 (1.8249)	Arch Beta Loss 13.3040 (13.2968)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.5%)	
12/04 11:56:53AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.0174 (1.0477)	Arch Loss 0.7641 (0.5108)	Arch Hard Loss 2.0960 (1.8413)	Arch Beta Loss 13.3189 (13.3046)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 93.4%)	
12/04 11:57:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.9103 (1.0495)	Arch Loss 0.4367 (0.5156)	Arch Hard Loss 1.7700 (1.8468)	Arch Beta Loss 13.3333 (13.3117)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.0%, 93.2%)	
12/04 11:58:26AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.2455 (1.0607)	Arch Loss 0.3790 (0.5075)	Arch Hard Loss 1.7133 (1.8393)	Arch Beta Loss 13.3427 (13.3178)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 93.0%)	
12/04 11:58:26AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 32/49] Final Prec@1 68.7240%
12/04 11:58:33AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8050	Prec@(1,5) (52.4%, 82.4%)
12/04 11:58:40AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8113	Prec@(1,5) (52.7%, 81.9%)
12/04 11:58:46AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8020	Prec@(1,5) (52.4%, 81.9%)
12/04 11:58:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7989	Prec@(1,5) (52.7%, 81.7%)
12/04 11:58:52AM searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 52.6680%
12/04 11:58:52AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 11:58:53AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6680%
12/04 11:59:42AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.9862 (0.9547)	Arch Loss 0.5460 (0.4886)	Arch Hard Loss 1.8816 (1.8235)	Arch Beta Loss 13.3562 (13.3490)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.4%)	
12/04 12:00:30PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.7545 (0.9913)	Arch Loss 0.2781 (0.4627)	Arch Hard Loss 1.6151 (1.7983)	Arch Beta Loss 13.3704 (13.3565)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.7%)	
12/04 12:01:19PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2342 (1.0060)	Arch Loss 0.9742 (0.4883)	Arch Hard Loss 2.3122 (1.8246)	Arch Beta Loss 13.3805 (13.3628)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.6%)	
12/04 12:02:03PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9923 (1.0198)	Arch Loss 0.2980 (0.4881)	Arch Hard Loss 1.6370 (1.8249)	Arch Beta Loss 13.3895 (13.3678)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.4%)	
12/04 12:02:04PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 33/49] Final Prec@1 70.0440%
12/04 12:02:11PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8174	Prec@(1,5) (51.9%, 81.6%)
12/04 12:02:17PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7862	Prec@(1,5) (52.5%, 81.8%)
12/04 12:02:23PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7907	Prec@(1,5) (52.2%, 81.9%)
12/04 12:02:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7939	Prec@(1,5) (52.3%, 81.8%)
12/04 12:02:29PM searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 52.3160%
12/04 12:02:29PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 12:02:30PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.6680%
12/04 12:03:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.8119 (0.9327)	Arch Loss 0.6840 (0.4243)	Arch Hard Loss 2.0241 (1.7638)	Arch Beta Loss 13.4003 (13.3950)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.6%)	
12/04 12:04:09PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.7170 (0.9665)	Arch Loss 0.8060 (0.4519)	Arch Hard Loss 2.1471 (1.7920)	Arch Beta Loss 13.4110 (13.4004)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.1%)	
12/04 12:04:58PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1065 (0.9744)	Arch Loss 0.7789 (0.4597)	Arch Hard Loss 2.1212 (1.8003)	Arch Beta Loss 13.4232 (13.4055)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.0%)	
12/04 12:05:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0586 (0.9872)	Arch Loss 0.4902 (0.4707)	Arch Hard Loss 1.8337 (1.8118)	Arch Beta Loss 13.4353 (13.4113)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
12/04 12:05:43PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 34/49] Final Prec@1 71.0760%
12/04 12:05:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8143	Prec@(1,5) (52.6%, 81.7%)
12/04 12:05:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.8039	Prec@(1,5) (52.3%, 82.0%)
12/04 12:06:03PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7904	Prec@(1,5) (52.7%, 82.1%)
12/04 12:06:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7914	Prec@(1,5) (52.8%, 82.0%)
12/04 12:06:09PM searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 52.7440%
12/04 12:06:09PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 7])
12/04 12:06:10PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.7440%
12/04 12:06:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.0387 (0.9228)	Arch Loss 0.3957 (0.4612)	Arch Hard Loss 1.7405 (1.8054)	Arch Beta Loss 13.4478 (13.4418)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.9%)	
12/04 12:07:47PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.9890 (0.9400)	Arch Loss 0.1824 (0.4579)	Arch Hard Loss 1.5282 (1.8027)	Arch Beta Loss 13.4587 (13.4479)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.4%)	
12/04 12:08:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.1165 (0.9460)	Arch Loss 0.4769 (0.4461)	Arch Hard Loss 1.8234 (1.7913)	Arch Beta Loss 13.4655 (13.4525)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.3%)	
12/04 12:09:17PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1580 (0.9493)	Arch Loss 0.4203 (0.4549)	Arch Hard Loss 1.7679 (1.8005)	Arch Beta Loss 13.4755 (13.4564)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.3%)	
12/04 12:09:17PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 35/49] Final Prec@1 72.1560%
12/04 12:09:24PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7289	Prec@(1,5) (54.4%, 82.6%)
12/04 12:09:31PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7387	Prec@(1,5) (54.0%, 82.9%)
12/04 12:09:37PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7366	Prec@(1,5) (54.1%, 82.8%)
12/04 12:09:43PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7419	Prec@(1,5) (54.0%, 82.7%)
12/04 12:09:43PM searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 53.9760%
12/04 12:09:43PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:09:43PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.9760%
12/04 12:10:33PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8482 (0.8723)	Arch Loss 0.6581 (0.4503)	Arch Hard Loss 2.0066 (1.7984)	Arch Beta Loss 13.4850 (13.4809)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.3%)	
12/04 12:11:20PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8168 (0.8960)	Arch Loss 0.1258 (0.4448)	Arch Hard Loss 1.4756 (1.7933)	Arch Beta Loss 13.4985 (13.4857)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.7%, 95.1%)	
12/04 12:12:07PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.0367 (0.9045)	Arch Loss 0.4514 (0.4495)	Arch Hard Loss 1.8024 (1.7987)	Arch Beta Loss 13.5092 (13.4918)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.0%)	
12/04 12:12:50PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.8222 (0.9144)	Arch Loss 0.4171 (0.4487)	Arch Hard Loss 1.7689 (1.7983)	Arch Beta Loss 13.5185 (13.4968)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
12/04 12:12:51PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 36/49] Final Prec@1 73.1840%
12/04 12:12:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7775	Prec@(1,5) (53.4%, 82.5%)
12/04 12:13:04PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7523	Prec@(1,5) (53.9%, 82.7%)
12/04 12:13:10PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7738	Prec@(1,5) (53.5%, 82.4%)
12/04 12:13:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7766	Prec@(1,5) (53.3%, 82.3%)
12/04 12:13:16PM searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 53.3360%
12/04 12:13:16PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:13:16PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.9760%
12/04 12:14:06PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.7518 (0.8476)	Arch Loss 0.8160 (0.4567)	Arch Hard Loss 2.1689 (1.8092)	Arch Beta Loss 13.5291 (13.5245)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.6%)	
12/04 12:14:55PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.9280 (0.8580)	Arch Loss 0.6724 (0.4376)	Arch Hard Loss 2.0264 (1.7905)	Arch Beta Loss 13.5401 (13.5297)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.6%)	
12/04 12:15:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8456 (0.8700)	Arch Loss 0.5881 (0.4477)	Arch Hard Loss 1.9427 (1.8012)	Arch Beta Loss 13.5465 (13.5342)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.3%)	
12/04 12:16:26PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.7861 (0.8755)	Arch Loss 0.3591 (0.4477)	Arch Hard Loss 1.7144 (1.8015)	Arch Beta Loss 13.5536 (13.5381)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.2%)	
12/04 12:16:26PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 37/49] Final Prec@1 74.5920%
12/04 12:16:33PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7610	Prec@(1,5) (53.9%, 82.6%)
12/04 12:16:40PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7521	Prec@(1,5) (54.1%, 82.6%)
12/04 12:16:46PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7320	Prec@(1,5) (54.7%, 82.9%)
12/04 12:16:52PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7405	Prec@(1,5) (54.5%, 82.8%)
12/04 12:16:53PM searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 54.5280%
12/04 12:16:53PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:16:53PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5280%
12/04 12:17:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.7996 (0.8332)	Arch Loss 0.3625 (0.4159)	Arch Hard Loss 1.7184 (1.7716)	Arch Beta Loss 13.5594 (13.5569)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.8%)	
12/04 12:18:32PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8297 (0.8358)	Arch Loss 0.4742 (0.4026)	Arch Hard Loss 1.8312 (1.7587)	Arch Beta Loss 13.5698 (13.5609)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.6%)	
12/04 12:19:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.9048 (0.8435)	Arch Loss 0.3382 (0.4104)	Arch Hard Loss 1.6958 (1.7669)	Arch Beta Loss 13.5766 (13.5649)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.6%)	
12/04 12:20:06PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.5911 (0.8467)	Arch Loss 0.3435 (0.4291)	Arch Hard Loss 1.7017 (1.7859)	Arch Beta Loss 13.5816 (13.5683)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.6%)	
12/04 12:20:06PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 38/49] Final Prec@1 75.1560%
12/04 12:20:13PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7596	Prec@(1,5) (53.8%, 82.0%)
12/04 12:20:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7422	Prec@(1,5) (54.3%, 82.6%)
12/04 12:20:26PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7393	Prec@(1,5) (54.1%, 82.7%)
12/04 12:20:32PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7359	Prec@(1,5) (54.1%, 82.7%)
12/04 12:20:32PM searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 54.0960%
12/04 12:20:32PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:20:33PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5280%
12/04 12:21:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.8435 (0.7863)	Arch Loss 0.2217 (0.4276)	Arch Hard Loss 1.5805 (1.7862)	Arch Beta Loss 13.5882 (13.5859)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
12/04 12:22:11PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6539 (0.7920)	Arch Loss 0.3473 (0.4198)	Arch Hard Loss 1.7065 (1.7786)	Arch Beta Loss 13.5928 (13.5884)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
12/04 12:22:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.8508 (0.8050)	Arch Loss 0.5192 (0.4224)	Arch Hard Loss 1.8793 (1.7815)	Arch Beta Loss 13.6001 (13.5909)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.0%)	
12/04 12:23:42PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.8862 (0.8131)	Arch Loss 0.5484 (0.4198)	Arch Hard Loss 1.9091 (1.7791)	Arch Beta Loss 13.6074 (13.5937)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.8%)	
12/04 12:23:42PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 39/49] Final Prec@1 76.5240%
12/04 12:23:49PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7427	Prec@(1,5) (53.8%, 82.4%)
12/04 12:23:56PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7524	Prec@(1,5) (53.9%, 82.6%)
12/04 12:24:02PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7430	Prec@(1,5) (54.0%, 82.6%)
12/04 12:24:08PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7530	Prec@(1,5) (53.8%, 82.6%)
12/04 12:24:08PM searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 53.8480%
12/04 12:24:08PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:24:08PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.5280%
12/04 12:24:57PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.8045 (0.7657)	Arch Loss 0.6627 (0.4556)	Arch Hard Loss 2.0241 (1.8167)	Arch Beta Loss 13.6146 (13.6107)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.4%)	
12/04 12:25:45PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.9296 (0.7715)	Arch Loss 0.6350 (0.4313)	Arch Hard Loss 1.9974 (1.7928)	Arch Beta Loss 13.6237 (13.6153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.3%)	
12/04 12:26:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6438 (0.7897)	Arch Loss 0.2252 (0.4251)	Arch Hard Loss 1.5881 (1.7870)	Arch Beta Loss 13.6289 (13.6191)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.1%)	
12/04 12:27:18PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.1701 (0.7925)	Arch Loss 0.1484 (0.4074)	Arch Hard Loss 1.5119 (1.7696)	Arch Beta Loss 13.6350 (13.6221)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.2%)	
12/04 12:27:19PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 40/49] Final Prec@1 77.1400%
12/04 12:27:25PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7018	Prec@(1,5) (55.1%, 83.6%)
12/04 12:27:32PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7138	Prec@(1,5) (55.0%, 83.0%)
12/04 12:27:38PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7132	Prec@(1,5) (54.8%, 83.0%)
12/04 12:27:44PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7141	Prec@(1,5) (54.7%, 83.1%)
12/04 12:27:44PM searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 54.7440%
12/04 12:27:44PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:27:45PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7440%
12/04 12:28:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.6209 (0.7412)	Arch Loss 0.4503 (0.4009)	Arch Hard Loss 1.8141 (1.7645)	Arch Beta Loss 13.6385 (13.6366)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 97.0%)	
12/04 12:29:23PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5772 (0.7500)	Arch Loss 0.5859 (0.4131)	Arch Hard Loss 1.9502 (1.7770)	Arch Beta Loss 13.6434 (13.6389)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.6%)	
12/04 12:30:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.6055 (0.7513)	Arch Loss 0.2084 (0.4132)	Arch Hard Loss 1.5732 (1.7773)	Arch Beta Loss 13.6481 (13.6411)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.7%)	
12/04 12:30:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9990 (0.7594)	Arch Loss 0.2969 (0.4154)	Arch Hard Loss 1.6621 (1.7798)	Arch Beta Loss 13.6522 (13.6433)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.5%)	
12/04 12:30:56PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 41/49] Final Prec@1 78.1880%
12/04 12:31:03PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7290	Prec@(1,5) (53.9%, 83.4%)
12/04 12:31:10PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7421	Prec@(1,5) (53.8%, 83.1%)
12/04 12:31:16PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7324	Prec@(1,5) (54.1%, 83.2%)
12/04 12:31:22PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7302	Prec@(1,5) (54.2%, 83.1%)
12/04 12:31:22PM searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 54.1400%
12/04 12:31:22PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:31:22PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.7440%
12/04 12:32:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7879 (0.7241)	Arch Loss 0.3095 (0.4166)	Arch Hard Loss 1.6756 (1.7824)	Arch Beta Loss 13.6609 (13.6572)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.9%)	
12/04 12:33:01PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7587 (0.7263)	Arch Loss 0.3917 (0.3928)	Arch Hard Loss 1.7583 (1.7589)	Arch Beta Loss 13.6656 (13.6607)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
12/04 12:33:50PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.6121 (0.7386)	Arch Loss 0.7540 (0.3953)	Arch Hard Loss 2.1206 (1.7615)	Arch Beta Loss 13.6664 (13.6625)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.7%)	
12/04 12:34:34PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.8231 (0.7408)	Arch Loss 0.4048 (0.3935)	Arch Hard Loss 1.7720 (1.7599)	Arch Beta Loss 13.6716 (13.6640)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.7%)	
12/04 12:34:34PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 42/49] Final Prec@1 78.9600%
12/04 12:34:42PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6850	Prec@(1,5) (56.1%, 83.5%)
12/04 12:34:48PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7147	Prec@(1,5) (55.0%, 83.2%)
12/04 12:34:55PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7184	Prec@(1,5) (55.2%, 82.9%)
12/04 12:35:00PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7248	Prec@(1,5) (54.9%, 83.0%)
12/04 12:35:01PM searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 54.9440%
12/04 12:35:01PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:35:01PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.9440%
12/04 12:35:51PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.8098 (0.7177)	Arch Loss 0.5572 (0.3827)	Arch Hard Loss 1.9251 (1.7502)	Arch Beta Loss 13.6790 (13.6754)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.7%)	
12/04 12:36:40PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.6499 (0.7244)	Arch Loss 0.2155 (0.3781)	Arch Hard Loss 1.5838 (1.7459)	Arch Beta Loss 13.6826 (13.6781)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.8%)	
12/04 12:37:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7836 (0.7247)	Arch Loss 0.8515 (0.3845)	Arch Hard Loss 2.2203 (1.7526)	Arch Beta Loss 13.6885 (13.6806)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.8%)	
12/04 12:38:12PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.5828 (0.7291)	Arch Loss 0.3183 (0.3848)	Arch Hard Loss 1.6874 (1.7531)	Arch Beta Loss 13.6913 (13.6826)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.8%)	
12/04 12:38:13PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 43/49] Final Prec@1 79.3840%
12/04 12:38:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6708	Prec@(1,5) (56.0%, 84.1%)
12/04 12:38:26PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6810	Prec@(1,5) (55.8%, 83.9%)
12/04 12:38:32PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6864	Prec@(1,5) (55.7%, 83.6%)
12/04 12:38:38PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7006	Prec@(1,5) (55.5%, 83.4%)
12/04 12:38:38PM searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 55.5520%
12/04 12:38:38PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:38:39PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 12:39:29PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.7097 (0.6984)	Arch Loss 0.6838 (0.3837)	Arch Hard Loss 2.0533 (1.7531)	Arch Beta Loss 13.6955 (13.6938)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.0%)	
12/04 12:40:19PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8270 (0.6999)	Arch Loss 0.9693 (0.3777)	Arch Hard Loss 2.3393 (1.7473)	Arch Beta Loss 13.7005 (13.6963)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.0%)	
12/04 12:41:08PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6511 (0.7106)	Arch Loss 0.3874 (0.3838)	Arch Hard Loss 1.7581 (1.7537)	Arch Beta Loss 13.7071 (13.6989)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.0%)	
12/04 12:41:52PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5679 (0.7129)	Arch Loss 0.3060 (0.3799)	Arch Hard Loss 1.6771 (1.7500)	Arch Beta Loss 13.7110 (13.7013)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
12/04 12:41:53PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 44/49] Final Prec@1 80.0280%
12/04 12:42:00PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6612	Prec@(1,5) (55.7%, 84.1%)
12/04 12:42:06PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6940	Prec@(1,5) (55.5%, 83.6%)
12/04 12:42:12PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6896	Prec@(1,5) (55.5%, 83.6%)
12/04 12:42:18PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7034	Prec@(1,5) (55.2%, 83.4%)
12/04 12:42:18PM searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 55.2160%
12/04 12:42:18PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:42:18PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 12:43:08PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.5172 (0.6952)	Arch Loss -0.1882 (0.3548)	Arch Hard Loss 1.1834 (1.7261)	Arch Beta Loss 13.7153 (13.7128)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.2%)	
12/04 12:43:56PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.7831 (0.6918)	Arch Loss 0.7034 (0.3709)	Arch Hard Loss 2.0751 (1.7423)	Arch Beta Loss 13.7167 (13.7143)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.1%)	
12/04 12:44:44PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7281 (0.6939)	Arch Loss 0.5463 (0.3780)	Arch Hard Loss 1.9182 (1.7496)	Arch Beta Loss 13.7193 (13.7158)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.2%)	
12/04 12:45:28PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7303 (0.6960)	Arch Loss 0.2110 (0.3849)	Arch Hard Loss 1.5831 (1.7567)	Arch Beta Loss 13.7219 (13.7172)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.2%)	
12/04 12:45:28PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 45/49] Final Prec@1 80.6560%
12/04 12:45:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6614	Prec@(1,5) (55.9%, 83.5%)
12/04 12:45:41PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7061	Prec@(1,5) (55.2%, 83.4%)
12/04 12:45:48PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7065	Prec@(1,5) (55.3%, 83.3%)
12/04 12:45:53PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7025	Prec@(1,5) (55.1%, 83.4%)
12/04 12:45:54PM searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 55.1280%
12/04 12:45:54PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:45:54PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 12:46:44PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.9011 (0.6620)	Arch Loss 0.4320 (0.3867)	Arch Hard Loss 1.8050 (1.7592)	Arch Beta Loss 13.7294 (13.7255)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.5%)	
12/04 12:47:33PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5211 (0.6772)	Arch Loss 0.1690 (0.3709)	Arch Hard Loss 1.5422 (1.7437)	Arch Beta Loss 13.7319 (13.7284)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
12/04 12:48:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5920 (0.6811)	Arch Loss 0.3850 (0.3677)	Arch Hard Loss 1.7584 (1.7407)	Arch Beta Loss 13.7340 (13.7299)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
12/04 12:49:05PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6612 (0.6871)	Arch Loss 0.4947 (0.3717)	Arch Hard Loss 1.8684 (1.7448)	Arch Beta Loss 13.7373 (13.7311)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.3%)	
12/04 12:49:06PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 46/49] Final Prec@1 81.0360%
12/04 12:49:13PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7036	Prec@(1,5) (55.0%, 83.7%)
12/04 12:49:19PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6934	Prec@(1,5) (55.5%, 83.4%)
12/04 12:49:25PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6945	Prec@(1,5) (55.6%, 83.5%)
12/04 12:49:31PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7005	Prec@(1,5) (55.4%, 83.4%)
12/04 12:49:31PM searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 55.3920%
12/04 12:49:31PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:49:32PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 12:50:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.7263 (0.6800)	Arch Loss 0.1267 (0.3526)	Arch Hard Loss 1.5010 (1.7265)	Arch Beta Loss 13.7422 (13.7396)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.3%)	
12/04 12:51:10PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6095 (0.6713)	Arch Loss -0.0015 (0.3805)	Arch Hard Loss 1.3725 (1.7546)	Arch Beta Loss 13.7403 (13.7406)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
12/04 12:51:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5841 (0.6807)	Arch Loss 0.2540 (0.3745)	Arch Hard Loss 1.6284 (1.7486)	Arch Beta Loss 13.7435 (13.7411)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
12/04 12:52:43PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7171 (0.6865)	Arch Loss 0.4803 (0.3719)	Arch Hard Loss 1.8552 (1.7461)	Arch Beta Loss 13.7485 (13.7422)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.2%)	
12/04 12:52:43PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 47/49] Final Prec@1 81.0720%
12/04 12:52:50PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6783	Prec@(1,5) (55.7%, 83.6%)
12/04 12:52:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6714	Prec@(1,5) (55.8%, 83.7%)
12/04 12:53:03PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6835	Prec@(1,5) (55.5%, 83.5%)
12/04 12:53:09PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6847	Prec@(1,5) (55.6%, 83.6%)
12/04 12:53:09PM searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 55.5480%
12/04 12:53:09PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:53:09PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 12:53:59PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6436 (0.6619)	Arch Loss 0.4463 (0.3402)	Arch Hard Loss 1.8216 (1.7152)	Arch Beta Loss 13.7535 (13.7502)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.7%)	
12/04 12:54:48PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.7018 (0.6683)	Arch Loss 0.7913 (0.3744)	Arch Hard Loss 2.1671 (1.7497)	Arch Beta Loss 13.7575 (13.7527)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
12/04 12:55:37PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.8083 (0.6801)	Arch Loss 0.2593 (0.3711)	Arch Hard Loss 1.6352 (1.7465)	Arch Beta Loss 13.7589 (13.7544)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
12/04 12:56:21PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6515 (0.6824)	Arch Loss 0.4975 (0.3671)	Arch Hard Loss 1.8738 (1.7427)	Arch Beta Loss 13.7631 (13.7560)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.3%)	
12/04 12:56:22PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 48/49] Final Prec@1 81.1360%
12/04 12:56:29PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7072	Prec@(1,5) (54.8%, 83.4%)
12/04 12:56:35PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6932	Prec@(1,5) (55.3%, 83.5%)
12/04 12:56:42PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6826	Prec@(1,5) (55.6%, 83.9%)
12/04 12:56:47PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6864	Prec@(1,5) (55.4%, 83.8%)
12/04 12:56:48PM searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 55.4000%
12/04 12:56:48PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 12:56:48PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 12:57:38PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.5649 (0.6730)	Arch Loss 0.4334 (0.3641)	Arch Hard Loss 1.8099 (1.7405)	Arch Beta Loss 13.7648 (13.7639)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
12/04 12:58:27PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4780 (0.6624)	Arch Loss 0.3911 (0.3658)	Arch Hard Loss 1.7678 (1.7423)	Arch Beta Loss 13.7665 (13.7652)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.6%)	
12/04 12:59:16PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5254 (0.6691)	Arch Loss 0.3076 (0.3660)	Arch Hard Loss 1.6847 (1.7427)	Arch Beta Loss 13.7711 (13.7665)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.5%)	
12/04 01:00:00PM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.7218 (0.6753)	Arch Loss 0.1112 (0.3694)	Arch Hard Loss 1.4888 (1.7462)	Arch Beta Loss 13.7753 (13.7680)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.4%)	
12/04 01:00:01PM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 49/49] Final Prec@1 81.7280%
12/04 01:00:08PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6788	Prec@(1,5) (55.1%, 83.5%)
12/04 01:00:14PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6877	Prec@(1,5) (55.2%, 83.6%)
12/04 01:00:21PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6968	Prec@(1,5) (55.2%, 83.4%)
12/04 01:00:27PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6877	Prec@(1,5) (55.5%, 83.5%)
12/04 01:00:27PM searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 55.5320%
12/04 01:00:27PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
12/04 01:00:27PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5520%
12/04 01:00:27PM trainer_runner.py:110 [INFO] Final best Prec@1 = 55.5520%
12/04 01:00:27PM trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[5, 6])
