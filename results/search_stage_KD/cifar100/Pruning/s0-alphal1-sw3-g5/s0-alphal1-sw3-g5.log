11/15 12:12:55PM parser.py:28 [INFO] 
11/15 12:12:55PM parser.py:29 [INFO] Parameters:
11/15 12:12:55PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g5/DAG
11/15 12:12:55PM parser.py:31 [INFO] T=10.0
11/15 12:12:55PM parser.py:31 [INFO] ADVANCED=1
11/15 12:12:55PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/15 12:12:55PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/15 12:12:55PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/15 12:12:55PM parser.py:31 [INFO] BATCH_SIZE=64
11/15 12:12:55PM parser.py:31 [INFO] CASCADE=0
11/15 12:12:55PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/15 12:12:55PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/15 12:12:55PM parser.py:31 [INFO] DATA_PATH=../data/
11/15 12:12:55PM parser.py:31 [INFO] DATASET=cifar100
11/15 12:12:55PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/15 12:12:55PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/15 12:12:55PM parser.py:31 [INFO] DISCRETE=0
11/15 12:12:55PM parser.py:31 [INFO] EPOCHS=50
11/15 12:12:55PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/15 12:12:55PM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g5
11/15 12:12:55PM parser.py:31 [INFO] FINAL_L=5.0
11/15 12:12:55PM parser.py:31 [INFO] G=5.0
11/15 12:12:55PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/15 12:12:55PM parser.py:31 [INFO] GPUS=[0]
11/15 12:12:55PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/15 12:12:55PM parser.py:31 [INFO] INIT_CHANNELS=16
11/15 12:12:55PM parser.py:31 [INFO] L=5.0
11/15 12:12:55PM parser.py:31 [INFO] LAYERS=32
11/15 12:12:55PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/15 12:12:55PM parser.py:31 [INFO] NAME=Pruning
11/15 12:12:55PM parser.py:31 [INFO] NONKD=1
11/15 12:12:55PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g5
11/15 12:12:55PM parser.py:31 [INFO] PCDARTS=0
11/15 12:12:55PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g5/plots
11/15 12:12:55PM parser.py:31 [INFO] PRINT_FREQ=100
11/15 12:12:55PM parser.py:31 [INFO] RESET=0
11/15 12:12:55PM parser.py:31 [INFO] RESUME_PATH=None
11/15 12:12:55PM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g5
11/15 12:12:55PM parser.py:31 [INFO] SEED=0
11/15 12:12:55PM parser.py:31 [INFO] SHARE_STAGE=0
11/15 12:12:55PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/15 12:12:55PM parser.py:31 [INFO] SPEC_CELL=1
11/15 12:12:55PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/15 12:12:55PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/15 12:12:55PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/15 12:12:55PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/15 12:12:55PM parser.py:31 [INFO] TYPE=ArchKD
11/15 12:12:55PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/15 12:12:55PM parser.py:31 [INFO] W_LR=0.025
11/15 12:12:55PM parser.py:31 [INFO] W_LR_MIN=0.001
11/15 12:12:55PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/15 12:12:55PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/15 12:12:55PM parser.py:31 [INFO] WORKERS=4
11/15 12:12:55PM parser.py:32 [INFO] 
11/15 12:12:57PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/15 12:12:57PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/15 12:13:43PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6706 (4.7077)	Arch Loss 4.4122 (4.7687)	Arch Hard Loss 4.3563 (4.7093)	Arch Alpha Loss 0.0112 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.4%, 6.6%)	
11/15 12:14:27PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2540 (4.5820)	Arch Loss 4.4190 (4.6368)	Arch Hard Loss 4.3629 (4.5800)	Arch Alpha Loss 0.0112 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 8.9%)	
11/15 12:15:11PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2683 (4.4866)	Arch Loss 4.4406 (4.5385)	Arch Hard Loss 4.3838 (4.4826)	Arch Alpha Loss 0.0114 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.5%, 11.2%)	
11/15 12:15:50PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2524 (4.4300)	Arch Loss 4.0517 (4.4799)	Arch Hard Loss 3.9951 (4.4244)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 12.5%)	
11/15 12:15:51PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 2.8160%
11/15 12:15:58PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.2153	Prec@(1,5) (4.2%, 19.4%)
11/15 12:16:05PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.2047	Prec@(1,5) (4.3%, 19.7%)
11/15 12:16:11PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.2175	Prec@(1,5) (4.2%, 19.3%)
11/15 12:16:17PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.2163	Prec@(1,5) (4.2%, 19.7%)
11/15 12:16:17PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 4.2440%
11/15 12:16:17PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 12:16:18PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 4.2440%
11/15 12:17:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.1625 (4.1393)	Arch Loss 4.2896 (4.1894)	Arch Hard Loss 4.2379 (4.1353)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.9%, 20.2%)	
11/15 12:17:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.0857 (4.1035)	Arch Loss 3.9851 (4.1620)	Arch Hard Loss 3.9329 (4.1078)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.3%, 21.4%)	
11/15 12:18:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9618 (4.0756)	Arch Loss 3.8497 (4.1291)	Arch Hard Loss 3.7957 (4.0748)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.6%, 22.3%)	
11/15 12:19:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8608 (4.0551)	Arch Loss 3.8505 (4.0968)	Arch Hard Loss 3.7981 (4.0425)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.9%, 22.9%)	
11/15 12:19:08午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 5.9360%
11/15 12:19:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.8709	Prec@(1,5) (8.3%, 29.0%)
11/15 12:19:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.8955	Prec@(1,5) (8.5%, 28.5%)
11/15 12:19:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.8912	Prec@(1,5) (8.5%, 28.8%)
11/15 12:19:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.8936	Prec@(1,5) (8.5%, 28.6%)
11/15 12:19:35午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 8.4680%
11/15 12:19:35午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/15 12:19:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.4680%
11/15 12:20:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8205 (3.8840)	Arch Loss 4.2651 (3.9708)	Arch Hard Loss 4.2079 (3.9166)	Arch Alpha Loss 0.0114 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.7%, 28.9%)	
11/15 12:21:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8542 (3.8792)	Arch Loss 3.9052 (3.9253)	Arch Hard Loss 3.8481 (3.8710)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.8%, 29.4%)	
11/15 12:21:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.9294 (3.8672)	Arch Loss 4.0920 (3.9070)	Arch Hard Loss 4.0356 (3.8527)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.9%, 29.8%)	
11/15 12:22:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.6649 (3.8514)	Arch Loss 3.7282 (3.8898)	Arch Hard Loss 3.6721 (3.8355)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (9.3%, 30.3%)	
11/15 12:22:27午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 9.2440%
11/15 12:22:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.7774	Prec@(1,5) (9.2%, 32.2%)
11/15 12:22:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.7709	Prec@(1,5) (9.7%, 32.5%)
11/15 12:22:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.7682	Prec@(1,5) (9.8%, 32.5%)
11/15 12:22:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.7643	Prec@(1,5) (9.9%, 32.7%)
11/15 12:22:53午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.8800%
11/15 12:22:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/15 12:22:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.8800%
11/15 12:23:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.6529 (3.7536)	Arch Loss 3.6725 (3.8112)	Arch Hard Loss 3.6197 (3.7567)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.2%, 33.1%)	
11/15 12:24:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7201 (3.7434)	Arch Loss 3.6193 (3.7990)	Arch Hard Loss 3.5671 (3.7444)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.1%, 33.3%)	
11/15 12:25:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.6301 (3.7313)	Arch Loss 3.8370 (3.7818)	Arch Hard Loss 3.7847 (3.7271)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.2%, 33.8%)	
11/15 12:25:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6772 (3.7251)	Arch Loss 3.7854 (3.7671)	Arch Hard Loss 3.7308 (3.7123)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.2%, 34.2%)	
11/15 12:25:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 11.2440%
11/15 12:25:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.6603	Prec@(1,5) (12.5%, 36.6%)
11/15 12:26:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.6552	Prec@(1,5) (12.3%, 37.0%)
11/15 12:26:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.6489	Prec@(1,5) (12.2%, 36.9%)
11/15 12:26:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.6496	Prec@(1,5) (12.4%, 37.2%)
11/15 12:26:12午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 12.3600%
11/15 12:26:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/15 12:26:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.3600%
11/15 12:26:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.6161 (3.6197)	Arch Loss 3.8487 (3.6817)	Arch Hard Loss 3.7915 (3.6265)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.2%, 37.2%)	
11/15 12:27:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.7803 (3.6193)	Arch Loss 3.7448 (3.6733)	Arch Hard Loss 3.6879 (3.6180)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.3%, 37.2%)	
11/15 12:28:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.4224 (3.6059)	Arch Loss 3.2250 (3.6577)	Arch Hard Loss 3.1679 (3.6025)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.6%, 37.7%)	
11/15 12:29:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.8073 (3.5952)	Arch Loss 3.7325 (3.6536)	Arch Hard Loss 3.6759 (3.5983)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.8%, 38.1%)	
11/15 12:29:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.8600%
11/15 12:29:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5176	Prec@(1,5) (15.2%, 40.3%)
11/15 12:29:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5248	Prec@(1,5) (15.3%, 40.7%)
11/15 12:29:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5345	Prec@(1,5) (15.1%, 40.7%)
11/15 12:29:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5341	Prec@(1,5) (15.0%, 40.7%)
11/15 12:29:32午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.9720%
11/15 12:29:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/15 12:29:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.9720%
11/15 12:30:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.7674 (3.4979)	Arch Loss 3.4684 (3.5698)	Arch Hard Loss 3.4148 (3.5146)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (15.1%, 41.5%)	
11/15 12:31:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.6605 (3.5076)	Arch Loss 3.7181 (3.5623)	Arch Hard Loss 3.6643 (3.5072)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.0%, 41.0%)	
11/15 12:31:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.3273 (3.4953)	Arch Loss 3.9312 (3.5521)	Arch Hard Loss 3.8767 (3.4971)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.4%)	
11/15 12:32:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.4554 (3.4894)	Arch Loss 3.5909 (3.5504)	Arch Hard Loss 3.5387 (3.4955)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.5%)	
11/15 12:32:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 15.2440%
11/15 12:32:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.5252	Prec@(1,5) (15.1%, 41.4%)
11/15 12:32:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.5344	Prec@(1,5) (14.7%, 41.0%)
11/15 12:32:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.5249	Prec@(1,5) (14.9%, 41.3%)
11/15 12:32:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.5300	Prec@(1,5) (14.8%, 41.3%)
11/15 12:32:50午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 14.7640%
11/15 12:32:50午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 12:32:50午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.9720%
11/15 12:33:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.1140 (3.4061)	Arch Loss 3.5384 (3.5115)	Arch Hard Loss 3.4833 (3.4566)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.9%, 43.9%)	
11/15 12:34:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.3331 (3.4092)	Arch Loss 3.8283 (3.5059)	Arch Hard Loss 3.7736 (3.4511)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.7%, 43.9%)	
11/15 12:35:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.3755 (3.3985)	Arch Loss 3.4342 (3.4789)	Arch Hard Loss 3.3792 (3.4240)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 44.1%)	
11/15 12:35:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.5641 (3.3938)	Arch Loss 3.5226 (3.4684)	Arch Hard Loss 3.4635 (3.4135)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 44.3%)	
11/15 12:35:41午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.1320%
11/15 12:35:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.3593	Prec@(1,5) (17.2%, 44.4%)
11/15 12:35:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3771	Prec@(1,5) (17.7%, 44.8%)
11/15 12:36:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.3791	Prec@(1,5) (17.6%, 44.7%)
11/15 12:36:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.3793	Prec@(1,5) (17.6%, 44.7%)
11/15 12:36:07午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 17.6280%
11/15 12:36:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 12:36:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.6280%
11/15 12:36:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.1734 (3.3024)	Arch Loss 3.3990 (3.4005)	Arch Hard Loss 3.3442 (3.3453)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 47.4%)	
11/15 12:37:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.5597 (3.3011)	Arch Loss 3.5143 (3.4093)	Arch Hard Loss 3.4618 (3.3540)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.1%, 47.1%)	
11/15 12:38:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.2915 (3.2859)	Arch Loss 3.3067 (3.3837)	Arch Hard Loss 3.2545 (3.3283)	Arch Alpha Loss 0.0104 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 47.5%)	
11/15 12:38:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.3168 (3.2747)	Arch Loss 3.4581 (3.3745)	Arch Hard Loss 3.4063 (3.3191)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.8%, 47.8%)	
11/15 12:39:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 19.7680%
11/15 12:39:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.2897	Prec@(1,5) (19.7%, 47.2%)
11/15 12:39:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.2734	Prec@(1,5) (19.6%, 47.7%)
11/15 12:39:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.2639	Prec@(1,5) (19.5%, 48.0%)
11/15 12:39:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.2632	Prec@(1,5) (19.5%, 48.3%)
11/15 12:39:26午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 19.4520%
11/15 12:39:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 12:39:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.4520%
11/15 12:40:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.2776 (3.1889)	Arch Loss 3.5535 (3.3143)	Arch Hard Loss 3.4957 (3.2590)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.5%, 50.1%)	
11/15 12:40:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.1768 (3.2042)	Arch Loss 2.8512 (3.3021)	Arch Hard Loss 2.7925 (3.2469)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.8%)	
11/15 12:41:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.3988 (3.2038)	Arch Loss 3.3664 (3.3086)	Arch Hard Loss 3.3076 (3.2536)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.6%)	
11/15 12:42:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.1198 (3.1946)	Arch Loss 3.5649 (3.2938)	Arch Hard Loss 3.5083 (3.2387)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.8%, 49.9%)	
11/15 12:42:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 20.7800%
11/15 12:42:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1885	Prec@(1,5) (21.4%, 50.2%)
11/15 12:42:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1937	Prec@(1,5) (21.2%, 50.2%)
11/15 12:42:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1919	Prec@(1,5) (21.3%, 50.2%)
11/15 12:42:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1913	Prec@(1,5) (21.2%, 50.3%)
11/15 12:42:44午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 21.1840%
11/15 12:42:44午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 12:42:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.1840%
11/15 12:43:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.9012 (3.0980)	Arch Loss 3.2103 (3.2366)	Arch Hard Loss 3.1574 (3.1817)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 52.2%)	
11/15 12:44:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.1651 (3.0886)	Arch Loss 3.1298 (3.2357)	Arch Hard Loss 3.0763 (3.1809)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 52.4%)	
11/15 12:44:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.5247 (3.0902)	Arch Loss 3.3611 (3.2213)	Arch Hard Loss 3.3073 (3.1665)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 52.5%)	
11/15 12:45:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.8771 (3.0977)	Arch Loss 2.9256 (3.2093)	Arch Hard Loss 2.8708 (3.1544)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 52.2%)	
11/15 12:45:37午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 22.8000%
11/15 12:45:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.1283	Prec@(1,5) (22.0%, 51.7%)
11/15 12:45:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.1105	Prec@(1,5) (22.4%, 52.2%)
11/15 12:45:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.1321	Prec@(1,5) (22.4%, 51.5%)
11/15 12:46:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.1389	Prec@(1,5) (22.4%, 51.1%)
11/15 12:46:04午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 22.3680%
11/15 12:46:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 12:46:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.3680%
11/15 12:46:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 3.0050 (2.9852)	Arch Loss 3.0731 (3.0999)	Arch Hard Loss 3.0191 (3.0446)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.5%, 55.5%)	
11/15 12:47:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 3.0768 (3.0071)	Arch Loss 3.3770 (3.1393)	Arch Hard Loss 3.3223 (3.0840)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.4%, 55.0%)	
11/15 12:48:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.7599 (3.0072)	Arch Loss 2.8714 (3.1411)	Arch Hard Loss 2.8157 (3.0858)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.6%, 54.8%)	
11/15 12:48:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.9169 (2.9985)	Arch Loss 3.3439 (3.1325)	Arch Hard Loss 3.2848 (3.0771)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.8%, 54.9%)	
11/15 12:48:55午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 24.7800%
11/15 12:49:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.1673	Prec@(1,5) (22.3%, 52.4%)
11/15 12:49:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.1343	Prec@(1,5) (22.9%, 53.0%)
11/15 12:49:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 3.1317	Prec@(1,5) (23.0%, 52.9%)
11/15 12:49:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 3.1299	Prec@(1,5) (22.9%, 53.1%)
11/15 12:49:21午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 22.9360%
11/15 12:49:21午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/15 12:49:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.9360%
11/15 12:50:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.8583 (2.9059)	Arch Loss 3.1664 (3.0877)	Arch Hard Loss 3.1115 (3.0323)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.2%, 57.6%)	
11/15 12:50:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.8767 (2.9067)	Arch Loss 2.5568 (3.0664)	Arch Hard Loss 2.5030 (3.0112)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.5%)	
11/15 12:51:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 3.0030 (2.9138)	Arch Loss 3.0175 (3.0507)	Arch Hard Loss 2.9646 (2.9957)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.3%)	
11/15 12:52:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 3.0133 (2.9088)	Arch Loss 2.4495 (3.0466)	Arch Hard Loss 2.3982 (2.9918)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.3%)	
11/15 12:52:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 26.8800%
11/15 12:52:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.9725	Prec@(1,5) (26.1%, 56.5%)
11/15 12:52:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.9758	Prec@(1,5) (25.9%, 56.1%)
11/15 12:52:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9697	Prec@(1,5) (25.7%, 56.4%)
11/15 12:52:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.9644	Prec@(1,5) (25.8%, 56.5%)
11/15 12:52:39午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 25.7640%
11/15 12:52:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 12:52:39午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.7640%
11/15 12:53:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4963 (2.8238)	Arch Loss 3.0124 (2.9896)	Arch Hard Loss 2.9553 (2.9353)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.9%, 58.6%)	
11/15 12:54:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.7409 (2.8307)	Arch Loss 2.6561 (2.9962)	Arch Hard Loss 2.6015 (2.9421)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.9%, 59.0%)	
11/15 12:54:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.8589 (2.8320)	Arch Loss 3.0790 (2.9862)	Arch Hard Loss 3.0242 (2.9323)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.8%, 59.2%)	
11/15 12:55:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 3.1556 (2.8277)	Arch Loss 2.9866 (2.9828)	Arch Hard Loss 2.9332 (2.9289)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 59.4%)	
11/15 12:55:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 28.0320%
11/15 12:55:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.9213	Prec@(1,5) (26.7%, 57.6%)
11/15 12:55:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.9216	Prec@(1,5) (26.7%, 57.3%)
11/15 12:55:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.9278	Prec@(1,5) (26.6%, 57.1%)
11/15 12:55:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.9314	Prec@(1,5) (26.5%, 57.1%)
11/15 12:55:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 26.4760%
11/15 12:55:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 12:55:57午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.4760%
11/15 12:56:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.4818 (2.7567)	Arch Loss 2.9819 (2.9618)	Arch Hard Loss 2.9288 (2.9080)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 60.8%)	
11/15 12:57:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 3.0863 (2.7643)	Arch Loss 3.0099 (2.9507)	Arch Hard Loss 2.9571 (2.8967)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 60.6%)	
11/15 12:58:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.7927 (2.7499)	Arch Loss 2.3856 (2.9407)	Arch Hard Loss 2.3322 (2.8868)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 60.9%)	
11/15 12:58:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.3668 (2.7521)	Arch Loss 3.0693 (2.9338)	Arch Hard Loss 3.0139 (2.8800)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.0%, 60.9%)	
11/15 12:58:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 28.9920%
11/15 12:58:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.8245	Prec@(1,5) (28.7%, 60.2%)
11/15 12:59:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8282	Prec@(1,5) (28.8%, 60.0%)
11/15 12:59:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.8350	Prec@(1,5) (28.5%, 59.8%)
11/15 12:59:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.8390	Prec@(1,5) (28.5%, 59.6%)
11/15 12:59:14午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 28.4680%
11/15 12:59:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/15 12:59:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.4680%
11/15 12:59:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.6477 (2.6614)	Arch Loss 2.8442 (2.8893)	Arch Hard Loss 2.7917 (2.8357)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.6%, 62.8%)	
11/15 01:00:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.7653 (2.6643)	Arch Loss 2.8446 (2.8805)	Arch Hard Loss 2.7938 (2.8268)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 62.8%)	
11/15 01:01:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.7548 (2.6719)	Arch Loss 2.5602 (2.8693)	Arch Hard Loss 2.5090 (2.8154)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.0%)	
11/15 01:02:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.7107 (2.6709)	Arch Loss 2.8388 (2.8669)	Arch Hard Loss 2.7839 (2.8130)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.1%)	
11/15 01:02:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 30.9560%
11/15 01:02:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.6718	Prec@(1,5) (30.3%, 63.0%)
11/15 01:02:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.6835	Prec@(1,5) (30.7%, 62.7%)
11/15 01:02:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.6901	Prec@(1,5) (30.7%, 62.8%)
11/15 01:02:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.7001	Prec@(1,5) (30.7%, 62.6%)
11/15 01:02:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 30.7240%
11/15 01:02:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:02:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.7240%
11/15 01:03:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.3178 (2.5574)	Arch Loss 2.8125 (2.8088)	Arch Hard Loss 2.7572 (2.7541)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.6%, 65.9%)	
11/15 01:04:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.1811 (2.5858)	Arch Loss 2.8411 (2.8114)	Arch Hard Loss 2.7857 (2.7566)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.1%, 65.0%)	
11/15 01:04:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.4979 (2.5927)	Arch Loss 3.1955 (2.8093)	Arch Hard Loss 3.1404 (2.7544)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 64.8%)	
11/15 01:05:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.3107 (2.6007)	Arch Loss 2.6589 (2.8052)	Arch Hard Loss 2.6047 (2.7504)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 64.5%)	
11/15 01:05:25午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 32.3960%
11/15 01:05:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.7648	Prec@(1,5) (30.3%, 61.3%)
11/15 01:05:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.7373	Prec@(1,5) (30.6%, 62.1%)
11/15 01:05:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.7346	Prec@(1,5) (30.5%, 62.3%)
11/15 01:05:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.7297	Prec@(1,5) (30.6%, 62.4%)
11/15 01:05:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 30.5800%
11/15 01:05:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:05:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.7240%
11/15 01:06:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.4173 (2.4755)	Arch Loss 2.9476 (2.7682)	Arch Hard Loss 2.8916 (2.7137)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.7%, 67.5%)	
11/15 01:07:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.3933 (2.5101)	Arch Loss 2.8002 (2.7730)	Arch Hard Loss 2.7413 (2.7186)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.9%)	
11/15 01:08:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.8848 (2.5167)	Arch Loss 2.5024 (2.7602)	Arch Hard Loss 2.4439 (2.7055)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.8%, 66.9%)	
11/15 01:08:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.5133 (2.5227)	Arch Loss 2.7952 (2.7540)	Arch Hard Loss 2.7414 (2.6993)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.7%)	
11/15 01:08:43午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 33.8560%
11/15 01:08:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.6287	Prec@(1,5) (33.2%, 63.9%)
11/15 01:08:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.6609	Prec@(1,5) (32.6%, 63.3%)
11/15 01:09:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.6660	Prec@(1,5) (32.5%, 63.3%)
11/15 01:09:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.6671	Prec@(1,5) (32.3%, 63.4%)
11/15 01:09:09午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 32.3160%
11/15 01:09:09午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:09:10午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.3160%
11/15 01:09:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.3455 (2.4819)	Arch Loss 2.8686 (2.7429)	Arch Hard Loss 2.8134 (2.6884)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.7%, 67.4%)	
11/15 01:10:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.1758 (2.4662)	Arch Loss 2.8249 (2.7211)	Arch Hard Loss 2.7701 (2.6662)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 67.8%)	
11/15 01:11:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.3045 (2.4559)	Arch Loss 2.5977 (2.7230)	Arch Hard Loss 2.5438 (2.6678)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 67.9%)	
11/15 01:12:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.1243 (2.4559)	Arch Loss 2.7975 (2.7120)	Arch Hard Loss 2.7431 (2.6567)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 67.9%)	
11/15 01:12:02午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 35.6920%
11/15 01:12:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.6138	Prec@(1,5) (33.6%, 64.8%)
11/15 01:12:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.6069	Prec@(1,5) (33.5%, 65.4%)
11/15 01:12:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.6224	Prec@(1,5) (33.2%, 64.9%)
11/15 01:12:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.6286	Prec@(1,5) (32.9%, 64.7%)
11/15 01:12:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 32.8880%
11/15 01:12:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:12:29午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.8880%
11/15 01:13:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.4428 (2.3966)	Arch Loss 2.6376 (2.7020)	Arch Hard Loss 2.5844 (2.6476)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.5%)	
11/15 01:13:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.6467 (2.3856)	Arch Loss 2.4133 (2.6950)	Arch Hard Loss 2.3596 (2.6406)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.9%, 69.5%)	
11/15 01:14:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.6039 (2.3852)	Arch Loss 2.3658 (2.6712)	Arch Hard Loss 2.3108 (2.6168)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.6%)	
11/15 01:15:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.2019 (2.3906)	Arch Loss 2.1985 (2.6567)	Arch Hard Loss 2.1417 (2.6022)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.9%, 69.4%)	
11/15 01:15:22午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 36.9240%
11/15 01:15:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5560	Prec@(1,5) (34.6%, 66.3%)
11/15 01:15:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5788	Prec@(1,5) (33.9%, 65.9%)
11/15 01:15:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5745	Prec@(1,5) (33.9%, 65.8%)
11/15 01:15:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5712	Prec@(1,5) (33.9%, 65.8%)
11/15 01:15:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 33.8760%
11/15 01:15:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:15:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.8760%
11/15 01:16:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.1328 (2.2548)	Arch Loss 2.7412 (2.6333)	Arch Hard Loss 2.6862 (2.5783)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.0%, 72.1%)	
11/15 01:17:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.9176 (2.2943)	Arch Loss 2.5971 (2.6146)	Arch Hard Loss 2.5424 (2.5594)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.2%)	
11/15 01:18:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.1798 (2.3122)	Arch Loss 2.3927 (2.6099)	Arch Hard Loss 2.3384 (2.5546)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 70.9%)	
11/15 01:18:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.4558 (2.3127)	Arch Loss 2.2001 (2.6141)	Arch Hard Loss 2.1447 (2.5589)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.0%)	
11/15 01:18:40午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 38.2760%
11/15 01:18:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.5606	Prec@(1,5) (34.3%, 66.9%)
11/15 01:18:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.5576	Prec@(1,5) (34.0%, 66.7%)
11/15 01:19:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.5544	Prec@(1,5) (34.3%, 66.5%)
11/15 01:19:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.5464	Prec@(1,5) (34.5%, 66.7%)
11/15 01:19:06午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 34.5200%
11/15 01:19:06午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:19:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5200%
11/15 01:19:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.8772 (2.2093)	Arch Loss 2.7133 (2.5496)	Arch Hard Loss 2.6607 (2.4945)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 72.8%)	
11/15 01:20:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.9326 (2.2411)	Arch Loss 2.5274 (2.5653)	Arch Hard Loss 2.4745 (2.5101)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.5%)	
11/15 01:21:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.3819 (2.2470)	Arch Loss 2.4115 (2.5771)	Arch Hard Loss 2.3611 (2.5221)	Arch Alpha Loss 0.0101 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.4%)	
11/15 01:21:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.9262 (2.2522)	Arch Loss 2.5437 (2.5762)	Arch Hard Loss 2.4925 (2.5215)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.3%)	
11/15 01:21:57午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 39.7080%
11/15 01:22:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.4716	Prec@(1,5) (36.1%, 67.8%)
11/15 01:22:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.5052	Prec@(1,5) (35.4%, 67.0%)
11/15 01:22:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.5073	Prec@(1,5) (35.5%, 67.2%)
11/15 01:22:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.5071	Prec@(1,5) (35.4%, 67.1%)
11/15 01:22:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 35.4000%
11/15 01:22:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:22:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.4000%
11/15 01:23:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.3749 (2.1312)	Arch Loss 2.5269 (2.5695)	Arch Hard Loss 2.4705 (2.5154)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 74.6%)	
11/15 01:23:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.4008 (2.1630)	Arch Loss 2.7864 (2.5718)	Arch Hard Loss 2.7289 (2.5175)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 74.3%)	
11/15 01:24:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.9678 (2.1779)	Arch Loss 2.5686 (2.5587)	Arch Hard Loss 2.5118 (2.5043)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.3%, 74.1%)	
11/15 01:25:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.3822 (2.1825)	Arch Loss 2.6454 (2.5482)	Arch Hard Loss 2.5883 (2.4937)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 74.1%)	
11/15 01:25:15午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 41.1480%
11/15 01:25:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.5064	Prec@(1,5) (35.0%, 67.1%)
11/15 01:25:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4703	Prec@(1,5) (35.9%, 68.4%)
11/15 01:25:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4597	Prec@(1,5) (36.4%, 68.6%)
11/15 01:25:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4546	Prec@(1,5) (36.5%, 68.8%)
11/15 01:25:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 36.4760%
11/15 01:25:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:25:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.4760%
11/15 01:26:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 2.0428 (2.0907)	Arch Loss 2.5137 (2.5111)	Arch Hard Loss 2.4607 (2.4557)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.7%)	
11/15 01:27:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.9330 (2.1082)	Arch Loss 2.8185 (2.5091)	Arch Hard Loss 2.7643 (2.4537)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.5%)	
11/15 01:27:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 2.1040 (2.1207)	Arch Loss 2.4679 (2.5070)	Arch Hard Loss 2.4132 (2.4516)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 75.3%)	
11/15 01:28:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7016 (2.1253)	Arch Loss 2.3001 (2.4924)	Arch Hard Loss 2.2466 (2.4369)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 75.2%)	
11/15 01:28:32午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 42.5320%
11/15 01:28:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.4161	Prec@(1,5) (37.8%, 69.4%)
11/15 01:28:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.3877	Prec@(1,5) (38.3%, 70.0%)
11/15 01:28:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.3888	Prec@(1,5) (38.0%, 70.0%)
11/15 01:28:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.3897	Prec@(1,5) (37.9%, 69.9%)
11/15 01:28:59午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 37.9080%
11/15 01:28:59午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:28:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.9080%
11/15 01:29:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.8978 (1.9844)	Arch Loss 2.8064 (2.4906)	Arch Hard Loss 2.7517 (2.4352)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.1%)	
11/15 01:30:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 2.0801 (2.0252)	Arch Loss 1.9091 (2.4647)	Arch Hard Loss 1.8535 (2.4094)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 76.9%)	
11/15 01:31:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.1718 (2.0474)	Arch Loss 2.3689 (2.4698)	Arch Hard Loss 2.3135 (2.4145)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.6%)	
11/15 01:31:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.1188 (2.0560)	Arch Loss 2.5208 (2.4656)	Arch Hard Loss 2.4625 (2.4103)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.1%, 76.3%)	
11/15 01:31:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 44.0640%
11/15 01:31:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.4188	Prec@(1,5) (38.3%, 69.7%)
11/15 01:32:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.4048	Prec@(1,5) (38.5%, 69.7%)
11/15 01:32:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.4028	Prec@(1,5) (38.4%, 69.9%)
11/15 01:32:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.4050	Prec@(1,5) (38.3%, 69.7%)
11/15 01:32:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 38.2600%
11/15 01:32:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:32:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2600%
11/15 01:33:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.9724 (1.9402)	Arch Loss 2.2708 (2.4638)	Arch Hard Loss 2.2183 (2.4085)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 78.7%)	
11/15 01:33:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 2.4385 (1.9665)	Arch Loss 2.1701 (2.4383)	Arch Hard Loss 2.1184 (2.3831)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 78.2%)	
11/15 01:34:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.8298 (1.9818)	Arch Loss 2.1839 (2.4423)	Arch Hard Loss 2.1306 (2.3872)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.9%)	
11/15 01:35:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.1941 (1.9937)	Arch Loss 2.4082 (2.4418)	Arch Hard Loss 2.3544 (2.3866)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 77.7%)	
11/15 01:35:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 45.4480%
11/15 01:35:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.3574	Prec@(1,5) (38.2%, 70.2%)
11/15 01:35:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.3605	Prec@(1,5) (38.3%, 70.3%)
11/15 01:35:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.3757	Prec@(1,5) (38.4%, 70.3%)
11/15 01:35:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.3729	Prec@(1,5) (38.5%, 70.3%)
11/15 01:35:38午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 38.5440%
11/15 01:35:38午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:35:38午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.5440%
11/15 01:36:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.9054 (1.8926)	Arch Loss 2.0755 (2.4104)	Arch Hard Loss 2.0200 (2.3554)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.4%)	
11/15 01:37:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 2.0724 (1.9039)	Arch Loss 2.7925 (2.4201)	Arch Hard Loss 2.7369 (2.3652)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.3%, 79.2%)	
11/15 01:37:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.6986 (1.9197)	Arch Loss 2.6426 (2.4155)	Arch Hard Loss 2.5885 (2.3604)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.0%)	
11/15 01:38:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 2.0721 (1.9373)	Arch Loss 2.7051 (2.4129)	Arch Hard Loss 2.6528 (2.3579)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.6%, 78.6%)	
11/15 01:38:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 46.5720%
11/15 01:38:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.3105	Prec@(1,5) (41.0%, 71.5%)
11/15 01:38:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.3440	Prec@(1,5) (40.1%, 71.2%)
11/15 01:38:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.3403	Prec@(1,5) (39.8%, 71.4%)
11/15 01:38:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.3289	Prec@(1,5) (39.9%, 71.7%)
11/15 01:38:55午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 39.8960%
11/15 01:38:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:38:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8960%
11/15 01:39:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.4015 (1.8473)	Arch Loss 2.9702 (2.3890)	Arch Hard Loss 2.9128 (2.3345)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.3%)	
11/15 01:40:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.6267 (1.8608)	Arch Loss 2.6311 (2.3906)	Arch Hard Loss 2.5737 (2.3362)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 80.1%)	
11/15 01:41:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.9524 (1.8727)	Arch Loss 2.9337 (2.3856)	Arch Hard Loss 2.8755 (2.3312)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.8%)	
11/15 01:41:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.5746 (1.8770)	Arch Loss 2.2489 (2.3801)	Arch Hard Loss 2.1932 (2.3255)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.7%)	
11/15 01:41:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 47.8960%
11/15 01:41:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2898	Prec@(1,5) (40.0%, 72.0%)
11/15 01:42:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.3034	Prec@(1,5) (40.2%, 71.9%)
11/15 01:42:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.3262	Prec@(1,5) (39.6%, 71.5%)
11/15 01:42:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.3210	Prec@(1,5) (39.7%, 71.6%)
11/15 01:42:13午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 39.6360%
11/15 01:42:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:42:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8960%
11/15 01:42:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.7027 (1.7709)	Arch Loss 2.2700 (2.3647)	Arch Hard Loss 2.2151 (2.3095)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.5%)	
11/15 01:43:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 2.1911 (1.7983)	Arch Loss 2.4189 (2.3599)	Arch Hard Loss 2.3644 (2.3049)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.1%)	
11/15 01:44:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.7926 (1.8141)	Arch Loss 2.4366 (2.3671)	Arch Hard Loss 2.3837 (2.3121)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.7%)	
11/15 01:45:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.6826 (1.8202)	Arch Loss 2.2124 (2.3670)	Arch Hard Loss 2.1586 (2.3121)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.8%)	
11/15 01:45:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 49.4840%
11/15 01:45:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.3610	Prec@(1,5) (40.5%, 71.4%)
11/15 01:45:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.3551	Prec@(1,5) (40.1%, 71.3%)
11/15 01:45:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.3740	Prec@(1,5) (40.0%, 71.0%)
11/15 01:45:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.3856	Prec@(1,5) (39.9%, 70.7%)
11/15 01:45:31午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 39.8680%
11/15 01:45:31午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:45:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8960%
11/15 01:46:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.6314 (1.7307)	Arch Loss 2.4139 (2.3935)	Arch Hard Loss 2.3587 (2.3388)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 81.9%)	
11/15 01:46:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5456 (1.7343)	Arch Loss 2.2503 (2.3581)	Arch Hard Loss 2.1960 (2.3032)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
11/15 01:47:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.8520 (1.7414)	Arch Loss 2.4389 (2.3510)	Arch Hard Loss 2.3856 (2.2960)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.3%)	
11/15 01:48:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.6758 (1.7531)	Arch Loss 2.0969 (2.3422)	Arch Hard Loss 2.0435 (2.2871)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.0%)	
11/15 01:48:22午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 50.9760%
11/15 01:48:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.2464	Prec@(1,5) (41.2%, 73.7%)
11/15 01:48:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.2328	Prec@(1,5) (41.4%, 73.6%)
11/15 01:48:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.2453	Prec@(1,5) (41.4%, 73.3%)
11/15 01:48:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.2471	Prec@(1,5) (41.5%, 73.2%)
11/15 01:48:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 41.4920%
11/15 01:48:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:48:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.4920%
11/15 01:49:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.9417 (1.6668)	Arch Loss 2.1960 (2.3359)	Arch Hard Loss 2.1372 (2.2805)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 84.0%)	
11/15 01:50:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.3409 (1.6716)	Arch Loss 2.4692 (2.3520)	Arch Hard Loss 2.4114 (2.2967)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.6%)	
11/15 01:51:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.7766 (1.6837)	Arch Loss 2.6330 (2.3513)	Arch Hard Loss 2.5752 (2.2961)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.6%)	
11/15 01:51:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.4785 (1.6913)	Arch Loss 2.1359 (2.3350)	Arch Hard Loss 2.0800 (2.2798)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 83.4%)	
11/15 01:51:42午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 52.3520%
11/15 01:51:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.2367	Prec@(1,5) (43.3%, 73.8%)
11/15 01:51:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.2205	Prec@(1,5) (43.3%, 73.6%)
11/15 01:52:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2319	Prec@(1,5) (42.5%, 73.6%)
11/15 01:52:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2284	Prec@(1,5) (42.6%, 73.7%)
11/15 01:52:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 42.5720%
11/15 01:52:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:52:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5720%
11/15 01:52:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.4022 (1.5805)	Arch Loss 2.2717 (2.3289)	Arch Hard Loss 2.2189 (2.2743)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.7%)	
11/15 01:53:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.6519 (1.6182)	Arch Loss 2.2523 (2.3280)	Arch Hard Loss 2.1988 (2.2734)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.3%)	
11/15 01:54:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.6540 (1.6293)	Arch Loss 2.1395 (2.3146)	Arch Hard Loss 2.0856 (2.2601)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.3%)	
11/15 01:55:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.8147 (1.6476)	Arch Loss 2.5175 (2.3155)	Arch Hard Loss 2.4661 (2.2610)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 84.1%)	
11/15 01:55:01午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 53.5160%
11/15 01:55:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.2016	Prec@(1,5) (43.1%, 74.7%)
11/15 01:55:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.2004	Prec@(1,5) (43.2%, 74.5%)
11/15 01:55:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.1971	Prec@(1,5) (43.2%, 74.5%)
11/15 01:55:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.2002	Prec@(1,5) (43.0%, 74.5%)
11/15 01:55:28午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 43.0080%
11/15 01:55:28午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:55:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0080%
11/15 01:56:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.7368 (1.5322)	Arch Loss 1.9143 (2.2461)	Arch Hard Loss 1.8565 (2.1912)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.5%)	
11/15 01:56:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 2.1705 (1.5560)	Arch Loss 2.3588 (2.2769)	Arch Hard Loss 2.2995 (2.2220)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.3%)	
11/15 01:57:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 2.0650 (1.5744)	Arch Loss 2.6408 (2.2868)	Arch Hard Loss 2.5825 (2.2320)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.0%)	
11/15 01:58:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.6601 (1.5825)	Arch Loss 2.1111 (2.2842)	Arch Hard Loss 2.0519 (2.2295)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.8%)	
11/15 01:58:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 55.4200%
11/15 01:58:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1492	Prec@(1,5) (44.3%, 75.2%)
11/15 01:58:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1752	Prec@(1,5) (43.5%, 75.0%)
11/15 01:58:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.2040	Prec@(1,5) (43.0%, 74.6%)
11/15 01:58:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.2108	Prec@(1,5) (42.7%, 74.4%)
11/15 01:58:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 42.7160%
11/15 01:58:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 01:58:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0080%
11/15 01:59:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.5104 (1.4631)	Arch Loss 2.7137 (2.2889)	Arch Hard Loss 2.6622 (2.2346)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.8%)	
11/15 02:00:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.4798 (1.4782)	Arch Loss 2.3516 (2.3051)	Arch Hard Loss 2.2981 (2.2505)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.5%)	
11/15 02:00:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.6819 (1.4872)	Arch Loss 1.8916 (2.3028)	Arch Hard Loss 1.8366 (2.2481)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.5%)	
11/15 02:01:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.8603 (1.5125)	Arch Loss 2.0551 (2.3007)	Arch Hard Loss 2.0022 (2.2459)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.1%)	
11/15 02:01:38午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 56.8600%
11/15 02:01:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.2118	Prec@(1,5) (44.0%, 74.8%)
11/15 02:01:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1946	Prec@(1,5) (44.3%, 74.8%)
11/15 02:01:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1998	Prec@(1,5) (43.8%, 74.9%)
11/15 02:02:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.2084	Prec@(1,5) (43.6%, 74.8%)
11/15 02:02:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 43.6520%
11/15 02:02:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:02:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.6520%
11/15 02:02:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.2255 (1.3917)	Arch Loss 2.3001 (2.2219)	Arch Hard Loss 2.2445 (2.1674)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.9%)	
11/15 02:03:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.4684 (1.4173)	Arch Loss 2.1779 (2.2528)	Arch Hard Loss 2.1224 (2.1981)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.5%)	
11/15 02:04:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 2.0568 (1.4458)	Arch Loss 2.1272 (2.2564)	Arch Hard Loss 2.0730 (2.2017)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.2%)	
11/15 02:04:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.2941 (1.4525)	Arch Loss 1.8480 (2.2573)	Arch Hard Loss 1.7935 (2.2027)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.2%)	
11/15 02:04:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 58.3840%
11/15 02:05:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1852	Prec@(1,5) (44.4%, 75.3%)
11/15 02:05:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.1837	Prec@(1,5) (44.6%, 75.5%)
11/15 02:05:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.1856	Prec@(1,5) (44.8%, 75.1%)
11/15 02:05:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.1775	Prec@(1,5) (45.1%, 75.4%)
11/15 02:05:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 45.0640%
11/15 02:05:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:05:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/15 02:06:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.2880 (1.3313)	Arch Loss 2.2558 (2.2832)	Arch Hard Loss 2.1995 (2.2288)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.0%)	
11/15 02:06:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.6280 (1.3805)	Arch Loss 1.9307 (2.2901)	Arch Hard Loss 1.8762 (2.2355)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.2%)	
11/15 02:07:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1510 (1.3871)	Arch Loss 2.0587 (2.2879)	Arch Hard Loss 2.0049 (2.2333)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.2%)	
11/15 02:08:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.2239 (1.3897)	Arch Loss 2.3373 (2.2841)	Arch Hard Loss 2.2857 (2.2296)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.1%)	
11/15 02:08:13午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 59.9840%
11/15 02:08:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1749	Prec@(1,5) (45.2%, 75.4%)
11/15 02:08:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1808	Prec@(1,5) (44.8%, 75.2%)
11/15 02:08:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1835	Prec@(1,5) (44.8%, 75.3%)
11/15 02:08:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1759	Prec@(1,5) (44.8%, 75.5%)
11/15 02:08:39午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 44.7360%
11/15 02:08:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:08:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/15 02:09:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.1609 (1.3031)	Arch Loss 2.3434 (2.2627)	Arch Hard Loss 2.2871 (2.2090)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.1%)	
11/15 02:10:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.3679 (1.3053)	Arch Loss 1.8912 (2.2639)	Arch Hard Loss 1.8345 (2.2104)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.2%)	
11/15 02:10:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0512 (1.3167)	Arch Loss 2.4979 (2.2791)	Arch Hard Loss 2.4422 (2.2258)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.3%)	
11/15 02:11:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.9910 (1.3260)	Arch Loss 1.8365 (2.2724)	Arch Hard Loss 1.7815 (2.2190)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 89.1%)	
11/15 02:11:32午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 61.4280%
11/15 02:11:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.1929	Prec@(1,5) (45.2%, 75.7%)
11/15 02:11:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.2108	Prec@(1,5) (44.9%, 74.7%)
11/15 02:11:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.1997	Prec@(1,5) (44.8%, 75.0%)
11/15 02:11:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.1950	Prec@(1,5) (45.0%, 75.2%)
11/15 02:11:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 45.0440%
11/15 02:11:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:11:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/15 02:12:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.4454 (1.2338)	Arch Loss 2.3764 (2.2185)	Arch Hard Loss 2.3244 (2.1645)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.4%)	
11/15 02:13:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.5203 (1.2411)	Arch Loss 2.2992 (2.2486)	Arch Hard Loss 2.2476 (2.1946)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.4%)	
11/15 02:14:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.3221 (1.2614)	Arch Loss 2.1204 (2.2592)	Arch Hard Loss 2.0688 (2.2052)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 90.1%)	
11/15 02:14:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.1952 (1.2664)	Arch Loss 2.8535 (2.2672)	Arch Hard Loss 2.7996 (2.2130)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.9%)	
11/15 02:14:52午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 62.7240%
11/15 02:14:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.1677	Prec@(1,5) (46.1%, 76.2%)
11/15 02:15:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.1610	Prec@(1,5) (46.1%, 76.3%)
11/15 02:15:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.1540	Prec@(1,5) (46.3%, 76.3%)
11/15 02:15:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.1549	Prec@(1,5) (46.2%, 76.4%)
11/15 02:15:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 46.2160%
11/15 02:15:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:15:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2160%
11/15 02:16:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.2133 (1.1671)	Arch Loss 2.0938 (2.2387)	Arch Hard Loss 2.0351 (2.1834)	Arch Alpha Loss 0.0117 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 91.4%)	
11/15 02:16:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.5077 (1.1762)	Arch Loss 2.7945 (2.2478)	Arch Hard Loss 2.7355 (2.1924)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.3%)	
11/15 02:17:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.1951 (1.1912)	Arch Loss 2.2487 (2.2523)	Arch Hard Loss 2.1895 (2.1971)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.0%)	
11/15 02:18:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.2052 (1.2027)	Arch Loss 2.8344 (2.2567)	Arch Hard Loss 2.7760 (2.2016)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.8%)	
11/15 02:18:10午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 64.7040%
11/15 02:18:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1946	Prec@(1,5) (45.6%, 75.7%)
11/15 02:18:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1800	Prec@(1,5) (46.0%, 76.0%)
11/15 02:18:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1802	Prec@(1,5) (45.9%, 76.1%)
11/15 02:18:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1754	Prec@(1,5) (46.1%, 76.0%)
11/15 02:18:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 46.1080%
11/15 02:18:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:18:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2160%
11/15 02:19:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 1.1633 (1.1060)	Arch Loss 2.3273 (2.2795)	Arch Hard Loss 2.2752 (2.2239)	Arch Alpha Loss 0.0104 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.6%)	
11/15 02:20:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8332 (1.1141)	Arch Loss 1.9252 (2.2713)	Arch Hard Loss 1.8729 (2.2155)	Arch Alpha Loss 0.0105 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.3%)	
11/15 02:20:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.2357 (1.1295)	Arch Loss 2.4163 (2.2871)	Arch Hard Loss 2.3656 (2.2312)	Arch Alpha Loss 0.0101 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.9%)	
11/15 02:21:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.2466 (1.1365)	Arch Loss 2.3102 (2.2847)	Arch Hard Loss 2.2597 (2.2290)	Arch Alpha Loss 0.0101 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.8%)	
11/15 02:21:27午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 66.6280%
11/15 02:21:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.1332	Prec@(1,5) (46.3%, 77.5%)
11/15 02:21:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.1622	Prec@(1,5) (46.4%, 76.8%)
11/15 02:21:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.1609	Prec@(1,5) (46.2%, 76.8%)
11/15 02:21:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.1773	Prec@(1,5) (46.2%, 76.5%)
11/15 02:21:54午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 46.1840%
11/15 02:21:54午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:21:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2160%
11/15 02:22:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 1.0707 (1.0382)	Arch Loss 2.5843 (2.3150)	Arch Hard Loss 2.5240 (2.2593)	Arch Alpha Loss 0.0121 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.4%)	
11/15 02:23:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 1.2717 (1.0526)	Arch Loss 1.8383 (2.3221)	Arch Hard Loss 1.7770 (2.2666)	Arch Alpha Loss 0.0123 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
11/15 02:24:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 1.1021 (1.0649)	Arch Loss 2.1421 (2.2968)	Arch Hard Loss 2.0811 (2.2412)	Arch Alpha Loss 0.0122 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
11/15 02:24:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 1.0236 (1.0732)	Arch Loss 1.9512 (2.2840)	Arch Hard Loss 1.8901 (2.2286)	Arch Alpha Loss 0.0122 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.6%)	
11/15 02:24:44午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 68.2440%
11/15 02:24:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1487	Prec@(1,5) (47.1%, 77.6%)
11/15 02:24:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1469	Prec@(1,5) (47.2%, 77.2%)
11/15 02:25:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1441	Prec@(1,5) (47.0%, 77.3%)
11/15 02:25:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1493	Prec@(1,5) (47.0%, 77.0%)
11/15 02:25:11午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 47.0400%
11/15 02:25:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:25:11午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0400%
11/15 02:25:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.9004 (0.9648)	Arch Loss 2.3288 (2.2323)	Arch Hard Loss 2.2804 (2.1779)	Arch Alpha Loss 0.0097 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.0%)	
11/15 02:26:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 1.1553 (1.0020)	Arch Loss 2.0676 (2.2669)	Arch Hard Loss 2.0167 (2.2121)	Arch Alpha Loss 0.0102 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
11/15 02:27:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 1.1749 (1.0123)	Arch Loss 2.0177 (2.2754)	Arch Hard Loss 1.9633 (2.2203)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.3%)	
11/15 02:28:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.2025 (1.0200)	Arch Loss 2.3587 (2.2753)	Arch Hard Loss 2.3057 (2.2200)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.2%)	
11/15 02:28:01午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 69.6240%
11/15 02:28:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.1969	Prec@(1,5) (47.2%, 76.9%)
11/15 02:28:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.1755	Prec@(1,5) (47.2%, 76.7%)
11/15 02:28:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.1640	Prec@(1,5) (47.4%, 77.1%)
11/15 02:28:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.1668	Prec@(1,5) (47.1%, 77.0%)
11/15 02:28:28午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 47.1240%
11/15 02:28:28午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:28:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1240%
11/15 02:29:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7995 (0.9240)	Arch Loss 2.4239 (2.2953)	Arch Hard Loss 2.3667 (2.2397)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/15 02:29:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 1.0276 (0.9476)	Arch Loss 2.5912 (2.2888)	Arch Hard Loss 2.5371 (2.2332)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.3%)	
11/15 02:30:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.9755 (0.9595)	Arch Loss 1.9604 (2.2822)	Arch Hard Loss 1.9043 (2.2265)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 94.1%)	
11/15 02:31:19午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9460 (0.9679)	Arch Loss 2.6865 (2.2935)	Arch Hard Loss 2.6308 (2.2378)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
11/15 02:31:19午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 71.0880%
11/15 02:31:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.2392	Prec@(1,5) (46.0%, 76.5%)
11/15 02:31:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.2351	Prec@(1,5) (46.0%, 76.7%)
11/15 02:31:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.2188	Prec@(1,5) (46.6%, 76.7%)
11/15 02:31:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.2059	Prec@(1,5) (46.6%, 76.9%)
11/15 02:31:46午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 46.5760%
11/15 02:31:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:31:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1240%
11/15 02:32:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7976 (0.9120)	Arch Loss 1.9643 (2.2983)	Arch Hard Loss 1.9104 (2.2433)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/15 02:33:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.8822 (0.9080)	Arch Loss 2.3916 (2.3132)	Arch Hard Loss 2.3361 (2.2584)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.4%)	
11/15 02:33:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.9656 (0.9190)	Arch Loss 2.7649 (2.3160)	Arch Hard Loss 2.7094 (2.2613)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/15 02:34:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.9656 (0.9212)	Arch Loss 2.3605 (2.3019)	Arch Hard Loss 2.3090 (2.2474)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.4%)	
11/15 02:34:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 72.9520%
11/15 02:34:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.1419	Prec@(1,5) (48.2%, 77.3%)
11/15 02:34:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.1537	Prec@(1,5) (48.4%, 77.3%)
11/15 02:34:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.1458	Prec@(1,5) (48.3%, 77.4%)
11/15 02:35:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.1626	Prec@(1,5) (47.9%, 77.1%)
11/15 02:35:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 47.8760%
11/15 02:35:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:35:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/15 02:35:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7845 (0.8750)	Arch Loss 2.6127 (2.3250)	Arch Hard Loss 2.5595 (2.2715)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.6%)	
11/15 02:36:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.8757 (0.8718)	Arch Loss 2.9213 (2.3031)	Arch Hard Loss 2.8682 (2.2498)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
11/15 02:37:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7106 (0.8775)	Arch Loss 2.0417 (2.3063)	Arch Hard Loss 1.9881 (2.2529)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.8%)	
11/15 02:37:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.8524 (0.8765)	Arch Loss 2.1653 (2.3046)	Arch Hard Loss 2.1112 (2.2510)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
11/15 02:37:59午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 73.8280%
11/15 02:38:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.1711	Prec@(1,5) (47.8%, 77.4%)
11/15 02:38:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.1994	Prec@(1,5) (47.5%, 77.0%)
11/15 02:38:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.1995	Prec@(1,5) (47.6%, 76.9%)
11/15 02:38:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.1956	Prec@(1,5) (47.6%, 77.0%)
11/15 02:38:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 47.6240%
11/15 02:38:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:38:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/15 02:39:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.8405 (0.8372)	Arch Loss 2.9625 (2.2707)	Arch Hard Loss 2.9102 (2.2167)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.2%)	
11/15 02:39:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8096 (0.8311)	Arch Loss 1.8590 (2.3029)	Arch Hard Loss 1.8087 (2.2492)	Arch Alpha Loss 0.0101 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.5%)	
11/15 02:40:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.8396 (0.8239)	Arch Loss 2.2975 (2.3175)	Arch Hard Loss 2.2467 (2.2640)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.5%)	
11/15 02:41:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.8182 (0.8380)	Arch Loss 2.8641 (2.3180)	Arch Hard Loss 2.8116 (2.2647)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.3%)	
11/15 02:41:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 75.1600%
11/15 02:41:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.1745	Prec@(1,5) (47.2%, 77.5%)
11/15 02:41:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.2011	Prec@(1,5) (46.8%, 77.1%)
11/15 02:41:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.1922	Prec@(1,5) (47.2%, 77.3%)
11/15 02:41:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.2001	Prec@(1,5) (47.2%, 77.2%)
11/15 02:41:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 47.1920%
11/15 02:41:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:41:43午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/15 02:42:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.6090 (0.7871)	Arch Loss 2.1857 (2.3683)	Arch Hard Loss 2.1346 (2.3157)	Arch Alpha Loss 0.0102 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.7%)	
11/15 02:43:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5428 (0.7859)	Arch Loss 2.3759 (2.3501)	Arch Hard Loss 2.3247 (2.2974)	Arch Alpha Loss 0.0102 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.9%)	
11/15 02:43:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7693 (0.7934)	Arch Loss 2.5330 (2.3323)	Arch Hard Loss 2.4785 (2.2795)	Arch Alpha Loss 0.0109 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.7%)	
11/15 02:44:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7143 (0.7992)	Arch Loss 2.4851 (2.3264)	Arch Hard Loss 2.4298 (2.2735)	Arch Alpha Loss 0.0111 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.6%)	
11/15 02:44:35午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 76.3200%
11/15 02:44:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.2268	Prec@(1,5) (46.7%, 76.3%)
11/15 02:44:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.2225	Prec@(1,5) (46.8%, 76.6%)
11/15 02:44:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.1956	Prec@(1,5) (47.5%, 77.2%)
11/15 02:45:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.2040	Prec@(1,5) (47.5%, 77.0%)
11/15 02:45:01午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 47.5160%
11/15 02:45:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:45:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/15 02:45:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6756 (0.7554)	Arch Loss 1.9637 (2.3070)	Arch Hard Loss 1.9122 (2.2534)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.0%)	
11/15 02:46:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 1.0307 (0.7690)	Arch Loss 2.5131 (2.3261)	Arch Hard Loss 2.4636 (2.2732)	Arch Alpha Loss 0.0099 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 95.9%)	
11/15 02:47:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.7582 (0.7807)	Arch Loss 2.4559 (2.3332)	Arch Hard Loss 2.4026 (2.2805)	Arch Alpha Loss 0.0107 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.8%)	
11/15 02:47:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6390 (0.7813)	Arch Loss 1.5922 (2.3252)	Arch Hard Loss 1.5372 (2.2726)	Arch Alpha Loss 0.0110 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 95.8%)	
11/15 02:47:51午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 76.8400%
11/15 02:47:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.2330	Prec@(1,5) (47.6%, 76.9%)
11/15 02:48:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.2394	Prec@(1,5) (47.4%, 76.8%)
11/15 02:48:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.2300	Prec@(1,5) (47.6%, 77.0%)
11/15 02:48:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.2225	Prec@(1,5) (47.6%, 77.1%)
11/15 02:48:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 47.6120%
11/15 02:48:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:48:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/15 02:49:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.7171 (0.7170)	Arch Loss 2.0767 (2.3218)	Arch Hard Loss 2.0247 (2.2692)	Arch Alpha Loss 0.0104 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.5%)	
11/15 02:49:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6849 (0.7252)	Arch Loss 2.8337 (2.3242)	Arch Hard Loss 2.7831 (2.2714)	Arch Alpha Loss 0.0101 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.5%)	
11/15 02:50:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.8205 (0.7372)	Arch Loss 2.7847 (2.3399)	Arch Hard Loss 2.7330 (2.2869)	Arch Alpha Loss 0.0104 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.4%)	
11/15 02:51:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7858 (0.7496)	Arch Loss 2.3665 (2.3463)	Arch Hard Loss 2.3139 (2.2934)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.2%)	
11/15 02:51:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 77.7040%
11/15 02:51:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.2127	Prec@(1,5) (48.2%, 77.3%)
11/15 02:51:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.2366	Prec@(1,5) (47.7%, 76.8%)
11/15 02:51:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.2287	Prec@(1,5) (47.5%, 77.1%)
11/15 02:51:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.2311	Prec@(1,5) (47.6%, 77.2%)
11/15 02:51:46午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 47.5800%
11/15 02:51:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/15 02:51:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/15 02:52:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6941 (0.7176)	Arch Loss 1.8293 (2.3084)	Arch Hard Loss 1.7750 (2.2559)	Arch Alpha Loss 0.0109 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.5%)	
11/15 02:53:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6193 (0.7300)	Arch Loss 2.1976 (2.3381)	Arch Hard Loss 2.1421 (2.2854)	Arch Alpha Loss 0.0111 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.4%)	
11/15 02:54:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.6404 (0.7287)	Arch Loss 2.3937 (2.3403)	Arch Hard Loss 2.3411 (2.2875)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.3%)	
11/15 02:55:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.8112 (0.7278)	Arch Loss 2.5144 (2.3500)	Arch Hard Loss 2.4597 (2.2974)	Arch Alpha Loss 0.0109 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.4%)	
11/15 02:55:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 78.4240%
11/15 02:55:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.2261	Prec@(1,5) (48.4%, 77.8%)
11/15 02:55:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.2132	Prec@(1,5) (48.0%, 77.8%)
11/15 02:55:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.2213	Prec@(1,5) (48.1%, 77.5%)
11/15 02:55:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.2272	Prec@(1,5) (47.9%, 77.2%)
11/15 02:55:34午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 47.9040%
11/15 02:55:34午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 02:55:35午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9040%
11/15 02:56:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4940 (0.6741)	Arch Loss 2.4123 (2.3582)	Arch Hard Loss 2.3623 (2.3048)	Arch Alpha Loss 0.0100 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.2%)	
11/15 02:57:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.8225 (0.7045)	Arch Loss 2.5130 (2.3587)	Arch Hard Loss 2.4615 (2.3052)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.7%)	
11/15 02:58:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.9562 (0.7070)	Arch Loss 2.3191 (2.3602)	Arch Hard Loss 2.2660 (2.3064)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.7%)	
11/15 02:58:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6770 (0.7099)	Arch Loss 1.6444 (2.3499)	Arch Hard Loss 1.5905 (2.2959)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.6%)	
11/15 02:58:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 78.9200%
11/15 02:58:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.2552	Prec@(1,5) (47.4%, 76.6%)
11/15 02:59:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.2680	Prec@(1,5) (47.4%, 76.7%)
11/15 02:59:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.2608	Prec@(1,5) (47.7%, 76.9%)
11/15 02:59:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.2528	Prec@(1,5) (47.9%, 76.9%)
11/15 02:59:17午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 47.9160%
11/15 02:59:17午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/15 02:59:17午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9160%
11/15 02:59:17午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 47.9160%
11/15 02:59:17午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/17 01:53:37PM parser.py:28 [INFO] 
11/17 01:53:37PM parser.py:29 [INFO] Parameters:
11/17 01:53:37PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g5/DAG
11/17 01:53:37PM parser.py:31 [INFO] T=10.0
11/17 01:53:37PM parser.py:31 [INFO] ADVANCED=1
11/17 01:53:37PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/17 01:53:37PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/17 01:53:37PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/17 01:53:37PM parser.py:31 [INFO] BATCH_SIZE=64
11/17 01:53:37PM parser.py:31 [INFO] CASCADE=0
11/17 01:53:37PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/17 01:53:37PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/17 01:53:37PM parser.py:31 [INFO] DATA_PATH=../data/
11/17 01:53:37PM parser.py:31 [INFO] DATASET=cifar100
11/17 01:53:37PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/17 01:53:37PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/17 01:53:37PM parser.py:31 [INFO] DISCRETE=0
11/17 01:53:37PM parser.py:31 [INFO] EPOCHS=50
11/17 01:53:37PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/17 01:53:37PM parser.py:31 [INFO] EXP_NAME=s0-alphal1-sw3-g5
11/17 01:53:37PM parser.py:31 [INFO] FINAL_L=5.0
11/17 01:53:37PM parser.py:31 [INFO] G=5.0
11/17 01:53:37PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/17 01:53:37PM parser.py:31 [INFO] GPUS=[0]
11/17 01:53:37PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/17 01:53:37PM parser.py:31 [INFO] INIT_CHANNELS=16
11/17 01:53:37PM parser.py:31 [INFO] L=5.0
11/17 01:53:37PM parser.py:31 [INFO] LAYERS=32
11/17 01:53:37PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/17 01:53:37PM parser.py:31 [INFO] NAME=Pruning
11/17 01:53:37PM parser.py:31 [INFO] NONKD=1
11/17 01:53:37PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g5
11/17 01:53:37PM parser.py:31 [INFO] PCDARTS=0
11/17 01:53:37PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-alphal1-sw3-g5/plots
11/17 01:53:37PM parser.py:31 [INFO] PRINT_FREQ=100
11/17 01:53:37PM parser.py:31 [INFO] RESET=0
11/17 01:53:37PM parser.py:31 [INFO] RESUME_PATH=None
11/17 01:53:37PM parser.py:31 [INFO] SAVE=s0-alphal1-sw3-g5
11/17 01:53:37PM parser.py:31 [INFO] SEED=0
11/17 01:53:37PM parser.py:31 [INFO] SHARE_STAGE=0
11/17 01:53:37PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/17 01:53:37PM parser.py:31 [INFO] SPEC_CELL=1
11/17 01:53:37PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/17 01:53:37PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/17 01:53:37PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/17 01:53:37PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/17 01:53:37PM parser.py:31 [INFO] TYPE=ArchKD
11/17 01:53:37PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/17 01:53:37PM parser.py:31 [INFO] W_LR=0.025
11/17 01:53:37PM parser.py:31 [INFO] W_LR_MIN=0.001
11/17 01:53:37PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/17 01:53:37PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/17 01:53:37PM parser.py:31 [INFO] WORKERS=4
11/17 01:53:37PM parser.py:32 [INFO] 
11/17 01:53:43PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/17 01:53:51PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/17 01:55:29PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.6706 (4.7077)	Arch Loss 4.4122 (4.7687)	Arch Hard Loss 4.3563 (4.7093)	Arch Alpha Loss 0.0112 (0.0119)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.4%, 6.6%)	
11/17 01:57:03PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2540 (4.5820)	Arch Loss 4.4190 (4.6368)	Arch Hard Loss 4.3629 (4.5800)	Arch Alpha Loss 0.0112 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.0%, 8.9%)	
11/17 01:58:37PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2683 (4.4866)	Arch Loss 4.4406 (4.5385)	Arch Hard Loss 4.3838 (4.4826)	Arch Alpha Loss 0.0114 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.5%, 11.2%)	
11/17 02:00:02PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2524 (4.4300)	Arch Loss 4.0517 (4.4799)	Arch Hard Loss 3.9951 (4.4244)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.8%, 12.5%)	
11/17 02:00:05PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 2.8160%
11/17 02:00:20PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.2153	Prec@(1,5) (4.2%, 19.4%)
11/17 02:00:35PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.2047	Prec@(1,5) (4.3%, 19.7%)
11/17 02:00:49PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.2175	Prec@(1,5) (4.2%, 19.3%)
11/17 02:01:02PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.2163	Prec@(1,5) (4.2%, 19.7%)
11/17 02:01:02PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 4.2440%
11/17 02:01:03PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/17 02:01:03PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 4.2440%
11/17 02:02:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.1625 (4.1393)	Arch Loss 4.2896 (4.1894)	Arch Hard Loss 4.2379 (4.1353)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.9%, 20.2%)	
11/17 02:04:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.0857 (4.1035)	Arch Loss 3.9851 (4.1620)	Arch Hard Loss 3.9329 (4.1078)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.3%, 21.4%)	
11/17 02:05:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9618 (4.0756)	Arch Loss 3.8497 (4.1291)	Arch Hard Loss 3.7957 (4.0748)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.6%, 22.3%)	
11/17 02:07:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8608 (4.0551)	Arch Loss 3.8505 (4.0968)	Arch Hard Loss 3.7981 (4.0425)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.9%, 22.9%)	
11/17 02:07:10午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 5.9360%
11/17 02:07:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.8709	Prec@(1,5) (8.3%, 29.0%)
11/17 02:07:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.8955	Prec@(1,5) (8.5%, 28.5%)
11/17 02:07:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.8912	Prec@(1,5) (8.5%, 28.8%)
11/17 02:08:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.8936	Prec@(1,5) (8.5%, 28.6%)
11/17 02:08:07午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 8.4680%
11/17 02:08:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/17 02:08:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.4680%
11/17 02:09:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8205 (3.8840)	Arch Loss 4.2651 (3.9708)	Arch Hard Loss 4.2079 (3.9166)	Arch Alpha Loss 0.0114 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.7%, 28.9%)	
11/17 02:11:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.8542 (3.8792)	Arch Loss 3.9052 (3.9253)	Arch Hard Loss 3.8481 (3.8710)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.8%, 29.4%)	
11/17 02:12:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.9294 (3.8672)	Arch Loss 4.0920 (3.9070)	Arch Hard Loss 4.0356 (3.8527)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (8.9%, 29.8%)	
11/17 02:14:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.6649 (3.8514)	Arch Loss 3.7282 (3.8898)	Arch Hard Loss 3.6721 (3.8355)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (9.3%, 30.3%)	
11/17 02:14:15午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 9.2440%
11/17 02:14:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.7774	Prec@(1,5) (9.2%, 32.2%)
11/17 02:14:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.7709	Prec@(1,5) (9.7%, 32.5%)
11/17 02:14:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.7682	Prec@(1,5) (9.8%, 32.5%)
11/17 02:15:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.7643	Prec@(1,5) (9.9%, 32.7%)
11/17 02:15:13午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.8800%
11/17 02:15:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/17 02:15:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.8800%
11/17 02:16:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.6529 (3.7536)	Arch Loss 3.6725 (3.8112)	Arch Hard Loss 3.6197 (3.7567)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.2%, 33.1%)	
11/17 02:18:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7201 (3.7434)	Arch Loss 3.6193 (3.7990)	Arch Hard Loss 3.5671 (3.7444)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.1%, 33.3%)	
11/17 02:19:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.6301 (3.7313)	Arch Loss 3.8370 (3.7818)	Arch Hard Loss 3.7847 (3.7271)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.2%, 33.8%)	
11/17 02:21:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6772 (3.7251)	Arch Loss 3.7854 (3.7671)	Arch Hard Loss 3.7308 (3.7123)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (11.2%, 34.2%)	
11/17 02:21:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 11.2440%
11/17 02:21:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.6603	Prec@(1,5) (12.5%, 36.6%)
11/17 02:21:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.6552	Prec@(1,5) (12.3%, 37.0%)
11/17 02:22:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.6489	Prec@(1,5) (12.2%, 36.9%)
11/17 02:22:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.6496	Prec@(1,5) (12.4%, 37.2%)
11/17 02:22:18午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 12.3600%
11/17 02:22:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/17 02:22:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.3600%
11/17 02:23:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.6161 (3.6197)	Arch Loss 3.8487 (3.6817)	Arch Hard Loss 3.7915 (3.6265)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.2%, 37.2%)	
11/17 02:25:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.7803 (3.6193)	Arch Loss 3.7448 (3.6733)	Arch Hard Loss 3.6879 (3.6180)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.3%, 37.2%)	
11/17 02:27:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.4224 (3.6059)	Arch Loss 3.2250 (3.6577)	Arch Hard Loss 3.1679 (3.6025)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.6%, 37.7%)	
11/17 02:28:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.8073 (3.5952)	Arch Loss 3.7325 (3.6536)	Arch Hard Loss 3.6759 (3.5983)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (13.8%, 38.1%)	
11/17 02:28:27午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.8600%
11/17 02:28:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5176	Prec@(1,5) (15.2%, 40.3%)
11/17 02:28:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5248	Prec@(1,5) (15.3%, 40.7%)
11/17 02:29:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5345	Prec@(1,5) (15.1%, 40.7%)
11/17 02:29:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5341	Prec@(1,5) (15.0%, 40.7%)
11/17 02:29:25午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.9720%
11/17 02:29:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
11/17 02:29:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.9720%
11/17 02:30:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.7674 (3.4979)	Arch Loss 3.4684 (3.5698)	Arch Hard Loss 3.4148 (3.5146)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (15.1%, 41.5%)	
11/17 02:32:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.6605 (3.5076)	Arch Loss 3.7181 (3.5623)	Arch Hard Loss 3.6643 (3.5072)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.0%, 41.0%)	
11/17 02:34:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.3273 (3.4953)	Arch Loss 3.9312 (3.5521)	Arch Hard Loss 3.8767 (3.4971)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.4%)	
11/17 02:35:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.4554 (3.4894)	Arch Loss 3.5909 (3.5504)	Arch Hard Loss 3.5387 (3.4955)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.5%)	
11/17 02:35:33午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 15.2440%
11/17 02:35:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.5252	Prec@(1,5) (15.1%, 41.4%)
11/17 02:36:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.5344	Prec@(1,5) (14.7%, 41.0%)
11/17 02:36:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.5249	Prec@(1,5) (14.9%, 41.3%)
11/17 02:36:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.5300	Prec@(1,5) (14.8%, 41.3%)
11/17 02:36:30午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 14.7640%
11/17 02:36:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/17 02:36:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.9720%
11/17 02:38:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.1140 (3.4061)	Arch Loss 3.5384 (3.5115)	Arch Hard Loss 3.4833 (3.4566)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.9%, 43.9%)	
11/17 02:39:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.3331 (3.4092)	Arch Loss 3.8283 (3.5059)	Arch Hard Loss 3.7736 (3.4511)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.7%, 43.9%)	
11/17 02:41:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.3755 (3.3985)	Arch Loss 3.4342 (3.4789)	Arch Hard Loss 3.3792 (3.4240)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 44.1%)	
11/17 02:42:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.5641 (3.3938)	Arch Loss 3.5226 (3.4684)	Arch Hard Loss 3.4635 (3.4135)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.1%, 44.3%)	
11/17 02:42:38午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.1320%
11/17 02:42:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.3593	Prec@(1,5) (17.2%, 44.4%)
11/17 02:43:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.3771	Prec@(1,5) (17.7%, 44.8%)
11/17 02:43:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.3791	Prec@(1,5) (17.6%, 44.7%)
11/17 02:43:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.3793	Prec@(1,5) (17.6%, 44.7%)
11/17 02:43:35午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 17.6280%
11/17 02:43:35午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/17 02:43:36午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 17.6280%
11/17 02:45:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.1734 (3.3024)	Arch Loss 3.3990 (3.4005)	Arch Hard Loss 3.3442 (3.3453)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 47.4%)	
11/17 02:46:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.5597 (3.3011)	Arch Loss 3.5143 (3.4093)	Arch Hard Loss 3.4618 (3.3540)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.1%, 47.1%)	
11/17 02:48:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.2915 (3.2859)	Arch Loss 3.3067 (3.3837)	Arch Hard Loss 3.2545 (3.3283)	Arch Alpha Loss 0.0104 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 47.5%)	
11/17 02:49:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.3168 (3.2747)	Arch Loss 3.4581 (3.3745)	Arch Hard Loss 3.4063 (3.3191)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.8%, 47.8%)	
11/17 02:49:43午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 19.7680%
11/17 02:49:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.2897	Prec@(1,5) (19.7%, 47.2%)
11/17 02:50:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.2734	Prec@(1,5) (19.6%, 47.7%)
11/17 02:50:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.2639	Prec@(1,5) (19.5%, 48.0%)
11/17 02:50:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.2632	Prec@(1,5) (19.5%, 48.3%)
11/17 02:50:40午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 19.4520%
11/17 02:50:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/17 02:50:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.4520%
11/17 02:52:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.2776 (3.1889)	Arch Loss 3.5535 (3.3143)	Arch Hard Loss 3.4957 (3.2590)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.5%, 50.1%)	
11/17 02:53:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.1768 (3.2042)	Arch Loss 2.8512 (3.3021)	Arch Hard Loss 2.7925 (3.2469)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.8%)	
11/17 02:55:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.3988 (3.2038)	Arch Loss 3.3664 (3.3086)	Arch Hard Loss 3.3076 (3.2536)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.6%)	
11/17 02:56:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.1198 (3.1946)	Arch Loss 3.5649 (3.2938)	Arch Hard Loss 3.5083 (3.2387)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.8%, 49.9%)	
11/17 02:56:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 20.7800%
11/17 02:57:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.1885	Prec@(1,5) (21.4%, 50.2%)
11/17 02:57:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.1937	Prec@(1,5) (21.2%, 50.2%)
11/17 02:57:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.1919	Prec@(1,5) (21.3%, 50.2%)
11/17 02:57:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.1913	Prec@(1,5) (21.2%, 50.3%)
11/17 02:57:46午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 21.1840%
11/17 02:57:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/17 02:57:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.1840%
11/17 02:59:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.9012 (3.0980)	Arch Loss 3.2103 (3.2366)	Arch Hard Loss 3.1574 (3.1817)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.6%, 52.2%)	
11/17 03:00:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.1651 (3.0886)	Arch Loss 3.1298 (3.2357)	Arch Hard Loss 3.0763 (3.1809)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 52.4%)	
11/17 03:02:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.5247 (3.0902)	Arch Loss 3.3611 (3.2213)	Arch Hard Loss 3.3073 (3.1665)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.0%, 52.5%)	
11/17 03:03:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.8771 (3.0977)	Arch Loss 2.9256 (3.2093)	Arch Hard Loss 2.8708 (3.1544)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (22.8%, 52.2%)	
11/17 03:03:55午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 22.8000%
11/17 03:04:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.1283	Prec@(1,5) (22.0%, 51.7%)
11/17 03:04:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.1105	Prec@(1,5) (22.4%, 52.2%)
11/17 03:04:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.1321	Prec@(1,5) (22.4%, 51.5%)
11/17 03:04:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.1389	Prec@(1,5) (22.4%, 51.1%)
11/17 03:04:52午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 22.3680%
11/17 03:04:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/17 03:04:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.3680%
11/17 03:06:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 3.0050 (2.9852)	Arch Loss 3.0731 (3.0999)	Arch Hard Loss 3.0191 (3.0446)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.5%, 55.5%)	
11/17 03:08:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 3.0768 (3.0071)	Arch Loss 3.3770 (3.1393)	Arch Hard Loss 3.3223 (3.0840)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.4%, 55.0%)	
11/17 03:09:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.7599 (3.0072)	Arch Loss 2.8714 (3.1411)	Arch Hard Loss 2.8157 (3.0858)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.6%, 54.8%)	
11/17 03:11:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.9169 (2.9985)	Arch Loss 3.3439 (3.1325)	Arch Hard Loss 3.2848 (3.0771)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.8%, 54.9%)	
11/17 03:11:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 24.7800%
11/17 03:11:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.1673	Prec@(1,5) (22.3%, 52.4%)
11/17 03:11:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.1343	Prec@(1,5) (22.9%, 53.0%)
11/17 03:11:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 3.1317	Prec@(1,5) (23.0%, 52.9%)
11/17 03:11:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 3.1299	Prec@(1,5) (22.9%, 53.1%)
11/17 03:11:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 22.9360%
11/17 03:11:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/17 03:11:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.9360%
11/17 03:13:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.8583 (2.9059)	Arch Loss 3.1664 (3.0877)	Arch Hard Loss 3.1115 (3.0323)	Arch Alpha Loss 0.0110 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.2%, 57.6%)	
11/17 03:15:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.8767 (2.9067)	Arch Loss 2.5568 (3.0664)	Arch Hard Loss 2.5030 (3.0112)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.5%)	
11/17 03:16:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 3.0030 (2.9138)	Arch Loss 3.0175 (3.0507)	Arch Hard Loss 2.9646 (2.9957)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.3%)	
11/17 03:18:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 3.0133 (2.9088)	Arch Loss 2.4495 (3.0466)	Arch Hard Loss 2.3982 (2.9918)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.9%, 57.3%)	
11/17 03:18:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 26.8800%
11/17 03:18:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.9725	Prec@(1,5) (26.1%, 56.5%)
11/17 03:18:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.9758	Prec@(1,5) (25.9%, 56.1%)
11/17 03:18:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9697	Prec@(1,5) (25.7%, 56.4%)
11/17 03:19:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.9644	Prec@(1,5) (25.8%, 56.5%)
11/17 03:19:03午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 25.7640%
11/17 03:19:03午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/17 03:19:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.7640%
11/17 03:20:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4963 (2.8238)	Arch Loss 3.0124 (2.9896)	Arch Hard Loss 2.9553 (2.9353)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.9%, 58.6%)	
11/17 03:22:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.7409 (2.8307)	Arch Loss 2.6561 (2.9962)	Arch Hard Loss 2.6015 (2.9421)	Arch Alpha Loss 0.0109 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.9%, 59.0%)	
11/17 03:23:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.8589 (2.8320)	Arch Loss 3.0790 (2.9862)	Arch Hard Loss 3.0242 (2.9323)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.8%, 59.2%)	
11/17 03:25:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 3.1556 (2.8277)	Arch Loss 2.9866 (2.9828)	Arch Hard Loss 2.9332 (2.9289)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.0%, 59.4%)	
11/17 03:25:11午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 28.0320%
11/17 03:25:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.9213	Prec@(1,5) (26.7%, 57.6%)
11/17 03:25:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.9216	Prec@(1,5) (26.7%, 57.3%)
11/17 03:25:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.9278	Prec@(1,5) (26.6%, 57.1%)
11/17 03:26:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.9314	Prec@(1,5) (26.5%, 57.1%)
11/17 03:26:09午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 26.4760%
11/17 03:26:09午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/17 03:26:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.4760%
11/17 03:27:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.4818 (2.7567)	Arch Loss 2.9819 (2.9618)	Arch Hard Loss 2.9288 (2.9080)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 60.8%)	
11/17 03:29:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 3.0863 (2.7643)	Arch Loss 3.0099 (2.9507)	Arch Hard Loss 2.9571 (2.8967)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.5%, 60.6%)	
11/17 03:30:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.7927 (2.7499)	Arch Loss 2.3856 (2.9407)	Arch Hard Loss 2.3322 (2.8868)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 60.9%)	
11/17 03:32:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.3668 (2.7521)	Arch Loss 3.0693 (2.9338)	Arch Hard Loss 3.0139 (2.8800)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.0%, 60.9%)	
11/17 03:32:18午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 28.9920%
11/17 03:32:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.8245	Prec@(1,5) (28.7%, 60.2%)
11/17 03:32:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8282	Prec@(1,5) (28.8%, 60.0%)
11/17 03:33:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.8350	Prec@(1,5) (28.5%, 59.8%)
11/17 03:33:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.8390	Prec@(1,5) (28.5%, 59.6%)
11/17 03:33:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 28.4680%
11/17 03:33:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/17 03:33:16午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.4680%
11/17 03:34:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.6477 (2.6614)	Arch Loss 2.8442 (2.8893)	Arch Hard Loss 2.7917 (2.8357)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.6%, 62.8%)	
11/17 03:36:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.7653 (2.6643)	Arch Loss 2.8446 (2.8805)	Arch Hard Loss 2.7938 (2.8268)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.4%, 62.8%)	
11/17 03:37:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.7548 (2.6719)	Arch Loss 2.5602 (2.8693)	Arch Hard Loss 2.5090 (2.8154)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.1%, 63.0%)	
11/17 03:39:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.7107 (2.6709)	Arch Loss 2.8388 (2.8669)	Arch Hard Loss 2.7839 (2.8130)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.0%, 63.1%)	
11/17 03:39:24午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 30.9560%
11/17 03:39:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.6718	Prec@(1,5) (30.3%, 63.0%)
11/17 03:39:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.6835	Prec@(1,5) (30.7%, 62.7%)
11/17 03:40:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.6901	Prec@(1,5) (30.7%, 62.8%)
11/17 03:40:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.7001	Prec@(1,5) (30.7%, 62.6%)
11/17 03:40:21午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 30.7240%
11/17 03:40:21午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 03:40:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.7240%
11/17 03:41:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.3178 (2.5574)	Arch Loss 2.8125 (2.8088)	Arch Hard Loss 2.7572 (2.7541)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.6%, 65.9%)	
11/17 03:43:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.1811 (2.5858)	Arch Loss 2.8411 (2.8114)	Arch Hard Loss 2.7857 (2.7566)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.1%, 65.0%)	
11/17 03:45:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.4979 (2.5927)	Arch Loss 3.1955 (2.8093)	Arch Hard Loss 3.1404 (2.7544)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 64.8%)	
11/17 03:46:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.3107 (2.6007)	Arch Loss 2.6589 (2.8052)	Arch Hard Loss 2.6047 (2.7504)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.4%, 64.5%)	
11/17 03:46:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 32.3960%
11/17 03:46:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.7648	Prec@(1,5) (30.3%, 61.3%)
11/17 03:46:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.7373	Prec@(1,5) (30.6%, 62.1%)
11/17 03:47:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.7346	Prec@(1,5) (30.5%, 62.3%)
11/17 03:47:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.7297	Prec@(1,5) (30.6%, 62.4%)
11/17 03:47:27午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 30.5800%
11/17 03:47:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 03:47:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 30.7240%
11/17 03:49:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.4173 (2.4755)	Arch Loss 2.9476 (2.7682)	Arch Hard Loss 2.8916 (2.7137)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.7%, 67.5%)	
11/17 03:50:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.3933 (2.5101)	Arch Loss 2.8002 (2.7730)	Arch Hard Loss 2.7413 (2.7186)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.9%)	
11/17 03:52:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.8848 (2.5167)	Arch Loss 2.5024 (2.7602)	Arch Hard Loss 2.4439 (2.7055)	Arch Alpha Loss 0.0117 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.8%, 66.9%)	
11/17 03:53:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.5133 (2.5227)	Arch Loss 2.7952 (2.7540)	Arch Hard Loss 2.7414 (2.6993)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.7%)	
11/17 03:53:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 33.8560%
11/17 03:53:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.6287	Prec@(1,5) (33.2%, 63.9%)
11/17 03:54:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.6609	Prec@(1,5) (32.6%, 63.3%)
11/17 03:54:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.6660	Prec@(1,5) (32.5%, 63.3%)
11/17 03:54:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.6671	Prec@(1,5) (32.3%, 63.4%)
11/17 03:54:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 32.3160%
11/17 03:54:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 03:54:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.3160%
11/17 03:56:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.3455 (2.4819)	Arch Loss 2.8686 (2.7429)	Arch Hard Loss 2.8134 (2.6884)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.7%, 67.4%)	
11/17 03:57:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.1758 (2.4662)	Arch Loss 2.8249 (2.7211)	Arch Hard Loss 2.7701 (2.6662)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.3%, 67.8%)	
11/17 03:59:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.3045 (2.4559)	Arch Loss 2.5977 (2.7230)	Arch Hard Loss 2.5438 (2.6678)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 67.9%)	
11/17 04:00:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.1243 (2.4559)	Arch Loss 2.7975 (2.7120)	Arch Hard Loss 2.7431 (2.6567)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 67.9%)	
11/17 04:00:43午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 35.6920%
11/17 04:00:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.6138	Prec@(1,5) (33.6%, 64.8%)
11/17 04:01:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.6069	Prec@(1,5) (33.5%, 65.4%)
11/17 04:01:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.6224	Prec@(1,5) (33.2%, 64.9%)
11/17 04:01:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.6286	Prec@(1,5) (32.9%, 64.7%)
11/17 04:01:39午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 32.8880%
11/17 04:01:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:01:39午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.8880%
11/17 04:03:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.4428 (2.3966)	Arch Loss 2.6376 (2.7020)	Arch Hard Loss 2.5844 (2.6476)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.5%)	
11/17 04:04:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.6467 (2.3856)	Arch Loss 2.4133 (2.6950)	Arch Hard Loss 2.3596 (2.6406)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.9%, 69.5%)	
11/17 04:06:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.6039 (2.3852)	Arch Loss 2.3658 (2.6712)	Arch Hard Loss 2.3108 (2.6168)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.0%, 69.6%)	
11/17 04:07:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.2019 (2.3906)	Arch Loss 2.1985 (2.6567)	Arch Hard Loss 2.1417 (2.6022)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.9%, 69.4%)	
11/17 04:07:48午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 36.9240%
11/17 04:08:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.5560	Prec@(1,5) (34.6%, 66.3%)
11/17 04:08:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.5788	Prec@(1,5) (33.9%, 65.9%)
11/17 04:08:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.5745	Prec@(1,5) (33.9%, 65.8%)
11/17 04:08:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.5712	Prec@(1,5) (33.9%, 65.8%)
11/17 04:08:45午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 33.8760%
11/17 04:08:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:08:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.8760%
11/17 04:10:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 2.1328 (2.2548)	Arch Loss 2.7412 (2.6333)	Arch Hard Loss 2.6862 (2.5783)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.0%, 72.1%)	
11/17 04:11:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.9176 (2.2943)	Arch Loss 2.5971 (2.6146)	Arch Hard Loss 2.5424 (2.5594)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.5%, 71.2%)	
11/17 04:13:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.1798 (2.3122)	Arch Loss 2.3927 (2.6099)	Arch Hard Loss 2.3384 (2.5546)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.2%, 70.9%)	
11/17 04:14:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.4558 (2.3127)	Arch Loss 2.2001 (2.6141)	Arch Hard Loss 2.1447 (2.5589)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.0%)	
11/17 04:14:54午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 38.2760%
11/17 04:15:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.5606	Prec@(1,5) (34.3%, 66.9%)
11/17 04:15:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.5576	Prec@(1,5) (34.0%, 66.7%)
11/17 04:15:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.5544	Prec@(1,5) (34.3%, 66.5%)
11/17 04:15:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.5464	Prec@(1,5) (34.5%, 66.7%)
11/17 04:15:52午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 34.5200%
11/17 04:15:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:15:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.5200%
11/17 04:17:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.8772 (2.2093)	Arch Loss 2.7133 (2.5496)	Arch Hard Loss 2.6607 (2.4945)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 72.8%)	
11/17 04:19:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.9326 (2.2411)	Arch Loss 2.5274 (2.5653)	Arch Hard Loss 2.4745 (2.5101)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.5%)	
11/17 04:20:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.3819 (2.2470)	Arch Loss 2.4115 (2.5771)	Arch Hard Loss 2.3611 (2.5221)	Arch Alpha Loss 0.0101 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.4%)	
11/17 04:21:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.9262 (2.2522)	Arch Loss 2.5437 (2.5762)	Arch Hard Loss 2.4925 (2.5215)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.7%, 72.3%)	
11/17 04:22:00午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 39.7080%
11/17 04:22:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.4716	Prec@(1,5) (36.1%, 67.8%)
11/17 04:22:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.5052	Prec@(1,5) (35.4%, 67.0%)
11/17 04:22:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.5073	Prec@(1,5) (35.5%, 67.2%)
11/17 04:22:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.5071	Prec@(1,5) (35.4%, 67.1%)
11/17 04:22:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 35.4000%
11/17 04:22:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:22:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.4000%
11/17 04:24:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.3749 (2.1312)	Arch Loss 2.5269 (2.5695)	Arch Hard Loss 2.4705 (2.5154)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 74.6%)	
11/17 04:26:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.4008 (2.1630)	Arch Loss 2.7864 (2.5718)	Arch Hard Loss 2.7289 (2.5175)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 74.3%)	
11/17 04:27:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.9678 (2.1779)	Arch Loss 2.5686 (2.5587)	Arch Hard Loss 2.5118 (2.5043)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.3%, 74.1%)	
11/17 04:29:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.3822 (2.1825)	Arch Loss 2.6454 (2.5482)	Arch Hard Loss 2.5883 (2.4937)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 74.1%)	
11/17 04:29:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 41.1480%
11/17 04:29:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.5064	Prec@(1,5) (35.0%, 67.1%)
11/17 04:29:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4703	Prec@(1,5) (35.9%, 68.4%)
11/17 04:29:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4597	Prec@(1,5) (36.4%, 68.6%)
11/17 04:29:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4546	Prec@(1,5) (36.5%, 68.8%)
11/17 04:29:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 36.4760%
11/17 04:29:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:29:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.4760%
11/17 04:31:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 2.0428 (2.0907)	Arch Loss 2.5137 (2.5111)	Arch Hard Loss 2.4607 (2.4557)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.7%)	
11/17 04:32:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.9330 (2.1082)	Arch Loss 2.8185 (2.5091)	Arch Hard Loss 2.7643 (2.4537)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.0%, 75.5%)	
11/17 04:34:23午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 2.1040 (2.1207)	Arch Loss 2.4679 (2.5070)	Arch Hard Loss 2.4132 (2.4516)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.7%, 75.3%)	
11/17 04:35:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7016 (2.1253)	Arch Loss 2.3001 (2.4924)	Arch Hard Loss 2.2466 (2.4369)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 75.2%)	
11/17 04:35:48午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 42.5320%
11/17 04:36:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.4161	Prec@(1,5) (37.8%, 69.4%)
11/17 04:36:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.3877	Prec@(1,5) (38.3%, 70.0%)
11/17 04:36:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.3888	Prec@(1,5) (38.0%, 70.0%)
11/17 04:36:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.3897	Prec@(1,5) (37.9%, 69.9%)
11/17 04:36:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 37.9080%
11/17 04:36:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:36:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.9080%
11/17 04:38:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.8978 (1.9844)	Arch Loss 2.8064 (2.4906)	Arch Hard Loss 2.7517 (2.4352)	Arch Alpha Loss 0.0109 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.1%)	
11/17 04:39:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 2.0801 (2.0252)	Arch Loss 1.9091 (2.4647)	Arch Hard Loss 1.8535 (2.4094)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 76.9%)	
11/17 04:41:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.1718 (2.0474)	Arch Loss 2.3689 (2.4698)	Arch Hard Loss 2.3135 (2.4145)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.0%, 76.6%)	
11/17 04:42:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.1188 (2.0560)	Arch Loss 2.5208 (2.4656)	Arch Hard Loss 2.4625 (2.4103)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.1%, 76.3%)	
11/17 04:42:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 44.0640%
11/17 04:43:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.4188	Prec@(1,5) (38.3%, 69.7%)
11/17 04:43:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.4048	Prec@(1,5) (38.5%, 69.7%)
11/17 04:43:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.4028	Prec@(1,5) (38.4%, 69.9%)
11/17 04:43:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.4050	Prec@(1,5) (38.3%, 69.7%)
11/17 04:43:48午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 38.2600%
11/17 04:43:48午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:43:48午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2600%
11/17 04:45:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.9724 (1.9402)	Arch Loss 2.2708 (2.4638)	Arch Hard Loss 2.2183 (2.4085)	Arch Alpha Loss 0.0105 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 78.7%)	
11/17 04:46:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 2.4385 (1.9665)	Arch Loss 2.1701 (2.4383)	Arch Hard Loss 2.1184 (2.3831)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 78.2%)	
11/17 04:48:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.8298 (1.9818)	Arch Loss 2.1839 (2.4423)	Arch Hard Loss 2.1306 (2.3872)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.6%, 77.9%)	
11/17 04:49:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.1941 (1.9937)	Arch Loss 2.4082 (2.4418)	Arch Hard Loss 2.3544 (2.3866)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 77.7%)	
11/17 04:49:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 45.4480%
11/17 04:50:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.3574	Prec@(1,5) (38.2%, 70.2%)
11/17 04:50:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.3605	Prec@(1,5) (38.3%, 70.3%)
11/17 04:50:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.3757	Prec@(1,5) (38.4%, 70.3%)
11/17 04:50:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.3729	Prec@(1,5) (38.5%, 70.3%)
11/17 04:50:53午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 38.5440%
11/17 04:50:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:50:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.5440%
11/17 04:52:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.9054 (1.8926)	Arch Loss 2.0755 (2.4104)	Arch Hard Loss 2.0200 (2.3554)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.4%)	
11/17 04:54:02午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 2.0724 (1.9039)	Arch Loss 2.7925 (2.4201)	Arch Hard Loss 2.7369 (2.3652)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.3%, 79.2%)	
11/17 04:55:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.6986 (1.9197)	Arch Loss 2.6426 (2.4155)	Arch Hard Loss 2.5885 (2.3604)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.0%)	
11/17 04:57:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 2.0721 (1.9373)	Arch Loss 2.7051 (2.4129)	Arch Hard Loss 2.6528 (2.3579)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.6%, 78.6%)	
11/17 04:57:01午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 46.5720%
11/17 04:57:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.3105	Prec@(1,5) (41.0%, 71.5%)
11/17 04:57:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.3440	Prec@(1,5) (40.1%, 71.2%)
11/17 04:57:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.3403	Prec@(1,5) (39.8%, 71.4%)
11/17 04:57:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.3289	Prec@(1,5) (39.9%, 71.7%)
11/17 04:57:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 39.8960%
11/17 04:57:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 04:57:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8960%
11/17 04:59:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.4015 (1.8473)	Arch Loss 2.9702 (2.3890)	Arch Hard Loss 2.9128 (2.3345)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.3%)	
11/17 05:01:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.6267 (1.8608)	Arch Loss 2.6311 (2.3906)	Arch Hard Loss 2.5737 (2.3362)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.4%, 80.1%)	
11/17 05:02:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.9524 (1.8727)	Arch Loss 2.9337 (2.3856)	Arch Hard Loss 2.8755 (2.3312)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.1%, 79.8%)	
11/17 05:04:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.5746 (1.8770)	Arch Loss 2.2489 (2.3801)	Arch Hard Loss 2.1932 (2.3255)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.9%, 79.7%)	
11/17 05:04:05午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 47.8960%
11/17 05:04:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.2898	Prec@(1,5) (40.0%, 72.0%)
11/17 05:04:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.3034	Prec@(1,5) (40.2%, 71.9%)
11/17 05:04:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.3262	Prec@(1,5) (39.6%, 71.5%)
11/17 05:05:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.3210	Prec@(1,5) (39.7%, 71.6%)
11/17 05:05:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 39.6360%
11/17 05:05:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:05:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8960%
11/17 05:06:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.7027 (1.7709)	Arch Loss 2.2700 (2.3647)	Arch Hard Loss 2.2151 (2.3095)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.5%)	
11/17 05:08:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 2.1911 (1.7983)	Arch Loss 2.4189 (2.3599)	Arch Hard Loss 2.3644 (2.3049)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.1%, 81.1%)	
11/17 05:09:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.7926 (1.8141)	Arch Loss 2.4366 (2.3671)	Arch Hard Loss 2.3837 (2.3121)	Arch Alpha Loss 0.0106 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 80.7%)	
11/17 05:11:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.6826 (1.8202)	Arch Loss 2.2124 (2.3670)	Arch Hard Loss 2.1586 (2.3121)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.5%, 80.8%)	
11/17 05:11:09午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 49.4840%
11/17 05:11:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.3610	Prec@(1,5) (40.5%, 71.4%)
11/17 05:11:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.3551	Prec@(1,5) (40.1%, 71.3%)
11/17 05:11:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.3740	Prec@(1,5) (40.0%, 71.0%)
11/17 05:12:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.3856	Prec@(1,5) (39.9%, 70.7%)
11/17 05:12:06午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 39.8680%
11/17 05:12:06午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:12:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.8960%
11/17 05:13:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.6314 (1.7307)	Arch Loss 2.4139 (2.3935)	Arch Hard Loss 2.3587 (2.3388)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 81.9%)	
11/17 05:15:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5456 (1.7343)	Arch Loss 2.2503 (2.3581)	Arch Hard Loss 2.1960 (2.3032)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
11/17 05:16:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.8520 (1.7414)	Arch Loss 2.4389 (2.3510)	Arch Hard Loss 2.3856 (2.2960)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.3%)	
11/17 05:18:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.6758 (1.7531)	Arch Loss 2.0969 (2.3422)	Arch Hard Loss 2.0435 (2.2871)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 82.0%)	
11/17 05:18:13午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 50.9760%
11/17 05:18:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.2464	Prec@(1,5) (41.2%, 73.7%)
11/17 05:18:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.2328	Prec@(1,5) (41.4%, 73.6%)
11/17 05:18:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.2453	Prec@(1,5) (41.4%, 73.3%)
11/17 05:19:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.2471	Prec@(1,5) (41.5%, 73.2%)
11/17 05:19:10午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 41.4920%
11/17 05:19:10午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:19:11午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.4920%
11/17 05:20:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.9417 (1.6668)	Arch Loss 2.1960 (2.3359)	Arch Hard Loss 2.1372 (2.2805)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 84.0%)	
11/17 05:22:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.3409 (1.6716)	Arch Loss 2.4692 (2.3520)	Arch Hard Loss 2.4114 (2.2967)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.6%)	
11/17 05:23:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.7766 (1.6837)	Arch Loss 2.6330 (2.3513)	Arch Hard Loss 2.5752 (2.2961)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.6%)	
11/17 05:25:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.4785 (1.6913)	Arch Loss 2.1359 (2.3350)	Arch Hard Loss 2.0800 (2.2798)	Arch Alpha Loss 0.0112 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.3%, 83.4%)	
11/17 05:25:17午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 52.3520%
11/17 05:25:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.2367	Prec@(1,5) (43.3%, 73.8%)
11/17 05:25:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.2205	Prec@(1,5) (43.3%, 73.6%)
11/17 05:26:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2319	Prec@(1,5) (42.5%, 73.6%)
11/17 05:26:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2284	Prec@(1,5) (42.6%, 73.7%)
11/17 05:26:14午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 42.5720%
11/17 05:26:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:26:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.5720%
11/17 05:27:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.4022 (1.5805)	Arch Loss 2.2717 (2.3289)	Arch Hard Loss 2.2189 (2.2743)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.7%)	
11/17 05:29:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.6519 (1.6182)	Arch Loss 2.2523 (2.3280)	Arch Hard Loss 2.1988 (2.2734)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.3%)	
11/17 05:30:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.6540 (1.6293)	Arch Loss 2.1395 (2.3146)	Arch Hard Loss 2.0856 (2.2601)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.9%, 84.3%)	
11/17 05:32:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.8147 (1.6476)	Arch Loss 2.5175 (2.3155)	Arch Hard Loss 2.4661 (2.2610)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 84.1%)	
11/17 05:32:21午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 53.5160%
11/17 05:32:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.2016	Prec@(1,5) (43.1%, 74.7%)
11/17 05:32:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.2004	Prec@(1,5) (43.2%, 74.5%)
11/17 05:33:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.1971	Prec@(1,5) (43.2%, 74.5%)
11/17 05:33:18午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.2002	Prec@(1,5) (43.0%, 74.5%)
11/17 05:33:18午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 43.0080%
11/17 05:33:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:33:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0080%
11/17 05:34:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.7368 (1.5322)	Arch Loss 1.9143 (2.2461)	Arch Hard Loss 1.8565 (2.1912)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.5%)	
11/17 05:36:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 2.1705 (1.5560)	Arch Loss 2.3588 (2.2769)	Arch Hard Loss 2.2995 (2.2220)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.9%, 85.3%)	
11/17 05:38:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 2.0650 (1.5744)	Arch Loss 2.6408 (2.2868)	Arch Hard Loss 2.5825 (2.2320)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.0%)	
11/17 05:39:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.6601 (1.5825)	Arch Loss 2.1111 (2.2842)	Arch Hard Loss 2.0519 (2.2295)	Arch Alpha Loss 0.0118 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.8%)	
11/17 05:39:25午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 55.4200%
11/17 05:39:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1492	Prec@(1,5) (44.3%, 75.2%)
11/17 05:39:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1752	Prec@(1,5) (43.5%, 75.0%)
11/17 05:40:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.2040	Prec@(1,5) (43.0%, 74.6%)
11/17 05:40:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.2108	Prec@(1,5) (42.7%, 74.4%)
11/17 05:40:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 42.7160%
11/17 05:40:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:40:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.0080%
11/17 05:41:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.5104 (1.4631)	Arch Loss 2.7137 (2.2889)	Arch Hard Loss 2.6622 (2.2346)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.8%)	
11/17 05:43:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.4798 (1.4782)	Arch Loss 2.3516 (2.3051)	Arch Hard Loss 2.2981 (2.2505)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.5%)	
11/17 05:45:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.6819 (1.4872)	Arch Loss 1.8916 (2.3028)	Arch Hard Loss 1.8366 (2.2481)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.5%)	
11/17 05:46:28午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.8603 (1.5125)	Arch Loss 2.0551 (2.3007)	Arch Hard Loss 2.0022 (2.2459)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.1%)	
11/17 05:46:29午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 56.8600%
11/17 05:46:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.2118	Prec@(1,5) (44.0%, 74.8%)
11/17 05:46:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1946	Prec@(1,5) (44.3%, 74.8%)
11/17 05:47:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1998	Prec@(1,5) (43.8%, 74.9%)
11/17 05:47:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.2084	Prec@(1,5) (43.6%, 74.8%)
11/17 05:47:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 43.6520%
11/17 05:47:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:47:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.6520%
11/17 05:49:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.2255 (1.3917)	Arch Loss 2.3001 (2.2219)	Arch Hard Loss 2.2445 (2.1674)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.9%)	
11/17 05:50:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.4684 (1.4173)	Arch Loss 2.1779 (2.2528)	Arch Hard Loss 2.1224 (2.1981)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.5%)	
11/17 05:52:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 2.0568 (1.4458)	Arch Loss 2.1272 (2.2564)	Arch Hard Loss 2.0730 (2.2017)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.2%)	
11/17 05:53:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.2941 (1.4525)	Arch Loss 1.8480 (2.2573)	Arch Hard Loss 1.7935 (2.2027)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 87.2%)	
11/17 05:53:32午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 58.3840%
11/17 05:53:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1852	Prec@(1,5) (44.4%, 75.3%)
11/17 05:54:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.1837	Prec@(1,5) (44.6%, 75.5%)
11/17 05:54:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.1856	Prec@(1,5) (44.8%, 75.1%)
11/17 05:54:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.1775	Prec@(1,5) (45.1%, 75.4%)
11/17 05:54:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 45.0640%
11/17 05:54:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 05:54:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/17 05:56:04午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.2880 (1.3313)	Arch Loss 2.2558 (2.2832)	Arch Hard Loss 2.1995 (2.2288)	Arch Alpha Loss 0.0113 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.0%)	
11/17 05:57:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.6280 (1.3805)	Arch Loss 1.9307 (2.2901)	Arch Hard Loss 1.8762 (2.2355)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.2%)	
11/17 05:59:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1510 (1.3871)	Arch Loss 2.0587 (2.2879)	Arch Hard Loss 2.0049 (2.2333)	Arch Alpha Loss 0.0108 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.2%)	
11/17 06:00:35午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.2239 (1.3897)	Arch Loss 2.3373 (2.2841)	Arch Hard Loss 2.2857 (2.2296)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.1%)	
11/17 06:00:36午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 59.9840%
11/17 06:00:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1749	Prec@(1,5) (45.2%, 75.4%)
11/17 06:01:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1808	Prec@(1,5) (44.8%, 75.2%)
11/17 06:01:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1835	Prec@(1,5) (44.8%, 75.3%)
11/17 06:01:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1759	Prec@(1,5) (44.8%, 75.5%)
11/17 06:01:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 44.7360%
11/17 06:01:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:01:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/17 06:03:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.1609 (1.3031)	Arch Loss 2.3434 (2.2627)	Arch Hard Loss 2.2871 (2.2090)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.1%)	
11/17 06:04:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.3679 (1.3053)	Arch Loss 1.8912 (2.2639)	Arch Hard Loss 1.8345 (2.2104)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.2%)	
11/17 06:06:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0512 (1.3167)	Arch Loss 2.4979 (2.2791)	Arch Hard Loss 2.4422 (2.2258)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 89.3%)	
11/17 06:07:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 0.9910 (1.3260)	Arch Loss 1.8365 (2.2724)	Arch Hard Loss 1.7815 (2.2190)	Arch Alpha Loss 0.0110 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 89.1%)	
11/17 06:07:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 61.4280%
11/17 06:07:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.1929	Prec@(1,5) (45.2%, 75.7%)
11/17 06:08:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.2108	Prec@(1,5) (44.9%, 74.7%)
11/17 06:08:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.1997	Prec@(1,5) (44.8%, 75.0%)
11/17 06:08:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.1950	Prec@(1,5) (45.0%, 75.2%)
11/17 06:08:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 45.0440%
11/17 06:08:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:08:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/17 06:10:11午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.4454 (1.2338)	Arch Loss 2.3764 (2.2185)	Arch Hard Loss 2.3244 (2.1645)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.4%)	
11/17 06:11:45午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.5203 (1.2411)	Arch Loss 2.2992 (2.2486)	Arch Hard Loss 2.2476 (2.1946)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.4%)	
11/17 06:13:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.3221 (1.2614)	Arch Loss 2.1204 (2.2592)	Arch Hard Loss 2.0688 (2.2052)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 90.1%)	
11/17 06:14:42午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.1952 (1.2664)	Arch Loss 2.8535 (2.2672)	Arch Hard Loss 2.7996 (2.2130)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.9%)	
11/17 06:14:43午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 62.7240%
11/17 06:14:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.1677	Prec@(1,5) (46.1%, 76.2%)
11/17 06:15:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.1610	Prec@(1,5) (46.1%, 76.3%)
11/17 06:15:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.1540	Prec@(1,5) (46.3%, 76.3%)
11/17 06:15:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.1549	Prec@(1,5) (46.2%, 76.4%)
11/17 06:15:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 46.2160%
11/17 06:15:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:15:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2160%
11/17 06:17:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.2133 (1.1671)	Arch Loss 2.0938 (2.2387)	Arch Hard Loss 2.0351 (2.1834)	Arch Alpha Loss 0.0117 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 91.4%)	
11/17 06:18:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.5077 (1.1762)	Arch Loss 2.7945 (2.2478)	Arch Hard Loss 2.7355 (2.1924)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.3%)	
11/17 06:20:21午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.1951 (1.1912)	Arch Loss 2.2487 (2.2523)	Arch Hard Loss 2.1895 (2.1971)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.0%)	
11/17 06:21:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.2052 (1.2027)	Arch Loss 2.8344 (2.2567)	Arch Hard Loss 2.7760 (2.2016)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.8%)	
11/17 06:21:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 64.7040%
11/17 06:22:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1946	Prec@(1,5) (45.6%, 75.7%)
11/17 06:22:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1800	Prec@(1,5) (46.0%, 76.0%)
11/17 06:22:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1802	Prec@(1,5) (45.9%, 76.1%)
11/17 06:22:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1754	Prec@(1,5) (46.1%, 76.0%)
11/17 06:22:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 46.1080%
11/17 06:22:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:22:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2160%
11/17 06:24:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 1.1633 (1.1060)	Arch Loss 2.3273 (2.2795)	Arch Hard Loss 2.2752 (2.2239)	Arch Alpha Loss 0.0104 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.6%)	
11/17 06:25:52午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.8332 (1.1141)	Arch Loss 1.9252 (2.2713)	Arch Hard Loss 1.8729 (2.2155)	Arch Alpha Loss 0.0105 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.3%)	
11/17 06:27:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.2357 (1.1295)	Arch Loss 2.4163 (2.2871)	Arch Hard Loss 2.3656 (2.2312)	Arch Alpha Loss 0.0101 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.9%)	
11/17 06:28:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.2466 (1.1365)	Arch Loss 2.3102 (2.2847)	Arch Hard Loss 2.2597 (2.2290)	Arch Alpha Loss 0.0101 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.8%)	
11/17 06:28:50午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 66.6280%
11/17 06:29:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.1332	Prec@(1,5) (46.3%, 77.5%)
11/17 06:29:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.1622	Prec@(1,5) (46.4%, 76.8%)
11/17 06:29:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.1609	Prec@(1,5) (46.2%, 76.8%)
11/17 06:29:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.1773	Prec@(1,5) (46.2%, 76.5%)
11/17 06:29:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 46.1840%
11/17 06:29:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:29:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.2160%
11/17 06:31:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 1.0707 (1.0382)	Arch Loss 2.5843 (2.3150)	Arch Hard Loss 2.5240 (2.2593)	Arch Alpha Loss 0.0121 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.4%)	
11/17 06:32:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 1.2717 (1.0526)	Arch Loss 1.8383 (2.3221)	Arch Hard Loss 1.7770 (2.2666)	Arch Alpha Loss 0.0123 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
11/17 06:34:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 1.1021 (1.0649)	Arch Loss 2.1421 (2.2968)	Arch Hard Loss 2.0811 (2.2412)	Arch Alpha Loss 0.0122 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.7%)	
11/17 06:35:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 1.0236 (1.0732)	Arch Loss 1.9512 (2.2840)	Arch Hard Loss 1.8901 (2.2286)	Arch Alpha Loss 0.0122 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.6%)	
11/17 06:35:53午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 68.2440%
11/17 06:36:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1487	Prec@(1,5) (47.1%, 77.6%)
11/17 06:36:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1469	Prec@(1,5) (47.2%, 77.2%)
11/17 06:36:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1441	Prec@(1,5) (47.0%, 77.3%)
11/17 06:36:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1493	Prec@(1,5) (47.0%, 77.0%)
11/17 06:36:50午後 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 47.0400%
11/17 06:36:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:36:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0400%
11/17 06:38:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.9004 (0.9648)	Arch Loss 2.3288 (2.2323)	Arch Hard Loss 2.2804 (2.1779)	Arch Alpha Loss 0.0097 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.0%)	
11/17 06:39:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 1.1553 (1.0020)	Arch Loss 2.0676 (2.2669)	Arch Hard Loss 2.0167 (2.2121)	Arch Alpha Loss 0.0102 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
11/17 06:41:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 1.1749 (1.0123)	Arch Loss 2.0177 (2.2754)	Arch Hard Loss 1.9633 (2.2203)	Arch Alpha Loss 0.0109 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.3%)	
11/17 06:42:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.2025 (1.0200)	Arch Loss 2.3587 (2.2753)	Arch Hard Loss 2.3057 (2.2200)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.2%)	
11/17 06:42:57午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 69.6240%
11/17 06:43:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.1969	Prec@(1,5) (47.2%, 76.9%)
11/17 06:43:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.1755	Prec@(1,5) (47.2%, 76.7%)
11/17 06:43:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.1640	Prec@(1,5) (47.4%, 77.1%)
11/17 06:43:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.1668	Prec@(1,5) (47.1%, 77.0%)
11/17 06:43:54午後 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 47.1240%
11/17 06:43:54午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:43:55午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1240%
11/17 06:45:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.7995 (0.9240)	Arch Loss 2.4239 (2.2953)	Arch Hard Loss 2.3667 (2.2397)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/17 06:47:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 1.0276 (0.9476)	Arch Loss 2.5912 (2.2888)	Arch Hard Loss 2.5371 (2.2332)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.3%)	
11/17 06:48:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.9755 (0.9595)	Arch Loss 1.9604 (2.2822)	Arch Hard Loss 1.9043 (2.2265)	Arch Alpha Loss 0.0112 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 94.1%)	
11/17 06:50:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9460 (0.9679)	Arch Loss 2.6865 (2.2935)	Arch Hard Loss 2.6308 (2.2378)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.9%)	
11/17 06:50:01午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 71.0880%
11/17 06:50:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.2392	Prec@(1,5) (46.0%, 76.5%)
11/17 06:50:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.2351	Prec@(1,5) (46.0%, 76.7%)
11/17 06:50:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.2188	Prec@(1,5) (46.6%, 76.7%)
11/17 06:50:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.2059	Prec@(1,5) (46.6%, 76.9%)
11/17 06:50:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 46.5760%
11/17 06:50:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:50:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1240%
11/17 06:52:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7976 (0.9120)	Arch Loss 1.9643 (2.2983)	Arch Hard Loss 1.9104 (2.2433)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.6%)	
11/17 06:54:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.8822 (0.9080)	Arch Loss 2.3916 (2.3132)	Arch Hard Loss 2.3361 (2.2584)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.4%)	
11/17 06:55:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.9656 (0.9190)	Arch Loss 2.7649 (2.3160)	Arch Hard Loss 2.7094 (2.2613)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/17 06:57:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.9656 (0.9212)	Arch Loss 2.3605 (2.3019)	Arch Hard Loss 2.3090 (2.2474)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.4%)	
11/17 06:57:04午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 72.9520%
11/17 06:57:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.1419	Prec@(1,5) (48.2%, 77.3%)
11/17 06:57:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.1537	Prec@(1,5) (48.4%, 77.3%)
11/17 06:57:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.1458	Prec@(1,5) (48.3%, 77.4%)
11/17 06:58:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.1626	Prec@(1,5) (47.9%, 77.1%)
11/17 06:58:01午後 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 47.8760%
11/17 06:58:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 06:58:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/17 06:59:36午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7845 (0.8750)	Arch Loss 2.6127 (2.3250)	Arch Hard Loss 2.5595 (2.2715)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.6%)	
11/17 07:01:10午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.8757 (0.8718)	Arch Loss 2.9213 (2.3031)	Arch Hard Loss 2.8682 (2.2498)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
11/17 07:02:44午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7106 (0.8775)	Arch Loss 2.0417 (2.3063)	Arch Hard Loss 1.9881 (2.2529)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.8%)	
11/17 07:04:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.8524 (0.8765)	Arch Loss 2.1653 (2.3046)	Arch Hard Loss 2.1112 (2.2510)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.8%)	
11/17 07:04:08午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 73.8280%
11/17 07:04:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.1711	Prec@(1,5) (47.8%, 77.4%)
11/17 07:04:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.1994	Prec@(1,5) (47.5%, 77.0%)
11/17 07:04:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.1995	Prec@(1,5) (47.6%, 76.9%)
11/17 07:05:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.1956	Prec@(1,5) (47.6%, 77.0%)
11/17 07:05:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 47.6240%
11/17 07:05:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 07:05:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/17 07:06:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.8405 (0.8372)	Arch Loss 2.9625 (2.2707)	Arch Hard Loss 2.9102 (2.2167)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.2%)	
11/17 07:08:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8096 (0.8311)	Arch Loss 1.8590 (2.3029)	Arch Hard Loss 1.8087 (2.2492)	Arch Alpha Loss 0.0101 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.5%)	
11/17 07:09:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.8396 (0.8239)	Arch Loss 2.2975 (2.3175)	Arch Hard Loss 2.2467 (2.2640)	Arch Alpha Loss 0.0102 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.5%)	
11/17 07:11:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.8182 (0.8380)	Arch Loss 2.8641 (2.3180)	Arch Hard Loss 2.8116 (2.2647)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.3%)	
11/17 07:11:13午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 75.1600%
11/17 07:11:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.1745	Prec@(1,5) (47.2%, 77.5%)
11/17 07:11:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.2011	Prec@(1,5) (46.8%, 77.1%)
11/17 07:11:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.1922	Prec@(1,5) (47.2%, 77.3%)
11/17 07:12:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.2001	Prec@(1,5) (47.2%, 77.2%)
11/17 07:12:09午後 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 47.1920%
11/17 07:12:09午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 07:12:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/17 07:13:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.6090 (0.7871)	Arch Loss 2.1857 (2.3683)	Arch Hard Loss 2.1346 (2.3157)	Arch Alpha Loss 0.0102 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.7%)	
11/17 07:15:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5428 (0.7859)	Arch Loss 2.3759 (2.3501)	Arch Hard Loss 2.3247 (2.2974)	Arch Alpha Loss 0.0102 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.9%)	
11/17 07:16:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7693 (0.7934)	Arch Loss 2.5330 (2.3323)	Arch Hard Loss 2.4785 (2.2795)	Arch Alpha Loss 0.0109 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.7%)	
11/17 07:18:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7143 (0.7992)	Arch Loss 2.4851 (2.3264)	Arch Hard Loss 2.4298 (2.2735)	Arch Alpha Loss 0.0111 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.6%)	
11/17 07:18:16午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 76.3200%
11/17 07:18:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.2268	Prec@(1,5) (46.7%, 76.3%)
11/17 07:18:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.2225	Prec@(1,5) (46.8%, 76.6%)
11/17 07:18:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.1956	Prec@(1,5) (47.5%, 77.2%)
11/17 07:19:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.2040	Prec@(1,5) (47.5%, 77.0%)
11/17 07:19:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 47.5160%
11/17 07:19:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 07:19:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/17 07:20:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6756 (0.7554)	Arch Loss 1.9637 (2.3070)	Arch Hard Loss 1.9122 (2.2534)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.0%)	
11/17 07:22:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 1.0307 (0.7690)	Arch Loss 2.5131 (2.3261)	Arch Hard Loss 2.4636 (2.2732)	Arch Alpha Loss 0.0099 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 95.9%)	
11/17 07:23:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.7582 (0.7807)	Arch Loss 2.4559 (2.3332)	Arch Hard Loss 2.4026 (2.2805)	Arch Alpha Loss 0.0107 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.8%)	
11/17 07:25:18午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6390 (0.7813)	Arch Loss 1.5922 (2.3252)	Arch Hard Loss 1.5372 (2.2726)	Arch Alpha Loss 0.0110 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 95.8%)	
11/17 07:25:19午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 76.8400%
11/17 07:25:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.2330	Prec@(1,5) (47.6%, 76.9%)
11/17 07:25:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.2394	Prec@(1,5) (47.4%, 76.8%)
11/17 07:26:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.2300	Prec@(1,5) (47.6%, 77.0%)
11/17 07:26:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.2225	Prec@(1,5) (47.6%, 77.1%)
11/17 07:26:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 47.6120%
11/17 07:26:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 07:26:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/17 07:27:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.7171 (0.7170)	Arch Loss 2.0767 (2.3218)	Arch Hard Loss 2.0247 (2.2692)	Arch Alpha Loss 0.0104 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.5%)	
11/17 07:29:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.6849 (0.7252)	Arch Loss 2.8337 (2.3242)	Arch Hard Loss 2.7831 (2.2714)	Arch Alpha Loss 0.0101 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.5%)	
11/17 07:30:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.8205 (0.7372)	Arch Loss 2.7847 (2.3399)	Arch Hard Loss 2.7330 (2.2869)	Arch Alpha Loss 0.0104 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.4%)	
11/17 07:32:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7858 (0.7496)	Arch Loss 2.3665 (2.3463)	Arch Hard Loss 2.3139 (2.2934)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.2%)	
11/17 07:32:23午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 77.7040%
11/17 07:32:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.2127	Prec@(1,5) (48.2%, 77.3%)
11/17 07:32:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.2366	Prec@(1,5) (47.7%, 76.8%)
11/17 07:33:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.2287	Prec@(1,5) (47.5%, 77.1%)
11/17 07:33:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.2311	Prec@(1,5) (47.6%, 77.2%)
11/17 07:33:20午後 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 47.5800%
11/17 07:33:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(10, 12))
11/17 07:33:20午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8760%
11/17 07:34:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6941 (0.7176)	Arch Loss 1.8293 (2.3084)	Arch Hard Loss 1.7750 (2.2559)	Arch Alpha Loss 0.0109 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.5%)	
11/17 07:36:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6193 (0.7300)	Arch Loss 2.1976 (2.3381)	Arch Hard Loss 2.1421 (2.2854)	Arch Alpha Loss 0.0111 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.4%)	
11/17 07:38:01午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.6404 (0.7287)	Arch Loss 2.3937 (2.3403)	Arch Hard Loss 2.3411 (2.2875)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.3%)	
11/17 07:39:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.8112 (0.7278)	Arch Loss 2.5144 (2.3500)	Arch Hard Loss 2.4597 (2.2974)	Arch Alpha Loss 0.0109 (0.0105)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.4%)	
11/17 07:39:26午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 78.4240%
11/17 07:39:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.2261	Prec@(1,5) (48.4%, 77.8%)
11/17 07:39:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.2132	Prec@(1,5) (48.0%, 77.8%)
11/17 07:40:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.2213	Prec@(1,5) (48.1%, 77.5%)
11/17 07:40:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.2272	Prec@(1,5) (47.9%, 77.2%)
11/17 07:40:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 47.9040%
11/17 07:40:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/17 07:40:24午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9040%
11/17 07:41:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4940 (0.6741)	Arch Loss 2.4123 (2.3582)	Arch Hard Loss 2.3623 (2.3048)	Arch Alpha Loss 0.0100 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.2%)	
11/17 07:43:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.8225 (0.7045)	Arch Loss 2.5130 (2.3587)	Arch Hard Loss 2.4615 (2.3052)	Arch Alpha Loss 0.0103 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.7%)	
11/17 07:45:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.9562 (0.7070)	Arch Loss 2.3191 (2.3602)	Arch Hard Loss 2.2660 (2.3064)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.7%)	
11/17 07:46:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6770 (0.7099)	Arch Loss 1.6444 (2.3499)	Arch Hard Loss 1.5905 (2.2959)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.6%)	
11/17 07:46:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 78.9200%
11/17 07:46:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.2552	Prec@(1,5) (47.4%, 76.6%)
11/17 07:46:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.2680	Prec@(1,5) (47.4%, 76.7%)
11/17 07:47:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.2608	Prec@(1,5) (47.7%, 76.9%)
11/17 07:47:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.2528	Prec@(1,5) (47.9%, 76.9%)
11/17 07:47:27午後 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 47.9160%
11/17 07:47:27午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/17 07:47:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.9160%
11/17 07:47:27午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 47.9160%
11/17 07:47:27午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
