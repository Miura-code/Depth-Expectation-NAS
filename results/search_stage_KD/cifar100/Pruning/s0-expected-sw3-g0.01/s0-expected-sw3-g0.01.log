11/22 06:05:37AM parser.py:28 [INFO] 
11/22 06:05:37AM parser.py:29 [INFO] Parameters:
11/22 06:05:37AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected-sw3-g0.01/DAG
11/22 06:05:37AM parser.py:31 [INFO] T=10.0
11/22 06:05:37AM parser.py:31 [INFO] ADVANCED=1
11/22 06:05:37AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/22 06:05:37AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/22 06:05:37AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/22 06:05:37AM parser.py:31 [INFO] BATCH_SIZE=64
11/22 06:05:37AM parser.py:31 [INFO] CASCADE=0
11/22 06:05:37AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/22 06:05:37AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[]
11/22 06:05:37AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/22 06:05:37AM parser.py:31 [INFO] DATA_PATH=../data/
11/22 06:05:37AM parser.py:31 [INFO] DATASET=cifar100
11/22 06:05:37AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/22 06:05:37AM parser.py:31 [INFO] DESCRIPTION=search_with_-Beta-expected-Depth-constraint_slidewindow-3
11/22 06:05:37AM parser.py:31 [INFO] DISCRETE=0
11/22 06:05:37AM parser.py:31 [INFO] EPOCHS=50
11/22 06:05:37AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/22 06:05:37AM parser.py:31 [INFO] EXP_NAME=s0-expected-sw3-g0.01
11/22 06:05:37AM parser.py:31 [INFO] FINAL_L=0.0
11/22 06:05:37AM parser.py:31 [INFO] G=0.01
11/22 06:05:37AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/22 06:05:37AM parser.py:31 [INFO] GPUS=[0]
11/22 06:05:37AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/22 06:05:37AM parser.py:31 [INFO] INIT_CHANNELS=16
11/22 06:05:37AM parser.py:31 [INFO] L=0.0
11/22 06:05:37AM parser.py:31 [INFO] LAYERS=32
11/22 06:05:37AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/22 06:05:37AM parser.py:31 [INFO] NAME=Pruning
11/22 06:05:37AM parser.py:31 [INFO] NONKD=1
11/22 06:05:37AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-expected-sw3-g0.01
11/22 06:05:37AM parser.py:31 [INFO] PCDARTS=0
11/22 06:05:37AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-expected-sw3-g0.01/plots
11/22 06:05:37AM parser.py:31 [INFO] PRINT_FREQ=100
11/22 06:05:37AM parser.py:31 [INFO] RESET=0
11/22 06:05:37AM parser.py:31 [INFO] RESUME_PATH=None
11/22 06:05:37AM parser.py:31 [INFO] SAVE=s0-expected-sw3-g0.01
11/22 06:05:37AM parser.py:31 [INFO] SEED=0
11/22 06:05:37AM parser.py:31 [INFO] SHARE_STAGE=0
11/22 06:05:37AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/22 06:05:37AM parser.py:31 [INFO] SPEC_CELL=1
11/22 06:05:37AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/22 06:05:37AM parser.py:31 [INFO] TEACHER_NAME=none
11/22 06:05:37AM parser.py:31 [INFO] TEACHER_PATH=none
11/22 06:05:37AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/22 06:05:37AM parser.py:31 [INFO] TYPE=Pruning
11/22 06:05:37AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/22 06:05:37AM parser.py:31 [INFO] W_LR=0.025
11/22 06:05:37AM parser.py:31 [INFO] W_LR_MIN=0.001
11/22 06:05:37AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/22 06:05:37AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/22 06:05:37AM parser.py:31 [INFO] WORKERS=4
11/22 06:05:37AM parser.py:32 [INFO] 
11/22 06:05:38AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/22 06:06:33AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.4910 (4.5867)	Arch Loss 8.0124 (8.1570)	Arch Hard Loss 4.4939 (4.5970)	Arch Beta Loss 351.8473 (356.0070)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.7%, 7.5%)	
11/22 06:07:28AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 3.9513 (4.4492)	Arch Loss 7.6405 (7.9638)	Arch Hard Loss 4.2049 (4.4455)	Arch Beta Loss 343.5646 (351.8279)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.3%, 12.7%)	
11/22 06:08:21AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0454 (4.3196)	Arch Loss 7.3112 (7.8009)	Arch Hard Loss 3.9567 (4.3238)	Arch Beta Loss 335.4473 (347.7029)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.6%, 16.6%)	
11/22 06:09:09AM searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8629 (4.2403)	Arch Loss 7.1511 (7.6774)	Arch Hard Loss 3.8678 (4.2370)	Arch Beta Loss 328.3352 (344.0415)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 19.1%)	
11/22 06:09:10AM searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  0/49] Final Prec@1 5.5240%
11/22 06:09:18AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9532	Prec@(1,5) (8.5%, 29.3%)
11/22 06:09:26AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9367	Prec@(1,5) (8.7%, 29.6%)
11/22 06:09:34AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9354	Prec@(1,5) (8.8%, 29.7%)
11/22 06:09:41AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9336	Prec@(1,5) (8.9%, 29.7%)
11/22 06:09:41AM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 8.9040%
11/22 06:09:41AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 7])
11/22 06:09:42AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 8.9040%
11/22 06:10:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.6683 (3.8392)	Arch Loss 7.1888 (7.0777)	Arch Hard Loss 3.9835 (3.8343)	Arch Beta Loss 320.5385 (324.3346)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.4%, 32.0%)	
11/22 06:11:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.6008 (3.8075)	Arch Loss 6.9154 (6.9917)	Arch Hard Loss 3.7853 (3.7865)	Arch Beta Loss 313.0178 (320.5273)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.6%, 32.8%)	
11/22 06:12:24午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.6687 (3.7659)	Arch Loss 6.5419 (6.9134)	Arch Hard Loss 3.4851 (3.7456)	Arch Beta Loss 305.6759 (316.7829)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.3%, 33.9%)	
11/22 06:13:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7978 (3.7180)	Arch Loss 6.8954 (6.8441)	Arch Hard Loss 3.9026 (3.7094)	Arch Beta Loss 299.2820 (313.4691)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (12.1%, 35.4%)	
11/22 06:13:13午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  1/49] Final Prec@1 12.0960%
11/22 06:13:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5690	Prec@(1,5) (14.3%, 39.1%)
11/22 06:13:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5659	Prec@(1,5) (14.7%, 39.5%)
11/22 06:13:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5747	Prec@(1,5) (14.5%, 39.4%)
11/22 06:13:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5645	Prec@(1,5) (14.6%, 39.9%)
11/22 06:13:44午前 searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 14.5400%
11/22 06:13:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG3_concat=[2, 7])
11/22 06:13:44午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.5400%
11/22 06:14:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.5756 (3.5142)	Arch Loss 6.3854 (6.4493)	Arch Hard Loss 3.4627 (3.4923)	Arch Beta Loss 292.2636 (295.6979)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.1%)	
11/22 06:15:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.3120 (3.4704)	Arch Loss 6.2444 (6.3957)	Arch Hard Loss 3.3887 (3.4728)	Arch Beta Loss 285.5680 (292.2853)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.0%, 42.2%)	
11/22 06:16:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.2640 (3.4341)	Arch Loss 6.0842 (6.3283)	Arch Hard Loss 3.2941 (3.4390)	Arch Beta Loss 279.0095 (288.9309)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.7%, 43.3%)	
11/22 06:17:16午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.3058 (3.4051)	Arch Loss 5.9881 (6.2725)	Arch Hard Loss 3.2560 (3.4129)	Arch Beta Loss 273.2155 (285.9596)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.3%, 44.1%)	
11/22 06:17:16午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  2/49] Final Prec@1 17.2600%
11/22 06:17:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.2862	Prec@(1,5) (19.8%, 48.3%)
11/22 06:17:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3045	Prec@(1,5) (19.4%, 47.6%)
11/22 06:17:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3038	Prec@(1,5) (19.5%, 47.6%)
11/22 06:17:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3013	Prec@(1,5) (19.7%, 47.7%)
11/22 06:17:47午前 searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 19.6600%
11/22 06:17:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[2, 5])
11/22 06:17:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.6600%
11/22 06:18:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.6945 (3.2597)	Arch Loss 5.8612 (5.9566)	Arch Hard Loss 3.1920 (3.2566)	Arch Beta Loss 266.9208 (270.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.1%, 47.5%)	
11/22 06:19:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 2.9244 (3.2198)	Arch Loss 5.9132 (5.9055)	Arch Hard Loss 3.3046 (3.2363)	Arch Beta Loss 260.8566 (266.9205)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.7%, 49.3%)	
11/22 06:20:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 2.9499 (3.1797)	Arch Loss 5.8526 (5.8474)	Arch Hard Loss 3.3033 (3.2085)	Arch Beta Loss 254.9305 (263.8917)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.2%, 50.2%)	
11/22 06:21:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9529 (3.1559)	Arch Loss 5.6777 (5.8006)	Arch Hard Loss 3.1806 (3.1885)	Arch Beta Loss 249.7112 (261.2108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.7%, 51.0%)	
11/22 06:21:19午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  3/49] Final Prec@1 21.7360%
11/22 06:21:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.0957	Prec@(1,5) (22.6%, 52.3%)
11/22 06:21:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1033	Prec@(1,5) (22.4%, 52.3%)
11/22 06:21:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1057	Prec@(1,5) (22.3%, 52.2%)
11/22 06:21:50午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1065	Prec@(1,5) (22.3%, 52.1%)
11/22 06:21:50午前 searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 22.3520%
11/22 06:21:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[2, 5])
11/22 06:21:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 22.3520%
11/22 06:22:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.8928 (2.9994)	Arch Loss 5.2253 (5.5723)	Arch Hard Loss 2.7848 (3.1042)	Arch Beta Loss 244.0513 (246.8073)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.3%, 56.0%)	
11/22 06:23:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.9173 (2.9782)	Arch Loss 5.1914 (5.5018)	Arch Hard Loss 2.8053 (3.0613)	Arch Beta Loss 238.6125 (244.0489)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.3%, 56.1%)	
11/22 06:24:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.5871 (2.9663)	Arch Loss 5.4517 (5.4526)	Arch Hard Loss 3.1189 (3.0393)	Arch Beta Loss 233.2784 (241.3342)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.6%, 56.1%)	
11/22 06:25:22午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8274 (2.9534)	Arch Loss 5.1120 (5.3997)	Arch Hard Loss 2.8270 (3.0106)	Arch Beta Loss 228.5022 (238.9160)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.5%)	
11/22 06:25:22午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  4/49] Final Prec@1 25.7600%
11/22 06:25:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0110	Prec@(1,5) (24.6%, 56.0%)
11/22 06:25:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9808	Prec@(1,5) (24.9%, 56.7%)
11/22 06:25:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9796	Prec@(1,5) (25.0%, 56.5%)
11/22 06:25:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9779	Prec@(1,5) (25.2%, 56.6%)
11/22 06:25:53午前 searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 25.2360%
11/22 06:25:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG3_concat=[2, 5])
11/22 06:25:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.2360%
11/22 06:26:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.0150 (2.7890)	Arch Loss 5.0146 (5.1370)	Arch Hard Loss 2.7810 (2.8782)	Arch Beta Loss 223.3571 (225.8813)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.6%, 60.1%)	
11/22 06:27:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.0425 (2.7820)	Arch Loss 5.4161 (5.1150)	Arch Hard Loss 3.2323 (2.8814)	Arch Beta Loss 218.3796 (223.3578)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.9%, 60.5%)	
11/22 06:28:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.7516 (2.7790)	Arch Loss 4.6760 (5.0724)	Arch Hard Loss 2.5413 (2.8636)	Arch Beta Loss 213.4750 (220.8710)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.0%, 60.5%)	
11/22 06:29:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.6300 (2.7710)	Arch Loss 4.8284 (5.0357)	Arch Hard Loss 2.7358 (2.8489)	Arch Beta Loss 209.2669 (218.6723)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.0%, 61.0%)	
11/22 06:29:25午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  5/49] Final Prec@1 28.9560%
11/22 06:29:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8027	Prec@(1,5) (27.9%, 60.8%)
11/22 06:29:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8108	Prec@(1,5) (28.5%, 60.4%)
11/22 06:29:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8144	Prec@(1,5) (28.6%, 60.2%)
11/22 06:29:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8089	Prec@(1,5) (28.7%, 60.3%)
11/22 06:29:56午前 searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 28.7080%
11/22 06:29:56午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 5])
11/22 06:29:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.7080%
11/22 06:30:52午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.6829 (2.6369)	Arch Loss 5.0967 (4.8128)	Arch Hard Loss 3.0505 (2.7439)	Arch Beta Loss 204.6222 (206.8847)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.5%, 63.9%)	
11/22 06:31:46午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.6887 (2.6412)	Arch Loss 4.7395 (4.7783)	Arch Hard Loss 2.7380 (2.7321)	Arch Beta Loss 200.1453 (204.6186)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.7%, 64.0%)	
11/22 06:32:40午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.7932 (2.6364)	Arch Loss 4.4922 (4.7379)	Arch Hard Loss 2.5340 (2.7139)	Arch Beta Loss 195.8151 (202.3989)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.5%, 64.2%)	
11/22 06:33:29午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7739 (2.6296)	Arch Loss 4.6398 (4.7205)	Arch Hard Loss 2.7198 (2.7162)	Arch Beta Loss 191.9967 (200.4288)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.4%)	
11/22 06:33:29午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  6/49] Final Prec@1 31.7400%
11/22 06:33:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6432	Prec@(1,5) (32.3%, 64.4%)
11/22 06:33:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6317	Prec@(1,5) (32.3%, 64.6%)
11/22 06:33:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6368	Prec@(1,5) (32.4%, 64.5%)
11/22 06:34:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6450	Prec@(1,5) (32.4%, 64.2%)
11/22 06:34:01午前 searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 32.3760%
11/22 06:34:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[2, 5])
11/22 06:34:02午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.3760%
11/22 06:34:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.6265 (2.4839)	Arch Loss 4.5349 (4.5476)	Arch Hard Loss 2.6566 (2.6490)	Arch Beta Loss 187.8341 (189.8650)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 67.7%)	
11/22 06:35:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.4061 (2.4970)	Arch Loss 4.3498 (4.5140)	Arch Hard Loss 2.5121 (2.6357)	Arch Beta Loss 183.7736 (187.8238)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.4%, 67.2%)	
11/22 06:36:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.6742 (2.4947)	Arch Loss 5.0760 (4.4921)	Arch Hard Loss 3.2772 (2.6340)	Arch Beta Loss 179.8772 (185.8138)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.9%, 67.3%)	
11/22 06:37:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.6466 (2.4885)	Arch Loss 4.3785 (4.4515)	Arch Hard Loss 2.6137 (2.6111)	Arch Beta Loss 176.4734 (184.0435)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.1%, 67.3%)	
11/22 06:37:34午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  7/49] Final Prec@1 35.0640%
11/22 06:37:42午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5699	Prec@(1,5) (33.5%, 65.2%)
11/22 06:37:50午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5564	Prec@(1,5) (33.6%, 66.0%)
11/22 06:37:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5482	Prec@(1,5) (33.7%, 66.3%)
11/22 06:38:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5575	Prec@(1,5) (33.5%, 66.0%)
11/22 06:38:05午前 searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 33.4960%
11/22 06:38:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[2, 5])
11/22 06:38:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.4960%
11/22 06:39:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4356 (2.3507)	Arch Loss 4.5706 (4.2723)	Arch Hard Loss 2.8438 (2.5270)	Arch Beta Loss 172.6792 (174.5349)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 70.5%)	
11/22 06:39:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.0620 (2.3616)	Arch Loss 4.4811 (4.2606)	Arch Hard Loss 2.7902 (2.5335)	Arch Beta Loss 169.0913 (172.7064)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.4%, 70.6%)	
11/22 06:40:47午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.4019 (2.3669)	Arch Loss 4.0969 (4.2404)	Arch Hard Loss 2.4411 (2.5313)	Arch Beta Loss 165.5741 (170.9045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.6%)	
11/22 06:41:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.0180 (2.3635)	Arch Loss 4.1489 (4.2125)	Arch Hard Loss 2.5239 (2.5194)	Arch Beta Loss 162.5043 (169.3138)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.6%)	
11/22 06:41:36午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  8/49] Final Prec@1 37.5400%
11/22 06:41:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4536	Prec@(1,5) (35.8%, 68.3%)
11/22 06:41:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4597	Prec@(1,5) (35.5%, 68.2%)
11/22 06:42:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4727	Prec@(1,5) (35.4%, 67.9%)
11/22 06:42:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4704	Prec@(1,5) (35.4%, 68.1%)
11/22 06:42:07午前 searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 35.4160%
11/22 06:42:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=[2, 3])
11/22 06:42:07午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.4160%
11/22 06:43:02午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.4139 (2.2569)	Arch Loss 4.4327 (4.0715)	Arch Hard Loss 2.8412 (2.4637)	Arch Beta Loss 159.1475 (160.7823)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.9%, 72.1%)	
11/22 06:43:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.3743 (2.2743)	Arch Loss 4.0381 (4.0264)	Arch Hard Loss 2.4791 (2.4350)	Arch Beta Loss 155.8972 (159.1437)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.5%, 71.8%)	
11/22 06:44:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.2508 (2.2662)	Arch Loss 3.7308 (4.0025)	Arch Hard Loss 2.2031 (2.4272)	Arch Beta Loss 152.7672 (157.5315)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 71.8%)	
11/22 06:45:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.2379 (2.2659)	Arch Loss 3.9374 (3.9861)	Arch Hard Loss 2.4372 (2.4250)	Arch Beta Loss 150.0253 (156.1100)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.6%, 72.0%)	
11/22 06:45:39午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [  9/49] Final Prec@1 39.5640%
11/22 06:45:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4872	Prec@(1,5) (34.7%, 68.2%)
11/22 06:45:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4809	Prec@(1,5) (35.0%, 68.4%)
11/22 06:46:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.5018	Prec@(1,5) (34.7%, 68.1%)
11/22 06:46:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4977	Prec@(1,5) (34.8%, 68.2%)
11/22 06:46:10午前 searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 34.8080%
11/22 06:46:10午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 06:46:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.4160%
11/22 06:47:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.3091 (2.1567)	Arch Loss 3.8449 (3.8820)	Arch Hard Loss 2.3748 (2.3972)	Arch Beta Loss 147.0092 (148.4801)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.5%, 74.7%)	
11/22 06:47:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.3361 (2.1752)	Arch Loss 3.6836 (3.8501)	Arch Hard Loss 2.2425 (2.3799)	Arch Beta Loss 144.1123 (147.0124)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.0%, 74.1%)	
11/22 06:48:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3273 (2.1810)	Arch Loss 3.6070 (3.8239)	Arch Hard Loss 2.1939 (2.3682)	Arch Beta Loss 141.3113 (145.5726)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 74.0%)	
11/22 06:49:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.2959 (2.1733)	Arch Loss 3.5603 (3.8044)	Arch Hard Loss 2.1724 (2.3615)	Arch Beta Loss 138.7851 (144.2921)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 74.1%)	
11/22 06:49:42午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 10/49] Final Prec@1 41.4240%
11/22 06:49:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3413	Prec@(1,5) (38.9%, 71.0%)
11/22 06:49:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3095	Prec@(1,5) (39.0%, 71.5%)
11/22 06:50:06午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3243	Prec@(1,5) (38.9%, 71.1%)
11/22 06:50:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3203	Prec@(1,5) (38.9%, 71.2%)
11/22 06:50:13午前 searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 38.8840%
11/22 06:50:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 06:50:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.8840%
11/22 06:51:09午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 1.8259 (2.0992)	Arch Loss 4.0503 (3.7042)	Arch Hard Loss 2.6894 (2.3302)	Arch Beta Loss 136.0965 (137.4003)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 75.6%)	
11/22 06:52:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4315 (2.0826)	Arch Loss 3.9380 (3.6870)	Arch Hard Loss 2.6034 (2.3262)	Arch Beta Loss 133.4688 (136.0774)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 75.8%)	
11/22 06:52:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.2320 (2.0808)	Arch Loss 3.4474 (3.6606)	Arch Hard Loss 2.1384 (2.3128)	Arch Beta Loss 130.9008 (134.7770)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 76.0%)	
11/22 06:53:46午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.8537 (2.0888)	Arch Loss 3.5632 (3.6450)	Arch Hard Loss 2.2767 (2.3088)	Arch Beta Loss 128.6568 (133.6228)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 75.8%)	
11/22 06:53:46午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 11/49] Final Prec@1 43.3880%
11/22 06:53:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.2424	Prec@(1,5) (40.6%, 73.0%)
11/22 06:54:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2365	Prec@(1,5) (40.6%, 73.0%)
11/22 06:54:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2324	Prec@(1,5) (40.7%, 73.2%)
11/22 06:54:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2288	Prec@(1,5) (40.9%, 73.2%)
11/22 06:54:17午前 searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 40.9240%
11/22 06:54:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 06:54:18午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.9240%
11/22 06:55:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.8657 (1.9818)	Arch Loss 3.3925 (3.5477)	Arch Hard Loss 2.1305 (2.2737)	Arch Beta Loss 126.2038 (127.4001)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.3%, 78.6%)	
11/22 06:56:07午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 1.9947 (2.0075)	Arch Loss 3.2071 (3.5322)	Arch Hard Loss 1.9686 (2.2702)	Arch Beta Loss 123.8457 (126.2010)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.8%, 78.2%)	
11/22 06:57:01午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.8330 (2.0141)	Arch Loss 3.5432 (3.5098)	Arch Hard Loss 2.3284 (2.2596)	Arch Beta Loss 121.4847 (125.0139)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.8%, 77.8%)	
11/22 06:57:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.6388 (2.0148)	Arch Loss 3.4834 (3.4841)	Arch Hard Loss 2.2893 (2.2446)	Arch Beta Loss 119.4069 (123.9585)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.8%, 77.8%)	
11/22 06:57:51午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 12/49] Final Prec@1 44.8360%
11/22 06:57:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3065	Prec@(1,5) (39.7%, 71.9%)
11/22 06:58:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2947	Prec@(1,5) (39.5%, 72.2%)
11/22 06:58:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2965	Prec@(1,5) (39.7%, 72.2%)
11/22 06:58:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.3035	Prec@(1,5) (39.6%, 71.9%)
11/22 06:58:22午前 searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 39.6200%
11/22 06:58:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 06:58:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.9240%
11/22 06:59:16午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.9989 (1.8905)	Arch Loss 3.5005 (3.3723)	Arch Hard Loss 2.3292 (2.1899)	Arch Beta Loss 117.1301 (118.2405)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 80.3%)	
11/22 07:00:10午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.7027 (1.9362)	Arch Loss 3.3133 (3.3609)	Arch Hard Loss 2.1642 (2.1897)	Arch Beta Loss 114.9124 (117.1266)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 79.4%)	
11/22 07:01:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.7525 (1.9384)	Arch Loss 3.0347 (3.3470)	Arch Hard Loss 1.9060 (2.1866)	Arch Beta Loss 112.8731 (116.0425)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 79.3%)	
11/22 07:01:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.7964 (1.9437)	Arch Loss 3.1535 (3.3313)	Arch Hard Loss 2.0433 (2.1803)	Arch Beta Loss 111.0230 (115.0937)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 79.2%)	
11/22 07:01:54午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 13/49] Final Prec@1 46.4520%
11/22 07:02:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1405	Prec@(1,5) (43.0%, 75.2%)
11/22 07:02:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1655	Prec@(1,5) (42.6%, 74.7%)
11/22 07:02:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1480	Prec@(1,5) (43.0%, 75.0%)
11/22 07:02:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1516	Prec@(1,5) (42.9%, 74.7%)
11/22 07:02:25午前 searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 42.8400%
11/22 07:02:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 07:02:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.8400%
11/22 07:03:20午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.8375 (1.8295)	Arch Loss 3.3436 (3.2899)	Arch Hard Loss 2.2542 (2.1904)	Arch Beta Loss 108.9347 (109.9484)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 81.0%)	
11/22 07:04:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.8869 (1.8602)	Arch Loss 3.2875 (3.2663)	Arch Hard Loss 2.2175 (2.1768)	Arch Beta Loss 107.0005 (108.9503)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.0%)	
11/22 07:05:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.1250 (1.8628)	Arch Loss 3.1142 (3.2469)	Arch Hard Loss 2.0631 (2.1672)	Arch Beta Loss 105.1111 (107.9768)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.2%)	
11/22 07:05:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.7944 (1.8672)	Arch Loss 3.1976 (3.2278)	Arch Hard Loss 2.1628 (2.1565)	Arch Beta Loss 103.4796 (107.1250)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.2%, 80.1%)	
11/22 07:05:57午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 14/49] Final Prec@1 48.1840%
11/22 07:06:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.0562	Prec@(1,5) (45.6%, 76.2%)
11/22 07:06:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.0785	Prec@(1,5) (44.8%, 75.7%)
11/22 07:06:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0854	Prec@(1,5) (44.3%, 75.8%)
11/22 07:06:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0854	Prec@(1,5) (44.3%, 76.0%)
11/22 07:06:27午前 searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 44.3440%
11/22 07:06:27午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 07:06:28午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.3440%
11/22 07:07:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.0731 (1.7655)	Arch Loss 3.1648 (3.1200)	Arch Hard Loss 2.1480 (2.0944)	Arch Beta Loss 101.6713 (102.5538)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.1%)	
11/22 07:08:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.6338 (1.7818)	Arch Loss 2.7840 (3.1224)	Arch Hard Loss 1.7849 (2.1058)	Arch Beta Loss 99.9121 (101.6573)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.5%)	
11/22 07:09:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.9764 (1.7861)	Arch Loss 2.8570 (3.1181)	Arch Hard Loss 1.8756 (2.1104)	Arch Beta Loss 98.1426 (100.7736)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.5%)	
11/22 07:09:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.5969 (1.7965)	Arch Loss 2.7855 (3.1098)	Arch Hard Loss 1.8195 (2.1099)	Arch Beta Loss 96.6084 (99.9884)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.3%)	
11/22 07:10:00午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 15/49] Final Prec@1 50.3080%
11/22 07:10:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1547	Prec@(1,5) (42.9%, 75.0%)
11/22 07:10:16午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1382	Prec@(1,5) (42.9%, 75.3%)
11/22 07:10:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1532	Prec@(1,5) (42.6%, 75.2%)
11/22 07:10:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1421	Prec@(1,5) (42.8%, 75.4%)
11/22 07:10:30午前 searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 42.7520%
11/22 07:10:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 07:10:31午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.3440%
11/22 07:11:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.5182 (1.6987)	Arch Loss 2.8528 (3.0326)	Arch Hard Loss 1.9036 (2.0751)	Arch Beta Loss 94.9248 (95.7517)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.3%, 82.7%)	
11/22 07:12:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.7745 (1.7270)	Arch Loss 2.9958 (3.0199)	Arch Hard Loss 2.0625 (2.0705)	Arch Beta Loss 93.3222 (94.9333)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.7%)	
11/22 07:13:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.7054 (1.7422)	Arch Loss 3.0622 (3.0262)	Arch Hard Loss 2.1444 (2.0849)	Arch Beta Loss 91.7812 (94.1346)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.3%)	
11/22 07:14:01午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.7038 (1.7456)	Arch Loss 2.9653 (3.0080)	Arch Hard Loss 2.0612 (2.0737)	Arch Beta Loss 90.4121 (93.4306)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.3%)	
11/22 07:14:02午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 16/49] Final Prec@1 51.2160%
11/22 07:14:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0631	Prec@(1,5) (44.8%, 75.9%)
11/22 07:14:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0512	Prec@(1,5) (45.0%, 76.6%)
11/22 07:14:25午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0534	Prec@(1,5) (45.0%, 76.7%)
11/22 07:14:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0449	Prec@(1,5) (45.3%, 76.9%)
11/22 07:14:33午前 searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 45.2800%
11/22 07:14:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 3])
11/22 07:14:33午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.2800%
11/22 07:15:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.5081 (1.6265)	Arch Loss 2.9211 (2.9353)	Arch Hard Loss 2.0322 (2.0390)	Arch Beta Loss 88.8923 (89.6392)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.2%)	
11/22 07:16:22午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.5671 (1.6601)	Arch Loss 2.8120 (2.9281)	Arch Hard Loss 1.9376 (2.0391)	Arch Beta Loss 87.4449 (88.8990)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.7%, 83.8%)	
11/22 07:17:16午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.0111 (1.6746)	Arch Loss 2.7315 (2.9294)	Arch Hard Loss 1.8716 (2.0478)	Arch Beta Loss 85.9862 (88.1618)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.2%, 83.7%)	
11/22 07:18:04午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.3076 (1.6877)	Arch Loss 2.8805 (2.9291)	Arch Hard Loss 2.0336 (2.0540)	Arch Beta Loss 84.6953 (87.5093)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.5%)	
11/22 07:18:05午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 17/49] Final Prec@1 52.5360%
11/22 07:18:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0037	Prec@(1,5) (45.7%, 77.7%)
11/22 07:18:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9878	Prec@(1,5) (46.0%, 77.9%)
11/22 07:18:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9959	Prec@(1,5) (46.1%, 77.7%)
11/22 07:18:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9993	Prec@(1,5) (45.9%, 77.6%)
11/22 07:18:36午前 searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 45.9520%
11/22 07:18:36午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 3])
11/22 07:18:36午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.9520%
11/22 07:19:31午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4815 (1.5819)	Arch Loss 2.8223 (2.8399)	Arch Hard Loss 1.9889 (1.9999)	Arch Beta Loss 83.3433 (84.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.2%)	
11/22 07:20:26午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4335 (1.6217)	Arch Loss 2.6920 (2.8539)	Arch Hard Loss 1.8723 (2.0206)	Arch Beta Loss 81.9683 (83.3213)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.4%)	
11/22 07:21:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6265 (1.6220)	Arch Loss 2.9400 (2.8479)	Arch Hard Loss 2.1331 (2.0214)	Arch Beta Loss 80.6896 (82.6570)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.2%)	
11/22 07:22:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.7596 (1.6330)	Arch Loss 2.1066 (2.8292)	Arch Hard Loss 1.3111 (2.0085)	Arch Beta Loss 79.5553 (82.0685)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.2%)	
11/22 07:22:09午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 18/49] Final Prec@1 54.0440%
11/22 07:22:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0050	Prec@(1,5) (46.4%, 78.0%)
11/22 07:22:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9958	Prec@(1,5) (46.6%, 78.2%)
11/22 07:22:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9970	Prec@(1,5) (46.6%, 78.2%)
11/22 07:22:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0006	Prec@(1,5) (46.4%, 78.2%)
11/22 07:22:39午前 searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 46.4560%
11/22 07:22:39午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 07:22:40午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.4560%
11/22 07:23:35午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.1914 (1.5306)	Arch Loss 2.9677 (2.7790)	Arch Hard Loss 2.1848 (1.9900)	Arch Beta Loss 78.2911 (78.9041)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.6%, 85.9%)	
11/22 07:24:28午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.8248 (1.5601)	Arch Loss 3.0189 (2.7698)	Arch Hard Loss 2.2473 (1.9868)	Arch Beta Loss 77.1596 (78.3047)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.7%)	
11/22 07:25:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.9294 (1.5747)	Arch Loss 2.4064 (2.7488)	Arch Hard Loss 1.6470 (1.9716)	Arch Beta Loss 75.9420 (77.7163)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.4%, 85.5%)	
11/22 07:26:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.5394 (1.5904)	Arch Loss 2.7114 (2.7448)	Arch Hard Loss 1.9622 (1.9730)	Arch Beta Loss 74.9193 (77.1833)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.9%, 85.1%)	
11/22 07:26:12午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 19/49] Final Prec@1 54.8960%
11/22 07:26:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9887	Prec@(1,5) (47.4%, 77.5%)
11/22 07:26:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9954	Prec@(1,5) (47.2%, 77.7%)
11/22 07:26:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9817	Prec@(1,5) (47.3%, 77.9%)
11/22 07:26:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9774	Prec@(1,5) (47.2%, 78.0%)
11/22 07:26:43午前 searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 47.2480%
11/22 07:26:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 07:26:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.2480%
11/22 07:27:38午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.4648 (1.4768)	Arch Loss 2.5888 (2.6866)	Arch Hard Loss 1.8510 (1.9431)	Arch Beta Loss 73.7878 (74.3458)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.9%)	
11/22 07:28:32午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.4681 (1.4973)	Arch Loss 3.4289 (2.6878)	Arch Hard Loss 2.7016 (1.9498)	Arch Beta Loss 72.7311 (73.7970)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.8%)	
11/22 07:29:26午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.1337 (1.5066)	Arch Loss 2.3486 (2.6775)	Arch Hard Loss 1.6325 (1.9449)	Arch Beta Loss 71.6122 (73.2588)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.5%)	
11/22 07:30:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.6876 (1.5310)	Arch Loss 2.1382 (2.6724)	Arch Hard Loss 1.4317 (1.9448)	Arch Beta Loss 70.6491 (72.7635)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.1%)	
11/22 07:30:15午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 20/49] Final Prec@1 56.5240%
11/22 07:30:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9283	Prec@(1,5) (49.2%, 78.8%)
11/22 07:30:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9187	Prec@(1,5) (49.0%, 79.1%)
11/22 07:30:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9274	Prec@(1,5) (48.7%, 79.1%)
11/22 07:30:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9341	Prec@(1,5) (48.4%, 79.0%)
11/22 07:30:46午前 searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 48.4400%
11/22 07:30:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 07:30:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4400%
11/22 07:31:41午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.4725 (1.4231)	Arch Loss 2.7852 (2.6610)	Arch Hard Loss 2.0893 (1.9599)	Arch Beta Loss 69.5860 (70.1022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.2%)	
11/22 07:32:35午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.5192 (1.4718)	Arch Loss 2.8423 (2.6495)	Arch Hard Loss 2.1568 (1.9537)	Arch Beta Loss 68.5471 (69.5802)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.0%, 87.2%)	
11/22 07:33:29午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.6275 (1.4899)	Arch Loss 2.4224 (2.6276)	Arch Hard Loss 1.7464 (1.9368)	Arch Beta Loss 67.5964 (69.0787)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.9%)	
11/22 07:34:18午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.6608 (1.4971)	Arch Loss 2.4516 (2.6199)	Arch Hard Loss 1.7839 (1.9336)	Arch Beta Loss 66.7648 (68.6355)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.7%)	
11/22 07:34:19午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 21/49] Final Prec@1 57.3520%
11/22 07:34:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.8983	Prec@(1,5) (49.3%, 79.3%)
11/22 07:34:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9029	Prec@(1,5) (48.7%, 79.1%)
11/22 07:34:42午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9050	Prec@(1,5) (48.4%, 79.1%)
11/22 07:34:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9011	Prec@(1,5) (48.5%, 79.2%)
11/22 07:34:50午前 searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 48.4920%
11/22 07:34:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 07:34:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.4920%
11/22 07:35:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.4594 (1.3702)	Arch Loss 2.9782 (2.6028)	Arch Hard Loss 2.3200 (1.9401)	Arch Beta Loss 65.8188 (66.2756)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.8%)	
11/22 07:36:38午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.5587 (1.3919)	Arch Loss 2.3881 (2.5637)	Arch Hard Loss 1.7392 (1.9055)	Arch Beta Loss 64.8909 (65.8153)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.0%, 88.3%)	
11/22 07:37:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.3699 (1.4195)	Arch Loss 2.9662 (2.5649)	Arch Hard Loss 2.3266 (1.9115)	Arch Beta Loss 63.9653 (65.3455)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.7%)	
11/22 07:38:22午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.6519 (1.4369)	Arch Loss 2.5117 (2.5583)	Arch Hard Loss 1.8795 (1.9089)	Arch Beta Loss 63.2119 (64.9391)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.4%)	
11/22 07:38:22午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 22/49] Final Prec@1 58.8640%
11/22 07:38:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8707	Prec@(1,5) (49.7%, 79.9%)
11/22 07:38:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8782	Prec@(1,5) (49.3%, 79.9%)
11/22 07:38:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8739	Prec@(1,5) (49.4%, 80.1%)
11/22 07:38:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8807	Prec@(1,5) (49.3%, 79.9%)
11/22 07:38:53午前 searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 49.2800%
11/22 07:38:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 07:38:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.2800%
11/22 07:39:49午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.3270 (1.3203)	Arch Loss 2.2841 (2.5083)	Arch Hard Loss 1.6602 (1.8805)	Arch Beta Loss 62.3914 (62.7821)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.5%)	
11/22 07:40:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.3195 (1.3643)	Arch Loss 2.7529 (2.5076)	Arch Hard Loss 2.1373 (1.8840)	Arch Beta Loss 61.5561 (62.3626)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.7%)	
11/22 07:41:37午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.4864 (1.3750)	Arch Loss 2.3433 (2.5096)	Arch Hard Loss 1.7357 (1.8900)	Arch Beta Loss 60.7539 (61.9565)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.7%)	
11/22 07:42:26午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.4898 (1.3920)	Arch Loss 2.8126 (2.5037)	Arch Hard Loss 2.2126 (1.8878)	Arch Beta Loss 60.0006 (61.5919)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.4%)	
11/22 07:42:26午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 23/49] Final Prec@1 59.9200%
11/22 07:42:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8277	Prec@(1,5) (50.8%, 80.1%)
11/22 07:42:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8329	Prec@(1,5) (50.9%, 80.7%)
11/22 07:42:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8351	Prec@(1,5) (50.6%, 80.6%)
11/22 07:42:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8383	Prec@(1,5) (50.4%, 80.6%)
11/22 07:42:58午前 searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 50.3760%
11/22 07:42:58午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 07:42:58午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.3760%
11/22 07:43:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.0891 (1.2921)	Arch Loss 2.5426 (2.4734)	Arch Hard Loss 1.9503 (1.8774)	Arch Beta Loss 59.2325 (59.6034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.6%, 89.2%)	
11/22 07:44:47午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3853 (1.3221)	Arch Loss 2.5448 (2.4722)	Arch Hard Loss 1.9599 (1.8798)	Arch Beta Loss 58.4918 (59.2357)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.2%)	
11/22 07:45:41午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.5785 (1.3355)	Arch Loss 2.4278 (2.4666)	Arch Hard Loss 1.8502 (1.8780)	Arch Beta Loss 57.7650 (58.8643)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.0%)	
11/22 07:46:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.3346 (1.3498)	Arch Loss 2.2511 (2.4611)	Arch Hard Loss 1.6800 (1.8759)	Arch Beta Loss 57.1138 (58.5276)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.9%)	
11/22 07:46:30午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 24/49] Final Prec@1 61.4120%
11/22 07:46:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.9093	Prec@(1,5) (49.1%, 80.1%)
11/22 07:46:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9039	Prec@(1,5) (49.7%, 80.1%)
11/22 07:46:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.9064	Prec@(1,5) (49.2%, 80.1%)
11/22 07:47:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9010	Prec@(1,5) (49.3%, 80.2%)
11/22 07:47:01午前 searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 49.2920%
11/22 07:47:01午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 07:47:01午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.3760%
11/22 07:47:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3771 (1.2474)	Arch Loss 2.3879 (2.3865)	Arch Hard Loss 1.8239 (1.8191)	Arch Beta Loss 56.4018 (56.7469)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
11/22 07:48:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.3864 (1.2829)	Arch Loss 2.8038 (2.4022)	Arch Hard Loss 2.2469 (1.8383)	Arch Beta Loss 55.6870 (56.3969)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.9%)	
11/22 07:49:44午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.0552 (1.2912)	Arch Loss 2.0230 (2.4038)	Arch Hard Loss 1.4727 (1.8434)	Arch Beta Loss 55.0293 (56.0472)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.7%)	
11/22 07:50:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.0781 (1.3052)	Arch Loss 2.1460 (2.4004)	Arch Hard Loss 1.6013 (1.8429)	Arch Beta Loss 54.4666 (55.7492)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.5%)	
11/22 07:50:33午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 25/49] Final Prec@1 62.2440%
11/22 07:50:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8309	Prec@(1,5) (50.2%, 81.4%)
11/22 07:50:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8310	Prec@(1,5) (50.9%, 81.0%)
11/22 07:50:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8055	Prec@(1,5) (51.7%, 81.3%)
11/22 07:51:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8066	Prec@(1,5) (51.4%, 81.2%)
11/22 07:51:04午前 searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 51.4280%
11/22 07:51:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 07:51:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4280%
11/22 07:52:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.5569 (1.2336)	Arch Loss 2.2594 (2.3116)	Arch Hard Loss 1.7210 (1.7703)	Arch Beta Loss 53.8443 (54.1332)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.3%)	
11/22 07:52:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.9743 (1.2463)	Arch Loss 2.6150 (2.3429)	Arch Hard Loss 2.0832 (1.8047)	Arch Beta Loss 53.1845 (53.8209)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.2%)	
11/22 07:53:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.3038 (1.2485)	Arch Loss 2.1650 (2.3521)	Arch Hard Loss 1.6395 (1.8171)	Arch Beta Loss 52.5489 (53.4958)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.2%)	
11/22 07:54:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.0852 (1.2665)	Arch Loss 2.6887 (2.3585)	Arch Hard Loss 2.1683 (1.8263)	Arch Beta Loss 52.0409 (53.2186)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 90.1%)	
11/22 07:54:37午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 26/49] Final Prec@1 63.0200%
11/22 07:54:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8053	Prec@(1,5) (51.1%, 81.5%)
11/22 07:54:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.7958	Prec@(1,5) (51.8%, 81.6%)
11/22 07:55:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8071	Prec@(1,5) (51.5%, 81.5%)
11/22 07:55:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8112	Prec@(1,5) (51.1%, 81.3%)
11/22 07:55:08午前 searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 51.1200%
11/22 07:55:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 07:55:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.4280%
11/22 07:56:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.0474 (1.1618)	Arch Loss 2.7506 (2.3480)	Arch Hard Loss 2.2360 (1.8306)	Arch Beta Loss 51.4634 (51.7349)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.8%)	
11/22 07:56:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.5552 (1.1969)	Arch Loss 2.3031 (2.3331)	Arch Hard Loss 1.7938 (1.8186)	Arch Beta Loss 50.9253 (51.4543)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.2%)	
11/22 07:57:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.0498 (1.2100)	Arch Loss 2.5937 (2.3316)	Arch Hard Loss 2.0899 (1.8197)	Arch Beta Loss 50.3819 (51.1886)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 91.1%)	
11/22 07:58:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.1190 (1.2262)	Arch Loss 2.1426 (2.3258)	Arch Hard Loss 1.6437 (1.8163)	Arch Beta Loss 49.8913 (50.9469)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.8%)	
11/22 07:58:40午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 27/49] Final Prec@1 64.3360%
11/22 07:58:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8198	Prec@(1,5) (51.5%, 80.9%)
11/22 07:58:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.7946	Prec@(1,5) (51.9%, 81.2%)
11/22 07:59:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.7923	Prec@(1,5) (52.0%, 81.5%)
11/22 07:59:11午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.7879	Prec@(1,5) (51.9%, 81.7%)
11/22 07:59:11午前 searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 51.8600%
11/22 07:59:11午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 07:59:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.8600%
11/22 08:00:06午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.2260 (1.1404)	Arch Loss 2.2808 (2.2720)	Arch Hard Loss 1.7873 (1.7758)	Arch Beta Loss 49.3410 (49.6152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.0%)	
11/22 08:01:01午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.0652 (1.1639)	Arch Loss 1.7397 (2.2801)	Arch Hard Loss 1.2513 (1.7866)	Arch Beta Loss 48.8394 (49.3472)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.7%)	
11/22 08:01:55午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.3689 (1.1709)	Arch Loss 2.2918 (2.2888)	Arch Hard Loss 1.8086 (1.7979)	Arch Beta Loss 48.3173 (49.0876)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.6%)	
11/22 08:02:44午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.1441 (1.1892)	Arch Loss 1.9394 (2.2952)	Arch Hard Loss 1.4603 (1.8066)	Arch Beta Loss 47.9105 (48.8607)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.3%)	
11/22 08:02:44午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 28/49] Final Prec@1 65.6120%
11/22 08:02:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.7858	Prec@(1,5) (51.6%, 81.6%)
11/22 08:03:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8139	Prec@(1,5) (50.9%, 81.1%)
11/22 08:03:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.7932	Prec@(1,5) (51.5%, 81.6%)
11/22 08:03:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7889	Prec@(1,5) (51.8%, 81.7%)
11/22 08:03:15午前 searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 51.7840%
11/22 08:03:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:03:15午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.8600%
11/22 08:04:10午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1648 (1.1159)	Arch Loss 2.0740 (2.2998)	Arch Hard Loss 1.5993 (1.8229)	Arch Beta Loss 47.4692 (47.6827)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.0%)	
11/22 08:05:04午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.0346 (1.1179)	Arch Loss 2.1924 (2.2896)	Arch Hard Loss 1.7226 (1.8151)	Arch Beta Loss 46.9807 (47.4540)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.2%)	
11/22 08:05:58午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.0224 (1.1327)	Arch Loss 2.4131 (2.2785)	Arch Hard Loss 1.9480 (1.8063)	Arch Beta Loss 46.5167 (47.2198)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.1%)	
11/22 08:06:47午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.1236 (1.1449)	Arch Loss 2.1498 (2.2684)	Arch Hard Loss 1.6883 (1.7982)	Arch Beta Loss 46.1544 (47.0174)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.6%, 92.0%)	
11/22 08:06:48午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 29/49] Final Prec@1 66.6120%
11/22 08:06:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7823	Prec@(1,5) (52.6%, 82.2%)
11/22 08:07:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7704	Prec@(1,5) (52.9%, 82.3%)
11/22 08:07:11午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7737	Prec@(1,5) (52.7%, 82.0%)
11/22 08:07:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7649	Prec@(1,5) (52.8%, 82.3%)
11/22 08:07:18午前 searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 52.7600%
11/22 08:07:18午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:07:19午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.7600%
11/22 08:08:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.2009 (1.0773)	Arch Loss 1.8906 (2.2262)	Arch Hard Loss 1.4332 (1.7667)	Arch Beta Loss 45.7417 (45.9483)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.9%)	
11/22 08:09:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.3786 (1.0695)	Arch Loss 2.2988 (2.2416)	Arch Hard Loss 1.8452 (1.7841)	Arch Beta Loss 45.3569 (45.7509)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
11/22 08:10:02午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1018 (1.0880)	Arch Loss 2.0668 (2.2298)	Arch Hard Loss 1.6173 (1.7743)	Arch Beta Loss 44.9541 (45.5464)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.5%)	
11/22 08:10:50午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2991 (1.1064)	Arch Loss 2.4824 (2.2352)	Arch Hard Loss 2.0367 (1.7816)	Arch Beta Loss 44.5731 (45.3654)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
11/22 08:10:51午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 30/49] Final Prec@1 67.7280%
11/22 08:10:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7418	Prec@(1,5) (53.0%, 82.5%)
11/22 08:11:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7424	Prec@(1,5) (53.2%, 82.5%)
11/22 08:11:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7488	Prec@(1,5) (53.0%, 82.2%)
11/22 08:11:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7450	Prec@(1,5) (53.2%, 82.3%)
11/22 08:11:22午前 searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 53.1800%
11/22 08:11:22午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:11:22午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.1800%
11/22 08:12:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.9567 (1.0495)	Arch Loss 2.1780 (2.1897)	Arch Hard Loss 1.7364 (1.7460)	Arch Beta Loss 44.1638 (44.3722)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.0%)	
11/22 08:13:10午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.9559 (1.0518)	Arch Loss 2.1039 (2.2199)	Arch Hard Loss 1.6658 (1.7781)	Arch Beta Loss 43.8086 (44.1776)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
11/22 08:14:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1302 (1.0742)	Arch Loss 2.2962 (2.2192)	Arch Hard Loss 1.8619 (1.7793)	Arch Beta Loss 43.4310 (43.9904)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.8%)	
11/22 08:14:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3650 (1.0846)	Arch Loss 2.2575 (2.2100)	Arch Hard Loss 1.8255 (1.7716)	Arch Beta Loss 43.1978 (43.8369)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.8%)	
11/22 08:14:54午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 31/49] Final Prec@1 68.2640%
11/22 08:15:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7030	Prec@(1,5) (53.3%, 83.8%)
11/22 08:15:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7135	Prec@(1,5) (53.3%, 83.4%)
11/22 08:15:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7215	Prec@(1,5) (53.2%, 83.1%)
11/22 08:15:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7312	Prec@(1,5) (53.2%, 82.8%)
11/22 08:15:25午前 searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 53.2280%
11/22 08:15:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 08:15:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.2280%
11/22 08:16:20午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.2437 (1.0240)	Arch Loss 1.8720 (2.1966)	Arch Hard Loss 1.4435 (1.7666)	Arch Beta Loss 42.8514 (43.0060)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.7%)	
11/22 08:17:14午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9634 (1.0289)	Arch Loss 2.4950 (2.1986)	Arch Hard Loss 2.0702 (1.7703)	Arch Beta Loss 42.4794 (42.8358)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.4%)	
11/22 08:18:08午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8984 (1.0329)	Arch Loss 2.2842 (2.2037)	Arch Hard Loss 1.8630 (1.7771)	Arch Beta Loss 42.1150 (42.6555)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.2%)	
11/22 08:18:58午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.2325 (1.0453)	Arch Loss 2.1468 (2.1905)	Arch Hard Loss 1.7286 (1.7655)	Arch Beta Loss 41.8268 (42.4952)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.1%)	
11/22 08:18:58午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 32/49] Final Prec@1 69.5560%
11/22 08:19:06午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7511	Prec@(1,5) (53.5%, 82.2%)
11/22 08:19:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7328	Prec@(1,5) (53.7%, 82.5%)
11/22 08:19:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7290	Prec@(1,5) (53.7%, 82.5%)
11/22 08:19:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7290	Prec@(1,5) (53.8%, 82.5%)
11/22 08:19:29午前 searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 53.7520%
11/22 08:19:29午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:19:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.7520%
11/22 08:20:24午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.7887 (0.9532)	Arch Loss 2.2047 (2.1687)	Arch Hard Loss 1.7897 (1.7521)	Arch Beta Loss 41.5066 (41.6537)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.3%)	
11/22 08:21:18午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.0061 (0.9782)	Arch Loss 1.8385 (2.1463)	Arch Hard Loss 1.4268 (1.7313)	Arch Beta Loss 41.1711 (41.4967)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.0%)	
11/22 08:22:12午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2638 (0.9952)	Arch Loss 2.6230 (2.1693)	Arch Hard Loss 2.2145 (1.7560)	Arch Beta Loss 40.8535 (41.3333)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.4%, 94.0%)	
11/22 08:23:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1857 (1.0081)	Arch Loss 2.1258 (2.1670)	Arch Hard Loss 1.7195 (1.7550)	Arch Beta Loss 40.6266 (41.1965)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.8%)	
11/22 08:23:01午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 33/49] Final Prec@1 70.9240%
11/22 08:23:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7122	Prec@(1,5) (54.3%, 83.1%)
11/22 08:23:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.6937	Prec@(1,5) (54.7%, 83.4%)
11/22 08:23:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.6982	Prec@(1,5) (54.4%, 83.4%)
11/22 08:23:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7031	Prec@(1,5) (54.5%, 83.3%)
11/22 08:23:32午前 searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 54.4520%
11/22 08:23:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 08:23:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4520%
11/22 08:24:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.7804 (0.9286)	Arch Loss 2.1135 (2.1064)	Arch Hard Loss 1.7097 (1.7015)	Arch Beta Loss 40.3834 (40.4883)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.9%, 95.0%)	
11/22 08:25:23午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.8430 (0.9550)	Arch Loss 2.3554 (2.1326)	Arch Hard Loss 1.9541 (1.7289)	Arch Beta Loss 40.1259 (40.3701)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.6%)	
11/22 08:26:17午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0639 (0.9592)	Arch Loss 2.5878 (2.1378)	Arch Hard Loss 2.1893 (1.7354)	Arch Beta Loss 39.8539 (40.2404)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.2%)	
11/22 08:27:06午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.0248 (0.9744)	Arch Loss 2.0467 (2.1462)	Arch Hard Loss 1.6512 (1.7450)	Arch Beta Loss 39.5504 (40.1183)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.1%)	
11/22 08:27:07午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 34/49] Final Prec@1 71.5480%
11/22 08:27:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7393	Prec@(1,5) (53.2%, 82.4%)
11/22 08:27:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7385	Prec@(1,5) (53.5%, 82.7%)
11/22 08:27:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7229	Prec@(1,5) (54.0%, 82.9%)
11/22 08:27:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7198	Prec@(1,5) (54.0%, 83.0%)
11/22 08:27:38午前 searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 54.0160%
11/22 08:27:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:27:38午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4520%
11/22 08:28:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.0349 (0.9040)	Arch Loss 2.0967 (2.1445)	Arch Hard Loss 1.7038 (1.7504)	Arch Beta Loss 39.2902 (39.4106)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.7%)	
11/22 08:29:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.0053 (0.9256)	Arch Loss 1.9240 (2.1377)	Arch Hard Loss 1.5337 (1.7448)	Arch Beta Loss 39.0297 (39.2874)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.5%)	
11/22 08:30:21午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.0553 (0.9360)	Arch Loss 2.2097 (2.1128)	Arch Hard Loss 1.8209 (1.7210)	Arch Beta Loss 38.8711 (39.1736)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.3%)	
11/22 08:31:10午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1033 (0.9419)	Arch Loss 2.1125 (2.1212)	Arch Hard Loss 1.7261 (1.7305)	Arch Beta Loss 38.6381 (39.0711)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.2%)	
11/22 08:31:11午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 35/49] Final Prec@1 72.6800%
11/22 08:31:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.6760	Prec@(1,5) (54.8%, 83.7%)
11/22 08:31:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.6899	Prec@(1,5) (54.5%, 83.6%)
11/22 08:31:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.6932	Prec@(1,5) (54.5%, 83.6%)
11/22 08:31:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.6958	Prec@(1,5) (54.3%, 83.5%)
11/22 08:31:41午前 searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 54.3480%
11/22 08:31:41午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:31:42午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4520%
11/22 08:32:37午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.8692 (0.8711)	Arch Loss 2.5470 (2.1356)	Arch Hard Loss 2.1627 (1.7502)	Arch Beta Loss 38.4264 (38.5368)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.3%)	
11/22 08:33:31午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.8380 (0.8923)	Arch Loss 1.7526 (2.1120)	Arch Hard Loss 1.3704 (1.7278)	Arch Beta Loss 38.2244 (38.4210)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.1%)	
11/22 08:34:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.9670 (0.9039)	Arch Loss 2.1522 (2.1155)	Arch Hard Loss 1.7725 (1.7323)	Arch Beta Loss 37.9702 (38.3135)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.0%)	
11/22 08:35:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.7802 (0.9050)	Arch Loss 1.9218 (2.1156)	Arch Hard Loss 1.5447 (1.7336)	Arch Beta Loss 37.7145 (38.2060)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 95.0%)	
11/22 08:35:14午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 36/49] Final Prec@1 73.4600%
11/22 08:35:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.6882	Prec@(1,5) (54.1%, 84.2%)
11/22 08:35:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.6762	Prec@(1,5) (54.6%, 84.1%)
11/22 08:35:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.6980	Prec@(1,5) (54.4%, 83.7%)
11/22 08:35:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7101	Prec@(1,5) (54.3%, 83.5%)
11/22 08:35:44午前 searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 54.2600%
11/22 08:35:44午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:35:45午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4520%
11/22 08:36:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.6725 (0.8388)	Arch Loss 2.4055 (2.1169)	Arch Hard Loss 2.0303 (1.7406)	Arch Beta Loss 37.5218 (37.6281)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.6%)	
11/22 08:37:33午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.9316 (0.8449)	Arch Loss 2.4896 (2.0935)	Arch Hard Loss 2.1168 (1.7184)	Arch Beta Loss 37.2853 (37.5129)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.5%)	
11/22 08:38:27午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.8123 (0.8633)	Arch Loss 1.9380 (2.0881)	Arch Hard Loss 1.5673 (1.7141)	Arch Beta Loss 37.0718 (37.4022)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
11/22 08:39:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.6922 (0.8741)	Arch Loss 1.9385 (2.0877)	Arch Hard Loss 1.5695 (1.7147)	Arch Beta Loss 36.8963 (37.3060)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.2%)	
11/22 08:39:16午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 37/49] Final Prec@1 74.3840%
11/22 08:39:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.6877	Prec@(1,5) (54.9%, 83.8%)
11/22 08:39:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.6913	Prec@(1,5) (54.8%, 83.6%)
11/22 08:39:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.6782	Prec@(1,5) (55.1%, 83.8%)
11/22 08:39:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.6789	Prec@(1,5) (55.1%, 83.7%)
11/22 08:39:47午前 searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 55.0800%
11/22 08:39:47午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/22 08:39:47午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.0800%
11/22 08:40:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6442 (0.8382)	Arch Loss 1.9151 (2.0715)	Arch Hard Loss 1.5480 (1.7033)	Arch Beta Loss 36.7124 (36.8147)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.4%)	
11/22 08:41:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.7848 (0.8383)	Arch Loss 1.9845 (2.0579)	Arch Hard Loss 1.6191 (1.6906)	Arch Beta Loss 36.5393 (36.7220)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.5%)	
11/22 08:42:30午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.9085 (0.8384)	Arch Loss 2.2127 (2.0722)	Arch Hard Loss 1.8498 (1.7060)	Arch Beta Loss 36.2864 (36.6145)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.6%)	
11/22 08:43:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.5954 (0.8456)	Arch Loss 2.0755 (2.0841)	Arch Hard Loss 1.7143 (1.7189)	Arch Beta Loss 36.1167 (36.5192)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.5%)	
11/22 08:43:19午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 38/49] Final Prec@1 75.2280%
11/22 08:43:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7163	Prec@(1,5) (55.7%, 82.6%)
11/22 08:43:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.6900	Prec@(1,5) (55.5%, 83.5%)
11/22 08:43:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.6815	Prec@(1,5) (55.4%, 83.6%)
11/22 08:43:50午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.6738	Prec@(1,5) (55.5%, 83.8%)
11/22 08:43:50午前 searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 55.5240%
11/22 08:43:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:43:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5240%
11/22 08:44:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.8146 (0.7806)	Arch Loss 1.6812 (2.0808)	Arch Hard Loss 1.3216 (1.7205)	Arch Beta Loss 35.9604 (36.0353)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.1%)	
11/22 08:45:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.6551 (0.7941)	Arch Loss 2.1161 (2.0635)	Arch Hard Loss 1.7587 (1.7041)	Arch Beta Loss 35.7423 (35.9478)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.2%, 95.9%)	
11/22 08:46:34午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.6352 (0.8073)	Arch Loss 2.1951 (2.0689)	Arch Hard Loss 1.8393 (1.7104)	Arch Beta Loss 35.5764 (35.8534)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 95.8%)	
11/22 08:47:22午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 1.0090 (0.8138)	Arch Loss 2.2013 (2.0667)	Arch Hard Loss 1.8469 (1.7090)	Arch Beta Loss 35.4367 (35.7750)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.8%)	
11/22 08:47:23午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 39/49] Final Prec@1 76.6480%
11/22 08:47:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.6935	Prec@(1,5) (55.0%, 83.0%)
11/22 08:47:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.6858	Prec@(1,5) (55.1%, 83.4%)
11/22 08:47:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.6892	Prec@(1,5) (55.0%, 83.4%)
11/22 08:47:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.6913	Prec@(1,5) (55.0%, 83.4%)
11/22 08:47:54午前 searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 55.0080%
11/22 08:47:54午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:47:54午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5240%
11/22 08:48:49午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.8505 (0.7667)	Arch Loss 2.2319 (2.1066)	Arch Hard Loss 1.8796 (1.7534)	Arch Beta Loss 35.2335 (35.3184)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.2%)	
11/22 08:49:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.7525 (0.7779)	Arch Loss 2.0977 (2.0966)	Arch Hard Loss 1.7470 (1.7443)	Arch Beta Loss 35.0632 (35.2358)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.1%)	
11/22 08:50:37午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.6626 (0.7952)	Arch Loss 1.9630 (2.0840)	Arch Hard Loss 1.6139 (1.7325)	Arch Beta Loss 34.9140 (35.1518)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
11/22 08:51:25午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 1.1059 (0.7943)	Arch Loss 2.0786 (2.0655)	Arch Hard Loss 1.7311 (1.7147)	Arch Beta Loss 34.7522 (35.0780)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
11/22 08:51:26午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 40/49] Final Prec@1 76.9920%
11/22 08:51:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.6512	Prec@(1,5) (56.2%, 84.0%)
11/22 08:51:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.6656	Prec@(1,5) (55.9%, 83.8%)
11/22 08:51:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.6684	Prec@(1,5) (55.6%, 83.7%)
11/22 08:51:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.6670	Prec@(1,5) (55.5%, 83.8%)
11/22 08:51:57午前 searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 55.5320%
11/22 08:51:57午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 08:51:57午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.5320%
11/22 08:52:52午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.6976 (0.7474)	Arch Loss 2.2868 (2.0762)	Arch Hard Loss 1.9410 (1.7295)	Arch Beta Loss 34.5786 (34.6719)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
11/22 08:53:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.5050 (0.7602)	Arch Loss 2.1936 (2.0685)	Arch Hard Loss 1.8495 (1.7227)	Arch Beta Loss 34.4115 (34.5822)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.4%)	
11/22 08:54:40午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.7619 (0.7621)	Arch Loss 1.8527 (2.0700)	Arch Hard Loss 1.5100 (1.7250)	Arch Beta Loss 34.2640 (34.5027)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.4%)	
11/22 08:55:28午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.9494 (0.7692)	Arch Loss 1.8869 (2.0638)	Arch Hard Loss 1.5460 (1.7196)	Arch Beta Loss 34.0977 (34.4272)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.3%)	
11/22 08:55:29午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 41/49] Final Prec@1 78.1160%
11/22 08:55:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.6774	Prec@(1,5) (54.8%, 83.5%)
11/22 08:55:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.6671	Prec@(1,5) (55.2%, 83.7%)
11/22 08:55:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.6643	Prec@(1,5) (55.6%, 83.9%)
11/22 08:55:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.6667	Prec@(1,5) (55.7%, 83.9%)
11/22 08:55:59午前 searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 55.6640%
11/22 08:55:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 08:56:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6640%
11/22 08:56:55午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.6791 (0.7305)	Arch Loss 1.8999 (2.0555)	Arch Hard Loss 1.5602 (1.7153)	Arch Beta Loss 33.9792 (34.0232)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.5%)	
11/22 08:57:49午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.8642 (0.7357)	Arch Loss 2.0587 (2.0342)	Arch Hard Loss 1.7198 (1.6944)	Arch Beta Loss 33.8832 (33.9848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.5%)	
11/22 08:58:43午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.7151 (0.7441)	Arch Loss 2.2728 (2.0356)	Arch Hard Loss 1.9353 (1.6963)	Arch Beta Loss 33.7546 (33.9284)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.5%)	
11/22 08:59:32午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.6356 (0.7476)	Arch Loss 2.1930 (2.0357)	Arch Hard Loss 1.8567 (1.6970)	Arch Beta Loss 33.6246 (33.8723)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.5%)	
11/22 08:59:32午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 42/49] Final Prec@1 78.9120%
11/22 08:59:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6205	Prec@(1,5) (56.5%, 85.0%)
11/22 08:59:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.6558	Prec@(1,5) (56.0%, 84.4%)
11/22 08:59:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.6510	Prec@(1,5) (56.0%, 84.3%)
11/22 09:00:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.6530	Prec@(1,5) (55.8%, 84.3%)
11/22 09:00:03午前 searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 55.8280%
11/22 09:00:03午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/22 09:00:04午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.8280%
11/22 09:01:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.8208 (0.7173)	Arch Loss 2.1100 (2.0418)	Arch Hard Loss 1.7753 (1.7065)	Arch Beta Loss 33.4604 (33.5304)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
11/22 09:01:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.6524 (0.7286)	Arch Loss 1.6981 (2.0352)	Arch Hard Loss 1.3650 (1.7007)	Arch Beta Loss 33.3054 (33.4518)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.9%)	
11/22 09:02:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7749 (0.7291)	Arch Loss 2.3113 (2.0393)	Arch Hard Loss 1.9791 (1.7054)	Arch Beta Loss 33.2177 (33.3862)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.8%)	
11/22 09:03:36午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.5592 (0.7310)	Arch Loss 1.8435 (2.0373)	Arch Hard Loss 1.5128 (1.7041)	Arch Beta Loss 33.0739 (33.3284)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.8%)	
11/22 09:03:36午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 43/49] Final Prec@1 79.3880%
11/22 09:03:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6579	Prec@(1,5) (56.4%, 83.9%)
11/22 09:03:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.6461	Prec@(1,5) (56.3%, 84.3%)
11/22 09:04:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.6444	Prec@(1,5) (56.3%, 84.4%)
11/22 09:04:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.6582	Prec@(1,5) (56.1%, 84.2%)
11/22 09:04:07午前 searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 56.1720%
11/22 09:04:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
11/22 09:04:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:05:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.7002 (0.7172)	Arch Loss 2.3109 (2.0341)	Arch Hard Loss 1.9812 (1.7037)	Arch Beta Loss 32.9672 (33.0370)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 96.7%)	
11/22 09:05:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6919 (0.7157)	Arch Loss 2.5426 (2.0233)	Arch Hard Loss 2.2143 (1.6936)	Arch Beta Loss 32.8303 (32.9718)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.8%)	
11/22 09:06:51午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.7003 (0.7208)	Arch Loss 2.1042 (2.0284)	Arch Hard Loss 1.7771 (1.6994)	Arch Beta Loss 32.7087 (32.9035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 96.7%)	
11/22 09:07:39午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.5983 (0.7179)	Arch Loss 2.1694 (2.0247)	Arch Hard Loss 1.8433 (1.6962)	Arch Beta Loss 32.6138 (32.8487)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 96.8%)	
11/22 09:07:40午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 44/49] Final Prec@1 79.9360%
11/22 09:07:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6188	Prec@(1,5) (56.7%, 84.6%)
11/22 09:07:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.6500	Prec@(1,5) (56.0%, 84.3%)
11/22 09:08:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.6488	Prec@(1,5) (56.0%, 84.4%)
11/22 09:08:11午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.6545	Prec@(1,5) (56.0%, 84.1%)
11/22 09:08:11午前 searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 56.0200%
11/22 09:08:11午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 09:08:11午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:09:06午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4520 (0.7035)	Arch Loss 1.6483 (2.0359)	Arch Hard Loss 1.3233 (1.7104)	Arch Beta Loss 32.4992 (32.5565)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.1%)	
11/22 09:10:00午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5941 (0.6980)	Arch Loss 2.4195 (2.0277)	Arch Hard Loss 2.0959 (1.7027)	Arch Beta Loss 32.3585 (32.4988)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.1%)	
11/22 09:10:54午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7989 (0.7009)	Arch Loss 2.6513 (2.0283)	Arch Hard Loss 2.3291 (1.7041)	Arch Beta Loss 32.2214 (32.4257)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
11/22 09:11:42午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6278 (0.7075)	Arch Loss 1.9306 (2.0326)	Arch Hard Loss 1.6093 (1.7090)	Arch Beta Loss 32.1254 (32.3674)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
11/22 09:11:43午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 45/49] Final Prec@1 79.9680%
11/22 09:11:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6246	Prec@(1,5) (57.0%, 84.2%)
11/22 09:11:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.6583	Prec@(1,5) (56.1%, 83.7%)
11/22 09:12:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.6584	Prec@(1,5) (56.0%, 83.8%)
11/22 09:12:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.6561	Prec@(1,5) (56.0%, 83.9%)
11/22 09:12:14午前 searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 55.9600%
11/22 09:12:14午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 09:12:14午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:13:09午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.9802 (0.6732)	Arch Loss 1.9776 (2.0125)	Arch Hard Loss 1.6571 (1.6917)	Arch Beta Loss 32.0513 (32.0888)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.3%)	
11/22 09:14:03午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.6262 (0.6825)	Arch Loss 1.9435 (2.0150)	Arch Hard Loss 1.6239 (1.6945)	Arch Beta Loss 31.9596 (32.0514)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.3%)	
11/22 09:14:57午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5388 (0.6852)	Arch Loss 2.1986 (2.0181)	Arch Hard Loss 1.8802 (1.6981)	Arch Beta Loss 31.8359 (31.9953)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.3%)	
11/22 09:15:45午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.5482 (0.6917)	Arch Loss 2.2860 (2.0199)	Arch Hard Loss 1.9685 (1.7004)	Arch Beta Loss 31.7426 (31.9492)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
11/22 09:15:46午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 46/49] Final Prec@1 80.5520%
11/22 09:15:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.6496	Prec@(1,5) (56.5%, 84.0%)
11/22 09:16:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.6378	Prec@(1,5) (56.7%, 84.3%)
11/22 09:16:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.6503	Prec@(1,5) (56.3%, 84.1%)
11/22 09:16:16午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.6517	Prec@(1,5) (56.1%, 84.2%)
11/22 09:16:17午前 searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 56.1480%
11/22 09:16:17午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 09:16:17午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:17:11午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.5996 (0.6813)	Arch Loss 1.5923 (1.9906)	Arch Hard Loss 1.2759 (1.6740)	Arch Beta Loss 31.6414 (31.6656)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.4%)	
11/22 09:18:05午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.5022 (0.6761)	Arch Loss 1.8929 (2.0149)	Arch Hard Loss 1.5778 (1.6986)	Arch Beta Loss 31.5084 (31.6231)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.5%)	
11/22 09:18:59午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5256 (0.6831)	Arch Loss 1.7437 (2.0030)	Arch Hard Loss 1.4300 (1.6874)	Arch Beta Loss 31.3715 (31.5634)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.4%)	
11/22 09:19:48午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7554 (0.6886)	Arch Loss 2.2517 (2.0051)	Arch Hard Loss 1.9388 (1.6900)	Arch Beta Loss 31.2913 (31.5100)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.3%)	
11/22 09:19:48午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 47/49] Final Prec@1 80.8160%
11/22 09:19:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.6559	Prec@(1,5) (55.3%, 84.4%)
11/22 09:20:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6446	Prec@(1,5) (56.1%, 84.4%)
11/22 09:20:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6463	Prec@(1,5) (56.0%, 84.3%)
11/22 09:20:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.6471	Prec@(1,5) (56.1%, 84.3%)
11/22 09:20:20午前 searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 56.1280%
11/22 09:20:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 09:20:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:21:15午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.7385 (0.6704)	Arch Loss 2.0789 (1.9932)	Arch Hard Loss 1.7672 (1.6809)	Arch Beta Loss 31.1732 (31.2262)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.4%)	
11/22 09:22:10午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.5576 (0.6704)	Arch Loss 2.3818 (2.0076)	Arch Hard Loss 2.0711 (1.6959)	Arch Beta Loss 31.0699 (31.1724)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
11/22 09:23:04午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.7693 (0.6825)	Arch Loss 1.9768 (2.0043)	Arch Hard Loss 1.6669 (1.6931)	Arch Beta Loss 30.9960 (31.1246)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.3%)	
11/22 09:23:53午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6672 (0.6881)	Arch Loss 2.0506 (2.0104)	Arch Hard Loss 1.7419 (1.6996)	Arch Beta Loss 30.8683 (31.0818)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.2%)	
11/22 09:23:53午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 48/49] Final Prec@1 80.8880%
11/22 09:24:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.6500	Prec@(1,5) (56.4%, 84.0%)
11/22 09:24:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6501	Prec@(1,5) (56.1%, 83.9%)
11/22 09:24:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6402	Prec@(1,5) (56.2%, 84.3%)
11/22 09:24:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.6409	Prec@(1,5) (56.1%, 84.3%)
11/22 09:24:24午前 searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 56.0640%
11/22 09:24:24午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/22 09:24:24午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:25:19午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.5410 (0.6658)	Arch Loss 1.9087 (2.0035)	Arch Hard Loss 1.6010 (1.6953)	Arch Beta Loss 30.7739 (30.8172)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.5%)	
11/22 09:26:13午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.4892 (0.6665)	Arch Loss 2.1647 (2.0019)	Arch Hard Loss 1.8581 (1.6943)	Arch Beta Loss 30.6630 (30.7576)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.3%)	
11/22 09:27:07午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5622 (0.6744)	Arch Loss 2.2143 (2.0067)	Arch Hard Loss 1.9084 (1.6996)	Arch Beta Loss 30.5948 (30.7134)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.3%)	
11/22 09:27:56午前 searchStage_BetaConcat_trainer.py:133 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.7612 (0.6796)	Arch Loss 1.7172 (2.0132)	Arch Hard Loss 1.4119 (1.7064)	Arch Beta Loss 30.5332 (30.6799)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
11/22 09:27:57午前 searchStage_BetaConcat_trainer.py:147 [INFO] Train: [ 49/49] Final Prec@1 81.2880%
11/22 09:28:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6139	Prec@(1,5) (56.2%, 84.4%)
11/22 09:28:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6482	Prec@(1,5) (55.8%, 84.2%)
11/22 09:28:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.6570	Prec@(1,5) (55.8%, 84.0%)
11/22 09:28:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6449	Prec@(1,5) (56.1%, 84.2%)
11/22 09:28:28午前 searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 56.0760%
11/22 09:28:28午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/22 09:28:28午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.1720%
11/22 09:28:28午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 56.1720%
11/22 09:28:28午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=[2, 3])
