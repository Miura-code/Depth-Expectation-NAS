12/27 02:11:54AM parser.py:28 [INFO] 
12/27 02:11:54AM parser.py:29 [INFO] Parameters:
12/27 02:11:54AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.1/DAG
12/27 02:11:54AM parser.py:31 [INFO] T=10.0
12/27 02:11:54AM parser.py:31 [INFO] ADVANCED=1
12/27 02:11:54AM parser.py:31 [INFO] ALPHA_LR=0.0003
12/27 02:11:54AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/27 02:11:54AM parser.py:31 [INFO] ARCH_CRITERION=expected
12/27 02:11:54AM parser.py:31 [INFO] BATCH_SIZE=64
12/27 02:11:54AM parser.py:31 [INFO] CASCADE=0
12/27 02:11:54AM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/27 02:11:54AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
12/27 02:11:54AM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/27 02:11:54AM parser.py:31 [INFO] DATA_PATH=../data/
12/27 02:11:54AM parser.py:31 [INFO] DATASET=cifar100
12/27 02:11:54AM parser.py:31 [INFO] DEPTH_COEF=-0.1
12/27 02:11:54AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/27 02:11:54AM parser.py:31 [INFO] DISCRETE=1
12/27 02:11:54AM parser.py:31 [INFO] EPOCHS=50
12/27 02:11:54AM parser.py:31 [INFO] EVAL_EPOCHS=100
12/27 02:11:54AM parser.py:31 [INFO] EXP_NAME=s0-depth-sw3-g-0.1
12/27 02:11:54AM parser.py:31 [INFO] FINAL_L=0.0
12/27 02:11:54AM parser.py:31 [INFO] G=0.0
12/27 02:11:54AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/27 02:11:54AM parser.py:31 [INFO] GPUS=[0]
12/27 02:11:54AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/27 02:11:54AM parser.py:31 [INFO] INIT_CHANNELS=16
12/27 02:11:54AM parser.py:31 [INFO] L=0.0
12/27 02:11:54AM parser.py:31 [INFO] LAYERS=32
12/27 02:11:54AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/27 02:11:54AM parser.py:31 [INFO] NAME=Pruning
12/27 02:11:54AM parser.py:31 [INFO] NONKD=1
12/27 02:11:54AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.1
12/27 02:11:54AM parser.py:31 [INFO] PCDARTS=0
12/27 02:11:54AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.1/plots
12/27 02:11:54AM parser.py:31 [INFO] PRINT_FREQ=100
12/27 02:11:54AM parser.py:31 [INFO] RESET=0
12/27 02:11:54AM parser.py:31 [INFO] RESUME_PATH=None
12/27 02:11:54AM parser.py:31 [INFO] SAVE=s0-depth-sw3-g-0.1
12/27 02:11:54AM parser.py:31 [INFO] SEED=0
12/27 02:11:54AM parser.py:31 [INFO] SHARE_STAGE=0
12/27 02:11:54AM parser.py:31 [INFO] SLIDE_WINDOW=3
12/27 02:11:54AM parser.py:31 [INFO] SPEC_CELL=1
12/27 02:11:54AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/27 02:11:54AM parser.py:31 [INFO] TEACHER_NAME=none
12/27 02:11:54AM parser.py:31 [INFO] TEACHER_PATH=none
12/27 02:11:54AM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/27 02:11:54AM parser.py:31 [INFO] TYPE=Distribution
12/27 02:11:54AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/27 02:11:54AM parser.py:31 [INFO] W_LR=0.025
12/27 02:11:54AM parser.py:31 [INFO] W_LR_MIN=0.001
12/27 02:11:54AM parser.py:31 [INFO] W_MOMENTUM=0.9
12/27 02:11:54AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/27 02:11:54AM parser.py:31 [INFO] WORKERS=4
12/27 02:11:54AM parser.py:32 [INFO] 
12/27 02:11:55AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/27 02:12:40AM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3395 (4.5226)	Arch Loss 4.2643 (4.4983)	Arch Hard Loss 4.2643 (4.4983)	Arch Beta Loss 2.8195 (2.8213)	Arch depth Loss 0.2819 (0.2821)	Prec@(1,5) (2.2%, 9.7%)	
12/27 02:13:22AM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0672 (4.3884)	Arch Loss 4.2660 (4.3735)	Arch Hard Loss 4.2660 (4.3735)	Arch Beta Loss 2.8166 (2.8196)	Arch depth Loss 0.2817 (0.2820)	Prec@(1,5) (3.3%, 14.0%)	
12/27 02:14:04AM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.3313 (4.2971)	Arch Loss 4.1860 (4.2785)	Arch Hard Loss 4.1860 (4.2785)	Arch Beta Loss 2.8148 (2.8182)	Arch depth Loss 0.2815 (0.2818)	Prec@(1,5) (4.3%, 17.0%)	
12/27 02:14:43AM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9276 (4.2298)	Arch Loss 3.9859 (4.2139)	Arch Hard Loss 3.9859 (4.2139)	Arch Beta Loss 2.8147 (2.8174)	Arch depth Loss 0.2815 (0.2817)	Prec@(1,5) (4.9%, 19.2%)	
12/27 02:14:44AM searchDistribution_trainer.py:166 [INFO] Train: [  0/49] Final Prec@1 4.9400%
12/27 02:14:52AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9490	Prec@(1,5) (7.9%, 27.8%)
12/27 02:14:59AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9513	Prec@(1,5) (7.6%, 27.6%)
12/27 02:15:05AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9556	Prec@(1,5) (7.8%, 27.3%)
12/27 02:15:11AM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9593	Prec@(1,5) (7.7%, 27.3%)
12/27 02:15:11AM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 7.6800%
12/27 02:15:11AM trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:15:12AM trainer_runner.py:108 [INFO] Until now, best Prec@1 = 7.6800%
12/27 02:15:56午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.0030 (3.9275)	Arch Loss 3.9923 (3.9460)	Arch Hard Loss 3.9923 (3.9460)	Arch Beta Loss 2.8173 (2.8163)	Arch depth Loss 0.2817 (0.2816)	Prec@(1,5) (8.4%, 28.2%)	
12/27 02:16:39午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.0405 (3.9080)	Arch Loss 3.9179 (3.9018)	Arch Hard Loss 3.9179 (3.9018)	Arch Beta Loss 2.8214 (2.8179)	Arch depth Loss 0.2821 (0.2818)	Prec@(1,5) (8.6%, 28.7%)	
12/27 02:17:22午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.9394 (3.8701)	Arch Loss 3.6753 (3.8653)	Arch Hard Loss 3.6753 (3.8653)	Arch Beta Loss 2.8255 (2.8198)	Arch depth Loss 0.2825 (0.2820)	Prec@(1,5) (9.3%, 29.7%)	
12/27 02:18:01午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8170 (3.8430)	Arch Loss 3.8309 (3.8263)	Arch Hard Loss 3.8309 (3.8263)	Arch Beta Loss 2.8301 (2.8217)	Arch depth Loss 0.2830 (0.2822)	Prec@(1,5) (9.6%, 30.6%)	
12/27 02:18:01午前 searchDistribution_trainer.py:166 [INFO] Train: [  1/49] Final Prec@1 9.6480%
12/27 02:18:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.7307	Prec@(1,5) (11.6%, 34.2%)
12/27 02:18:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.7226	Prec@(1,5) (11.7%, 34.4%)
12/27 02:18:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.7254	Prec@(1,5) (11.4%, 34.4%)
12/27 02:18:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.7326	Prec@(1,5) (11.4%, 34.0%)
12/27 02:18:26午前 searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 11.4360%
12/27 02:18:26午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:18:26午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 11.4360%
12/27 02:19:10午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8077 (3.6533)	Arch Loss 3.9296 (3.6918)	Arch Hard Loss 3.9296 (3.6918)	Arch Beta Loss 2.8346 (2.8326)	Arch depth Loss 0.2835 (0.2833)	Prec@(1,5) (12.4%, 36.5%)	
12/27 02:19:54午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4356 (3.6395)	Arch Loss 3.5210 (3.6574)	Arch Hard Loss 3.5210 (3.6574)	Arch Beta Loss 2.8396 (2.8348)	Arch depth Loss 0.2840 (0.2835)	Prec@(1,5) (12.8%, 36.8%)	
12/27 02:20:37午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.5021 (3.6280)	Arch Loss 3.5127 (3.6180)	Arch Hard Loss 3.5127 (3.6180)	Arch Beta Loss 2.8438 (2.8371)	Arch depth Loss 0.2844 (0.2837)	Prec@(1,5) (13.1%, 37.3%)	
12/27 02:21:18午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.5256 (3.6052)	Arch Loss 3.5285 (3.5909)	Arch Hard Loss 3.5285 (3.5909)	Arch Beta Loss 2.8480 (2.8391)	Arch depth Loss 0.2848 (0.2839)	Prec@(1,5) (13.7%, 38.1%)	
12/27 02:21:18午前 searchDistribution_trainer.py:166 [INFO] Train: [  2/49] Final Prec@1 13.7400%
12/27 02:21:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4627	Prec@(1,5) (16.0%, 42.8%)
12/27 02:21:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4658	Prec@(1,5) (15.9%, 42.4%)
12/27 02:21:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4650	Prec@(1,5) (16.2%, 42.6%)
12/27 02:21:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4652	Prec@(1,5) (16.3%, 42.7%)
12/27 02:21:47午前 searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 16.2880%
12/27 02:21:47午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:21:48午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 16.2880%
12/27 02:22:34午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.3821 (3.4461)	Arch Loss 3.3161 (3.4704)	Arch Hard Loss 3.3161 (3.4704)	Arch Beta Loss 2.8517 (2.8498)	Arch depth Loss 0.2852 (0.2850)	Prec@(1,5) (16.0%, 42.8%)	
12/27 02:23:20午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.4445 (3.4352)	Arch Loss 3.5859 (3.4529)	Arch Hard Loss 3.5859 (3.4529)	Arch Beta Loss 2.8549 (2.8515)	Arch depth Loss 0.2855 (0.2851)	Prec@(1,5) (16.3%, 43.1%)	
12/27 02:24:06午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.4318 (3.4303)	Arch Loss 3.4779 (3.4285)	Arch Hard Loss 3.4779 (3.4285)	Arch Beta Loss 2.8576 (2.8531)	Arch depth Loss 0.2858 (0.2853)	Prec@(1,5) (16.4%, 43.4%)	
12/27 02:24:48午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9903 (3.4106)	Arch Loss 3.3851 (3.4166)	Arch Hard Loss 3.3851 (3.4166)	Arch Beta Loss 2.8600 (2.8544)	Arch depth Loss 0.2860 (0.2854)	Prec@(1,5) (16.9%, 44.0%)	
12/27 02:24:49午前 searchDistribution_trainer.py:166 [INFO] Train: [  3/49] Final Prec@1 16.8720%
12/27 02:24:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.3117	Prec@(1,5) (18.8%, 46.7%)
12/27 02:25:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.3216	Prec@(1,5) (18.7%, 46.3%)
12/27 02:25:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.3226	Prec@(1,5) (18.8%, 46.5%)
12/27 02:25:16午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.3235	Prec@(1,5) (18.8%, 46.4%)
12/27 02:25:16午前 searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 18.7960%
12/27 02:25:16午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:25:17午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 18.7960%
12/27 02:26:01午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.2244 (3.2926)	Arch Loss 3.0410 (3.3288)	Arch Hard Loss 3.0410 (3.3288)	Arch Beta Loss 2.8617 (2.8608)	Arch depth Loss 0.2862 (0.2861)	Prec@(1,5) (18.8%, 47.6%)	
12/27 02:26:44午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.8090 (3.2731)	Arch Loss 3.0610 (3.2944)	Arch Hard Loss 3.0610 (3.2944)	Arch Beta Loss 2.8634 (2.8618)	Arch depth Loss 0.2863 (0.2862)	Prec@(1,5) (19.2%, 47.9%)	
12/27 02:27:28午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.1783 (3.2572)	Arch Loss 3.2160 (3.2751)	Arch Hard Loss 3.2160 (3.2751)	Arch Beta Loss 2.8639 (2.8624)	Arch depth Loss 0.2864 (0.2862)	Prec@(1,5) (19.7%, 48.3%)	
12/27 02:28:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.1924 (3.2449)	Arch Loss 3.1791 (3.2657)	Arch Hard Loss 3.1791 (3.2657)	Arch Beta Loss 2.8640 (2.8628)	Arch depth Loss 0.2864 (0.2863)	Prec@(1,5) (20.1%, 48.7%)	
12/27 02:28:07午前 searchDistribution_trainer.py:166 [INFO] Train: [  4/49] Final Prec@1 20.0600%
12/27 02:28:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.2824	Prec@(1,5) (20.5%, 48.7%)
12/27 02:28:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.2240	Prec@(1,5) (21.3%, 50.4%)
12/27 02:28:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.2311	Prec@(1,5) (20.9%, 50.0%)
12/27 02:28:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.2287	Prec@(1,5) (20.7%, 50.1%)
12/27 02:28:32午前 searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 20.7040%
12/27 02:28:32午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:28:33午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 20.7040%
12/27 02:29:16午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.0158 (3.1360)	Arch Loss 3.2681 (3.2130)	Arch Hard Loss 3.2681 (3.2130)	Arch Beta Loss 2.8639 (2.8641)	Arch depth Loss 0.2864 (0.2864)	Prec@(1,5) (21.6%, 51.5%)	
12/27 02:30:03午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.8809 (3.1293)	Arch Loss 3.2507 (3.1779)	Arch Hard Loss 3.2507 (3.1779)	Arch Beta Loss 2.8645 (2.8641)	Arch depth Loss 0.2865 (0.2864)	Prec@(1,5) (21.6%, 51.8%)	
12/27 02:30:51午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.5232 (3.1241)	Arch Loss 3.1362 (3.1701)	Arch Hard Loss 3.1362 (3.1701)	Arch Beta Loss 2.8641 (2.8642)	Arch depth Loss 0.2864 (0.2864)	Prec@(1,5) (21.8%, 51.9%)	
12/27 02:31:33午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.9205 (3.1147)	Arch Loss 3.1065 (3.1567)	Arch Hard Loss 3.1065 (3.1567)	Arch Beta Loss 2.8639 (2.8642)	Arch depth Loss 0.2864 (0.2864)	Prec@(1,5) (22.2%, 52.1%)	
12/27 02:31:34午前 searchDistribution_trainer.py:166 [INFO] Train: [  5/49] Final Prec@1 22.1560%
12/27 02:31:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.0336	Prec@(1,5) (24.2%, 54.1%)
12/27 02:31:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.0442	Prec@(1,5) (23.9%, 54.0%)
12/27 02:31:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.0473	Prec@(1,5) (24.2%, 54.1%)
12/27 02:32:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.0508	Prec@(1,5) (24.1%, 54.0%)
12/27 02:32:03午前 searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 24.0720%
12/27 02:32:03午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:32:03午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 24.0720%
12/27 02:32:50午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.9841 (2.9642)	Arch Loss 2.9293 (3.0762)	Arch Hard Loss 2.9293 (3.0762)	Arch Beta Loss 2.8634 (2.8637)	Arch depth Loss 0.2863 (0.2864)	Prec@(1,5) (24.4%, 55.3%)	
12/27 02:33:38午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.9665 (2.9873)	Arch Loss 2.7536 (3.0467)	Arch Hard Loss 2.7536 (3.0467)	Arch Beta Loss 2.8628 (2.8635)	Arch depth Loss 0.2863 (0.2864)	Prec@(1,5) (24.6%, 55.0%)	
12/27 02:34:23午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.1366 (2.9821)	Arch Loss 2.9980 (3.0462)	Arch Hard Loss 2.9980 (3.0462)	Arch Beta Loss 2.8619 (2.8631)	Arch depth Loss 0.2862 (0.2863)	Prec@(1,5) (24.7%, 55.3%)	
12/27 02:35:04午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.2135 (2.9847)	Arch Loss 3.2205 (3.0414)	Arch Hard Loss 3.2205 (3.0414)	Arch Beta Loss 2.8600 (2.8626)	Arch depth Loss 0.2860 (0.2863)	Prec@(1,5) (24.7%, 55.4%)	
12/27 02:35:04午前 searchDistribution_trainer.py:166 [INFO] Train: [  6/49] Final Prec@1 24.6960%
12/27 02:35:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.0361	Prec@(1,5) (24.4%, 54.5%)
12/27 02:35:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.0231	Prec@(1,5) (24.2%, 55.0%)
12/27 02:35:25午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.0366	Prec@(1,5) (24.1%, 54.7%)
12/27 02:35:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.0305	Prec@(1,5) (24.3%, 54.9%)
12/27 02:35:31午前 searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 24.2520%
12/27 02:35:31午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:35:32午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 24.2520%
12/27 02:36:18午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.9361 (2.8902)	Arch Loss 2.8173 (2.9704)	Arch Hard Loss 2.8173 (2.9704)	Arch Beta Loss 2.8583 (2.8590)	Arch depth Loss 0.2858 (0.2859)	Prec@(1,5) (26.2%, 58.6%)	
12/27 02:37:03午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.8514 (2.8818)	Arch Loss 2.9901 (2.9661)	Arch Hard Loss 2.9901 (2.9661)	Arch Beta Loss 2.8569 (2.8582)	Arch depth Loss 0.2857 (0.2858)	Prec@(1,5) (26.6%, 58.9%)	
12/27 02:37:51午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.8077 (2.8791)	Arch Loss 2.9168 (2.9546)	Arch Hard Loss 2.9168 (2.9546)	Arch Beta Loss 2.8547 (2.8574)	Arch depth Loss 0.2855 (0.2857)	Prec@(1,5) (26.9%, 58.7%)	
12/27 02:38:34午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.0172 (2.8793)	Arch Loss 2.5517 (2.9495)	Arch Hard Loss 2.5517 (2.9495)	Arch Beta Loss 2.8530 (2.8566)	Arch depth Loss 0.2853 (0.2857)	Prec@(1,5) (26.8%, 58.6%)	
12/27 02:38:35午前 searchDistribution_trainer.py:166 [INFO] Train: [  7/49] Final Prec@1 26.7960%
12/27 02:38:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.8778	Prec@(1,5) (27.6%, 59.6%)
12/27 02:38:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.8957	Prec@(1,5) (26.8%, 59.1%)
12/27 02:38:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.9016	Prec@(1,5) (26.9%, 58.5%)
12/27 02:39:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.9113	Prec@(1,5) (26.6%, 58.3%)
12/27 02:39:05午前 searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 26.5760%
12/27 02:39:05午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:39:05午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 26.5760%
12/27 02:39:53午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.6194 (2.7565)	Arch Loss 3.0143 (2.9387)	Arch Hard Loss 3.0143 (2.9387)	Arch Beta Loss 2.8507 (2.8517)	Arch depth Loss 0.2851 (0.2852)	Prec@(1,5) (29.6%, 61.0%)	
12/27 02:40:39午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.8805 (2.7759)	Arch Loss 2.6399 (2.9172)	Arch Hard Loss 2.6399 (2.9172)	Arch Beta Loss 2.8492 (2.8508)	Arch depth Loss 0.2849 (0.2851)	Prec@(1,5) (29.1%, 60.8%)	
12/27 02:41:25午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.8789 (2.7851)	Arch Loss 2.9320 (2.8974)	Arch Hard Loss 2.9320 (2.8974)	Arch Beta Loss 2.8471 (2.8499)	Arch depth Loss 0.2847 (0.2850)	Prec@(1,5) (29.0%, 60.7%)	
12/27 02:42:09午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.5245 (2.7868)	Arch Loss 3.2062 (2.8873)	Arch Hard Loss 3.2062 (2.8873)	Arch Beta Loss 2.8453 (2.8490)	Arch depth Loss 0.2845 (0.2849)	Prec@(1,5) (29.0%, 60.6%)	
12/27 02:42:10午前 searchDistribution_trainer.py:166 [INFO] Train: [  8/49] Final Prec@1 29.0400%
12/27 02:42:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.8579	Prec@(1,5) (27.8%, 59.2%)
12/27 02:42:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.8762	Prec@(1,5) (27.1%, 58.8%)
12/27 02:42:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.8665	Prec@(1,5) (27.2%, 59.1%)
12/27 02:42:37午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.8716	Prec@(1,5) (27.2%, 58.9%)
12/27 02:42:37午前 searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 27.2200%
12/27 02:42:37午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:42:37午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 27.2200%
12/27 02:43:22午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.8374 (2.6879)	Arch Loss 2.9184 (2.8103)	Arch Hard Loss 2.9184 (2.8103)	Arch Beta Loss 2.8432 (2.8443)	Arch depth Loss 0.2843 (0.2844)	Prec@(1,5) (31.0%, 63.2%)	
12/27 02:44:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.6333 (2.6935)	Arch Loss 3.1397 (2.8212)	Arch Hard Loss 3.1397 (2.8212)	Arch Beta Loss 2.8413 (2.8432)	Arch depth Loss 0.2841 (0.2843)	Prec@(1,5) (30.6%, 63.0%)	
12/27 02:44:49午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.5502 (2.6905)	Arch Loss 2.6848 (2.8213)	Arch Hard Loss 2.6848 (2.8213)	Arch Beta Loss 2.8395 (2.8422)	Arch depth Loss 0.2840 (0.2842)	Prec@(1,5) (30.4%, 62.9%)	
12/27 02:45:28午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.5873 (2.6898)	Arch Loss 3.0955 (2.8148)	Arch Hard Loss 3.0955 (2.8148)	Arch Beta Loss 2.8372 (2.8413)	Arch depth Loss 0.2837 (0.2841)	Prec@(1,5) (30.4%, 62.9%)	
12/27 02:45:28午前 searchDistribution_trainer.py:166 [INFO] Train: [  9/49] Final Prec@1 30.4280%
12/27 02:45:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.7745	Prec@(1,5) (29.7%, 61.9%)
12/27 02:45:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.7467	Prec@(1,5) (29.8%, 62.3%)
12/27 02:45:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.7491	Prec@(1,5) (30.1%, 62.1%)
12/27 02:45:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.7463	Prec@(1,5) (30.0%, 62.0%)
12/27 02:45:53午前 searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 30.0000%
12/27 02:45:53午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:45:54午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 30.0000%
12/27 02:46:38午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9590 (2.5947)	Arch Loss 2.9348 (2.7679)	Arch Hard Loss 2.9348 (2.7679)	Arch Beta Loss 2.8356 (2.8364)	Arch depth Loss 0.2836 (0.2836)	Prec@(1,5) (32.7%, 65.0%)	
12/27 02:47:20午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4220 (2.5824)	Arch Loss 2.9601 (2.7451)	Arch Hard Loss 2.9601 (2.7451)	Arch Beta Loss 2.8332 (2.8353)	Arch depth Loss 0.2833 (0.2835)	Prec@(1,5) (32.9%, 65.2%)	
12/27 02:48:03午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3718 (2.6010)	Arch Loss 3.0589 (2.7460)	Arch Hard Loss 3.0589 (2.7460)	Arch Beta Loss 2.8305 (2.8342)	Arch depth Loss 0.2830 (0.2834)	Prec@(1,5) (32.6%, 64.8%)	
12/27 02:48:41午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.6070 (2.5955)	Arch Loss 3.1702 (2.7334)	Arch Hard Loss 3.1702 (2.7334)	Arch Beta Loss 2.8290 (2.8332)	Arch depth Loss 0.2829 (0.2833)	Prec@(1,5) (32.8%, 64.8%)	
12/27 02:48:42午前 searchDistribution_trainer.py:166 [INFO] Train: [ 10/49] Final Prec@1 32.7960%
12/27 02:48:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.7250	Prec@(1,5) (31.0%, 63.2%)
12/27 02:48:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.7427	Prec@(1,5) (30.7%, 62.4%)
12/27 02:49:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.7433	Prec@(1,5) (30.6%, 62.3%)
12/27 02:49:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.7360	Prec@(1,5) (30.5%, 62.5%)
12/27 02:49:07午前 searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 30.5520%
12/27 02:49:07午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:49:08午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 30.5520%
12/27 02:49:52午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.4634 (2.5321)	Arch Loss 2.3649 (2.7142)	Arch Hard Loss 2.3649 (2.7142)	Arch Beta Loss 2.8275 (2.8282)	Arch depth Loss 0.2828 (0.2828)	Prec@(1,5) (33.5%, 66.9%)	
12/27 02:50:37午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.3741 (2.5203)	Arch Loss 2.8469 (2.6806)	Arch Hard Loss 2.8469 (2.6806)	Arch Beta Loss 2.8253 (2.8273)	Arch depth Loss 0.2825 (0.2827)	Prec@(1,5) (33.9%, 66.8%)	
12/27 02:51:21午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.6435 (2.5143)	Arch Loss 2.5695 (2.6721)	Arch Hard Loss 2.5695 (2.6721)	Arch Beta Loss 2.8229 (2.8262)	Arch depth Loss 0.2823 (0.2826)	Prec@(1,5) (34.0%, 66.9%)	
12/27 02:52:00午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.3775 (2.5135)	Arch Loss 2.5244 (2.6610)	Arch Hard Loss 2.5244 (2.6610)	Arch Beta Loss 2.8211 (2.8252)	Arch depth Loss 0.2821 (0.2825)	Prec@(1,5) (34.1%, 66.7%)	
12/27 02:52:01午前 searchDistribution_trainer.py:166 [INFO] Train: [ 11/49] Final Prec@1 34.1480%
12/27 02:52:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.6719	Prec@(1,5) (32.2%, 63.5%)
12/27 02:52:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.6604	Prec@(1,5) (32.0%, 63.5%)
12/27 02:52:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.6541	Prec@(1,5) (31.9%, 63.7%)
12/27 02:52:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.6564	Prec@(1,5) (31.9%, 63.7%)
12/27 02:52:26午前 searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 31.9120%
12/27 02:52:26午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:52:26午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 31.9120%
12/27 02:53:10午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.3260 (2.3859)	Arch Loss 2.6793 (2.6189)	Arch Hard Loss 2.6793 (2.6189)	Arch Beta Loss 2.8199 (2.8204)	Arch depth Loss 0.2820 (0.2820)	Prec@(1,5) (37.0%, 69.9%)	
12/27 02:53:54午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.2251 (2.4038)	Arch Loss 2.6937 (2.6183)	Arch Hard Loss 2.6937 (2.6183)	Arch Beta Loss 2.8175 (2.8195)	Arch depth Loss 0.2818 (0.2819)	Prec@(1,5) (37.0%, 69.4%)	
12/27 02:54:36午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.5855 (2.4266)	Arch Loss 2.5386 (2.6160)	Arch Hard Loss 2.5386 (2.6160)	Arch Beta Loss 2.8159 (2.8186)	Arch depth Loss 0.2816 (0.2819)	Prec@(1,5) (36.3%, 68.8%)	
12/27 02:55:14午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.5460 (2.4223)	Arch Loss 2.9268 (2.6014)	Arch Hard Loss 2.9268 (2.6014)	Arch Beta Loss 2.8139 (2.8177)	Arch depth Loss 0.2814 (0.2818)	Prec@(1,5) (36.2%, 68.9%)	
12/27 02:55:15午前 searchDistribution_trainer.py:166 [INFO] Train: [ 12/49] Final Prec@1 36.2320%
12/27 02:55:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.5519	Prec@(1,5) (34.5%, 65.9%)
12/27 02:55:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.5690	Prec@(1,5) (33.8%, 65.7%)
12/27 02:55:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.5669	Prec@(1,5) (34.0%, 65.7%)
12/27 02:55:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.5690	Prec@(1,5) (33.9%, 65.8%)
12/27 02:55:39午前 searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 33.8960%
12/27 02:55:39午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:55:39午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 33.8960%
12/27 02:56:23午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.1661 (2.3204)	Arch Loss 2.1565 (2.5423)	Arch Hard Loss 2.1565 (2.5423)	Arch Beta Loss 2.8123 (2.8132)	Arch depth Loss 0.2812 (0.2813)	Prec@(1,5) (38.5%, 70.8%)	
12/27 02:57:06午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.6347 (2.3352)	Arch Loss 2.5115 (2.5502)	Arch Hard Loss 2.5115 (2.5502)	Arch Beta Loss 2.8112 (2.8125)	Arch depth Loss 0.2811 (0.2813)	Prec@(1,5) (37.8%, 70.6%)	
12/27 02:57:49午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.4805 (2.3423)	Arch Loss 2.7622 (2.5503)	Arch Hard Loss 2.7622 (2.5503)	Arch Beta Loss 2.8090 (2.8118)	Arch depth Loss 0.2809 (0.2812)	Prec@(1,5) (37.7%, 70.6%)	
12/27 02:58:27午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0273 (2.3395)	Arch Loss 2.5436 (2.5454)	Arch Hard Loss 2.5436 (2.5454)	Arch Beta Loss 2.8074 (2.8110)	Arch depth Loss 0.2807 (0.2811)	Prec@(1,5) (37.8%, 70.7%)	
12/27 02:58:28午前 searchDistribution_trainer.py:166 [INFO] Train: [ 13/49] Final Prec@1 37.7560%
12/27 02:58:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.4958	Prec@(1,5) (35.3%, 68.5%)
12/27 02:58:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.4966	Prec@(1,5) (35.5%, 68.2%)
12/27 02:58:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.5064	Prec@(1,5) (35.4%, 67.8%)
12/27 02:58:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.5026	Prec@(1,5) (35.5%, 68.0%)
12/27 02:58:52午前 searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 35.5000%
12/27 02:58:52午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 02:58:52午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 35.5000%
12/27 02:59:36午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.2466 (2.2231)	Arch Loss 2.4143 (2.4978)	Arch Hard Loss 2.4143 (2.4978)	Arch Beta Loss 2.8057 (2.8066)	Arch depth Loss 0.2806 (0.2807)	Prec@(1,5) (40.6%, 73.5%)	
12/27 03:00:19午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.1584 (2.2555)	Arch Loss 2.5283 (2.4880)	Arch Hard Loss 2.5283 (2.4880)	Arch Beta Loss 2.8044 (2.8058)	Arch depth Loss 0.2804 (0.2806)	Prec@(1,5) (39.6%, 72.6%)	
12/27 03:01:01午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.9846 (2.2551)	Arch Loss 2.7631 (2.4906)	Arch Hard Loss 2.7631 (2.4906)	Arch Beta Loss 2.8031 (2.8051)	Arch depth Loss 0.2803 (0.2805)	Prec@(1,5) (39.4%, 72.8%)	
12/27 03:01:38午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.3111 (2.2571)	Arch Loss 2.6216 (2.4864)	Arch Hard Loss 2.6216 (2.4864)	Arch Beta Loss 2.8009 (2.8044)	Arch depth Loss 0.2801 (0.2804)	Prec@(1,5) (39.5%, 72.6%)	
12/27 03:01:38午前 searchDistribution_trainer.py:166 [INFO] Train: [ 14/49] Final Prec@1 39.5000%
12/27 03:01:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.5161	Prec@(1,5) (34.8%, 66.9%)
12/27 03:01:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.5134	Prec@(1,5) (35.4%, 66.7%)
12/27 03:01:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.5169	Prec@(1,5) (35.1%, 66.8%)
12/27 03:02:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.5120	Prec@(1,5) (35.2%, 67.0%)
12/27 03:02:02午前 searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 35.1920%
12/27 03:02:02午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:02:03午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 35.5000%
12/27 03:02:46午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.3990 (2.1664)	Arch Loss 2.1535 (2.4421)	Arch Hard Loss 2.1535 (2.4421)	Arch Beta Loss 2.7994 (2.8002)	Arch depth Loss 0.2799 (0.2800)	Prec@(1,5) (41.6%, 74.5%)	
12/27 03:03:28午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.8532 (2.1917)	Arch Loss 2.4921 (2.4402)	Arch Hard Loss 2.4921 (2.4402)	Arch Beta Loss 2.7976 (2.7993)	Arch depth Loss 0.2798 (0.2799)	Prec@(1,5) (41.2%, 73.8%)	
12/27 03:04:10午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0009 (2.1944)	Arch Loss 2.6177 (2.4384)	Arch Hard Loss 2.6177 (2.4384)	Arch Beta Loss 2.7961 (2.7985)	Arch depth Loss 0.2796 (0.2799)	Prec@(1,5) (41.1%, 73.7%)	
12/27 03:04:50午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.2550 (2.1964)	Arch Loss 2.3550 (2.4411)	Arch Hard Loss 2.3550 (2.4411)	Arch Beta Loss 2.7949 (2.7978)	Arch depth Loss 0.2795 (0.2798)	Prec@(1,5) (41.1%, 73.7%)	
12/27 03:04:50午前 searchDistribution_trainer.py:166 [INFO] Train: [ 15/49] Final Prec@1 41.1120%
12/27 03:04:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.3887	Prec@(1,5) (38.2%, 69.5%)
12/27 03:05:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.3952	Prec@(1,5) (38.3%, 69.5%)
12/27 03:05:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.3998	Prec@(1,5) (38.0%, 69.4%)
12/27 03:05:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.4087	Prec@(1,5) (37.8%, 69.2%)
12/27 03:05:15午前 searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 37.8200%
12/27 03:05:15午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:05:15午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 37.8200%
12/27 03:05:58午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.0656 (2.0680)	Arch Loss 2.2621 (2.4332)	Arch Hard Loss 2.2621 (2.4332)	Arch Beta Loss 2.7936 (2.7943)	Arch depth Loss 0.2794 (0.2794)	Prec@(1,5) (44.0%, 75.8%)	
12/27 03:06:43午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.2610 (2.1029)	Arch Loss 2.3151 (2.4211)	Arch Hard Loss 2.3151 (2.4211)	Arch Beta Loss 2.7914 (2.7933)	Arch depth Loss 0.2791 (0.2793)	Prec@(1,5) (43.0%, 75.3%)	
12/27 03:07:28午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.0908 (2.1188)	Arch Loss 2.4770 (2.4050)	Arch Hard Loss 2.4770 (2.4050)	Arch Beta Loss 2.7901 (2.7924)	Arch depth Loss 0.2790 (0.2792)	Prec@(1,5) (42.6%, 75.0%)	
12/27 03:08:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.9011 (2.1182)	Arch Loss 2.5514 (2.4009)	Arch Hard Loss 2.5514 (2.4009)	Arch Beta Loss 2.7892 (2.7918)	Arch depth Loss 0.2789 (0.2792)	Prec@(1,5) (42.6%, 75.2%)	
12/27 03:08:08午前 searchDistribution_trainer.py:166 [INFO] Train: [ 16/49] Final Prec@1 42.5680%
12/27 03:08:16午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.4395	Prec@(1,5) (37.0%, 69.4%)
12/27 03:08:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.4520	Prec@(1,5) (36.7%, 69.2%)
12/27 03:08:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.4356	Prec@(1,5) (37.1%, 69.4%)
12/27 03:08:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.4293	Prec@(1,5) (37.1%, 69.5%)
12/27 03:08:38午前 searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 37.0880%
12/27 03:08:38午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:08:38午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 37.8200%
12/27 03:09:24午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.1825 (2.0365)	Arch Loss 2.4336 (2.3510)	Arch Hard Loss 2.4336 (2.3510)	Arch Beta Loss 2.7872 (2.7882)	Arch depth Loss 0.2787 (0.2788)	Prec@(1,5) (45.0%, 76.6%)	
12/27 03:10:08午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.0895 (2.0499)	Arch Loss 2.2810 (2.3609)	Arch Hard Loss 2.2810 (2.3609)	Arch Beta Loss 2.7865 (2.7875)	Arch depth Loss 0.2786 (0.2787)	Prec@(1,5) (44.1%, 76.5%)	
12/27 03:10:52午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.2161 (2.0608)	Arch Loss 2.1431 (2.3493)	Arch Hard Loss 2.1431 (2.3493)	Arch Beta Loss 2.7849 (2.7869)	Arch depth Loss 0.2785 (0.2787)	Prec@(1,5) (44.0%, 76.3%)	
12/27 03:11:33午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.2858 (2.0566)	Arch Loss 2.3865 (2.3516)	Arch Hard Loss 2.3865 (2.3516)	Arch Beta Loss 2.7845 (2.7864)	Arch depth Loss 0.2784 (0.2786)	Prec@(1,5) (44.1%, 76.5%)	
12/27 03:11:33午前 searchDistribution_trainer.py:166 [INFO] Train: [ 17/49] Final Prec@1 44.1400%
12/27 03:11:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.3634	Prec@(1,5) (38.4%, 70.6%)
12/27 03:11:48午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.3512	Prec@(1,5) (39.3%, 70.5%)
12/27 03:11:55午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.3537	Prec@(1,5) (39.2%, 70.5%)
12/27 03:12:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.3551	Prec@(1,5) (39.0%, 70.6%)
12/27 03:12:02午前 searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 39.0520%
12/27 03:12:02午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:12:03午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 39.0520%
12/27 03:12:48午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.0432 (2.0017)	Arch Loss 2.1912 (2.3110)	Arch Hard Loss 2.1912 (2.3110)	Arch Beta Loss 2.7826 (2.7837)	Arch depth Loss 0.2783 (0.2784)	Prec@(1,5) (45.1%, 77.7%)	
12/27 03:13:32午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.2767 (1.9668)	Arch Loss 2.0657 (2.3307)	Arch Hard Loss 2.0657 (2.3307)	Arch Beta Loss 2.7818 (2.7830)	Arch depth Loss 0.2782 (0.2783)	Prec@(1,5) (46.2%, 78.3%)	
12/27 03:14:17午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.8276 (1.9697)	Arch Loss 2.2256 (2.3307)	Arch Hard Loss 2.2256 (2.3307)	Arch Beta Loss 2.7806 (2.7825)	Arch depth Loss 0.2781 (0.2782)	Prec@(1,5) (46.1%, 78.2%)	
12/27 03:14:57午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.9948 (1.9798)	Arch Loss 2.1685 (2.3182)	Arch Hard Loss 2.1685 (2.3182)	Arch Beta Loss 2.7794 (2.7819)	Arch depth Loss 0.2779 (0.2782)	Prec@(1,5) (45.8%, 78.0%)	
12/27 03:14:58午前 searchDistribution_trainer.py:166 [INFO] Train: [ 18/49] Final Prec@1 45.7480%
12/27 03:15:05午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.3473	Prec@(1,5) (38.9%, 71.4%)
12/27 03:15:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.3679	Prec@(1,5) (38.7%, 70.7%)
12/27 03:15:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.3556	Prec@(1,5) (38.8%, 71.1%)
12/27 03:15:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.3602	Prec@(1,5) (38.7%, 71.0%)
12/27 03:15:26午前 searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 38.7080%
12/27 03:15:26午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:15:27午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 39.0520%
12/27 03:16:12午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.7846 (1.8499)	Arch Loss 2.0156 (2.3176)	Arch Hard Loss 2.0156 (2.3176)	Arch Beta Loss 2.7783 (2.7789)	Arch depth Loss 0.2778 (0.2779)	Prec@(1,5) (48.5%, 80.4%)	
12/27 03:16:56午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.5327 (1.8812)	Arch Loss 2.2294 (2.2943)	Arch Hard Loss 2.2294 (2.2943)	Arch Beta Loss 2.7767 (2.7782)	Arch depth Loss 0.2777 (0.2778)	Prec@(1,5) (48.1%, 79.8%)	
12/27 03:17:41午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.9535 (1.8998)	Arch Loss 1.9750 (2.2870)	Arch Hard Loss 1.9750 (2.2870)	Arch Beta Loss 2.7753 (2.7775)	Arch depth Loss 0.2775 (0.2778)	Prec@(1,5) (47.7%, 79.3%)	
12/27 03:18:21午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.9397 (1.9116)	Arch Loss 2.6914 (2.2916)	Arch Hard Loss 2.6914 (2.2916)	Arch Beta Loss 2.7745 (2.7769)	Arch depth Loss 0.2774 (0.2777)	Prec@(1,5) (47.2%, 79.3%)	
12/27 03:18:22午前 searchDistribution_trainer.py:166 [INFO] Train: [ 19/49] Final Prec@1 47.2040%
12/27 03:18:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.2898	Prec@(1,5) (39.3%, 72.5%)
12/27 03:18:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.2965	Prec@(1,5) (39.6%, 72.4%)
12/27 03:18:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.3011	Prec@(1,5) (39.8%, 72.1%)
12/27 03:18:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.3105	Prec@(1,5) (39.7%, 71.9%)
12/27 03:18:50午前 searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 39.6600%
12/27 03:18:50午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:18:50午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 39.6600%
12/27 03:19:36午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6917 (1.7954)	Arch Loss 2.3326 (2.2515)	Arch Hard Loss 2.3326 (2.2515)	Arch Beta Loss 2.7736 (2.7741)	Arch depth Loss 0.2774 (0.2774)	Prec@(1,5) (49.8%, 82.0%)	
12/27 03:20:22午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 2.1323 (1.8397)	Arch Loss 1.8251 (2.2590)	Arch Hard Loss 1.8251 (2.2590)	Arch Beta Loss 2.7730 (2.7738)	Arch depth Loss 0.2773 (0.2774)	Prec@(1,5) (49.1%, 80.8%)	
12/27 03:21:05午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.1119 (1.8477)	Arch Loss 2.2385 (2.2571)	Arch Hard Loss 2.2385 (2.2571)	Arch Beta Loss 2.7714 (2.7733)	Arch depth Loss 0.2771 (0.2773)	Prec@(1,5) (48.9%, 80.6%)	
12/27 03:21:46午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.8832 (1.8568)	Arch Loss 2.2226 (2.2481)	Arch Hard Loss 2.2226 (2.2481)	Arch Beta Loss 2.7707 (2.7727)	Arch depth Loss 0.2771 (0.2773)	Prec@(1,5) (48.7%, 80.3%)	
12/27 03:21:46午前 searchDistribution_trainer.py:166 [INFO] Train: [ 20/49] Final Prec@1 48.7360%
12/27 03:21:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.2158	Prec@(1,5) (41.7%, 74.0%)
12/27 03:22:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.2510	Prec@(1,5) (40.8%, 73.0%)
12/27 03:22:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.2578	Prec@(1,5) (40.8%, 73.1%)
12/27 03:22:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.2520	Prec@(1,5) (40.9%, 73.2%)
12/27 03:22:14午前 searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 40.8720%
12/27 03:22:14午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:22:15午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 40.8720%
12/27 03:23:00午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.8105 (1.7849)	Arch Loss 2.5623 (2.2612)	Arch Hard Loss 2.5623 (2.2612)	Arch Beta Loss 2.7688 (2.7698)	Arch depth Loss 0.2769 (0.2770)	Prec@(1,5) (50.3%, 81.6%)	
12/27 03:23:44午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.4081 (1.7788)	Arch Loss 2.6266 (2.2144)	Arch Hard Loss 2.6266 (2.2144)	Arch Beta Loss 2.7679 (2.7690)	Arch depth Loss 0.2768 (0.2769)	Prec@(1,5) (50.1%, 81.7%)	
12/27 03:24:27午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.8669 (1.7909)	Arch Loss 2.1751 (2.2153)	Arch Hard Loss 2.1751 (2.2153)	Arch Beta Loss 2.7672 (2.7686)	Arch depth Loss 0.2767 (0.2769)	Prec@(1,5) (49.6%, 81.6%)	
12/27 03:25:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.7525 (1.7972)	Arch Loss 2.4283 (2.2165)	Arch Hard Loss 2.4283 (2.2165)	Arch Beta Loss 2.7667 (2.7682)	Arch depth Loss 0.2767 (0.2768)	Prec@(1,5) (49.5%, 81.6%)	
12/27 03:25:08午前 searchDistribution_trainer.py:166 [INFO] Train: [ 21/49] Final Prec@1 49.5240%
12/27 03:25:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.2513	Prec@(1,5) (41.7%, 73.8%)
12/27 03:25:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.2327	Prec@(1,5) (42.0%, 74.0%)
12/27 03:25:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.2358	Prec@(1,5) (42.1%, 73.6%)
12/27 03:25:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.2428	Prec@(1,5) (41.9%, 73.4%)
12/27 03:25:34午前 searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 41.8520%
12/27 03:25:34午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:25:34午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 41.8520%
12/27 03:26:18午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.9588 (1.6766)	Arch Loss 1.9164 (2.2083)	Arch Hard Loss 1.9164 (2.2083)	Arch Beta Loss 2.7658 (2.7662)	Arch depth Loss 0.2766 (0.2766)	Prec@(1,5) (52.8%, 83.7%)	
12/27 03:27:04午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.8735 (1.7090)	Arch Loss 2.0614 (2.2143)	Arch Hard Loss 2.0614 (2.2143)	Arch Beta Loss 2.7648 (2.7658)	Arch depth Loss 0.2765 (0.2766)	Prec@(1,5) (51.8%, 83.0%)	
12/27 03:27:46午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.9740 (1.7238)	Arch Loss 2.2482 (2.1974)	Arch Hard Loss 2.2482 (2.1974)	Arch Beta Loss 2.7639 (2.7654)	Arch depth Loss 0.2764 (0.2765)	Prec@(1,5) (51.5%, 82.9%)	
12/27 03:28:25午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7902 (1.7338)	Arch Loss 2.2485 (2.1911)	Arch Hard Loss 2.2485 (2.1911)	Arch Beta Loss 2.7628 (2.7649)	Arch depth Loss 0.2763 (0.2765)	Prec@(1,5) (51.4%, 82.6%)	
12/27 03:28:26午前 searchDistribution_trainer.py:166 [INFO] Train: [ 22/49] Final Prec@1 51.3840%
12/27 03:28:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.2802	Prec@(1,5) (41.0%, 72.5%)
12/27 03:28:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.2830	Prec@(1,5) (40.7%, 72.4%)
12/27 03:28:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.3006	Prec@(1,5) (40.4%, 72.1%)
12/27 03:28:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.2920	Prec@(1,5) (40.7%, 72.2%)
12/27 03:28:51午前 searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 40.6560%
12/27 03:28:51午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/27 03:28:51午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 41.8520%
12/27 03:29:37午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.3280 (1.6049)	Arch Loss 1.7962 (2.1597)	Arch Hard Loss 1.7962 (2.1597)	Arch Beta Loss 2.7610 (2.7618)	Arch depth Loss 0.2761 (0.2762)	Prec@(1,5) (54.1%, 85.6%)	
12/27 03:30:20午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.6288 (1.6533)	Arch Loss 2.3506 (2.1729)	Arch Hard Loss 2.3506 (2.1729)	Arch Beta Loss 2.7597 (2.7611)	Arch depth Loss 0.2760 (0.2761)	Prec@(1,5) (53.1%, 84.2%)	
12/27 03:31:04午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.0858 (1.6704)	Arch Loss 2.0300 (2.1754)	Arch Hard Loss 2.0300 (2.1754)	Arch Beta Loss 2.7584 (2.7605)	Arch depth Loss 0.2758 (0.2760)	Prec@(1,5) (52.9%, 83.8%)	
12/27 03:31:42午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.5568 (1.6942)	Arch Loss 2.1428 (2.1658)	Arch Hard Loss 2.1428 (2.1658)	Arch Beta Loss 2.7587 (2.7600)	Arch depth Loss 0.2759 (0.2760)	Prec@(1,5) (52.3%, 83.4%)	
12/27 03:31:43午前 searchDistribution_trainer.py:166 [INFO] Train: [ 23/49] Final Prec@1 52.2280%
12/27 03:31:49午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.1982	Prec@(1,5) (43.2%, 74.9%)
12/27 03:31:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.2015	Prec@(1,5) (42.7%, 74.4%)
12/27 03:32:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.2067	Prec@(1,5) (42.5%, 74.4%)
12/27 03:32:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.2045	Prec@(1,5) (42.5%, 74.6%)
12/27 03:32:08午前 searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 42.5400%
12/27 03:32:08午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 03:32:09午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 42.5400%
12/27 03:32:54午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.3397 (1.5532)	Arch Loss 2.2320 (2.1394)	Arch Hard Loss 2.2320 (2.1394)	Arch Beta Loss 2.7577 (2.7582)	Arch depth Loss 0.2758 (0.2758)	Prec@(1,5) (55.0%, 85.6%)	
12/27 03:33:37午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.4724 (1.5788)	Arch Loss 2.1283 (2.1451)	Arch Hard Loss 2.1283 (2.1451)	Arch Beta Loss 2.7565 (2.7577)	Arch depth Loss 0.2756 (0.2758)	Prec@(1,5) (54.5%, 85.4%)	
12/27 03:34:21午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.9094 (1.6038)	Arch Loss 2.1745 (2.1456)	Arch Hard Loss 2.1745 (2.1456)	Arch Beta Loss 2.7556 (2.7571)	Arch depth Loss 0.2756 (0.2757)	Prec@(1,5) (54.2%, 84.9%)	
12/27 03:35:00午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.6845 (1.6165)	Arch Loss 2.2342 (2.1510)	Arch Hard Loss 2.2342 (2.1510)	Arch Beta Loss 2.7552 (2.7567)	Arch depth Loss 0.2755 (0.2757)	Prec@(1,5) (53.8%, 84.8%)	
12/27 03:35:01午前 searchDistribution_trainer.py:166 [INFO] Train: [ 24/49] Final Prec@1 53.7880%
12/27 03:35:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.2363	Prec@(1,5) (42.5%, 73.3%)
12/27 03:35:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.2353	Prec@(1,5) (42.4%, 73.4%)
12/27 03:35:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.2311	Prec@(1,5) (42.2%, 73.7%)
12/27 03:35:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.2375	Prec@(1,5) (42.0%, 73.6%)
12/27 03:35:26午前 searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 41.9840%
12/27 03:35:26午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 03:35:26午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 42.5400%
12/27 03:36:10午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3407 (1.5037)	Arch Loss 2.1891 (2.1416)	Arch Hard Loss 2.1891 (2.1416)	Arch Beta Loss 2.7543 (2.7547)	Arch depth Loss 0.2754 (0.2755)	Prec@(1,5) (56.6%, 86.7%)	
12/27 03:36:54午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.7433 (1.5301)	Arch Loss 1.7544 (2.1368)	Arch Hard Loss 1.7544 (2.1368)	Arch Beta Loss 2.7534 (2.7543)	Arch depth Loss 0.2753 (0.2754)	Prec@(1,5) (56.1%, 86.2%)	
12/27 03:37:36午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.3750 (1.5492)	Arch Loss 1.8500 (2.1236)	Arch Hard Loss 1.8500 (2.1236)	Arch Beta Loss 2.7521 (2.7537)	Arch depth Loss 0.2752 (0.2754)	Prec@(1,5) (55.7%, 86.0%)	
12/27 03:38:15午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.6557 (1.5610)	Arch Loss 2.3209 (2.1333)	Arch Hard Loss 2.3209 (2.1333)	Arch Beta Loss 2.7510 (2.7532)	Arch depth Loss 0.2751 (0.2753)	Prec@(1,5) (55.4%, 85.7%)	
12/27 03:38:15午前 searchDistribution_trainer.py:166 [INFO] Train: [ 25/49] Final Prec@1 55.4600%
12/27 03:38:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.1589	Prec@(1,5) (44.1%, 75.1%)
12/27 03:38:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.1407	Prec@(1,5) (44.7%, 75.5%)
12/27 03:38:35午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.1446	Prec@(1,5) (44.5%, 75.5%)
12/27 03:38:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.1371	Prec@(1,5) (44.7%, 75.4%)
12/27 03:38:41午前 searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 44.6880%
12/27 03:38:41午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 03:38:41午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 44.6880%
12/27 03:39:25午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.7652 (1.4445)	Arch Loss 2.0186 (2.1134)	Arch Hard Loss 2.0186 (2.1134)	Arch Beta Loss 2.7501 (2.7504)	Arch depth Loss 0.2750 (0.2750)	Prec@(1,5) (58.7%, 87.1%)	
12/27 03:40:09午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.3858 (1.4627)	Arch Loss 2.4466 (2.1316)	Arch Hard Loss 2.4466 (2.1316)	Arch Beta Loss 2.7494 (2.7501)	Arch depth Loss 0.2749 (0.2750)	Prec@(1,5) (57.7%, 86.7%)	
12/27 03:40:53午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2635 (1.4831)	Arch Loss 1.9932 (2.1134)	Arch Hard Loss 1.9932 (2.1134)	Arch Beta Loss 2.7485 (2.7497)	Arch depth Loss 0.2749 (0.2750)	Prec@(1,5) (57.3%, 86.6%)	
12/27 03:41:32午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.9720 (1.5011)	Arch Loss 2.0813 (2.1190)	Arch Hard Loss 2.0813 (2.1190)	Arch Beta Loss 2.7477 (2.7493)	Arch depth Loss 0.2748 (0.2749)	Prec@(1,5) (57.1%, 86.4%)	
12/27 03:41:33午前 searchDistribution_trainer.py:166 [INFO] Train: [ 26/49] Final Prec@1 57.1480%
12/27 03:41:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.1768	Prec@(1,5) (44.0%, 75.3%)
12/27 03:41:45午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.1471	Prec@(1,5) (44.6%, 75.8%)
12/27 03:41:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.1446	Prec@(1,5) (44.8%, 75.7%)
12/27 03:41:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.1413	Prec@(1,5) (44.8%, 75.7%)
12/27 03:41:57午前 searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 44.7760%
12/27 03:41:57午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 03:41:58午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 44.7760%
12/27 03:42:42午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.4583 (1.3670)	Arch Loss 1.8961 (2.0883)	Arch Hard Loss 1.8961 (2.0883)	Arch Beta Loss 2.7468 (2.7471)	Arch depth Loss 0.2747 (0.2747)	Prec@(1,5) (59.8%, 88.5%)	
12/27 03:43:25午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.4990 (1.4172)	Arch Loss 2.1545 (2.1062)	Arch Hard Loss 2.1545 (2.1062)	Arch Beta Loss 2.7463 (2.7468)	Arch depth Loss 0.2746 (0.2747)	Prec@(1,5) (58.8%, 87.9%)	
12/27 03:44:08午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.6644 (1.4417)	Arch Loss 1.4171 (2.0838)	Arch Hard Loss 1.4171 (2.0838)	Arch Beta Loss 2.7452 (2.7464)	Arch depth Loss 0.2745 (0.2746)	Prec@(1,5) (58.2%, 87.3%)	
12/27 03:44:47午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.2624 (1.4660)	Arch Loss 2.4047 (2.0872)	Arch Hard Loss 2.4047 (2.0872)	Arch Beta Loss 2.7450 (2.7462)	Arch depth Loss 0.2745 (0.2746)	Prec@(1,5) (57.8%, 87.0%)	
12/27 03:44:48午前 searchDistribution_trainer.py:166 [INFO] Train: [ 27/49] Final Prec@1 57.7680%
12/27 03:44:54午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.4226	Prec@(1,5) (38.8%, 70.5%)
12/27 03:45:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.4175	Prec@(1,5) (38.9%, 70.8%)
12/27 03:45:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.4164	Prec@(1,5) (39.1%, 70.8%)
12/27 03:45:13午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.4108	Prec@(1,5) (39.5%, 70.8%)
12/27 03:45:13午前 searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 39.4680%
12/27 03:45:13午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 03:45:13午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 44.7760%
12/27 03:45:57午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.5088 (1.3342)	Arch Loss 2.1664 (2.1049)	Arch Hard Loss 2.1664 (2.1049)	Arch Beta Loss 2.7437 (2.7443)	Arch depth Loss 0.2744 (0.2744)	Prec@(1,5) (61.7%, 89.1%)	
12/27 03:46:39午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5654 (1.3665)	Arch Loss 1.9325 (2.0990)	Arch Hard Loss 1.9325 (2.0990)	Arch Beta Loss 2.7427 (2.7438)	Arch depth Loss 0.2743 (0.2744)	Prec@(1,5) (60.6%, 88.6%)	
12/27 03:47:21午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.3517 (1.3800)	Arch Loss 1.9928 (2.1043)	Arch Hard Loss 1.9928 (2.1043)	Arch Beta Loss 2.7424 (2.7434)	Arch depth Loss 0.2742 (0.2743)	Prec@(1,5) (60.3%, 88.4%)	
12/27 03:47:59午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.7166 (1.3931)	Arch Loss 1.7348 (2.0856)	Arch Hard Loss 1.7348 (2.0856)	Arch Beta Loss 2.7420 (2.7431)	Arch depth Loss 0.2742 (0.2743)	Prec@(1,5) (60.0%, 88.3%)	
12/27 03:48:00午前 searchDistribution_trainer.py:166 [INFO] Train: [ 28/49] Final Prec@1 60.0000%
12/27 03:48:06午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.2032	Prec@(1,5) (44.0%, 74.8%)
12/27 03:48:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.1866	Prec@(1,5) (44.0%, 75.2%)
12/27 03:48:18午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.1863	Prec@(1,5) (43.9%, 75.3%)
12/27 03:48:24午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.1877	Prec@(1,5) (43.8%, 75.4%)
12/27 03:48:24午前 searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 43.8320%
12/27 03:48:24午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 03:48:24午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 44.7760%
12/27 03:49:08午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1232 (1.2768)	Arch Loss 1.9015 (2.0894)	Arch Hard Loss 1.9015 (2.0894)	Arch Beta Loss 2.7410 (2.7416)	Arch depth Loss 0.2741 (0.2742)	Prec@(1,5) (63.0%, 89.7%)	
12/27 03:49:51午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.9958 (1.2966)	Arch Loss 1.7818 (2.0673)	Arch Hard Loss 1.7818 (2.0673)	Arch Beta Loss 2.7404 (2.7413)	Arch depth Loss 0.2740 (0.2741)	Prec@(1,5) (62.4%, 89.8%)	
12/27 03:50:34午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.3863 (1.3295)	Arch Loss 2.5666 (2.0587)	Arch Hard Loss 2.5666 (2.0587)	Arch Beta Loss 2.7401 (2.7409)	Arch depth Loss 0.2740 (0.2741)	Prec@(1,5) (61.4%, 89.2%)	
12/27 03:51:14午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.5362 (1.3447)	Arch Loss 1.9508 (2.0697)	Arch Hard Loss 1.9508 (2.0697)	Arch Beta Loss 2.7401 (2.7408)	Arch depth Loss 0.2740 (0.2741)	Prec@(1,5) (60.8%, 89.0%)	
12/27 03:51:15午前 searchDistribution_trainer.py:166 [INFO] Train: [ 29/49] Final Prec@1 60.8120%
12/27 03:51:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.1559	Prec@(1,5) (46.1%, 76.0%)
12/27 03:51:28午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.1954	Prec@(1,5) (45.0%, 75.2%)
12/27 03:51:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2027	Prec@(1,5) (44.8%, 75.2%)
12/27 03:51:40午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.1886	Prec@(1,5) (44.8%, 75.4%)
12/27 03:51:40午前 searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 44.8160%
12/27 03:51:40午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 03:51:41午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 44.8160%
12/27 03:52:25午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.5970 (1.2394)	Arch Loss 2.3860 (2.0877)	Arch Hard Loss 2.3860 (2.0877)	Arch Beta Loss 2.7396 (2.7398)	Arch depth Loss 0.2740 (0.2740)	Prec@(1,5) (63.4%, 90.5%)	
12/27 03:53:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.0072 (1.2578)	Arch Loss 2.5470 (2.0810)	Arch Hard Loss 2.5470 (2.0810)	Arch Beta Loss 2.7393 (2.7397)	Arch depth Loss 0.2739 (0.2740)	Prec@(1,5) (63.0%, 90.3%)	
12/27 03:53:51午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1679 (1.2665)	Arch Loss 2.5285 (2.0761)	Arch Hard Loss 2.5285 (2.0761)	Arch Beta Loss 2.7385 (2.7394)	Arch depth Loss 0.2738 (0.2739)	Prec@(1,5) (62.7%, 90.3%)	
12/27 03:54:31午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.1868 (1.2915)	Arch Loss 2.0581 (2.0672)	Arch Hard Loss 2.0581 (2.0672)	Arch Beta Loss 2.7379 (2.7391)	Arch depth Loss 0.2738 (0.2739)	Prec@(1,5) (61.9%, 89.8%)	
12/27 03:54:31午前 searchDistribution_trainer.py:166 [INFO] Train: [ 30/49] Final Prec@1 61.9200%
12/27 03:54:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.0548	Prec@(1,5) (46.8%, 77.9%)
12/27 03:54:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.0814	Prec@(1,5) (46.5%, 77.7%)
12/27 03:54:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.0946	Prec@(1,5) (46.5%, 77.2%)
12/27 03:54:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.0907	Prec@(1,5) (46.9%, 77.3%)
12/27 03:54:57午前 searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 46.9120%
12/27 03:54:57午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 03:54:57午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 46.9120%
12/27 03:55:41午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.5470 (1.1781)	Arch Loss 1.9897 (2.0068)	Arch Hard Loss 1.9897 (2.0068)	Arch Beta Loss 2.7373 (2.7376)	Arch depth Loss 0.2737 (0.2738)	Prec@(1,5) (64.8%, 91.1%)	
12/27 03:56:24午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.2067 (1.1917)	Arch Loss 1.9698 (2.0426)	Arch Hard Loss 1.9698 (2.0426)	Arch Beta Loss 2.7374 (2.7376)	Arch depth Loss 0.2737 (0.2738)	Prec@(1,5) (64.4%, 91.0%)	
12/27 03:57:06午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1645 (1.2180)	Arch Loss 2.2067 (2.0543)	Arch Hard Loss 2.2067 (2.0543)	Arch Beta Loss 2.7373 (2.7375)	Arch depth Loss 0.2737 (0.2738)	Prec@(1,5) (64.0%, 90.6%)	
12/27 03:57:44午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.2071 (1.2316)	Arch Loss 1.9994 (2.0636)	Arch Hard Loss 1.9994 (2.0636)	Arch Beta Loss 2.7367 (2.7374)	Arch depth Loss 0.2737 (0.2737)	Prec@(1,5) (63.7%, 90.4%)	
12/27 03:57:44午前 searchDistribution_trainer.py:166 [INFO] Train: [ 31/49] Final Prec@1 63.7400%
12/27 03:57:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1235	Prec@(1,5) (45.8%, 76.9%)
12/27 03:57:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1208	Prec@(1,5) (46.2%, 76.7%)
12/27 03:58:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.1216	Prec@(1,5) (46.2%, 76.8%)
12/27 03:58:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.1238	Prec@(1,5) (46.3%, 76.8%)
12/27 03:58:09午前 searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 46.2720%
12/27 03:58:09午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 03:58:09午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 46.9120%
12/27 03:58:54午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.1306 (1.1258)	Arch Loss 2.3858 (2.0134)	Arch Hard Loss 2.3858 (2.0134)	Arch Beta Loss 2.7370 (2.7368)	Arch depth Loss 0.2737 (0.2737)	Prec@(1,5) (66.9%, 91.7%)	
12/27 03:59:38午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.4951 (1.1359)	Arch Loss 2.1437 (2.0607)	Arch Hard Loss 2.1437 (2.0607)	Arch Beta Loss 2.7361 (2.7367)	Arch depth Loss 0.2736 (0.2737)	Prec@(1,5) (66.2%, 91.6%)	
12/27 04:00:22午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.1566 (1.1541)	Arch Loss 2.3254 (2.0534)	Arch Hard Loss 2.3254 (2.0534)	Arch Beta Loss 2.7359 (2.7365)	Arch depth Loss 0.2736 (0.2736)	Prec@(1,5) (65.7%, 91.7%)	
12/27 04:01:01午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.2055 (1.1740)	Arch Loss 2.0391 (2.0546)	Arch Hard Loss 2.0391 (2.0546)	Arch Beta Loss 2.7354 (2.7363)	Arch depth Loss 0.2735 (0.2736)	Prec@(1,5) (65.2%, 91.4%)	
12/27 04:01:01午前 searchDistribution_trainer.py:166 [INFO] Train: [ 32/49] Final Prec@1 65.1680%
12/27 04:01:09午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.1892	Prec@(1,5) (46.0%, 76.7%)
12/27 04:01:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1810	Prec@(1,5) (46.3%, 76.7%)
12/27 04:01:22午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1832	Prec@(1,5) (46.3%, 76.7%)
12/27 04:01:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.1638	Prec@(1,5) (46.5%, 76.9%)
12/27 04:01:27午前 searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 46.4600%
12/27 04:01:27午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 04:01:28午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 46.9120%
12/27 04:02:11午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.0896 (1.0712)	Arch Loss 2.3724 (2.0358)	Arch Hard Loss 2.3724 (2.0358)	Arch Beta Loss 2.7347 (2.7352)	Arch depth Loss 0.2735 (0.2735)	Prec@(1,5) (68.7%, 92.8%)	
12/27 04:02:56午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8636 (1.0975)	Arch Loss 1.9918 (2.0580)	Arch Hard Loss 1.9918 (2.0580)	Arch Beta Loss 2.7340 (2.7348)	Arch depth Loss 0.2734 (0.2735)	Prec@(1,5) (67.8%, 92.1%)	
12/27 04:03:39午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2528 (1.1065)	Arch Loss 1.8401 (2.0637)	Arch Hard Loss 1.8401 (2.0637)	Arch Beta Loss 2.7331 (2.7344)	Arch depth Loss 0.2733 (0.2734)	Prec@(1,5) (67.4%, 92.1%)	
12/27 04:04:19午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.1978 (1.1236)	Arch Loss 1.9975 (2.0647)	Arch Hard Loss 1.9975 (2.0647)	Arch Beta Loss 2.7327 (2.7341)	Arch depth Loss 0.2733 (0.2734)	Prec@(1,5) (66.9%, 91.9%)	
12/27 04:04:19午前 searchDistribution_trainer.py:166 [INFO] Train: [ 33/49] Final Prec@1 66.8600%
12/27 04:04:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.0731	Prec@(1,5) (48.2%, 77.2%)
12/27 04:04:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.0587	Prec@(1,5) (48.4%, 77.8%)
12/27 04:04:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.0462	Prec@(1,5) (48.5%, 78.0%)
12/27 04:04:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.0486	Prec@(1,5) (48.5%, 78.1%)
12/27 04:04:44午前 searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 48.4520%
12/27 04:04:44午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 04:04:45午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.4520%
12/27 04:05:29午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.1400 (0.9947)	Arch Loss 2.0606 (2.0401)	Arch Hard Loss 2.0606 (2.0401)	Arch Beta Loss 2.7324 (2.7327)	Arch depth Loss 0.2732 (0.2733)	Prec@(1,5) (70.2%, 93.7%)	
12/27 04:06:12午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.3221 (1.0199)	Arch Loss 2.0658 (2.0691)	Arch Hard Loss 2.0658 (2.0691)	Arch Beta Loss 2.7322 (2.7325)	Arch depth Loss 0.2732 (0.2733)	Prec@(1,5) (69.7%, 93.3%)	
12/27 04:06:55午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.1538 (1.0369)	Arch Loss 1.7861 (2.0555)	Arch Hard Loss 1.7861 (2.0555)	Arch Beta Loss 2.7322 (2.7324)	Arch depth Loss 0.2732 (0.2732)	Prec@(1,5) (69.1%, 93.1%)	
12/27 04:07:34午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.4875 (1.0502)	Arch Loss 1.9574 (2.0498)	Arch Hard Loss 1.9574 (2.0498)	Arch Beta Loss 2.7321 (2.7324)	Arch depth Loss 0.2732 (0.2732)	Prec@(1,5) (68.7%, 92.9%)	
12/27 04:07:34午前 searchDistribution_trainer.py:166 [INFO] Train: [ 34/49] Final Prec@1 68.6760%
12/27 04:07:41午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1252	Prec@(1,5) (47.7%, 77.5%)
12/27 04:07:47午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1076	Prec@(1,5) (47.9%, 77.8%)
12/27 04:07:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1228	Prec@(1,5) (47.8%, 77.6%)
12/27 04:07:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1069	Prec@(1,5) (48.1%, 77.7%)
12/27 04:07:59午前 searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 48.0800%
12/27 04:07:59午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 04:07:59午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.4520%
12/27 04:08:43午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.8743 (0.9515)	Arch Loss 2.2060 (2.0618)	Arch Hard Loss 2.2060 (2.0618)	Arch Beta Loss 2.7316 (2.7321)	Arch depth Loss 0.2732 (0.2732)	Prec@(1,5) (71.6%, 94.2%)	
12/27 04:09:26午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.1494 (0.9737)	Arch Loss 1.8196 (2.0592)	Arch Hard Loss 1.8196 (2.0592)	Arch Beta Loss 2.7318 (2.7319)	Arch depth Loss 0.2732 (0.2732)	Prec@(1,5) (70.8%, 94.1%)	
12/27 04:10:10午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.2534 (0.9894)	Arch Loss 2.4079 (2.0612)	Arch Hard Loss 2.4079 (2.0612)	Arch Beta Loss 2.7315 (2.7318)	Arch depth Loss 0.2731 (0.2732)	Prec@(1,5) (70.3%, 93.8%)	
12/27 04:10:50午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1386 (0.9972)	Arch Loss 1.7774 (2.0605)	Arch Hard Loss 1.7774 (2.0605)	Arch Beta Loss 2.7310 (2.7316)	Arch depth Loss 0.2731 (0.2732)	Prec@(1,5) (70.2%, 93.7%)	
12/27 04:10:50午前 searchDistribution_trainer.py:166 [INFO] Train: [ 35/49] Final Prec@1 70.2400%
12/27 04:10:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.0541	Prec@(1,5) (48.3%, 78.6%)
12/27 04:11:04午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.0548	Prec@(1,5) (48.6%, 78.9%)
12/27 04:11:11午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.0669	Prec@(1,5) (48.5%, 78.7%)
12/27 04:11:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.0819	Prec@(1,5) (48.1%, 78.4%)
12/27 04:11:17午前 searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 48.0720%
12/27 04:11:17午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG3_concat=range(9, 11))
12/27 04:11:17午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.4520%
12/27 04:12:02午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.7531 (0.9098)	Arch Loss 1.8880 (2.0647)	Arch Hard Loss 1.8880 (2.0647)	Arch Beta Loss 2.7306 (2.7308)	Arch depth Loss 0.2731 (0.2731)	Prec@(1,5) (73.3%, 94.8%)	
12/27 04:12:46午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.2366 (0.9256)	Arch Loss 2.1153 (2.0585)	Arch Hard Loss 2.1153 (2.0585)	Arch Beta Loss 2.7303 (2.7307)	Arch depth Loss 0.2730 (0.2731)	Prec@(1,5) (72.6%, 94.5%)	
12/27 04:13:29午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.7549 (0.9343)	Arch Loss 2.5214 (2.0422)	Arch Hard Loss 2.5214 (2.0422)	Arch Beta Loss 2.7299 (2.7305)	Arch depth Loss 0.2730 (0.2730)	Prec@(1,5) (72.0%, 94.3%)	
12/27 04:14:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.9420 (0.9417)	Arch Loss 2.0127 (2.0563)	Arch Hard Loss 2.0127 (2.0563)	Arch Beta Loss 2.7299 (2.7304)	Arch depth Loss 0.2730 (0.2730)	Prec@(1,5) (71.8%, 94.2%)	
12/27 04:14:07午前 searchDistribution_trainer.py:166 [INFO] Train: [ 36/49] Final Prec@1 71.7640%
12/27 04:14:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.5200	Prec@(1,5) (42.0%, 71.9%)
12/27 04:14:20午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.5257	Prec@(1,5) (41.9%, 71.8%)
12/27 04:14:27午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.5403	Prec@(1,5) (41.8%, 71.9%)
12/27 04:14:34午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.5487	Prec@(1,5) (41.8%, 71.8%)
12/27 04:14:34午前 searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 41.7400%
12/27 04:14:34午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:14:34午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.4520%
12/27 04:15:18午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.0161 (0.8516)	Arch Loss 1.4979 (2.0554)	Arch Hard Loss 1.4979 (2.0554)	Arch Beta Loss 2.7299 (2.7299)	Arch depth Loss 0.2730 (0.2730)	Prec@(1,5) (74.9%, 95.2%)	
12/27 04:16:02午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.9850 (0.8692)	Arch Loss 2.4462 (2.0709)	Arch Hard Loss 2.4462 (2.0709)	Arch Beta Loss 2.7298 (2.7298)	Arch depth Loss 0.2730 (0.2730)	Prec@(1,5) (74.0%, 95.0%)	
12/27 04:16:46午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0101 (0.8824)	Arch Loss 2.2196 (2.0680)	Arch Hard Loss 2.2196 (2.0680)	Arch Beta Loss 2.7292 (2.7297)	Arch depth Loss 0.2729 (0.2730)	Prec@(1,5) (73.5%, 94.9%)	
12/27 04:17:28午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.9946 (0.8889)	Arch Loss 2.0027 (2.0653)	Arch Hard Loss 2.0027 (2.0653)	Arch Beta Loss 2.7286 (2.7296)	Arch depth Loss 0.2729 (0.2730)	Prec@(1,5) (73.3%, 94.9%)	
12/27 04:17:28午前 searchDistribution_trainer.py:166 [INFO] Train: [ 37/49] Final Prec@1 73.3280%
12/27 04:17:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.3282	Prec@(1,5) (45.2%, 75.4%)
12/27 04:17:43午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.2826	Prec@(1,5) (45.7%, 75.8%)
12/27 04:17:51午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.2762	Prec@(1,5) (45.5%, 75.8%)
12/27 04:17:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.2749	Prec@(1,5) (45.6%, 75.9%)
12/27 04:17:58午前 searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 45.5560%
12/27 04:17:58午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:17:58午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.4520%
12/27 04:18:47午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.6823 (0.8084)	Arch Loss 1.8750 (2.0950)	Arch Hard Loss 1.8750 (2.0950)	Arch Beta Loss 2.7285 (2.7286)	Arch depth Loss 0.2728 (0.2729)	Prec@(1,5) (75.3%, 95.7%)	
12/27 04:19:36午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 1.3167 (0.8255)	Arch Loss 2.0006 (2.0739)	Arch Hard Loss 2.0006 (2.0739)	Arch Beta Loss 2.7286 (2.7286)	Arch depth Loss 0.2729 (0.2729)	Prec@(1,5) (74.9%, 95.3%)	
12/27 04:20:24午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.6723 (0.8354)	Arch Loss 2.3372 (2.0835)	Arch Hard Loss 2.3372 (2.0835)	Arch Beta Loss 2.7283 (2.7286)	Arch depth Loss 0.2728 (0.2729)	Prec@(1,5) (74.7%, 95.3%)	
12/27 04:21:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.0677 (0.8428)	Arch Loss 2.4279 (2.0791)	Arch Hard Loss 2.4279 (2.0791)	Arch Beta Loss 2.7278 (2.7284)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (74.6%, 95.2%)	
12/27 04:21:08午前 searchDistribution_trainer.py:166 [INFO] Train: [ 38/49] Final Prec@1 74.6040%
12/27 04:21:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.3580	Prec@(1,5) (44.7%, 74.2%)
12/27 04:21:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.3438	Prec@(1,5) (44.6%, 74.5%)
12/27 04:21:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.3378	Prec@(1,5) (44.6%, 74.7%)
12/27 04:21:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.3421	Prec@(1,5) (44.3%, 74.6%)
12/27 04:21:38午前 searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 44.2640%
12/27 04:21:38午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:21:38午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.4520%
12/27 04:22:26午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.7834 (0.7668)	Arch Loss 1.7655 (2.1103)	Arch Hard Loss 1.7655 (2.1103)	Arch Beta Loss 2.7283 (2.7280)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (77.1%, 96.0%)	
12/27 04:23:13午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7620 (0.7706)	Arch Loss 2.0122 (2.0705)	Arch Hard Loss 2.0122 (2.0705)	Arch Beta Loss 2.7280 (2.7281)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (77.0%, 96.0%)	
12/27 04:24:01午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 1.0565 (0.7856)	Arch Loss 1.5854 (2.0575)	Arch Hard Loss 1.5854 (2.0575)	Arch Beta Loss 2.7277 (2.7280)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (76.4%, 95.8%)	
12/27 04:24:44午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.6194 (0.7952)	Arch Loss 1.9397 (2.0629)	Arch Hard Loss 1.9397 (2.0629)	Arch Beta Loss 2.7277 (2.7279)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (76.1%, 95.8%)	
12/27 04:24:45午前 searchDistribution_trainer.py:166 [INFO] Train: [ 39/49] Final Prec@1 76.1160%
12/27 04:24:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.0844	Prec@(1,5) (49.2%, 79.2%)
12/27 04:25:01午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1271	Prec@(1,5) (48.8%, 78.7%)
12/27 04:25:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1226	Prec@(1,5) (48.8%, 79.0%)
12/27 04:25:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1240	Prec@(1,5) (48.7%, 78.7%)
12/27 04:25:14午前 searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 48.6600%
12/27 04:25:14午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:25:15午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 48.6600%
12/27 04:26:02午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6795 (0.7079)	Arch Loss 2.2380 (2.0434)	Arch Hard Loss 2.2380 (2.0434)	Arch Beta Loss 2.7277 (2.7278)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (78.7%, 96.7%)	
12/27 04:26:48午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.6571 (0.7267)	Arch Loss 1.9474 (2.0633)	Arch Hard Loss 1.9474 (2.0633)	Arch Beta Loss 2.7271 (2.7276)	Arch depth Loss 0.2727 (0.2728)	Prec@(1,5) (78.0%, 96.5%)	
12/27 04:27:33午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.9164 (0.7377)	Arch Loss 1.7323 (2.0748)	Arch Hard Loss 1.7323 (2.0748)	Arch Beta Loss 2.7274 (2.7276)	Arch depth Loss 0.2727 (0.2728)	Prec@(1,5) (77.7%, 96.3%)	
12/27 04:28:14午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.6656 (0.7427)	Arch Loss 1.8146 (2.0723)	Arch Hard Loss 1.8146 (2.0723)	Arch Beta Loss 2.7276 (2.7276)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (77.4%, 96.3%)	
12/27 04:28:14午前 searchDistribution_trainer.py:166 [INFO] Train: [ 40/49] Final Prec@1 77.4400%
12/27 04:28:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.1006	Prec@(1,5) (48.7%, 79.4%)
12/27 04:28:29午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.0429	Prec@(1,5) (50.0%, 79.9%)
12/27 04:28:36午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.0503	Prec@(1,5) (50.0%, 79.5%)
12/27 04:28:42午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.0630	Prec@(1,5) (49.9%, 79.4%)
12/27 04:28:42午前 searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 49.9400%
12/27 04:28:42午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:28:43午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 49.9400%
12/27 04:29:31午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.4624 (0.6687)	Arch Loss 1.5110 (2.0564)	Arch Hard Loss 1.5110 (2.0564)	Arch Beta Loss 2.7276 (2.7275)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (80.6%, 97.2%)	
12/27 04:30:18午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6343 (0.6860)	Arch Loss 2.0891 (2.0722)	Arch Hard Loss 2.0891 (2.0722)	Arch Beta Loss 2.7284 (2.7277)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (79.4%, 97.1%)	
12/27 04:31:06午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5929 (0.6999)	Arch Loss 1.9168 (2.0885)	Arch Hard Loss 1.9168 (2.0885)	Arch Beta Loss 2.7282 (2.7278)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (79.0%, 96.9%)	
12/27 04:31:47午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.7221 (0.7060)	Arch Loss 2.0501 (2.0731)	Arch Hard Loss 2.0501 (2.0731)	Arch Beta Loss 2.7279 (2.7278)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (78.9%, 96.8%)	
12/27 04:31:48午前 searchDistribution_trainer.py:166 [INFO] Train: [ 41/49] Final Prec@1 78.9120%
12/27 04:31:56午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.0827	Prec@(1,5) (49.7%, 79.8%)
12/27 04:32:03午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.0684	Prec@(1,5) (49.7%, 79.4%)
12/27 04:32:10午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.0673	Prec@(1,5) (50.0%, 79.4%)
12/27 04:32:17午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.0842	Prec@(1,5) (49.7%, 79.2%)
12/27 04:32:17午前 searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 49.7360%
12/27 04:32:17午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:32:18午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 49.9400%
12/27 04:33:06午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.8363 (0.6297)	Arch Loss 1.8938 (2.0498)	Arch Hard Loss 1.8938 (2.0498)	Arch Beta Loss 2.7278 (2.7279)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (81.9%, 97.2%)	
12/27 04:33:54午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7097 (0.6431)	Arch Loss 1.7716 (2.0886)	Arch Hard Loss 1.7716 (2.0886)	Arch Beta Loss 2.7271 (2.7278)	Arch depth Loss 0.2727 (0.2728)	Prec@(1,5) (81.1%, 97.2%)	
12/27 04:34:41午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.9444 (0.6633)	Arch Loss 1.9749 (2.0690)	Arch Hard Loss 1.9749 (2.0690)	Arch Beta Loss 2.7277 (2.7276)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (80.3%, 97.0%)	
12/27 04:35:23午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.8122 (0.6687)	Arch Loss 2.0599 (2.0732)	Arch Hard Loss 2.0599 (2.0732)	Arch Beta Loss 2.7272 (2.7276)	Arch depth Loss 0.2727 (0.2728)	Prec@(1,5) (80.1%, 97.0%)	
12/27 04:35:23午前 searchDistribution_trainer.py:166 [INFO] Train: [ 42/49] Final Prec@1 80.0960%
12/27 04:35:31午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.1666	Prec@(1,5) (48.8%, 78.0%)
12/27 04:35:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.1635	Prec@(1,5) (48.5%, 78.0%)
12/27 04:35:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.1331	Prec@(1,5) (48.9%, 78.4%)
12/27 04:35:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.1310	Prec@(1,5) (48.9%, 78.3%)
12/27 04:35:53午前 searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 48.9320%
12/27 04:35:53午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:35:53午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 49.9400%
12/27 04:36:40午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.6850 (0.6235)	Arch Loss 2.0645 (2.0560)	Arch Hard Loss 2.0645 (2.0560)	Arch Beta Loss 2.7274 (2.7273)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (81.6%, 97.3%)	
12/27 04:37:28午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.6462 (0.6227)	Arch Loss 2.7500 (2.0869)	Arch Hard Loss 2.7500 (2.0869)	Arch Beta Loss 2.7273 (2.7273)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (81.9%, 97.3%)	
12/27 04:38:16午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.7201 (0.6277)	Arch Loss 2.2134 (2.0720)	Arch Hard Loss 2.2134 (2.0720)	Arch Beta Loss 2.7267 (2.7272)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (81.4%, 97.5%)	
12/27 04:38:59午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.4573 (0.6344)	Arch Loss 1.8427 (2.0790)	Arch Hard Loss 1.8427 (2.0790)	Arch Beta Loss 2.7269 (2.7271)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (81.0%, 97.3%)	
12/27 04:39:00午前 searchDistribution_trainer.py:166 [INFO] Train: [ 43/49] Final Prec@1 81.0040%
12/27 04:39:08午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.0856	Prec@(1,5) (50.2%, 79.8%)
12/27 04:39:15午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.0936	Prec@(1,5) (50.2%, 79.3%)
12/27 04:39:23午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.1157	Prec@(1,5) (49.7%, 79.1%)
12/27 04:39:30午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.1127	Prec@(1,5) (49.9%, 79.1%)
12/27 04:39:30午前 searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 49.8520%
12/27 04:39:30午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:39:30午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 49.9400%
12/27 04:40:19午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.6443 (0.5718)	Arch Loss 2.0091 (2.0839)	Arch Hard Loss 2.0091 (2.0839)	Arch Beta Loss 2.7272 (2.7270)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.5%, 97.8%)	
12/27 04:41:07午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.5105 (0.5814)	Arch Loss 2.3709 (2.0640)	Arch Hard Loss 2.3709 (2.0640)	Arch Beta Loss 2.7273 (2.7272)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (82.9%, 97.8%)	
12/27 04:41:56午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.6947 (0.5954)	Arch Loss 2.1463 (2.0638)	Arch Hard Loss 2.1463 (2.0638)	Arch Beta Loss 2.7275 (2.7273)	Arch depth Loss 0.2728 (0.2727)	Prec@(1,5) (82.4%, 97.8%)	
12/27 04:42:36午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.6626 (0.6028)	Arch Loss 2.1169 (2.0685)	Arch Hard Loss 2.1169 (2.0685)	Arch Beta Loss 2.7275 (2.7273)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (82.2%, 97.7%)	
12/27 04:42:36午前 searchDistribution_trainer.py:166 [INFO] Train: [ 44/49] Final Prec@1 82.1720%
12/27 04:42:44午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0386	Prec@(1,5) (50.9%, 79.7%)
12/27 04:42:50午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.0373	Prec@(1,5) (50.9%, 79.7%)
12/27 04:42:57午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.0600	Prec@(1,5) (50.6%, 79.4%)
12/27 04:43:02午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.0489	Prec@(1,5) (50.8%, 79.6%)
12/27 04:43:02午前 searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 50.8320%
12/27 04:43:02午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:43:03午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 50.8320%
12/27 04:43:47午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.4755 (0.5571)	Arch Loss 2.3374 (2.0906)	Arch Hard Loss 2.3374 (2.0906)	Arch Beta Loss 2.7270 (2.7272)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (84.2%, 98.2%)	
12/27 04:44:31午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5423 (0.5712)	Arch Loss 1.9750 (2.0932)	Arch Hard Loss 1.9750 (2.0932)	Arch Beta Loss 2.7268 (2.7271)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.6%, 97.9%)	
12/27 04:45:14午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.5165 (0.5798)	Arch Loss 1.8511 (2.0856)	Arch Hard Loss 1.8511 (2.0856)	Arch Beta Loss 2.7267 (2.7270)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.4%, 97.9%)	
12/27 04:45:53午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.6964 (0.5833)	Arch Loss 1.8647 (2.0789)	Arch Hard Loss 1.8647 (2.0789)	Arch Beta Loss 2.7268 (2.7270)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.1%, 97.8%)	
12/27 04:45:54午前 searchDistribution_trainer.py:166 [INFO] Train: [ 45/49] Final Prec@1 83.1280%
12/27 04:46:00午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.0058	Prec@(1,5) (51.6%, 80.5%)
12/27 04:46:07午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.0109	Prec@(1,5) (51.5%, 80.4%)
12/27 04:46:14午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.0178	Prec@(1,5) (51.3%, 80.3%)
12/27 04:46:21午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.0408	Prec@(1,5) (51.0%, 80.0%)
12/27 04:46:21午前 searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 51.0240%
12/27 04:46:21午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:46:22午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.0240%
12/27 04:47:05午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.5180 (0.5607)	Arch Loss 1.7697 (2.0596)	Arch Hard Loss 1.7697 (2.0596)	Arch Beta Loss 2.7270 (2.7269)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (84.1%, 97.9%)	
12/27 04:47:47午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5255 (0.5632)	Arch Loss 2.0027 (2.0633)	Arch Hard Loss 2.0027 (2.0633)	Arch Beta Loss 2.7270 (2.7270)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.7%, 98.0%)	
12/27 04:48:30午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.3566 (0.5649)	Arch Loss 2.3331 (2.0955)	Arch Hard Loss 2.3331 (2.0955)	Arch Beta Loss 2.7272 (2.7270)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.7%, 97.9%)	
12/27 04:49:11午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.5631 (0.5675)	Arch Loss 1.8522 (2.0879)	Arch Hard Loss 1.8522 (2.0879)	Arch Beta Loss 2.7269 (2.7271)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (83.6%, 97.9%)	
12/27 04:49:12午前 searchDistribution_trainer.py:166 [INFO] Train: [ 46/49] Final Prec@1 83.5840%
12/27 04:49:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.0478	Prec@(1,5) (51.5%, 79.7%)
12/27 04:49:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.0413	Prec@(1,5) (51.1%, 79.6%)
12/27 04:49:32午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.0465	Prec@(1,5) (51.2%, 79.8%)
12/27 04:49:38午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.0494	Prec@(1,5) (51.0%, 79.7%)
12/27 04:49:39午前 searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 50.9200%
12/27 04:49:39午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/27 04:49:39午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.0240%
12/27 04:50:24午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.7432 (0.5255)	Arch Loss 1.8471 (2.0852)	Arch Hard Loss 1.8471 (2.0852)	Arch Beta Loss 2.7267 (2.7271)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (84.9%, 98.3%)	
12/27 04:51:09午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.7953 (0.5414)	Arch Loss 3.1228 (2.0733)	Arch Hard Loss 3.1228 (2.0733)	Arch Beta Loss 2.7272 (2.7271)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (84.4%, 98.0%)	
12/27 04:51:52午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.5893 (0.5459)	Arch Loss 1.9458 (2.0751)	Arch Hard Loss 1.9458 (2.0751)	Arch Beta Loss 2.7274 (2.7271)	Arch depth Loss 0.2727 (0.2727)	Prec@(1,5) (84.2%, 98.0%)	
12/27 04:52:31午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.4873 (0.5524)	Arch Loss 1.7441 (2.0730)	Arch Hard Loss 1.7441 (2.0730)	Arch Beta Loss 2.7278 (2.7272)	Arch depth Loss 0.2728 (0.2727)	Prec@(1,5) (84.0%, 98.0%)	
12/27 04:52:32午前 searchDistribution_trainer.py:166 [INFO] Train: [ 47/49] Final Prec@1 84.0400%
12/27 04:52:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.1031	Prec@(1,5) (49.6%, 79.3%)
12/27 04:52:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.1250	Prec@(1,5) (49.6%, 79.2%)
12/27 04:52:52午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.1097	Prec@(1,5) (50.1%, 79.4%)
12/27 04:52:58午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.1036	Prec@(1,5) (50.3%, 79.3%)
12/27 04:52:58午前 searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 50.2560%
12/27 04:52:58午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
12/27 04:52:59午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.0240%
12/27 04:53:45午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.3278 (0.5010)	Arch Loss 1.9455 (2.0512)	Arch Hard Loss 1.9455 (2.0512)	Arch Beta Loss 2.7279 (2.7278)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (86.2%, 98.3%)	
12/27 04:54:34午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.6783 (0.5253)	Arch Loss 2.4274 (2.0842)	Arch Hard Loss 2.4274 (2.0842)	Arch Beta Loss 2.7274 (2.7278)	Arch depth Loss 0.2727 (0.2728)	Prec@(1,5) (85.1%, 98.3%)	
12/27 04:55:21午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.4920 (0.5306)	Arch Loss 1.9584 (2.0802)	Arch Hard Loss 1.9584 (2.0802)	Arch Beta Loss 2.7270 (2.7276)	Arch depth Loss 0.2727 (0.2728)	Prec@(1,5) (84.9%, 98.3%)	
12/27 04:56:03午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.7029 (0.5438)	Arch Loss 2.1439 (2.0802)	Arch Hard Loss 2.1439 (2.0802)	Arch Beta Loss 2.7280 (2.7276)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (84.3%, 98.2%)	
12/27 04:56:04午前 searchDistribution_trainer.py:166 [INFO] Train: [ 48/49] Final Prec@1 84.3320%
12/27 04:56:12午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.0530	Prec@(1,5) (50.9%, 79.9%)
12/27 04:56:19午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.0477	Prec@(1,5) (51.1%, 79.9%)
12/27 04:56:26午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.0423	Prec@(1,5) (51.3%, 80.0%)
12/27 04:56:33午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.0387	Prec@(1,5) (51.3%, 80.1%)
12/27 04:56:33午前 searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 51.3160%
12/27 04:56:33午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
12/27 04:56:34午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.3160%
12/27 04:57:20午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4411 (0.5191)	Arch Loss 2.0038 (2.0615)	Arch Hard Loss 2.0038 (2.0615)	Arch Beta Loss 2.7277 (2.7278)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (85.2%, 98.4%)	
12/27 04:58:06午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5697 (0.5214)	Arch Loss 2.0142 (2.0800)	Arch Hard Loss 2.0142 (2.0800)	Arch Beta Loss 2.7285 (2.7280)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (85.2%, 98.3%)	
12/27 04:58:51午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.5517 (0.5314)	Arch Loss 2.0079 (2.0654)	Arch Hard Loss 2.0079 (2.0654)	Arch Beta Loss 2.7281 (2.7281)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (84.8%, 98.2%)	
12/27 04:59:32午前 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5210 (0.5379)	Arch Loss 2.1065 (2.0755)	Arch Hard Loss 2.1065 (2.0755)	Arch Beta Loss 2.7279 (2.7280)	Arch depth Loss 0.2728 (0.2728)	Prec@(1,5) (84.6%, 98.2%)	
12/27 04:59:32午前 searchDistribution_trainer.py:166 [INFO] Train: [ 49/49] Final Prec@1 84.6600%
12/27 04:59:39午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.0848	Prec@(1,5) (49.8%, 79.5%)
12/27 04:59:46午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.0631	Prec@(1,5) (50.5%, 79.8%)
12/27 04:59:53午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.0506	Prec@(1,5) (50.7%, 80.0%)
12/27 04:59:59午前 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.0489	Prec@(1,5) (50.9%, 80.1%)
12/27 04:59:59午前 searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 50.8920%
12/27 04:59:59午前 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
12/27 05:00:00午前 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.3160%
12/27 05:00:00午前 trainer_runner.py:113 [INFO] Final best Prec@1 = 51.3160%
12/27 05:00:00午前 trainer_runner.py:114 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
