11/20 11:18:55AM parser.py:28 [INFO] 
11/20 11:18:55AM parser.py:29 [INFO] Parameters:
11/20 11:18:55AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s1-l1-sw3-g1/DAG
11/20 11:18:55AM parser.py:31 [INFO] T=10.0
11/20 11:18:55AM parser.py:31 [INFO] ADVANCED=1
11/20 11:18:55AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/20 11:18:55AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/20 11:18:55AM parser.py:31 [INFO] ARCH_CRITERION=l1
11/20 11:18:55AM parser.py:31 [INFO] BATCH_SIZE=64
11/20 11:18:55AM parser.py:31 [INFO] CASCADE=0
11/20 11:18:55AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/20 11:18:55AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/20 11:18:55AM parser.py:31 [INFO] DATA_PATH=../data/
11/20 11:18:55AM parser.py:31 [INFO] DATASET=cifar100
11/20 11:18:55AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/20 11:18:55AM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/20 11:18:55AM parser.py:31 [INFO] DISCRETE=0
11/20 11:18:55AM parser.py:31 [INFO] EPOCHS=50
11/20 11:18:55AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/20 11:18:55AM parser.py:31 [INFO] EXP_NAME=s1-l1-sw3-g1
11/20 11:18:55AM parser.py:31 [INFO] FINAL_L=0.0
11/20 11:18:55AM parser.py:31 [INFO] G=1.0
11/20 11:18:55AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/20 11:18:55AM parser.py:31 [INFO] GPUS=[0]
11/20 11:18:55AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/20 11:18:55AM parser.py:31 [INFO] INIT_CHANNELS=16
11/20 11:18:55AM parser.py:31 [INFO] L=0.0
11/20 11:18:55AM parser.py:31 [INFO] LAYERS=32
11/20 11:18:55AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/20 11:18:55AM parser.py:31 [INFO] NAME=Pruning
11/20 11:18:55AM parser.py:31 [INFO] NONKD=1
11/20 11:18:55AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s1-l1-sw3-g1
11/20 11:18:55AM parser.py:31 [INFO] PCDARTS=0
11/20 11:18:55AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s1-l1-sw3-g1/plots
11/20 11:18:55AM parser.py:31 [INFO] PRINT_FREQ=100
11/20 11:18:55AM parser.py:31 [INFO] RESET=0
11/20 11:18:55AM parser.py:31 [INFO] RESUME_PATH=None
11/20 11:18:55AM parser.py:31 [INFO] SAVE=s1-l1-sw3-g1
11/20 11:18:55AM parser.py:31 [INFO] SEED=1
11/20 11:18:55AM parser.py:31 [INFO] SHARE_STAGE=0
11/20 11:18:55AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/20 11:18:55AM parser.py:31 [INFO] SPEC_CELL=1
11/20 11:18:55AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/20 11:18:55AM parser.py:31 [INFO] TEACHER_NAME=none
11/20 11:18:55AM parser.py:31 [INFO] TEACHER_PATH=none
11/20 11:18:55AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/20 11:18:55AM parser.py:31 [INFO] TYPE=Pruning
11/20 11:18:55AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/20 11:18:55AM parser.py:31 [INFO] W_LR=0.025
11/20 11:18:55AM parser.py:31 [INFO] W_LR_MIN=0.001
11/20 11:18:55AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/20 11:18:55AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/20 11:18:55AM parser.py:31 [INFO] WORKERS=4
11/20 11:18:55AM parser.py:32 [INFO] 
11/20 11:18:56AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/20 11:19:52AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.5529 (4.5323)	Arch Loss 4.5133 (4.5301)	Arch Hard Loss 4.5093 (4.5256)	Arch Beta Loss 0.0040 (0.0045)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.2%, 9.2%)	
11/20 11:20:47AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.2902 (4.4156)	Arch Loss 4.2654 (4.4153)	Arch Hard Loss 4.2613 (4.4112)	Arch Beta Loss 0.0041 (0.0040)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.0%, 12.5%)	
11/20 11:21:41AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.0871 (4.3215)	Arch Loss 4.1576 (4.3127)	Arch Hard Loss 4.1536 (4.3088)	Arch Beta Loss 0.0040 (0.0039)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 15.5%)	
11/20 11:22:30AM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.2596 (4.2486)	Arch Loss 4.0780 (4.2353)	Arch Hard Loss 4.0744 (4.2315)	Arch Beta Loss 0.0036 (0.0038)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.7%, 17.9%)	
11/20 11:22:31AM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  0/49] Final Prec@1 4.6480%
11/20 11:22:41AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9598	Prec@(1,5) (7.3%, 27.5%)
11/20 11:22:50AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9499	Prec@(1,5) (7.5%, 27.3%)
11/20 11:22:59AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9497	Prec@(1,5) (7.5%, 27.2%)
11/20 11:23:07AM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9438	Prec@(1,5) (7.5%, 27.5%)
11/20 11:23:07AM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 7.4600%
11/20 11:23:07AM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 5], DAG2=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[3, 7])
11/20 11:23:08AM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.4600%
11/20 11:24:03午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9106 (3.8855)	Arch Loss 3.9263 (3.8927)	Arch Hard Loss 3.9232 (3.8892)	Arch Beta Loss 0.0032 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.5%, 29.2%)	
11/20 11:24:58午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.8030 (3.8562)	Arch Loss 3.9067 (3.8533)	Arch Hard Loss 3.9034 (3.8498)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.2%, 30.1%)	
11/20 11:25:52午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.7965 (3.8214)	Arch Loss 3.8791 (3.8089)	Arch Hard Loss 3.8758 (3.8054)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.8%, 31.6%)	
11/20 11:26:41午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7002 (3.7920)	Arch Loss 3.5718 (3.7709)	Arch Hard Loss 3.5684 (3.7674)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.5%, 32.6%)	
11/20 11:26:42午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  1/49] Final Prec@1 10.5440%
11/20 11:26:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6583	Prec@(1,5) (12.6%, 36.8%)
11/20 11:27:00午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6655	Prec@(1,5) (12.6%, 36.7%)
11/20 11:27:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6489	Prec@(1,5) (13.1%, 37.4%)
11/20 11:27:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6437	Prec@(1,5) (13.1%, 37.4%)
11/20 11:27:18午前 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 13.1320%
11/20 11:27:18午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[7, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[5, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[5, 10])
11/20 11:27:18午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 13.1320%
11/20 11:28:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.6272 (3.5636)	Arch Loss 3.5160 (3.5983)	Arch Hard Loss 3.5125 (3.5949)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.4%, 39.2%)	
11/20 11:29:08午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5760 (3.5530)	Arch Loss 3.4525 (3.5531)	Arch Hard Loss 3.4488 (3.5497)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.6%, 39.8%)	
11/20 11:30:02午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.4916 (3.5181)	Arch Loss 3.4225 (3.5232)	Arch Hard Loss 3.4187 (3.5199)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.1%, 41.2%)	
11/20 11:30:51午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.3090 (3.4950)	Arch Loss 3.2362 (3.4904)	Arch Hard Loss 3.2327 (3.4870)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.8%)	
11/20 11:30:52午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  2/49] Final Prec@1 15.3400%
11/20 11:31:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3543	Prec@(1,5) (17.5%, 46.3%)
11/20 11:31:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3516	Prec@(1,5) (18.0%, 46.0%)
11/20 11:31:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3517	Prec@(1,5) (18.1%, 46.1%)
11/20 11:31:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3535	Prec@(1,5) (18.2%, 46.0%)
11/20 11:31:28午前 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 18.1640%
11/20 11:31:28午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[4, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
11/20 11:31:29午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 18.1640%
11/20 11:32:24午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.3858 (3.3036)	Arch Loss 3.6600 (3.3616)	Arch Hard Loss 3.6567 (3.3582)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.4%, 47.4%)	
11/20 11:33:18午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1992 (3.2792)	Arch Loss 3.1888 (3.3279)	Arch Hard Loss 3.1856 (3.3245)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.0%, 48.4%)	
11/20 11:34:13午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.2476 (3.2637)	Arch Loss 3.1892 (3.2834)	Arch Hard Loss 3.1860 (3.2800)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.5%, 48.6%)	
11/20 11:35:02午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.7886 (3.2417)	Arch Loss 3.4136 (3.2585)	Arch Hard Loss 3.4105 (3.2551)	Arch Beta Loss 0.0030 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.9%, 49.2%)	
11/20 11:35:02午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  3/49] Final Prec@1 19.9040%
11/20 11:35:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2158	Prec@(1,5) (20.6%, 51.0%)
11/20 11:35:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2064	Prec@(1,5) (20.8%, 51.0%)
11/20 11:35:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2056	Prec@(1,5) (20.9%, 50.9%)
11/20 11:35:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2020	Prec@(1,5) (20.8%, 50.9%)
11/20 11:35:38午前 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 20.8080%
11/20 11:35:38午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG1_concat=[2, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[4, 8], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 8])
11/20 11:35:39午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.8080%
11/20 11:36:34午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.2095 (3.0609)	Arch Loss 2.9660 (3.1426)	Arch Hard Loss 2.9627 (3.1393)	Arch Beta Loss 0.0033 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.2%, 54.5%)	
11/20 11:37:28午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.0241 (3.0541)	Arch Loss 2.8299 (3.1204)	Arch Hard Loss 2.8264 (3.1171)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.3%, 54.4%)	
11/20 11:38:23午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.2273 (3.0475)	Arch Loss 2.9514 (3.0960)	Arch Hard Loss 2.9480 (3.0928)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.5%, 54.5%)	
11/20 11:39:12午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.0640 (3.0286)	Arch Loss 2.7800 (3.0761)	Arch Hard Loss 2.7764 (3.0728)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (23.8%, 55.1%)	
11/20 11:39:12午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  4/49] Final Prec@1 23.8480%
11/20 11:39:22午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0442	Prec@(1,5) (22.7%, 54.7%)
11/20 11:39:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0322	Prec@(1,5) (23.6%, 54.7%)
11/20 11:39:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0339	Prec@(1,5) (23.7%, 54.8%)
11/20 11:39:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0387	Prec@(1,5) (23.6%, 54.9%)
11/20 11:39:49午前 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 23.6080%
11/20 11:39:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[5, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[8, 9], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[3, 11])
11/20 11:39:49午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 23.6080%
11/20 11:40:44午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.7686 (2.8904)	Arch Loss 3.0584 (2.9686)	Arch Hard Loss 3.0547 (2.9652)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.0%, 58.5%)	
11/20 11:41:39午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.8755 (2.8738)	Arch Loss 2.8616 (2.9430)	Arch Hard Loss 2.8586 (2.9396)	Arch Beta Loss 0.0029 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.5%, 58.6%)	
11/20 11:42:33午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.0104 (2.8683)	Arch Loss 2.5084 (2.9221)	Arch Hard Loss 2.5052 (2.9187)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.6%, 58.8%)	
11/20 11:43:22午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.7220 (2.8515)	Arch Loss 2.8161 (2.9105)	Arch Hard Loss 2.8130 (2.9071)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.1%, 59.2%)	
11/20 11:43:23午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  5/49] Final Prec@1 27.1200%
11/20 11:43:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8144	Prec@(1,5) (28.6%, 60.3%)
11/20 11:43:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8283	Prec@(1,5) (27.8%, 60.1%)
11/20 11:43:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8284	Prec@(1,5) (27.9%, 60.2%)
11/20 11:43:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8280	Prec@(1,5) (28.0%, 60.2%)
11/20 11:43:59午前 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 27.9880%
11/20 11:43:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[4, 10], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 7])
11/20 11:43:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.9880%
11/20 11:44:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.9083 (2.6747)	Arch Loss 3.0277 (2.8189)	Arch Hard Loss 3.0243 (2.8156)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.3%, 63.1%)	
11/20 11:45:49午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.3112 (2.6827)	Arch Loss 2.4737 (2.8133)	Arch Hard Loss 2.4701 (2.8100)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.2%, 63.5%)	
11/20 11:46:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.8750 (2.6884)	Arch Loss 2.6871 (2.7867)	Arch Hard Loss 2.6836 (2.7834)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.4%, 63.2%)	
11/20 11:47:32午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.7643 (2.6807)	Arch Loss 2.9502 (2.7755)	Arch Hard Loss 2.9468 (2.7722)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.7%, 63.3%)	
11/20 11:47:33午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  6/49] Final Prec@1 30.6760%
11/20 11:47:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6688	Prec@(1,5) (30.8%, 62.9%)
11/20 11:47:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6786	Prec@(1,5) (31.0%, 62.7%)
11/20 11:48:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6790	Prec@(1,5) (31.4%, 62.8%)
11/20 11:48:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6748	Prec@(1,5) (31.4%, 63.1%)
11/20 11:48:09午前 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 31.3600%
11/20 11:48:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[6, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[5, 7], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 11])
11/20 11:48:10午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.3600%
11/20 11:49:05午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.4509 (2.5456)	Arch Loss 2.7120 (2.6864)	Arch Hard Loss 2.7089 (2.6832)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.9%, 67.0%)	
11/20 11:49:59午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.7298 (2.5470)	Arch Loss 2.7358 (2.6772)	Arch Hard Loss 2.7325 (2.6739)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.7%, 66.8%)	
11/20 11:50:54午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.6490 (2.5357)	Arch Loss 2.3816 (2.6534)	Arch Hard Loss 2.3784 (2.6500)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.2%, 67.0%)	
11/20 11:51:43午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.3198 (2.5290)	Arch Loss 2.4058 (2.6443)	Arch Hard Loss 2.4020 (2.6410)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.3%, 67.1%)	
11/20 11:51:43午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  7/49] Final Prec@1 33.2920%
11/20 11:51:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5873	Prec@(1,5) (32.6%, 65.2%)
11/20 11:52:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5843	Prec@(1,5) (32.8%, 65.7%)
11/20 11:52:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5816	Prec@(1,5) (32.8%, 65.7%)
11/20 11:52:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5866	Prec@(1,5) (32.8%, 65.6%)
11/20 11:52:19午前 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 32.7800%
11/20 11:52:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[3, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[5, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[6, 11])
11/20 11:52:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.7800%
11/20 11:53:15午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.3109 (2.3771)	Arch Loss 2.8183 (2.6026)	Arch Hard Loss 2.8150 (2.5992)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.3%, 69.7%)	
11/20 11:54:10午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.4437 (2.4147)	Arch Loss 2.7181 (2.5807)	Arch Hard Loss 2.7149 (2.5773)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.3%, 69.3%)	
11/20 11:55:04午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.3808 (2.4107)	Arch Loss 2.5580 (2.5498)	Arch Hard Loss 2.5549 (2.5464)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.3%)	
11/20 11:55:53午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.7039 (2.4094)	Arch Loss 2.6190 (2.5369)	Arch Hard Loss 2.6158 (2.5335)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.4%, 69.5%)	
11/20 11:55:53午前 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  8/49] Final Prec@1 36.4520%
11/20 11:56:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4917	Prec@(1,5) (35.1%, 68.6%)
11/20 11:56:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4820	Prec@(1,5) (35.4%, 68.7%)
11/20 11:56:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5012	Prec@(1,5) (34.9%, 68.2%)
11/20 11:56:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5061	Prec@(1,5) (34.8%, 68.1%)
11/20 11:56:30午前 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 34.7400%
11/20 11:56:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[5, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[6, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[3, 7])
11/20 11:56:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 34.7400%
11/20 11:57:25午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.7114 (2.2762)	Arch Loss 2.7014 (2.4543)	Arch Hard Loss 2.6979 (2.4509)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.9%, 72.4%)	
11/20 11:58:20午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.2178 (2.2942)	Arch Loss 2.2456 (2.4529)	Arch Hard Loss 2.2418 (2.4496)	Arch Beta Loss 0.0038 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 72.0%)	
11/20 11:59:14午前 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.2514 (2.2981)	Arch Loss 2.2903 (2.4743)	Arch Hard Loss 2.2867 (2.4709)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.6%, 71.8%)	
11/20 12:00:03午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.1146 (2.2970)	Arch Loss 2.3598 (2.4525)	Arch Hard Loss 2.3564 (2.4491)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.3%, 71.8%)	
11/20 12:00:04午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  9/49] Final Prec@1 38.3560%
11/20 12:00:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.3238	Prec@(1,5) (39.0%, 71.5%)
11/20 12:00:23午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.3374	Prec@(1,5) (38.5%, 71.2%)
11/20 12:00:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.3546	Prec@(1,5) (38.0%, 70.8%)
11/20 12:00:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.3488	Prec@(1,5) (38.2%, 70.8%)
11/20 12:00:40午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 38.2000%
11/20 12:00:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[6, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[3, 6], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[4, 11])
11/20 12:00:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2000%
11/20 12:01:36午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 1.9748 (2.1730)	Arch Loss 2.2370 (2.4234)	Arch Hard Loss 2.2338 (2.4201)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.9%, 75.3%)	
11/20 12:02:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.0606 (2.1656)	Arch Loss 2.2143 (2.4156)	Arch Hard Loss 2.2110 (2.4122)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.2%, 75.0%)	
11/20 12:03:25午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3172 (2.1818)	Arch Loss 2.3234 (2.3920)	Arch Hard Loss 2.3199 (2.3886)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.2%, 74.5%)	
11/20 12:04:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.2140 (2.1876)	Arch Loss 2.3750 (2.3744)	Arch Hard Loss 2.3717 (2.3711)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 74.3%)	
11/20 12:04:14午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 10/49] Final Prec@1 41.0800%
11/20 12:04:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3436	Prec@(1,5) (38.6%, 71.4%)
11/20 12:04:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3388	Prec@(1,5) (38.3%, 71.2%)
11/20 12:04:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3512	Prec@(1,5) (38.1%, 70.7%)
11/20 12:04:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3630	Prec@(1,5) (37.9%, 70.7%)
11/20 12:04:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 37.9160%
11/20 12:04:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[5, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[5, 6])
11/20 12:04:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.2000%
11/20 12:05:46午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 1.8078 (2.0592)	Arch Loss 2.3302 (2.3460)	Arch Hard Loss 2.3269 (2.3426)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.2%, 76.9%)	
11/20 12:06:40午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 1.8976 (2.0843)	Arch Loss 2.4367 (2.3145)	Arch Hard Loss 2.4332 (2.3112)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.5%, 76.7%)	
11/20 12:07:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.1391 (2.0857)	Arch Loss 2.4621 (2.3115)	Arch Hard Loss 2.4585 (2.3082)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 76.5%)	
11/20 12:08:24午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.3788 (2.0951)	Arch Loss 2.3131 (2.3116)	Arch Hard Loss 2.3096 (2.3082)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.9%, 76.2%)	
11/20 12:08:25午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 11/49] Final Prec@1 42.8920%
11/20 12:08:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3383	Prec@(1,5) (38.9%, 71.7%)
11/20 12:08:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.3311	Prec@(1,5) (38.9%, 71.6%)
11/20 12:08:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.3277	Prec@(1,5) (39.0%, 71.8%)
11/20 12:09:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.3307	Prec@(1,5) (39.0%, 71.6%)
11/20 12:09:01午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 39.0040%
11/20 12:09:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[2, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 12:09:01午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.0040%
11/20 12:09:57午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4750 (1.9759)	Arch Loss 2.1089 (2.2968)	Arch Hard Loss 2.1059 (2.2935)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 78.9%)	
11/20 12:10:51午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.1467 (2.0021)	Arch Loss 2.2484 (2.2637)	Arch Hard Loss 2.2453 (2.2605)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.4%, 78.1%)	
11/20 12:11:46午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.8065 (2.0116)	Arch Loss 2.2895 (2.2431)	Arch Hard Loss 2.2861 (2.2399)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.7%)	
11/20 12:12:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.0088 (2.0235)	Arch Loss 2.2527 (2.2365)	Arch Hard Loss 2.2493 (2.2333)	Arch Beta Loss 0.0034 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 77.6%)	
11/20 12:12:35午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 12/49] Final Prec@1 44.6480%
11/20 12:12:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2016	Prec@(1,5) (42.7%, 73.8%)
11/20 12:12:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2095	Prec@(1,5) (42.3%, 73.6%)
11/20 12:13:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2005	Prec@(1,5) (42.1%, 73.9%)
11/20 12:13:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2067	Prec@(1,5) (41.8%, 73.7%)
11/20 12:13:11午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 41.7320%
11/20 12:13:11午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[4, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[3, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 10])
11/20 12:13:12午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.7320%
11/20 12:14:07午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.7200 (1.8840)	Arch Loss 2.1136 (2.1944)	Arch Hard Loss 2.1104 (2.1912)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.1%)	
11/20 12:15:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.1186 (1.9094)	Arch Loss 2.5617 (2.2089)	Arch Hard Loss 2.5584 (2.2057)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.6%)	
11/20 12:15:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.0737 (1.9339)	Arch Loss 2.2825 (2.2075)	Arch Hard Loss 2.2794 (2.2042)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 79.2%)	
11/20 12:16:45午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.1705 (1.9357)	Arch Loss 1.9987 (2.1931)	Arch Hard Loss 1.9955 (2.1898)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (46.6%, 79.2%)	
11/20 12:16:46午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 13/49] Final Prec@1 46.6240%
11/20 12:16:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1536	Prec@(1,5) (42.2%, 75.9%)
11/20 12:17:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1508	Prec@(1,5) (42.6%, 75.1%)
11/20 12:17:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1394	Prec@(1,5) (42.9%, 75.3%)
11/20 12:17:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1446	Prec@(1,5) (42.9%, 75.2%)
11/20 12:17:22午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 42.8640%
11/20 12:17:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[2, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[5, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 9])
11/20 12:17:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.8640%
11/20 12:18:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.2153 (1.8263)	Arch Loss 2.3337 (2.1567)	Arch Hard Loss 2.3302 (2.1534)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.2%, 81.6%)	
11/20 12:19:12午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 1.5364 (1.8524)	Arch Loss 2.1944 (2.1559)	Arch Hard Loss 2.1910 (2.1526)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.8%, 80.9%)	
11/20 12:20:07午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.8976 (1.8653)	Arch Loss 2.0682 (2.1378)	Arch Hard Loss 2.0645 (2.1344)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.5%, 80.4%)	
11/20 12:20:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.6134 (1.8771)	Arch Loss 2.4622 (2.1272)	Arch Hard Loss 2.4587 (2.1238)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (48.1%, 80.2%)	
11/20 12:20:56午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 14/49] Final Prec@1 48.0920%
11/20 12:21:06午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1100	Prec@(1,5) (44.4%, 75.6%)
11/20 12:21:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1008	Prec@(1,5) (44.3%, 75.5%)
11/20 12:21:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0955	Prec@(1,5) (44.4%, 75.7%)
11/20 12:21:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1024	Prec@(1,5) (44.2%, 75.4%)
11/20 12:21:33午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 44.1400%
11/20 12:21:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[4, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[4, 8], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 10])
11/20 12:21:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.1400%
11/20 12:22:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 1.8688 (1.7420)	Arch Loss 2.3759 (2.1115)	Arch Hard Loss 2.3727 (2.1082)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.5%, 82.6%)	
11/20 12:23:23午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.9775 (1.7898)	Arch Loss 1.8340 (2.1300)	Arch Hard Loss 1.8308 (2.1267)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.7%)	
11/20 12:24:17午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.1374 (1.8055)	Arch Loss 2.2043 (2.1131)	Arch Hard Loss 2.2009 (2.1098)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.3%)	
11/20 12:25:06午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.6217 (1.8046)	Arch Loss 1.6051 (2.1056)	Arch Hard Loss 1.6022 (2.1024)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.3%)	
11/20 12:25:07午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 15/49] Final Prec@1 49.6520%
11/20 12:25:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0519	Prec@(1,5) (44.7%, 77.0%)
11/20 12:25:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0357	Prec@(1,5) (45.1%, 77.3%)
11/20 12:25:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0357	Prec@(1,5) (45.1%, 77.2%)
11/20 12:25:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0411	Prec@(1,5) (45.1%, 77.0%)
11/20 12:25:43午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 45.0640%
11/20 12:25:43午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[3, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 7])
11/20 12:25:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.0640%
11/20 12:26:39午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.6754 (1.7078)	Arch Loss 1.8573 (2.0648)	Arch Hard Loss 1.8542 (2.0617)	Arch Beta Loss 0.0031 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.3%)	
11/20 12:27:33午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9608 (1.7203)	Arch Loss 2.0664 (2.0607)	Arch Hard Loss 2.0625 (2.0574)	Arch Beta Loss 0.0039 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.1%, 82.9%)	
11/20 12:28:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.7157 (1.7396)	Arch Loss 2.5213 (2.0640)	Arch Hard Loss 2.5178 (2.0607)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.4%, 82.6%)	
11/20 12:29:17午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.8207 (1.7440)	Arch Loss 2.0500 (2.0676)	Arch Hard Loss 2.0468 (2.0642)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.3%, 82.5%)	
11/20 12:29:17午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 16/49] Final Prec@1 51.2920%
11/20 12:29:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0360	Prec@(1,5) (45.7%, 76.9%)
11/20 12:29:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0248	Prec@(1,5) (45.7%, 77.1%)
11/20 12:29:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0323	Prec@(1,5) (45.7%, 76.8%)
11/20 12:29:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0319	Prec@(1,5) (45.5%, 77.0%)
11/20 12:29:54午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 45.5520%
11/20 12:29:54午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[7, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[7, 9], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 9])
11/20 12:29:54午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.5520%
11/20 12:30:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.5252 (1.6493)	Arch Loss 2.1808 (2.0230)	Arch Hard Loss 2.1777 (2.0196)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 83.9%)	
11/20 12:31:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.9557 (1.6629)	Arch Loss 2.1337 (2.0373)	Arch Hard Loss 2.1304 (2.0338)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.3%, 83.6%)	
11/20 12:32:39午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.7716 (1.6739)	Arch Loss 2.0813 (2.0283)	Arch Hard Loss 2.0777 (2.0249)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.5%)	
11/20 12:33:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.7232 (1.6838)	Arch Loss 2.1866 (2.0255)	Arch Hard Loss 2.1831 (2.0220)	Arch Beta Loss 0.0036 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.3%)	
11/20 12:33:28午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 17/49] Final Prec@1 52.8720%
11/20 12:33:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0268	Prec@(1,5) (45.7%, 77.1%)
11/20 12:33:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0345	Prec@(1,5) (45.7%, 77.1%)
11/20 12:33:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0266	Prec@(1,5) (45.6%, 77.2%)
11/20 12:34:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0213	Prec@(1,5) (45.8%, 77.2%)
11/20 12:34:04午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 45.7880%
11/20 12:34:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[4, 10], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 6])
11/20 12:34:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7880%
11/20 12:35:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.4491 (1.5836)	Arch Loss 1.8518 (2.0767)	Arch Hard Loss 1.8481 (2.0731)	Arch Beta Loss 0.0036 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.0%, 85.3%)	
11/20 12:35:54午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.4848 (1.6101)	Arch Loss 2.0763 (2.0509)	Arch Hard Loss 2.0730 (2.0474)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.8%)	
11/20 12:36:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.2810 (1.6131)	Arch Loss 2.2133 (2.0309)	Arch Hard Loss 2.2100 (2.0274)	Arch Beta Loss 0.0033 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.4%, 84.7%)	
11/20 12:37:38午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.5281 (1.6259)	Arch Loss 2.4033 (2.0172)	Arch Hard Loss 2.3997 (2.0138)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.0%, 84.4%)	
11/20 12:37:39午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 18/49] Final Prec@1 54.0240%
11/20 12:37:48午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9649	Prec@(1,5) (46.6%, 78.4%)
11/20 12:37:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9657	Prec@(1,5) (46.7%, 78.4%)
11/20 12:38:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9684	Prec@(1,5) (47.1%, 78.6%)
11/20 12:38:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9703	Prec@(1,5) (47.0%, 78.4%)
11/20 12:38:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 47.0080%
11/20 12:38:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[4, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[6, 8], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[6, 11])
11/20 12:38:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.0080%
11/20 12:39:11午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.7842 (1.5436)	Arch Loss 1.9333 (1.9392)	Arch Hard Loss 1.9300 (1.9358)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 86.1%)	
11/20 12:40:05午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.4459 (1.5382)	Arch Loss 1.7834 (1.9865)	Arch Hard Loss 1.7801 (1.9831)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.9%)	
11/20 12:41:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.7080 (1.5584)	Arch Loss 2.1149 (1.9863)	Arch Hard Loss 2.1112 (1.9829)	Arch Beta Loss 0.0038 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.8%)	
11/20 12:41:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.3841 (1.5784)	Arch Loss 2.3148 (1.9813)	Arch Hard Loss 2.3114 (1.9780)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.4%)	
11/20 12:41:49午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 19/49] Final Prec@1 55.1120%
11/20 12:41:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 1.9249	Prec@(1,5) (47.9%, 79.3%)
11/20 12:42:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 1.9438	Prec@(1,5) (47.9%, 78.8%)
11/20 12:42:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 1.9414	Prec@(1,5) (47.7%, 78.9%)
11/20 12:42:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 1.9468	Prec@(1,5) (47.7%, 78.8%)
11/20 12:42:26午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 47.6880%
11/20 12:42:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[5, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[4, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 11])
11/20 12:42:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.6880%
11/20 12:43:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.2600 (1.4876)	Arch Loss 1.7291 (1.9497)	Arch Hard Loss 1.7260 (1.9465)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.5%)	
11/20 12:44:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.4094 (1.5052)	Arch Loss 1.9475 (1.9554)	Arch Hard Loss 1.9446 (1.9522)	Arch Beta Loss 0.0029 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.5%)	
11/20 12:45:10午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 1.3424 (1.5095)	Arch Loss 2.1886 (1.9441)	Arch Hard Loss 2.1851 (1.9409)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.9%, 86.3%)	
11/20 12:46:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.2345 (1.5149)	Arch Loss 1.7294 (1.9483)	Arch Hard Loss 1.7260 (1.9451)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.8%, 86.2%)	
11/20 12:46:00午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 20/49] Final Prec@1 56.8240%
11/20 12:46:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9700	Prec@(1,5) (47.7%, 78.9%)
11/20 12:46:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9684	Prec@(1,5) (47.6%, 79.0%)
11/20 12:46:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9677	Prec@(1,5) (47.7%, 78.8%)
11/20 12:46:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9640	Prec@(1,5) (47.8%, 78.8%)
11/20 12:46:36午後 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 47.8400%
11/20 12:46:36午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[3, 8], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[9, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 12:46:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.8400%
11/20 12:47:32午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.0326 (1.4256)	Arch Loss 2.2626 (1.9566)	Arch Hard Loss 2.2591 (1.9532)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.8%)	
11/20 12:48:26午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.1528 (1.4580)	Arch Loss 1.7074 (1.9564)	Arch Hard Loss 1.7040 (1.9531)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.0%)	
11/20 12:49:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.3979 (1.4650)	Arch Loss 2.2090 (1.9316)	Arch Hard Loss 2.2054 (1.9283)	Arch Beta Loss 0.0037 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.0%)	
11/20 12:50:10午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.3374 (1.4675)	Arch Loss 1.5541 (1.9353)	Arch Hard Loss 1.5508 (1.9320)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.2%, 87.0%)	
11/20 12:50:11午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 21/49] Final Prec@1 58.1840%
11/20 12:50:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9075	Prec@(1,5) (48.8%, 79.4%)
11/20 12:50:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9002	Prec@(1,5) (48.7%, 79.3%)
11/20 12:50:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9077	Prec@(1,5) (48.6%, 79.2%)
11/20 12:50:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9053	Prec@(1,5) (48.7%, 79.2%)
11/20 12:50:47午後 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 48.6440%
11/20 12:50:47午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[2, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[5, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/20 12:50:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.6440%
11/20 12:51:43午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.3843 (1.3543)	Arch Loss 1.8832 (1.9313)	Arch Hard Loss 1.8798 (1.9280)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.8%)	
11/20 12:52:37午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.3463 (1.3884)	Arch Loss 1.9895 (1.9168)	Arch Hard Loss 1.9864 (1.9135)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.7%)	
11/20 12:53:32午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.5618 (1.4150)	Arch Loss 1.7793 (1.9206)	Arch Hard Loss 1.7762 (1.9173)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 88.0%)	
11/20 12:54:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.4711 (1.4267)	Arch Loss 1.5279 (1.9153)	Arch Hard Loss 1.5248 (1.9119)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.8%)	
11/20 12:54:21午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 22/49] Final Prec@1 59.0200%
11/20 12:54:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8500	Prec@(1,5) (50.4%, 80.4%)
11/20 12:54:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8339	Prec@(1,5) (50.8%, 80.6%)
11/20 12:54:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8356	Prec@(1,5) (50.8%, 80.5%)
11/20 12:54:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8377	Prec@(1,5) (50.8%, 80.6%)
11/20 12:54:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 50.7800%
11/20 12:54:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[2, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 12:54:58午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7800%
11/20 12:55:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.6868 (1.3050)	Arch Loss 1.6392 (1.8971)	Arch Hard Loss 1.6356 (1.8938)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.7%, 88.7%)	
11/20 12:56:48午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.4056 (1.3465)	Arch Loss 2.0974 (1.8830)	Arch Hard Loss 2.0939 (1.8796)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.9%, 88.6%)	
11/20 12:57:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.1467 (1.3662)	Arch Loss 1.9548 (1.8907)	Arch Hard Loss 1.9513 (1.8874)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.3%)	
11/20 12:58:32午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.2596 (1.3743)	Arch Loss 1.8883 (1.8861)	Arch Hard Loss 1.8849 (1.8827)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.3%)	
11/20 12:58:32午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 23/49] Final Prec@1 60.0760%
11/20 12:58:41午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8789	Prec@(1,5) (49.8%, 80.0%)
11/20 12:58:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8717	Prec@(1,5) (50.1%, 80.4%)
11/20 12:59:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8763	Prec@(1,5) (50.1%, 80.4%)
11/20 12:59:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8830	Prec@(1,5) (50.0%, 80.3%)
11/20 12:59:08午後 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 50.0160%
11/20 12:59:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[7, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 8])
11/20 12:59:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7800%
11/20 01:00:04午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.3040 (1.2772)	Arch Loss 1.6216 (1.8465)	Arch Hard Loss 1.6183 (1.8431)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.2%)	
11/20 01:00:58午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3714 (1.2930)	Arch Loss 1.6911 (1.8688)	Arch Hard Loss 1.6877 (1.8653)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.7%)	
11/20 01:01:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.1111 (1.3193)	Arch Loss 2.4126 (1.8801)	Arch Hard Loss 2.4091 (1.8766)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.9%, 89.4%)	
11/20 01:02:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2622 (1.3342)	Arch Loss 1.7978 (1.8840)	Arch Hard Loss 1.7939 (1.8805)	Arch Beta Loss 0.0039 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.5%, 89.2%)	
11/20 01:02:42午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 24/49] Final Prec@1 61.4800%
11/20 01:02:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8109	Prec@(1,5) (50.8%, 81.1%)
11/20 01:03:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8153	Prec@(1,5) (50.8%, 81.2%)
11/20 01:03:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8066	Prec@(1,5) (51.1%, 81.2%)
11/20 01:03:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8126	Prec@(1,5) (51.0%, 81.3%)
11/20 01:03:19午後 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 51.0520%
11/20 01:03:19午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[6, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[8, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[8, 9])
11/20 01:03:19午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0520%
11/20 01:04:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.0217 (1.2112)	Arch Loss 2.0398 (1.8468)	Arch Hard Loss 2.0367 (1.8434)	Arch Beta Loss 0.0032 (0.0035)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.9%)	
11/20 01:05:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.5150 (1.2470)	Arch Loss 1.6274 (1.8619)	Arch Hard Loss 1.6244 (1.8584)	Arch Beta Loss 0.0030 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.6%, 90.5%)	
11/20 01:06:04午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.6515 (1.2703)	Arch Loss 1.7389 (1.8690)	Arch Hard Loss 1.7357 (1.8656)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.1%)	
11/20 01:06:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.3773 (1.2858)	Arch Loss 2.2649 (1.8695)	Arch Hard Loss 2.2615 (1.8661)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.9%)	
11/20 01:06:53午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 25/49] Final Prec@1 62.5320%
11/20 01:07:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8869	Prec@(1,5) (50.6%, 79.5%)
11/20 01:07:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8730	Prec@(1,5) (50.8%, 79.9%)
11/20 01:07:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8753	Prec@(1,5) (50.7%, 80.1%)
11/20 01:07:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8796	Prec@(1,5) (50.5%, 80.0%)
11/20 01:07:29午後 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 50.4880%
11/20 01:07:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 10])
11/20 01:07:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.0520%
11/20 01:08:25午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.2778 (1.1955)	Arch Loss 2.0366 (1.8535)	Arch Hard Loss 2.0339 (1.8502)	Arch Beta Loss 0.0027 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.9%)	
11/20 01:09:19午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.1784 (1.2133)	Arch Loss 1.9567 (1.8631)	Arch Hard Loss 1.9537 (1.8598)	Arch Beta Loss 0.0030 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.6%, 91.0%)	
11/20 01:10:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.6593 (1.2317)	Arch Loss 2.2886 (1.8617)	Arch Hard Loss 2.2855 (1.8584)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.7%)	
11/20 01:11:03午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.1788 (1.2442)	Arch Loss 1.5251 (1.8624)	Arch Hard Loss 1.5220 (1.8591)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.5%)	
11/20 01:11:03午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 26/49] Final Prec@1 63.8160%
11/20 01:11:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.7904	Prec@(1,5) (52.3%, 81.5%)
11/20 01:11:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8077	Prec@(1,5) (52.2%, 81.4%)
11/20 01:11:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8037	Prec@(1,5) (52.3%, 81.3%)
11/20 01:11:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8131	Prec@(1,5) (52.0%, 81.2%)
11/20 01:11:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 51.9440%
11/20 01:11:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[8, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 11])
11/20 01:11:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9440%
11/20 01:12:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.2566 (1.1488)	Arch Loss 1.6229 (1.8545)	Arch Hard Loss 1.6195 (1.8511)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.7%)	
11/20 01:13:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.0882 (1.1784)	Arch Loss 1.8779 (1.8562)	Arch Hard Loss 1.8746 (1.8528)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.2%)	
11/20 01:14:25午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.2866 (1.1963)	Arch Loss 1.8792 (1.8413)	Arch Hard Loss 1.8759 (1.8379)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.0%)	
11/20 01:15:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.2467 (1.2035)	Arch Loss 1.6645 (1.8469)	Arch Hard Loss 1.6615 (1.8436)	Arch Beta Loss 0.0030 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.0%)	
11/20 01:15:14午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 27/49] Final Prec@1 65.3800%
11/20 01:15:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8047	Prec@(1,5) (51.4%, 81.9%)
11/20 01:15:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8060	Prec@(1,5) (51.6%, 81.7%)
11/20 01:15:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8189	Prec@(1,5) (51.3%, 81.5%)
11/20 01:15:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8225	Prec@(1,5) (51.4%, 81.4%)
11/20 01:15:51午後 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 51.4080%
11/20 01:15:51午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[8, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[4, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 11])
11/20 01:15:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9440%
11/20 01:16:46午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 0.9186 (1.0949)	Arch Loss 1.9072 (1.8470)	Arch Hard Loss 1.9039 (1.8437)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
11/20 01:17:41午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.0751 (1.1256)	Arch Loss 1.4072 (1.8498)	Arch Hard Loss 1.4034 (1.8465)	Arch Beta Loss 0.0039 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.7%)	
11/20 01:18:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 0.9264 (1.1346)	Arch Loss 1.9605 (1.8505)	Arch Hard Loss 1.9570 (1.8472)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.8%)	
11/20 01:19:25午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.3361 (1.1475)	Arch Loss 1.3914 (1.8430)	Arch Hard Loss 1.3878 (1.8397)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.6%)	
11/20 01:19:25午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 28/49] Final Prec@1 66.1800%
11/20 01:19:35午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8427	Prec@(1,5) (51.2%, 81.3%)
11/20 01:19:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8301	Prec@(1,5) (51.6%, 81.8%)
11/20 01:19:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8274	Prec@(1,5) (51.9%, 81.6%)
11/20 01:20:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8305	Prec@(1,5) (52.0%, 81.5%)
11/20 01:20:02午後 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 51.9800%
11/20 01:20:02午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[5, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 11])
11/20 01:20:03午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.9800%
11/20 01:21:04午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.3291 (1.0543)	Arch Loss 1.1995 (1.8318)	Arch Hard Loss 1.1964 (1.8284)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 93.0%)	
11/20 01:22:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.0908 (1.0787)	Arch Loss 1.4920 (1.8304)	Arch Hard Loss 1.4889 (1.8270)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.8%)	
11/20 01:22:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.2228 (1.0936)	Arch Loss 2.0384 (1.8338)	Arch Hard Loss 2.0354 (1.8304)	Arch Beta Loss 0.0030 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.6%)	
11/20 01:23:47午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 0.9511 (1.1008)	Arch Loss 2.1325 (1.8263)	Arch Hard Loss 2.1289 (1.8229)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.4%)	
11/20 01:23:47午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 29/49] Final Prec@1 67.6920%
11/20 01:23:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7493	Prec@(1,5) (53.2%, 82.6%)
11/20 01:24:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7748	Prec@(1,5) (52.9%, 82.4%)
11/20 01:24:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7626	Prec@(1,5) (53.1%, 82.5%)
11/20 01:24:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7670	Prec@(1,5) (52.8%, 82.5%)
11/20 01:24:24午後 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 52.8200%
11/20 01:24:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[8, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[7, 8])
11/20 01:24:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.8200%
11/20 01:25:22午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.2259 (1.0026)	Arch Loss 2.1134 (1.8066)	Arch Hard Loss 2.1103 (1.8032)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.6%)	
11/20 01:26:17午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.0000 (1.0380)	Arch Loss 1.5060 (1.8263)	Arch Hard Loss 1.5023 (1.8230)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.1%)	
11/20 01:27:12午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.0075 (1.0548)	Arch Loss 1.6810 (1.8268)	Arch Hard Loss 1.6776 (1.8235)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.8%)	
11/20 01:28:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.0653 (1.0656)	Arch Loss 1.8993 (1.8259)	Arch Hard Loss 1.8957 (1.8226)	Arch Beta Loss 0.0036 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.7%)	
11/20 01:28:03午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 30/49] Final Prec@1 68.5280%
11/20 01:28:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8218	Prec@(1,5) (51.7%, 81.8%)
11/20 01:28:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7956	Prec@(1,5) (52.4%, 82.2%)
11/20 01:28:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7905	Prec@(1,5) (52.7%, 82.2%)
11/20 01:28:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7942	Prec@(1,5) (52.7%, 82.1%)
11/20 01:28:40午後 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 52.6560%
11/20 01:28:40午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[2, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[2, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 6])
11/20 01:28:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.8200%
11/20 01:29:36午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8780 (0.9983)	Arch Loss 1.8375 (1.8203)	Arch Hard Loss 1.8343 (1.8171)	Arch Beta Loss 0.0032 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.3%, 94.0%)	
11/20 01:30:32午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.2444 (1.0018)	Arch Loss 1.3806 (1.7984)	Arch Hard Loss 1.3771 (1.7952)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.9%)	
11/20 01:31:27午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1044 (1.0234)	Arch Loss 1.6746 (1.7915)	Arch Hard Loss 1.6711 (1.7884)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.6%)	
11/20 01:32:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.5945 (1.0312)	Arch Loss 1.6101 (1.8066)	Arch Hard Loss 1.6066 (1.8034)	Arch Beta Loss 0.0035 (0.0032)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.4%)	
11/20 01:32:18午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 31/49] Final Prec@1 69.5360%
11/20 01:32:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.7950	Prec@(1,5) (52.9%, 82.2%)
11/20 01:32:38午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7988	Prec@(1,5) (52.8%, 82.3%)
11/20 01:32:47午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7859	Prec@(1,5) (53.2%, 82.1%)
11/20 01:32:55午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7833	Prec@(1,5) (53.2%, 82.3%)
11/20 01:32:55午後 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 53.1800%
11/20 01:32:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[9, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[3, 9], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/20 01:32:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.1800%
11/20 01:33:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 0.6764 (0.9487)	Arch Loss 1.6823 (1.7859)	Arch Hard Loss 1.6789 (1.7826)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.0%)	
11/20 01:34:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.7953 (0.9595)	Arch Loss 2.1192 (1.7873)	Arch Hard Loss 2.1157 (1.7840)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.2%)	
11/20 01:35:45午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.0713 (0.9710)	Arch Loss 1.6122 (1.8038)	Arch Hard Loss 1.6087 (1.8005)	Arch Beta Loss 0.0035 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.6%, 94.0%)	
11/20 01:36:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.1394 (0.9828)	Arch Loss 1.7383 (1.7991)	Arch Hard Loss 1.7352 (1.7958)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.8%)	
11/20 01:36:35午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 32/49] Final Prec@1 71.1680%
11/20 01:36:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7645	Prec@(1,5) (53.2%, 82.6%)
11/20 01:36:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7695	Prec@(1,5) (53.5%, 82.4%)
11/20 01:37:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7655	Prec@(1,5) (53.6%, 82.5%)
11/20 01:37:12午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7671	Prec@(1,5) (53.5%, 82.5%)
11/20 01:37:12午後 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 53.5640%
11/20 01:37:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[8, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[7, 10], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/20 01:37:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.5640%
11/20 01:38:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8869 (0.9384)	Arch Loss 1.3482 (1.8182)	Arch Hard Loss 1.3446 (1.8149)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.5%)	
11/20 01:39:04午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.0309 (0.9221)	Arch Loss 2.0299 (1.8091)	Arch Hard Loss 2.0265 (1.8058)	Arch Beta Loss 0.0034 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.8%)	
11/20 01:39:59午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.0741 (0.9359)	Arch Loss 2.0487 (1.8067)	Arch Hard Loss 2.0451 (1.8034)	Arch Beta Loss 0.0037 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.5%)	
11/20 01:40:48午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 0.9191 (0.9456)	Arch Loss 2.0781 (1.8078)	Arch Hard Loss 2.0749 (1.8045)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.3%)	
11/20 01:40:48午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 33/49] Final Prec@1 72.0320%
11/20 01:40:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7487	Prec@(1,5) (54.8%, 82.8%)
11/20 01:41:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7523	Prec@(1,5) (54.1%, 82.6%)
11/20 01:41:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7446	Prec@(1,5) (54.1%, 82.8%)
11/20 01:41:25午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7490	Prec@(1,5) (54.1%, 82.8%)
11/20 01:41:25午後 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 54.0360%
11/20 01:41:25午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[7, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[5, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[5, 8])
11/20 01:41:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.0360%
11/20 01:42:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.9563 (0.8410)	Arch Loss 1.8730 (1.7825)	Arch Hard Loss 1.8697 (1.7791)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
11/20 01:43:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.0388 (0.8716)	Arch Loss 1.6994 (1.8081)	Arch Hard Loss 1.6960 (1.8048)	Arch Beta Loss 0.0034 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.1%)	
11/20 01:44:11午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0534 (0.8900)	Arch Loss 1.7305 (1.8068)	Arch Hard Loss 1.7272 (1.8034)	Arch Beta Loss 0.0033 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
11/20 01:45:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9098 (0.8948)	Arch Loss 2.1359 (1.8017)	Arch Hard Loss 2.1327 (1.7983)	Arch Beta Loss 0.0032 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.8%)	
11/20 01:45:00午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 34/49] Final Prec@1 73.3440%
11/20 01:45:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7464	Prec@(1,5) (55.1%, 81.9%)
11/20 01:45:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7278	Prec@(1,5) (55.1%, 82.6%)
11/20 01:45:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7360	Prec@(1,5) (54.8%, 82.6%)
11/20 01:45:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7313	Prec@(1,5) (55.0%, 82.8%)
11/20 01:45:37午後 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 54.9560%
11/20 01:45:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[9, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 7])
11/20 01:45:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.9560%
11/20 01:46:33午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.7259 (0.8257)	Arch Loss 1.8244 (1.7910)	Arch Hard Loss 1.8208 (1.7877)	Arch Beta Loss 0.0036 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.7%)	
11/20 01:47:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 0.8948 (0.8407)	Arch Loss 1.7088 (1.8030)	Arch Hard Loss 1.7053 (1.7996)	Arch Beta Loss 0.0035 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.6%)	
11/20 01:48:22午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.6898 (0.8482)	Arch Loss 2.0095 (1.8004)	Arch Hard Loss 2.0064 (1.7970)	Arch Beta Loss 0.0031 (0.0034)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.5%)	
11/20 01:49:12午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1658 (0.8540)	Arch Loss 1.8017 (1.8011)	Arch Hard Loss 1.7985 (1.7978)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.4%)	
11/20 01:49:12午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 35/49] Final Prec@1 74.5120%
11/20 01:49:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7177	Prec@(1,5) (54.7%, 83.5%)
11/20 01:49:31午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7385	Prec@(1,5) (54.2%, 83.3%)
11/20 01:49:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7420	Prec@(1,5) (54.2%, 83.1%)
11/20 01:49:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7479	Prec@(1,5) (54.1%, 82.9%)
11/20 01:49:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 54.0960%
11/20 01:49:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[7, 9], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[6, 8], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 9])
11/20 01:49:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.9560%
11/20 01:50:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.9400 (0.7959)	Arch Loss 2.0549 (1.7938)	Arch Hard Loss 2.0517 (1.7904)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.7%)	
11/20 01:51:39午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.6875 (0.8057)	Arch Loss 1.8088 (1.7960)	Arch Hard Loss 1.8057 (1.7927)	Arch Beta Loss 0.0031 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.7%)	
11/20 01:52:34午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8392 (0.8133)	Arch Loss 1.6888 (1.7954)	Arch Hard Loss 1.6856 (1.7920)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.7%)	
11/20 01:53:23午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.9476 (0.8230)	Arch Loss 1.7639 (1.7989)	Arch Hard Loss 1.7606 (1.7956)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.6%)	
11/20 01:53:23午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 36/49] Final Prec@1 75.3960%
11/20 01:53:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7570	Prec@(1,5) (54.6%, 83.3%)
11/20 01:53:42午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7524	Prec@(1,5) (54.5%, 83.4%)
11/20 01:53:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7505	Prec@(1,5) (54.3%, 83.2%)
11/20 01:54:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7570	Prec@(1,5) (54.2%, 83.0%)
11/20 01:54:00午後 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 54.1760%
11/20 01:54:00午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 2), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[8, 10], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[8, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[9, 11])
11/20 01:54:00午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.9560%
11/20 01:54:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.8492 (0.7424)	Arch Loss 2.0698 (1.8013)	Arch Hard Loss 2.0666 (1.7980)	Arch Beta Loss 0.0032 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.5%)	
11/20 01:55:50午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.0303 (0.7493)	Arch Loss 2.2068 (1.7878)	Arch Hard Loss 2.2035 (1.7845)	Arch Beta Loss 0.0033 (0.0033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.5%)	
