11/19 10:52:27PM parser.py:28 [INFO] 
11/19 10:52:27PM parser.py:29 [INFO] Parameters:
11/19 10:52:27PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s1-alphal1-sw3-g10/DAG
11/19 10:52:27PM parser.py:31 [INFO] T=10.0
11/19 10:52:27PM parser.py:31 [INFO] ADVANCED=1
11/19 10:52:27PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/19 10:52:27PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/19 10:52:27PM parser.py:31 [INFO] ARCH_CRITERION=alphal1
11/19 10:52:27PM parser.py:31 [INFO] BATCH_SIZE=64
11/19 10:52:27PM parser.py:31 [INFO] CASCADE=0
11/19 10:52:27PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/19 10:52:27PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/19 10:52:27PM parser.py:31 [INFO] DATA_PATH=../data/
11/19 10:52:27PM parser.py:31 [INFO] DATASET=cifar100
11/19 10:52:27PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/19 10:52:27PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Alpha-constraint_slidewindow-3
11/19 10:52:27PM parser.py:31 [INFO] DISCRETE=0
11/19 10:52:27PM parser.py:31 [INFO] EPOCHS=50
11/19 10:52:27PM parser.py:31 [INFO] EVAL_EPOCHS=100
11/19 10:52:27PM parser.py:31 [INFO] EXP_NAME=s1-alphal1-sw3-g10
11/19 10:52:27PM parser.py:31 [INFO] FINAL_L=10.0
11/19 10:52:27PM parser.py:31 [INFO] G=10.0
11/19 10:52:27PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/19 10:52:27PM parser.py:31 [INFO] GPUS=[0]
11/19 10:52:27PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/19 10:52:27PM parser.py:31 [INFO] INIT_CHANNELS=16
11/19 10:52:27PM parser.py:31 [INFO] L=10.0
11/19 10:52:27PM parser.py:31 [INFO] LAYERS=32
11/19 10:52:27PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/19 10:52:27PM parser.py:31 [INFO] NAME=Pruning
11/19 10:52:27PM parser.py:31 [INFO] NONKD=1
11/19 10:52:27PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s1-alphal1-sw3-g10
11/19 10:52:27PM parser.py:31 [INFO] PCDARTS=0
11/19 10:52:27PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s1-alphal1-sw3-g10/plots
11/19 10:52:27PM parser.py:31 [INFO] PRINT_FREQ=100
11/19 10:52:27PM parser.py:31 [INFO] RESET=0
11/19 10:52:27PM parser.py:31 [INFO] RESUME_PATH=None
11/19 10:52:27PM parser.py:31 [INFO] SAVE=s1-alphal1-sw3-g10
11/19 10:52:27PM parser.py:31 [INFO] SEED=1
11/19 10:52:27PM parser.py:31 [INFO] SHARE_STAGE=0
11/19 10:52:27PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/19 10:52:27PM parser.py:31 [INFO] SPEC_CELL=1
11/19 10:52:27PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/19 10:52:27PM parser.py:31 [INFO] TEACHER_NAME=h_das_224baseline
11/19 10:52:27PM parser.py:31 [INFO] TEACHER_PATH=/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar
11/19 10:52:27PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/19 10:52:27PM parser.py:31 [INFO] TYPE=ArchKD
11/19 10:52:27PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/19 10:52:27PM parser.py:31 [INFO] W_LR=0.025
11/19 10:52:27PM parser.py:31 [INFO] W_LR_MIN=0.001
11/19 10:52:27PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/19 10:52:27PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/19 10:52:27PM parser.py:31 [INFO] WORKERS=4
11/19 10:52:27PM parser.py:32 [INFO] 
11/19 10:52:28PM searchStage_ArchKD_trainer.py:90 [INFO] --> Loaded teacher model 'h_das_224baseline' from '/home/miura/lab/KD-hdas/results/evaluate_stage_KD/cifar100/noDepthLoss/s0-BaselineBestCell/best.pth.tar' and Freezed parameters)
11/19 10:52:28PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/19 10:53:13PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.4249 (4.7111)	Arch Loss 4.7746 (4.8543)	Arch Hard Loss 4.6611 (4.7387)	Arch Alpha Loss 0.0113 (0.0116)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.7%, 6.9%)	
11/19 10:53:57PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.3495 (4.5725)	Arch Loss 4.4263 (4.6977)	Arch Hard Loss 4.3131 (4.5860)	Arch Alpha Loss 0.0113 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.3%, 9.6%)	
11/19 10:54:41PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.3573 (4.4896)	Arch Loss 4.2736 (4.6049)	Arch Hard Loss 4.1610 (4.4945)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.7%, 11.2%)	
11/19 10:55:19PM searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 4.1777 (4.4364)	Arch Loss 4.4898 (4.5492)	Arch Hard Loss 4.3740 (4.4394)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.0%, 12.6%)	
11/19 10:55:20PM searchStage_ArchKD_trainer.py:180 [INFO] Train: [  0/49] Final Prec@1 2.9720%
11/19 10:55:27PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.2049	Prec@(1,5) (4.6%, 17.8%)
11/19 10:55:34PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.2035	Prec@(1,5) (4.7%, 17.8%)
11/19 10:55:41PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.1979	Prec@(1,5) (4.8%, 18.1%)
11/19 10:55:47PM searchStage_trainer.py:309 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.1942	Prec@(1,5) (4.8%, 18.2%)
11/19 10:55:47PM searchStage_trainer.py:320 [INFO] Valid: [  0/49] Final Prec@1 4.7960%
11/19 10:55:47PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 10:55:47PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 4.7960%
11/19 10:56:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.9790 (4.1451)	Arch Loss 4.2348 (4.2876)	Arch Hard Loss 4.1333 (4.1797)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.5%, 19.9%)	
11/19 10:57:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.1386 (4.1268)	Arch Loss 4.5003 (4.2389)	Arch Hard Loss 4.3989 (4.1310)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.7%, 20.9%)	
11/19 10:57:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 4.3148 (4.1043)	Arch Loss 4.1108 (4.2116)	Arch Hard Loss 4.0106 (4.1036)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (5.8%, 21.6%)	
11/19 10:58:38午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.9540 (4.0827)	Arch Loss 4.1347 (4.1856)	Arch Hard Loss 4.0338 (4.0776)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (6.0%, 22.2%)	
11/19 10:58:38午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  1/49] Final Prec@1 6.0080%
11/19 10:58:45午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.9455	Prec@(1,5) (7.2%, 25.5%)
11/19 10:58:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.9465	Prec@(1,5) (7.6%, 25.9%)
11/19 10:58:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.9507	Prec@(1,5) (7.8%, 26.2%)
11/19 10:59:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.9483	Prec@(1,5) (7.8%, 26.1%)
11/19 10:59:04午後 searchStage_trainer.py:320 [INFO] Valid: [  1/49] Final Prec@1 7.8040%
11/19 10:59:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 2)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 10:59:05午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.8040%
11/19 10:59:49午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8901 (3.9442)	Arch Loss 3.8116 (4.0435)	Arch Hard Loss 3.6948 (3.9354)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (7.9%, 26.6%)	
11/19 11:00:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.9299 (3.9230)	Arch Loss 3.9379 (4.0252)	Arch Hard Loss 3.8196 (3.9172)	Arch Alpha Loss 0.0118 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.3%, 27.1%)	
11/19 11:01:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 4.1291 (3.9107)	Arch Loss 3.9161 (4.0098)	Arch Hard Loss 3.7998 (3.9018)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.6%, 27.7%)	
11/19 11:01:55午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.8693 (3.8930)	Arch Loss 4.0689 (3.9904)	Arch Hard Loss 3.9543 (3.8825)	Arch Alpha Loss 0.0115 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (8.8%, 28.5%)	
11/19 11:01:55午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  2/49] Final Prec@1 8.8320%
11/19 11:02:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.8114	Prec@(1,5) (8.8%, 31.1%)
11/19 11:02:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.8112	Prec@(1,5) (9.0%, 31.2%)
11/19 11:02:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.8201	Prec@(1,5) (9.0%, 30.9%)
11/19 11:02:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.8176	Prec@(1,5) (9.0%, 31.0%)
11/19 11:02:22午後 searchStage_trainer.py:320 [INFO] Valid: [  2/49] Final Prec@1 9.0320%
11/19 11:02:22午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/19 11:02:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 9.0320%
11/19 11:03:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.7167 (3.7977)	Arch Loss 3.9173 (3.9015)	Arch Hard Loss 3.8193 (3.7938)	Arch Alpha Loss 0.0098 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.4%, 31.7%)	
11/19 11:03:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.7888 (3.7690)	Arch Loss 3.8004 (3.8773)	Arch Hard Loss 3.7011 (3.7696)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.8%, 32.6%)	
11/19 11:04:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.6857 (3.7574)	Arch Loss 3.9176 (3.8602)	Arch Hard Loss 3.8180 (3.7526)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.2%, 33.0%)	
11/19 11:05:13午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.6273 (3.7436)	Arch Loss 3.5385 (3.8407)	Arch Hard Loss 3.4402 (3.7329)	Arch Alpha Loss 0.0098 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.6%, 33.3%)	
11/19 11:05:13午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  3/49] Final Prec@1 10.5880%
11/19 11:05:20午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.6476	Prec@(1,5) (12.0%, 36.2%)
11/19 11:05:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.6461	Prec@(1,5) (12.0%, 36.4%)
11/19 11:05:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.6470	Prec@(1,5) (12.0%, 36.4%)
11/19 11:05:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.6347	Prec@(1,5) (12.2%, 36.8%)
11/19 11:05:39午後 searchStage_trainer.py:320 [INFO] Valid: [  3/49] Final Prec@1 12.1680%
11/19 11:05:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/19 11:05:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 12.1680%
11/19 11:06:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.6449 (3.5930)	Arch Loss 3.7061 (3.7506)	Arch Hard Loss 3.5897 (3.6428)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.3%, 38.1%)	
11/19 11:07:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 3.7083 (3.6140)	Arch Loss 3.6228 (3.7452)	Arch Hard Loss 3.5079 (3.6374)	Arch Alpha Loss 0.0115 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.3%, 37.6%)	
11/19 11:07:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.8514 (3.6182)	Arch Loss 3.7329 (3.7353)	Arch Hard Loss 3.6168 (3.6276)	Arch Alpha Loss 0.0116 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.1%, 37.7%)	
11/19 11:08:30午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.4746 (3.6135)	Arch Loss 3.9098 (3.7212)	Arch Hard Loss 3.7912 (3.6134)	Arch Alpha Loss 0.0119 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (13.2%, 37.8%)	
11/19 11:08:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  4/49] Final Prec@1 13.1920%
11/19 11:08:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5744	Prec@(1,5) (14.0%, 38.3%)
11/19 11:08:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.5680	Prec@(1,5) (14.1%, 39.1%)
11/19 11:08:50午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.5729	Prec@(1,5) (13.9%, 39.1%)
11/19 11:08:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.5681	Prec@(1,5) (14.1%, 39.3%)
11/19 11:08:57午後 searchStage_trainer.py:320 [INFO] Valid: [  4/49] Final Prec@1 14.1240%
11/19 11:08:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/19 11:08:57午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.1240%
11/19 11:09:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.4239 (3.5095)	Arch Loss 3.5365 (3.6408)	Arch Hard Loss 3.4398 (3.5326)	Arch Alpha Loss 0.0097 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.9%, 41.3%)	
11/19 11:10:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.4823 (3.5000)	Arch Loss 3.4533 (3.6503)	Arch Hard Loss 3.3566 (3.5423)	Arch Alpha Loss 0.0097 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.4%, 41.3%)	
11/19 11:11:08午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.6867 (3.5010)	Arch Loss 3.6014 (3.6382)	Arch Hard Loss 3.5032 (3.5303)	Arch Alpha Loss 0.0098 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.2%, 41.3%)	
11/19 11:11:47午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.7796 (3.4916)	Arch Loss 3.5233 (3.6181)	Arch Hard Loss 3.4191 (3.5102)	Arch Alpha Loss 0.0104 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.3%, 41.6%)	
11/19 11:11:47午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  5/49] Final Prec@1 15.2800%
11/19 11:11:54午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.4487	Prec@(1,5) (15.1%, 43.0%)
11/19 11:12:01午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.4405	Prec@(1,5) (16.1%, 43.1%)
11/19 11:12:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.4395	Prec@(1,5) (16.1%, 43.2%)
11/19 11:12:14午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.4384	Prec@(1,5) (16.2%, 43.3%)
11/19 11:12:14午後 searchStage_trainer.py:320 [INFO] Valid: [  5/49] Final Prec@1 16.2200%
11/19 11:12:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG3_concat=range(10, 12))
11/19 11:12:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.2200%
11/19 11:12:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.4822 (3.4063)	Arch Loss 3.5547 (3.5274)	Arch Hard Loss 3.4375 (3.4196)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.9%, 43.5%)	
11/19 11:13:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 3.2705 (3.3958)	Arch Loss 3.5595 (3.5335)	Arch Hard Loss 3.4421 (3.4256)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.9%, 44.0%)	
11/19 11:14:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.3206 (3.4061)	Arch Loss 3.0811 (3.5254)	Arch Hard Loss 2.9639 (3.4172)	Arch Alpha Loss 0.0117 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.0%, 43.6%)	
11/19 11:15:03午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 3.4186 (3.3965)	Arch Loss 3.7782 (3.5128)	Arch Hard Loss 3.6589 (3.4045)	Arch Alpha Loss 0.0119 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.2%, 43.9%)	
11/19 11:15:04午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  6/49] Final Prec@1 17.2240%
11/19 11:15:11午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.4330	Prec@(1,5) (15.7%, 43.4%)
11/19 11:15:17午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.4421	Prec@(1,5) (16.0%, 43.1%)
11/19 11:15:24午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.4598	Prec@(1,5) (16.0%, 42.9%)
11/19 11:15:30午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.4655	Prec@(1,5) (16.0%, 42.7%)
11/19 11:15:30午後 searchStage_trainer.py:320 [INFO] Valid: [  6/49] Final Prec@1 15.9880%
11/19 11:15:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/19 11:15:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.2200%
11/19 11:16:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.2603 (3.3252)	Arch Loss 3.6370 (3.4571)	Arch Hard Loss 3.5360 (3.3491)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.9%, 46.0%)	
11/19 11:16:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 3.3348 (3.3231)	Arch Loss 3.5270 (3.4613)	Arch Hard Loss 3.4273 (3.3533)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (17.9%, 46.1%)	
11/19 11:17:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.1674 (3.3021)	Arch Loss 3.4793 (3.4250)	Arch Hard Loss 3.3819 (3.3170)	Arch Alpha Loss 0.0097 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.4%, 46.7%)	
11/19 11:18:20午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 3.3202 (3.3032)	Arch Loss 3.1705 (3.4250)	Arch Hard Loss 3.0731 (3.3170)	Arch Alpha Loss 0.0097 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.5%, 46.7%)	
11/19 11:18:20午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  7/49] Final Prec@1 18.4880%
11/19 11:18:27午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 3.5393	Prec@(1,5) (15.6%, 42.2%)
11/19 11:18:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 3.5339	Prec@(1,5) (16.0%, 42.5%)
11/19 11:18:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 3.5551	Prec@(1,5) (15.6%, 42.3%)
11/19 11:18:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 3.5660	Prec@(1,5) (15.5%, 42.1%)
11/19 11:18:46午後 searchStage_trainer.py:320 [INFO] Valid: [  7/49] Final Prec@1 15.4800%
11/19 11:18:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/19 11:18:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 16.2200%
11/19 11:19:31午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 3.4199 (3.2173)	Arch Loss 3.3529 (3.3679)	Arch Hard Loss 3.2363 (3.2607)	Arch Alpha Loss 0.0117 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.3%, 50.2%)	
11/19 11:20:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 3.2018 (3.2197)	Arch Loss 3.1873 (3.3687)	Arch Hard Loss 3.0689 (3.2615)	Arch Alpha Loss 0.0118 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.3%)	
11/19 11:20:58午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.1082 (3.2177)	Arch Loss 3.0673 (3.3584)	Arch Hard Loss 2.9501 (3.2512)	Arch Alpha Loss 0.0117 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.0%)	
11/19 11:21:37午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 3.7196 (3.2111)	Arch Loss 3.4185 (3.3510)	Arch Hard Loss 3.3022 (3.2439)	Arch Alpha Loss 0.0116 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.6%, 49.1%)	
11/19 11:21:37午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  8/49] Final Prec@1 20.6000%
11/19 11:21:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 3.3142	Prec@(1,5) (19.0%, 48.6%)
11/19 11:21:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 3.2982	Prec@(1,5) (19.3%, 48.9%)
11/19 11:21:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 3.2927	Prec@(1,5) (19.6%, 49.1%)
11/19 11:22:04午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 3.2956	Prec@(1,5) (19.7%, 49.0%)
11/19 11:22:04午後 searchStage_trainer.py:320 [INFO] Valid: [  8/49] Final Prec@1 19.6560%
11/19 11:22:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/19 11:22:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 19.6560%
11/19 11:22:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.9820 (3.1473)	Arch Loss 3.3535 (3.2964)	Arch Hard Loss 3.2568 (3.1893)	Arch Alpha Loss 0.0097 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.0%, 51.1%)	
11/19 11:23:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 3.0509 (3.1326)	Arch Loss 3.3139 (3.2916)	Arch Hard Loss 3.2181 (3.1845)	Arch Alpha Loss 0.0096 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.1%, 51.8%)	
11/19 11:24:15午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 3.4324 (3.1287)	Arch Loss 3.0909 (3.2710)	Arch Hard Loss 2.9934 (3.1637)	Arch Alpha Loss 0.0097 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.3%, 51.8%)	
11/19 11:24:54午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.9264 (3.1185)	Arch Loss 3.7028 (3.2631)	Arch Hard Loss 3.6040 (3.1558)	Arch Alpha Loss 0.0099 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (21.6%, 51.9%)	
11/19 11:24:55午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [  9/49] Final Prec@1 21.5920%
11/19 11:25:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 3.2016	Prec@(1,5) (20.9%, 50.5%)
11/19 11:25:08午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 3.2130	Prec@(1,5) (21.1%, 50.5%)
11/19 11:25:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 3.2189	Prec@(1,5) (21.1%, 50.2%)
11/19 11:25:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 3.2248	Prec@(1,5) (21.0%, 50.1%)
11/19 11:25:21午後 searchStage_trainer.py:320 [INFO] Valid: [  9/49] Final Prec@1 21.0160%
11/19 11:25:21午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
11/19 11:25:22午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 21.0160%
11/19 11:26:06午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9479 (3.0238)	Arch Loss 3.2813 (3.2281)	Arch Hard Loss 3.1666 (3.1206)	Arch Alpha Loss 0.0115 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.0%, 54.4%)	
11/19 11:26:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 3.3925 (3.0325)	Arch Loss 3.0763 (3.2451)	Arch Hard Loss 2.9607 (3.1377)	Arch Alpha Loss 0.0116 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.2%, 54.0%)	
11/19 11:27:34午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 3.0204 (3.0263)	Arch Loss 3.7249 (3.2225)	Arch Hard Loss 3.6082 (3.1150)	Arch Alpha Loss 0.0117 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.3%, 54.2%)	
11/19 11:28:14午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 3.0571 (3.0270)	Arch Loss 3.3213 (3.2098)	Arch Hard Loss 3.2086 (3.1023)	Arch Alpha Loss 0.0113 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.2%, 54.2%)	
11/19 11:28:14午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 10/49] Final Prec@1 24.2320%
11/19 11:28:21午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 3.0752	Prec@(1,5) (23.6%, 53.8%)
11/19 11:28:28午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 3.0661	Prec@(1,5) (24.3%, 53.7%)
11/19 11:28:34午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 3.0525	Prec@(1,5) (24.3%, 54.2%)
11/19 11:28:40午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 3.0464	Prec@(1,5) (24.3%, 54.3%)
11/19 11:28:41午後 searchStage_trainer.py:320 [INFO] Valid: [ 10/49] Final Prec@1 24.2640%
11/19 11:28:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:28:41午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 24.2640%
11/19 11:29:25午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.3956 (2.9369)	Arch Loss 3.0524 (3.1090)	Arch Hard Loss 2.9529 (3.0013)	Arch Alpha Loss 0.0100 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.6%, 56.4%)	
11/19 11:30:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.6535 (2.9153)	Arch Loss 3.1438 (3.1267)	Arch Hard Loss 3.0421 (3.0189)	Arch Alpha Loss 0.0102 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 57.3%)	
11/19 11:30:53午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.9209 (2.9353)	Arch Loss 3.1938 (3.1308)	Arch Hard Loss 3.0948 (3.0230)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.7%, 56.8%)	
11/19 11:31:32午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.7977 (2.9311)	Arch Loss 2.5203 (3.1173)	Arch Hard Loss 2.4217 (3.0097)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (25.9%, 56.9%)	
11/19 11:31:32午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 11/49] Final Prec@1 25.8680%
11/19 11:31:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.9264	Prec@(1,5) (26.5%, 56.8%)
11/19 11:31:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.9215	Prec@(1,5) (26.6%, 57.2%)
11/19 11:31:52午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.9314	Prec@(1,5) (26.7%, 57.2%)
11/19 11:31:58午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.9332	Prec@(1,5) (26.6%, 57.1%)
11/19 11:31:58午後 searchStage_trainer.py:320 [INFO] Valid: [ 11/49] Final Prec@1 26.6480%
11/19 11:31:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:31:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.6480%
11/19 11:32:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 3.0065 (2.8481)	Arch Loss 2.7454 (3.0751)	Arch Hard Loss 2.6329 (2.9686)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 58.5%)	
11/19 11:33:26午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 3.2390 (2.8505)	Arch Loss 3.0341 (3.0671)	Arch Hard Loss 2.9219 (2.9607)	Arch Alpha Loss 0.0112 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 58.4%)	
11/19 11:34:09午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.4697 (2.8429)	Arch Loss 2.9586 (3.0620)	Arch Hard Loss 2.8463 (2.9557)	Arch Alpha Loss 0.0112 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.4%, 58.6%)	
11/19 11:34:48午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 3.0462 (2.8510)	Arch Loss 2.9942 (3.0550)	Arch Hard Loss 2.8804 (2.9489)	Arch Alpha Loss 0.0114 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.2%, 58.5%)	
11/19 11:34:49午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 12/49] Final Prec@1 27.1880%
11/19 11:34:56午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.9152	Prec@(1,5) (26.6%, 57.1%)
11/19 11:35:02午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.9032	Prec@(1,5) (26.9%, 57.5%)
11/19 11:35:09午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.9095	Prec@(1,5) (26.6%, 57.4%)
11/19 11:35:15午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.9116	Prec@(1,5) (26.7%, 57.4%)
11/19 11:35:15午後 searchStage_trainer.py:320 [INFO] Valid: [ 12/49] Final Prec@1 26.6640%
11/19 11:35:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:35:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 26.6640%
11/19 11:36:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.5546 (2.7404)	Arch Loss 2.9125 (3.0021)	Arch Hard Loss 2.8159 (2.8964)	Arch Alpha Loss 0.0097 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.0%, 61.3%)	
11/19 11:36:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.8673 (2.7616)	Arch Loss 2.9217 (3.0274)	Arch Hard Loss 2.8262 (2.9217)	Arch Alpha Loss 0.0096 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.7%, 60.5%)	
11/19 11:37:27午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.9725 (2.7691)	Arch Loss 2.8805 (3.0111)	Arch Hard Loss 2.7849 (2.9054)	Arch Alpha Loss 0.0096 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.4%, 60.5%)	
11/19 11:38:05午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.8563 (2.7692)	Arch Loss 2.8082 (2.9956)	Arch Hard Loss 2.7090 (2.8899)	Arch Alpha Loss 0.0099 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (29.3%, 60.7%)	
11/19 11:38:06午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 13/49] Final Prec@1 29.2520%
11/19 11:38:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.8079	Prec@(1,5) (28.5%, 59.8%)
11/19 11:38:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.8219	Prec@(1,5) (28.7%, 59.7%)
11/19 11:38:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.8261	Prec@(1,5) (28.7%, 59.7%)
11/19 11:38:32午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.8252	Prec@(1,5) (28.6%, 59.6%)
11/19 11:38:32午後 searchStage_trainer.py:320 [INFO] Valid: [ 13/49] Final Prec@1 28.6120%
11/19 11:38:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:38:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 28.6120%
11/19 11:39:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.1457 (2.6750)	Arch Loss 2.8251 (2.9470)	Arch Hard Loss 2.7084 (2.8407)	Arch Alpha Loss 0.0117 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 63.5%)	
11/19 11:39:59午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.8887 (2.6806)	Arch Loss 2.8404 (2.9412)	Arch Hard Loss 2.7235 (2.8348)	Arch Alpha Loss 0.0117 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.7%, 63.3%)	
11/19 11:40:43午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.6386 (2.6801)	Arch Loss 2.9666 (2.9423)	Arch Hard Loss 2.8506 (2.8358)	Arch Alpha Loss 0.0116 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.8%, 63.2%)	
11/19 11:41:22午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.3689 (2.6902)	Arch Loss 2.7330 (2.9328)	Arch Hard Loss 2.6208 (2.8264)	Arch Alpha Loss 0.0112 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.6%, 62.9%)	
11/19 11:41:22午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 14/49] Final Prec@1 30.6480%
11/19 11:41:29午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.7890	Prec@(1,5) (28.6%, 60.6%)
11/19 11:41:36午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.7963	Prec@(1,5) (28.7%, 60.6%)
11/19 11:41:43午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.7740	Prec@(1,5) (29.4%, 60.9%)
11/19 11:41:49午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.7605	Prec@(1,5) (29.6%, 61.2%)
11/19 11:41:49午後 searchStage_trainer.py:320 [INFO] Valid: [ 14/49] Final Prec@1 29.5920%
11/19 11:41:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:41:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 29.5920%
11/19 11:42:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.6946 (2.5731)	Arch Loss 2.6728 (2.8922)	Arch Hard Loss 2.5727 (2.7860)	Arch Alpha Loss 0.0100 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.8%, 65.1%)	
11/19 11:43:16午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 2.3972 (2.6022)	Arch Loss 2.8929 (2.8686)	Arch Hard Loss 2.7920 (2.7625)	Arch Alpha Loss 0.0101 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (32.5%, 64.8%)	
11/19 11:44:00午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.5526 (2.6217)	Arch Loss 2.5601 (2.8620)	Arch Hard Loss 2.4587 (2.7558)	Arch Alpha Loss 0.0101 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.8%, 64.4%)	
11/19 11:44:39午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.9699 (2.6183)	Arch Loss 2.8423 (2.8653)	Arch Hard Loss 2.7447 (2.7589)	Arch Alpha Loss 0.0098 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.9%, 64.4%)	
11/19 11:44:39午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 15/49] Final Prec@1 31.9400%
11/19 11:44:46午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.6846	Prec@(1,5) (31.2%, 64.0%)
11/19 11:44:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.6991	Prec@(1,5) (30.9%, 63.3%)
11/19 11:44:59午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.6949	Prec@(1,5) (31.1%, 63.1%)
11/19 11:45:05午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.7025	Prec@(1,5) (31.1%, 62.9%)
11/19 11:45:05午後 searchStage_trainer.py:320 [INFO] Valid: [ 15/49] Final Prec@1 31.1200%
11/19 11:45:05午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:45:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.1200%
11/19 11:45:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.4096 (2.4925)	Arch Loss 2.1987 (2.8662)	Arch Hard Loss 2.0867 (2.7591)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.5%, 66.6%)	
11/19 11:46:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.7461 (2.5190)	Arch Loss 2.5446 (2.8445)	Arch Hard Loss 2.4306 (2.7375)	Arch Alpha Loss 0.0114 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 66.5%)	
11/19 11:47:17午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.4942 (2.5267)	Arch Loss 2.9743 (2.8268)	Arch Hard Loss 2.8625 (2.7198)	Arch Alpha Loss 0.0112 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.1%, 66.1%)	
11/19 11:47:56午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 2.2924 (2.5303)	Arch Loss 2.6838 (2.8201)	Arch Hard Loss 2.5689 (2.7132)	Arch Alpha Loss 0.0115 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 66.1%)	
11/19 11:47:56午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 16/49] Final Prec@1 33.9320%
11/19 11:48:03午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.7114	Prec@(1,5) (31.8%, 62.8%)
11/19 11:48:10午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.7268	Prec@(1,5) (31.3%, 62.3%)
11/19 11:48:16午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.7378	Prec@(1,5) (31.1%, 61.9%)
11/19 11:48:22午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.7403	Prec@(1,5) (31.0%, 62.0%)
11/19 11:48:23午後 searchStage_trainer.py:320 [INFO] Valid: [ 16/49] Final Prec@1 31.0080%
11/19 11:48:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:48:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.1200%
11/19 11:49:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.8296 (2.4387)	Arch Loss 3.0367 (2.8114)	Arch Hard Loss 2.9381 (2.7035)	Arch Alpha Loss 0.0099 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.5%, 68.4%)	
11/19 11:49:50午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.4696 (2.4373)	Arch Loss 2.7931 (2.7969)	Arch Hard Loss 2.6906 (2.6882)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.7%, 68.4%)	
11/19 11:50:33午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.3803 (2.4500)	Arch Loss 2.7429 (2.7842)	Arch Hard Loss 2.6411 (2.6750)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.4%, 68.1%)	
11/19 11:51:12午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.6358 (2.4663)	Arch Loss 2.4517 (2.7746)	Arch Hard Loss 2.3443 (2.6651)	Arch Alpha Loss 0.0107 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (35.2%, 67.6%)	
11/19 11:51:12午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 17/49] Final Prec@1 35.1520%
11/19 11:51:19午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.6578	Prec@(1,5) (31.6%, 63.4%)
11/19 11:51:26午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.6492	Prec@(1,5) (32.3%, 63.7%)
11/19 11:51:33午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.6466	Prec@(1,5) (32.1%, 63.9%)
11/19 11:51:39午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.6466	Prec@(1,5) (32.0%, 63.8%)
11/19 11:51:39午後 searchStage_trainer.py:320 [INFO] Valid: [ 17/49] Final Prec@1 32.0120%
11/19 11:51:39午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:51:40午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.0120%
11/19 11:52:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 2.5716 (2.3883)	Arch Loss 3.0467 (2.7361)	Arch Hard Loss 2.9265 (2.6256)	Arch Alpha Loss 0.0120 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.7%, 69.7%)	
11/19 11:53:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.7458 (2.3918)	Arch Loss 2.7971 (2.7390)	Arch Hard Loss 2.6748 (2.6284)	Arch Alpha Loss 0.0122 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 69.3%)	
11/19 11:53:51午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 2.1648 (2.4020)	Arch Loss 2.7824 (2.7352)	Arch Hard Loss 2.6633 (2.6244)	Arch Alpha Loss 0.0119 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.6%, 69.1%)	
11/19 11:54:29午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.4558 (2.4099)	Arch Loss 2.6808 (2.7339)	Arch Hard Loss 2.5628 (2.6229)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.2%, 69.0%)	
11/19 11:54:30午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 18/49] Final Prec@1 36.2280%
11/19 11:54:37午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.6542	Prec@(1,5) (32.3%, 63.7%)
11/19 11:54:44午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.6580	Prec@(1,5) (32.5%, 63.6%)
11/19 11:54:51午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.6541	Prec@(1,5) (32.4%, 63.6%)
11/19 11:54:57午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.6510	Prec@(1,5) (32.4%, 63.9%)
11/19 11:54:57午後 searchStage_trainer.py:320 [INFO] Valid: [ 18/49] Final Prec@1 32.4080%
11/19 11:54:57午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:54:57午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 32.4080%
11/19 11:55:41午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.9238 (2.3298)	Arch Loss 2.4674 (2.7288)	Arch Hard Loss 2.3602 (2.6166)	Arch Alpha Loss 0.0107 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 70.5%)	
11/19 11:56:24午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 2.2470 (2.3355)	Arch Loss 2.4378 (2.7114)	Arch Hard Loss 2.3322 (2.5996)	Arch Alpha Loss 0.0106 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.4%, 70.6%)	
11/19 11:57:07午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.3122 (2.3252)	Arch Loss 2.8180 (2.6988)	Arch Hard Loss 2.7106 (2.5873)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.9%, 70.7%)	
11/19 11:57:46午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 2.5754 (2.3369)	Arch Loss 2.8928 (2.6891)	Arch Hard Loss 2.7863 (2.5778)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.8%, 70.5%)	
11/19 11:57:46午後 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 19/49] Final Prec@1 37.7680%
11/19 11:57:53午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.6640	Prec@(1,5) (32.9%, 64.2%)
11/19 11:58:00午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.6372	Prec@(1,5) (33.3%, 65.0%)
11/19 11:58:07午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.6396	Prec@(1,5) (33.2%, 64.9%)
11/19 11:58:13午後 searchStage_trainer.py:309 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.6356	Prec@(1,5) (33.3%, 64.9%)
11/19 11:58:13午後 searchStage_trainer.py:320 [INFO] Valid: [ 19/49] Final Prec@1 33.2400%
11/19 11:58:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/19 11:58:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.2400%
11/19 11:58:57午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 2.1475 (2.2351)	Arch Loss 2.5530 (2.6482)	Arch Hard Loss 2.4398 (2.5374)	Arch Alpha Loss 0.0113 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.8%, 72.5%)	
11/19 11:59:40午後 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 2.2651 (2.2580)	Arch Loss 2.3826 (2.6559)	Arch Hard Loss 2.2689 (2.5454)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.3%)	
11/20 12:00:24午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.1762 (2.2632)	Arch Loss 2.5024 (2.6563)	Arch Hard Loss 2.3875 (2.5458)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.2%)	
11/20 12:01:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 2.1222 (2.2662)	Arch Loss 2.4962 (2.6426)	Arch Hard Loss 2.3780 (2.5322)	Arch Alpha Loss 0.0118 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 72.1%)	
11/20 12:01:03午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 20/49] Final Prec@1 39.1960%
11/20 12:01:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.5678	Prec@(1,5) (34.7%, 67.3%)
11/20 12:01:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.5408	Prec@(1,5) (35.6%, 67.3%)
11/20 12:01:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.5340	Prec@(1,5) (35.9%, 67.2%)
11/20 12:01:29午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.5288	Prec@(1,5) (35.8%, 67.2%)
11/20 12:01:30午前 searchStage_trainer.py:320 [INFO] Valid: [ 20/49] Final Prec@1 35.7960%
11/20 12:01:30午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:01:30午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.7960%
11/20 12:02:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 2.4850 (2.1871)	Arch Loss 2.1998 (2.6067)	Arch Hard Loss 2.0948 (2.4969)	Arch Alpha Loss 0.0105 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.7%, 73.9%)	
11/20 12:02:57午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.9881 (2.1911)	Arch Loss 2.3767 (2.5814)	Arch Hard Loss 2.2722 (2.4719)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.8%, 73.8%)	
11/20 12:03:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 2.2585 (2.2011)	Arch Loss 2.6051 (2.6086)	Arch Hard Loss 2.5004 (2.4995)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.5%)	
11/20 12:04:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 2.0469 (2.2063)	Arch Loss 2.4638 (2.6033)	Arch Hard Loss 2.3657 (2.4941)	Arch Alpha Loss 0.0098 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.4%)	
11/20 12:04:20午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 21/49] Final Prec@1 40.4800%
11/20 12:04:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.4369	Prec@(1,5) (36.8%, 69.6%)
11/20 12:04:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.4525	Prec@(1,5) (36.9%, 68.8%)
11/20 12:04:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.4443	Prec@(1,5) (37.1%, 68.9%)
11/20 12:04:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.4383	Prec@(1,5) (37.1%, 68.8%)
11/20 12:04:46午前 searchStage_trainer.py:320 [INFO] Valid: [ 21/49] Final Prec@1 37.0880%
11/20 12:04:46午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:04:46午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.0880%
11/20 12:05:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 2.0186 (2.1005)	Arch Loss 2.6507 (2.5797)	Arch Hard Loss 2.5303 (2.4705)	Arch Alpha Loss 0.0120 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 75.5%)	
11/20 12:06:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 2.2300 (2.1312)	Arch Loss 2.6221 (2.5862)	Arch Hard Loss 2.5032 (2.4771)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.8%, 75.2%)	
11/20 12:06:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 2.3578 (2.1400)	Arch Loss 2.3210 (2.5871)	Arch Hard Loss 2.2020 (2.4781)	Arch Alpha Loss 0.0119 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.6%, 74.9%)	
11/20 12:07:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.9815 (2.1417)	Arch Loss 2.2324 (2.5776)	Arch Hard Loss 2.1163 (2.4688)	Arch Alpha Loss 0.0116 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.2%, 75.0%)	
11/20 12:07:37午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 22/49] Final Prec@1 42.2080%
11/20 12:07:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.5038	Prec@(1,5) (35.0%, 68.4%)
11/20 12:07:51午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.5092	Prec@(1,5) (35.2%, 68.3%)
11/20 12:07:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.5031	Prec@(1,5) (35.4%, 68.3%)
11/20 12:08:04午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.5011	Prec@(1,5) (35.3%, 68.3%)
11/20 12:08:04午前 searchStage_trainer.py:320 [INFO] Valid: [ 22/49] Final Prec@1 35.3280%
11/20 12:08:04午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:08:04午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.0880%
11/20 12:08:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 2.2791 (2.0367)	Arch Loss 2.3233 (2.5317)	Arch Hard Loss 2.2231 (2.4230)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.4%, 76.6%)	
11/20 12:09:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 2.2071 (2.0608)	Arch Loss 2.7317 (2.5534)	Arch Hard Loss 2.6315 (2.4445)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.2%)	
11/20 12:10:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.9993 (2.0661)	Arch Loss 2.5575 (2.5514)	Arch Hard Loss 2.4533 (2.4422)	Arch Alpha Loss 0.0104 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 76.2%)	
11/20 12:10:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 2.0581 (2.0794)	Arch Loss 2.9200 (2.5380)	Arch Hard Loss 2.8167 (2.4285)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.3%, 75.9%)	
11/20 12:10:54午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 23/49] Final Prec@1 43.3320%
11/20 12:11:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.3982	Prec@(1,5) (37.0%, 69.6%)
11/20 12:11:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.3947	Prec@(1,5) (37.5%, 69.5%)
11/20 12:11:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.4084	Prec@(1,5) (37.5%, 69.3%)
11/20 12:11:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.4027	Prec@(1,5) (37.7%, 69.6%)
11/20 12:11:20午前 searchStage_trainer.py:320 [INFO] Valid: [ 23/49] Final Prec@1 37.7480%
11/20 12:11:20午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:11:20午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.7480%
11/20 12:12:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 2.5356 (1.9716)	Arch Loss 2.8438 (2.5139)	Arch Hard Loss 2.7295 (2.4034)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.5%, 77.7%)	
11/20 12:12:48午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.8749 (1.9818)	Arch Loss 2.3387 (2.5094)	Arch Hard Loss 2.2221 (2.3990)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.2%, 77.7%)	
11/20 12:13:31午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6879 (1.9949)	Arch Loss 2.9731 (2.5130)	Arch Hard Loss 2.8571 (2.4026)	Arch Alpha Loss 0.0116 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.1%, 77.4%)	
11/20 12:14:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 2.2301 (2.0069)	Arch Loss 2.2952 (2.5093)	Arch Hard Loss 2.1786 (2.3989)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.9%, 77.3%)	
11/20 12:14:10午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 24/49] Final Prec@1 44.8840%
11/20 12:14:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.4510	Prec@(1,5) (37.3%, 68.8%)
11/20 12:14:24午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.4496	Prec@(1,5) (37.3%, 69.0%)
11/20 12:14:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.4331	Prec@(1,5) (37.5%, 69.4%)
11/20 12:14:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.4219	Prec@(1,5) (37.8%, 69.6%)
11/20 12:14:37午前 searchStage_trainer.py:320 [INFO] Valid: [ 24/49] Final Prec@1 37.8400%
11/20 12:14:37午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:14:37午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.8400%
11/20 12:15:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.9828 (1.8982)	Arch Loss 2.5129 (2.4899)	Arch Hard Loss 2.4102 (2.3800)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.5%, 79.2%)	
11/20 12:16:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.7977 (1.9040)	Arch Loss 2.9426 (2.4828)	Arch Hard Loss 2.8384 (2.3727)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.4%, 79.3%)	
11/20 12:16:47午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 2.3819 (1.9366)	Arch Loss 2.2389 (2.4744)	Arch Hard Loss 2.1345 (2.3643)	Arch Alpha Loss 0.0104 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.8%, 78.7%)	
11/20 12:17:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 2.0749 (1.9525)	Arch Loss 2.5738 (2.4746)	Arch Hard Loss 2.4658 (2.3643)	Arch Alpha Loss 0.0108 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.4%, 78.3%)	
11/20 12:17:26午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 25/49] Final Prec@1 46.4200%
11/20 12:17:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.4293	Prec@(1,5) (37.5%, 69.6%)
11/20 12:17:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.4468	Prec@(1,5) (37.4%, 68.9%)
11/20 12:17:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.4418	Prec@(1,5) (37.4%, 69.1%)
11/20 12:17:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.4298	Prec@(1,5) (37.7%, 69.3%)
11/20 12:17:53午前 searchStage_trainer.py:320 [INFO] Valid: [ 25/49] Final Prec@1 37.6880%
11/20 12:17:53午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:17:53午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 37.8400%
11/20 12:18:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.6669 (1.8340)	Arch Loss 2.7766 (2.4257)	Arch Hard Loss 2.6573 (2.3151)	Arch Alpha Loss 0.0119 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.3%, 80.4%)	
11/20 12:19:20午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.9405 (1.8727)	Arch Loss 2.4392 (2.4415)	Arch Hard Loss 2.3226 (2.3315)	Arch Alpha Loss 0.0117 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.2%, 79.7%)	
11/20 12:20:03午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.8156 (1.8883)	Arch Loss 2.7558 (2.4398)	Arch Hard Loss 2.6413 (2.3301)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.7%, 79.6%)	
11/20 12:20:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.9102 (1.8967)	Arch Loss 2.7366 (2.4436)	Arch Hard Loss 2.6299 (2.3341)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.6%, 79.4%)	
11/20 12:20:43午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 26/49] Final Prec@1 47.5720%
11/20 12:20:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.3607	Prec@(1,5) (40.1%, 70.1%)
11/20 12:20:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.3516	Prec@(1,5) (40.0%, 70.7%)
11/20 12:21:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.3453	Prec@(1,5) (39.9%, 71.0%)
11/20 12:21:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.3351	Prec@(1,5) (40.1%, 71.2%)
11/20 12:21:09午前 searchStage_trainer.py:320 [INFO] Valid: [ 26/49] Final Prec@1 40.1040%
11/20 12:21:09午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:21:09午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 40.1040%
11/20 12:21:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.8637 (1.7997)	Arch Loss 2.4577 (2.4443)	Arch Hard Loss 2.3514 (2.3369)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.6%, 81.9%)	
11/20 12:22:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.7894 (1.8136)	Arch Loss 2.1485 (2.4197)	Arch Hard Loss 2.0400 (2.3121)	Arch Alpha Loss 0.0108 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.4%)	
11/20 12:23:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.7493 (1.8282)	Arch Loss 2.4030 (2.4396)	Arch Hard Loss 2.2957 (2.3320)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.2%, 80.9%)	
11/20 12:23:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.9957 (1.8399)	Arch Loss 2.4159 (2.4334)	Arch Hard Loss 2.3094 (2.3259)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.7%, 80.7%)	
11/20 12:24:00午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 27/49] Final Prec@1 48.7120%
11/20 12:24:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 2.2940	Prec@(1,5) (40.2%, 72.7%)
11/20 12:24:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 2.2818	Prec@(1,5) (41.0%, 72.8%)
11/20 12:24:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 2.2840	Prec@(1,5) (40.9%, 72.5%)
11/20 12:24:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 2.2831	Prec@(1,5) (41.0%, 72.6%)
11/20 12:24:26午前 searchStage_trainer.py:320 [INFO] Valid: [ 27/49] Final Prec@1 41.0120%
11/20 12:24:26午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:24:26午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.0120%
11/20 12:25:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.7009 (1.7564)	Arch Loss 2.4654 (2.3809)	Arch Hard Loss 2.3576 (2.2741)	Arch Alpha Loss 0.0108 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.5%, 81.8%)	
11/20 12:25:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.6210 (1.7747)	Arch Loss 2.7954 (2.3777)	Arch Hard Loss 2.6898 (2.2711)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.6%)	
11/20 12:26:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.4342 (1.7632)	Arch Loss 2.6974 (2.3865)	Arch Hard Loss 2.5928 (2.2801)	Arch Alpha Loss 0.0105 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 82.0%)	
11/20 12:27:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.6660 (1.7698)	Arch Loss 2.9301 (2.3933)	Arch Hard Loss 2.8232 (2.2869)	Arch Alpha Loss 0.0107 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.9%)	
11/20 12:27:16午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 28/49] Final Prec@1 50.4360%
11/20 12:27:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.2559	Prec@(1,5) (42.1%, 72.7%)
11/20 12:27:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.2597	Prec@(1,5) (42.3%, 73.0%)
11/20 12:27:37午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.2720	Prec@(1,5) (41.9%, 72.9%)
11/20 12:27:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.2669	Prec@(1,5) (42.0%, 73.0%)
11/20 12:27:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 28/49] Final Prec@1 42.0080%
11/20 12:27:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:27:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.0080%
11/20 12:28:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.6542 (1.6687)	Arch Loss 2.3519 (2.3966)	Arch Hard Loss 2.2460 (2.2901)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 84.0%)	
11/20 12:29:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.7857 (1.6939)	Arch Loss 1.8527 (2.3767)	Arch Hard Loss 1.7447 (2.2705)	Arch Alpha Loss 0.0108 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.2%)	
11/20 12:29:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.7350 (1.7077)	Arch Loss 2.0340 (2.3752)	Arch Hard Loss 1.9262 (2.2689)	Arch Alpha Loss 0.0108 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.1%, 82.9%)	
11/20 12:30:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.7056 (1.7184)	Arch Loss 2.1890 (2.3680)	Arch Hard Loss 2.0863 (2.2617)	Arch Alpha Loss 0.0103 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.7%)	
11/20 12:30:33午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 29/49] Final Prec@1 51.6880%
11/20 12:30:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.2145	Prec@(1,5) (43.1%, 74.0%)
11/20 12:30:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.2271	Prec@(1,5) (42.5%, 74.1%)
11/20 12:30:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.2270	Prec@(1,5) (42.4%, 74.3%)
11/20 12:30:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.2193	Prec@(1,5) (42.8%, 74.2%)
11/20 12:30:59午前 searchStage_trainer.py:320 [INFO] Valid: [ 29/49] Final Prec@1 42.7640%
11/20 12:30:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 1)], [('skip_connect', 4), ('skip_connect', 2)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:30:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.7640%
11/20 12:31:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.5862 (1.6170)	Arch Loss 2.0557 (2.3745)	Arch Hard Loss 1.9463 (2.2681)	Arch Alpha Loss 0.0109 (0.0106)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.6%, 84.7%)	
11/20 12:32:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.4286 (1.6281)	Arch Loss 2.6193 (2.3755)	Arch Hard Loss 2.5099 (2.2688)	Arch Alpha Loss 0.0109 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.6%)	
11/20 12:33:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.6261 (1.6316)	Arch Loss 2.6930 (2.3605)	Arch Hard Loss 2.5867 (2.2537)	Arch Alpha Loss 0.0106 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.5%)	
11/20 12:33:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 2.0389 (1.6512)	Arch Loss 2.4121 (2.3709)	Arch Hard Loss 2.3069 (2.2642)	Arch Alpha Loss 0.0105 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.5%, 84.2%)	
11/20 12:33:49午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 30/49] Final Prec@1 53.5000%
11/20 12:33:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.3238	Prec@(1,5) (41.7%, 73.4%)
11/20 12:34:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.3307	Prec@(1,5) (41.4%, 73.1%)
11/20 12:34:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.3164	Prec@(1,5) (41.7%, 73.0%)
11/20 12:34:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.3104	Prec@(1,5) (41.8%, 72.8%)
11/20 12:34:16午前 searchStage_trainer.py:320 [INFO] Valid: [ 30/49] Final Prec@1 41.7640%
11/20 12:34:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:34:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.7640%
11/20 12:35:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.4603 (1.5447)	Arch Loss 2.5814 (2.3353)	Arch Hard Loss 2.4746 (2.2284)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.6%)	
11/20 12:35:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.1769 (1.5646)	Arch Loss 2.2718 (2.3497)	Arch Hard Loss 2.1653 (2.2427)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.5%, 85.5%)	
11/20 12:36:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.3973 (1.5774)	Arch Loss 2.3095 (2.3558)	Arch Hard Loss 2.2022 (2.2483)	Arch Alpha Loss 0.0107 (0.0107)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 85.2%)	
11/20 12:37:05午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.5654 (1.5878)	Arch Loss 2.9179 (2.3563)	Arch Hard Loss 2.8078 (2.2487)	Arch Alpha Loss 0.0110 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.0%)	
11/20 12:37:06午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 31/49] Final Prec@1 54.8280%
11/20 12:37:13午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1856	Prec@(1,5) (42.3%, 74.2%)
11/20 12:37:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.2001	Prec@(1,5) (42.7%, 74.1%)
11/20 12:37:26午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.1997	Prec@(1,5) (42.7%, 74.3%)
11/20 12:37:32午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.2067	Prec@(1,5) (42.5%, 74.3%)
11/20 12:37:32午前 searchStage_trainer.py:320 [INFO] Valid: [ 31/49] Final Prec@1 42.4960%
11/20 12:37:32午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:37:32午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 42.7640%
11/20 12:38:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.6619 (1.4671)	Arch Loss 2.2795 (2.3079)	Arch Hard Loss 2.1727 (2.1994)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.7%)	
11/20 12:39:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.6588 (1.4903)	Arch Loss 2.5845 (2.3480)	Arch Hard Loss 2.4775 (2.2391)	Arch Alpha Loss 0.0107 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.4%)	
11/20 12:39:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.6713 (1.5005)	Arch Loss 2.6693 (2.3531)	Arch Hard Loss 2.5601 (2.2439)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.3%)	
11/20 12:40:22午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.4647 (1.5220)	Arch Loss 1.9585 (2.3432)	Arch Hard Loss 1.8539 (2.2338)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.0%)	
11/20 12:40:23午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 32/49] Final Prec@1 56.6000%
11/20 12:40:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.1677	Prec@(1,5) (44.5%, 75.2%)
11/20 12:40:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.2117	Prec@(1,5) (43.6%, 74.6%)
11/20 12:40:43午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.2191	Prec@(1,5) (43.4%, 74.6%)
11/20 12:40:49午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.2149	Prec@(1,5) (43.7%, 74.6%)
11/20 12:40:49午前 searchStage_trainer.py:320 [INFO] Valid: [ 32/49] Final Prec@1 43.6920%
11/20 12:40:49午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:40:50午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.6920%
11/20 12:41:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.5992 (1.4181)	Arch Loss 2.3175 (2.3287)	Arch Hard Loss 2.2032 (2.2192)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 88.0%)	
11/20 12:42:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 1.8017 (1.4484)	Arch Loss 2.2990 (2.3069)	Arch Hard Loss 2.1851 (2.1971)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.6%)	
11/20 12:43:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.5892 (1.4496)	Arch Loss 1.9428 (2.3147)	Arch Hard Loss 1.8275 (2.2047)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.3%, 87.4%)	
11/20 12:43:40午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.8156 (1.4674)	Arch Loss 2.1528 (2.3237)	Arch Hard Loss 2.0417 (2.2137)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 87.1%)	
11/20 12:43:40午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 33/49] Final Prec@1 57.8360%
11/20 12:43:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1709	Prec@(1,5) (43.8%, 75.2%)
11/20 12:43:54午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.1579	Prec@(1,5) (44.7%, 75.4%)
11/20 12:44:01午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.1535	Prec@(1,5) (44.6%, 75.4%)
11/20 12:44:07午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.1620	Prec@(1,5) (44.6%, 75.4%)
11/20 12:44:07午前 searchStage_trainer.py:320 [INFO] Valid: [ 33/49] Final Prec@1 44.6480%
11/20 12:44:07午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:44:07午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.6480%
11/20 12:44:51午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.4152 (1.3355)	Arch Loss 2.4271 (2.3260)	Arch Hard Loss 2.3171 (2.2164)	Arch Alpha Loss 0.0110 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.8%)	
11/20 12:45:34午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.3973 (1.3735)	Arch Loss 3.0899 (2.3308)	Arch Hard Loss 2.9787 (2.2207)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.4%)	
11/20 12:46:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.2764 (1.3920)	Arch Loss 2.2804 (2.3273)	Arch Hard Loss 2.1657 (2.2173)	Arch Alpha Loss 0.0115 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 88.1%)	
11/20 12:46:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.4089 (1.4040)	Arch Loss 2.5270 (2.3221)	Arch Hard Loss 2.4136 (2.2123)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.3%, 87.9%)	
11/20 12:46:58午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 34/49] Final Prec@1 59.2960%
11/20 12:47:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.1779	Prec@(1,5) (44.7%, 75.1%)
11/20 12:47:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.1965	Prec@(1,5) (44.0%, 75.1%)
11/20 12:47:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.1975	Prec@(1,5) (44.3%, 75.3%)
11/20 12:47:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.1819	Prec@(1,5) (44.4%, 75.6%)
11/20 12:47:25午前 searchStage_trainer.py:320 [INFO] Valid: [ 34/49] Final Prec@1 44.4440%
11/20 12:47:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:47:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.6480%
11/20 12:48:08午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.2614 (1.2756)	Arch Loss 2.2603 (2.2849)	Arch Hard Loss 2.1574 (2.1767)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.8%)	
11/20 12:48:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.4016 (1.2996)	Arch Loss 2.3393 (2.2973)	Arch Hard Loss 2.2359 (2.1893)	Arch Alpha Loss 0.0103 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.7%)	
11/20 12:49:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.3087 (1.3238)	Arch Loss 3.2440 (2.3164)	Arch Hard Loss 3.1432 (2.2085)	Arch Alpha Loss 0.0101 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 89.2%)	
11/20 12:50:14午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.2976 (1.3307)	Arch Loss 2.3874 (2.3093)	Arch Hard Loss 2.2829 (2.2014)	Arch Alpha Loss 0.0105 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 89.0%)	
11/20 12:50:15午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 35/49] Final Prec@1 61.2960%
11/20 12:50:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.1616	Prec@(1,5) (45.4%, 76.3%)
11/20 12:50:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.1544	Prec@(1,5) (45.4%, 76.3%)
11/20 12:50:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.1631	Prec@(1,5) (45.4%, 76.2%)
11/20 12:50:41午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.1600	Prec@(1,5) (45.3%, 76.3%)
11/20 12:50:41午前 searchStage_trainer.py:320 [INFO] Valid: [ 35/49] Final Prec@1 45.2920%
11/20 12:50:41午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 2)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 4)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 2), ('skip_connect', 4)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('avg_pool_3x3', 4)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:50:41午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.2920%
11/20 12:51:26午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 1.1109 (1.2216)	Arch Loss 2.0882 (2.3190)	Arch Hard Loss 1.9752 (2.2113)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.7%)	
11/20 12:52:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.2672 (1.2487)	Arch Loss 2.5788 (2.3133)	Arch Hard Loss 2.4657 (2.2054)	Arch Alpha Loss 0.0113 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 90.4%)	
11/20 12:52:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 1.3164 (1.2582)	Arch Loss 1.8863 (2.3106)	Arch Hard Loss 1.7725 (2.2025)	Arch Alpha Loss 0.0114 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.2%)	
11/20 12:53:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.4788 (1.2704)	Arch Loss 2.7694 (2.3087)	Arch Hard Loss 2.6586 (2.2006)	Arch Alpha Loss 0.0111 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.9%)	
11/20 12:53:32午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 36/49] Final Prec@1 62.8560%
11/20 12:53:39午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.1191	Prec@(1,5) (46.7%, 77.4%)
11/20 12:53:46午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.1546	Prec@(1,5) (46.0%, 76.5%)
11/20 12:53:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.1631	Prec@(1,5) (45.7%, 76.3%)
11/20 12:53:58午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.1610	Prec@(1,5) (45.7%, 76.2%)
11/20 12:53:58午前 searchStage_trainer.py:320 [INFO] Valid: [ 36/49] Final Prec@1 45.7280%
11/20 12:53:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:53:59午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 45.7280%
11/20 12:54:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.0959 (1.1802)	Arch Loss 2.7439 (2.3094)	Arch Hard Loss 2.6379 (2.2009)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.9%)	
11/20 12:55:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.8824 (1.1678)	Arch Loss 2.4687 (2.3021)	Arch Hard Loss 2.3615 (2.1937)	Arch Alpha Loss 0.0107 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.6%)	
11/20 12:56:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.0861 (1.1882)	Arch Loss 2.4025 (2.3025)	Arch Hard Loss 2.2968 (2.1940)	Arch Alpha Loss 0.0106 (0.0108)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.2%)	
11/20 12:56:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.2546 (1.2024)	Arch Loss 2.7129 (2.3134)	Arch Hard Loss 2.6079 (2.2048)	Arch Alpha Loss 0.0105 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 91.0%)	
11/20 12:56:49午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 37/49] Final Prec@1 64.7760%
11/20 12:56:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.1319	Prec@(1,5) (46.9%, 77.4%)
11/20 12:57:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.1510	Prec@(1,5) (46.8%, 77.0%)
11/20 12:57:09午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.1590	Prec@(1,5) (46.6%, 76.5%)
11/20 12:57:15午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.1482	Prec@(1,5) (46.7%, 76.5%)
11/20 12:57:15午前 searchStage_trainer.py:320 [INFO] Valid: [ 37/49] Final Prec@1 46.6480%
11/20 12:57:15午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 12:57:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6480%
11/20 12:58:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 1.2831 (1.1033)	Arch Loss 2.3028 (2.3107)	Arch Hard Loss 2.1939 (2.2019)	Arch Alpha Loss 0.0109 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.1%)	
11/20 12:58:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 1.0712 (1.1203)	Arch Loss 2.2877 (2.3304)	Arch Hard Loss 2.1815 (2.2214)	Arch Alpha Loss 0.0106 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.0%)	
11/20 12:59:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 1.5043 (1.1297)	Arch Loss 3.0698 (2.3243)	Arch Hard Loss 2.9597 (2.2152)	Arch Alpha Loss 0.0110 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.9%)	
11/20 01:00:06午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 1.1413 (1.1392)	Arch Loss 2.1103 (2.3193)	Arch Hard Loss 1.9982 (2.2098)	Arch Alpha Loss 0.0112 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.6%)	
11/20 01:00:07午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 38/49] Final Prec@1 66.3760%
11/20 01:00:14午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 2.1688	Prec@(1,5) (46.8%, 76.7%)
11/20 01:00:21午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 2.1649	Prec@(1,5) (46.4%, 77.1%)
11/20 01:00:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 2.1592	Prec@(1,5) (46.4%, 77.2%)
11/20 01:00:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 2.1534	Prec@(1,5) (46.5%, 77.2%)
11/20 01:00:33午前 searchStage_trainer.py:320 [INFO] Valid: [ 38/49] Final Prec@1 46.4560%
11/20 01:00:33午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:00:34午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6480%
11/20 01:01:18午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 1.1777 (1.0500)	Arch Loss 2.4734 (2.3196)	Arch Hard Loss 2.3620 (2.2094)	Arch Alpha Loss 0.0111 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.8%)	
11/20 01:02:01午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.7808 (1.0548)	Arch Loss 2.0411 (2.3173)	Arch Hard Loss 1.9285 (2.2069)	Arch Alpha Loss 0.0113 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.7%)	
11/20 01:02:44午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.9738 (1.0743)	Arch Loss 2.6700 (2.3225)	Arch Hard Loss 2.5553 (2.2114)	Arch Alpha Loss 0.0115 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.3%)	
11/20 01:03:23午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 1.1680 (1.0797)	Arch Loss 2.7711 (2.3281)	Arch Hard Loss 2.6600 (2.2166)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.3%)	
11/20 01:03:24午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 39/49] Final Prec@1 68.2800%
11/20 01:03:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.1388	Prec@(1,5) (46.7%, 77.3%)
11/20 01:03:38午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.1897	Prec@(1,5) (46.4%, 76.7%)
11/20 01:03:44午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.1714	Prec@(1,5) (46.7%, 77.0%)
11/20 01:03:50午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.1740	Prec@(1,5) (46.7%, 76.9%)
11/20 01:03:50午前 searchStage_trainer.py:320 [INFO] Valid: [ 39/49] Final Prec@1 46.6480%
11/20 01:03:50午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('avg_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:03:51午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.6480%
11/20 01:04:35午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.8729 (0.9947)	Arch Loss 2.0056 (2.3513)	Arch Hard Loss 1.8898 (2.2382)	Arch Alpha Loss 0.0116 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.8%)	
11/20 01:05:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.9031 (1.0037)	Arch Loss 2.6810 (2.3376)	Arch Hard Loss 2.5656 (2.2240)	Arch Alpha Loss 0.0115 (0.0114)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.6%)	
11/20 01:06:02午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 1.2498 (1.0113)	Arch Loss 2.4204 (2.3555)	Arch Hard Loss 2.3074 (2.2421)	Arch Alpha Loss 0.0113 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.5%)	
11/20 01:06:41午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.6878 (1.0174)	Arch Loss 2.6828 (2.3509)	Arch Hard Loss 2.5742 (2.2379)	Arch Alpha Loss 0.0109 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.3%)	
11/20 01:06:41午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 40/49] Final Prec@1 69.7600%
11/20 01:06:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 2.1663	Prec@(1,5) (47.2%, 77.6%)
11/20 01:06:55午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 2.1659	Prec@(1,5) (46.4%, 77.4%)
11/20 01:07:02午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 2.1731	Prec@(1,5) (46.7%, 77.0%)
11/20 01:07:08午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 2.1487	Prec@(1,5) (47.2%, 77.2%)
11/20 01:07:08午前 searchStage_trainer.py:320 [INFO] Valid: [ 40/49] Final Prec@1 47.1920%
11/20 01:07:08午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('max_pool_3x3', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:07:08午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1920%
11/20 01:07:52午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 1.0534 (0.9464)	Arch Loss 2.2984 (2.2936)	Arch Hard Loss 2.1857 (2.1815)	Arch Alpha Loss 0.0113 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.0%)	
11/20 01:08:36午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.7871 (0.9560)	Arch Loss 2.4375 (2.3306)	Arch Hard Loss 2.3289 (2.2185)	Arch Alpha Loss 0.0109 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.0%)	
11/20 01:09:19午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 1.0664 (0.9586)	Arch Loss 2.4692 (2.3392)	Arch Hard Loss 2.3604 (2.2273)	Arch Alpha Loss 0.0109 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 93.9%)	
11/20 01:09:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 1.0710 (0.9652)	Arch Loss 2.9005 (2.3359)	Arch Hard Loss 2.7933 (2.2242)	Arch Alpha Loss 0.0107 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.8%)	
11/20 01:09:58午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 41/49] Final Prec@1 71.3280%
11/20 01:10:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.1603	Prec@(1,5) (47.2%, 77.4%)
11/20 01:10:12午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 2.1627	Prec@(1,5) (47.2%, 77.3%)
11/20 01:10:19午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.1524	Prec@(1,5) (47.5%, 77.4%)
11/20 01:10:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.1511	Prec@(1,5) (47.6%, 77.4%)
11/20 01:10:25午前 searchStage_trainer.py:320 [INFO] Valid: [ 41/49] Final Prec@1 47.5760%
11/20 01:10:25午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('avg_pool_3x3', 2)], [('avg_pool_3x3', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:10:25午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.5760%
11/20 01:11:09午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7520 (0.8817)	Arch Loss 2.2939 (2.2827)	Arch Hard Loss 2.1764 (2.1715)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 95.2%)	
11/20 01:11:53午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.8512 (0.8989)	Arch Loss 2.3467 (2.2926)	Arch Hard Loss 2.2282 (2.1814)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
11/20 01:12:37午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.9416 (0.9100)	Arch Loss 2.6000 (2.3220)	Arch Hard Loss 2.4822 (2.2108)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/20 01:13:16午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 1.2132 (0.9178)	Arch Loss 2.5211 (2.3315)	Arch Hard Loss 2.4015 (2.2205)	Arch Alpha Loss 0.0120 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.3%)	
11/20 01:13:16午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 42/49] Final Prec@1 72.8320%
11/20 01:13:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.1622	Prec@(1,5) (48.3%, 77.1%)
11/20 01:13:30午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 2.1702	Prec@(1,5) (48.1%, 77.1%)
11/20 01:13:36午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 2.1435	Prec@(1,5) (48.3%, 77.7%)
11/20 01:13:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 2.1627	Prec@(1,5) (48.2%, 77.5%)
11/20 01:13:43午前 searchStage_trainer.py:320 [INFO] Valid: [ 42/49] Final Prec@1 48.2000%
11/20 01:13:43午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:13:43午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.2000%
11/20 01:14:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.7831 (0.8401)	Arch Loss 1.8033 (2.3549)	Arch Hard Loss 1.7017 (2.2446)	Arch Alpha Loss 0.0102 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.6%)	
11/20 01:15:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 1.0982 (0.8521)	Arch Loss 2.3397 (2.3649)	Arch Hard Loss 2.2365 (2.2544)	Arch Alpha Loss 0.0103 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.3%)	
11/20 01:15:54午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.8160 (0.8584)	Arch Loss 2.0613 (2.3497)	Arch Hard Loss 1.9551 (2.2389)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.3%)	
11/20 01:16:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.8938 (0.8701)	Arch Loss 2.1392 (2.3515)	Arch Hard Loss 2.0358 (2.2405)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 95.2%)	
11/20 01:16:33午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 43/49] Final Prec@1 73.7560%
11/20 01:16:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 2.2050	Prec@(1,5) (47.5%, 77.5%)
11/20 01:16:47午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 2.1892	Prec@(1,5) (48.0%, 77.3%)
11/20 01:16:53午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 2.1764	Prec@(1,5) (48.2%, 77.3%)
11/20 01:16:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 2.1810	Prec@(1,5) (48.0%, 77.3%)
11/20 01:16:59午前 searchStage_trainer.py:320 [INFO] Valid: [ 43/49] Final Prec@1 48.0040%
11/20 01:16:59午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 4), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:17:00午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.2000%
11/20 01:17:43午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.4923 (0.7851)	Arch Loss 2.0504 (2.3914)	Arch Hard Loss 1.9318 (2.2810)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 95.8%)	
11/20 01:18:27午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.8554 (0.8153)	Arch Loss 2.5866 (2.3706)	Arch Hard Loss 2.4681 (2.2600)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.5%)	
11/20 01:19:10午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 1.0419 (0.8269)	Arch Loss 2.1305 (2.3591)	Arch Hard Loss 2.0121 (2.2484)	Arch Alpha Loss 0.0118 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.3%)	
11/20 01:19:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.8650 (0.8308)	Arch Loss 1.6459 (2.3586)	Arch Hard Loss 1.5344 (2.2480)	Arch Alpha Loss 0.0111 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.2%)	
11/20 01:19:49午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 44/49] Final Prec@1 75.5880%
11/20 01:19:56午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.1868	Prec@(1,5) (48.1%, 77.6%)
11/20 01:20:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.2063	Prec@(1,5) (47.7%, 77.4%)
11/20 01:20:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.1950	Prec@(1,5) (47.8%, 77.4%)
11/20 01:20:16午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.1893	Prec@(1,5) (48.0%, 77.4%)
11/20 01:20:16午前 searchStage_trainer.py:320 [INFO] Valid: [ 44/49] Final Prec@1 47.9560%
11/20 01:20:16午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:20:16午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.2000%
11/20 01:21:00午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.9487 (0.7671)	Arch Loss 2.5514 (2.3853)	Arch Hard Loss 2.4437 (2.2748)	Arch Alpha Loss 0.0108 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 95.8%)	
11/20 01:21:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 1.0053 (0.7900)	Arch Loss 2.0784 (2.3781)	Arch Hard Loss 1.9721 (2.2670)	Arch Alpha Loss 0.0106 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 95.8%)	
11/20 01:22:25午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.7804 (0.7929)	Arch Loss 2.3808 (2.3765)	Arch Hard Loss 2.2779 (2.2651)	Arch Alpha Loss 0.0103 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.8%)	
11/20 01:23:04午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7972 (0.7998)	Arch Loss 2.5430 (2.3667)	Arch Hard Loss 2.4361 (2.2552)	Arch Alpha Loss 0.0107 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.8%)	
11/20 01:23:05午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 45/49] Final Prec@1 76.2440%
11/20 01:23:11午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 2.1666	Prec@(1,5) (48.4%, 77.7%)
11/20 01:23:18午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 2.1983	Prec@(1,5) (47.7%, 77.4%)
11/20 01:23:25午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 2.1875	Prec@(1,5) (48.3%, 77.6%)
11/20 01:23:31午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 2.1809	Prec@(1,5) (48.3%, 77.7%)
11/20 01:23:31午前 searchStage_trainer.py:320 [INFO] Valid: [ 45/49] Final Prec@1 48.3320%
11/20 01:23:31午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:23:31午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3320%
11/20 01:24:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.7174 (0.7643)	Arch Loss 2.3153 (2.3239)	Arch Hard Loss 2.2014 (2.2137)	Arch Alpha Loss 0.0114 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.1%)	
11/20 01:24:58午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.8179 (0.7645)	Arch Loss 2.4734 (2.3678)	Arch Hard Loss 2.3593 (2.2586)	Arch Alpha Loss 0.0114 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.0%)	
11/20 01:25:42午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.8655 (0.7595)	Arch Loss 2.3956 (2.3888)	Arch Hard Loss 2.2843 (2.2797)	Arch Alpha Loss 0.0111 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.1%)	
11/20 01:26:21午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 1.0908 (0.7617)	Arch Loss 2.4884 (2.3856)	Arch Hard Loss 2.3731 (2.2767)	Arch Alpha Loss 0.0115 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.1%)	
11/20 01:26:21午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 46/49] Final Prec@1 77.2640%
11/20 01:26:28午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.1943	Prec@(1,5) (48.2%, 78.2%)
11/20 01:26:35午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.1986	Prec@(1,5) (48.4%, 78.1%)
11/20 01:26:42午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.2121	Prec@(1,5) (48.0%, 77.6%)
11/20 01:26:48午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.2118	Prec@(1,5) (48.1%, 77.5%)
11/20 01:26:48午前 searchStage_trainer.py:320 [INFO] Valid: [ 46/49] Final Prec@1 48.0840%
11/20 01:26:48午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 2), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('avg_pool_3x3', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 2)], [('skip_connect', 5), ('max_pool_3x3', 3)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:26:48午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3320%
11/20 01:27:32午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.6107 (0.7230)	Arch Loss 2.0311 (2.3873)	Arch Hard Loss 1.9306 (2.2784)	Arch Alpha Loss 0.0100 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.4%)	
11/20 01:28:15午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.7641 (0.7245)	Arch Loss 2.3210 (2.3893)	Arch Hard Loss 2.2193 (2.2804)	Arch Alpha Loss 0.0102 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.4%)	
11/20 01:28:59午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.8500 (0.7349)	Arch Loss 1.9535 (2.3900)	Arch Hard Loss 1.8501 (2.2810)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
11/20 01:29:38午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7935 (0.7403)	Arch Loss 2.7866 (2.3902)	Arch Hard Loss 2.6836 (2.2809)	Arch Alpha Loss 0.0103 (0.0109)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.4%)	
11/20 01:29:38午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 47/49] Final Prec@1 77.9800%
11/20 01:29:45午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.1711	Prec@(1,5) (48.1%, 78.3%)
11/20 01:29:52午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.1879	Prec@(1,5) (48.2%, 78.0%)
11/20 01:29:59午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.1948	Prec@(1,5) (48.2%, 77.8%)
11/20 01:30:05午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.2022	Prec@(1,5) (48.1%, 77.8%)
11/20 01:30:05午前 searchStage_trainer.py:320 [INFO] Valid: [ 47/49] Final Prec@1 48.0600%
11/20 01:30:05午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 3), ('avg_pool_3x3', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:30:05午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3320%
11/20 01:30:49午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.6983 (0.6918)	Arch Loss 2.2685 (2.3990)	Arch Hard Loss 2.1497 (2.2885)	Arch Alpha Loss 0.0119 (0.0110)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.8%)	
11/20 01:31:33午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.7421 (0.7030)	Arch Loss 2.1604 (2.3898)	Arch Hard Loss 2.0441 (2.2790)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.7%)	
11/20 01:32:17午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.8358 (0.7097)	Arch Loss 2.4269 (2.3984)	Arch Hard Loss 2.3129 (2.2876)	Arch Alpha Loss 0.0114 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.6%)	
11/20 01:32:56午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.8104 (0.7137)	Arch Loss 2.3417 (2.3956)	Arch Hard Loss 2.2255 (2.2848)	Arch Alpha Loss 0.0116 (0.0111)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.6%)	
11/20 01:32:56午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 48/49] Final Prec@1 78.8240%
11/20 01:33:03午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 2.2245	Prec@(1,5) (48.2%, 77.2%)
11/20 01:33:10午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 2.2052	Prec@(1,5) (48.7%, 77.7%)
11/20 01:33:17午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 2.2100	Prec@(1,5) (48.2%, 77.5%)
11/20 01:33:23午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 2.2177	Prec@(1,5) (47.9%, 77.5%)
11/20 01:33:23午前 searchStage_trainer.py:320 [INFO] Valid: [ 48/49] Final Prec@1 47.8560%
11/20 01:33:23午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 3), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 2), ('avg_pool_3x3', 1)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:33:23午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3320%
11/20 01:34:07午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.6652 (0.6926)	Arch Loss 2.6652 (2.3586)	Arch Hard Loss 2.5564 (2.2465)	Arch Alpha Loss 0.0109 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.7%)	
11/20 01:34:50午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.6440 (0.6957)	Arch Loss 2.6450 (2.3787)	Arch Hard Loss 2.5344 (2.2665)	Arch Alpha Loss 0.0111 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.5%)	
11/20 01:35:34午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.7601 (0.6966)	Arch Loss 2.1406 (2.3847)	Arch Hard Loss 2.0266 (2.2723)	Arch Alpha Loss 0.0114 (0.0112)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.7%)	
11/20 01:36:13午前 searchStage_ArchKD_trainer.py:166 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5734 (0.6994)	Arch Loss 2.3204 (2.4026)	Arch Hard Loss 2.2065 (2.2899)	Arch Alpha Loss 0.0114 (0.0113)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.6%)	
11/20 01:36:13午前 searchStage_ArchKD_trainer.py:180 [INFO] Train: [ 49/49] Final Prec@1 79.4480%
11/20 01:36:20午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.2338	Prec@(1,5) (49.2%, 77.2%)
11/20 01:36:27午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.2354	Prec@(1,5) (48.7%, 77.3%)
11/20 01:36:33午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.2434	Prec@(1,5) (48.4%, 77.3%)
11/20 01:36:40午前 searchStage_trainer.py:309 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 2.2310	Prec@(1,5) (48.2%, 77.5%)
11/20 01:36:40午前 searchStage_trainer.py:320 [INFO] Valid: [ 49/49] Final Prec@1 48.2600%
11/20 01:36:40午前 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 4)], [('avg_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 1)], [('skip_connect', 3), ('avg_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 4)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
11/20 01:36:40午前 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 48.3320%
11/20 01:36:40午前 trainer_runner.py:110 [INFO] Final best Prec@1 = 48.3320%
11/20 01:36:40午前 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 2), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('avg_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('avg_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('avg_pool_3x3', 3), ('max_pool_3x3', 1)], [('avg_pool_3x3', 2), ('max_pool_3x3', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('avg_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(10, 12))
