11/20 04:41:33PM parser.py:28 [INFO] 
11/20 04:41:33PM parser.py:29 [INFO] Parameters:
11/20 04:41:33PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g-10/DAG
11/20 04:41:33PM parser.py:31 [INFO] T=10.0
11/20 04:41:33PM parser.py:31 [INFO] ADVANCED=1
11/20 04:41:33PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/20 04:41:33PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/20 04:41:33PM parser.py:31 [INFO] ARCH_CRITERION=length
11/20 04:41:33PM parser.py:31 [INFO] BATCH_SIZE=64
11/20 04:41:33PM parser.py:31 [INFO] CASCADE=0
11/20 04:41:33PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/20 04:41:33PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[]
11/20 04:41:33PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/20 04:41:33PM parser.py:31 [INFO] DATA_PATH=../data/
11/20 04:41:33PM parser.py:31 [INFO] DATASET=cifar100
11/20 04:41:33PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/20 04:41:33PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Beta-length-constraint_slidewindow-3
11/20 04:41:33PM parser.py:31 [INFO] DISCRETE=0
11/20 04:41:33PM parser.py:31 [INFO] EPOCHS=50
11/20 04:41:33PM parser.py:31 [INFO] EVAL_EPOCHS=2
11/20 04:41:33PM parser.py:31 [INFO] EXP_NAME=s0-length-sw3-g-10
11/20 04:41:33PM parser.py:31 [INFO] FINAL_L=0.0
11/20 04:41:33PM parser.py:31 [INFO] G=-10.0
11/20 04:41:33PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/20 04:41:33PM parser.py:31 [INFO] GPUS=[0]
11/20 04:41:33PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/20 04:41:33PM parser.py:31 [INFO] INIT_CHANNELS=16
11/20 04:41:33PM parser.py:31 [INFO] L=0.0
11/20 04:41:33PM parser.py:31 [INFO] LAYERS=20
11/20 04:41:33PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/20 04:41:33PM parser.py:31 [INFO] NAME=Pruning
11/20 04:41:33PM parser.py:31 [INFO] NONKD=1
11/20 04:41:33PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g-10
11/20 04:41:33PM parser.py:31 [INFO] PCDARTS=0
11/20 04:41:33PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g-10/plots
11/20 04:41:33PM parser.py:31 [INFO] PRINT_FREQ=100
11/20 04:41:33PM parser.py:31 [INFO] RESET=0
11/20 04:41:33PM parser.py:31 [INFO] RESUME_PATH=None
11/20 04:41:33PM parser.py:31 [INFO] SAVE=s0-length-sw3-g-10
11/20 04:41:33PM parser.py:31 [INFO] SEED=0
11/20 04:41:33PM parser.py:31 [INFO] SHARE_STAGE=0
11/20 04:41:33PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/20 04:41:33PM parser.py:31 [INFO] SPEC_CELL=1
11/20 04:41:33PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/20 04:41:33PM parser.py:31 [INFO] TEACHER_NAME=none
11/20 04:41:33PM parser.py:31 [INFO] TEACHER_PATH=none
11/20 04:41:33PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/20 04:41:33PM parser.py:31 [INFO] TYPE=Pruning
11/20 04:41:33PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/20 04:41:33PM parser.py:31 [INFO] W_LR=0.025
11/20 04:41:33PM parser.py:31 [INFO] W_LR_MIN=0.001
11/20 04:41:33PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/20 04:41:33PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/20 04:41:33PM parser.py:31 [INFO] WORKERS=4
11/20 04:41:33PM parser.py:32 [INFO] 
11/20 04:41:35PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/20 04:41:40PM parser.py:28 [INFO] 
11/20 04:41:40PM parser.py:29 [INFO] Parameters:
11/20 04:41:40PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g-10/DAG
11/20 04:41:40PM parser.py:31 [INFO] T=10.0
11/20 04:41:40PM parser.py:31 [INFO] ADVANCED=1
11/20 04:41:40PM parser.py:31 [INFO] ALPHA_LR=0.0003
11/20 04:41:40PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/20 04:41:40PM parser.py:31 [INFO] ARCH_CRITERION=length
11/20 04:41:40PM parser.py:31 [INFO] BATCH_SIZE=64
11/20 04:41:40PM parser.py:31 [INFO] CASCADE=0
11/20 04:41:40PM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/20 04:41:40PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[]
11/20 04:41:40PM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/20 04:41:40PM parser.py:31 [INFO] DATA_PATH=../data/
11/20 04:41:40PM parser.py:31 [INFO] DATASET=cifar100
11/20 04:41:40PM parser.py:31 [INFO] DEPTH_COEF=0.0
11/20 04:41:40PM parser.py:31 [INFO] DESCRIPTION=search_with_L1-Beta-length-constraint_slidewindow-3
11/20 04:41:40PM parser.py:31 [INFO] DISCRETE=0
11/20 04:41:40PM parser.py:31 [INFO] EPOCHS=50
11/20 04:41:40PM parser.py:31 [INFO] EVAL_EPOCHS=2
11/20 04:41:40PM parser.py:31 [INFO] EXP_NAME=s0-length-sw3-g-10
11/20 04:41:40PM parser.py:31 [INFO] FINAL_L=0.0
11/20 04:41:40PM parser.py:31 [INFO] G=-10.0
11/20 04:41:40PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/20 04:41:40PM parser.py:31 [INFO] GPUS=[0]
11/20 04:41:40PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/20 04:41:40PM parser.py:31 [INFO] INIT_CHANNELS=16
11/20 04:41:40PM parser.py:31 [INFO] L=0.0
11/20 04:41:40PM parser.py:31 [INFO] LAYERS=32
11/20 04:41:40PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/20 04:41:40PM parser.py:31 [INFO] NAME=Pruning
11/20 04:41:40PM parser.py:31 [INFO] NONKD=1
11/20 04:41:40PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g-10
11/20 04:41:40PM parser.py:31 [INFO] PCDARTS=0
11/20 04:41:40PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-length-sw3-g-10/plots
11/20 04:41:40PM parser.py:31 [INFO] PRINT_FREQ=100
11/20 04:41:40PM parser.py:31 [INFO] RESET=0
11/20 04:41:40PM parser.py:31 [INFO] RESUME_PATH=None
11/20 04:41:40PM parser.py:31 [INFO] SAVE=s0-length-sw3-g-10
11/20 04:41:40PM parser.py:31 [INFO] SEED=0
11/20 04:41:40PM parser.py:31 [INFO] SHARE_STAGE=0
11/20 04:41:40PM parser.py:31 [INFO] SLIDE_WINDOW=3
11/20 04:41:40PM parser.py:31 [INFO] SPEC_CELL=1
11/20 04:41:40PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/20 04:41:40PM parser.py:31 [INFO] TEACHER_NAME=none
11/20 04:41:40PM parser.py:31 [INFO] TEACHER_PATH=none
11/20 04:41:40PM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/20 04:41:40PM parser.py:31 [INFO] TYPE=Pruning
11/20 04:41:40PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/20 04:41:40PM parser.py:31 [INFO] W_LR=0.025
11/20 04:41:40PM parser.py:31 [INFO] W_LR_MIN=0.001
11/20 04:41:40PM parser.py:31 [INFO] W_MOMENTUM=0.9
11/20 04:41:40PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/20 04:41:40PM parser.py:31 [INFO] WORKERS=4
11/20 04:41:40PM parser.py:32 [INFO] 
11/20 04:41:42PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/20 04:42:30PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.5431 (4.5873)	Arch Loss -55.3719 (-26.2280)	Arch Hard Loss 4.5465 (4.5845)	Arch Beta Loss 5.9918 (3.0812)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (1.5%, 7.6%)	
11/20 04:43:19PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1431 (4.4899)	Arch Loss -114.4623 (-55.7360)	Arch Hard Loss 4.2561 (4.4765)	Arch Beta Loss 11.8718 (6.0212)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (2.7%, 11.1%)	
11/20 04:44:06PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.1484 (4.3692)	Arch Loss -173.3020 (-85.2505)	Arch Hard Loss 4.2163 (4.3619)	Arch Beta Loss 17.7518 (8.9612)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (3.9%, 15.0%)	
11/20 04:44:48PM searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8758 (4.2860)	Arch Loss -226.4280 (-111.7989)	Arch Hard Loss 4.0102 (4.2735)	Arch Beta Loss 23.0438 (11.6072)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (4.8%, 17.5%)	
11/20 04:44:49PM searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  0/49] Final Prec@1 4.8120%
11/20 04:44:57PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0513	Prec@(1,5) (7.5%, 26.2%)
11/20 04:45:05PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.0266	Prec@(1,5) (8.0%, 26.8%)
11/20 04:45:13PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0232	Prec@(1,5) (7.9%, 27.0%)
11/20 04:45:20PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0222	Prec@(1,5) (7.9%, 26.9%)
11/20 04:45:20PM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 7.9480%
11/20 04:45:20PM trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 7), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 3), ('skip_connect', 1)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 04:45:21PM trainer_runner.py:105 [INFO] Until now, best Prec@1 = 7.9480%
11/20 04:46:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 3.8722 (3.8671)	Arch Loss -285.9147 (-256.8563)	Arch Hard Loss 3.9111 (3.8636)	Arch Beta Loss 28.9826 (26.0720)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (9.7%, 31.0%)	
11/20 04:46:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 3.7355 (3.8208)	Arch Loss -344.7701 (-286.3116)	Arch Hard Loss 3.8554 (3.8082)	Arch Beta Loss 34.8625 (29.0120)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (10.4%, 32.1%)	
11/20 04:47:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.5671 (3.7771)	Arch Loss -404.0085 (-315.7608)	Arch Hard Loss 3.4167 (3.7588)	Arch Beta Loss 40.7425 (31.9520)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.4%, 33.3%)	
11/20 04:48:27午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.7805 (3.7347)	Arch Loss -456.2927 (-342.2569)	Arch Hard Loss 4.0524 (3.7226)	Arch Beta Loss 46.0345 (34.5980)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (11.8%, 34.8%)	
11/20 04:48:27午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  1/49] Final Prec@1 11.8440%
11/20 04:48:35午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6655	Prec@(1,5) (13.6%, 37.1%)
11/20 04:48:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6390	Prec@(1,5) (14.3%, 37.8%)
11/20 04:48:51午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6448	Prec@(1,5) (14.1%, 37.8%)
11/20 04:48:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6406	Prec@(1,5) (14.1%, 37.9%)
11/20 04:48:58午後 searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 14.0640%
11/20 04:48:58午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 04:48:59午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 14.0640%
11/20 04:49:47午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.5672 (3.5378)	Arch Loss -516.2242 (-487.0999)	Arch Hard Loss 3.5083 (3.5269)	Arch Beta Loss 51.9733 (49.0627)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (14.5%, 40.3%)	
11/20 04:50:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.4345 (3.4947)	Arch Loss -574.9656 (-516.5273)	Arch Hard Loss 3.5662 (3.4992)	Arch Beta Loss 57.8532 (52.0027)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (15.4%, 41.4%)	
11/20 04:51:22午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.1894 (3.4520)	Arch Loss -633.9367 (-545.9645)	Arch Hard Loss 3.3948 (3.4617)	Arch Beta Loss 63.7331 (54.9426)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.1%, 42.8%)	
11/20 04:52:05午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.4291 (3.4304)	Arch Loss -686.9443 (-572.4464)	Arch Hard Loss 3.3066 (3.4396)	Arch Beta Loss 69.0251 (57.5886)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (16.6%, 43.3%)	
11/20 04:52:06午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  2/49] Final Prec@1 16.6600%
11/20 04:52:14午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3392	Prec@(1,5) (18.4%, 47.0%)
11/20 04:52:22午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3518	Prec@(1,5) (18.3%, 46.5%)
11/20 04:52:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3498	Prec@(1,5) (18.4%, 46.5%)
11/20 04:52:37午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3475	Prec@(1,5) (18.4%, 46.4%)
11/20 04:52:37午後 searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 18.4520%
11/20 04:52:37午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[4, 9])
11/20 04:52:37午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 18.4520%
11/20 04:53:26午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.5813 (3.3016)	Arch Loss -746.4391 (-717.2435)	Arch Hard Loss 3.1992 (3.2891)	Arch Beta Loss 74.9638 (72.0533)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (18.6%, 47.7%)	
11/20 04:54:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 2.9948 (3.2563)	Arch Loss -805.1750 (-746.6772)	Arch Hard Loss 3.2624 (3.2549)	Arch Beta Loss 80.8437 (74.9932)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (19.9%, 48.7%)	
11/20 04:55:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.0316 (3.2190)	Arch Loss -863.9925 (-776.0980)	Arch Hard Loss 3.2442 (3.2338)	Arch Beta Loss 86.7237 (77.9332)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.3%, 49.7%)	
11/20 04:55:45午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 2.9529 (3.1969)	Arch Loss -916.8482 (-802.5755)	Arch Hard Loss 3.3081 (3.2160)	Arch Beta Loss 92.0156 (80.5791)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (20.7%, 50.2%)	
11/20 04:55:45午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  3/49] Final Prec@1 20.7320%
11/20 04:55:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2311	Prec@(1,5) (20.5%, 48.8%)
11/20 04:56:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2362	Prec@(1,5) (20.2%, 48.8%)
11/20 04:56:09午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2353	Prec@(1,5) (20.4%, 48.9%)
11/20 04:56:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2399	Prec@(1,5) (20.4%, 48.7%)
11/20 04:56:16午後 searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 20.3960%
11/20 04:56:16午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[4, 9])
11/20 04:56:17午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 20.3960%
11/20 04:57:05午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 2.9071 (3.0235)	Arch Loss -976.7230 (-947.3059)	Arch Hard Loss 2.8203 (3.1318)	Arch Beta Loss 97.9543 (95.0438)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.0%, 54.6%)	
11/20 04:57:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.9736 (3.0114)	Arch Loss -1035.3080 (-976.7383)	Arch Hard Loss 3.0342 (3.0989)	Arch Beta Loss 103.8342 (97.9837)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.2%, 55.0%)	
11/20 04:58:41午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 2.6200 (3.0002)	Arch Loss -1094.1229 (-1006.1639)	Arch Hard Loss 3.0178 (3.0727)	Arch Beta Loss 109.7141 (100.9237)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.4%, 55.1%)	
11/20 04:59:24午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 2.8165 (2.9940)	Arch Loss -1147.0945 (-1032.6461)	Arch Hard Loss 2.9656 (3.0501)	Arch Beta Loss 115.0060 (103.5696)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (24.5%, 55.2%)	
11/20 04:59:24午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  4/49] Final Prec@1 24.5480%
11/20 04:59:32午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0160	Prec@(1,5) (25.0%, 54.7%)
11/20 04:59:40午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 2.9797	Prec@(1,5) (25.6%, 55.8%)
11/20 04:59:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 2.9740	Prec@(1,5) (25.5%, 56.2%)
11/20 04:59:55午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9711	Prec@(1,5) (25.6%, 56.3%)
11/20 04:59:55午後 searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 25.6320%
11/20 04:59:55午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 04:59:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 25.6320%
11/20 05:00:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 2.9547 (2.8454)	Arch Loss -1206.4679 (-1177.4307)	Arch Hard Loss 2.9787 (2.9106)	Arch Beta Loss 120.9446 (118.0341)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (26.6%, 58.9%)	
11/20 05:01:31午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 2.9482 (2.8396)	Arch Loss -1264.8372 (-1206.8047)	Arch Hard Loss 3.4080 (2.9359)	Arch Beta Loss 126.8245 (120.9741)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.0%, 59.4%)	
11/20 05:02:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 2.9421 (2.8382)	Arch Loss -1324.6061 (-1236.2262)	Arch Hard Loss 2.4378 (2.9137)	Arch Beta Loss 132.7044 (123.9140)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.4%, 59.3%)	
11/20 05:03:01午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 2.5763 (2.8242)	Arch Loss -1377.1757 (-1262.7054)	Arch Hard Loss 2.7871 (2.8939)	Arch Beta Loss 137.9963 (126.5599)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (27.5%, 59.8%)	
11/20 05:03:01午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  5/49] Final Prec@1 27.5240%
11/20 05:03:09午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8605	Prec@(1,5) (26.3%, 58.8%)
11/20 05:03:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8645	Prec@(1,5) (26.8%, 58.8%)
11/20 05:03:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8679	Prec@(1,5) (26.9%, 58.7%)
11/20 05:03:32午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8605	Prec@(1,5) (27.1%, 59.0%)
11/20 05:03:32午後 searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 27.1280%
11/20 05:03:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 05:03:33午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 27.1280%
11/20 05:04:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 2.6488 (2.6766)	Arch Loss -1436.3673 (-1407.4687)	Arch Hard Loss 2.9826 (2.7754)	Arch Beta Loss 143.9350 (141.0244)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.7%, 63.3%)	
11/20 05:05:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.7951 (2.6747)	Arch Loss -1495.4122 (-1436.8794)	Arch Hard Loss 2.7365 (2.7640)	Arch Beta Loss 149.8149 (143.9643)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.7%, 63.2%)	
11/20 05:05:57午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 2.9126 (2.6672)	Arch Loss -1554.2705 (-1466.3031)	Arch Hard Loss 2.6759 (2.7396)	Arch Beta Loss 155.6946 (146.9043)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (30.9%, 63.4%)	
11/20 05:06:41午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.8441 (2.6583)	Arch Loss -1607.0000 (-1492.7660)	Arch Hard Loss 2.8646 (2.7360)	Arch Beta Loss 160.9865 (149.5502)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (31.2%, 63.5%)	
11/20 05:06:41午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  6/49] Final Prec@1 31.1600%
11/20 05:06:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.6947	Prec@(1,5) (32.1%, 62.4%)
11/20 05:06:57午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.6798	Prec@(1,5) (32.1%, 63.1%)
11/20 05:07:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.6870	Prec@(1,5) (31.8%, 63.2%)
11/20 05:07:12午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.6866	Prec@(1,5) (31.8%, 63.0%)
11/20 05:07:12午後 searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 31.7960%
11/20 05:07:12午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 05:07:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 31.7960%
11/20 05:08:01午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 2.5463 (2.5021)	Arch Loss -1666.5707 (-1637.4719)	Arch Hard Loss 2.6805 (2.6740)	Arch Beta Loss 166.9251 (164.0146)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.5%, 67.7%)	
11/20 05:08:48午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.5533 (2.5136)	Arch Loss -1725.4413 (-1666.8985)	Arch Hard Loss 2.6087 (2.6467)	Arch Beta Loss 172.8050 (166.9545)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.6%, 67.2%)	
11/20 05:09:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 2.7953 (2.5109)	Arch Loss -1783.7816 (-1696.3015)	Arch Hard Loss 3.0670 (2.6429)	Arch Beta Loss 178.6849 (169.8944)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (33.9%, 67.2%)	
11/20 05:10:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.5789 (2.5099)	Arch Loss -1837.1091 (-1722.7792)	Arch Hard Loss 2.6571 (2.6245)	Arch Beta Loss 183.9766 (172.5404)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.0%, 67.1%)	
11/20 05:10:19午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  7/49] Final Prec@1 33.9320%
11/20 05:10:27午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.5666	Prec@(1,5) (33.6%, 66.1%)
11/20 05:10:35午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.5511	Prec@(1,5) (33.8%, 66.3%)
11/20 05:10:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.5474	Prec@(1,5) (33.9%, 66.3%)
11/20 05:10:50午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.5551	Prec@(1,5) (33.5%, 66.1%)
11/20 05:10:50午後 searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 33.5000%
11/20 05:10:50午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 05:10:50午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 33.5000%
11/20 05:11:39午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.4244 (2.3814)	Arch Loss -1896.3822 (-1867.5030)	Arch Hard Loss 2.7707 (2.5447)	Arch Beta Loss 189.9153 (187.0048)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.8%, 70.0%)	
11/20 05:12:26午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.0716 (2.3732)	Arch Loss -1955.1204 (-1896.9154)	Arch Hard Loss 2.8315 (2.5316)	Arch Beta Loss 195.7952 (189.9447)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.2%, 69.9%)	
11/20 05:13:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 2.4302 (2.3760)	Arch Loss -2014.1442 (-1926.3163)	Arch Hard Loss 2.6086 (2.5306)	Arch Beta Loss 201.6753 (192.8847)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.1%, 69.7%)	
11/20 05:13:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.1176 (2.3759)	Arch Loss -2066.9319 (-1952.7914)	Arch Hard Loss 2.7429 (2.5157)	Arch Beta Loss 206.9675 (195.5307)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.1%, 69.8%)	
11/20 05:13:57午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  8/49] Final Prec@1 37.1240%
11/20 05:14:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4230	Prec@(1,5) (35.7%, 69.0%)
11/20 05:14:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4362	Prec@(1,5) (35.8%, 68.8%)
11/20 05:14:21午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4523	Prec@(1,5) (35.5%, 68.1%)
11/20 05:14:28午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.4535	Prec@(1,5) (35.6%, 68.1%)
11/20 05:14:28午後 searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 35.6040%
11/20 05:14:28午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[4, 9])
11/20 05:14:28午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 35.6040%
11/20 05:15:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.3815 (2.2778)	Arch Loss -2126.2478 (-2097.4900)	Arch Hard Loss 2.8175 (2.4682)	Arch Beta Loss 212.9065 (209.9958)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.0%)	
11/20 05:16:04午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.2633 (2.2866)	Arch Loss -2185.2358 (-2126.9082)	Arch Hard Loss 2.6322 (2.4512)	Arch Beta Loss 218.7868 (212.9359)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (38.8%, 71.9%)	
11/20 05:16:51午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.2444 (2.2784)	Arch Loss -2244.4817 (-2156.3220)	Arch Hard Loss 2.1887 (2.4387)	Arch Beta Loss 224.6670 (215.8761)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.3%, 72.0%)	
11/20 05:17:34午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.0758 (2.2761)	Arch Loss -2297.1553 (-2182.7935)	Arch Hard Loss 2.4380 (2.4284)	Arch Beta Loss 229.9593 (218.5222)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.2%, 72.1%)	
11/20 05:17:35午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [  9/49] Final Prec@1 39.2240%
11/20 05:17:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4355	Prec@(1,5) (36.8%, 69.7%)
11/20 05:17:51午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4263	Prec@(1,5) (36.9%, 69.6%)
11/20 05:17:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4345	Prec@(1,5) (36.7%, 69.5%)
11/20 05:18:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4392	Prec@(1,5) (36.5%, 69.3%)
11/20 05:18:06午後 searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 36.5360%
11/20 05:18:06午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 05:18:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 36.5360%
11/20 05:18:54午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.2962 (2.1458)	Arch Loss -2356.5002 (-2327.4668)	Arch Hard Loss 2.4831 (2.4095)	Arch Beta Loss 235.8983 (232.9876)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.9%, 75.1%)	
11/20 05:19:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.4145 (2.1717)	Arch Loss -2415.6702 (-2356.8985)	Arch Hard Loss 2.1158 (2.3792)	Arch Beta Loss 241.7786 (235.9278)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 74.5%)	
11/20 05:20:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.3769 (2.1781)	Arch Loss -2474.4407 (-2386.3150)	Arch Hard Loss 2.1476 (2.3640)	Arch Beta Loss 247.6588 (238.8679)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 74.4%)	
11/20 05:21:13午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.2428 (2.1734)	Arch Loss -2527.2251 (-2412.7918)	Arch Hard Loss 2.2875 (2.3484)	Arch Beta Loss 252.9513 (241.5140)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.4%, 74.5%)	
11/20 05:21:13午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 10/49] Final Prec@1 41.4520%
11/20 05:21:21午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3348	Prec@(1,5) (37.9%, 71.2%)
11/20 05:21:29午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3012	Prec@(1,5) (38.7%, 71.7%)
11/20 05:21:37午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3177	Prec@(1,5) (38.7%, 71.5%)
11/20 05:21:44午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3142	Prec@(1,5) (38.9%, 71.5%)
11/20 05:21:44午後 searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 38.8720%
11/20 05:21:44午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:21:44午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 38.8720%
11/20 05:22:33午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.0691 (2.0866)	Arch Loss -2586.1365 (-2557.4811)	Arch Hard Loss 2.7663 (2.3140)	Arch Beta Loss 258.8903 (255.9795)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 76.2%)	
11/20 05:23:20午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.4963 (2.0740)	Arch Loss -2645.0120 (-2586.8951)	Arch Hard Loss 2.6942 (2.3015)	Arch Beta Loss 264.7706 (258.9197)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.4%, 76.4%)	
11/20 05:24:08午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 1.9341 (2.0687)	Arch Loss -2704.4592 (-2616.3072)	Arch Hard Loss 2.0493 (2.2909)	Arch Beta Loss 270.6508 (261.8598)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.8%, 76.5%)	
11/20 05:24:52午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 1.9549 (2.0753)	Arch Loss -2757.3604 (-2642.7756)	Arch Hard Loss 2.0714 (2.2840)	Arch Beta Loss 275.9432 (264.5060)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.6%, 76.4%)	
11/20 05:24:52午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 11/49] Final Prec@1 43.6200%
11/20 05:25:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3092	Prec@(1,5) (39.0%, 71.4%)
11/20 05:25:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2886	Prec@(1,5) (39.7%, 71.8%)
11/20 05:25:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2841	Prec@(1,5) (39.8%, 72.1%)
11/20 05:25:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2818	Prec@(1,5) (40.0%, 72.2%)
11/20 05:25:23午後 searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 39.9440%
11/20 05:25:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 05:25:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 39.9440%
11/20 05:26:12午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 1.9166 (1.9535)	Arch Loss -2816.7070 (-2787.4809)	Arch Hard Loss 2.1160 (2.2344)	Arch Beta Loss 281.8823 (278.9715)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.1%, 78.8%)	
11/20 05:27:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.1032 (1.9776)	Arch Loss -2875.7285 (-2816.8803)	Arch Hard Loss 1.8963 (2.2364)	Arch Beta Loss 287.7625 (281.9117)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.7%, 78.3%)	
11/20 05:27:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 1.9403 (1.9893)	Arch Loss -2934.3013 (-2846.2941)	Arch Hard Loss 2.1279 (2.2241)	Arch Beta Loss 293.6429 (284.8518)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.5%, 77.9%)	
11/20 05:28:31午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 1.6204 (1.9905)	Arch Loss -2987.1567 (-2872.7727)	Arch Hard Loss 2.1952 (2.2070)	Arch Beta Loss 298.9352 (287.4980)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.5%, 77.8%)	
11/20 05:28:32午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 12/49] Final Prec@1 45.4800%
11/20 05:28:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.1775	Prec@(1,5) (41.7%, 74.6%)
11/20 05:28:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.1681	Prec@(1,5) (41.7%, 74.7%)
11/20 05:28:56午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.1655	Prec@(1,5) (41.9%, 74.8%)
11/20 05:29:04午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.1753	Prec@(1,5) (41.8%, 74.6%)
11/20 05:29:04午後 searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 41.8040%
11/20 05:29:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 05:29:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 41.8040%
11/20 05:29:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 1.8628 (1.8577)	Arch Loss -3046.6392 (-3017.4521)	Arch Hard Loss 2.1037 (2.1836)	Arch Beta Loss 304.8743 (301.9636)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.0%, 80.6%)	
11/20 05:30:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 1.6109 (1.9161)	Arch Loss -3105.4338 (-3046.8742)	Arch Hard Loss 2.1125 (2.1631)	Arch Beta Loss 310.7546 (304.9037)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.7%, 79.5%)	
11/20 05:31:31午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 1.7804 (1.9147)	Arch Loss -3164.4585 (-3076.2800)	Arch Hard Loss 1.8917 (2.1590)	Arch Beta Loss 316.6350 (307.8439)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.3%)	
11/20 05:32:15午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 1.7296 (1.9137)	Arch Loss -3217.1570 (-3102.7433)	Arch Hard Loss 2.1169 (2.1573)	Arch Beta Loss 321.9274 (310.4901)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.2%, 79.3%)	
11/20 05:32:15午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 13/49] Final Prec@1 47.2440%
11/20 05:32:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1046	Prec@(1,5) (43.6%, 75.6%)
11/20 05:32:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1387	Prec@(1,5) (42.9%, 75.1%)
11/20 05:32:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1241	Prec@(1,5) (43.2%, 75.3%)
11/20 05:32:46午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1271	Prec@(1,5) (43.1%, 75.2%)
11/20 05:32:46午後 searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 43.1240%
11/20 05:32:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 05:32:47午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.1240%
11/20 05:33:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 1.6358 (1.7988)	Arch Loss -3276.4819 (-3247.4304)	Arch Hard Loss 2.1832 (2.1270)	Arch Beta Loss 327.8665 (324.9557)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.7%, 81.9%)	
11/20 05:34:24午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.0144 (1.8357)	Arch Loss -3335.3716 (-3276.8298)	Arch Hard Loss 2.0976 (2.1294)	Arch Beta Loss 333.7469 (327.8959)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.0%, 81.0%)	
11/20 05:35:12午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 1.9292 (1.8368)	Arch Loss -3394.1040 (-3306.2376)	Arch Hard Loss 2.1684 (2.1233)	Arch Beta Loss 339.6273 (330.8361)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.9%, 80.9%)	
11/20 05:35:55午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 1.8583 (1.8447)	Arch Loss -3446.9673 (-3332.7050)	Arch Hard Loss 2.2290 (2.1177)	Arch Beta Loss 344.9196 (333.4823)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (48.6%, 80.8%)	
11/20 05:35:55午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 14/49] Final Prec@1 48.5760%
11/20 05:36:03午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.0680	Prec@(1,5) (44.5%, 76.5%)
11/20 05:36:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.0847	Prec@(1,5) (43.8%, 76.2%)
11/20 05:36:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.0908	Prec@(1,5) (43.6%, 76.3%)
11/20 05:36:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.0930	Prec@(1,5) (43.7%, 76.2%)
11/20 05:36:26午後 searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 43.6640%
11/20 05:36:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:36:27午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 43.6640%
11/20 05:37:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.0588 (1.7542)	Arch Loss -3506.4226 (-3477.3671)	Arch Hard Loss 2.1660 (2.1127)	Arch Beta Loss 350.8589 (347.9480)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.7%, 82.1%)	
11/20 05:38:03午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.3505 (1.7608)	Arch Loss -3565.3506 (-3506.7772)	Arch Hard Loss 2.0409 (2.1044)	Arch Beta Loss 356.7391 (350.8882)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.2%, 82.0%)	
11/20 05:38:52午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 1.8500 (1.7600)	Arch Loss -3624.2712 (-3536.1874)	Arch Hard Loss 1.9248 (2.0962)	Arch Beta Loss 362.6196 (353.8284)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (51.1%, 82.2%)	
11/20 05:39:37午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 1.5224 (1.7734)	Arch Loss -3677.3503 (-3562.6578)	Arch Hard Loss 1.7673 (2.0875)	Arch Beta Loss 367.9118 (356.4745)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.9%)	
11/20 05:39:37午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 15/49] Final Prec@1 50.5960%
11/20 05:39:46午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.0514	Prec@(1,5) (44.6%, 77.1%)
11/20 05:39:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0342	Prec@(1,5) (45.2%, 77.3%)
11/20 05:40:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.0485	Prec@(1,5) (44.8%, 77.2%)
11/20 05:40:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0436	Prec@(1,5) (45.0%, 77.2%)
11/20 05:40:08午後 searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 44.9640%
11/20 05:40:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:40:09午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 44.9640%
11/20 05:40:58午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 1.4964 (1.6722)	Arch Loss -3736.9229 (-3707.3624)	Arch Hard Loss 1.5880 (2.0405)	Arch Beta Loss 373.8511 (370.9403)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.5%, 83.7%)	
11/20 05:41:46午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 1.9743 (1.6968)	Arch Loss -3795.3601 (-3736.7754)	Arch Hard Loss 1.9549 (2.0295)	Arch Beta Loss 379.7315 (373.8805)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.4%)	
11/20 05:42:36午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 1.6564 (1.7097)	Arch Loss -3854.0168 (-3766.1598)	Arch Hard Loss 2.1014 (2.0469)	Arch Beta Loss 385.6118 (376.8207)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.2%, 83.3%)	
11/20 05:43:20午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.6498 (1.7137)	Arch Loss -3907.1155 (-3792.6334)	Arch Hard Loss 1.9286 (2.0351)	Arch Beta Loss 390.9044 (379.4668)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (52.1%, 83.1%)	
11/20 05:43:21午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 16/49] Final Prec@1 52.1360%
11/20 05:43:29午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.0369	Prec@(1,5) (46.6%, 77.1%)
11/20 05:43:37午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0089	Prec@(1,5) (46.6%, 77.4%)
11/20 05:43:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0132	Prec@(1,5) (46.1%, 77.5%)
11/20 05:43:52午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0022	Prec@(1,5) (46.3%, 77.7%)
11/20 05:43:52午後 searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 46.3240%
11/20 05:43:52午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:43:52午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 46.3240%
11/20 05:44:41午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 1.4113 (1.6158)	Arch Loss -3966.2708 (-3937.3185)	Arch Hard Loss 2.1530 (2.0031)	Arch Beta Loss 396.8424 (393.9322)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.3%, 84.5%)	
11/20 05:45:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 1.8137 (1.6287)	Arch Loss -4025.1726 (-3966.7131)	Arch Hard Loss 2.0405 (2.0037)	Arch Beta Loss 402.7213 (396.8717)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.2%)	
11/20 05:46:17午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 1.7652 (1.6432)	Arch Loss -4084.2307 (-3996.0937)	Arch Hard Loss 1.7716 (2.0183)	Arch Beta Loss 408.6003 (399.8112)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.7%, 84.1%)	
11/20 05:47:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 1.3353 (1.6529)	Arch Loss -4136.8569 (-4022.5501)	Arch Hard Loss 2.0584 (2.0176)	Arch Beta Loss 413.8915 (402.4568)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (53.3%, 84.0%)	
11/20 05:47:01午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 17/49] Final Prec@1 53.2800%
11/20 05:47:09午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 1.9889	Prec@(1,5) (46.8%, 78.6%)
11/20 05:47:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 1.9671	Prec@(1,5) (47.0%, 79.0%)
11/20 05:47:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 1.9672	Prec@(1,5) (47.1%, 78.8%)
11/20 05:47:32午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 1.9705	Prec@(1,5) (47.1%, 78.7%)
11/20 05:47:32午後 searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 47.1000%
11/20 05:47:32午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 7], DAG3=[[('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:47:32午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1000%
11/20 05:48:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.3213 (1.5553)	Arch Loss -4196.2114 (-4167.2316)	Arch Hard Loss 2.0814 (1.9600)	Arch Beta Loss 419.8293 (416.9192)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.8%, 85.7%)	
11/20 05:49:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 1.3360 (1.5892)	Arch Loss -4255.1230 (-4196.6003)	Arch Hard Loss 1.9601 (1.9866)	Arch Beta Loss 425.7083 (419.8587)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (55.1%, 85.2%)	
11/20 05:49:58午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.5434 (1.5927)	Arch Loss -4314.0337 (-4225.9846)	Arch Hard Loss 1.8410 (1.9977)	Arch Beta Loss 431.5875 (422.7982)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.8%, 85.2%)	
11/20 05:50:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 1.6115 (1.6025)	Arch Loss -4367.4517 (-4252.4552)	Arch Hard Loss 1.3345 (1.9829)	Arch Beta Loss 436.8786 (425.4438)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (54.7%, 85.0%)	
11/20 05:50:42午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 18/49] Final Prec@1 54.6800%
11/20 05:50:50午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 1.9871	Prec@(1,5) (47.1%, 78.3%)
11/20 05:50:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 1.9913	Prec@(1,5) (47.2%, 78.2%)
11/20 05:51:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 1.9896	Prec@(1,5) (47.4%, 78.3%)
11/20 05:51:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 1.9940	Prec@(1,5) (47.1%, 78.3%)
11/20 05:51:13午後 searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 47.1120%
11/20 05:51:13午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:51:13午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1120%
11/20 05:52:03午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.1950 (1.4883)	Arch Loss -4426.0962 (-4397.1004)	Arch Hard Loss 2.0684 (1.9623)	Arch Beta Loss 442.8164 (439.9063)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.9%)	
11/20 05:52:51午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.7094 (1.5194)	Arch Loss -4484.6670 (-4426.4850)	Arch Hard Loss 2.2879 (1.9730)	Arch Beta Loss 448.6955 (442.8458)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.5%, 86.6%)	
11/20 05:53:40午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 1.9552 (1.5355)	Arch Loss -4544.2036 (-4455.8989)	Arch Hard Loss 1.5427 (1.9543)	Arch Beta Loss 454.5746 (445.7853)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.3%, 86.2%)	
11/20 05:54:24午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.7168 (1.5493)	Arch Loss -4596.8262 (-4482.3499)	Arch Hard Loss 1.8312 (1.9590)	Arch Beta Loss 459.8657 (448.4309)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.8%)	
11/20 05:54:25午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 19/49] Final Prec@1 56.0040%
11/20 05:54:33午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0626	Prec@(1,5) (45.7%, 76.2%)
11/20 05:54:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0675	Prec@(1,5) (45.9%, 76.3%)
11/20 05:54:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0511	Prec@(1,5) (46.1%, 76.9%)
11/20 05:54:56午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0477	Prec@(1,5) (46.1%, 76.9%)
11/20 05:54:56午後 searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 46.1440%
11/20 05:54:56午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:54:56午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 47.1120%
11/20 05:55:47午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6674 (1.4653)	Arch Loss -4656.2236 (-4626.9833)	Arch Hard Loss 1.8105 (1.9498)	Arch Beta Loss 465.8034 (462.8933)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.8%, 87.6%)	
11/20 05:56:38午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 1.4005 (1.4782)	Arch Loss -4714.3726 (-4656.3862)	Arch Hard Loss 2.4519 (1.9421)	Arch Beta Loss 471.6825 (465.8328)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.6%, 87.3%)	
11/20 05:57:27午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 0.9794 (1.4863)	Arch Loss -4773.8413 (-4685.7863)	Arch Hard Loss 1.7734 (1.9373)	Arch Beta Loss 477.5615 (468.7724)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.5%, 87.1%)	
11/20 05:58:10午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.5041 (1.5048)	Arch Loss -4826.9663 (-4712.2459)	Arch Hard Loss 1.5608 (1.9334)	Arch Beta Loss 482.8527 (471.4179)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (57.1%, 86.7%)	
11/20 05:58:10午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 20/49] Final Prec@1 57.1040%
11/20 05:58:18午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9005	Prec@(1,5) (49.2%, 79.9%)
11/20 05:58:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.8909	Prec@(1,5) (49.5%, 79.6%)
11/20 05:58:34午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.8959	Prec@(1,5) (49.3%, 79.8%)
11/20 05:58:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9006	Prec@(1,5) (49.0%, 79.7%)
11/20 05:58:41午後 searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 49.0200%
11/20 05:58:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 05:58:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.0200%
11/20 05:59:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.5875 (1.3799)	Arch Loss -4885.5298 (-4856.8717)	Arch Hard Loss 2.3762 (1.9322)	Arch Beta Loss 488.7906 (485.8804)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.4%, 89.0%)	
11/20 06:00:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 1.5594 (1.4159)	Arch Loss -4944.5439 (-4886.2700)	Arch Hard Loss 2.1525 (1.9292)	Arch Beta Loss 494.6696 (488.8199)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.2%, 88.1%)	
11/20 06:01:07午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 1.6611 (1.4358)	Arch Loss -5003.6431 (-4915.6760)	Arch Hard Loss 1.8432 (1.9184)	Arch Beta Loss 500.5486 (491.7594)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.7%)	
11/20 06:01:51午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.3880 (1.4474)	Arch Loss -5056.6030 (-4942.1337)	Arch Hard Loss 1.7943 (1.9164)	Arch Beta Loss 505.8398 (494.4050)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.5%)	
11/20 06:01:51午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 21/49] Final Prec@1 58.5440%
11/20 06:02:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9157	Prec@(1,5) (48.8%, 79.2%)
11/20 06:02:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9100	Prec@(1,5) (48.8%, 79.7%)
11/20 06:02:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9084	Prec@(1,5) (48.6%, 79.5%)
11/20 06:02:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9053	Prec@(1,5) (48.7%, 79.6%)
11/20 06:02:23午後 searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 48.7120%
11/20 06:02:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:02:23午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.0200%
11/20 06:03:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 1.5174 (1.3298)	Arch Loss -5115.5552 (-5086.7560)	Arch Hard Loss 2.2214 (1.9187)	Arch Beta Loss 511.7776 (508.8675)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.5%)	
11/20 06:04:03午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.3521 (1.3579)	Arch Loss -5174.9028 (-5116.1796)	Arch Hard Loss 1.6647 (1.8903)	Arch Beta Loss 517.6567 (511.8070)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.7%)	
11/20 06:04:52午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.2030 (1.3749)	Arch Loss -5233.0371 (-5145.5750)	Arch Hard Loss 2.3196 (1.8902)	Arch Beta Loss 523.5357 (514.7465)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.5%)	
11/20 06:05:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.6216 (1.3936)	Arch Loss -5286.4829 (-5172.0286)	Arch Hard Loss 1.7862 (1.8923)	Arch Beta Loss 528.8269 (517.3921)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (59.7%, 88.2%)	
11/20 06:05:35午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 22/49] Final Prec@1 59.7280%
11/20 06:05:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.8519	Prec@(1,5) (49.9%, 80.9%)
11/20 06:05:51午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.8523	Prec@(1,5) (49.6%, 80.7%)
11/20 06:05:59午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.8487	Prec@(1,5) (49.8%, 80.9%)
11/20 06:06:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.8558	Prec@(1,5) (49.8%, 80.7%)
11/20 06:06:06午後 searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 49.7600%
11/20 06:06:06午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=[4, 9])
11/20 06:06:06午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.7600%
11/20 06:06:54午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.2835 (1.2609)	Arch Loss -5345.9814 (-5316.6729)	Arch Hard Loss 1.6661 (1.8725)	Arch Beta Loss 534.7648 (531.8545)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.3%, 90.2%)	
11/20 06:07:43午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.2180 (1.3073)	Arch Loss -5404.3862 (-5346.0696)	Arch Hard Loss 2.0511 (1.8712)	Arch Beta Loss 540.6437 (534.7941)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.6%)	
11/20 06:08:33午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 1.4391 (1.3251)	Arch Loss -5463.3833 (-5375.4497)	Arch Hard Loss 1.8459 (1.8864)	Arch Beta Loss 546.5229 (537.7336)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.3%)	
11/20 06:09:17午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.5923 (1.3430)	Arch Loss -5516.2515 (-5401.9079)	Arch Hard Loss 1.8886 (1.8841)	Arch Beta Loss 551.8140 (540.3792)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (61.1%, 89.0%)	
11/20 06:09:17午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 23/49] Final Prec@1 61.1200%
11/20 06:09:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.8505	Prec@(1,5) (49.7%, 80.2%)
11/20 06:09:33午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.8445	Prec@(1,5) (49.9%, 80.8%)
11/20 06:09:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.8522	Prec@(1,5) (50.1%, 80.6%)
11/20 06:09:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.8600	Prec@(1,5) (49.9%, 80.7%)
11/20 06:09:49午後 searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 49.9000%
11/20 06:09:49午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:09:49午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 49.9000%
11/20 06:10:39午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 0.9471 (1.2402)	Arch Loss -5575.6089 (-5546.5718)	Arch Hard Loss 1.9081 (1.8455)	Arch Beta Loss 557.7517 (554.8417)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.4%)	
11/20 06:11:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.3675 (1.2496)	Arch Loss -5634.4277 (-5575.9511)	Arch Hard Loss 1.8828 (1.8617)	Arch Beta Loss 563.6310 (557.7813)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.5%, 90.4%)	
11/20 06:12:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.6137 (1.2662)	Arch Loss -5693.2944 (-5605.3524)	Arch Hard Loss 1.8076 (1.8557)	Arch Beta Loss 569.5102 (560.7208)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.9%, 90.1%)	
11/20 06:12:59午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.2022 (1.2878)	Arch Loss -5746.3765 (-5631.8049)	Arch Hard Loss 1.6358 (1.8590)	Arch Beta Loss 574.8012 (563.3664)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.8%)	
11/20 06:12:59午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 24/49] Final Prec@1 62.1920%
11/20 06:13:07午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 1.8820	Prec@(1,5) (50.2%, 80.8%)
11/20 06:13:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.8651	Prec@(1,5) (50.2%, 80.8%)
11/20 06:13:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 1.8767	Prec@(1,5) (50.3%, 80.6%)
11/20 06:13:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.8700	Prec@(1,5) (50.5%, 80.7%)
11/20 06:13:30午後 searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 50.4600%
11/20 06:13:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:13:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.4600%
11/20 06:14:19午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.3654 (1.2133)	Arch Loss -5805.3403 (-5776.4620)	Arch Hard Loss 2.0503 (1.8267)	Arch Beta Loss 580.7391 (577.8289)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 91.1%)	
11/20 06:15:06午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.4260 (1.2269)	Arch Loss -5863.9443 (-5805.8552)	Arch Hard Loss 2.2370 (1.8289)	Arch Beta Loss 586.6181 (580.7684)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.9%)	
11/20 06:15:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.1541 (1.2416)	Arch Loss -5923.6089 (-5835.2426)	Arch Hard Loss 1.3644 (1.8370)	Arch Beta Loss 592.4973 (583.7080)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.9%, 90.7%)	
11/20 06:16:36午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.2180 (1.2512)	Arch Loss -5976.2158 (-5861.6995)	Arch Hard Loss 1.6689 (1.8360)	Arch Beta Loss 597.7885 (586.3535)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (63.6%, 90.5%)	
11/20 06:16:37午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 25/49] Final Prec@1 63.5840%
11/20 06:16:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.8514	Prec@(1,5) (50.1%, 80.9%)
11/20 06:16:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.8588	Prec@(1,5) (50.2%, 80.5%)
11/20 06:17:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8331	Prec@(1,5) (50.7%, 81.2%)
11/20 06:17:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8386	Prec@(1,5) (50.7%, 81.2%)
11/20 06:17:08午後 searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 50.7040%
11/20 06:17:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:17:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 50.7040%
11/20 06:17:57午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.4526 (1.1753)	Arch Loss -6035.6792 (-6006.3957)	Arch Hard Loss 1.5827 (1.7649)	Arch Beta Loss 603.7262 (600.8161)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.5%)	
11/20 06:18:46午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 0.9949 (1.1947)	Arch Loss -6094.0581 (-6035.7592)	Arch Hard Loss 1.9934 (1.7968)	Arch Beta Loss 609.6052 (603.7556)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.1%, 91.3%)	
11/20 06:19:34午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.3595 (1.1944)	Arch Loss -6153.2651 (-6065.1391)	Arch Hard Loss 1.5779 (1.8122)	Arch Beta Loss 615.4843 (606.6951)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.0%, 91.3%)	
11/20 06:20:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 0.9084 (1.2137)	Arch Loss -6205.6562 (-6091.5834)	Arch Hard Loss 2.0989 (1.8238)	Arch Beta Loss 620.7755 (609.3407)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.8%)	
11/20 06:20:19午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 26/49] Final Prec@1 64.5520%
11/20 06:20:27午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8230	Prec@(1,5) (51.0%, 81.4%)
11/20 06:20:35午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8174	Prec@(1,5) (51.8%, 81.2%)
11/20 06:20:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8251	Prec@(1,5) (51.5%, 81.2%)
11/20 06:20:50午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8302	Prec@(1,5) (51.2%, 81.1%)
11/20 06:20:50午後 searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 51.2160%
11/20 06:20:50午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:20:51午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 51.2160%
11/20 06:21:40午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 0.9391 (1.0853)	Arch Loss -6264.8481 (-6236.1994)	Arch Hard Loss 2.2874 (1.8332)	Arch Beta Loss 626.7136 (623.8033)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.6%)	
11/20 06:22:28午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.3342 (1.1303)	Arch Loss -6324.3687 (-6265.6136)	Arch Hard Loss 1.5591 (1.8145)	Arch Beta Loss 632.5928 (626.7428)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.7%)	
11/20 06:23:17午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.1220 (1.1395)	Arch Loss -6382.5981 (-6294.9982)	Arch Hard Loss 2.1161 (1.8253)	Arch Beta Loss 638.4714 (629.6823)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.6%)	
11/20 06:24:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.0398 (1.1574)	Arch Loss -6436.2842 (-6321.4576)	Arch Hard Loss 1.3405 (1.8218)	Arch Beta Loss 643.7625 (632.3279)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.4%)	
11/20 06:24:02午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 27/49] Final Prec@1 65.9240%
11/20 06:24:10午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8312	Prec@(1,5) (51.4%, 81.7%)
11/20 06:24:18午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8086	Prec@(1,5) (52.3%, 81.7%)
11/20 06:24:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8175	Prec@(1,5) (52.1%, 81.6%)
11/20 06:24:33午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8063	Prec@(1,5) (52.2%, 81.8%)
11/20 06:24:33午後 searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 52.1520%
11/20 06:24:33午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:24:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.1520%
11/20 06:25:23午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.1941 (1.0611)	Arch Loss -6495.2593 (-6466.1197)	Arch Hard Loss 1.7479 (1.7852)	Arch Beta Loss 649.7007 (646.7905)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.7%)	
11/20 06:26:12午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 0.9856 (1.0841)	Arch Loss -6554.4448 (-6495.5078)	Arch Hard Loss 1.3518 (1.7926)	Arch Beta Loss 655.5797 (649.7300)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.3%)	
11/20 06:27:00午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.1312 (1.0906)	Arch Loss -6613.0142 (-6524.8900)	Arch Hard Loss 1.5716 (1.8057)	Arch Beta Loss 661.4586 (652.6696)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.3%)	
11/20 06:27:43午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.2463 (1.1167)	Arch Loss -6665.9785 (-6551.3442)	Arch Hard Loss 1.5205 (1.8074)	Arch Beta Loss 666.7499 (655.3152)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.0%)	
11/20 06:27:44午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 28/49] Final Prec@1 67.1640%
11/20 06:27:52午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8174	Prec@(1,5) (51.9%, 82.0%)
11/20 06:28:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8319	Prec@(1,5) (51.4%, 81.4%)
11/20 06:28:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8097	Prec@(1,5) (52.0%, 81.9%)
11/20 06:28:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.7987	Prec@(1,5) (52.3%, 82.0%)
11/20 06:28:15午後 searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 52.2880%
11/20 06:28:15午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:28:15午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 52.2880%
11/20 06:29:05午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 0.9944 (1.0254)	Arch Loss -6725.3301 (-6695.9562)	Arch Hard Loss 1.5477 (1.8208)	Arch Beta Loss 672.6878 (669.7777)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.4%)	
11/20 06:29:55午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 0.8994 (1.0300)	Arch Loss -6784.3232 (-6725.3670)	Arch Hard Loss 1.3466 (1.8055)	Arch Beta Loss 678.5670 (672.7172)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.4%)	
11/20 06:30:43午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.1638 (1.0533)	Arch Loss -6842.5649 (-6754.7685)	Arch Hard Loss 1.8942 (1.7995)	Arch Beta Loss 684.4459 (675.6568)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (69.1%, 93.0%)	
11/20 06:31:27午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.0277 (1.0648)	Arch Loss -6895.4722 (-6781.2288)	Arch Hard Loss 1.9017 (1.7951)	Arch Beta Loss 689.7374 (678.3024)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.9%)	
11/20 06:31:28午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 29/49] Final Prec@1 68.6000%
11/20 06:31:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.7882	Prec@(1,5) (52.8%, 82.3%)
11/20 06:31:44午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.7702	Prec@(1,5) (53.3%, 82.5%)
11/20 06:31:52午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.7738	Prec@(1,5) (53.2%, 82.6%)
11/20 06:31:59午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.7635	Prec@(1,5) (53.1%, 82.8%)
11/20 06:31:59午後 searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 53.1000%
11/20 06:31:59午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('avg_pool_3x3', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG3_concat=[4, 9])
11/20 06:32:00午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.1000%
11/20 06:32:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.0232 (0.9690)	Arch Loss -6955.1050 (-6925.8800)	Arch Hard Loss 1.6468 (1.7697)	Arch Beta Loss 695.6752 (692.7650)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.3%, 93.7%)	
11/20 06:33:38午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.2231 (0.9684)	Arch Loss -7013.5859 (-6955.2577)	Arch Hard Loss 1.9581 (1.7876)	Arch Beta Loss 701.5544 (695.7045)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.9%, 93.9%)	
11/20 06:34:27午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1325 (0.9943)	Arch Loss -7072.7686 (-6984.6632)	Arch Hard Loss 1.5666 (1.7776)	Arch Beta Loss 707.4335 (698.6441)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.5%)	
11/20 06:35:10午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2368 (1.0207)	Arch Loss -7125.2207 (-7011.1109)	Arch Hard Loss 2.0235 (1.7858)	Arch Beta Loss 712.7244 (701.2897)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.2%)	
11/20 06:35:10午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 30/49] Final Prec@1 70.0480%
11/20 06:35:18午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.7560	Prec@(1,5) (53.3%, 82.5%)
11/20 06:35:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.7535	Prec@(1,5) (53.7%, 82.5%)
11/20 06:35:34午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.7639	Prec@(1,5) (53.5%, 82.5%)
11/20 06:35:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.7612	Prec@(1,5) (53.4%, 82.6%)
11/20 06:35:41午後 searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 53.3840%
11/20 06:35:41午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:35:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 53.3840%
11/20 06:36:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 0.8755 (0.9260)	Arch Loss -7184.8799 (-7155.7641)	Arch Hard Loss 1.7413 (1.7583)	Arch Beta Loss 718.6621 (715.7522)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.6%)	
11/20 06:37:18午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 0.8858 (0.9432)	Arch Loss -7243.5625 (-7185.1332)	Arch Hard Loss 1.8507 (1.7846)	Arch Beta Loss 724.5413 (718.6918)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.5%)	
11/20 06:38:06午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.1333 (0.9700)	Arch Loss -7302.0762 (-7214.5290)	Arch Hard Loss 2.1278 (1.7843)	Arch Beta Loss 730.4204 (721.6313)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 94.1%)	
11/20 06:38:48午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.3098 (0.9827)	Arch Loss -7355.2954 (-7240.9869)	Arch Hard Loss 1.8197 (1.7822)	Arch Beta Loss 735.7115 (724.2769)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.9%)	
11/20 06:38:49午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 31/49] Final Prec@1 70.6560%
11/20 06:38:57午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.6958	Prec@(1,5) (55.0%, 84.1%)
11/20 06:39:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.7049	Prec@(1,5) (54.8%, 83.5%)
11/20 06:39:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.7155	Prec@(1,5) (54.6%, 83.5%)
11/20 06:39:20午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.7215	Prec@(1,5) (54.3%, 83.4%)
11/20 06:39:20午後 searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 54.2560%
11/20 06:39:20午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:39:21午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.2560%
11/20 06:40:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.4640 (0.9056)	Arch Loss -7414.9614 (-7385.6124)	Arch Hard Loss 1.5334 (1.7822)	Arch Beta Loss 741.6495 (738.7395)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.6%)	
11/20 06:40:57午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 0.9681 (0.9225)	Arch Loss -7473.1021 (-7415.0038)	Arch Hard Loss 2.1858 (1.7863)	Arch Beta Loss 747.5288 (741.6790)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.5%)	
11/20 06:41:47午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 0.8364 (0.9252)	Arch Loss -7532.0894 (-7444.3834)	Arch Hard Loss 1.9887 (1.8023)	Arch Beta Loss 753.4078 (744.6186)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.4%)	
11/20 06:42:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.0886 (0.9373)	Arch Loss -7585.3623 (-7470.8503)	Arch Hard Loss 1.6254 (1.7913)	Arch Beta Loss 758.6988 (747.2642)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.3%)	
11/20 06:42:31午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 32/49] Final Prec@1 72.1320%
11/20 06:42:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.7601	Prec@(1,5) (53.7%, 83.1%)
11/20 06:42:47午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.7422	Prec@(1,5) (54.3%, 83.3%)
11/20 06:42:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.7311	Prec@(1,5) (54.3%, 83.3%)
11/20 06:43:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.7301	Prec@(1,5) (54.5%, 83.3%)
11/20 06:43:01午後 searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 54.4480%
11/20 06:43:01午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:43:02午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4480%
11/20 06:43:51午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 0.8364 (0.8395)	Arch Loss -7644.7246 (-7615.4743)	Arch Hard Loss 1.6438 (1.7926)	Arch Beta Loss 764.6368 (761.7267)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.6%)	
11/20 06:44:38午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.6551 (0.8670)	Arch Loss -7703.9014 (-7644.9024)	Arch Hard Loss 1.2597 (1.7601)	Arch Beta Loss 770.5161 (764.6662)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.2%)	
11/20 06:45:27午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 0.9755 (0.8821)	Arch Loss -7761.8867 (-7674.2756)	Arch Hard Loss 2.0653 (1.7823)	Arch Beta Loss 776.3952 (767.6058)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.8%, 95.1%)	
11/20 06:46:11午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.0339 (0.8960)	Arch Loss -7815.3218 (-7700.7323)	Arch Hard Loss 1.5412 (1.7815)	Arch Beta Loss 781.6863 (770.2514)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (73.3%, 95.0%)	
11/20 06:46:11午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 33/49] Final Prec@1 73.3000%
11/20 06:46:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.7496	Prec@(1,5) (54.0%, 83.1%)
11/20 06:46:27午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.7450	Prec@(1,5) (54.2%, 83.0%)
11/20 06:46:35午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.7472	Prec@(1,5) (54.0%, 83.0%)
11/20 06:46:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.7471	Prec@(1,5) (54.2%, 83.0%)
11/20 06:46:42午後 searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 54.1800%
11/20 06:46:42午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:46:42午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4480%
11/20 06:47:31午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 0.6211 (0.7880)	Arch Loss -7874.4312 (-7845.4025)	Arch Hard Loss 1.8095 (1.7366)	Arch Beta Loss 787.6241 (784.7139)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.9%, 95.9%)	
11/20 06:48:19午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 0.5710 (0.8166)	Arch Loss -7932.9253 (-7874.7667)	Arch Hard Loss 2.1060 (1.7672)	Arch Beta Loss 793.5031 (787.6534)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.6%)	
11/20 06:49:07午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.0016 (0.8365)	Arch Loss -7991.5098 (-7904.1577)	Arch Hard Loss 2.3109 (1.7708)	Arch Beta Loss 799.3821 (790.5929)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.4%)	
11/20 06:49:52午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 0.9425 (0.8493)	Arch Loss -8045.0288 (-7930.6132)	Arch Hard Loss 1.7015 (1.7705)	Arch Beta Loss 804.6730 (793.2384)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.2%)	
11/20 06:49:52午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 34/49] Final Prec@1 75.0560%
11/20 06:50:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.7890	Prec@(1,5) (53.7%, 83.0%)
11/20 06:50:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.7792	Prec@(1,5) (53.5%, 83.1%)
11/20 06:50:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.7544	Prec@(1,5) (54.0%, 83.5%)
11/20 06:50:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.7513	Prec@(1,5) (54.2%, 83.4%)
11/20 06:50:23午後 searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 54.1680%
11/20 06:50:23午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:50:24午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 54.4480%
11/20 06:51:13午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 0.7480 (0.8043)	Arch Loss -8104.3428 (-8075.2305)	Arch Hard Loss 1.7615 (1.7751)	Arch Beta Loss 810.6105 (807.7006)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.7%)	
11/20 06:52:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.0031 (0.8061)	Arch Loss -8163.5151 (-8104.6224)	Arch Hard Loss 1.3819 (1.7778)	Arch Beta Loss 816.4897 (810.6400)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.7%)	
11/20 06:52:49午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 0.8930 (0.8142)	Arch Loss -8221.7900 (-8134.0311)	Arch Hard Loss 1.8934 (1.7638)	Arch Beta Loss 822.3684 (813.5795)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.7%)	
11/20 06:53:32午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.0775 (0.8156)	Arch Loss -8274.9424 (-8160.4735)	Arch Hard Loss 1.6520 (1.7766)	Arch Beta Loss 827.6595 (816.2250)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.7%)	
11/20 06:53:33午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 35/49] Final Prec@1 75.7120%
11/20 06:53:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7145	Prec@(1,5) (55.5%, 83.5%)
11/20 06:53:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7226	Prec@(1,5) (55.3%, 83.4%)
11/20 06:53:57午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7265	Prec@(1,5) (55.3%, 83.5%)
11/20 06:54:04午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7305	Prec@(1,5) (55.2%, 83.6%)
11/20 06:54:04午後 searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 55.1920%
11/20 06:54:04午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:54:04午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.1920%
11/20 06:54:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.6875 (0.7185)	Arch Loss -8333.7793 (-8305.0979)	Arch Hard Loss 2.1939 (1.7735)	Arch Beta Loss 833.5974 (830.6871)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.8%)	
11/20 06:55:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 0.6612 (0.7485)	Arch Loss -8393.2256 (-8334.5032)	Arch Hard Loss 1.5333 (1.7629)	Arch Beta Loss 839.4759 (833.6266)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.4%)	
11/20 06:56:30午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.6899 (0.7595)	Arch Loss -8451.9229 (-8363.8986)	Arch Hard Loss 1.6295 (1.7621)	Arch Beta Loss 845.3552 (836.5661)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.3%)	
11/20 06:57:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 0.5935 (0.7656)	Arch Loss -8504.9004 (-8390.3531)	Arch Hard Loss 1.5592 (1.7628)	Arch Beta Loss 850.6460 (839.2116)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
11/20 06:57:14午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 36/49] Final Prec@1 77.4000%
11/20 06:57:22午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7414	Prec@(1,5) (55.4%, 83.3%)
11/20 06:57:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7266	Prec@(1,5) (55.3%, 83.8%)
11/20 06:57:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7345	Prec@(1,5) (55.1%, 83.5%)
11/20 06:57:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7358	Prec@(1,5) (55.1%, 83.4%)
11/20 06:57:45午後 searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 55.1080%
11/20 06:57:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[3, 7], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 06:57:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.1920%
11/20 06:58:35午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 0.6973 (0.7009)	Arch Loss -8563.8594 (-8534.9609)	Arch Hard Loss 1.9776 (1.7764)	Arch Beta Loss 856.5837 (853.6737)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.0%, 96.9%)	
11/20 06:59:23午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 0.7878 (0.7068)	Arch Loss -8622.3506 (-8564.3732)	Arch Hard Loss 2.2759 (1.7587)	Arch Beta Loss 862.4626 (856.6132)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.8%)	
11/20 07:00:13午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 0.5826 (0.7141)	Arch Loss -8682.0879 (-8593.7583)	Arch Hard Loss 1.3297 (1.7683)	Arch Beta Loss 868.3418 (859.5527)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
11/20 07:00:58午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 0.5101 (0.7214)	Arch Loss -8734.7959 (-8620.2168)	Arch Hard Loss 1.5304 (1.7651)	Arch Beta Loss 873.6326 (862.1982)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
11/20 07:00:58午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 37/49] Final Prec@1 78.6160%
11/20 07:01:07午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7460	Prec@(1,5) (54.8%, 83.7%)
11/20 07:01:14午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7237	Prec@(1,5) (55.4%, 83.7%)
11/20 07:01:22午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7107	Prec@(1,5) (55.9%, 84.0%)
11/20 07:01:29午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7183	Prec@(1,5) (55.7%, 83.9%)
11/20 07:01:29午後 searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 55.6840%
11/20 07:01:29午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[4, 9])
11/20 07:01:30午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6840%
11/20 07:02:19午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.5480 (0.6634)	Arch Loss -8794.1338 (-8764.8762)	Arch Hard Loss 1.5703 (1.7277)	Arch Beta Loss 879.5704 (876.6604)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.0%)	
11/20 07:03:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 0.5278 (0.6677)	Arch Loss -8852.6152 (-8794.2787)	Arch Hard Loss 1.8804 (1.7200)	Arch Beta Loss 885.4496 (879.5999)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
11/20 07:03:59午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.8799 (0.6791)	Arch Loss -8911.6494 (-8823.6546)	Arch Hard Loss 1.6326 (1.7387)	Arch Beta Loss 891.3282 (882.5393)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/20 07:04:42午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.5532 (0.6845)	Arch Loss -8964.2578 (-8850.0842)	Arch Hard Loss 1.9373 (1.7642)	Arch Beta Loss 896.6196 (885.1848)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (79.6%, 97.0%)	
11/20 07:04:42午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 38/49] Final Prec@1 79.6480%
11/20 07:04:51午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7334	Prec@(1,5) (55.9%, 83.2%)
11/20 07:04:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7209	Prec@(1,5) (55.7%, 83.7%)
11/20 07:05:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7199	Prec@(1,5) (55.7%, 83.8%)
11/20 07:05:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7163	Prec@(1,5) (55.6%, 84.0%)
11/20 07:05:13午後 searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 55.5600%
11/20 07:05:14午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:05:14午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6840%
11/20 07:06:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.5909 (0.6186)	Arch Loss -9024.0303 (-8994.7079)	Arch Hard Loss 1.5402 (1.7621)	Arch Beta Loss 902.5571 (899.6470)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.7%)	
11/20 07:06:50午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.5364 (0.6295)	Arch Loss -9082.7354 (-9024.1129)	Arch Hard Loss 1.6234 (1.7520)	Arch Beta Loss 908.4359 (902.5865)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.7%, 97.5%)	
11/20 07:07:39午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.5953 (0.6433)	Arch Loss -9141.2480 (-9053.4913)	Arch Hard Loss 1.9008 (1.7683)	Arch Beta Loss 914.3148 (905.5260)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.2%)	
11/20 07:08:22午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.7358 (0.6497)	Arch Loss -9194.4912 (-9079.9462)	Arch Hard Loss 1.5690 (1.7686)	Arch Beta Loss 919.6061 (908.1715)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.2%)	
11/20 07:08:22午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 39/49] Final Prec@1 80.9080%
11/20 07:08:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.7387	Prec@(1,5) (55.4%, 83.7%)
11/20 07:08:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.7417	Prec@(1,5) (55.2%, 83.8%)
11/20 07:08:46午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7471	Prec@(1,5) (55.2%, 83.6%)
11/20 07:08:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.7459	Prec@(1,5) (55.3%, 83.7%)
11/20 07:08:53午後 searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 55.3480%
11/20 07:08:53午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:08:53午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6840%
11/20 07:09:43午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.6328 (0.5945)	Arch Loss -9253.2656 (-9224.5518)	Arch Hard Loss 2.1708 (1.7849)	Arch Beta Loss 925.5436 (922.6337)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.7%)	
11/20 07:10:31午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.5411 (0.6005)	Arch Loss -9312.1289 (-9253.9458)	Arch Hard Loss 2.0995 (1.7858)	Arch Beta Loss 931.4229 (925.5732)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.7%)	
11/20 07:11:19午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 0.4608 (0.6142)	Arch Loss -9371.2334 (-9283.3513)	Arch Hard Loss 1.7848 (1.7751)	Arch Beta Loss 937.3018 (928.5126)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.4%, 97.6%)	
11/20 07:12:03午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.8248 (0.6204)	Arch Loss -9424.3496 (-9309.8144)	Arch Hard Loss 1.5775 (1.7674)	Arch Beta Loss 942.5927 (931.1582)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.5%)	
11/20 07:12:03午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 40/49] Final Prec@1 82.0760%
11/20 07:12:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7122	Prec@(1,5) (55.9%, 84.2%)
11/20 07:12:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7117	Prec@(1,5) (56.1%, 84.1%)
11/20 07:12:27午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7214	Prec@(1,5) (55.8%, 84.0%)
11/20 07:12:34午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7302	Prec@(1,5) (55.6%, 83.9%)
11/20 07:12:34午後 searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 55.6280%
11/20 07:12:34午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:12:34午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.6840%
11/20 07:13:24午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.4990 (0.5818)	Arch Loss -9483.5039 (-9454.4124)	Arch Hard Loss 1.8028 (1.7913)	Arch Beta Loss 948.5306 (945.6204)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.4%, 98.0%)	
11/20 07:14:15午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.4932 (0.5904)	Arch Loss -9542.2471 (-9483.8103)	Arch Hard Loss 1.8453 (1.7883)	Arch Beta Loss 954.4092 (948.5599)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.9%)	
11/20 07:15:10午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.5438 (0.5883)	Arch Loss -9601.2783 (-9513.2102)	Arch Hard Loss 1.6048 (1.7831)	Arch Beta Loss 960.2883 (951.4993)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.8%)	
11/20 07:15:57午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.8012 (0.5920)	Arch Loss -9654.1514 (-9539.6695)	Arch Hard Loss 1.6442 (1.7792)	Arch Beta Loss 965.5796 (954.1449)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
11/20 07:15:58午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 41/49] Final Prec@1 82.7760%
11/20 07:16:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.7449	Prec@(1,5) (56.4%, 83.6%)
11/20 07:16:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.7373	Prec@(1,5) (55.8%, 83.7%)
11/20 07:16:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.7263	Prec@(1,5) (55.9%, 84.0%)
11/20 07:16:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.7257	Prec@(1,5) (56.0%, 84.0%)
11/20 07:16:30午後 searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 55.9560%
11/20 07:16:30午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:16:31午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 55.9560%
11/20 07:17:22午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.5253 (0.5502)	Arch Loss -9713.4941 (-9684.2981)	Arch Hard Loss 1.6779 (1.7722)	Arch Beta Loss 971.5172 (968.6070)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.3%)	
11/20 07:18:13午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.5685 (0.5538)	Arch Loss -9772.1123 (-9713.7131)	Arch Hard Loss 1.8488 (1.7522)	Arch Beta Loss 977.3961 (971.5465)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/20 07:19:04午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 0.5540 (0.5614)	Arch Loss -9830.6387 (-9743.0991)	Arch Hard Loss 2.1122 (1.7609)	Arch Beta Loss 983.2751 (974.4860)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.1%)	
11/20 07:19:50午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.6208 (0.5624)	Arch Loss -9883.9150 (-9769.5553)	Arch Hard Loss 1.7448 (1.7601)	Arch Beta Loss 988.5660 (977.1315)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.1%)	
11/20 07:19:50午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 42/49] Final Prec@1 83.7800%
11/20 07:19:59午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.6981	Prec@(1,5) (56.2%, 84.9%)
11/20 07:20:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7204	Prec@(1,5) (55.4%, 84.3%)
11/20 07:20:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7191	Prec@(1,5) (56.0%, 84.2%)
11/20 07:20:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7182	Prec@(1,5) (56.1%, 84.2%)
11/20 07:20:24午後 searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 56.0960%
11/20 07:20:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:20:24午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0960%
11/20 07:21:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.5720 (0.5282)	Arch Loss -9943.1592 (-9914.2035)	Arch Hard Loss 1.8786 (1.7337)	Arch Beta Loss 994.5038 (991.5937)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.3%)	
11/20 07:22:06午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.5739 (0.5410)	Arch Loss -10001.9980 (-9943.5810)	Arch Hard Loss 1.8291 (1.7512)	Arch Beta Loss 1000.3827 (994.5332)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.2%)	
11/20 07:22:57午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6938 (0.5403)	Arch Loss -10060.5723 (-9972.9715)	Arch Hard Loss 2.0463 (1.7554)	Arch Beta Loss 1006.2618 (997.4727)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.2%)	
11/20 07:23:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.5204 (0.5394)	Arch Loss -10113.9961 (-9999.4241)	Arch Hard Loss 1.5333 (1.7582)	Arch Beta Loss 1011.5529 (1000.1182)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.2%)	
11/20 07:23:44午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 43/49] Final Prec@1 84.3880%
11/20 07:23:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.6956	Prec@(1,5) (56.0%, 84.5%)
11/20 07:24:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7060	Prec@(1,5) (56.1%, 84.1%)
11/20 07:24:10午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7126	Prec@(1,5) (55.9%, 84.2%)
11/20 07:24:18午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7241	Prec@(1,5) (55.9%, 84.1%)
11/20 07:24:18午後 searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 55.8880%
11/20 07:24:18午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:24:18午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.0960%
11/20 07:25:10午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.5217 (0.5048)	Arch Loss -10172.9482 (-10144.0378)	Arch Hard Loss 1.9567 (1.7668)	Arch Beta Loss 1017.4905 (1014.5805)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.6%)	
11/20 07:26:02午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6586 (0.5128)	Arch Loss -10231.4219 (-10173.4313)	Arch Hard Loss 2.2739 (1.7681)	Arch Beta Loss 1023.3696 (1017.5199)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
11/20 07:26:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.5696 (0.5202)	Arch Loss -10290.5225 (-10202.8243)	Arch Hard Loss 1.9615 (1.7700)	Arch Beta Loss 1029.2484 (1020.4594)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.4%)	
11/20 07:27:36午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.3552 (0.5234)	Arch Loss -10343.7139 (-10229.2887)	Arch Hard Loss 1.6783 (1.7609)	Arch Beta Loss 1034.5393 (1023.1050)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
11/20 07:27:36午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 44/49] Final Prec@1 85.0600%
11/20 07:27:44午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6865	Prec@(1,5) (55.9%, 84.3%)
11/20 07:27:52午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7060	Prec@(1,5) (55.8%, 84.2%)
11/20 07:28:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7030	Prec@(1,5) (56.1%, 84.2%)
11/20 07:28:07午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7045	Prec@(1,5) (56.2%, 84.3%)
11/20 07:28:07午後 searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 56.2600%
11/20 07:28:07午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:28:07午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.2600%
11/20 07:28:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.3629 (0.5045)	Arch Loss -10403.3984 (-10373.9222)	Arch Hard Loss 1.3727 (1.7495)	Arch Beta Loss 1040.4772 (1037.5672)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.6%)	
11/20 07:29:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.4995 (0.5014)	Arch Loss -10461.3223 (-10403.3057)	Arch Hard Loss 2.2386 (1.7609)	Arch Beta Loss 1046.3561 (1040.5067)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
11/20 07:30:32午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.5901 (0.5045)	Arch Loss -10520.2119 (-10432.7030)	Arch Hard Loss 2.1409 (1.7583)	Arch Beta Loss 1052.2352 (1043.4461)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
11/20 07:31:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.5300 (0.5082)	Arch Loss -10573.7197 (-10459.1575)	Arch Hard Loss 1.5440 (1.7592)	Arch Beta Loss 1057.5264 (1046.0917)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.5%)	
11/20 07:31:15午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 45/49] Final Prec@1 85.8760%
11/20 07:31:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6682	Prec@(1,5) (57.1%, 84.7%)
11/20 07:31:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7146	Prec@(1,5) (56.5%, 84.0%)
11/20 07:31:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7172	Prec@(1,5) (56.4%, 83.9%)
11/20 07:31:46午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7108	Prec@(1,5) (56.7%, 84.1%)
11/20 07:31:46午後 searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 56.6920%
11/20 07:31:46午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:31:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/20 07:32:34午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.5600 (0.4614)	Arch Loss -10632.9434 (-10603.7678)	Arch Hard Loss 1.6996 (1.7711)	Arch Beta Loss 1063.4642 (1060.5539)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.7%)	
11/20 07:33:22午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.3360 (0.4799)	Arch Loss -10691.8203 (-10633.1818)	Arch Hard Loss 1.6070 (1.7519)	Arch Beta Loss 1069.3428 (1063.4934)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.6%)	
11/20 07:34:11午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.3784 (0.4850)	Arch Loss -10750.4756 (-10662.5721)	Arch Hard Loss 1.7451 (1.7565)	Arch Beta Loss 1075.2220 (1066.4329)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.6%)	
11/20 07:34:54午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.4084 (0.4910)	Arch Loss -10803.2285 (-10689.0271)	Arch Hard Loss 1.9000 (1.7569)	Arch Beta Loss 1080.5129 (1069.0784)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.6%)	
11/20 07:34:55午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 46/49] Final Prec@1 86.4400%
11/20 07:35:03午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7295	Prec@(1,5) (56.5%, 83.8%)
11/20 07:35:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7077	Prec@(1,5) (56.7%, 84.0%)
11/20 07:35:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7115	Prec@(1,5) (56.5%, 84.1%)
11/20 07:35:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7093	Prec@(1,5) (56.4%, 84.2%)
11/20 07:35:26午後 searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 56.4240%
11/20 07:35:26午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:35:26午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/20 07:36:16午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.4856 (0.4636)	Arch Loss -10863.1436 (-10833.6843)	Arch Hard Loss 1.3631 (1.7224)	Arch Beta Loss 1086.4507 (1083.5407)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.7%)	
11/20 07:37:05午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.4743 (0.4647)	Arch Loss -10921.7979 (-10863.0437)	Arch Hard Loss 1.4978 (1.7577)	Arch Beta Loss 1092.3296 (1086.4801)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.7%)	
11/20 07:37:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.3873 (0.4757)	Arch Loss -10980.6377 (-10892.4400)	Arch Hard Loss 1.4481 (1.7562)	Arch Beta Loss 1098.2086 (1089.4196)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.6%)	
11/20 07:38:36午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.5226 (0.4818)	Arch Loss -11032.9258 (-10918.8971)	Arch Hard Loss 2.0702 (1.7545)	Arch Beta Loss 1103.4996 (1092.0652)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.6%)	
11/20 07:38:37午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 47/49] Final Prec@1 86.8960%
11/20 07:38:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7118	Prec@(1,5) (56.2%, 84.0%)
11/20 07:38:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.6989	Prec@(1,5) (56.7%, 84.0%)
11/20 07:39:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.6966	Prec@(1,5) (56.7%, 84.4%)
11/20 07:39:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7006	Prec@(1,5) (56.6%, 84.4%)
11/20 07:39:08午後 searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 56.5680%
11/20 07:39:08午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:39:08午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/20 07:39:56午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.4920 (0.4590)	Arch Loss -11092.8340 (-11063.5446)	Arch Hard Loss 1.5406 (1.7297)	Arch Beta Loss 1109.4375 (1106.5274)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.8%)	
11/20 07:40:44午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.4496 (0.4662)	Arch Loss -11150.9561 (-11092.9242)	Arch Hard Loss 2.2063 (1.7451)	Arch Beta Loss 1115.3162 (1109.4669)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.6%, 98.8%)	
11/20 07:41:31午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.7146 (0.4727)	Arch Loss -11210.1064 (-11122.3202)	Arch Hard Loss 1.8484 (1.7439)	Arch Beta Loss 1121.1956 (1112.4064)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.8%)	
11/20 07:42:14午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.4641 (0.4772)	Arch Loss -11263.0547 (-11148.7683)	Arch Hard Loss 1.8134 (1.7512)	Arch Beta Loss 1126.4868 (1115.0519)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
11/20 07:42:14午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 48/49] Final Prec@1 87.0080%
11/20 07:42:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7070	Prec@(1,5) (56.2%, 84.5%)
11/20 07:42:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.6976	Prec@(1,5) (56.5%, 84.5%)
11/20 07:42:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.6928	Prec@(1,5) (56.4%, 84.6%)
11/20 07:42:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7016	Prec@(1,5) (56.2%, 84.4%)
11/20 07:42:45午後 searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 56.1440%
11/20 07:42:45午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:42:46午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/20 07:43:34午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.4444 (0.4746)	Arch Loss -11322.3545 (-11293.3700)	Arch Hard Loss 1.8856 (1.7714)	Arch Beta Loss 1132.4241 (1129.5141)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.9%)	
11/20 07:44:21午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.3513 (0.4660)	Arch Loss -11381.0391 (-11322.7659)	Arch Hard Loss 1.9936 (1.7704)	Arch Beta Loss 1138.3032 (1132.4536)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.9%)	
11/20 07:45:09午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.3986 (0.4713)	Arch Loss -11440.0420 (-11352.1660)	Arch Hard Loss 1.7798 (1.7650)	Arch Beta Loss 1144.1823 (1135.3931)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
11/20 07:45:53午後 searchStage_BetaConcat_trainer.py:131 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.6123 (0.4811)	Arch Loss -11493.2148 (-11378.6208)	Arch Hard Loss 1.5171 (1.7655)	Arch Beta Loss 1149.4733 (1138.0386)	Arch depth Loss -0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.7%)	
11/20 07:45:53午後 searchStage_BetaConcat_trainer.py:145 [INFO] Train: [ 49/49] Final Prec@1 86.6120%
11/20 07:46:02午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6751	Prec@(1,5) (56.4%, 84.7%)
11/20 07:46:09午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.6981	Prec@(1,5) (56.3%, 84.6%)
11/20 07:46:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7086	Prec@(1,5) (56.0%, 84.4%)
11/20 07:46:24午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.6945	Prec@(1,5) (56.3%, 84.5%)
11/20 07:46:24午後 searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 56.3040%
11/20 07:46:24午後 trainer_runner.py:74 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
11/20 07:46:25午後 trainer_runner.py:105 [INFO] Until now, best Prec@1 = 56.6920%
11/20 07:46:25午後 trainer_runner.py:110 [INFO] Final best Prec@1 = 56.6920%
11/20 07:46:25午後 trainer_runner.py:111 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[2, 3], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 10), ('skip_connect', 8)]], DAG2_concat=[2, 7], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[2, 4])
