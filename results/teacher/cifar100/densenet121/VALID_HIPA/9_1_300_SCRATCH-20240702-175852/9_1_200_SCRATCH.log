07/02 05:58:52PM parser.py:28 [INFO] 
07/02 05:58:52PM parser.py:29 [INFO] Parameters:
07/02 05:58:52PM parser.py:31 [INFO] BATCH_SIZE=64
07/02 05:58:52PM parser.py:31 [INFO] CUTOUT_LENGTH=0
07/02 05:58:52PM parser.py:31 [INFO] DATA_PATH=../data/
07/02 05:58:52PM parser.py:31 [INFO] DATASET=cifar100
07/02 05:58:52PM parser.py:31 [INFO] EPOCHS=300
07/02 05:58:52PM parser.py:31 [INFO] EXP_NAME=TEST-20240702-175852
07/02 05:58:52PM parser.py:31 [INFO] GPUS=[0]
07/02 05:58:52PM parser.py:31 [INFO] LOCAL_RANK=0
07/02 05:58:52PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
07/02 05:58:52PM parser.py:31 [INFO] MODEL_NAME=densenet121
07/02 05:58:52PM parser.py:31 [INFO] NAME=9_1_200_SCRATCH
07/02 05:58:52PM parser.py:31 [INFO] PATH=results/teacher/cifar100/densenet121/9_1_200_SCRATCH/TEST-20240702-175852
07/02 05:58:52PM parser.py:31 [INFO] PLOT_PATH=results/teacher/cifar100/densenet121/9_1_200_SCRATCH/TEST-20240702-175852/plots
07/02 05:58:52PM parser.py:31 [INFO] PRINT_FREQ=50
07/02 05:58:52PM parser.py:31 [INFO] RESUME_PATH=None
07/02 05:58:52PM parser.py:31 [INFO] SAVE=TEST
07/02 05:58:52PM parser.py:31 [INFO] SEED=0
07/02 05:58:52PM parser.py:31 [INFO] TRAIN_PORTION=0.9
07/02 05:58:52PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
07/02 05:58:52PM parser.py:31 [INFO] W_LR=0.1
07/02 05:58:52PM parser.py:31 [INFO] W_LR_MIN=0.001
07/02 05:58:52PM parser.py:31 [INFO] W_MOMENTUM=0.9
07/02 05:58:52PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
07/02 05:58:52PM parser.py:31 [INFO] WORKERS=4
07/02 05:58:52PM parser.py:32 [INFO] 
07/02 05:58:59PM finetuneTeacher_trainer.py:108 [INFO] --> No loaded checkpoint!
07/02 05:59:07PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][50/703]	Step 50	lr 0.1	Loss 5.5486 (6.1237)	Prec@(1,5) (1.7%, 7.1%)	
07/02 05:59:10PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][100/703]	Step 100	lr 0.1	Loss 4.6213 (5.5672)	Prec@(1,5) (2.0%, 9.3%)	
07/02 05:59:13PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][150/703]	Step 150	lr 0.1	Loss 4.5136 (5.2233)	Prec@(1,5) (2.5%, 11.2%)	
07/02 05:59:16PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][200/703]	Step 200	lr 0.1	Loss 4.1653 (5.0036)	Prec@(1,5) (2.8%, 12.7%)	
07/02 05:59:19PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][250/703]	Step 250	lr 0.1	Loss 4.3182 (4.8484)	Prec@(1,5) (3.4%, 14.1%)	
07/02 05:59:22PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][300/703]	Step 300	lr 0.1	Loss 4.0660 (4.7324)	Prec@(1,5) (3.8%, 15.3%)	
07/02 05:59:25PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][350/703]	Step 350	lr 0.1	Loss 3.9135 (4.6475)	Prec@(1,5) (4.0%, 16.0%)	
07/02 05:59:28PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][400/703]	Step 400	lr 0.1	Loss 4.1841 (4.5746)	Prec@(1,5) (4.3%, 16.9%)	
07/02 05:59:31PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][450/703]	Step 450	lr 0.1	Loss 3.9914 (4.5138)	Prec@(1,5) (4.6%, 17.9%)	
07/02 05:59:34PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][500/703]	Step 500	lr 0.1	Loss 3.7287 (4.4609)	Prec@(1,5) (4.9%, 18.8%)	
07/02 05:59:37PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][550/703]	Step 550	lr 0.1	Loss 3.8944 (4.4187)	Prec@(1,5) (5.2%, 19.5%)	
07/02 05:59:40PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][600/703]	Step 600	lr 0.1	Loss 3.8284 (4.3811)	Prec@(1,5) (5.4%, 20.1%)	
07/02 05:59:43PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][650/703]	Step 650	lr 0.1	Loss 3.7324 (4.3470)	Prec@(1,5) (5.6%, 20.7%)	
07/02 05:59:46PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][700/703]	Step 700	lr 0.1	Loss 3.9095 (4.3168)	Prec@(1,5) (5.8%, 21.3%)	
07/02 05:59:46PM finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [0][703/703]	Step 703	lr 0.1	Loss 4.0653 (4.3150)	Prec@(1,5) (5.8%, 21.4%)	
07/02 05:59:53PM finetuneTeacher_trainer.py:180 [INFO] Train: [  0/299] Final Prec@1 5.8133%
07/02 05:59:55PM finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [0][50/79]	Step 704	Loss 3.9478	Prec@(1,5) (8.4%, 28.1%)
07/02 05:59:55PM finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [0][78/79]	Step 704	Loss 3.9382	Prec@(1,5) (8.5%, 28.4%)
07/02 05:59:55PM finetuneTeacher_trainer.py:215 [INFO] Valid: [  0/299] Final Prec@1 8.5200%
07/02 05:59:56午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 8.5200%
07/02 05:59:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][50/703]	Step 754	lr 0.1	Loss 3.9190 (3.9114)	Prec@(1,5) (8.9%, 28.7%)	
07/02 06:00:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][100/703]	Step 804	lr 0.1	Loss 3.8857 (3.8986)	Prec@(1,5) (8.5%, 28.9%)	
07/02 06:00:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][150/703]	Step 854	lr 0.1	Loss 3.8042 (3.8823)	Prec@(1,5) (8.8%, 29.5%)	
07/02 06:00:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][200/703]	Step 904	lr 0.1	Loss 3.6873 (3.8777)	Prec@(1,5) (9.1%, 29.9%)	
07/02 06:00:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][250/703]	Step 954	lr 0.1	Loss 3.9090 (3.8716)	Prec@(1,5) (9.1%, 30.1%)	
07/02 06:00:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][300/703]	Step 1004	lr 0.1	Loss 3.9507 (3.8600)	Prec@(1,5) (9.2%, 30.6%)	
07/02 06:00:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][350/703]	Step 1054	lr 0.1	Loss 3.6081 (3.8470)	Prec@(1,5) (9.4%, 30.8%)	
07/02 06:00:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][400/703]	Step 1104	lr 0.1	Loss 3.7836 (3.8421)	Prec@(1,5) (9.5%, 31.0%)	
07/02 06:00:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][450/703]	Step 1154	lr 0.1	Loss 3.5356 (3.8306)	Prec@(1,5) (9.7%, 31.4%)	
07/02 06:00:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][500/703]	Step 1204	lr 0.1	Loss 3.6930 (3.8210)	Prec@(1,5) (10.0%, 31.8%)	
07/02 06:00:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][550/703]	Step 1254	lr 0.1	Loss 3.4816 (3.8125)	Prec@(1,5) (10.2%, 32.0%)	
07/02 06:00:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][600/703]	Step 1304	lr 0.1	Loss 3.6641 (3.8034)	Prec@(1,5) (10.5%, 32.4%)	
07/02 06:00:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][650/703]	Step 1354	lr 0.1	Loss 3.8916 (3.7918)	Prec@(1,5) (10.6%, 32.7%)	
07/02 06:00:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][700/703]	Step 1404	lr 0.1	Loss 3.7288 (3.7828)	Prec@(1,5) (10.8%, 33.0%)	
07/02 06:00:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [1][703/703]	Step 1407	lr 0.1	Loss 3.7917 (3.7830)	Prec@(1,5) (10.8%, 33.0%)	
07/02 06:00:40午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  1/299] Final Prec@1 10.8400%
07/02 06:00:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [1][50/79]	Step 1408	Loss 3.6582	Prec@(1,5) (13.4%, 36.2%)
07/02 06:00:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [1][78/79]	Step 1408	Loss 3.6687	Prec@(1,5) (13.0%, 36.4%)
07/02 06:00:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  1/299] Final Prec@1 13.0000%
07/02 06:00:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 13.0000%
07/02 06:00:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][50/703]	Step 1458	lr 0.09999	Loss 3.3982 (3.7287)	Prec@(1,5) (12.2%, 35.5%)	
07/02 06:00:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][100/703]	Step 1508	lr 0.09999	Loss 3.5594 (3.6630)	Prec@(1,5) (13.0%, 37.0%)	
07/02 06:00:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][150/703]	Step 1558	lr 0.09999	Loss 3.5113 (3.6173)	Prec@(1,5) (13.5%, 38.2%)	
07/02 06:00:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][200/703]	Step 1608	lr 0.09999	Loss 3.6600 (3.5941)	Prec@(1,5) (13.8%, 39.0%)	
07/02 06:00:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][250/703]	Step 1658	lr 0.09999	Loss 3.4011 (3.5753)	Prec@(1,5) (14.2%, 39.5%)	
07/02 06:01:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][300/703]	Step 1708	lr 0.09999	Loss 3.2922 (3.5572)	Prec@(1,5) (14.4%, 40.0%)	
07/02 06:01:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][350/703]	Step 1758	lr 0.09999	Loss 3.2519 (3.5441)	Prec@(1,5) (14.5%, 40.5%)	
07/02 06:01:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][400/703]	Step 1808	lr 0.09999	Loss 3.2671 (3.5330)	Prec@(1,5) (14.7%, 40.8%)	
07/02 06:01:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][450/703]	Step 1858	lr 0.09999	Loss 3.3330 (3.5206)	Prec@(1,5) (14.9%, 41.2%)	
07/02 06:01:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][500/703]	Step 1908	lr 0.09999	Loss 3.3399 (3.5052)	Prec@(1,5) (15.2%, 41.6%)	
07/02 06:01:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][550/703]	Step 1958	lr 0.09999	Loss 3.2340 (3.4943)	Prec@(1,5) (15.4%, 41.9%)	
07/02 06:01:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][600/703]	Step 2008	lr 0.09999	Loss 3.3707 (3.4830)	Prec@(1,5) (15.7%, 42.2%)	
07/02 06:01:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][650/703]	Step 2058	lr 0.09999	Loss 3.2320 (3.4730)	Prec@(1,5) (15.8%, 42.5%)	
07/02 06:01:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][700/703]	Step 2108	lr 0.09999	Loss 3.3924 (3.4620)	Prec@(1,5) (16.0%, 42.8%)	
07/02 06:01:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [2][703/703]	Step 2111	lr 0.09999	Loss 3.2793 (3.4612)	Prec@(1,5) (16.0%, 42.8%)	
07/02 06:01:26午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  2/299] Final Prec@1 16.0356%
07/02 06:01:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [2][50/79]	Step 2112	Loss 3.3390	Prec@(1,5) (18.5%, 45.6%)
07/02 06:01:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [2][78/79]	Step 2112	Loss 3.3371	Prec@(1,5) (18.4%, 45.6%)
07/02 06:01:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  2/299] Final Prec@1 18.4000%
07/02 06:01:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 18.4000%
07/02 06:01:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][50/703]	Step 2162	lr 0.09998	Loss 3.3284 (3.2968)	Prec@(1,5) (18.5%, 48.1%)	
07/02 06:01:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][100/703]	Step 2212	lr 0.09998	Loss 3.1820 (3.2851)	Prec@(1,5) (19.3%, 48.0%)	
07/02 06:01:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][150/703]	Step 2262	lr 0.09998	Loss 3.3440 (3.2711)	Prec@(1,5) (19.1%, 48.1%)	
07/02 06:01:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][200/703]	Step 2312	lr 0.09998	Loss 3.6840 (3.2682)	Prec@(1,5) (19.1%, 48.4%)	
07/02 06:01:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][250/703]	Step 2362	lr 0.09998	Loss 3.3885 (3.2504)	Prec@(1,5) (19.4%, 49.0%)	
07/02 06:01:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][300/703]	Step 2412	lr 0.09998	Loss 3.0361 (3.2319)	Prec@(1,5) (19.9%, 49.4%)	
07/02 06:01:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][350/703]	Step 2462	lr 0.09998	Loss 3.3655 (3.2255)	Prec@(1,5) (20.0%, 49.7%)	
07/02 06:01:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][400/703]	Step 2512	lr 0.09998	Loss 3.1469 (3.2193)	Prec@(1,5) (20.1%, 49.8%)	
07/02 06:01:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][450/703]	Step 2562	lr 0.09998	Loss 3.1586 (3.2150)	Prec@(1,5) (20.2%, 50.0%)	
07/02 06:01:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][500/703]	Step 2612	lr 0.09998	Loss 2.9902 (3.2045)	Prec@(1,5) (20.5%, 50.2%)	
07/02 06:02:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][550/703]	Step 2662	lr 0.09998	Loss 3.5661 (3.1922)	Prec@(1,5) (20.9%, 50.4%)	
07/02 06:02:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][600/703]	Step 2712	lr 0.09998	Loss 3.0889 (3.1818)	Prec@(1,5) (21.1%, 50.6%)	
07/02 06:02:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][650/703]	Step 2762	lr 0.09998	Loss 3.0387 (3.1728)	Prec@(1,5) (21.3%, 50.9%)	
07/02 06:02:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][700/703]	Step 2812	lr 0.09998	Loss 3.0924 (3.1657)	Prec@(1,5) (21.4%, 51.0%)	
07/02 06:02:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [3][703/703]	Step 2815	lr 0.09998	Loss 2.9330 (3.1645)	Prec@(1,5) (21.4%, 51.1%)	
07/02 06:02:12午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  3/299] Final Prec@1 21.3889%
07/02 06:02:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [3][50/79]	Step 2816	Loss 3.1220	Prec@(1,5) (22.6%, 51.5%)
07/02 06:02:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [3][78/79]	Step 2816	Loss 3.1256	Prec@(1,5) (22.5%, 52.0%)
07/02 06:02:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  3/299] Final Prec@1 22.4600%
07/02 06:02:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 22.4600%
07/02 06:02:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][50/703]	Step 2866	lr 0.09996	Loss 2.5415 (2.9793)	Prec@(1,5) (25.0%, 56.7%)	
07/02 06:02:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][100/703]	Step 2916	lr 0.09996	Loss 3.0535 (2.9684)	Prec@(1,5) (24.7%, 56.7%)	
07/02 06:02:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][150/703]	Step 2966	lr 0.09996	Loss 3.1325 (2.9831)	Prec@(1,5) (24.6%, 56.0%)	
07/02 06:02:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][200/703]	Step 3016	lr 0.09996	Loss 2.6839 (2.9784)	Prec@(1,5) (24.7%, 55.9%)	
07/02 06:02:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][250/703]	Step 3066	lr 0.09996	Loss 3.0208 (2.9717)	Prec@(1,5) (24.8%, 56.1%)	
07/02 06:02:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][300/703]	Step 3116	lr 0.09996	Loss 2.9902 (2.9729)	Prec@(1,5) (24.9%, 56.1%)	
07/02 06:02:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][350/703]	Step 3166	lr 0.09996	Loss 2.9481 (2.9634)	Prec@(1,5) (25.0%, 56.3%)	
07/02 06:02:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][400/703]	Step 3216	lr 0.09996	Loss 3.0691 (2.9579)	Prec@(1,5) (25.2%, 56.5%)	
07/02 06:02:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][450/703]	Step 3266	lr 0.09996	Loss 2.7088 (2.9525)	Prec@(1,5) (25.3%, 56.6%)	
07/02 06:02:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][500/703]	Step 3316	lr 0.09996	Loss 2.7875 (2.9496)	Prec@(1,5) (25.5%, 56.7%)	
07/02 06:02:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][550/703]	Step 3366	lr 0.09996	Loss 2.9985 (2.9463)	Prec@(1,5) (25.6%, 56.8%)	
07/02 06:02:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][600/703]	Step 3416	lr 0.09996	Loss 2.6802 (2.9409)	Prec@(1,5) (25.7%, 56.9%)	
07/02 06:02:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][650/703]	Step 3466	lr 0.09996	Loss 2.8911 (2.9380)	Prec@(1,5) (25.7%, 57.0%)	
07/02 06:02:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][700/703]	Step 3516	lr 0.09996	Loss 3.0296 (2.9345)	Prec@(1,5) (25.9%, 57.1%)	
07/02 06:02:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [4][703/703]	Step 3519	lr 0.09996	Loss 3.1393 (2.9346)	Prec@(1,5) (25.9%, 57.1%)	
07/02 06:02:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  4/299] Final Prec@1 25.8644%
07/02 06:03:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [4][50/79]	Step 3520	Loss 2.9686	Prec@(1,5) (26.6%, 57.1%)
07/02 06:03:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [4][78/79]	Step 3520	Loss 2.9775	Prec@(1,5) (26.1%, 56.8%)
07/02 06:03:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  4/299] Final Prec@1 26.1200%
07/02 06:03:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 26.1200%
07/02 06:03:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][50/703]	Step 3570	lr 0.09993	Loss 2.8706 (2.7971)	Prec@(1,5) (29.3%, 59.7%)	
07/02 06:03:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][100/703]	Step 3620	lr 0.09993	Loss 3.2570 (2.8149)	Prec@(1,5) (28.6%, 59.6%)	
07/02 06:03:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][150/703]	Step 3670	lr 0.09993	Loss 2.7119 (2.8095)	Prec@(1,5) (28.9%, 59.9%)	
07/02 06:03:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][200/703]	Step 3720	lr 0.09993	Loss 2.6668 (2.8214)	Prec@(1,5) (28.2%, 59.7%)	
07/02 06:03:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][250/703]	Step 3770	lr 0.09993	Loss 2.6783 (2.8062)	Prec@(1,5) (28.4%, 60.2%)	
07/02 06:03:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][300/703]	Step 3820	lr 0.09993	Loss 2.4666 (2.7937)	Prec@(1,5) (28.6%, 60.4%)	
07/02 06:03:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][350/703]	Step 3870	lr 0.09993	Loss 2.7653 (2.7961)	Prec@(1,5) (28.6%, 60.3%)	
07/02 06:03:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][400/703]	Step 3920	lr 0.09993	Loss 2.8837 (2.7950)	Prec@(1,5) (28.7%, 60.4%)	
07/02 06:03:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][450/703]	Step 3970	lr 0.09993	Loss 2.3518 (2.7855)	Prec@(1,5) (28.9%, 60.7%)	
07/02 06:03:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][500/703]	Step 4020	lr 0.09993	Loss 2.8338 (2.7882)	Prec@(1,5) (28.8%, 60.6%)	
07/02 06:03:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][550/703]	Step 4070	lr 0.09993	Loss 3.2510 (2.7890)	Prec@(1,5) (28.8%, 60.6%)	
07/02 06:03:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][600/703]	Step 4120	lr 0.09993	Loss 2.7961 (2.7890)	Prec@(1,5) (28.7%, 60.5%)	
07/02 06:03:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][650/703]	Step 4170	lr 0.09993	Loss 2.7959 (2.7846)	Prec@(1,5) (28.9%, 60.6%)	
07/02 06:03:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][700/703]	Step 4220	lr 0.09993	Loss 2.6781 (2.7805)	Prec@(1,5) (29.0%, 60.7%)	
07/02 06:03:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [5][703/703]	Step 4223	lr 0.09993	Loss 2.9545 (2.7810)	Prec@(1,5) (29.0%, 60.7%)	
07/02 06:03:46午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  5/299] Final Prec@1 28.9933%
07/02 06:03:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [5][50/79]	Step 4224	Loss 2.8937	Prec@(1,5) (27.7%, 58.6%)
07/02 06:03:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [5][78/79]	Step 4224	Loss 2.8671	Prec@(1,5) (27.8%, 59.1%)
07/02 06:03:48午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  5/299] Final Prec@1 27.8400%
07/02 06:03:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 27.8400%
07/02 06:03:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][50/703]	Step 4274	lr 0.0999	Loss 2.9699 (2.7175)	Prec@(1,5) (30.5%, 62.2%)	
07/02 06:03:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][100/703]	Step 4324	lr 0.0999	Loss 2.6171 (2.6915)	Prec@(1,5) (30.9%, 62.7%)	
07/02 06:03:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][150/703]	Step 4374	lr 0.0999	Loss 2.6884 (2.6884)	Prec@(1,5) (30.6%, 62.8%)	
07/02 06:04:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][200/703]	Step 4424	lr 0.0999	Loss 2.7466 (2.6745)	Prec@(1,5) (31.0%, 63.1%)	
07/02 06:04:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][250/703]	Step 4474	lr 0.0999	Loss 2.5100 (2.6841)	Prec@(1,5) (30.8%, 62.8%)	
07/02 06:04:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][300/703]	Step 4524	lr 0.0999	Loss 2.6163 (2.6822)	Prec@(1,5) (30.9%, 62.6%)	
07/02 06:04:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][350/703]	Step 4574	lr 0.0999	Loss 2.5951 (2.6723)	Prec@(1,5) (31.1%, 62.9%)	
07/02 06:04:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][400/703]	Step 4624	lr 0.0999	Loss 2.6229 (2.6734)	Prec@(1,5) (31.2%, 63.0%)	
07/02 06:04:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][450/703]	Step 4674	lr 0.0999	Loss 2.9120 (2.6773)	Prec@(1,5) (31.1%, 63.0%)	
07/02 06:04:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][500/703]	Step 4724	lr 0.0999	Loss 3.0669 (2.6777)	Prec@(1,5) (31.1%, 63.0%)	
07/02 06:04:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][550/703]	Step 4774	lr 0.0999	Loss 2.6508 (2.6751)	Prec@(1,5) (31.1%, 63.1%)	
07/02 06:04:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][600/703]	Step 4824	lr 0.0999	Loss 2.5542 (2.6715)	Prec@(1,5) (31.2%, 63.2%)	
07/02 06:04:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][650/703]	Step 4874	lr 0.0999	Loss 2.5157 (2.6674)	Prec@(1,5) (31.1%, 63.3%)	
07/02 06:04:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][700/703]	Step 4924	lr 0.0999	Loss 2.8816 (2.6657)	Prec@(1,5) (31.2%, 63.3%)	
07/02 06:04:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [6][703/703]	Step 4927	lr 0.0999	Loss 2.5576 (2.6655)	Prec@(1,5) (31.2%, 63.3%)	
07/02 06:04:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  6/299] Final Prec@1 31.2467%
07/02 06:04:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [6][50/79]	Step 4928	Loss 2.7026	Prec@(1,5) (30.4%, 62.5%)
07/02 06:04:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [6][78/79]	Step 4928	Loss 2.7016	Prec@(1,5) (31.1%, 62.8%)
07/02 06:04:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  6/299] Final Prec@1 31.1200%
07/02 06:04:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 31.1200%
07/02 06:04:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][50/703]	Step 4978	lr 0.09987	Loss 2.5868 (2.6066)	Prec@(1,5) (32.5%, 65.2%)	
07/02 06:04:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][100/703]	Step 5028	lr 0.09987	Loss 2.7160 (2.5993)	Prec@(1,5) (32.3%, 65.1%)	
07/02 06:04:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][150/703]	Step 5078	lr 0.09987	Loss 2.6544 (2.5847)	Prec@(1,5) (33.1%, 65.2%)	
07/02 06:04:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][200/703]	Step 5128	lr 0.09987	Loss 2.4190 (2.5750)	Prec@(1,5) (33.2%, 65.4%)	
07/02 06:04:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][250/703]	Step 5178	lr 0.09987	Loss 2.5793 (2.5822)	Prec@(1,5) (33.2%, 65.1%)	
07/02 06:04:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][300/703]	Step 5228	lr 0.09987	Loss 2.4394 (2.5778)	Prec@(1,5) (33.2%, 65.2%)	
07/02 06:04:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][350/703]	Step 5278	lr 0.09987	Loss 2.3970 (2.5842)	Prec@(1,5) (33.1%, 65.2%)	
07/02 06:05:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][400/703]	Step 5328	lr 0.09987	Loss 2.7541 (2.5833)	Prec@(1,5) (33.1%, 65.2%)	
07/02 06:05:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][450/703]	Step 5378	lr 0.09987	Loss 3.0381 (2.5831)	Prec@(1,5) (33.0%, 65.3%)	
07/02 06:05:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][500/703]	Step 5428	lr 0.09987	Loss 2.3934 (2.5867)	Prec@(1,5) (33.0%, 65.1%)	
07/02 06:05:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][550/703]	Step 5478	lr 0.09987	Loss 2.8538 (2.5794)	Prec@(1,5) (33.1%, 65.3%)	
07/02 06:05:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][600/703]	Step 5528	lr 0.09987	Loss 2.7834 (2.5801)	Prec@(1,5) (33.1%, 65.2%)	
07/02 06:05:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][650/703]	Step 5578	lr 0.09987	Loss 2.4755 (2.5770)	Prec@(1,5) (33.1%, 65.3%)	
07/02 06:05:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][700/703]	Step 5628	lr 0.09987	Loss 2.9127 (2.5766)	Prec@(1,5) (33.2%, 65.4%)	
07/02 06:05:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [7][703/703]	Step 5631	lr 0.09987	Loss 2.4330 (2.5772)	Prec@(1,5) (33.1%, 65.3%)	
07/02 06:05:19午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  7/299] Final Prec@1 33.1222%
07/02 06:05:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [7][50/79]	Step 5632	Loss 2.7318	Prec@(1,5) (30.7%, 62.7%)
07/02 06:05:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [7][78/79]	Step 5632	Loss 2.7295	Prec@(1,5) (30.9%, 62.5%)
07/02 06:05:21午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  7/299] Final Prec@1 30.9200%
07/02 06:05:21午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 31.1200%
07/02 06:05:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][50/703]	Step 5682	lr 0.09983	Loss 2.6076 (2.5391)	Prec@(1,5) (34.0%, 67.9%)	
07/02 06:05:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][100/703]	Step 5732	lr 0.09983	Loss 2.4347 (2.5093)	Prec@(1,5) (35.1%, 67.8%)	
07/02 06:05:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][150/703]	Step 5782	lr 0.09983	Loss 2.4471 (2.5001)	Prec@(1,5) (34.9%, 67.7%)	
07/02 06:05:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][200/703]	Step 5832	lr 0.09983	Loss 2.5772 (2.4964)	Prec@(1,5) (34.9%, 67.8%)	
07/02 06:05:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][250/703]	Step 5882	lr 0.09983	Loss 2.2063 (2.5045)	Prec@(1,5) (34.9%, 67.5%)	
07/02 06:05:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][300/703]	Step 5932	lr 0.09983	Loss 2.6350 (2.5144)	Prec@(1,5) (34.8%, 67.2%)	
07/02 06:05:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][350/703]	Step 5982	lr 0.09983	Loss 2.5433 (2.5151)	Prec@(1,5) (34.6%, 67.4%)	
07/02 06:05:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][400/703]	Step 6032	lr 0.09983	Loss 2.4396 (2.5064)	Prec@(1,5) (34.8%, 67.4%)	
07/02 06:05:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][450/703]	Step 6082	lr 0.09983	Loss 2.5271 (2.5137)	Prec@(1,5) (34.7%, 67.3%)	
07/02 06:05:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][500/703]	Step 6132	lr 0.09983	Loss 2.5325 (2.5187)	Prec@(1,5) (34.6%, 67.1%)	
07/02 06:05:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][550/703]	Step 6182	lr 0.09983	Loss 2.4450 (2.5163)	Prec@(1,5) (34.5%, 67.2%)	
07/02 06:05:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][600/703]	Step 6232	lr 0.09983	Loss 2.2878 (2.5139)	Prec@(1,5) (34.5%, 67.2%)	
07/02 06:06:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][650/703]	Step 6282	lr 0.09983	Loss 2.6454 (2.5155)	Prec@(1,5) (34.6%, 67.1%)	
07/02 06:06:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][700/703]	Step 6332	lr 0.09983	Loss 2.2225 (2.5159)	Prec@(1,5) (34.5%, 67.1%)	
07/02 06:06:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [8][703/703]	Step 6335	lr 0.09983	Loss 2.4614 (2.5152)	Prec@(1,5) (34.5%, 67.1%)	
07/02 06:06:05午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  8/299] Final Prec@1 34.5467%
07/02 06:06:07午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [8][50/79]	Step 6336	Loss 2.6522	Prec@(1,5) (33.0%, 63.7%)
07/02 06:06:07午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [8][78/79]	Step 6336	Loss 2.6544	Prec@(1,5) (33.2%, 64.0%)
07/02 06:06:07午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  8/299] Final Prec@1 33.2200%
07/02 06:06:08午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 33.2200%
07/02 06:06:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][50/703]	Step 6386	lr 0.09978	Loss 2.3476 (2.4439)	Prec@(1,5) (36.3%, 70.0%)	
07/02 06:06:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][100/703]	Step 6436	lr 0.09978	Loss 2.7885 (2.4207)	Prec@(1,5) (36.2%, 70.1%)	
07/02 06:06:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][150/703]	Step 6486	lr 0.09978	Loss 2.5026 (2.4160)	Prec@(1,5) (36.5%, 69.7%)	
07/02 06:06:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][200/703]	Step 6536	lr 0.09978	Loss 2.6082 (2.4214)	Prec@(1,5) (36.3%, 69.4%)	
07/02 06:06:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][250/703]	Step 6586	lr 0.09978	Loss 2.7077 (2.4379)	Prec@(1,5) (36.0%, 69.0%)	
07/02 06:06:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][300/703]	Step 6636	lr 0.09978	Loss 2.4961 (2.4473)	Prec@(1,5) (35.8%, 68.7%)	
07/02 06:06:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][350/703]	Step 6686	lr 0.09978	Loss 2.3118 (2.4499)	Prec@(1,5) (35.8%, 68.6%)	
07/02 06:06:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][400/703]	Step 6736	lr 0.09978	Loss 2.3399 (2.4424)	Prec@(1,5) (35.9%, 68.8%)	
07/02 06:06:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][450/703]	Step 6786	lr 0.09978	Loss 2.3353 (2.4427)	Prec@(1,5) (35.9%, 68.7%)	
07/02 06:06:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][500/703]	Step 6836	lr 0.09978	Loss 2.3063 (2.4421)	Prec@(1,5) (36.0%, 68.7%)	
07/02 06:06:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][550/703]	Step 6886	lr 0.09978	Loss 2.2907 (2.4447)	Prec@(1,5) (36.0%, 68.7%)	
07/02 06:06:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][600/703]	Step 6936	lr 0.09978	Loss 2.5556 (2.4467)	Prec@(1,5) (35.9%, 68.7%)	
07/02 06:06:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][650/703]	Step 6986	lr 0.09978	Loss 1.8657 (2.4453)	Prec@(1,5) (35.9%, 68.7%)	
07/02 06:06:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][700/703]	Step 7036	lr 0.09978	Loss 2.4731 (2.4466)	Prec@(1,5) (35.9%, 68.6%)	
07/02 06:06:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [9][703/703]	Step 7039	lr 0.09978	Loss 2.6020 (2.4475)	Prec@(1,5) (35.9%, 68.6%)	
07/02 06:06:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [  9/299] Final Prec@1 35.9222%
07/02 06:06:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [9][50/79]	Step 7040	Loss 2.5612	Prec@(1,5) (33.2%, 66.3%)
07/02 06:06:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [9][78/79]	Step 7040	Loss 2.6013	Prec@(1,5) (33.0%, 65.4%)
07/02 06:06:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [  9/299] Final Prec@1 32.9800%
07/02 06:06:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 33.2200%
07/02 06:06:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][50/703]	Step 7090	lr 0.09973	Loss 2.1041 (2.3709)	Prec@(1,5) (36.3%, 70.5%)	
07/02 06:07:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][100/703]	Step 7140	lr 0.09973	Loss 2.3425 (2.3834)	Prec@(1,5) (36.7%, 69.9%)	
07/02 06:07:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][150/703]	Step 7190	lr 0.09973	Loss 2.2705 (2.3786)	Prec@(1,5) (37.1%, 70.2%)	
07/02 06:07:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][200/703]	Step 7240	lr 0.09973	Loss 2.2368 (2.3754)	Prec@(1,5) (37.0%, 70.1%)	
07/02 06:07:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][250/703]	Step 7290	lr 0.09973	Loss 2.3231 (2.3825)	Prec@(1,5) (36.9%, 70.0%)	
07/02 06:07:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][300/703]	Step 7340	lr 0.09973	Loss 2.5620 (2.3867)	Prec@(1,5) (37.0%, 69.9%)	
07/02 06:07:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][350/703]	Step 7390	lr 0.09973	Loss 2.1617 (2.3934)	Prec@(1,5) (36.8%, 69.9%)	
07/02 06:07:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][400/703]	Step 7440	lr 0.09973	Loss 2.4501 (2.3901)	Prec@(1,5) (37.0%, 70.0%)	
07/02 06:07:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][450/703]	Step 7490	lr 0.09973	Loss 2.5621 (2.3885)	Prec@(1,5) (37.0%, 69.9%)	
07/02 06:07:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][500/703]	Step 7540	lr 0.09973	Loss 2.4877 (2.3907)	Prec@(1,5) (36.9%, 69.9%)	
07/02 06:07:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][550/703]	Step 7590	lr 0.09973	Loss 2.2919 (2.3940)	Prec@(1,5) (36.8%, 69.9%)	
07/02 06:07:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][600/703]	Step 7640	lr 0.09973	Loss 1.9480 (2.3974)	Prec@(1,5) (36.8%, 69.8%)	
07/02 06:07:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][650/703]	Step 7690	lr 0.09973	Loss 2.2473 (2.3979)	Prec@(1,5) (36.8%, 69.8%)	
07/02 06:07:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][700/703]	Step 7740	lr 0.09973	Loss 2.6737 (2.3991)	Prec@(1,5) (36.8%, 69.8%)	
07/02 06:07:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [10][703/703]	Step 7743	lr 0.09973	Loss 2.4928 (2.3997)	Prec@(1,5) (36.8%, 69.7%)	
07/02 06:07:40午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 10/299] Final Prec@1 36.8244%
07/02 06:07:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [10][50/79]	Step 7744	Loss 2.6440	Prec@(1,5) (33.0%, 65.3%)
07/02 06:07:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [10][78/79]	Step 7744	Loss 2.6465	Prec@(1,5) (33.0%, 64.8%)
07/02 06:07:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 10/299] Final Prec@1 32.9600%
07/02 06:07:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 33.2200%
07/02 06:07:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][50/703]	Step 7794	lr 0.09967	Loss 2.2932 (2.3322)	Prec@(1,5) (38.1%, 71.1%)	
07/02 06:07:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][100/703]	Step 7844	lr 0.09967	Loss 2.1899 (2.3122)	Prec@(1,5) (39.0%, 71.2%)	
07/02 06:07:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][150/703]	Step 7894	lr 0.09967	Loss 2.8711 (2.2996)	Prec@(1,5) (38.9%, 71.7%)	
07/02 06:07:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][200/703]	Step 7944	lr 0.09967	Loss 2.2683 (2.3233)	Prec@(1,5) (38.7%, 71.0%)	
07/02 06:07:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][250/703]	Step 7994	lr 0.09967	Loss 2.6396 (2.3299)	Prec@(1,5) (38.4%, 70.9%)	
07/02 06:08:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][300/703]	Step 8044	lr 0.09967	Loss 2.5030 (2.3398)	Prec@(1,5) (38.0%, 70.8%)	
07/02 06:08:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][350/703]	Step 8094	lr 0.09967	Loss 2.5969 (2.3403)	Prec@(1,5) (38.1%, 70.8%)	
07/02 06:08:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][400/703]	Step 8144	lr 0.09967	Loss 2.0522 (2.3407)	Prec@(1,5) (38.1%, 70.8%)	
07/02 06:08:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][450/703]	Step 8194	lr 0.09967	Loss 2.4600 (2.3398)	Prec@(1,5) (38.0%, 70.8%)	
07/02 06:08:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][500/703]	Step 8244	lr 0.09967	Loss 2.4226 (2.3445)	Prec@(1,5) (37.9%, 70.6%)	
07/02 06:08:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][550/703]	Step 8294	lr 0.09967	Loss 2.4319 (2.3475)	Prec@(1,5) (37.9%, 70.6%)	
07/02 06:08:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][600/703]	Step 8344	lr 0.09967	Loss 2.7744 (2.3526)	Prec@(1,5) (37.7%, 70.5%)	
07/02 06:08:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][650/703]	Step 8394	lr 0.09967	Loss 2.3183 (2.3540)	Prec@(1,5) (37.6%, 70.5%)	
07/02 06:08:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][700/703]	Step 8444	lr 0.09967	Loss 2.1111 (2.3532)	Prec@(1,5) (37.7%, 70.4%)	
07/02 06:08:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [11][703/703]	Step 8447	lr 0.09967	Loss 2.2416 (2.3531)	Prec@(1,5) (37.7%, 70.4%)	
07/02 06:08:26午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 11/299] Final Prec@1 37.6956%
07/02 06:08:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [11][50/79]	Step 8448	Loss 2.5136	Prec@(1,5) (34.7%, 67.2%)
07/02 06:08:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [11][78/79]	Step 8448	Loss 2.5192	Prec@(1,5) (35.0%, 67.0%)
07/02 06:08:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 11/299] Final Prec@1 35.0000%
07/02 06:08:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 35.0000%
07/02 06:08:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][50/703]	Step 8498	lr 0.09961	Loss 2.3944 (2.2911)	Prec@(1,5) (39.4%, 72.4%)	
07/02 06:08:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][100/703]	Step 8548	lr 0.09961	Loss 2.1467 (2.2665)	Prec@(1,5) (39.9%, 73.0%)	
07/02 06:08:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][150/703]	Step 8598	lr 0.09961	Loss 2.1607 (2.2723)	Prec@(1,5) (39.6%, 72.7%)	
07/02 06:08:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][200/703]	Step 8648	lr 0.09961	Loss 1.9968 (2.2762)	Prec@(1,5) (39.6%, 72.8%)	
07/02 06:08:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][250/703]	Step 8698	lr 0.09961	Loss 2.5406 (2.2805)	Prec@(1,5) (39.4%, 72.7%)	
07/02 06:08:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][300/703]	Step 8748	lr 0.09961	Loss 2.1804 (2.2958)	Prec@(1,5) (39.2%, 72.3%)	
07/02 06:08:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][350/703]	Step 8798	lr 0.09961	Loss 2.2906 (2.2942)	Prec@(1,5) (39.2%, 72.4%)	
07/02 06:08:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][400/703]	Step 8848	lr 0.09961	Loss 2.1909 (2.2944)	Prec@(1,5) (39.2%, 72.4%)	
07/02 06:08:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][450/703]	Step 8898	lr 0.09961	Loss 2.1440 (2.3009)	Prec@(1,5) (39.0%, 72.3%)	
07/02 06:08:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][500/703]	Step 8948	lr 0.09961	Loss 2.2351 (2.3064)	Prec@(1,5) (38.9%, 72.1%)	
07/02 06:09:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][550/703]	Step 8998	lr 0.09961	Loss 2.4398 (2.3054)	Prec@(1,5) (39.0%, 72.1%)	
07/02 06:09:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][600/703]	Step 9048	lr 0.09961	Loss 2.4243 (2.3080)	Prec@(1,5) (38.8%, 72.0%)	
07/02 06:09:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][650/703]	Step 9098	lr 0.09961	Loss 2.1856 (2.3122)	Prec@(1,5) (38.7%, 71.9%)	
07/02 06:09:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][700/703]	Step 9148	lr 0.09961	Loss 2.4792 (2.3133)	Prec@(1,5) (38.7%, 71.9%)	
07/02 06:09:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [12][703/703]	Step 9151	lr 0.09961	Loss 2.1184 (2.3136)	Prec@(1,5) (38.7%, 71.9%)	
07/02 06:09:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 12/299] Final Prec@1 38.7067%
07/02 06:09:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [12][50/79]	Step 9152	Loss 2.4481	Prec@(1,5) (36.3%, 68.5%)
07/02 06:09:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [12][78/79]	Step 9152	Loss 2.4579	Prec@(1,5) (36.5%, 68.3%)
07/02 06:09:13午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 12/299] Final Prec@1 36.4800%
07/02 06:09:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.4800%
07/02 06:09:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][50/703]	Step 9202	lr 0.09954	Loss 2.1305 (2.2336)	Prec@(1,5) (40.6%, 72.9%)	
07/02 06:09:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][100/703]	Step 9252	lr 0.09954	Loss 2.0447 (2.2375)	Prec@(1,5) (40.4%, 73.1%)	
07/02 06:09:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][150/703]	Step 9302	lr 0.09954	Loss 2.2208 (2.2405)	Prec@(1,5) (40.0%, 73.0%)	
07/02 06:09:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][200/703]	Step 9352	lr 0.09954	Loss 2.7282 (2.2460)	Prec@(1,5) (40.2%, 72.8%)	
07/02 06:09:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][250/703]	Step 9402	lr 0.09954	Loss 1.9409 (2.2451)	Prec@(1,5) (40.3%, 72.8%)	
07/02 06:09:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][300/703]	Step 9452	lr 0.09954	Loss 2.3800 (2.2492)	Prec@(1,5) (40.3%, 72.7%)	
07/02 06:09:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][350/703]	Step 9502	lr 0.09954	Loss 2.5725 (2.2530)	Prec@(1,5) (40.2%, 72.6%)	
07/02 06:09:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][400/703]	Step 9552	lr 0.09954	Loss 2.0505 (2.2660)	Prec@(1,5) (39.8%, 72.3%)	
07/02 06:09:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][450/703]	Step 9602	lr 0.09954	Loss 2.3042 (2.2678)	Prec@(1,5) (39.7%, 72.3%)	
07/02 06:09:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][500/703]	Step 9652	lr 0.09954	Loss 2.5310 (2.2706)	Prec@(1,5) (39.6%, 72.4%)	
07/02 06:09:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][550/703]	Step 9702	lr 0.09954	Loss 2.5714 (2.2717)	Prec@(1,5) (39.4%, 72.4%)	
07/02 06:09:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][600/703]	Step 9752	lr 0.09954	Loss 2.0680 (2.2667)	Prec@(1,5) (39.6%, 72.5%)	
07/02 06:09:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][650/703]	Step 9802	lr 0.09954	Loss 2.2662 (2.2661)	Prec@(1,5) (39.6%, 72.5%)	
07/02 06:09:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][700/703]	Step 9852	lr 0.09954	Loss 2.1087 (2.2663)	Prec@(1,5) (39.7%, 72.4%)	
07/02 06:09:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [13][703/703]	Step 9855	lr 0.09954	Loss 1.7286 (2.2667)	Prec@(1,5) (39.7%, 72.4%)	
07/02 06:09:58午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 13/299] Final Prec@1 39.7311%
07/02 06:09:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [13][50/79]	Step 9856	Loss 2.5115	Prec@(1,5) (35.8%, 68.2%)
07/02 06:10:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [13][78/79]	Step 9856	Loss 2.5222	Prec@(1,5) (35.8%, 67.6%)
07/02 06:10:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 13/299] Final Prec@1 35.7800%
07/02 06:10:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.4800%
07/02 06:10:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][50/703]	Step 9906	lr 0.09947	Loss 2.3830 (2.2546)	Prec@(1,5) (39.5%, 72.9%)	
07/02 06:10:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][100/703]	Step 9956	lr 0.09947	Loss 1.7044 (2.2100)	Prec@(1,5) (40.2%, 73.8%)	
07/02 06:10:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][150/703]	Step 10006	lr 0.09947	Loss 2.2924 (2.1856)	Prec@(1,5) (41.0%, 74.2%)	
07/02 06:10:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][200/703]	Step 10056	lr 0.09947	Loss 2.2440 (2.2001)	Prec@(1,5) (40.8%, 73.9%)	
07/02 06:10:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][250/703]	Step 10106	lr 0.09947	Loss 2.2320 (2.2091)	Prec@(1,5) (40.5%, 73.8%)	
07/02 06:10:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][300/703]	Step 10156	lr 0.09947	Loss 2.1546 (2.2076)	Prec@(1,5) (40.6%, 73.9%)	
07/02 06:10:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][350/703]	Step 10206	lr 0.09947	Loss 2.3855 (2.2082)	Prec@(1,5) (40.7%, 73.8%)	
07/02 06:10:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][400/703]	Step 10256	lr 0.09947	Loss 2.6085 (2.2064)	Prec@(1,5) (40.9%, 73.8%)	
07/02 06:10:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][450/703]	Step 10306	lr 0.09947	Loss 2.1072 (2.2125)	Prec@(1,5) (40.8%, 73.7%)	
07/02 06:10:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][500/703]	Step 10356	lr 0.09947	Loss 2.1595 (2.2187)	Prec@(1,5) (40.7%, 73.6%)	
07/02 06:10:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][550/703]	Step 10406	lr 0.09947	Loss 2.3323 (2.2222)	Prec@(1,5) (40.6%, 73.5%)	
07/02 06:10:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][600/703]	Step 10456	lr 0.09947	Loss 2.2897 (2.2261)	Prec@(1,5) (40.5%, 73.4%)	
07/02 06:10:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][650/703]	Step 10506	lr 0.09947	Loss 2.2940 (2.2244)	Prec@(1,5) (40.6%, 73.3%)	
07/02 06:10:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][700/703]	Step 10556	lr 0.09947	Loss 2.2062 (2.2301)	Prec@(1,5) (40.4%, 73.3%)	
07/02 06:10:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [14][703/703]	Step 10559	lr 0.09947	Loss 2.3322 (2.2306)	Prec@(1,5) (40.4%, 73.2%)	
07/02 06:10:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 14/299] Final Prec@1 40.4289%
07/02 06:10:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [14][50/79]	Step 10560	Loss 2.3920	Prec@(1,5) (37.1%, 69.2%)
07/02 06:10:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [14][78/79]	Step 10560	Loss 2.3930	Prec@(1,5) (37.8%, 69.5%)
07/02 06:10:47午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 14/299] Final Prec@1 37.7800%
07/02 06:10:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.7800%
07/02 06:10:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][50/703]	Step 10610	lr 0.09939	Loss 1.9024 (2.1595)	Prec@(1,5) (41.7%, 74.4%)	
07/02 06:10:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][100/703]	Step 10660	lr 0.09939	Loss 2.4960 (2.1535)	Prec@(1,5) (42.2%, 74.6%)	
07/02 06:10:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][150/703]	Step 10710	lr 0.09939	Loss 1.9322 (2.1337)	Prec@(1,5) (42.7%, 74.8%)	
07/02 06:11:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][200/703]	Step 10760	lr 0.09939	Loss 2.0610 (2.1537)	Prec@(1,5) (42.4%, 74.5%)	
07/02 06:11:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][250/703]	Step 10810	lr 0.09939	Loss 2.2817 (2.1609)	Prec@(1,5) (42.3%, 74.4%)	
07/02 06:11:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][300/703]	Step 10860	lr 0.09939	Loss 2.1150 (2.1711)	Prec@(1,5) (42.1%, 74.3%)	
07/02 06:11:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][350/703]	Step 10910	lr 0.09939	Loss 2.1232 (2.1719)	Prec@(1,5) (42.0%, 74.2%)	
07/02 06:11:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][400/703]	Step 10960	lr 0.09939	Loss 2.1830 (2.1806)	Prec@(1,5) (41.8%, 74.0%)	
07/02 06:11:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][450/703]	Step 11010	lr 0.09939	Loss 2.0418 (2.1848)	Prec@(1,5) (41.6%, 73.9%)	
07/02 06:11:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][500/703]	Step 11060	lr 0.09939	Loss 2.1234 (2.1910)	Prec@(1,5) (41.5%, 73.9%)	
07/02 06:11:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][550/703]	Step 11110	lr 0.09939	Loss 2.0907 (2.1914)	Prec@(1,5) (41.4%, 73.9%)	
07/02 06:11:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][600/703]	Step 11160	lr 0.09939	Loss 2.3017 (2.1943)	Prec@(1,5) (41.3%, 73.9%)	
07/02 06:11:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][650/703]	Step 11210	lr 0.09939	Loss 2.2530 (2.1891)	Prec@(1,5) (41.4%, 74.0%)	
07/02 06:11:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][700/703]	Step 11260	lr 0.09939	Loss 1.9757 (2.1920)	Prec@(1,5) (41.3%, 74.0%)	
07/02 06:11:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [15][703/703]	Step 11263	lr 0.09939	Loss 2.2937 (2.1915)	Prec@(1,5) (41.4%, 74.0%)	
07/02 06:11:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 15/299] Final Prec@1 41.3600%
07/02 06:11:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [15][50/79]	Step 11264	Loss 2.5793	Prec@(1,5) (34.7%, 65.0%)
07/02 06:11:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [15][78/79]	Step 11264	Loss 2.5721	Prec@(1,5) (35.0%, 65.5%)
07/02 06:11:35午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 15/299] Final Prec@1 34.9800%
07/02 06:11:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.7800%
07/02 06:11:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][50/703]	Step 11314	lr 0.09931	Loss 1.9595 (2.1931)	Prec@(1,5) (41.1%, 74.0%)	
07/02 06:11:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][100/703]	Step 11364	lr 0.09931	Loss 2.6222 (2.1450)	Prec@(1,5) (42.3%, 75.1%)	
07/02 06:11:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][150/703]	Step 11414	lr 0.09931	Loss 2.1449 (2.1584)	Prec@(1,5) (41.9%, 74.7%)	
07/02 06:11:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][200/703]	Step 11464	lr 0.09931	Loss 2.2890 (2.1713)	Prec@(1,5) (41.6%, 74.5%)	
07/02 06:11:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][250/703]	Step 11514	lr 0.09931	Loss 2.0260 (2.1571)	Prec@(1,5) (42.0%, 74.8%)	
07/02 06:11:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][300/703]	Step 11564	lr 0.09931	Loss 1.9555 (2.1582)	Prec@(1,5) (41.9%, 74.7%)	
07/02 06:11:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][350/703]	Step 11614	lr 0.09931	Loss 2.2129 (2.1533)	Prec@(1,5) (41.9%, 74.9%)	
07/02 06:12:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][400/703]	Step 11664	lr 0.09931	Loss 2.2027 (2.1487)	Prec@(1,5) (42.0%, 75.0%)	
07/02 06:12:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][450/703]	Step 11714	lr 0.09931	Loss 2.2201 (2.1577)	Prec@(1,5) (41.9%, 74.8%)	
07/02 06:12:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][500/703]	Step 11764	lr 0.09931	Loss 2.2026 (2.1633)	Prec@(1,5) (41.9%, 74.7%)	
07/02 06:12:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][550/703]	Step 11814	lr 0.09931	Loss 2.1479 (2.1611)	Prec@(1,5) (42.0%, 74.7%)	
07/02 06:12:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][600/703]	Step 11864	lr 0.09931	Loss 2.4772 (2.1582)	Prec@(1,5) (42.0%, 74.7%)	
07/02 06:12:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][650/703]	Step 11914	lr 0.09931	Loss 2.2956 (2.1579)	Prec@(1,5) (42.1%, 74.8%)	
07/02 06:12:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][700/703]	Step 11964	lr 0.09931	Loss 2.3149 (2.1566)	Prec@(1,5) (42.2%, 74.8%)	
07/02 06:12:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [16][703/703]	Step 11967	lr 0.09931	Loss 1.7968 (2.1564)	Prec@(1,5) (42.2%, 74.8%)	
07/02 06:12:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 16/299] Final Prec@1 42.1600%
07/02 06:12:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [16][50/79]	Step 11968	Loss 2.3763	Prec@(1,5) (37.5%, 71.4%)
07/02 06:12:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [16][78/79]	Step 11968	Loss 2.3329	Prec@(1,5) (38.5%, 72.1%)
07/02 06:12:22午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 16/299] Final Prec@1 38.5200%
07/02 06:12:22午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 38.5200%
07/02 06:12:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][50/703]	Step 12018	lr 0.09922	Loss 1.9375 (2.1291)	Prec@(1,5) (42.8%, 75.6%)	
07/02 06:12:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][100/703]	Step 12068	lr 0.09922	Loss 2.0057 (2.1118)	Prec@(1,5) (42.7%, 75.8%)	
07/02 06:12:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][150/703]	Step 12118	lr 0.09922	Loss 1.7377 (2.0947)	Prec@(1,5) (43.2%, 76.0%)	
07/02 06:12:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][200/703]	Step 12168	lr 0.09922	Loss 2.1575 (2.0841)	Prec@(1,5) (43.8%, 76.1%)	
07/02 06:12:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][250/703]	Step 12218	lr 0.09922	Loss 2.2597 (2.0908)	Prec@(1,5) (43.7%, 75.9%)	
07/02 06:12:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][300/703]	Step 12268	lr 0.09922	Loss 2.1255 (2.0962)	Prec@(1,5) (43.7%, 75.9%)	
07/02 06:12:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][350/703]	Step 12318	lr 0.09922	Loss 2.4971 (2.0958)	Prec@(1,5) (43.6%, 75.9%)	
07/02 06:12:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][400/703]	Step 12368	lr 0.09922	Loss 2.4540 (2.1097)	Prec@(1,5) (43.2%, 75.7%)	
07/02 06:12:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][450/703]	Step 12418	lr 0.09922	Loss 2.2998 (2.1159)	Prec@(1,5) (43.0%, 75.5%)	
07/02 06:12:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][500/703]	Step 12468	lr 0.09922	Loss 2.1198 (2.1143)	Prec@(1,5) (43.1%, 75.6%)	
07/02 06:12:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][550/703]	Step 12518	lr 0.09922	Loss 1.8264 (2.1179)	Prec@(1,5) (43.1%, 75.5%)	
07/02 06:13:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][600/703]	Step 12568	lr 0.09922	Loss 1.9879 (2.1238)	Prec@(1,5) (43.0%, 75.4%)	
07/02 06:13:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][650/703]	Step 12618	lr 0.09922	Loss 2.2490 (2.1279)	Prec@(1,5) (42.8%, 75.3%)	
07/02 06:13:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][700/703]	Step 12668	lr 0.09922	Loss 2.4677 (2.1274)	Prec@(1,5) (42.9%, 75.3%)	
07/02 06:13:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [17][703/703]	Step 12671	lr 0.09922	Loss 2.2752 (2.1280)	Prec@(1,5) (42.8%, 75.3%)	
07/02 06:13:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 17/299] Final Prec@1 42.8422%
07/02 06:13:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [17][50/79]	Step 12672	Loss 2.4382	Prec@(1,5) (37.1%, 69.1%)
07/02 06:13:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [17][78/79]	Step 12672	Loss 2.4516	Prec@(1,5) (36.5%, 68.8%)
07/02 06:13:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 17/299] Final Prec@1 36.5000%
07/02 06:13:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 38.5200%
07/02 06:13:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][50/703]	Step 12722	lr 0.09912	Loss 1.7621 (2.1095)	Prec@(1,5) (43.2%, 76.2%)	
07/02 06:13:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][100/703]	Step 12772	lr 0.09912	Loss 2.2359 (2.0915)	Prec@(1,5) (43.9%, 75.8%)	
07/02 06:13:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][150/703]	Step 12822	lr 0.09912	Loss 2.1593 (2.0714)	Prec@(1,5) (44.3%, 76.2%)	
07/02 06:13:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][200/703]	Step 12872	lr 0.09912	Loss 1.8259 (2.0707)	Prec@(1,5) (44.4%, 76.1%)	
07/02 06:13:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][250/703]	Step 12922	lr 0.09912	Loss 2.1762 (2.0690)	Prec@(1,5) (44.3%, 76.2%)	
07/02 06:13:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][300/703]	Step 12972	lr 0.09912	Loss 2.1314 (2.0785)	Prec@(1,5) (44.1%, 76.1%)	
07/02 06:13:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][350/703]	Step 13022	lr 0.09912	Loss 2.1926 (2.0860)	Prec@(1,5) (44.1%, 75.8%)	
07/02 06:13:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][400/703]	Step 13072	lr 0.09912	Loss 1.9457 (2.0851)	Prec@(1,5) (44.0%, 75.8%)	
07/02 06:13:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][450/703]	Step 13122	lr 0.09912	Loss 2.0355 (2.0882)	Prec@(1,5) (44.0%, 75.8%)	
07/02 06:13:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][500/703]	Step 13172	lr 0.09912	Loss 2.1498 (2.0897)	Prec@(1,5) (43.9%, 75.9%)	
07/02 06:13:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][550/703]	Step 13222	lr 0.09912	Loss 2.1657 (2.0913)	Prec@(1,5) (44.0%, 75.8%)	
07/02 06:13:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][600/703]	Step 13272	lr 0.09912	Loss 2.0784 (2.0913)	Prec@(1,5) (44.0%, 75.9%)	
07/02 06:13:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][650/703]	Step 13322	lr 0.09912	Loss 2.2955 (2.0959)	Prec@(1,5) (43.8%, 75.8%)	
07/02 06:13:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][700/703]	Step 13372	lr 0.09912	Loss 2.5950 (2.0993)	Prec@(1,5) (43.8%, 75.8%)	
07/02 06:13:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [18][703/703]	Step 13375	lr 0.09912	Loss 2.0161 (2.0991)	Prec@(1,5) (43.8%, 75.8%)	
07/02 06:13:54午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 18/299] Final Prec@1 43.7733%
07/02 06:13:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [18][50/79]	Step 13376	Loss 2.2731	Prec@(1,5) (40.6%, 72.8%)
07/02 06:13:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [18][78/79]	Step 13376	Loss 2.2832	Prec@(1,5) (40.1%, 72.1%)
07/02 06:13:56午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 18/299] Final Prec@1 40.0400%
07/02 06:13:56午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.0400%
07/02 06:14:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][50/703]	Step 13426	lr 0.09902	Loss 1.8899 (2.0029)	Prec@(1,5) (45.5%, 77.9%)	
07/02 06:14:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][100/703]	Step 13476	lr 0.09902	Loss 1.9076 (2.0275)	Prec@(1,5) (45.2%, 77.3%)	
07/02 06:14:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][150/703]	Step 13526	lr 0.09902	Loss 2.0400 (2.0438)	Prec@(1,5) (44.6%, 77.0%)	
07/02 06:14:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][200/703]	Step 13576	lr 0.09902	Loss 2.0385 (2.0433)	Prec@(1,5) (44.9%, 77.0%)	
07/02 06:14:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][250/703]	Step 13626	lr 0.09902	Loss 2.0218 (2.0432)	Prec@(1,5) (44.8%, 76.9%)	
07/02 06:14:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][300/703]	Step 13676	lr 0.09902	Loss 1.9916 (2.0456)	Prec@(1,5) (44.6%, 76.7%)	
07/02 06:14:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][350/703]	Step 13726	lr 0.09902	Loss 1.9831 (2.0475)	Prec@(1,5) (44.5%, 76.8%)	
07/02 06:14:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][400/703]	Step 13776	lr 0.09902	Loss 1.9722 (2.0458)	Prec@(1,5) (44.4%, 76.9%)	
07/02 06:14:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][450/703]	Step 13826	lr 0.09902	Loss 1.7367 (2.0478)	Prec@(1,5) (44.2%, 76.9%)	
07/02 06:14:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][500/703]	Step 13876	lr 0.09902	Loss 2.0005 (2.0511)	Prec@(1,5) (44.2%, 76.8%)	
07/02 06:14:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][550/703]	Step 13926	lr 0.09902	Loss 1.9867 (2.0565)	Prec@(1,5) (44.1%, 76.7%)	
07/02 06:14:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][600/703]	Step 13976	lr 0.09902	Loss 2.4213 (2.0598)	Prec@(1,5) (44.1%, 76.7%)	
07/02 06:14:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][650/703]	Step 14026	lr 0.09902	Loss 1.7834 (2.0603)	Prec@(1,5) (44.1%, 76.6%)	
07/02 06:14:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][700/703]	Step 14076	lr 0.09902	Loss 2.0280 (2.0614)	Prec@(1,5) (44.1%, 76.6%)	
07/02 06:14:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [19][703/703]	Step 14079	lr 0.09902	Loss 2.2111 (2.0615)	Prec@(1,5) (44.1%, 76.6%)	
07/02 06:14:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 19/299] Final Prec@1 44.1378%
07/02 06:14:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [19][50/79]	Step 14080	Loss 2.4292	Prec@(1,5) (37.3%, 69.2%)
07/02 06:14:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [19][78/79]	Step 14080	Loss 2.4181	Prec@(1,5) (37.1%, 69.2%)
07/02 06:14:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 19/299] Final Prec@1 37.1200%
07/02 06:14:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.0400%
07/02 06:14:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][50/703]	Step 14130	lr 0.09892	Loss 2.2041 (2.0181)	Prec@(1,5) (45.4%, 78.1%)	
07/02 06:14:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][100/703]	Step 14180	lr 0.09892	Loss 1.9628 (2.0201)	Prec@(1,5) (44.6%, 78.1%)	
07/02 06:14:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][150/703]	Step 14230	lr 0.09892	Loss 2.0654 (2.0248)	Prec@(1,5) (44.9%, 78.0%)	
07/02 06:14:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][200/703]	Step 14280	lr 0.09892	Loss 1.7273 (2.0166)	Prec@(1,5) (44.8%, 78.1%)	
07/02 06:14:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][250/703]	Step 14330	lr 0.09892	Loss 1.8983 (2.0330)	Prec@(1,5) (44.5%, 77.6%)	
07/02 06:15:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][300/703]	Step 14380	lr 0.09892	Loss 2.0303 (2.0429)	Prec@(1,5) (44.3%, 77.4%)	
07/02 06:15:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][350/703]	Step 14430	lr 0.09892	Loss 2.1634 (2.0449)	Prec@(1,5) (44.2%, 77.3%)	
07/02 06:15:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][400/703]	Step 14480	lr 0.09892	Loss 2.1277 (2.0504)	Prec@(1,5) (44.2%, 77.1%)	
07/02 06:15:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][450/703]	Step 14530	lr 0.09892	Loss 2.6599 (2.0519)	Prec@(1,5) (44.2%, 77.0%)	
07/02 06:15:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][500/703]	Step 14580	lr 0.09892	Loss 1.9219 (2.0502)	Prec@(1,5) (44.4%, 77.0%)	
07/02 06:15:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][550/703]	Step 14630	lr 0.09892	Loss 2.0143 (2.0514)	Prec@(1,5) (44.3%, 77.0%)	
07/02 06:15:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][600/703]	Step 14680	lr 0.09892	Loss 2.1104 (2.0492)	Prec@(1,5) (44.4%, 76.9%)	
07/02 06:15:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][650/703]	Step 14730	lr 0.09892	Loss 2.0275 (2.0477)	Prec@(1,5) (44.3%, 77.0%)	
07/02 06:15:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][700/703]	Step 14780	lr 0.09892	Loss 2.0305 (2.0486)	Prec@(1,5) (44.4%, 76.9%)	
07/02 06:15:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [20][703/703]	Step 14783	lr 0.09892	Loss 2.1268 (2.0497)	Prec@(1,5) (44.4%, 76.9%)	
07/02 06:15:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 20/299] Final Prec@1 44.3600%
07/02 06:15:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [20][50/79]	Step 14784	Loss 2.1246	Prec@(1,5) (42.7%, 74.7%)
07/02 06:15:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [20][78/79]	Step 14784	Loss 2.1661	Prec@(1,5) (42.0%, 74.0%)
07/02 06:15:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 20/299] Final Prec@1 42.0400%
07/02 06:15:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0400%
07/02 06:15:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][50/703]	Step 14834	lr 0.09881	Loss 2.1213 (1.9342)	Prec@(1,5) (47.1%, 78.3%)	
07/02 06:15:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][100/703]	Step 14884	lr 0.09881	Loss 2.0687 (1.9528)	Prec@(1,5) (46.6%, 78.3%)	
07/02 06:15:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][150/703]	Step 14934	lr 0.09881	Loss 2.0401 (1.9620)	Prec@(1,5) (46.4%, 78.4%)	
07/02 06:15:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][200/703]	Step 14984	lr 0.09881	Loss 1.8228 (1.9686)	Prec@(1,5) (46.2%, 78.2%)	
07/02 06:15:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][250/703]	Step 15034	lr 0.09881	Loss 1.9287 (1.9714)	Prec@(1,5) (45.9%, 78.3%)	
07/02 06:15:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][300/703]	Step 15084	lr 0.09881	Loss 1.8019 (1.9815)	Prec@(1,5) (45.7%, 78.2%)	
07/02 06:15:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][350/703]	Step 15134	lr 0.09881	Loss 2.0258 (1.9888)	Prec@(1,5) (45.5%, 78.1%)	
07/02 06:15:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][400/703]	Step 15184	lr 0.09881	Loss 2.2248 (1.9971)	Prec@(1,5) (45.5%, 77.8%)	
07/02 06:15:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][450/703]	Step 15234	lr 0.09881	Loss 2.3709 (2.0000)	Prec@(1,5) (45.5%, 77.8%)	
07/02 06:16:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][500/703]	Step 15284	lr 0.09881	Loss 2.0986 (2.0005)	Prec@(1,5) (45.5%, 77.7%)	
07/02 06:16:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][550/703]	Step 15334	lr 0.09881	Loss 1.7163 (2.0071)	Prec@(1,5) (45.4%, 77.6%)	
07/02 06:16:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][600/703]	Step 15384	lr 0.09881	Loss 2.3155 (2.0074)	Prec@(1,5) (45.4%, 77.6%)	
07/02 06:16:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][650/703]	Step 15434	lr 0.09881	Loss 2.0833 (2.0087)	Prec@(1,5) (45.4%, 77.6%)	
07/02 06:16:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][700/703]	Step 15484	lr 0.09881	Loss 2.3123 (2.0107)	Prec@(1,5) (45.3%, 77.6%)	
07/02 06:16:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [21][703/703]	Step 15487	lr 0.09881	Loss 2.1513 (2.0111)	Prec@(1,5) (45.3%, 77.6%)	
07/02 06:16:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 21/299] Final Prec@1 45.3244%
07/02 06:16:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [21][50/79]	Step 15488	Loss 2.2827	Prec@(1,5) (40.5%, 72.9%)
07/02 06:16:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [21][78/79]	Step 15488	Loss 2.3048	Prec@(1,5) (39.5%, 72.5%)
07/02 06:16:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 21/299] Final Prec@1 39.4200%
07/02 06:16:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0400%
07/02 06:16:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][50/703]	Step 15538	lr 0.09869	Loss 2.1012 (1.9746)	Prec@(1,5) (45.8%, 78.6%)	
07/02 06:16:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][100/703]	Step 15588	lr 0.09869	Loss 2.1384 (1.9599)	Prec@(1,5) (45.9%, 78.5%)	
07/02 06:16:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][150/703]	Step 15638	lr 0.09869	Loss 2.0023 (1.9552)	Prec@(1,5) (46.3%, 78.7%)	
07/02 06:16:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][200/703]	Step 15688	lr 0.09869	Loss 1.8150 (1.9686)	Prec@(1,5) (46.0%, 78.4%)	
07/02 06:16:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][250/703]	Step 15738	lr 0.09869	Loss 1.9698 (1.9695)	Prec@(1,5) (46.3%, 78.4%)	
07/02 06:16:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][300/703]	Step 15788	lr 0.09869	Loss 2.3095 (1.9709)	Prec@(1,5) (46.1%, 78.3%)	
07/02 06:16:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][350/703]	Step 15838	lr 0.09869	Loss 1.6831 (1.9780)	Prec@(1,5) (46.1%, 78.1%)	
07/02 06:16:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][400/703]	Step 15888	lr 0.09869	Loss 2.3274 (1.9834)	Prec@(1,5) (46.0%, 78.1%)	
07/02 06:16:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][450/703]	Step 15938	lr 0.09869	Loss 1.6253 (1.9884)	Prec@(1,5) (45.9%, 78.0%)	
07/02 06:16:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][500/703]	Step 15988	lr 0.09869	Loss 1.8947 (1.9902)	Prec@(1,5) (45.9%, 77.9%)	
07/02 06:16:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][550/703]	Step 16038	lr 0.09869	Loss 1.8020 (1.9880)	Prec@(1,5) (45.9%, 78.0%)	
07/02 06:16:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][600/703]	Step 16088	lr 0.09869	Loss 2.2499 (1.9948)	Prec@(1,5) (45.8%, 77.9%)	
07/02 06:16:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][650/703]	Step 16138	lr 0.09869	Loss 2.0477 (1.9952)	Prec@(1,5) (45.8%, 77.9%)	
07/02 06:17:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][700/703]	Step 16188	lr 0.09869	Loss 2.2058 (1.9980)	Prec@(1,5) (45.8%, 77.7%)	
07/02 06:17:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [22][703/703]	Step 16191	lr 0.09869	Loss 2.3068 (1.9993)	Prec@(1,5) (45.8%, 77.7%)	
07/02 06:17:02午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 22/299] Final Prec@1 45.7600%
07/02 06:17:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [22][50/79]	Step 16192	Loss 2.3089	Prec@(1,5) (39.6%, 71.8%)
07/02 06:17:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [22][78/79]	Step 16192	Loss 2.3284	Prec@(1,5) (39.4%, 71.7%)
07/02 06:17:03午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 22/299] Final Prec@1 39.4800%
07/02 06:17:04午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0400%
07/02 06:17:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][50/703]	Step 16242	lr 0.09857	Loss 1.7105 (1.9235)	Prec@(1,5) (46.2%, 79.3%)	
07/02 06:17:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][100/703]	Step 16292	lr 0.09857	Loss 2.2181 (1.9062)	Prec@(1,5) (47.3%, 79.6%)	
07/02 06:17:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][150/703]	Step 16342	lr 0.09857	Loss 2.0889 (1.9243)	Prec@(1,5) (47.1%, 79.0%)	
07/02 06:17:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][200/703]	Step 16392	lr 0.09857	Loss 2.1042 (1.9345)	Prec@(1,5) (47.0%, 78.8%)	
07/02 06:17:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][250/703]	Step 16442	lr 0.09857	Loss 2.1227 (1.9448)	Prec@(1,5) (46.8%, 78.8%)	
07/02 06:17:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][300/703]	Step 16492	lr 0.09857	Loss 2.0810 (1.9507)	Prec@(1,5) (46.8%, 78.7%)	
07/02 06:17:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][350/703]	Step 16542	lr 0.09857	Loss 1.7008 (1.9511)	Prec@(1,5) (46.8%, 78.7%)	
07/02 06:17:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][400/703]	Step 16592	lr 0.09857	Loss 1.9171 (1.9466)	Prec@(1,5) (47.0%, 78.8%)	
07/02 06:17:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][450/703]	Step 16642	lr 0.09857	Loss 2.0279 (1.9554)	Prec@(1,5) (46.9%, 78.6%)	
07/02 06:17:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][500/703]	Step 16692	lr 0.09857	Loss 2.0069 (1.9614)	Prec@(1,5) (46.7%, 78.5%)	
07/02 06:17:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][550/703]	Step 16742	lr 0.09857	Loss 1.9204 (1.9650)	Prec@(1,5) (46.6%, 78.4%)	
07/02 06:17:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][600/703]	Step 16792	lr 0.09857	Loss 2.1829 (1.9724)	Prec@(1,5) (46.5%, 78.3%)	
07/02 06:17:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][650/703]	Step 16842	lr 0.09857	Loss 1.8622 (1.9746)	Prec@(1,5) (46.4%, 78.3%)	
07/02 06:17:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][700/703]	Step 16892	lr 0.09857	Loss 1.8301 (1.9758)	Prec@(1,5) (46.3%, 78.3%)	
07/02 06:17:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [23][703/703]	Step 16895	lr 0.09857	Loss 2.2054 (1.9766)	Prec@(1,5) (46.3%, 78.3%)	
07/02 06:17:48午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 23/299] Final Prec@1 46.2800%
07/02 06:17:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [23][50/79]	Step 16896	Loss 2.2774	Prec@(1,5) (41.5%, 73.2%)
07/02 06:17:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [23][78/79]	Step 16896	Loss 2.2793	Prec@(1,5) (41.0%, 72.7%)
07/02 06:17:50午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 23/299] Final Prec@1 41.0000%
07/02 06:17:50午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0400%
07/02 06:17:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][50/703]	Step 16946	lr 0.09844	Loss 1.6197 (1.9602)	Prec@(1,5) (47.0%, 78.3%)	
07/02 06:17:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][100/703]	Step 16996	lr 0.09844	Loss 2.2554 (1.9338)	Prec@(1,5) (47.5%, 79.4%)	
07/02 06:18:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][150/703]	Step 17046	lr 0.09844	Loss 2.3322 (1.9472)	Prec@(1,5) (47.1%, 78.9%)	
07/02 06:18:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][200/703]	Step 17096	lr 0.09844	Loss 1.5894 (1.9322)	Prec@(1,5) (47.3%, 79.2%)	
07/02 06:18:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][250/703]	Step 17146	lr 0.09844	Loss 1.9815 (1.9337)	Prec@(1,5) (47.3%, 79.2%)	
07/02 06:18:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][300/703]	Step 17196	lr 0.09844	Loss 2.0191 (1.9392)	Prec@(1,5) (47.2%, 79.2%)	
07/02 06:18:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][350/703]	Step 17246	lr 0.09844	Loss 1.9791 (1.9381)	Prec@(1,5) (47.3%, 79.1%)	
07/02 06:18:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][400/703]	Step 17296	lr 0.09844	Loss 1.6754 (1.9473)	Prec@(1,5) (47.1%, 78.9%)	
07/02 06:18:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][450/703]	Step 17346	lr 0.09844	Loss 1.9942 (1.9478)	Prec@(1,5) (47.2%, 78.9%)	
07/02 06:18:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][500/703]	Step 17396	lr 0.09844	Loss 1.9495 (1.9525)	Prec@(1,5) (47.0%, 78.8%)	
07/02 06:18:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][550/703]	Step 17446	lr 0.09844	Loss 2.1750 (1.9542)	Prec@(1,5) (47.0%, 78.8%)	
07/02 06:18:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][600/703]	Step 17496	lr 0.09844	Loss 1.8195 (1.9581)	Prec@(1,5) (46.9%, 78.7%)	
07/02 06:18:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][650/703]	Step 17546	lr 0.09844	Loss 1.8139 (1.9596)	Prec@(1,5) (46.8%, 78.7%)	
07/02 06:18:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][700/703]	Step 17596	lr 0.09844	Loss 1.6339 (1.9636)	Prec@(1,5) (46.7%, 78.6%)	
07/02 06:18:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [24][703/703]	Step 17599	lr 0.09844	Loss 1.9895 (1.9635)	Prec@(1,5) (46.7%, 78.6%)	
07/02 06:18:35午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 24/299] Final Prec@1 46.7200%
07/02 06:18:37午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [24][50/79]	Step 17600	Loss 2.3361	Prec@(1,5) (40.0%, 71.9%)
07/02 06:18:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [24][78/79]	Step 17600	Loss 2.3145	Prec@(1,5) (40.4%, 72.2%)
07/02 06:18:38午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 24/299] Final Prec@1 40.3800%
07/02 06:18:38午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0400%
07/02 06:18:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][50/703]	Step 17650	lr 0.09831	Loss 1.7269 (1.9552)	Prec@(1,5) (46.6%, 78.6%)	
07/02 06:18:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][100/703]	Step 17700	lr 0.09831	Loss 1.9005 (1.8873)	Prec@(1,5) (48.7%, 79.9%)	
07/02 06:18:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][150/703]	Step 17750	lr 0.09831	Loss 1.7597 (1.9023)	Prec@(1,5) (48.2%, 79.5%)	
07/02 06:18:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][200/703]	Step 17800	lr 0.09831	Loss 2.0955 (1.9150)	Prec@(1,5) (47.7%, 79.4%)	
07/02 06:18:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][250/703]	Step 17850	lr 0.09831	Loss 1.6958 (1.9229)	Prec@(1,5) (47.5%, 79.2%)	
07/02 06:18:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][300/703]	Step 17900	lr 0.09831	Loss 1.6766 (1.9175)	Prec@(1,5) (47.6%, 79.3%)	
07/02 06:19:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][350/703]	Step 17950	lr 0.09831	Loss 2.0292 (1.9172)	Prec@(1,5) (47.7%, 79.2%)	
07/02 06:19:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][400/703]	Step 18000	lr 0.09831	Loss 2.0725 (1.9254)	Prec@(1,5) (47.6%, 79.1%)	
07/02 06:19:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][450/703]	Step 18050	lr 0.09831	Loss 1.9725 (1.9301)	Prec@(1,5) (47.5%, 79.0%)	
07/02 06:19:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][500/703]	Step 18100	lr 0.09831	Loss 2.2959 (1.9379)	Prec@(1,5) (47.3%, 78.9%)	
07/02 06:19:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][550/703]	Step 18150	lr 0.09831	Loss 1.9920 (1.9343)	Prec@(1,5) (47.4%, 79.0%)	
07/02 06:19:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][600/703]	Step 18200	lr 0.09831	Loss 2.0507 (1.9410)	Prec@(1,5) (47.3%, 78.8%)	
07/02 06:19:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][650/703]	Step 18250	lr 0.09831	Loss 1.8106 (1.9407)	Prec@(1,5) (47.3%, 78.9%)	
07/02 06:19:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][700/703]	Step 18300	lr 0.09831	Loss 1.7705 (1.9433)	Prec@(1,5) (47.2%, 78.9%)	
07/02 06:19:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [25][703/703]	Step 18303	lr 0.09831	Loss 1.7138 (1.9423)	Prec@(1,5) (47.2%, 78.9%)	
07/02 06:19:22午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 25/299] Final Prec@1 47.1933%
07/02 06:19:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [25][50/79]	Step 18304	Loss 2.2183	Prec@(1,5) (41.8%, 73.3%)
07/02 06:19:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [25][78/79]	Step 18304	Loss 2.2154	Prec@(1,5) (41.8%, 73.3%)
07/02 06:19:23午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 25/299] Final Prec@1 41.7800%
07/02 06:19:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0400%
07/02 06:19:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][50/703]	Step 18354	lr 0.09818	Loss 1.8598 (1.9134)	Prec@(1,5) (47.5%, 80.1%)	
07/02 06:19:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][100/703]	Step 18404	lr 0.09818	Loss 1.7878 (1.8839)	Prec@(1,5) (48.6%, 80.3%)	
07/02 06:19:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][150/703]	Step 18454	lr 0.09818	Loss 2.0968 (1.8786)	Prec@(1,5) (48.5%, 80.2%)	
07/02 06:19:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][200/703]	Step 18504	lr 0.09818	Loss 1.8857 (1.8856)	Prec@(1,5) (48.5%, 80.0%)	
07/02 06:19:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][250/703]	Step 18554	lr 0.09818	Loss 2.1229 (1.9057)	Prec@(1,5) (47.9%, 79.8%)	
07/02 06:19:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][300/703]	Step 18604	lr 0.09818	Loss 1.7176 (1.9023)	Prec@(1,5) (47.9%, 79.8%)	
07/02 06:19:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][350/703]	Step 18654	lr 0.09818	Loss 1.6514 (1.9059)	Prec@(1,5) (47.7%, 79.6%)	
07/02 06:19:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][400/703]	Step 18704	lr 0.09818	Loss 2.1538 (1.9085)	Prec@(1,5) (47.7%, 79.5%)	
07/02 06:19:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][450/703]	Step 18754	lr 0.09818	Loss 1.8987 (1.9102)	Prec@(1,5) (47.6%, 79.5%)	
07/02 06:19:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][500/703]	Step 18804	lr 0.09818	Loss 2.1689 (1.9130)	Prec@(1,5) (47.6%, 79.5%)	
07/02 06:19:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][550/703]	Step 18854	lr 0.09818	Loss 2.1368 (1.9151)	Prec@(1,5) (47.5%, 79.4%)	
07/02 06:20:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][600/703]	Step 18904	lr 0.09818	Loss 1.5726 (1.9192)	Prec@(1,5) (47.4%, 79.3%)	
07/02 06:20:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][650/703]	Step 18954	lr 0.09818	Loss 2.4100 (1.9209)	Prec@(1,5) (47.4%, 79.3%)	
07/02 06:20:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][700/703]	Step 19004	lr 0.09818	Loss 1.7658 (1.9221)	Prec@(1,5) (47.4%, 79.3%)	
07/02 06:20:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [26][703/703]	Step 19007	lr 0.09818	Loss 1.6187 (1.9212)	Prec@(1,5) (47.4%, 79.3%)	
07/02 06:20:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 26/299] Final Prec@1 47.4222%
07/02 06:20:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [26][50/79]	Step 19008	Loss 2.2276	Prec@(1,5) (41.6%, 74.2%)
07/02 06:20:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [26][78/79]	Step 19008	Loss 2.2403	Prec@(1,5) (42.0%, 73.9%)
07/02 06:20:11午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 26/299] Final Prec@1 42.0600%
07/02 06:20:12午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0600%
07/02 06:20:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][50/703]	Step 19058	lr 0.09803	Loss 1.9891 (1.9307)	Prec@(1,5) (46.9%, 79.9%)	
07/02 06:20:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][100/703]	Step 19108	lr 0.09803	Loss 1.9629 (1.8787)	Prec@(1,5) (48.6%, 80.3%)	
07/02 06:20:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][150/703]	Step 19158	lr 0.09803	Loss 2.1024 (1.8909)	Prec@(1,5) (48.2%, 79.9%)	
07/02 06:20:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][200/703]	Step 19208	lr 0.09803	Loss 1.6138 (1.8832)	Prec@(1,5) (48.4%, 80.1%)	
07/02 06:20:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][250/703]	Step 19258	lr 0.09803	Loss 1.7823 (1.8785)	Prec@(1,5) (48.6%, 80.1%)	
07/02 06:20:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][300/703]	Step 19308	lr 0.09803	Loss 1.5829 (1.8905)	Prec@(1,5) (48.2%, 79.9%)	
07/02 06:20:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][350/703]	Step 19358	lr 0.09803	Loss 1.6372 (1.8904)	Prec@(1,5) (48.2%, 80.0%)	
07/02 06:20:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][400/703]	Step 19408	lr 0.09803	Loss 2.0741 (1.8970)	Prec@(1,5) (48.0%, 79.8%)	
07/02 06:20:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][450/703]	Step 19458	lr 0.09803	Loss 1.8116 (1.8926)	Prec@(1,5) (48.1%, 79.9%)	
07/02 06:20:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][500/703]	Step 19508	lr 0.09803	Loss 1.9194 (1.9018)	Prec@(1,5) (48.1%, 79.7%)	
07/02 06:20:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][550/703]	Step 19558	lr 0.09803	Loss 1.8333 (1.9048)	Prec@(1,5) (48.0%, 79.6%)	
07/02 06:20:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][600/703]	Step 19608	lr 0.09803	Loss 2.3472 (1.9102)	Prec@(1,5) (47.9%, 79.5%)	
07/02 06:20:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][650/703]	Step 19658	lr 0.09803	Loss 1.9155 (1.9134)	Prec@(1,5) (47.7%, 79.5%)	
07/02 06:20:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][700/703]	Step 19708	lr 0.09803	Loss 1.8073 (1.9174)	Prec@(1,5) (47.6%, 79.4%)	
07/02 06:20:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [27][703/703]	Step 19711	lr 0.09803	Loss 2.2588 (1.9177)	Prec@(1,5) (47.7%, 79.4%)	
07/02 06:20:57午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 27/299] Final Prec@1 47.6533%
07/02 06:20:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [27][50/79]	Step 19712	Loss 2.2351	Prec@(1,5) (41.2%, 74.3%)
07/02 06:20:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [27][78/79]	Step 19712	Loss 2.2290	Prec@(1,5) (41.2%, 74.3%)
07/02 06:20:59午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 27/299] Final Prec@1 41.2600%
07/02 06:20:59午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.0600%
07/02 06:21:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][50/703]	Step 19762	lr 0.09789	Loss 1.3558 (1.8271)	Prec@(1,5) (49.8%, 81.1%)	
07/02 06:21:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][100/703]	Step 19812	lr 0.09789	Loss 1.8193 (1.8477)	Prec@(1,5) (49.7%, 80.5%)	
07/02 06:21:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][150/703]	Step 19862	lr 0.09789	Loss 1.6998 (1.8490)	Prec@(1,5) (49.4%, 80.5%)	
07/02 06:21:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][200/703]	Step 19912	lr 0.09789	Loss 1.9518 (1.8515)	Prec@(1,5) (49.3%, 80.4%)	
07/02 06:21:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][250/703]	Step 19962	lr 0.09789	Loss 2.0083 (1.8521)	Prec@(1,5) (49.2%, 80.5%)	
07/02 06:21:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][300/703]	Step 20012	lr 0.09789	Loss 1.6794 (1.8612)	Prec@(1,5) (49.1%, 80.3%)	
07/02 06:21:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][350/703]	Step 20062	lr 0.09789	Loss 1.9798 (1.8730)	Prec@(1,5) (48.6%, 80.2%)	
07/02 06:21:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][400/703]	Step 20112	lr 0.09789	Loss 2.1372 (1.8807)	Prec@(1,5) (48.4%, 80.0%)	
07/02 06:21:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][450/703]	Step 20162	lr 0.09789	Loss 2.0886 (1.8872)	Prec@(1,5) (48.2%, 79.9%)	
07/02 06:21:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][500/703]	Step 20212	lr 0.09789	Loss 2.1044 (1.8907)	Prec@(1,5) (48.1%, 79.9%)	
07/02 06:21:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][550/703]	Step 20262	lr 0.09789	Loss 1.6312 (1.8914)	Prec@(1,5) (48.1%, 79.8%)	
07/02 06:21:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][600/703]	Step 20312	lr 0.09789	Loss 1.7222 (1.8951)	Prec@(1,5) (48.1%, 79.7%)	
07/02 06:21:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][650/703]	Step 20362	lr 0.09789	Loss 2.0760 (1.8936)	Prec@(1,5) (48.1%, 79.8%)	
07/02 06:21:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][700/703]	Step 20412	lr 0.09789	Loss 2.0734 (1.8987)	Prec@(1,5) (48.2%, 79.7%)	
07/02 06:21:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [28][703/703]	Step 20415	lr 0.09789	Loss 2.1172 (1.8988)	Prec@(1,5) (48.2%, 79.7%)	
07/02 06:21:43午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 28/299] Final Prec@1 48.1578%
07/02 06:21:44午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [28][50/79]	Step 20416	Loss 2.1572	Prec@(1,5) (42.6%, 75.0%)
07/02 06:21:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [28][78/79]	Step 20416	Loss 2.1534	Prec@(1,5) (43.0%, 74.8%)
07/02 06:21:45午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 28/299] Final Prec@1 42.9800%
07/02 06:21:45午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 42.9800%
07/02 06:21:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][50/703]	Step 20466	lr 0.09773	Loss 1.8707 (1.8248)	Prec@(1,5) (50.0%, 81.4%)	
07/02 06:21:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][100/703]	Step 20516	lr 0.09773	Loss 1.7828 (1.8516)	Prec@(1,5) (49.7%, 81.2%)	
07/02 06:21:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][150/703]	Step 20566	lr 0.09773	Loss 1.9135 (1.8301)	Prec@(1,5) (49.9%, 81.5%)	
07/02 06:21:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][200/703]	Step 20616	lr 0.09773	Loss 1.4446 (1.8348)	Prec@(1,5) (49.7%, 81.4%)	
07/02 06:22:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][250/703]	Step 20666	lr 0.09773	Loss 2.0601 (1.8435)	Prec@(1,5) (49.4%, 81.1%)	
07/02 06:22:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][300/703]	Step 20716	lr 0.09773	Loss 1.9304 (1.8517)	Prec@(1,5) (49.1%, 80.9%)	
07/02 06:22:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][350/703]	Step 20766	lr 0.09773	Loss 1.8623 (1.8524)	Prec@(1,5) (49.2%, 80.9%)	
07/02 06:22:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][400/703]	Step 20816	lr 0.09773	Loss 1.9235 (1.8617)	Prec@(1,5) (48.9%, 80.6%)	
07/02 06:22:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][450/703]	Step 20866	lr 0.09773	Loss 1.8822 (1.8634)	Prec@(1,5) (49.0%, 80.6%)	
07/02 06:22:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][500/703]	Step 20916	lr 0.09773	Loss 1.9513 (1.8605)	Prec@(1,5) (49.0%, 80.6%)	
07/02 06:22:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][550/703]	Step 20966	lr 0.09773	Loss 2.0055 (1.8655)	Prec@(1,5) (48.8%, 80.4%)	
07/02 06:22:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][600/703]	Step 21016	lr 0.09773	Loss 1.8061 (1.8714)	Prec@(1,5) (48.7%, 80.4%)	
07/02 06:22:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][650/703]	Step 21066	lr 0.09773	Loss 1.8991 (1.8762)	Prec@(1,5) (48.6%, 80.3%)	
07/02 06:22:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][700/703]	Step 21116	lr 0.09773	Loss 1.5502 (1.8758)	Prec@(1,5) (48.6%, 80.3%)	
07/02 06:22:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [29][703/703]	Step 21119	lr 0.09773	Loss 1.7523 (1.8757)	Prec@(1,5) (48.6%, 80.3%)	
07/02 06:22:30午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 29/299] Final Prec@1 48.5511%
07/02 06:22:32午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [29][50/79]	Step 21120	Loss 2.1178	Prec@(1,5) (44.4%, 75.5%)
07/02 06:22:32午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [29][78/79]	Step 21120	Loss 2.1400	Prec@(1,5) (44.1%, 75.1%)
07/02 06:22:32午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 29/299] Final Prec@1 44.1000%
07/02 06:22:33午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.1000%
07/02 06:22:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][50/703]	Step 21170	lr 0.09758	Loss 1.6008 (1.8774)	Prec@(1,5) (48.8%, 80.3%)	
07/02 06:22:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][100/703]	Step 21220	lr 0.09758	Loss 1.6038 (1.8283)	Prec@(1,5) (50.1%, 80.8%)	
07/02 06:22:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][150/703]	Step 21270	lr 0.09758	Loss 1.5810 (1.8337)	Prec@(1,5) (49.8%, 80.7%)	
07/02 06:22:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][200/703]	Step 21320	lr 0.09758	Loss 1.7742 (1.8417)	Prec@(1,5) (49.8%, 80.6%)	
07/02 06:22:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][250/703]	Step 21370	lr 0.09758	Loss 1.9199 (1.8532)	Prec@(1,5) (49.5%, 80.3%)	
07/02 06:22:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][300/703]	Step 21420	lr 0.09758	Loss 1.4625 (1.8586)	Prec@(1,5) (49.3%, 80.2%)	
07/02 06:22:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][350/703]	Step 21470	lr 0.09758	Loss 1.7286 (1.8630)	Prec@(1,5) (49.1%, 80.2%)	
07/02 06:22:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][400/703]	Step 21520	lr 0.09758	Loss 2.1995 (1.8704)	Prec@(1,5) (49.1%, 80.1%)	
07/02 06:23:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][450/703]	Step 21570	lr 0.09758	Loss 1.9414 (1.8672)	Prec@(1,5) (49.1%, 80.2%)	
07/02 06:23:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][500/703]	Step 21620	lr 0.09758	Loss 2.1724 (1.8729)	Prec@(1,5) (49.1%, 80.2%)	
07/02 06:23:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][550/703]	Step 21670	lr 0.09758	Loss 2.0963 (1.8759)	Prec@(1,5) (49.0%, 80.1%)	
07/02 06:23:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][600/703]	Step 21720	lr 0.09758	Loss 2.0571 (1.8727)	Prec@(1,5) (49.1%, 80.2%)	
07/02 06:23:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][650/703]	Step 21770	lr 0.09758	Loss 2.1025 (1.8777)	Prec@(1,5) (48.9%, 80.0%)	
07/02 06:23:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][700/703]	Step 21820	lr 0.09758	Loss 1.8043 (1.8789)	Prec@(1,5) (48.9%, 80.0%)	
07/02 06:23:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [30][703/703]	Step 21823	lr 0.09758	Loss 2.0025 (1.8781)	Prec@(1,5) (48.9%, 80.0%)	
07/02 06:23:17午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 30/299] Final Prec@1 48.8889%
07/02 06:23:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [30][50/79]	Step 21824	Loss 2.1722	Prec@(1,5) (43.5%, 74.5%)
07/02 06:23:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [30][78/79]	Step 21824	Loss 2.1661	Prec@(1,5) (43.1%, 75.1%)
07/02 06:23:19午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 30/299] Final Prec@1 43.0800%
07/02 06:23:19午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.1000%
07/02 06:23:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][50/703]	Step 21874	lr 0.09741	Loss 1.7438 (1.7984)	Prec@(1,5) (50.4%, 81.5%)	
07/02 06:23:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][100/703]	Step 21924	lr 0.09741	Loss 1.9276 (1.7950)	Prec@(1,5) (50.4%, 81.4%)	
07/02 06:23:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][150/703]	Step 21974	lr 0.09741	Loss 1.7644 (1.7927)	Prec@(1,5) (50.4%, 81.6%)	
07/02 06:23:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][200/703]	Step 22024	lr 0.09741	Loss 2.2112 (1.8121)	Prec@(1,5) (50.3%, 81.1%)	
07/02 06:23:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][250/703]	Step 22074	lr 0.09741	Loss 1.8931 (1.8190)	Prec@(1,5) (50.0%, 80.9%)	
07/02 06:23:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][300/703]	Step 22124	lr 0.09741	Loss 1.6726 (1.8295)	Prec@(1,5) (49.8%, 80.6%)	
07/02 06:23:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][350/703]	Step 22174	lr 0.09741	Loss 2.1442 (1.8363)	Prec@(1,5) (49.6%, 80.5%)	
07/02 06:23:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][400/703]	Step 22224	lr 0.09741	Loss 2.0555 (1.8411)	Prec@(1,5) (49.5%, 80.4%)	
07/02 06:23:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][450/703]	Step 22274	lr 0.09741	Loss 1.8634 (1.8445)	Prec@(1,5) (49.4%, 80.3%)	
07/02 06:23:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][500/703]	Step 22324	lr 0.09741	Loss 2.0805 (1.8471)	Prec@(1,5) (49.3%, 80.3%)	
07/02 06:23:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][550/703]	Step 22374	lr 0.09741	Loss 2.1968 (1.8524)	Prec@(1,5) (49.1%, 80.3%)	
07/02 06:23:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][600/703]	Step 22424	lr 0.09741	Loss 2.2696 (1.8560)	Prec@(1,5) (49.1%, 80.2%)	
07/02 06:23:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][650/703]	Step 22474	lr 0.09741	Loss 2.0186 (1.8562)	Prec@(1,5) (49.1%, 80.2%)	
07/02 06:24:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][700/703]	Step 22524	lr 0.09741	Loss 1.6891 (1.8606)	Prec@(1,5) (48.9%, 80.1%)	
07/02 06:24:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [31][703/703]	Step 22527	lr 0.09741	Loss 1.8921 (1.8614)	Prec@(1,5) (48.9%, 80.1%)	
07/02 06:24:03午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 31/299] Final Prec@1 48.9111%
07/02 06:24:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [31][50/79]	Step 22528	Loss 2.1763	Prec@(1,5) (41.8%, 75.2%)
07/02 06:24:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [31][78/79]	Step 22528	Loss 2.1509	Prec@(1,5) (43.0%, 75.2%)
07/02 06:24:04午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 31/299] Final Prec@1 43.0400%
07/02 06:24:05午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.1000%
07/02 06:24:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][50/703]	Step 22578	lr 0.09725	Loss 1.3859 (1.7544)	Prec@(1,5) (51.0%, 82.2%)	
07/02 06:24:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][100/703]	Step 22628	lr 0.09725	Loss 1.8317 (1.7671)	Prec@(1,5) (51.1%, 81.9%)	
07/02 06:24:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][150/703]	Step 22678	lr 0.09725	Loss 1.6328 (1.7723)	Prec@(1,5) (51.0%, 82.0%)	
07/02 06:24:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][200/703]	Step 22728	lr 0.09725	Loss 1.7676 (1.7928)	Prec@(1,5) (50.5%, 81.5%)	
07/02 06:24:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][250/703]	Step 22778	lr 0.09725	Loss 1.8673 (1.8119)	Prec@(1,5) (50.1%, 81.3%)	
07/02 06:24:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][300/703]	Step 22828	lr 0.09725	Loss 1.3682 (1.8080)	Prec@(1,5) (50.1%, 81.4%)	
07/02 06:24:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][350/703]	Step 22878	lr 0.09725	Loss 1.7584 (1.8096)	Prec@(1,5) (50.0%, 81.3%)	
07/02 06:24:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][400/703]	Step 22928	lr 0.09725	Loss 1.6410 (1.8155)	Prec@(1,5) (50.0%, 81.2%)	
07/02 06:24:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][450/703]	Step 22978	lr 0.09725	Loss 1.9161 (1.8282)	Prec@(1,5) (49.7%, 80.9%)	
07/02 06:24:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][500/703]	Step 23028	lr 0.09725	Loss 1.9224 (1.8268)	Prec@(1,5) (49.9%, 80.8%)	
07/02 06:24:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][550/703]	Step 23078	lr 0.09725	Loss 1.8075 (1.8322)	Prec@(1,5) (49.8%, 80.8%)	
07/02 06:24:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][600/703]	Step 23128	lr 0.09725	Loss 2.0391 (1.8467)	Prec@(1,5) (49.5%, 80.5%)	
07/02 06:24:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][650/703]	Step 23178	lr 0.09725	Loss 2.1734 (1.8515)	Prec@(1,5) (49.3%, 80.4%)	
07/02 06:24:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][700/703]	Step 23228	lr 0.09725	Loss 1.9139 (1.8558)	Prec@(1,5) (49.3%, 80.3%)	
07/02 06:24:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [32][703/703]	Step 23231	lr 0.09725	Loss 1.4065 (1.8554)	Prec@(1,5) (49.3%, 80.3%)	
07/02 06:24:50午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 32/299] Final Prec@1 49.2711%
07/02 06:24:51午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [32][50/79]	Step 23232	Loss 2.0800	Prec@(1,5) (45.0%, 76.3%)
07/02 06:24:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [32][78/79]	Step 23232	Loss 2.0965	Prec@(1,5) (44.6%, 76.1%)
07/02 06:24:52午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 32/299] Final Prec@1 44.7000%
07/02 06:24:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:24:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][50/703]	Step 23282	lr 0.09707	Loss 1.5270 (1.7043)	Prec@(1,5) (52.3%, 83.5%)	
07/02 06:24:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][100/703]	Step 23332	lr 0.09707	Loss 1.8567 (1.7496)	Prec@(1,5) (51.6%, 82.4%)	
07/02 06:25:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][150/703]	Step 23382	lr 0.09707	Loss 1.4924 (1.7837)	Prec@(1,5) (50.9%, 81.8%)	
07/02 06:25:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][200/703]	Step 23432	lr 0.09707	Loss 1.7993 (1.7938)	Prec@(1,5) (50.7%, 81.6%)	
07/02 06:25:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][250/703]	Step 23482	lr 0.09707	Loss 1.7420 (1.7951)	Prec@(1,5) (50.7%, 81.6%)	
07/02 06:25:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][300/703]	Step 23532	lr 0.09707	Loss 2.1908 (1.8028)	Prec@(1,5) (50.5%, 81.4%)	
07/02 06:25:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][350/703]	Step 23582	lr 0.09707	Loss 1.7120 (1.8124)	Prec@(1,5) (50.1%, 81.4%)	
07/02 06:25:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][400/703]	Step 23632	lr 0.09707	Loss 1.5212 (1.8131)	Prec@(1,5) (50.1%, 81.3%)	
07/02 06:25:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][450/703]	Step 23682	lr 0.09707	Loss 2.3475 (1.8198)	Prec@(1,5) (50.0%, 81.1%)	
07/02 06:25:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][500/703]	Step 23732	lr 0.09707	Loss 1.6583 (1.8251)	Prec@(1,5) (49.9%, 81.1%)	
07/02 06:25:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][550/703]	Step 23782	lr 0.09707	Loss 1.9464 (1.8275)	Prec@(1,5) (49.9%, 81.0%)	
07/02 06:25:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][600/703]	Step 23832	lr 0.09707	Loss 1.7894 (1.8314)	Prec@(1,5) (49.8%, 80.9%)	
07/02 06:25:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][650/703]	Step 23882	lr 0.09707	Loss 1.6654 (1.8343)	Prec@(1,5) (49.7%, 80.8%)	
07/02 06:25:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][700/703]	Step 23932	lr 0.09707	Loss 1.8210 (1.8373)	Prec@(1,5) (49.7%, 80.8%)	
07/02 06:25:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [33][703/703]	Step 23935	lr 0.09707	Loss 1.9008 (1.8365)	Prec@(1,5) (49.7%, 80.8%)	
07/02 06:25:37午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 33/299] Final Prec@1 49.6889%
07/02 06:25:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [33][50/79]	Step 23936	Loss 2.1253	Prec@(1,5) (43.6%, 74.8%)
07/02 06:25:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [33][78/79]	Step 23936	Loss 2.1637	Prec@(1,5) (42.5%, 74.8%)
07/02 06:25:38午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 33/299] Final Prec@1 42.5200%
07/02 06:25:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:25:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][50/703]	Step 23986	lr 0.0969	Loss 1.7794 (1.7735)	Prec@(1,5) (51.8%, 82.2%)	
07/02 06:25:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][100/703]	Step 24036	lr 0.0969	Loss 2.1077 (1.7750)	Prec@(1,5) (51.1%, 82.2%)	
07/02 06:25:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][150/703]	Step 24086	lr 0.0969	Loss 1.9119 (1.7946)	Prec@(1,5) (50.6%, 81.9%)	
07/02 06:25:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][200/703]	Step 24136	lr 0.0969	Loss 1.5589 (1.7925)	Prec@(1,5) (50.5%, 81.9%)	
07/02 06:25:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][250/703]	Step 24186	lr 0.0969	Loss 1.8271 (1.7936)	Prec@(1,5) (50.3%, 82.0%)	
07/02 06:25:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][300/703]	Step 24236	lr 0.0969	Loss 2.2134 (1.8026)	Prec@(1,5) (50.1%, 81.7%)	
07/02 06:26:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][350/703]	Step 24286	lr 0.0969	Loss 1.7356 (1.7981)	Prec@(1,5) (50.2%, 81.7%)	
07/02 06:26:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][400/703]	Step 24336	lr 0.0969	Loss 1.8248 (1.8089)	Prec@(1,5) (50.0%, 81.6%)	
07/02 06:26:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][450/703]	Step 24386	lr 0.0969	Loss 2.1654 (1.8121)	Prec@(1,5) (49.9%, 81.5%)	
07/02 06:26:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][500/703]	Step 24436	lr 0.0969	Loss 2.1301 (1.8135)	Prec@(1,5) (49.9%, 81.4%)	
07/02 06:26:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][550/703]	Step 24486	lr 0.0969	Loss 2.0942 (1.8153)	Prec@(1,5) (50.0%, 81.3%)	
07/02 06:26:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][600/703]	Step 24536	lr 0.0969	Loss 2.0603 (1.8191)	Prec@(1,5) (49.9%, 81.3%)	
07/02 06:26:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][650/703]	Step 24586	lr 0.0969	Loss 1.9154 (1.8230)	Prec@(1,5) (49.7%, 81.2%)	
07/02 06:26:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][700/703]	Step 24636	lr 0.0969	Loss 1.9219 (1.8251)	Prec@(1,5) (49.7%, 81.1%)	
07/02 06:26:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [34][703/703]	Step 24639	lr 0.0969	Loss 2.1974 (1.8257)	Prec@(1,5) (49.7%, 81.1%)	
07/02 06:26:23午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 34/299] Final Prec@1 49.6933%
07/02 06:26:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [34][50/79]	Step 24640	Loss 2.2222	Prec@(1,5) (41.8%, 73.7%)
07/02 06:26:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [34][78/79]	Step 24640	Loss 2.2015	Prec@(1,5) (42.1%, 74.2%)
07/02 06:26:25午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 34/299] Final Prec@1 42.1400%
07/02 06:26:25午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:26:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][50/703]	Step 24690	lr 0.09671	Loss 1.9207 (1.7803)	Prec@(1,5) (51.1%, 81.9%)	
07/02 06:26:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][100/703]	Step 24740	lr 0.09671	Loss 1.8513 (1.7728)	Prec@(1,5) (51.3%, 82.1%)	
07/02 06:26:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][150/703]	Step 24790	lr 0.09671	Loss 1.8306 (1.7893)	Prec@(1,5) (50.7%, 81.9%)	
07/02 06:26:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][200/703]	Step 24840	lr 0.09671	Loss 1.7538 (1.7880)	Prec@(1,5) (50.7%, 81.6%)	
07/02 06:26:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][250/703]	Step 24890	lr 0.09671	Loss 1.9422 (1.7947)	Prec@(1,5) (50.6%, 81.3%)	
07/02 06:26:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][300/703]	Step 24940	lr 0.09671	Loss 1.6498 (1.7939)	Prec@(1,5) (50.6%, 81.1%)	
07/02 06:26:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][350/703]	Step 24990	lr 0.09671	Loss 1.6547 (1.8041)	Prec@(1,5) (50.5%, 81.0%)	
07/02 06:26:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][400/703]	Step 25040	lr 0.09671	Loss 1.4582 (1.8119)	Prec@(1,5) (50.4%, 80.9%)	
07/02 06:26:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][450/703]	Step 25090	lr 0.09671	Loss 1.6229 (1.8156)	Prec@(1,5) (50.2%, 80.9%)	
07/02 06:26:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][500/703]	Step 25140	lr 0.09671	Loss 1.5729 (1.8114)	Prec@(1,5) (50.3%, 80.9%)	
07/02 06:27:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][550/703]	Step 25190	lr 0.09671	Loss 1.7804 (1.8145)	Prec@(1,5) (50.2%, 81.0%)	
07/02 06:27:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][600/703]	Step 25240	lr 0.09671	Loss 2.3397 (1.8205)	Prec@(1,5) (50.0%, 80.9%)	
07/02 06:27:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][650/703]	Step 25290	lr 0.09671	Loss 1.8566 (1.8232)	Prec@(1,5) (49.9%, 80.9%)	
07/02 06:27:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][700/703]	Step 25340	lr 0.09671	Loss 1.5965 (1.8229)	Prec@(1,5) (50.0%, 80.9%)	
07/02 06:27:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [35][703/703]	Step 25343	lr 0.09671	Loss 1.5888 (1.8231)	Prec@(1,5) (50.0%, 80.9%)	
07/02 06:27:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 35/299] Final Prec@1 49.9756%
07/02 06:27:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [35][50/79]	Step 25344	Loss 2.2336	Prec@(1,5) (42.4%, 74.1%)
07/02 06:27:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [35][78/79]	Step 25344	Loss 2.2425	Prec@(1,5) (42.1%, 74.0%)
07/02 06:27:11午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 35/299] Final Prec@1 42.1600%
07/02 06:27:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:27:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][50/703]	Step 25394	lr 0.09652	Loss 1.5683 (1.7735)	Prec@(1,5) (50.7%, 82.3%)	
07/02 06:27:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][100/703]	Step 25444	lr 0.09652	Loss 2.1191 (1.7817)	Prec@(1,5) (50.8%, 81.4%)	
07/02 06:27:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][150/703]	Step 25494	lr 0.09652	Loss 1.3468 (1.7767)	Prec@(1,5) (51.0%, 81.7%)	
07/02 06:27:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][200/703]	Step 25544	lr 0.09652	Loss 1.6379 (1.7796)	Prec@(1,5) (50.9%, 81.7%)	
07/02 06:27:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][250/703]	Step 25594	lr 0.09652	Loss 1.7580 (1.7866)	Prec@(1,5) (50.4%, 81.5%)	
07/02 06:27:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][300/703]	Step 25644	lr 0.09652	Loss 1.4584 (1.7977)	Prec@(1,5) (50.2%, 81.3%)	
07/02 06:27:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][350/703]	Step 25694	lr 0.09652	Loss 1.7846 (1.7910)	Prec@(1,5) (50.4%, 81.4%)	
07/02 06:27:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][400/703]	Step 25744	lr 0.09652	Loss 1.9667 (1.7923)	Prec@(1,5) (50.4%, 81.4%)	
07/02 06:27:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][450/703]	Step 25794	lr 0.09652	Loss 1.9607 (1.8036)	Prec@(1,5) (50.1%, 81.2%)	
07/02 06:27:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][500/703]	Step 25844	lr 0.09652	Loss 1.6788 (1.8066)	Prec@(1,5) (50.1%, 81.2%)	
07/02 06:27:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][550/703]	Step 25894	lr 0.09652	Loss 1.7776 (1.8093)	Prec@(1,5) (50.0%, 81.2%)	
07/02 06:27:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][600/703]	Step 25944	lr 0.09652	Loss 1.9894 (1.8150)	Prec@(1,5) (49.9%, 81.1%)	
07/02 06:27:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][650/703]	Step 25994	lr 0.09652	Loss 1.6080 (1.8152)	Prec@(1,5) (49.9%, 81.1%)	
07/02 06:27:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][700/703]	Step 26044	lr 0.09652	Loss 1.8452 (1.8157)	Prec@(1,5) (49.9%, 81.2%)	
07/02 06:27:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [36][703/703]	Step 26047	lr 0.09652	Loss 1.5331 (1.8159)	Prec@(1,5) (49.9%, 81.2%)	
07/02 06:27:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 36/299] Final Prec@1 49.8733%
07/02 06:27:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [36][50/79]	Step 26048	Loss 2.1740	Prec@(1,5) (43.8%, 75.3%)
07/02 06:27:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [36][78/79]	Step 26048	Loss 2.1673	Prec@(1,5) (43.8%, 75.4%)
07/02 06:27:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 36/299] Final Prec@1 43.8400%
07/02 06:27:58午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:28:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][50/703]	Step 26098	lr 0.09633	Loss 2.0536 (1.7836)	Prec@(1,5) (49.8%, 81.8%)	
07/02 06:28:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][100/703]	Step 26148	lr 0.09633	Loss 1.3073 (1.7639)	Prec@(1,5) (50.6%, 82.0%)	
07/02 06:28:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][150/703]	Step 26198	lr 0.09633	Loss 1.6557 (1.7571)	Prec@(1,5) (50.7%, 82.4%)	
07/02 06:28:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][200/703]	Step 26248	lr 0.09633	Loss 1.6795 (1.7566)	Prec@(1,5) (50.8%, 82.5%)	
07/02 06:28:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][250/703]	Step 26298	lr 0.09633	Loss 1.5022 (1.7646)	Prec@(1,5) (50.8%, 82.2%)	
07/02 06:28:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][300/703]	Step 26348	lr 0.09633	Loss 2.0029 (1.7677)	Prec@(1,5) (50.9%, 82.1%)	
07/02 06:28:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][350/703]	Step 26398	lr 0.09633	Loss 1.8640 (1.7706)	Prec@(1,5) (50.7%, 82.1%)	
07/02 06:28:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][400/703]	Step 26448	lr 0.09633	Loss 1.9620 (1.7843)	Prec@(1,5) (50.4%, 81.8%)	
07/02 06:28:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][450/703]	Step 26498	lr 0.09633	Loss 1.8025 (1.7957)	Prec@(1,5) (50.2%, 81.7%)	
07/02 06:28:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][500/703]	Step 26548	lr 0.09633	Loss 1.4554 (1.7949)	Prec@(1,5) (50.2%, 81.7%)	
07/02 06:28:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][550/703]	Step 26598	lr 0.09633	Loss 1.9575 (1.7970)	Prec@(1,5) (50.2%, 81.7%)	
07/02 06:28:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][600/703]	Step 26648	lr 0.09633	Loss 1.9494 (1.8032)	Prec@(1,5) (50.0%, 81.6%)	
07/02 06:28:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][650/703]	Step 26698	lr 0.09633	Loss 1.8766 (1.8066)	Prec@(1,5) (50.0%, 81.4%)	
07/02 06:28:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][700/703]	Step 26748	lr 0.09633	Loss 1.8543 (1.8167)	Prec@(1,5) (49.7%, 81.2%)	
07/02 06:28:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [37][703/703]	Step 26751	lr 0.09633	Loss 2.1312 (1.8178)	Prec@(1,5) (49.7%, 81.2%)	
07/02 06:28:42午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 37/299] Final Prec@1 49.7222%
07/02 06:28:44午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [37][50/79]	Step 26752	Loss 2.3322	Prec@(1,5) (40.2%, 71.9%)
07/02 06:28:44午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [37][78/79]	Step 26752	Loss 2.3078	Prec@(1,5) (40.8%, 72.2%)
07/02 06:28:44午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 37/299] Final Prec@1 40.8200%
07/02 06:28:44午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:28:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][50/703]	Step 26802	lr 0.09613	Loss 1.7240 (1.8523)	Prec@(1,5) (49.7%, 80.2%)	
07/02 06:28:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][100/703]	Step 26852	lr 0.09613	Loss 1.7524 (1.8074)	Prec@(1,5) (50.5%, 80.9%)	
07/02 06:28:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][150/703]	Step 26902	lr 0.09613	Loss 1.6285 (1.8039)	Prec@(1,5) (50.7%, 81.1%)	
07/02 06:28:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][200/703]	Step 26952	lr 0.09613	Loss 1.4912 (1.7894)	Prec@(1,5) (50.9%, 81.6%)	
07/02 06:29:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][250/703]	Step 27002	lr 0.09613	Loss 2.2115 (1.7882)	Prec@(1,5) (51.0%, 81.7%)	
07/02 06:29:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][300/703]	Step 27052	lr 0.09613	Loss 2.1242 (1.8034)	Prec@(1,5) (50.5%, 81.4%)	
07/02 06:29:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][350/703]	Step 27102	lr 0.09613	Loss 2.1062 (1.8087)	Prec@(1,5) (50.4%, 81.3%)	
07/02 06:29:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][400/703]	Step 27152	lr 0.09613	Loss 1.5777 (1.8139)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:29:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][450/703]	Step 27202	lr 0.09613	Loss 2.0294 (1.8129)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:29:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][500/703]	Step 27252	lr 0.09613	Loss 1.9097 (1.8157)	Prec@(1,5) (50.1%, 81.1%)	
07/02 06:29:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][550/703]	Step 27302	lr 0.09613	Loss 2.0530 (1.8201)	Prec@(1,5) (50.1%, 81.1%)	
07/02 06:29:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][600/703]	Step 27352	lr 0.09613	Loss 1.7325 (1.8254)	Prec@(1,5) (49.9%, 80.9%)	
07/02 06:29:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][650/703]	Step 27402	lr 0.09613	Loss 1.5495 (1.8309)	Prec@(1,5) (49.8%, 80.8%)	
07/02 06:29:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][700/703]	Step 27452	lr 0.09613	Loss 1.6808 (1.8330)	Prec@(1,5) (49.7%, 80.8%)	
07/02 06:29:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [38][703/703]	Step 27455	lr 0.09613	Loss 1.5611 (1.8323)	Prec@(1,5) (49.8%, 80.8%)	
07/02 06:29:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 38/299] Final Prec@1 49.7489%
07/02 06:29:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [38][50/79]	Step 27456	Loss 2.1561	Prec@(1,5) (44.8%, 74.5%)
07/02 06:29:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [38][78/79]	Step 27456	Loss 2.1561	Prec@(1,5) (44.4%, 74.7%)
07/02 06:29:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 38/299] Final Prec@1 44.4600%
07/02 06:29:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 44.7000%
07/02 06:29:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][50/703]	Step 27506	lr 0.09593	Loss 1.5189 (1.7818)	Prec@(1,5) (51.2%, 82.2%)	
07/02 06:29:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][100/703]	Step 27556	lr 0.09593	Loss 1.6796 (1.7876)	Prec@(1,5) (51.0%, 82.0%)	
07/02 06:29:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][150/703]	Step 27606	lr 0.09593	Loss 1.7076 (1.7663)	Prec@(1,5) (51.6%, 82.4%)	
07/02 06:29:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][200/703]	Step 27656	lr 0.09593	Loss 1.6674 (1.7778)	Prec@(1,5) (51.2%, 82.1%)	
07/02 06:29:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][250/703]	Step 27706	lr 0.09593	Loss 1.8337 (1.7865)	Prec@(1,5) (50.9%, 81.8%)	
07/02 06:29:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][300/703]	Step 27756	lr 0.09593	Loss 2.0778 (1.7958)	Prec@(1,5) (50.5%, 81.6%)	
07/02 06:29:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][350/703]	Step 27806	lr 0.09593	Loss 1.8879 (1.8018)	Prec@(1,5) (50.4%, 81.3%)	
07/02 06:29:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][400/703]	Step 27856	lr 0.09593	Loss 2.1778 (1.8000)	Prec@(1,5) (50.5%, 81.4%)	
07/02 06:29:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][450/703]	Step 27906	lr 0.09593	Loss 1.6534 (1.8027)	Prec@(1,5) (50.3%, 81.3%)	
07/02 06:30:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][500/703]	Step 27956	lr 0.09593	Loss 1.7878 (1.8019)	Prec@(1,5) (50.3%, 81.3%)	
07/02 06:30:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][550/703]	Step 28006	lr 0.09593	Loss 2.3308 (1.8071)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:30:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][600/703]	Step 28056	lr 0.09593	Loss 2.0343 (1.8103)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:30:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][650/703]	Step 28106	lr 0.09593	Loss 1.8686 (1.8111)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:30:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][700/703]	Step 28156	lr 0.09593	Loss 1.6514 (1.8125)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:30:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [39][703/703]	Step 28159	lr 0.09593	Loss 1.4686 (1.8123)	Prec@(1,5) (50.2%, 81.2%)	
07/02 06:30:15午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 39/299] Final Prec@1 50.1556%
07/02 06:30:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [39][50/79]	Step 28160	Loss 2.0665	Prec@(1,5) (45.3%, 76.5%)
07/02 06:30:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [39][78/79]	Step 28160	Loss 2.0637	Prec@(1,5) (45.7%, 76.3%)
07/02 06:30:17午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 39/299] Final Prec@1 45.7000%
07/02 06:30:17午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 45.7000%
07/02 06:30:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][50/703]	Step 28210	lr 0.09572	Loss 1.9867 (1.7867)	Prec@(1,5) (50.6%, 82.2%)	
07/02 06:30:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][100/703]	Step 28260	lr 0.09572	Loss 1.4387 (1.7684)	Prec@(1,5) (51.3%, 82.1%)	
07/02 06:30:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][150/703]	Step 28310	lr 0.09572	Loss 1.8629 (1.7719)	Prec@(1,5) (50.5%, 82.3%)	
07/02 06:30:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][200/703]	Step 28360	lr 0.09572	Loss 1.8086 (1.7724)	Prec@(1,5) (50.7%, 82.2%)	
07/02 06:30:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][250/703]	Step 28410	lr 0.09572	Loss 1.8300 (1.7752)	Prec@(1,5) (50.7%, 82.2%)	
07/02 06:30:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][300/703]	Step 28460	lr 0.09572	Loss 1.5933 (1.7792)	Prec@(1,5) (50.5%, 82.0%)	
07/02 06:30:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][350/703]	Step 28510	lr 0.09572	Loss 1.8387 (1.7843)	Prec@(1,5) (50.5%, 81.9%)	
07/02 06:30:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][400/703]	Step 28560	lr 0.09572	Loss 1.4616 (1.7831)	Prec@(1,5) (50.6%, 81.9%)	
07/02 06:30:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][450/703]	Step 28610	lr 0.09572	Loss 1.4177 (1.7882)	Prec@(1,5) (50.5%, 81.7%)	
07/02 06:30:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][500/703]	Step 28660	lr 0.09572	Loss 2.4873 (1.7927)	Prec@(1,5) (50.4%, 81.6%)	
07/02 06:30:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][550/703]	Step 28710	lr 0.09572	Loss 1.5893 (1.7937)	Prec@(1,5) (50.3%, 81.7%)	
07/02 06:30:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][600/703]	Step 28760	lr 0.09572	Loss 1.8853 (1.7982)	Prec@(1,5) (50.3%, 81.6%)	
07/02 06:30:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][650/703]	Step 28810	lr 0.09572	Loss 1.9392 (1.8006)	Prec@(1,5) (50.3%, 81.6%)	
07/02 06:31:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][700/703]	Step 28860	lr 0.09572	Loss 1.3484 (1.8080)	Prec@(1,5) (50.1%, 81.4%)	
07/02 06:31:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [40][703/703]	Step 28863	lr 0.09572	Loss 1.6735 (1.8081)	Prec@(1,5) (50.1%, 81.4%)	
07/02 06:31:03午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 40/299] Final Prec@1 50.0933%
07/02 06:31:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [40][50/79]	Step 28864	Loss 2.2088	Prec@(1,5) (42.1%, 74.2%)
07/02 06:31:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [40][78/79]	Step 28864	Loss 2.2036	Prec@(1,5) (41.9%, 74.1%)
07/02 06:31:05午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 40/299] Final Prec@1 41.9000%
07/02 06:31:05午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 45.7000%
07/02 06:31:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][50/703]	Step 28914	lr 0.09551	Loss 1.6473 (1.7063)	Prec@(1,5) (52.2%, 83.0%)	
07/02 06:31:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][100/703]	Step 28964	lr 0.09551	Loss 1.8682 (1.7564)	Prec@(1,5) (51.2%, 82.5%)	
07/02 06:31:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][150/703]	Step 29014	lr 0.09551	Loss 1.7684 (1.7538)	Prec@(1,5) (51.4%, 82.3%)	
07/02 06:31:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][200/703]	Step 29064	lr 0.09551	Loss 1.5528 (1.7525)	Prec@(1,5) (51.3%, 82.5%)	
07/02 06:31:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][250/703]	Step 29114	lr 0.09551	Loss 1.9880 (1.7413)	Prec@(1,5) (51.7%, 82.7%)	
07/02 06:31:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][300/703]	Step 29164	lr 0.09551	Loss 1.8433 (1.7486)	Prec@(1,5) (51.5%, 82.6%)	
07/02 06:31:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][350/703]	Step 29214	lr 0.09551	Loss 2.1061 (1.7593)	Prec@(1,5) (51.2%, 82.3%)	
07/02 06:31:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][400/703]	Step 29264	lr 0.09551	Loss 1.8275 (1.7651)	Prec@(1,5) (51.2%, 82.2%)	
07/02 06:31:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][450/703]	Step 29314	lr 0.09551	Loss 2.0069 (1.7690)	Prec@(1,5) (51.1%, 82.1%)	
07/02 06:31:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][500/703]	Step 29364	lr 0.09551	Loss 1.9502 (1.7799)	Prec@(1,5) (50.9%, 81.9%)	
07/02 06:31:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][550/703]	Step 29414	lr 0.09551	Loss 1.7190 (1.7825)	Prec@(1,5) (50.9%, 81.8%)	
07/02 06:31:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][600/703]	Step 29464	lr 0.09551	Loss 2.0580 (1.7878)	Prec@(1,5) (50.8%, 81.7%)	
07/02 06:31:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][650/703]	Step 29514	lr 0.09551	Loss 1.8418 (1.7899)	Prec@(1,5) (50.7%, 81.7%)	
07/02 06:31:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][700/703]	Step 29564	lr 0.09551	Loss 1.8173 (1.7968)	Prec@(1,5) (50.5%, 81.5%)	
07/02 06:31:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [41][703/703]	Step 29567	lr 0.09551	Loss 2.1127 (1.7975)	Prec@(1,5) (50.5%, 81.5%)	
07/02 06:31:50午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 41/299] Final Prec@1 50.5311%
07/02 06:31:51午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [41][50/79]	Step 29568	Loss 2.1477	Prec@(1,5) (45.0%, 75.7%)
07/02 06:31:51午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [41][78/79]	Step 29568	Loss 2.1252	Prec@(1,5) (44.8%, 75.4%)
07/02 06:31:51午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 41/299] Final Prec@1 44.8400%
07/02 06:31:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 45.7000%
07/02 06:31:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][50/703]	Step 29618	lr 0.09529	Loss 1.4570 (1.6676)	Prec@(1,5) (53.1%, 83.7%)	
07/02 06:31:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][100/703]	Step 29668	lr 0.09529	Loss 1.7559 (1.7048)	Prec@(1,5) (52.3%, 83.4%)	
07/02 06:32:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][150/703]	Step 29718	lr 0.09529	Loss 1.6127 (1.7233)	Prec@(1,5) (51.8%, 83.1%)	
07/02 06:32:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][200/703]	Step 29768	lr 0.09529	Loss 1.7743 (1.7340)	Prec@(1,5) (51.7%, 82.8%)	
07/02 06:32:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][250/703]	Step 29818	lr 0.09529	Loss 1.9710 (1.7477)	Prec@(1,5) (51.4%, 82.6%)	
07/02 06:32:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][300/703]	Step 29868	lr 0.09529	Loss 1.5682 (1.7465)	Prec@(1,5) (51.4%, 82.7%)	
07/02 06:32:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][350/703]	Step 29918	lr 0.09529	Loss 1.7466 (1.7506)	Prec@(1,5) (51.3%, 82.5%)	
07/02 06:32:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][400/703]	Step 29968	lr 0.09529	Loss 1.9237 (1.7501)	Prec@(1,5) (51.3%, 82.6%)	
07/02 06:32:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][450/703]	Step 30018	lr 0.09529	Loss 1.9875 (1.7553)	Prec@(1,5) (51.1%, 82.5%)	
07/02 06:32:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][500/703]	Step 30068	lr 0.09529	Loss 1.5831 (1.7626)	Prec@(1,5) (51.0%, 82.3%)	
07/02 06:32:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][550/703]	Step 30118	lr 0.09529	Loss 2.0204 (1.7618)	Prec@(1,5) (51.1%, 82.3%)	
07/02 06:32:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][600/703]	Step 30168	lr 0.09529	Loss 1.8017 (1.7689)	Prec@(1,5) (51.0%, 82.1%)	
07/02 06:32:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][650/703]	Step 30218	lr 0.09529	Loss 1.9657 (1.7752)	Prec@(1,5) (50.8%, 82.0%)	
07/02 06:32:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][700/703]	Step 30268	lr 0.09529	Loss 2.2113 (1.7803)	Prec@(1,5) (50.7%, 81.9%)	
07/02 06:32:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [42][703/703]	Step 30271	lr 0.09529	Loss 1.5956 (1.7807)	Prec@(1,5) (50.7%, 81.9%)	
07/02 06:32:37午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 42/299] Final Prec@1 50.7267%
07/02 06:32:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [42][50/79]	Step 30272	Loss 2.1571	Prec@(1,5) (43.3%, 75.9%)
07/02 06:32:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [42][78/79]	Step 30272	Loss 2.1552	Prec@(1,5) (43.5%, 76.0%)
07/02 06:32:39午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 42/299] Final Prec@1 43.5400%
07/02 06:32:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 45.7000%
07/02 06:32:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][50/703]	Step 30322	lr 0.09507	Loss 1.5950 (1.7378)	Prec@(1,5) (51.6%, 83.2%)	
07/02 06:32:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][100/703]	Step 30372	lr 0.09507	Loss 1.9775 (1.6935)	Prec@(1,5) (52.3%, 83.5%)	
07/02 06:32:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][150/703]	Step 30422	lr 0.09507	Loss 1.6100 (1.7063)	Prec@(1,5) (51.8%, 83.3%)	
07/02 06:32:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][200/703]	Step 30472	lr 0.09507	Loss 1.8443 (1.7259)	Prec@(1,5) (51.3%, 83.1%)	
07/02 06:32:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][250/703]	Step 30522	lr 0.09507	Loss 2.1980 (1.7152)	Prec@(1,5) (51.7%, 83.2%)	
07/02 06:32:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][300/703]	Step 30572	lr 0.09507	Loss 1.7618 (1.7324)	Prec@(1,5) (51.6%, 82.9%)	
07/02 06:33:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][350/703]	Step 30622	lr 0.09507	Loss 1.8484 (1.7411)	Prec@(1,5) (51.3%, 82.7%)	
07/02 06:33:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][400/703]	Step 30672	lr 0.09507	Loss 2.0830 (1.7518)	Prec@(1,5) (51.0%, 82.6%)	
07/02 06:33:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][450/703]	Step 30722	lr 0.09507	Loss 1.9289 (1.7560)	Prec@(1,5) (51.0%, 82.4%)	
07/02 06:33:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][500/703]	Step 30772	lr 0.09507	Loss 1.7346 (1.7607)	Prec@(1,5) (51.0%, 82.3%)	
07/02 06:33:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][550/703]	Step 30822	lr 0.09507	Loss 1.4822 (1.7645)	Prec@(1,5) (51.0%, 82.2%)	
07/02 06:33:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][600/703]	Step 30872	lr 0.09507	Loss 1.7212 (1.7750)	Prec@(1,5) (50.8%, 82.0%)	
07/02 06:33:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][650/703]	Step 30922	lr 0.09507	Loss 1.8268 (1.7744)	Prec@(1,5) (50.8%, 81.9%)	
07/02 06:33:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][700/703]	Step 30972	lr 0.09507	Loss 1.5949 (1.7725)	Prec@(1,5) (50.9%, 82.0%)	
07/02 06:33:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [43][703/703]	Step 30975	lr 0.09507	Loss 1.9220 (1.7731)	Prec@(1,5) (50.9%, 82.0%)	
07/02 06:33:23午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 43/299] Final Prec@1 50.8978%
07/02 06:33:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [43][50/79]	Step 30976	Loss 2.1629	Prec@(1,5) (44.0%, 75.1%)
07/02 06:33:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [43][78/79]	Step 30976	Loss 2.1791	Prec@(1,5) (43.5%, 74.8%)
07/02 06:33:24午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 43/299] Final Prec@1 43.5400%
07/02 06:33:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 45.7000%
07/02 06:33:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][50/703]	Step 31026	lr 0.09484	Loss 1.8493 (1.6866)	Prec@(1,5) (52.9%, 83.7%)	
07/02 06:33:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][100/703]	Step 31076	lr 0.09484	Loss 1.8683 (1.7061)	Prec@(1,5) (52.5%, 83.5%)	
07/02 06:33:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][150/703]	Step 31126	lr 0.09484	Loss 1.7798 (1.7192)	Prec@(1,5) (52.0%, 83.2%)	
07/02 06:33:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][200/703]	Step 31176	lr 0.09484	Loss 1.7191 (1.7241)	Prec@(1,5) (51.9%, 83.1%)	
07/02 06:33:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][250/703]	Step 31226	lr 0.09484	Loss 1.8874 (1.7278)	Prec@(1,5) (51.8%, 83.1%)	
07/02 06:33:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][300/703]	Step 31276	lr 0.09484	Loss 1.8072 (1.7267)	Prec@(1,5) (51.9%, 83.2%)	
07/02 06:33:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][350/703]	Step 31326	lr 0.09484	Loss 1.5125 (1.7352)	Prec@(1,5) (51.8%, 82.9%)	
07/02 06:33:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][400/703]	Step 31376	lr 0.09484	Loss 1.7828 (1.7488)	Prec@(1,5) (51.6%, 82.6%)	
07/02 06:33:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][450/703]	Step 31426	lr 0.09484	Loss 1.6980 (1.7479)	Prec@(1,5) (51.5%, 82.7%)	
07/02 06:33:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][500/703]	Step 31476	lr 0.09484	Loss 1.7984 (1.7541)	Prec@(1,5) (51.4%, 82.5%)	
07/02 06:33:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][550/703]	Step 31526	lr 0.09484	Loss 1.4048 (1.7566)	Prec@(1,5) (51.3%, 82.4%)	
07/02 06:34:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][600/703]	Step 31576	lr 0.09484	Loss 1.7759 (1.7633)	Prec@(1,5) (51.2%, 82.2%)	
07/02 06:34:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][650/703]	Step 31626	lr 0.09484	Loss 2.4685 (1.7623)	Prec@(1,5) (51.2%, 82.2%)	
07/02 06:34:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][700/703]	Step 31676	lr 0.09484	Loss 1.7678 (1.7649)	Prec@(1,5) (51.2%, 82.1%)	
07/02 06:34:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [44][703/703]	Step 31679	lr 0.09484	Loss 1.9470 (1.7658)	Prec@(1,5) (51.1%, 82.1%)	
07/02 06:34:08午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 44/299] Final Prec@1 51.1356%
07/02 06:34:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [44][50/79]	Step 31680	Loss 2.0226	Prec@(1,5) (45.9%, 78.1%)
07/02 06:34:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [44][78/79]	Step 31680	Loss 2.0350	Prec@(1,5) (46.2%, 77.4%)
07/02 06:34:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 44/299] Final Prec@1 46.2800%
07/02 06:34:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:34:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][50/703]	Step 31730	lr 0.0946	Loss 1.8837 (1.7204)	Prec@(1,5) (51.2%, 83.5%)	
07/02 06:34:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][100/703]	Step 31780	lr 0.0946	Loss 1.5387 (1.7009)	Prec@(1,5) (52.3%, 83.5%)	
07/02 06:34:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][150/703]	Step 31830	lr 0.0946	Loss 1.5916 (1.7042)	Prec@(1,5) (52.3%, 83.4%)	
07/02 06:34:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][200/703]	Step 31880	lr 0.0946	Loss 2.1234 (1.7185)	Prec@(1,5) (52.1%, 83.1%)	
07/02 06:34:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][250/703]	Step 31930	lr 0.0946	Loss 1.8720 (1.7174)	Prec@(1,5) (52.2%, 83.1%)	
07/02 06:34:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][300/703]	Step 31980	lr 0.0946	Loss 1.9095 (1.7213)	Prec@(1,5) (52.2%, 82.9%)	
07/02 06:34:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][350/703]	Step 32030	lr 0.0946	Loss 1.4111 (1.7268)	Prec@(1,5) (52.0%, 82.8%)	
07/02 06:34:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][400/703]	Step 32080	lr 0.0946	Loss 1.9039 (1.7419)	Prec@(1,5) (51.7%, 82.5%)	
07/02 06:34:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][450/703]	Step 32130	lr 0.0946	Loss 1.5258 (1.7457)	Prec@(1,5) (51.6%, 82.6%)	
07/02 06:34:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][500/703]	Step 32180	lr 0.0946	Loss 1.9199 (1.7454)	Prec@(1,5) (51.7%, 82.6%)	
07/02 06:34:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][550/703]	Step 32230	lr 0.0946	Loss 1.8936 (1.7516)	Prec@(1,5) (51.6%, 82.4%)	
07/02 06:34:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][600/703]	Step 32280	lr 0.0946	Loss 1.4770 (1.7513)	Prec@(1,5) (51.6%, 82.4%)	
07/02 06:34:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][650/703]	Step 32330	lr 0.0946	Loss 1.7913 (1.7541)	Prec@(1,5) (51.5%, 82.4%)	
07/02 06:34:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][700/703]	Step 32380	lr 0.0946	Loss 1.7008 (1.7606)	Prec@(1,5) (51.4%, 82.2%)	
07/02 06:34:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [45][703/703]	Step 32383	lr 0.0946	Loss 1.5491 (1.7604)	Prec@(1,5) (51.4%, 82.3%)	
07/02 06:34:50午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 45/299] Final Prec@1 51.3889%
07/02 06:34:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [45][50/79]	Step 32384	Loss 2.2276	Prec@(1,5) (42.3%, 73.7%)
07/02 06:34:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [45][78/79]	Step 32384	Loss 2.2293	Prec@(1,5) (42.2%, 73.6%)
07/02 06:34:52午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 45/299] Final Prec@1 42.2000%
07/02 06:34:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:34:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][50/703]	Step 32434	lr 0.09437	Loss 1.8833 (1.7122)	Prec@(1,5) (51.8%, 83.8%)	
07/02 06:34:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][100/703]	Step 32484	lr 0.09437	Loss 1.8479 (1.6907)	Prec@(1,5) (52.5%, 83.7%)	
07/02 06:35:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][150/703]	Step 32534	lr 0.09437	Loss 1.4563 (1.7087)	Prec@(1,5) (52.3%, 83.2%)	
07/02 06:35:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][200/703]	Step 32584	lr 0.09437	Loss 1.7448 (1.7131)	Prec@(1,5) (52.4%, 83.1%)	
07/02 06:35:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][250/703]	Step 32634	lr 0.09437	Loss 2.1895 (1.7204)	Prec@(1,5) (52.0%, 83.0%)	
07/02 06:35:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][300/703]	Step 32684	lr 0.09437	Loss 1.8378 (1.7295)	Prec@(1,5) (51.8%, 83.0%)	
07/02 06:35:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][350/703]	Step 32734	lr 0.09437	Loss 1.3317 (1.7317)	Prec@(1,5) (51.9%, 82.9%)	
07/02 06:35:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][400/703]	Step 32784	lr 0.09437	Loss 1.7874 (1.7345)	Prec@(1,5) (51.7%, 82.8%)	
07/02 06:35:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][450/703]	Step 32834	lr 0.09437	Loss 2.1696 (1.7379)	Prec@(1,5) (51.7%, 82.6%)	
07/02 06:35:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][500/703]	Step 32884	lr 0.09437	Loss 2.0893 (1.7447)	Prec@(1,5) (51.6%, 82.5%)	
07/02 06:35:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][550/703]	Step 32934	lr 0.09437	Loss 1.8863 (1.7464)	Prec@(1,5) (51.5%, 82.5%)	
07/02 06:35:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][600/703]	Step 32984	lr 0.09437	Loss 1.5017 (1.7510)	Prec@(1,5) (51.5%, 82.4%)	
07/02 06:35:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][650/703]	Step 33034	lr 0.09437	Loss 1.9865 (1.7526)	Prec@(1,5) (51.4%, 82.4%)	
07/02 06:35:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][700/703]	Step 33084	lr 0.09437	Loss 1.6158 (1.7571)	Prec@(1,5) (51.3%, 82.3%)	
07/02 06:35:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [46][703/703]	Step 33087	lr 0.09437	Loss 1.8712 (1.7572)	Prec@(1,5) (51.3%, 82.3%)	
07/02 06:35:36午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 46/299] Final Prec@1 51.2600%
07/02 06:35:37午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [46][50/79]	Step 33088	Loss 2.1607	Prec@(1,5) (42.9%, 76.2%)
07/02 06:35:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [46][78/79]	Step 33088	Loss 2.1781	Prec@(1,5) (42.8%, 75.6%)
07/02 06:35:38午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 46/299] Final Prec@1 42.7600%
07/02 06:35:38午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:35:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][50/703]	Step 33138	lr 0.09412	Loss 1.4130 (1.7352)	Prec@(1,5) (51.3%, 83.2%)	
07/02 06:35:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][100/703]	Step 33188	lr 0.09412	Loss 1.8364 (1.6904)	Prec@(1,5) (52.6%, 84.1%)	
07/02 06:35:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][150/703]	Step 33238	lr 0.09412	Loss 1.6957 (1.6941)	Prec@(1,5) (52.6%, 83.9%)	
07/02 06:35:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][200/703]	Step 33288	lr 0.09412	Loss 1.6763 (1.7061)	Prec@(1,5) (52.4%, 83.6%)	
07/02 06:35:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][250/703]	Step 33338	lr 0.09412	Loss 1.6769 (1.7048)	Prec@(1,5) (52.4%, 83.6%)	
07/02 06:35:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][300/703]	Step 33388	lr 0.09412	Loss 1.4368 (1.7098)	Prec@(1,5) (52.3%, 83.5%)	
07/02 06:36:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][350/703]	Step 33438	lr 0.09412	Loss 1.6344 (1.7074)	Prec@(1,5) (52.5%, 83.4%)	
07/02 06:36:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][400/703]	Step 33488	lr 0.09412	Loss 1.6302 (1.7114)	Prec@(1,5) (52.3%, 83.3%)	
07/02 06:36:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][450/703]	Step 33538	lr 0.09412	Loss 1.6809 (1.7169)	Prec@(1,5) (52.2%, 83.2%)	
07/02 06:36:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][500/703]	Step 33588	lr 0.09412	Loss 1.8097 (1.7194)	Prec@(1,5) (52.2%, 83.0%)	
07/02 06:36:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][550/703]	Step 33638	lr 0.09412	Loss 1.9067 (1.7248)	Prec@(1,5) (52.1%, 82.9%)	
07/02 06:36:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][600/703]	Step 33688	lr 0.09412	Loss 1.7341 (1.7280)	Prec@(1,5) (52.1%, 82.8%)	
07/02 06:36:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][650/703]	Step 33738	lr 0.09412	Loss 1.7574 (1.7343)	Prec@(1,5) (51.9%, 82.7%)	
07/02 06:36:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][700/703]	Step 33788	lr 0.09412	Loss 1.8518 (1.7368)	Prec@(1,5) (51.9%, 82.6%)	
07/02 06:36:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [47][703/703]	Step 33791	lr 0.09412	Loss 2.1498 (1.7376)	Prec@(1,5) (51.8%, 82.6%)	
07/02 06:36:22午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 47/299] Final Prec@1 51.8356%
07/02 06:36:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [47][50/79]	Step 33792	Loss 2.0892	Prec@(1,5) (46.4%, 76.0%)
07/02 06:36:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [47][78/79]	Step 33792	Loss 2.1172	Prec@(1,5) (45.5%, 75.7%)
07/02 06:36:24午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 47/299] Final Prec@1 45.4400%
07/02 06:36:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:36:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][50/703]	Step 33842	lr 0.09388	Loss 1.7230 (1.6413)	Prec@(1,5) (54.6%, 84.1%)	
07/02 06:36:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][100/703]	Step 33892	lr 0.09388	Loss 1.6854 (1.6746)	Prec@(1,5) (53.5%, 83.9%)	
07/02 06:36:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][150/703]	Step 33942	lr 0.09388	Loss 1.4538 (1.6764)	Prec@(1,5) (53.4%, 83.6%)	
07/02 06:36:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][200/703]	Step 33992	lr 0.09388	Loss 1.5816 (1.6860)	Prec@(1,5) (53.1%, 83.5%)	
07/02 06:36:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][250/703]	Step 34042	lr 0.09388	Loss 1.6907 (1.6939)	Prec@(1,5) (52.6%, 83.5%)	
07/02 06:36:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][300/703]	Step 34092	lr 0.09388	Loss 1.8385 (1.7036)	Prec@(1,5) (52.5%, 83.3%)	
07/02 06:36:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][350/703]	Step 34142	lr 0.09388	Loss 1.4021 (1.7058)	Prec@(1,5) (52.6%, 83.2%)	
07/02 06:36:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][400/703]	Step 34192	lr 0.09388	Loss 1.7261 (1.7128)	Prec@(1,5) (52.4%, 83.1%)	
07/02 06:36:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][450/703]	Step 34242	lr 0.09388	Loss 1.6048 (1.7224)	Prec@(1,5) (52.2%, 82.9%)	
07/02 06:36:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][500/703]	Step 34292	lr 0.09388	Loss 1.5459 (1.7270)	Prec@(1,5) (52.1%, 82.8%)	
07/02 06:36:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][550/703]	Step 34342	lr 0.09388	Loss 1.6274 (1.7250)	Prec@(1,5) (52.2%, 82.8%)	
07/02 06:37:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][600/703]	Step 34392	lr 0.09388	Loss 1.9059 (1.7283)	Prec@(1,5) (52.1%, 82.7%)	
07/02 06:37:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][650/703]	Step 34442	lr 0.09388	Loss 1.8857 (1.7366)	Prec@(1,5) (52.0%, 82.6%)	
07/02 06:37:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][700/703]	Step 34492	lr 0.09388	Loss 1.7638 (1.7386)	Prec@(1,5) (51.9%, 82.5%)	
07/02 06:37:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [48][703/703]	Step 34495	lr 0.09388	Loss 1.6631 (1.7385)	Prec@(1,5) (51.9%, 82.5%)	
07/02 06:37:08午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 48/299] Final Prec@1 51.8933%
07/02 06:37:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [48][50/79]	Step 34496	Loss 2.0751	Prec@(1,5) (44.9%, 76.0%)
07/02 06:37:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [48][78/79]	Step 34496	Loss 2.0794	Prec@(1,5) (45.5%, 76.4%)
07/02 06:37:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 48/299] Final Prec@1 45.4400%
07/02 06:37:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:37:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][50/703]	Step 34546	lr 0.09363	Loss 1.8809 (1.6457)	Prec@(1,5) (53.9%, 84.6%)	
07/02 06:37:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][100/703]	Step 34596	lr 0.09363	Loss 1.7817 (1.6534)	Prec@(1,5) (53.7%, 84.3%)	
07/02 06:37:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][150/703]	Step 34646	lr 0.09363	Loss 1.8096 (1.6584)	Prec@(1,5) (53.7%, 84.1%)	
07/02 06:37:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][200/703]	Step 34696	lr 0.09363	Loss 1.9487 (1.6838)	Prec@(1,5) (52.9%, 83.7%)	
07/02 06:37:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][250/703]	Step 34746	lr 0.09363	Loss 1.7719 (1.6947)	Prec@(1,5) (52.6%, 83.4%)	
07/02 06:37:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][300/703]	Step 34796	lr 0.09363	Loss 1.8108 (1.6968)	Prec@(1,5) (52.6%, 83.3%)	
07/02 06:37:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][350/703]	Step 34846	lr 0.09363	Loss 1.3400 (1.7024)	Prec@(1,5) (52.5%, 83.3%)	
07/02 06:37:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][400/703]	Step 34896	lr 0.09363	Loss 1.9415 (1.7076)	Prec@(1,5) (52.4%, 83.2%)	
07/02 06:37:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][450/703]	Step 34946	lr 0.09363	Loss 1.7695 (1.7189)	Prec@(1,5) (52.3%, 83.0%)	
07/02 06:37:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][500/703]	Step 34996	lr 0.09363	Loss 1.8665 (1.7244)	Prec@(1,5) (52.2%, 83.0%)	
07/02 06:37:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][550/703]	Step 35046	lr 0.09363	Loss 2.1579 (1.7283)	Prec@(1,5) (52.2%, 82.8%)	
07/02 06:37:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][600/703]	Step 35096	lr 0.09363	Loss 1.9257 (1.7333)	Prec@(1,5) (52.1%, 82.7%)	
07/02 06:37:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][650/703]	Step 35146	lr 0.09363	Loss 2.0139 (1.7389)	Prec@(1,5) (52.0%, 82.6%)	
07/02 06:37:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][700/703]	Step 35196	lr 0.09363	Loss 2.1691 (1.7365)	Prec@(1,5) (52.0%, 82.7%)	
07/02 06:37:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [49][703/703]	Step 35199	lr 0.09363	Loss 1.3412 (1.7361)	Prec@(1,5) (52.0%, 82.7%)	
07/02 06:37:55午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 49/299] Final Prec@1 51.9978%
07/02 06:37:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [49][50/79]	Step 35200	Loss 2.0910	Prec@(1,5) (45.2%, 76.6%)
07/02 06:37:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [49][78/79]	Step 35200	Loss 2.0797	Prec@(1,5) (45.9%, 77.0%)
07/02 06:37:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 49/299] Final Prec@1 45.8400%
07/02 06:37:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:38:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][50/703]	Step 35250	lr 0.09337	Loss 1.6570 (1.6292)	Prec@(1,5) (54.4%, 84.7%)	
07/02 06:38:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][100/703]	Step 35300	lr 0.09337	Loss 1.8819 (1.6821)	Prec@(1,5) (52.9%, 83.7%)	
07/02 06:38:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][150/703]	Step 35350	lr 0.09337	Loss 1.6641 (1.6940)	Prec@(1,5) (52.6%, 83.5%)	
07/02 06:38:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][200/703]	Step 35400	lr 0.09337	Loss 1.7428 (1.6876)	Prec@(1,5) (52.5%, 83.6%)	
07/02 06:38:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][250/703]	Step 35450	lr 0.09337	Loss 1.4956 (1.6945)	Prec@(1,5) (52.4%, 83.5%)	
07/02 06:38:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][300/703]	Step 35500	lr 0.09337	Loss 1.9816 (1.7007)	Prec@(1,5) (52.2%, 83.4%)	
07/02 06:38:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][350/703]	Step 35550	lr 0.09337	Loss 1.9094 (1.7046)	Prec@(1,5) (52.3%, 83.2%)	
07/02 06:38:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][400/703]	Step 35600	lr 0.09337	Loss 1.9847 (1.7119)	Prec@(1,5) (52.1%, 83.1%)	
07/02 06:38:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][450/703]	Step 35650	lr 0.09337	Loss 1.7771 (1.7240)	Prec@(1,5) (51.9%, 82.9%)	
07/02 06:38:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][500/703]	Step 35700	lr 0.09337	Loss 1.7854 (1.7264)	Prec@(1,5) (51.9%, 82.9%)	
07/02 06:38:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][550/703]	Step 35750	lr 0.09337	Loss 1.5839 (1.7352)	Prec@(1,5) (51.6%, 82.8%)	
07/02 06:38:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][600/703]	Step 35800	lr 0.09337	Loss 1.5274 (1.7360)	Prec@(1,5) (51.6%, 82.7%)	
07/02 06:38:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][650/703]	Step 35850	lr 0.09337	Loss 1.9441 (1.7380)	Prec@(1,5) (51.6%, 82.7%)	
07/02 06:38:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][700/703]	Step 35900	lr 0.09337	Loss 1.6668 (1.7430)	Prec@(1,5) (51.5%, 82.6%)	
07/02 06:38:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [50][703/703]	Step 35903	lr 0.09337	Loss 1.7918 (1.7424)	Prec@(1,5) (51.5%, 82.6%)	
07/02 06:38:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 50/299] Final Prec@1 51.4822%
07/02 06:38:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [50][50/79]	Step 35904	Loss 2.1448	Prec@(1,5) (43.7%, 75.2%)
07/02 06:38:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [50][78/79]	Step 35904	Loss 2.1181	Prec@(1,5) (44.4%, 76.0%)
07/02 06:38:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 50/299] Final Prec@1 44.3400%
07/02 06:38:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:38:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][50/703]	Step 35954	lr 0.09311	Loss 1.7683 (1.6705)	Prec@(1,5) (53.6%, 84.2%)	
07/02 06:38:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][100/703]	Step 36004	lr 0.09311	Loss 1.5484 (1.6582)	Prec@(1,5) (54.1%, 84.2%)	
07/02 06:38:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][150/703]	Step 36054	lr 0.09311	Loss 2.2407 (1.6812)	Prec@(1,5) (53.4%, 83.5%)	
07/02 06:38:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][200/703]	Step 36104	lr 0.09311	Loss 2.1063 (1.6949)	Prec@(1,5) (53.1%, 83.2%)	
07/02 06:38:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][250/703]	Step 36154	lr 0.09311	Loss 1.6212 (1.6981)	Prec@(1,5) (53.1%, 83.2%)	
07/02 06:39:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][300/703]	Step 36204	lr 0.09311	Loss 1.9920 (1.6982)	Prec@(1,5) (52.9%, 83.1%)	
07/02 06:39:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][350/703]	Step 36254	lr 0.09311	Loss 1.5739 (1.7002)	Prec@(1,5) (52.9%, 83.2%)	
07/02 06:39:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][400/703]	Step 36304	lr 0.09311	Loss 1.7782 (1.7003)	Prec@(1,5) (52.9%, 83.2%)	
07/02 06:39:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][450/703]	Step 36354	lr 0.09311	Loss 2.1124 (1.7110)	Prec@(1,5) (52.7%, 83.0%)	
07/02 06:39:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][500/703]	Step 36404	lr 0.09311	Loss 1.9610 (1.7106)	Prec@(1,5) (52.7%, 83.1%)	
07/02 06:39:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][550/703]	Step 36454	lr 0.09311	Loss 1.8212 (1.7161)	Prec@(1,5) (52.5%, 83.0%)	
07/02 06:39:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][600/703]	Step 36504	lr 0.09311	Loss 1.2873 (1.7178)	Prec@(1,5) (52.5%, 83.0%)	
07/02 06:39:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][650/703]	Step 36554	lr 0.09311	Loss 1.9289 (1.7254)	Prec@(1,5) (52.4%, 82.9%)	
07/02 06:39:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][700/703]	Step 36604	lr 0.09311	Loss 1.7779 (1.7286)	Prec@(1,5) (52.4%, 82.8%)	
07/02 06:39:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [51][703/703]	Step 36607	lr 0.09311	Loss 2.0265 (1.7302)	Prec@(1,5) (52.3%, 82.8%)	
07/02 06:39:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 51/299] Final Prec@1 52.3333%
07/02 06:39:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [51][50/79]	Step 36608	Loss 2.3076	Prec@(1,5) (41.8%, 73.2%)
07/02 06:39:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [51][78/79]	Step 36608	Loss 2.3072	Prec@(1,5) (41.6%, 73.7%)
07/02 06:39:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 51/299] Final Prec@1 41.5800%
07/02 06:39:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:39:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][50/703]	Step 36658	lr 0.09284	Loss 1.3817 (1.6357)	Prec@(1,5) (55.1%, 84.2%)	
07/02 06:39:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][100/703]	Step 36708	lr 0.09284	Loss 1.5581 (1.6563)	Prec@(1,5) (54.6%, 83.7%)	
07/02 06:39:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][150/703]	Step 36758	lr 0.09284	Loss 1.5870 (1.6607)	Prec@(1,5) (54.1%, 83.8%)	
07/02 06:39:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][200/703]	Step 36808	lr 0.09284	Loss 1.9870 (1.6693)	Prec@(1,5) (54.0%, 83.6%)	
07/02 06:39:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][250/703]	Step 36858	lr 0.09284	Loss 1.5223 (1.6800)	Prec@(1,5) (53.5%, 83.3%)	
07/02 06:39:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][300/703]	Step 36908	lr 0.09284	Loss 1.7768 (1.6874)	Prec@(1,5) (53.2%, 83.4%)	
07/02 06:39:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][350/703]	Step 36958	lr 0.09284	Loss 1.7885 (1.6862)	Prec@(1,5) (53.2%, 83.4%)	
07/02 06:39:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][400/703]	Step 37008	lr 0.09284	Loss 2.1168 (1.6902)	Prec@(1,5) (53.2%, 83.2%)	
07/02 06:39:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][450/703]	Step 37058	lr 0.09284	Loss 1.8579 (1.6971)	Prec@(1,5) (53.0%, 83.1%)	
07/02 06:40:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][500/703]	Step 37108	lr 0.09284	Loss 1.9574 (1.7027)	Prec@(1,5) (52.9%, 82.9%)	
07/02 06:40:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][550/703]	Step 37158	lr 0.09284	Loss 2.0969 (1.7062)	Prec@(1,5) (52.9%, 82.9%)	
07/02 06:40:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][600/703]	Step 37208	lr 0.09284	Loss 1.7247 (1.7102)	Prec@(1,5) (52.7%, 82.8%)	
07/02 06:40:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][650/703]	Step 37258	lr 0.09284	Loss 1.8264 (1.7169)	Prec@(1,5) (52.6%, 82.7%)	
07/02 06:40:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][700/703]	Step 37308	lr 0.09284	Loss 1.6275 (1.7221)	Prec@(1,5) (52.5%, 82.6%)	
07/02 06:40:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [52][703/703]	Step 37311	lr 0.09284	Loss 1.7564 (1.7223)	Prec@(1,5) (52.5%, 82.6%)	
07/02 06:40:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 52/299] Final Prec@1 52.5156%
07/02 06:40:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [52][50/79]	Step 37312	Loss 2.1322	Prec@(1,5) (44.7%, 75.3%)
07/02 06:40:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [52][78/79]	Step 37312	Loss 2.1029	Prec@(1,5) (45.5%, 76.1%)
07/02 06:40:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 52/299] Final Prec@1 45.5000%
07/02 06:40:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:40:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][50/703]	Step 37362	lr 0.09257	Loss 1.6516 (1.6663)	Prec@(1,5) (53.4%, 83.8%)	
07/02 06:40:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][100/703]	Step 37412	lr 0.09257	Loss 1.7420 (1.6423)	Prec@(1,5) (54.2%, 84.1%)	
07/02 06:40:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][150/703]	Step 37462	lr 0.09257	Loss 1.7613 (1.6558)	Prec@(1,5) (53.7%, 84.1%)	
07/02 06:40:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][200/703]	Step 37512	lr 0.09257	Loss 1.5364 (1.6644)	Prec@(1,5) (53.6%, 84.1%)	
07/02 06:40:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][250/703]	Step 37562	lr 0.09257	Loss 1.5779 (1.6656)	Prec@(1,5) (53.6%, 83.8%)	
07/02 06:40:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][300/703]	Step 37612	lr 0.09257	Loss 1.7341 (1.6697)	Prec@(1,5) (53.5%, 83.9%)	
07/02 06:40:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][350/703]	Step 37662	lr 0.09257	Loss 1.9295 (1.6721)	Prec@(1,5) (53.6%, 83.8%)	
07/02 06:40:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][400/703]	Step 37712	lr 0.09257	Loss 1.5196 (1.6802)	Prec@(1,5) (53.3%, 83.7%)	
07/02 06:40:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][450/703]	Step 37762	lr 0.09257	Loss 1.6269 (1.6866)	Prec@(1,5) (53.2%, 83.6%)	
07/02 06:40:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][500/703]	Step 37812	lr 0.09257	Loss 1.4493 (1.6857)	Prec@(1,5) (53.1%, 83.7%)	
07/02 06:40:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][550/703]	Step 37862	lr 0.09257	Loss 1.6747 (1.6858)	Prec@(1,5) (53.1%, 83.7%)	
07/02 06:40:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][600/703]	Step 37912	lr 0.09257	Loss 2.0456 (1.6920)	Prec@(1,5) (52.8%, 83.6%)	
07/02 06:40:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][650/703]	Step 37962	lr 0.09257	Loss 1.7308 (1.6988)	Prec@(1,5) (52.8%, 83.4%)	
07/02 06:41:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][700/703]	Step 38012	lr 0.09257	Loss 1.6902 (1.7010)	Prec@(1,5) (52.7%, 83.3%)	
07/02 06:41:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [53][703/703]	Step 38015	lr 0.09257	Loss 1.1990 (1.7001)	Prec@(1,5) (52.7%, 83.3%)	
07/02 06:41:01午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 53/299] Final Prec@1 52.7400%
07/02 06:41:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [53][50/79]	Step 38016	Loss 2.1434	Prec@(1,5) (43.7%, 75.2%)
07/02 06:41:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [53][78/79]	Step 38016	Loss 2.1463	Prec@(1,5) (43.6%, 75.4%)
07/02 06:41:03午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 53/299] Final Prec@1 43.6000%
07/02 06:41:03午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:41:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][50/703]	Step 38066	lr 0.09229	Loss 1.4254 (1.5904)	Prec@(1,5) (55.3%, 85.5%)	
07/02 06:41:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][100/703]	Step 38116	lr 0.09229	Loss 1.3849 (1.6063)	Prec@(1,5) (54.5%, 85.0%)	
07/02 06:41:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][150/703]	Step 38166	lr 0.09229	Loss 1.4813 (1.6272)	Prec@(1,5) (54.3%, 84.5%)	
07/02 06:41:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][200/703]	Step 38216	lr 0.09229	Loss 1.7055 (1.6433)	Prec@(1,5) (53.8%, 84.1%)	
07/02 06:41:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][250/703]	Step 38266	lr 0.09229	Loss 1.7606 (1.6481)	Prec@(1,5) (53.7%, 83.9%)	
07/02 06:41:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][300/703]	Step 38316	lr 0.09229	Loss 1.6101 (1.6535)	Prec@(1,5) (53.7%, 83.9%)	
07/02 06:41:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][350/703]	Step 38366	lr 0.09229	Loss 1.1817 (1.6583)	Prec@(1,5) (53.6%, 83.8%)	
07/02 06:41:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][400/703]	Step 38416	lr 0.09229	Loss 1.8423 (1.6682)	Prec@(1,5) (53.3%, 83.6%)	
07/02 06:41:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][450/703]	Step 38466	lr 0.09229	Loss 1.5002 (1.6715)	Prec@(1,5) (53.3%, 83.7%)	
07/02 06:41:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][500/703]	Step 38516	lr 0.09229	Loss 1.4562 (1.6764)	Prec@(1,5) (53.2%, 83.6%)	
07/02 06:41:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][550/703]	Step 38566	lr 0.09229	Loss 1.6311 (1.6793)	Prec@(1,5) (53.0%, 83.6%)	
07/02 06:41:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][600/703]	Step 38616	lr 0.09229	Loss 1.6746 (1.6862)	Prec@(1,5) (52.9%, 83.5%)	
07/02 06:41:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][650/703]	Step 38666	lr 0.09229	Loss 1.5113 (1.6904)	Prec@(1,5) (52.8%, 83.3%)	
07/02 06:41:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][700/703]	Step 38716	lr 0.09229	Loss 1.5617 (1.6938)	Prec@(1,5) (52.7%, 83.2%)	
07/02 06:41:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [54][703/703]	Step 38719	lr 0.09229	Loss 1.6739 (1.6936)	Prec@(1,5) (52.7%, 83.2%)	
07/02 06:41:47午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 54/299] Final Prec@1 52.7467%
07/02 06:41:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [54][50/79]	Step 38720	Loss 2.0915	Prec@(1,5) (44.2%, 76.8%)
07/02 06:41:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [54][78/79]	Step 38720	Loss 2.1039	Prec@(1,5) (44.5%, 76.5%)
07/02 06:41:49午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 54/299] Final Prec@1 44.5000%
07/02 06:41:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:41:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][50/703]	Step 38770	lr 0.09201	Loss 1.8670 (1.6426)	Prec@(1,5) (54.8%, 84.0%)	
07/02 06:41:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][100/703]	Step 38820	lr 0.09201	Loss 1.6945 (1.6426)	Prec@(1,5) (54.0%, 84.3%)	
07/02 06:41:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][150/703]	Step 38870	lr 0.09201	Loss 1.8131 (1.6270)	Prec@(1,5) (54.1%, 84.6%)	
07/02 06:42:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][200/703]	Step 38920	lr 0.09201	Loss 1.8114 (1.6294)	Prec@(1,5) (54.3%, 84.5%)	
07/02 06:42:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][250/703]	Step 38970	lr 0.09201	Loss 1.7970 (1.6316)	Prec@(1,5) (54.3%, 84.4%)	
07/02 06:42:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][300/703]	Step 39020	lr 0.09201	Loss 1.9780 (1.6457)	Prec@(1,5) (54.0%, 84.2%)	
07/02 06:42:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][350/703]	Step 39070	lr 0.09201	Loss 1.7321 (1.6607)	Prec@(1,5) (53.7%, 83.8%)	
07/02 06:42:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][400/703]	Step 39120	lr 0.09201	Loss 1.6984 (1.6687)	Prec@(1,5) (53.3%, 83.7%)	
07/02 06:42:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][450/703]	Step 39170	lr 0.09201	Loss 1.7161 (1.6716)	Prec@(1,5) (53.4%, 83.6%)	
07/02 06:42:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][500/703]	Step 39220	lr 0.09201	Loss 1.7998 (1.6754)	Prec@(1,5) (53.3%, 83.5%)	
07/02 06:42:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][550/703]	Step 39270	lr 0.09201	Loss 1.5112 (1.6845)	Prec@(1,5) (53.1%, 83.3%)	
07/02 06:42:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][600/703]	Step 39320	lr 0.09201	Loss 1.8861 (1.6831)	Prec@(1,5) (53.1%, 83.3%)	
07/02 06:42:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][650/703]	Step 39370	lr 0.09201	Loss 1.9221 (1.6868)	Prec@(1,5) (53.0%, 83.3%)	
07/02 06:42:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][700/703]	Step 39420	lr 0.09201	Loss 1.5000 (1.6879)	Prec@(1,5) (53.0%, 83.2%)	
07/02 06:42:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [55][703/703]	Step 39423	lr 0.09201	Loss 1.7441 (1.6885)	Prec@(1,5) (53.0%, 83.2%)	
07/02 06:42:34午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 55/299] Final Prec@1 52.9556%
07/02 06:42:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [55][50/79]	Step 39424	Loss 2.1184	Prec@(1,5) (45.0%, 76.3%)
07/02 06:42:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [55][78/79]	Step 39424	Loss 2.1406	Prec@(1,5) (44.4%, 75.7%)
07/02 06:42:36午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 55/299] Final Prec@1 44.3800%
07/02 06:42:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:42:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][50/703]	Step 39474	lr 0.09173	Loss 1.7467 (1.6084)	Prec@(1,5) (55.0%, 84.8%)	
07/02 06:42:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][100/703]	Step 39524	lr 0.09173	Loss 1.6538 (1.5960)	Prec@(1,5) (55.5%, 84.9%)	
07/02 06:42:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][150/703]	Step 39574	lr 0.09173	Loss 1.2761 (1.6089)	Prec@(1,5) (55.2%, 84.6%)	
07/02 06:42:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][200/703]	Step 39624	lr 0.09173	Loss 1.9582 (1.6188)	Prec@(1,5) (54.9%, 84.5%)	
07/02 06:42:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][250/703]	Step 39674	lr 0.09173	Loss 1.6428 (1.6318)	Prec@(1,5) (54.5%, 84.3%)	
07/02 06:42:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][300/703]	Step 39724	lr 0.09173	Loss 1.4085 (1.6396)	Prec@(1,5) (54.2%, 84.2%)	
07/02 06:42:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][350/703]	Step 39774	lr 0.09173	Loss 1.4726 (1.6451)	Prec@(1,5) (54.0%, 84.1%)	
07/02 06:43:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][400/703]	Step 39824	lr 0.09173	Loss 1.6073 (1.6540)	Prec@(1,5) (53.9%, 84.0%)	
07/02 06:43:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][450/703]	Step 39874	lr 0.09173	Loss 1.7846 (1.6591)	Prec@(1,5) (53.8%, 83.9%)	
07/02 06:43:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][500/703]	Step 39924	lr 0.09173	Loss 1.5821 (1.6641)	Prec@(1,5) (53.6%, 83.9%)	
07/02 06:43:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][550/703]	Step 39974	lr 0.09173	Loss 1.9536 (1.6685)	Prec@(1,5) (53.5%, 83.8%)	
07/02 06:43:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][600/703]	Step 40024	lr 0.09173	Loss 1.6210 (1.6755)	Prec@(1,5) (53.4%, 83.6%)	
07/02 06:43:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][650/703]	Step 40074	lr 0.09173	Loss 1.5469 (1.6815)	Prec@(1,5) (53.3%, 83.5%)	
07/02 06:43:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][700/703]	Step 40124	lr 0.09173	Loss 1.9411 (1.6846)	Prec@(1,5) (53.2%, 83.5%)	
07/02 06:43:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [56][703/703]	Step 40127	lr 0.09173	Loss 1.9465 (1.6855)	Prec@(1,5) (53.2%, 83.4%)	
07/02 06:43:21午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 56/299] Final Prec@1 53.1578%
07/02 06:43:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [56][50/79]	Step 40128	Loss 2.1190	Prec@(1,5) (44.2%, 76.1%)
07/02 06:43:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [56][78/79]	Step 40128	Loss 2.1125	Prec@(1,5) (44.9%, 76.1%)
07/02 06:43:23午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 56/299] Final Prec@1 44.9000%
07/02 06:43:23午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:43:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][50/703]	Step 40178	lr 0.09144	Loss 1.5548 (1.6272)	Prec@(1,5) (53.8%, 84.2%)	
07/02 06:43:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][100/703]	Step 40228	lr 0.09144	Loss 1.3582 (1.6233)	Prec@(1,5) (54.4%, 84.1%)	
07/02 06:43:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][150/703]	Step 40278	lr 0.09144	Loss 1.6066 (1.6366)	Prec@(1,5) (54.2%, 83.9%)	
07/02 06:43:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][200/703]	Step 40328	lr 0.09144	Loss 1.8186 (1.6266)	Prec@(1,5) (54.3%, 84.2%)	
07/02 06:43:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][250/703]	Step 40378	lr 0.09144	Loss 1.8602 (1.6442)	Prec@(1,5) (53.6%, 84.2%)	
07/02 06:43:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][300/703]	Step 40428	lr 0.09144	Loss 2.1513 (1.6484)	Prec@(1,5) (53.4%, 84.2%)	
07/02 06:43:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][350/703]	Step 40478	lr 0.09144	Loss 1.4936 (1.6602)	Prec@(1,5) (53.1%, 84.0%)	
07/02 06:43:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][400/703]	Step 40528	lr 0.09144	Loss 1.5975 (1.6641)	Prec@(1,5) (53.2%, 83.9%)	
07/02 06:43:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][450/703]	Step 40578	lr 0.09144	Loss 1.9567 (1.6746)	Prec@(1,5) (52.9%, 83.8%)	
07/02 06:43:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][500/703]	Step 40628	lr 0.09144	Loss 1.4104 (1.6762)	Prec@(1,5) (52.9%, 83.8%)	
07/02 06:43:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][550/703]	Step 40678	lr 0.09144	Loss 1.7169 (1.6763)	Prec@(1,5) (52.9%, 83.8%)	
07/02 06:44:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][600/703]	Step 40728	lr 0.09144	Loss 1.3500 (1.6847)	Prec@(1,5) (52.8%, 83.6%)	
07/02 06:44:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][650/703]	Step 40778	lr 0.09144	Loss 2.4036 (1.6900)	Prec@(1,5) (52.8%, 83.5%)	
07/02 06:44:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][700/703]	Step 40828	lr 0.09144	Loss 1.5076 (1.6919)	Prec@(1,5) (52.7%, 83.5%)	
07/02 06:44:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [57][703/703]	Step 40831	lr 0.09144	Loss 1.5143 (1.6924)	Prec@(1,5) (52.7%, 83.5%)	
07/02 06:44:08午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 57/299] Final Prec@1 52.7111%
07/02 06:44:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [57][50/79]	Step 40832	Loss 2.1187	Prec@(1,5) (43.7%, 75.8%)
07/02 06:44:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [57][78/79]	Step 40832	Loss 2.1192	Prec@(1,5) (43.8%, 75.5%)
07/02 06:44:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 57/299] Final Prec@1 43.8400%
07/02 06:44:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.2800%
07/02 06:44:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][50/703]	Step 40882	lr 0.09115	Loss 1.8720 (1.6712)	Prec@(1,5) (53.7%, 83.7%)	
07/02 06:44:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][100/703]	Step 40932	lr 0.09115	Loss 1.3372 (1.6366)	Prec@(1,5) (54.1%, 84.5%)	
07/02 06:44:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][150/703]	Step 40982	lr 0.09115	Loss 1.6760 (1.6344)	Prec@(1,5) (54.0%, 84.6%)	
07/02 06:44:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][200/703]	Step 41032	lr 0.09115	Loss 1.8304 (1.6411)	Prec@(1,5) (54.0%, 84.4%)	
07/02 06:44:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][250/703]	Step 41082	lr 0.09115	Loss 2.0741 (1.6428)	Prec@(1,5) (53.9%, 84.5%)	
07/02 06:44:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][300/703]	Step 41132	lr 0.09115	Loss 1.7508 (1.6488)	Prec@(1,5) (53.8%, 84.3%)	
07/02 06:44:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][350/703]	Step 41182	lr 0.09115	Loss 1.3836 (1.6570)	Prec@(1,5) (53.5%, 84.2%)	
07/02 06:44:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][400/703]	Step 41232	lr 0.09115	Loss 1.5119 (1.6573)	Prec@(1,5) (53.5%, 84.2%)	
07/02 06:44:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][450/703]	Step 41282	lr 0.09115	Loss 1.8418 (1.6669)	Prec@(1,5) (53.3%, 84.1%)	
07/02 06:44:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][500/703]	Step 41332	lr 0.09115	Loss 1.4335 (1.6700)	Prec@(1,5) (53.3%, 84.1%)	
07/02 06:44:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][550/703]	Step 41382	lr 0.09115	Loss 1.3578 (1.6723)	Prec@(1,5) (53.2%, 83.9%)	
07/02 06:44:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][600/703]	Step 41432	lr 0.09115	Loss 1.9037 (1.6771)	Prec@(1,5) (53.1%, 83.8%)	
07/02 06:44:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][650/703]	Step 41482	lr 0.09115	Loss 1.8951 (1.6791)	Prec@(1,5) (53.1%, 83.8%)	
07/02 06:44:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][700/703]	Step 41532	lr 0.09115	Loss 1.6879 (1.6810)	Prec@(1,5) (53.2%, 83.7%)	
07/02 06:44:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [58][703/703]	Step 41535	lr 0.09115	Loss 1.5839 (1.6808)	Prec@(1,5) (53.2%, 83.7%)	
07/02 06:44:54午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 58/299] Final Prec@1 53.1644%
07/02 06:44:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [58][50/79]	Step 41536	Loss 2.0018	Prec@(1,5) (47.5%, 78.0%)
07/02 06:44:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [58][78/79]	Step 41536	Loss 2.0455	Prec@(1,5) (46.9%, 77.0%)
07/02 06:44:56午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 58/299] Final Prec@1 46.8600%
07/02 06:44:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.8600%
07/02 06:45:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][50/703]	Step 41586	lr 0.09085	Loss 1.5041 (1.5793)	Prec@(1,5) (55.4%, 85.0%)	
07/02 06:45:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][100/703]	Step 41636	lr 0.09085	Loss 1.3902 (1.6192)	Prec@(1,5) (54.9%, 84.5%)	
07/02 06:45:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][150/703]	Step 41686	lr 0.09085	Loss 1.5893 (1.6236)	Prec@(1,5) (54.5%, 84.5%)	
07/02 06:45:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][200/703]	Step 41736	lr 0.09085	Loss 1.4457 (1.6271)	Prec@(1,5) (54.3%, 84.5%)	
07/02 06:45:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][250/703]	Step 41786	lr 0.09085	Loss 1.6654 (1.6272)	Prec@(1,5) (54.3%, 84.4%)	
07/02 06:45:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][300/703]	Step 41836	lr 0.09085	Loss 1.8862 (1.6336)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:45:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][350/703]	Step 41886	lr 0.09085	Loss 1.9805 (1.6433)	Prec@(1,5) (53.9%, 84.1%)	
07/02 06:45:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][400/703]	Step 41936	lr 0.09085	Loss 2.0467 (1.6485)	Prec@(1,5) (54.0%, 83.9%)	
07/02 06:45:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][450/703]	Step 41986	lr 0.09085	Loss 1.7846 (1.6555)	Prec@(1,5) (53.7%, 83.8%)	
07/02 06:45:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][500/703]	Step 42036	lr 0.09085	Loss 2.0374 (1.6637)	Prec@(1,5) (53.5%, 83.7%)	
07/02 06:45:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][550/703]	Step 42086	lr 0.09085	Loss 1.6732 (1.6643)	Prec@(1,5) (53.5%, 83.7%)	
07/02 06:45:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][600/703]	Step 42136	lr 0.09085	Loss 2.0370 (1.6649)	Prec@(1,5) (53.5%, 83.7%)	
07/02 06:45:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][650/703]	Step 42186	lr 0.09085	Loss 1.7319 (1.6675)	Prec@(1,5) (53.4%, 83.7%)	
07/02 06:45:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][700/703]	Step 42236	lr 0.09085	Loss 1.3847 (1.6721)	Prec@(1,5) (53.3%, 83.6%)	
07/02 06:45:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [59][703/703]	Step 42239	lr 0.09085	Loss 1.8879 (1.6730)	Prec@(1,5) (53.3%, 83.6%)	
07/02 06:45:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 59/299] Final Prec@1 53.2978%
07/02 06:45:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [59][50/79]	Step 42240	Loss 2.2230	Prec@(1,5) (43.3%, 74.0%)
07/02 06:45:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [59][78/79]	Step 42240	Loss 2.1978	Prec@(1,5) (43.5%, 74.0%)
07/02 06:45:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 59/299] Final Prec@1 43.5400%
07/02 06:45:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.8600%
07/02 06:45:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][50/703]	Step 42290	lr 0.09055	Loss 1.5844 (1.6150)	Prec@(1,5) (54.7%, 84.4%)	
07/02 06:45:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][100/703]	Step 42340	lr 0.09055	Loss 1.6395 (1.6280)	Prec@(1,5) (55.1%, 84.0%)	
07/02 06:45:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][150/703]	Step 42390	lr 0.09055	Loss 1.6690 (1.6281)	Prec@(1,5) (54.6%, 84.3%)	
07/02 06:45:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][200/703]	Step 42440	lr 0.09055	Loss 2.3132 (1.6424)	Prec@(1,5) (54.3%, 84.2%)	
07/02 06:45:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][250/703]	Step 42490	lr 0.09055	Loss 2.1439 (1.6520)	Prec@(1,5) (54.1%, 84.0%)	
07/02 06:46:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][300/703]	Step 42540	lr 0.09055	Loss 1.4492 (1.6482)	Prec@(1,5) (54.1%, 84.1%)	
07/02 06:46:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][350/703]	Step 42590	lr 0.09055	Loss 1.6084 (1.6469)	Prec@(1,5) (54.1%, 84.2%)	
07/02 06:46:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][400/703]	Step 42640	lr 0.09055	Loss 1.4010 (1.6521)	Prec@(1,5) (54.0%, 84.0%)	
07/02 06:46:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][450/703]	Step 42690	lr 0.09055	Loss 1.4121 (1.6571)	Prec@(1,5) (53.8%, 83.9%)	
07/02 06:46:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][500/703]	Step 42740	lr 0.09055	Loss 1.6306 (1.6624)	Prec@(1,5) (53.7%, 83.9%)	
07/02 06:46:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][550/703]	Step 42790	lr 0.09055	Loss 1.5835 (1.6691)	Prec@(1,5) (53.6%, 83.8%)	
07/02 06:46:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][600/703]	Step 42840	lr 0.09055	Loss 1.6866 (1.6750)	Prec@(1,5) (53.5%, 83.7%)	
07/02 06:46:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][650/703]	Step 42890	lr 0.09055	Loss 1.7706 (1.6765)	Prec@(1,5) (53.4%, 83.7%)	
07/02 06:46:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][700/703]	Step 42940	lr 0.09055	Loss 2.0856 (1.6826)	Prec@(1,5) (53.3%, 83.5%)	
07/02 06:46:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [60][703/703]	Step 42943	lr 0.09055	Loss 1.3810 (1.6822)	Prec@(1,5) (53.3%, 83.5%)	
07/02 06:46:26午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 60/299] Final Prec@1 53.2733%
07/02 06:46:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [60][50/79]	Step 42944	Loss 2.1388	Prec@(1,5) (43.3%, 76.0%)
07/02 06:46:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [60][78/79]	Step 42944	Loss 2.1440	Prec@(1,5) (43.3%, 75.7%)
07/02 06:46:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 60/299] Final Prec@1 43.3400%
07/02 06:46:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.8600%
07/02 06:46:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][50/703]	Step 42994	lr 0.09024	Loss 1.5368 (1.5754)	Prec@(1,5) (54.2%, 86.5%)	
07/02 06:46:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][100/703]	Step 43044	lr 0.09024	Loss 1.5936 (1.5995)	Prec@(1,5) (54.1%, 85.5%)	
07/02 06:46:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][150/703]	Step 43094	lr 0.09024	Loss 1.4136 (1.6236)	Prec@(1,5) (53.8%, 84.9%)	
07/02 06:46:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][200/703]	Step 43144	lr 0.09024	Loss 1.6478 (1.6366)	Prec@(1,5) (53.7%, 84.6%)	
07/02 06:46:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][250/703]	Step 43194	lr 0.09024	Loss 1.9379 (1.6431)	Prec@(1,5) (53.7%, 84.5%)	
07/02 06:46:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][300/703]	Step 43244	lr 0.09024	Loss 1.5251 (1.6441)	Prec@(1,5) (53.8%, 84.5%)	
07/02 06:46:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][350/703]	Step 43294	lr 0.09024	Loss 1.9256 (1.6462)	Prec@(1,5) (53.8%, 84.4%)	
07/02 06:46:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][400/703]	Step 43344	lr 0.09024	Loss 1.7469 (1.6583)	Prec@(1,5) (53.6%, 84.2%)	
07/02 06:46:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][450/703]	Step 43394	lr 0.09024	Loss 1.7237 (1.6655)	Prec@(1,5) (53.3%, 84.1%)	
07/02 06:47:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][500/703]	Step 43444	lr 0.09024	Loss 1.7605 (1.6703)	Prec@(1,5) (53.3%, 83.9%)	
07/02 06:47:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][550/703]	Step 43494	lr 0.09024	Loss 1.6893 (1.6696)	Prec@(1,5) (53.4%, 84.0%)	
07/02 06:47:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][600/703]	Step 43544	lr 0.09024	Loss 1.5258 (1.6764)	Prec@(1,5) (53.2%, 83.8%)	
07/02 06:47:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][650/703]	Step 43594	lr 0.09024	Loss 1.8225 (1.6803)	Prec@(1,5) (53.1%, 83.7%)	
07/02 06:47:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][700/703]	Step 43644	lr 0.09024	Loss 1.8754 (1.6869)	Prec@(1,5) (52.9%, 83.7%)	
07/02 06:47:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [61][703/703]	Step 43647	lr 0.09024	Loss 1.7277 (1.6868)	Prec@(1,5) (52.9%, 83.7%)	
07/02 06:47:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 61/299] Final Prec@1 52.8844%
07/02 06:47:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [61][50/79]	Step 43648	Loss 2.1186	Prec@(1,5) (45.2%, 76.3%)
07/02 06:47:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [61][78/79]	Step 43648	Loss 2.1080	Prec@(1,5) (44.9%, 76.0%)
07/02 06:47:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 61/299] Final Prec@1 44.9000%
07/02 06:47:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.8600%
07/02 06:47:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][50/703]	Step 43698	lr 0.08993	Loss 1.7445 (1.5830)	Prec@(1,5) (56.1%, 84.9%)	
07/02 06:47:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][100/703]	Step 43748	lr 0.08993	Loss 1.5956 (1.6065)	Prec@(1,5) (54.8%, 85.1%)	
07/02 06:47:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][150/703]	Step 43798	lr 0.08993	Loss 1.5345 (1.6247)	Prec@(1,5) (54.5%, 84.8%)	
07/02 06:47:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][200/703]	Step 43848	lr 0.08993	Loss 1.6189 (1.6187)	Prec@(1,5) (54.4%, 84.6%)	
07/02 06:47:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][250/703]	Step 43898	lr 0.08993	Loss 1.2164 (1.6098)	Prec@(1,5) (54.5%, 84.6%)	
07/02 06:47:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][300/703]	Step 43948	lr 0.08993	Loss 1.6497 (1.6214)	Prec@(1,5) (54.1%, 84.5%)	
07/02 06:47:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][350/703]	Step 43998	lr 0.08993	Loss 1.7266 (1.6267)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:47:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][400/703]	Step 44048	lr 0.08993	Loss 1.9368 (1.6363)	Prec@(1,5) (54.0%, 84.3%)	
07/02 06:47:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][450/703]	Step 44098	lr 0.08993	Loss 1.7065 (1.6431)	Prec@(1,5) (53.8%, 84.1%)	
07/02 06:47:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][500/703]	Step 44148	lr 0.08993	Loss 1.6714 (1.6445)	Prec@(1,5) (54.0%, 84.1%)	
07/02 06:47:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][550/703]	Step 44198	lr 0.08993	Loss 1.6251 (1.6525)	Prec@(1,5) (53.7%, 84.0%)	
07/02 06:47:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][600/703]	Step 44248	lr 0.08993	Loss 1.4918 (1.6549)	Prec@(1,5) (53.7%, 83.9%)	
07/02 06:47:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][650/703]	Step 44298	lr 0.08993	Loss 1.6031 (1.6604)	Prec@(1,5) (53.6%, 83.7%)	
07/02 06:47:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][700/703]	Step 44348	lr 0.08993	Loss 1.8956 (1.6632)	Prec@(1,5) (53.6%, 83.7%)	
07/02 06:47:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [62][703/703]	Step 44351	lr 0.08993	Loss 1.9143 (1.6636)	Prec@(1,5) (53.6%, 83.7%)	
07/02 06:47:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 62/299] Final Prec@1 53.5800%
07/02 06:48:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [62][50/79]	Step 44352	Loss 2.0212	Prec@(1,5) (46.7%, 77.9%)
07/02 06:48:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [62][78/79]	Step 44352	Loss 2.0404	Prec@(1,5) (46.3%, 77.7%)
07/02 06:48:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 62/299] Final Prec@1 46.3400%
07/02 06:48:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 46.8600%
07/02 06:48:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][50/703]	Step 44402	lr 0.08961	Loss 1.6292 (1.6106)	Prec@(1,5) (55.1%, 85.1%)	
07/02 06:48:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][100/703]	Step 44452	lr 0.08961	Loss 1.7693 (1.6009)	Prec@(1,5) (55.0%, 85.4%)	
07/02 06:48:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][150/703]	Step 44502	lr 0.08961	Loss 1.7433 (1.6287)	Prec@(1,5) (54.3%, 85.0%)	
07/02 06:48:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][200/703]	Step 44552	lr 0.08961	Loss 1.4861 (1.6184)	Prec@(1,5) (54.5%, 85.0%)	
07/02 06:48:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][250/703]	Step 44602	lr 0.08961	Loss 1.4905 (1.6272)	Prec@(1,5) (54.3%, 84.8%)	
07/02 06:48:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][300/703]	Step 44652	lr 0.08961	Loss 1.7958 (1.6345)	Prec@(1,5) (54.3%, 84.5%)	
07/02 06:48:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][350/703]	Step 44702	lr 0.08961	Loss 1.7706 (1.6473)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:48:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][400/703]	Step 44752	lr 0.08961	Loss 1.6807 (1.6482)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:48:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][450/703]	Step 44802	lr 0.08961	Loss 1.6212 (1.6503)	Prec@(1,5) (54.0%, 84.2%)	
07/02 06:48:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][500/703]	Step 44852	lr 0.08961	Loss 1.5839 (1.6503)	Prec@(1,5) (54.0%, 84.2%)	
07/02 06:48:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][550/703]	Step 44902	lr 0.08961	Loss 1.5436 (1.6524)	Prec@(1,5) (53.9%, 84.1%)	
07/02 06:48:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][600/703]	Step 44952	lr 0.08961	Loss 1.8773 (1.6565)	Prec@(1,5) (53.8%, 84.1%)	
07/02 06:48:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][650/703]	Step 45002	lr 0.08961	Loss 1.9492 (1.6582)	Prec@(1,5) (53.8%, 84.1%)	
07/02 06:48:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][700/703]	Step 45052	lr 0.08961	Loss 1.7214 (1.6605)	Prec@(1,5) (53.7%, 84.1%)	
07/02 06:48:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [63][703/703]	Step 45055	lr 0.08961	Loss 1.6242 (1.6608)	Prec@(1,5) (53.7%, 84.0%)	
07/02 06:48:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 63/299] Final Prec@1 53.7311%
07/02 06:48:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [63][50/79]	Step 45056	Loss 1.9964	Prec@(1,5) (46.9%, 77.9%)
07/02 06:48:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [63][78/79]	Step 45056	Loss 1.9994	Prec@(1,5) (47.1%, 78.1%)
07/02 06:48:47午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 63/299] Final Prec@1 47.1600%
07/02 06:48:48午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 47.1600%
07/02 06:48:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][50/703]	Step 45106	lr 0.08929	Loss 1.5326 (1.5574)	Prec@(1,5) (55.6%, 85.3%)	
07/02 06:48:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][100/703]	Step 45156	lr 0.08929	Loss 1.5520 (1.5743)	Prec@(1,5) (55.5%, 85.2%)	
07/02 06:48:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][150/703]	Step 45206	lr 0.08929	Loss 1.4506 (1.5903)	Prec@(1,5) (55.3%, 84.9%)	
07/02 06:49:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][200/703]	Step 45256	lr 0.08929	Loss 1.6609 (1.6038)	Prec@(1,5) (55.0%, 84.5%)	
07/02 06:49:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][250/703]	Step 45306	lr 0.08929	Loss 1.8656 (1.6152)	Prec@(1,5) (54.9%, 84.3%)	
07/02 06:49:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][300/703]	Step 45356	lr 0.08929	Loss 1.6056 (1.6164)	Prec@(1,5) (55.0%, 84.3%)	
07/02 06:49:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][350/703]	Step 45406	lr 0.08929	Loss 2.0601 (1.6220)	Prec@(1,5) (54.9%, 84.2%)	
07/02 06:49:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][400/703]	Step 45456	lr 0.08929	Loss 1.8237 (1.6285)	Prec@(1,5) (54.8%, 84.1%)	
07/02 06:49:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][450/703]	Step 45506	lr 0.08929	Loss 1.6791 (1.6370)	Prec@(1,5) (54.6%, 84.0%)	
07/02 06:49:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][500/703]	Step 45556	lr 0.08929	Loss 1.3058 (1.6442)	Prec@(1,5) (54.4%, 83.8%)	
07/02 06:49:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][550/703]	Step 45606	lr 0.08929	Loss 1.5226 (1.6489)	Prec@(1,5) (54.2%, 83.9%)	
07/02 06:49:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][600/703]	Step 45656	lr 0.08929	Loss 1.3621 (1.6550)	Prec@(1,5) (54.0%, 83.8%)	
07/02 06:49:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][650/703]	Step 45706	lr 0.08929	Loss 1.4876 (1.6574)	Prec@(1,5) (54.0%, 83.8%)	
07/02 06:49:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][700/703]	Step 45756	lr 0.08929	Loss 1.8376 (1.6612)	Prec@(1,5) (53.8%, 83.7%)	
07/02 06:49:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [64][703/703]	Step 45759	lr 0.08929	Loss 1.8844 (1.6618)	Prec@(1,5) (53.8%, 83.7%)	
07/02 06:49:32午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 64/299] Final Prec@1 53.7956%
07/02 06:49:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [64][50/79]	Step 45760	Loss 2.0358	Prec@(1,5) (45.6%, 76.7%)
07/02 06:49:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [64][78/79]	Step 45760	Loss 2.0324	Prec@(1,5) (46.1%, 77.3%)
07/02 06:49:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 64/299] Final Prec@1 46.0400%
07/02 06:49:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 47.1600%
07/02 06:49:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][50/703]	Step 45810	lr 0.08897	Loss 1.4819 (1.4923)	Prec@(1,5) (57.7%, 86.9%)	
07/02 06:49:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][100/703]	Step 45860	lr 0.08897	Loss 1.7113 (1.5358)	Prec@(1,5) (56.2%, 86.2%)	
07/02 06:49:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][150/703]	Step 45910	lr 0.08897	Loss 1.7860 (1.5664)	Prec@(1,5) (55.7%, 85.9%)	
07/02 06:49:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][200/703]	Step 45960	lr 0.08897	Loss 1.6575 (1.5731)	Prec@(1,5) (55.5%, 85.8%)	
07/02 06:49:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][250/703]	Step 46010	lr 0.08897	Loss 1.6582 (1.5834)	Prec@(1,5) (55.3%, 85.5%)	
07/02 06:49:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][300/703]	Step 46060	lr 0.08897	Loss 1.9071 (1.6002)	Prec@(1,5) (55.0%, 85.0%)	
07/02 06:49:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][350/703]	Step 46110	lr 0.08897	Loss 1.6622 (1.6069)	Prec@(1,5) (54.8%, 84.9%)	
07/02 06:50:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][400/703]	Step 46160	lr 0.08897	Loss 1.8362 (1.6139)	Prec@(1,5) (54.7%, 84.6%)	
07/02 06:50:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][450/703]	Step 46210	lr 0.08897	Loss 1.5769 (1.6199)	Prec@(1,5) (54.6%, 84.5%)	
07/02 06:50:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][500/703]	Step 46260	lr 0.08897	Loss 1.4862 (1.6281)	Prec@(1,5) (54.4%, 84.4%)	
07/02 06:50:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][550/703]	Step 46310	lr 0.08897	Loss 1.6382 (1.6342)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:50:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][600/703]	Step 46360	lr 0.08897	Loss 1.4988 (1.6404)	Prec@(1,5) (54.1%, 84.1%)	
07/02 06:50:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][650/703]	Step 46410	lr 0.08897	Loss 1.7201 (1.6425)	Prec@(1,5) (54.0%, 84.1%)	
07/02 06:50:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][700/703]	Step 46460	lr 0.08897	Loss 1.9270 (1.6478)	Prec@(1,5) (53.9%, 84.0%)	
07/02 06:50:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [65][703/703]	Step 46463	lr 0.08897	Loss 1.7166 (1.6478)	Prec@(1,5) (53.9%, 84.0%)	
07/02 06:50:19午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 65/299] Final Prec@1 53.9289%
07/02 06:50:20午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [65][50/79]	Step 46464	Loss 1.9678	Prec@(1,5) (48.0%, 78.6%)
07/02 06:50:20午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [65][78/79]	Step 46464	Loss 1.9602	Prec@(1,5) (48.7%, 78.4%)
07/02 06:50:20午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 65/299] Final Prec@1 48.6200%
07/02 06:50:21午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:50:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][50/703]	Step 46514	lr 0.08864	Loss 1.4675 (1.5575)	Prec@(1,5) (54.9%, 86.0%)	
07/02 06:50:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][100/703]	Step 46564	lr 0.08864	Loss 1.6710 (1.5775)	Prec@(1,5) (54.8%, 85.7%)	
07/02 06:50:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][150/703]	Step 46614	lr 0.08864	Loss 1.5315 (1.5805)	Prec@(1,5) (54.8%, 85.5%)	
07/02 06:50:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][200/703]	Step 46664	lr 0.08864	Loss 1.7433 (1.5923)	Prec@(1,5) (54.8%, 85.2%)	
07/02 06:50:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][250/703]	Step 46714	lr 0.08864	Loss 1.4551 (1.5809)	Prec@(1,5) (55.1%, 85.3%)	
07/02 06:50:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][300/703]	Step 46764	lr 0.08864	Loss 1.4527 (1.5857)	Prec@(1,5) (55.3%, 85.3%)	
07/02 06:50:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][350/703]	Step 46814	lr 0.08864	Loss 1.7290 (1.5949)	Prec@(1,5) (55.0%, 85.1%)	
07/02 06:50:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][400/703]	Step 46864	lr 0.08864	Loss 1.7233 (1.6005)	Prec@(1,5) (55.0%, 84.9%)	
07/02 06:50:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][450/703]	Step 46914	lr 0.08864	Loss 1.6811 (1.6040)	Prec@(1,5) (54.9%, 84.9%)	
07/02 06:50:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][500/703]	Step 46964	lr 0.08864	Loss 1.7068 (1.6117)	Prec@(1,5) (54.7%, 84.7%)	
07/02 06:50:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][550/703]	Step 47014	lr 0.08864	Loss 1.4431 (1.6175)	Prec@(1,5) (54.7%, 84.5%)	
07/02 06:50:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][600/703]	Step 47064	lr 0.08864	Loss 1.6345 (1.6213)	Prec@(1,5) (54.5%, 84.4%)	
07/02 06:51:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][650/703]	Step 47114	lr 0.08864	Loss 1.8501 (1.6287)	Prec@(1,5) (54.4%, 84.3%)	
07/02 06:51:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][700/703]	Step 47164	lr 0.08864	Loss 1.7908 (1.6324)	Prec@(1,5) (54.2%, 84.2%)	
07/02 06:51:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [66][703/703]	Step 47167	lr 0.08864	Loss 1.5260 (1.6315)	Prec@(1,5) (54.2%, 84.2%)	
07/02 06:51:05午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 66/299] Final Prec@1 54.2400%
07/02 06:51:07午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [66][50/79]	Step 47168	Loss 2.0867	Prec@(1,5) (45.1%, 76.2%)
07/02 06:51:07午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [66][78/79]	Step 47168	Loss 2.0771	Prec@(1,5) (45.4%, 76.2%)
07/02 06:51:07午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 66/299] Final Prec@1 45.4600%
07/02 06:51:07午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:51:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][50/703]	Step 47218	lr 0.08831	Loss 1.5826 (1.5227)	Prec@(1,5) (55.7%, 86.7%)	
07/02 06:51:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][100/703]	Step 47268	lr 0.08831	Loss 1.5222 (1.5386)	Prec@(1,5) (56.0%, 86.3%)	
07/02 06:51:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][150/703]	Step 47318	lr 0.08831	Loss 1.6162 (1.5627)	Prec@(1,5) (55.8%, 85.9%)	
07/02 06:51:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][200/703]	Step 47368	lr 0.08831	Loss 1.8900 (1.5782)	Prec@(1,5) (55.7%, 85.4%)	
07/02 06:51:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][250/703]	Step 47418	lr 0.08831	Loss 1.5583 (1.5822)	Prec@(1,5) (55.6%, 85.2%)	
07/02 06:51:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][300/703]	Step 47468	lr 0.08831	Loss 1.3811 (1.5943)	Prec@(1,5) (55.3%, 85.0%)	
07/02 06:51:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][350/703]	Step 47518	lr 0.08831	Loss 1.6612 (1.6011)	Prec@(1,5) (55.0%, 84.9%)	
07/02 06:51:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][400/703]	Step 47568	lr 0.08831	Loss 1.6848 (1.6015)	Prec@(1,5) (55.0%, 84.9%)	
07/02 06:51:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][450/703]	Step 47618	lr 0.08831	Loss 1.6530 (1.6095)	Prec@(1,5) (54.7%, 84.8%)	
07/02 06:51:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][500/703]	Step 47668	lr 0.08831	Loss 1.7376 (1.6134)	Prec@(1,5) (54.7%, 84.7%)	
07/02 06:51:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][550/703]	Step 47718	lr 0.08831	Loss 1.3908 (1.6200)	Prec@(1,5) (54.5%, 84.7%)	
07/02 06:51:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][600/703]	Step 47768	lr 0.08831	Loss 1.8904 (1.6279)	Prec@(1,5) (54.4%, 84.5%)	
07/02 06:51:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][650/703]	Step 47818	lr 0.08831	Loss 1.7114 (1.6318)	Prec@(1,5) (54.2%, 84.5%)	
07/02 06:51:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][700/703]	Step 47868	lr 0.08831	Loss 1.6285 (1.6379)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:51:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [67][703/703]	Step 47871	lr 0.08831	Loss 1.4032 (1.6375)	Prec@(1,5) (54.1%, 84.3%)	
07/02 06:51:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 67/299] Final Prec@1 54.1044%
07/02 06:51:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [67][50/79]	Step 47872	Loss 1.9809	Prec@(1,5) (47.8%, 78.6%)
07/02 06:51:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [67][78/79]	Step 47872	Loss 2.0037	Prec@(1,5) (47.2%, 78.3%)
07/02 06:51:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 67/299] Final Prec@1 47.2400%
07/02 06:51:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:51:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][50/703]	Step 47922	lr 0.08797	Loss 1.3656 (1.5833)	Prec@(1,5) (54.5%, 85.0%)	
07/02 06:52:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][100/703]	Step 47972	lr 0.08797	Loss 1.7683 (1.5739)	Prec@(1,5) (55.4%, 85.4%)	
07/02 06:52:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][150/703]	Step 48022	lr 0.08797	Loss 1.6065 (1.5589)	Prec@(1,5) (55.8%, 85.6%)	
07/02 06:52:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][200/703]	Step 48072	lr 0.08797	Loss 1.0753 (1.5557)	Prec@(1,5) (56.1%, 85.6%)	
07/02 06:52:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][250/703]	Step 48122	lr 0.08797	Loss 1.5893 (1.5690)	Prec@(1,5) (55.8%, 85.4%)	
07/02 06:52:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][300/703]	Step 48172	lr 0.08797	Loss 1.6112 (1.5896)	Prec@(1,5) (55.3%, 85.1%)	
07/02 06:52:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][350/703]	Step 48222	lr 0.08797	Loss 1.6484 (1.5990)	Prec@(1,5) (54.9%, 85.1%)	
07/02 06:52:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][400/703]	Step 48272	lr 0.08797	Loss 1.9116 (1.6049)	Prec@(1,5) (54.7%, 85.1%)	
07/02 06:52:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][450/703]	Step 48322	lr 0.08797	Loss 2.0258 (1.6037)	Prec@(1,5) (54.7%, 85.0%)	
07/02 06:52:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][500/703]	Step 48372	lr 0.08797	Loss 1.5489 (1.6053)	Prec@(1,5) (54.7%, 85.0%)	
07/02 06:52:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][550/703]	Step 48422	lr 0.08797	Loss 1.7602 (1.6179)	Prec@(1,5) (54.5%, 84.7%)	
07/02 06:52:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][600/703]	Step 48472	lr 0.08797	Loss 1.2764 (1.6240)	Prec@(1,5) (54.4%, 84.6%)	
07/02 06:52:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][650/703]	Step 48522	lr 0.08797	Loss 1.5746 (1.6230)	Prec@(1,5) (54.5%, 84.5%)	
07/02 06:52:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][700/703]	Step 48572	lr 0.08797	Loss 1.4745 (1.6280)	Prec@(1,5) (54.4%, 84.5%)	
07/02 06:52:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [68][703/703]	Step 48575	lr 0.08797	Loss 1.2621 (1.6272)	Prec@(1,5) (54.4%, 84.5%)	
07/02 06:52:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 68/299] Final Prec@1 54.4200%
07/02 06:52:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [68][50/79]	Step 48576	Loss 1.9930	Prec@(1,5) (47.2%, 78.1%)
07/02 06:52:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [68][78/79]	Step 48576	Loss 1.9759	Prec@(1,5) (47.7%, 78.5%)
07/02 06:52:41午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 68/299] Final Prec@1 47.6800%
07/02 06:52:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:52:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][50/703]	Step 48626	lr 0.08763	Loss 1.4891 (1.5438)	Prec@(1,5) (55.8%, 86.4%)	
07/02 06:52:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][100/703]	Step 48676	lr 0.08763	Loss 1.6678 (1.5388)	Prec@(1,5) (56.5%, 86.0%)	
07/02 06:52:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][150/703]	Step 48726	lr 0.08763	Loss 1.3828 (1.5426)	Prec@(1,5) (56.2%, 86.2%)	
07/02 06:52:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][200/703]	Step 48776	lr 0.08763	Loss 1.7151 (1.5477)	Prec@(1,5) (56.0%, 86.0%)	
07/02 06:52:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][250/703]	Step 48826	lr 0.08763	Loss 1.3586 (1.5605)	Prec@(1,5) (55.7%, 85.8%)	
07/02 06:53:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][300/703]	Step 48876	lr 0.08763	Loss 1.3825 (1.5796)	Prec@(1,5) (55.3%, 85.3%)	
07/02 06:53:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][350/703]	Step 48926	lr 0.08763	Loss 1.8184 (1.5795)	Prec@(1,5) (55.3%, 85.3%)	
07/02 06:53:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][400/703]	Step 48976	lr 0.08763	Loss 1.4779 (1.5900)	Prec@(1,5) (55.1%, 85.1%)	
07/02 06:53:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][450/703]	Step 49026	lr 0.08763	Loss 1.6348 (1.5985)	Prec@(1,5) (54.9%, 85.0%)	
07/02 06:53:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][500/703]	Step 49076	lr 0.08763	Loss 1.5720 (1.6050)	Prec@(1,5) (54.8%, 84.9%)	
07/02 06:53:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][550/703]	Step 49126	lr 0.08763	Loss 1.8411 (1.6098)	Prec@(1,5) (54.7%, 84.9%)	
07/02 06:53:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][600/703]	Step 49176	lr 0.08763	Loss 1.8424 (1.6168)	Prec@(1,5) (54.4%, 84.7%)	
07/02 06:53:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][650/703]	Step 49226	lr 0.08763	Loss 1.4590 (1.6221)	Prec@(1,5) (54.4%, 84.6%)	
07/02 06:53:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][700/703]	Step 49276	lr 0.08763	Loss 1.9303 (1.6276)	Prec@(1,5) (54.3%, 84.5%)	
07/02 06:53:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [69][703/703]	Step 49279	lr 0.08763	Loss 1.5564 (1.6276)	Prec@(1,5) (54.3%, 84.5%)	
07/02 06:53:25午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 69/299] Final Prec@1 54.2956%
07/02 06:53:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [69][50/79]	Step 49280	Loss 2.2653	Prec@(1,5) (43.4%, 74.2%)
07/02 06:53:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [69][78/79]	Step 49280	Loss 2.2205	Prec@(1,5) (44.3%, 74.6%)
07/02 06:53:27午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 69/299] Final Prec@1 44.3000%
07/02 06:53:27午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:53:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][50/703]	Step 49330	lr 0.08729	Loss 1.2171 (1.5670)	Prec@(1,5) (56.0%, 85.9%)	
07/02 06:53:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][100/703]	Step 49380	lr 0.08729	Loss 1.7529 (1.5647)	Prec@(1,5) (55.9%, 85.4%)	
07/02 06:53:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][150/703]	Step 49430	lr 0.08729	Loss 1.3549 (1.5716)	Prec@(1,5) (55.7%, 85.4%)	
07/02 06:53:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][200/703]	Step 49480	lr 0.08729	Loss 1.6583 (1.5845)	Prec@(1,5) (55.6%, 85.2%)	
07/02 06:53:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][250/703]	Step 49530	lr 0.08729	Loss 1.5602 (1.5823)	Prec@(1,5) (55.8%, 85.4%)	
07/02 06:53:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][300/703]	Step 49580	lr 0.08729	Loss 1.5869 (1.5891)	Prec@(1,5) (55.5%, 85.3%)	
07/02 06:53:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][350/703]	Step 49630	lr 0.08729	Loss 1.5575 (1.5925)	Prec@(1,5) (55.5%, 85.2%)	
07/02 06:53:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][400/703]	Step 49680	lr 0.08729	Loss 1.6175 (1.5967)	Prec@(1,5) (55.4%, 85.2%)	
07/02 06:53:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][450/703]	Step 49730	lr 0.08729	Loss 1.8188 (1.5997)	Prec@(1,5) (55.3%, 85.1%)	
07/02 06:53:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][500/703]	Step 49780	lr 0.08729	Loss 1.3644 (1.6064)	Prec@(1,5) (55.2%, 84.9%)	
07/02 06:54:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][550/703]	Step 49830	lr 0.08729	Loss 1.7441 (1.6110)	Prec@(1,5) (55.0%, 84.9%)	
07/02 06:54:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][600/703]	Step 49880	lr 0.08729	Loss 1.3984 (1.6171)	Prec@(1,5) (54.9%, 84.8%)	
07/02 06:54:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][650/703]	Step 49930	lr 0.08729	Loss 1.3754 (1.6158)	Prec@(1,5) (54.8%, 84.8%)	
07/02 06:54:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][700/703]	Step 49980	lr 0.08729	Loss 2.2249 (1.6237)	Prec@(1,5) (54.7%, 84.7%)	
07/02 06:54:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [70][703/703]	Step 49983	lr 0.08729	Loss 1.6482 (1.6250)	Prec@(1,5) (54.7%, 84.6%)	
07/02 06:54:12午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 70/299] Final Prec@1 54.6511%
07/02 06:54:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [70][50/79]	Step 49984	Loss 2.0843	Prec@(1,5) (45.5%, 77.3%)
07/02 06:54:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [70][78/79]	Step 49984	Loss 2.1018	Prec@(1,5) (44.4%, 77.4%)
07/02 06:54:13午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 70/299] Final Prec@1 44.4000%
07/02 06:54:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:54:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][50/703]	Step 50034	lr 0.08694	Loss 1.2174 (1.5698)	Prec@(1,5) (55.5%, 85.6%)	
07/02 06:54:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][100/703]	Step 50084	lr 0.08694	Loss 1.7086 (1.5578)	Prec@(1,5) (55.9%, 85.8%)	
07/02 06:54:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][150/703]	Step 50134	lr 0.08694	Loss 1.5995 (1.5573)	Prec@(1,5) (55.8%, 85.8%)	
07/02 06:54:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][200/703]	Step 50184	lr 0.08694	Loss 1.3148 (1.5740)	Prec@(1,5) (55.5%, 85.6%)	
07/02 06:54:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][250/703]	Step 50234	lr 0.08694	Loss 1.3546 (1.5654)	Prec@(1,5) (55.7%, 85.7%)	
07/02 06:54:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][300/703]	Step 50284	lr 0.08694	Loss 1.5876 (1.5758)	Prec@(1,5) (55.5%, 85.5%)	
07/02 06:54:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][350/703]	Step 50334	lr 0.08694	Loss 1.3439 (1.5829)	Prec@(1,5) (55.3%, 85.3%)	
07/02 06:54:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][400/703]	Step 50384	lr 0.08694	Loss 1.8356 (1.5828)	Prec@(1,5) (55.5%, 85.3%)	
07/02 06:54:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][450/703]	Step 50434	lr 0.08694	Loss 1.6602 (1.5851)	Prec@(1,5) (55.4%, 85.3%)	
07/02 06:54:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][500/703]	Step 50484	lr 0.08694	Loss 1.4520 (1.5904)	Prec@(1,5) (55.2%, 85.2%)	
07/02 06:54:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][550/703]	Step 50534	lr 0.08694	Loss 1.8254 (1.5948)	Prec@(1,5) (55.2%, 85.2%)	
07/02 06:54:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][600/703]	Step 50584	lr 0.08694	Loss 1.2269 (1.5976)	Prec@(1,5) (55.2%, 85.1%)	
07/02 06:54:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][650/703]	Step 50634	lr 0.08694	Loss 1.8332 (1.6065)	Prec@(1,5) (54.9%, 84.9%)	
07/02 06:54:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][700/703]	Step 50684	lr 0.08694	Loss 2.1495 (1.6091)	Prec@(1,5) (54.9%, 84.8%)	
07/02 06:54:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [71][703/703]	Step 50687	lr 0.08694	Loss 1.5052 (1.6087)	Prec@(1,5) (54.9%, 84.8%)	
07/02 06:54:58午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 71/299] Final Prec@1 54.9311%
07/02 06:54:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [71][50/79]	Step 50688	Loss 1.9954	Prec@(1,5) (48.0%, 77.3%)
07/02 06:55:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [71][78/79]	Step 50688	Loss 1.9868	Prec@(1,5) (48.0%, 77.3%)
07/02 06:55:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 71/299] Final Prec@1 48.0400%
07/02 06:55:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:55:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][50/703]	Step 50738	lr 0.08658	Loss 1.5359 (1.5510)	Prec@(1,5) (56.2%, 85.4%)	
07/02 06:55:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][100/703]	Step 50788	lr 0.08658	Loss 1.6958 (1.5396)	Prec@(1,5) (57.2%, 85.6%)	
07/02 06:55:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][150/703]	Step 50838	lr 0.08658	Loss 1.4590 (1.5475)	Prec@(1,5) (56.9%, 85.4%)	
07/02 06:55:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][200/703]	Step 50888	lr 0.08658	Loss 1.5489 (1.5496)	Prec@(1,5) (56.8%, 85.6%)	
07/02 06:55:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][250/703]	Step 50938	lr 0.08658	Loss 1.6133 (1.5550)	Prec@(1,5) (56.7%, 85.5%)	
07/02 06:55:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][300/703]	Step 50988	lr 0.08658	Loss 1.4763 (1.5583)	Prec@(1,5) (56.6%, 85.4%)	
07/02 06:55:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][350/703]	Step 51038	lr 0.08658	Loss 1.7027 (1.5672)	Prec@(1,5) (56.4%, 85.3%)	
07/02 06:55:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][400/703]	Step 51088	lr 0.08658	Loss 1.5703 (1.5752)	Prec@(1,5) (56.2%, 85.2%)	
07/02 06:55:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][450/703]	Step 51138	lr 0.08658	Loss 2.0036 (1.5789)	Prec@(1,5) (55.9%, 85.2%)	
07/02 06:55:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][500/703]	Step 51188	lr 0.08658	Loss 1.5664 (1.5835)	Prec@(1,5) (55.8%, 85.2%)	
07/02 06:55:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][550/703]	Step 51238	lr 0.08658	Loss 1.8032 (1.5928)	Prec@(1,5) (55.7%, 85.0%)	
07/02 06:55:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][600/703]	Step 51288	lr 0.08658	Loss 1.8160 (1.6008)	Prec@(1,5) (55.5%, 84.9%)	
07/02 06:55:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][650/703]	Step 51338	lr 0.08658	Loss 1.8814 (1.6083)	Prec@(1,5) (55.3%, 84.8%)	
07/02 06:55:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][700/703]	Step 51388	lr 0.08658	Loss 1.9026 (1.6149)	Prec@(1,5) (55.0%, 84.7%)	
07/02 06:55:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [72][703/703]	Step 51391	lr 0.08658	Loss 1.5224 (1.6146)	Prec@(1,5) (55.0%, 84.8%)	
07/02 06:55:44午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 72/299] Final Prec@1 54.9911%
07/02 06:55:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [72][50/79]	Step 51392	Loss 2.0934	Prec@(1,5) (46.5%, 75.3%)
07/02 06:55:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [72][78/79]	Step 51392	Loss 2.0603	Prec@(1,5) (46.6%, 76.6%)
07/02 06:55:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 72/299] Final Prec@1 46.6000%
07/02 06:55:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:55:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][50/703]	Step 51442	lr 0.08623	Loss 1.8269 (1.5182)	Prec@(1,5) (57.1%, 87.0%)	
07/02 06:55:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][100/703]	Step 51492	lr 0.08623	Loss 1.3844 (1.5346)	Prec@(1,5) (56.3%, 86.6%)	
07/02 06:55:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][150/703]	Step 51542	lr 0.08623	Loss 1.8247 (1.5465)	Prec@(1,5) (56.5%, 86.3%)	
07/02 06:55:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][200/703]	Step 51592	lr 0.08623	Loss 1.9043 (1.5496)	Prec@(1,5) (56.4%, 86.2%)	
07/02 06:56:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][250/703]	Step 51642	lr 0.08623	Loss 1.9902 (1.5644)	Prec@(1,5) (56.0%, 85.7%)	
07/02 06:56:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][300/703]	Step 51692	lr 0.08623	Loss 1.7095 (1.5629)	Prec@(1,5) (56.0%, 85.6%)	
07/02 06:56:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][350/703]	Step 51742	lr 0.08623	Loss 1.5553 (1.5734)	Prec@(1,5) (55.7%, 85.4%)	
07/02 06:56:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][400/703]	Step 51792	lr 0.08623	Loss 1.6053 (1.5833)	Prec@(1,5) (55.5%, 85.2%)	
07/02 06:56:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][450/703]	Step 51842	lr 0.08623	Loss 1.7084 (1.5923)	Prec@(1,5) (55.2%, 85.0%)	
07/02 06:56:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][500/703]	Step 51892	lr 0.08623	Loss 1.5020 (1.5971)	Prec@(1,5) (55.1%, 85.0%)	
07/02 06:56:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][550/703]	Step 51942	lr 0.08623	Loss 1.3750 (1.5961)	Prec@(1,5) (55.1%, 85.1%)	
07/02 06:56:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][600/703]	Step 51992	lr 0.08623	Loss 1.5131 (1.6004)	Prec@(1,5) (54.9%, 85.1%)	
07/02 06:56:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][650/703]	Step 52042	lr 0.08623	Loss 2.0511 (1.6081)	Prec@(1,5) (54.8%, 84.9%)	
07/02 06:56:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][700/703]	Step 52092	lr 0.08623	Loss 1.7210 (1.6151)	Prec@(1,5) (54.7%, 84.8%)	
07/02 06:56:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [73][703/703]	Step 52095	lr 0.08623	Loss 1.7411 (1.6159)	Prec@(1,5) (54.7%, 84.8%)	
07/02 06:56:31午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 73/299] Final Prec@1 54.6889%
07/02 06:56:32午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [73][50/79]	Step 52096	Loss 2.1228	Prec@(1,5) (45.4%, 75.5%)
07/02 06:56:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [73][78/79]	Step 52096	Loss 2.0980	Prec@(1,5) (46.0%, 76.0%)
07/02 06:56:33午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 73/299] Final Prec@1 45.9600%
07/02 06:56:33午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 48.6200%
07/02 06:56:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][50/703]	Step 52146	lr 0.08587	Loss 1.6963 (1.5395)	Prec@(1,5) (56.4%, 86.8%)	
07/02 06:56:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][100/703]	Step 52196	lr 0.08587	Loss 1.4582 (1.5259)	Prec@(1,5) (56.8%, 86.8%)	
07/02 06:56:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][150/703]	Step 52246	lr 0.08587	Loss 1.7855 (1.5392)	Prec@(1,5) (56.8%, 86.4%)	
07/02 06:56:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][200/703]	Step 52296	lr 0.08587	Loss 1.4763 (1.5598)	Prec@(1,5) (56.4%, 85.8%)	
07/02 06:56:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][250/703]	Step 52346	lr 0.08587	Loss 1.2401 (1.5560)	Prec@(1,5) (56.5%, 85.9%)	
07/02 06:56:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][300/703]	Step 52396	lr 0.08587	Loss 1.6056 (1.5642)	Prec@(1,5) (56.2%, 85.7%)	
07/02 06:56:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][350/703]	Step 52446	lr 0.08587	Loss 1.5674 (1.5716)	Prec@(1,5) (55.9%, 85.5%)	
07/02 06:56:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][400/703]	Step 52496	lr 0.08587	Loss 1.7589 (1.5753)	Prec@(1,5) (55.7%, 85.5%)	
07/02 06:57:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][450/703]	Step 52546	lr 0.08587	Loss 1.8555 (1.5770)	Prec@(1,5) (55.7%, 85.4%)	
07/02 06:57:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][500/703]	Step 52596	lr 0.08587	Loss 1.9775 (1.5837)	Prec@(1,5) (55.5%, 85.3%)	
07/02 06:57:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][550/703]	Step 52646	lr 0.08587	Loss 2.0506 (1.5863)	Prec@(1,5) (55.5%, 85.2%)	
07/02 06:57:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][600/703]	Step 52696	lr 0.08587	Loss 1.4006 (1.5888)	Prec@(1,5) (55.4%, 85.2%)	
07/02 06:57:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][650/703]	Step 52746	lr 0.08587	Loss 1.9121 (1.5901)	Prec@(1,5) (55.3%, 85.2%)	
07/02 06:57:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][700/703]	Step 52796	lr 0.08587	Loss 1.7779 (1.5955)	Prec@(1,5) (55.2%, 85.1%)	
07/02 06:57:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [74][703/703]	Step 52799	lr 0.08587	Loss 1.7614 (1.5953)	Prec@(1,5) (55.2%, 85.1%)	
07/02 06:57:17午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 74/299] Final Prec@1 55.1622%
07/02 06:57:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [74][50/79]	Step 52800	Loss 1.8988	Prec@(1,5) (49.6%, 79.4%)
07/02 06:57:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [74][78/79]	Step 52800	Loss 1.9164	Prec@(1,5) (49.4%, 79.5%)
07/02 06:57:19午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 74/299] Final Prec@1 49.3800%
07/02 06:57:20午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 06:57:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][50/703]	Step 52850	lr 0.0855	Loss 1.2252 (1.5410)	Prec@(1,5) (55.8%, 87.1%)	
07/02 06:57:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][100/703]	Step 52900	lr 0.0855	Loss 1.0478 (1.5348)	Prec@(1,5) (55.8%, 86.9%)	
07/02 06:57:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][150/703]	Step 52950	lr 0.0855	Loss 1.5879 (1.5445)	Prec@(1,5) (55.7%, 86.5%)	
07/02 06:57:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][200/703]	Step 53000	lr 0.0855	Loss 1.6283 (1.5465)	Prec@(1,5) (56.2%, 86.2%)	
07/02 06:57:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][250/703]	Step 53050	lr 0.0855	Loss 1.3919 (1.5534)	Prec@(1,5) (56.0%, 86.1%)	
07/02 06:57:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][300/703]	Step 53100	lr 0.0855	Loss 1.6115 (1.5456)	Prec@(1,5) (56.3%, 86.2%)	
07/02 06:57:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][350/703]	Step 53150	lr 0.0855	Loss 1.6152 (1.5571)	Prec@(1,5) (56.1%, 85.9%)	
07/02 06:57:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][400/703]	Step 53200	lr 0.0855	Loss 1.8550 (1.5608)	Prec@(1,5) (55.9%, 85.9%)	
07/02 06:57:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][450/703]	Step 53250	lr 0.0855	Loss 1.4291 (1.5710)	Prec@(1,5) (55.6%, 85.7%)	
07/02 06:57:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][500/703]	Step 53300	lr 0.0855	Loss 1.4249 (1.5765)	Prec@(1,5) (55.5%, 85.6%)	
07/02 06:57:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][550/703]	Step 53350	lr 0.0855	Loss 1.7705 (1.5800)	Prec@(1,5) (55.4%, 85.5%)	
07/02 06:57:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][600/703]	Step 53400	lr 0.0855	Loss 1.4536 (1.5859)	Prec@(1,5) (55.4%, 85.4%)	
07/02 06:58:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][650/703]	Step 53450	lr 0.0855	Loss 1.8849 (1.5916)	Prec@(1,5) (55.2%, 85.4%)	
07/02 06:58:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][700/703]	Step 53500	lr 0.0855	Loss 1.8544 (1.5956)	Prec@(1,5) (55.0%, 85.3%)	
07/02 06:58:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [75][703/703]	Step 53503	lr 0.0855	Loss 1.7023 (1.5956)	Prec@(1,5) (55.0%, 85.3%)	
07/02 06:58:04午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 75/299] Final Prec@1 55.0467%
07/02 06:58:06午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [75][50/79]	Step 53504	Loss 2.0034	Prec@(1,5) (47.9%, 77.6%)
07/02 06:58:06午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [75][78/79]	Step 53504	Loss 2.0364	Prec@(1,5) (47.1%, 77.3%)
07/02 06:58:06午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 75/299] Final Prec@1 47.0400%
07/02 06:58:06午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 06:58:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][50/703]	Step 53554	lr 0.08513	Loss 1.4490 (1.5392)	Prec@(1,5) (56.7%, 86.5%)	
07/02 06:58:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][100/703]	Step 53604	lr 0.08513	Loss 1.4817 (1.5247)	Prec@(1,5) (57.5%, 86.1%)	
07/02 06:58:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][150/703]	Step 53654	lr 0.08513	Loss 1.6560 (1.5307)	Prec@(1,5) (57.4%, 86.0%)	
07/02 06:58:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][200/703]	Step 53704	lr 0.08513	Loss 1.3166 (1.5417)	Prec@(1,5) (57.1%, 85.8%)	
07/02 06:58:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][250/703]	Step 53754	lr 0.08513	Loss 1.8740 (1.5493)	Prec@(1,5) (56.7%, 85.8%)	
07/02 06:58:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][300/703]	Step 53804	lr 0.08513	Loss 1.7158 (1.5551)	Prec@(1,5) (56.5%, 85.8%)	
07/02 06:58:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][350/703]	Step 53854	lr 0.08513	Loss 1.6399 (1.5606)	Prec@(1,5) (56.4%, 85.7%)	
07/02 06:58:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][400/703]	Step 53904	lr 0.08513	Loss 1.5338 (1.5670)	Prec@(1,5) (56.2%, 85.6%)	
07/02 06:58:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][450/703]	Step 53954	lr 0.08513	Loss 1.6357 (1.5710)	Prec@(1,5) (56.1%, 85.5%)	
07/02 06:58:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][500/703]	Step 54004	lr 0.08513	Loss 1.5544 (1.5746)	Prec@(1,5) (56.0%, 85.4%)	
07/02 06:58:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][550/703]	Step 54054	lr 0.08513	Loss 1.4139 (1.5770)	Prec@(1,5) (56.0%, 85.3%)	
07/02 06:58:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][600/703]	Step 54104	lr 0.08513	Loss 1.4446 (1.5786)	Prec@(1,5) (55.9%, 85.3%)	
07/02 06:58:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][650/703]	Step 54154	lr 0.08513	Loss 1.5017 (1.5850)	Prec@(1,5) (55.7%, 85.2%)	
07/02 06:58:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][700/703]	Step 54204	lr 0.08513	Loss 1.5757 (1.5881)	Prec@(1,5) (55.6%, 85.1%)	
07/02 06:58:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [76][703/703]	Step 54207	lr 0.08513	Loss 1.6347 (1.5887)	Prec@(1,5) (55.5%, 85.1%)	
07/02 06:58:50午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 76/299] Final Prec@1 55.5467%
07/02 06:58:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [76][50/79]	Step 54208	Loss 2.0590	Prec@(1,5) (47.2%, 77.0%)
07/02 06:58:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [76][78/79]	Step 54208	Loss 2.0451	Prec@(1,5) (47.2%, 77.3%)
07/02 06:58:52午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 76/299] Final Prec@1 47.1800%
07/02 06:58:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 06:58:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][50/703]	Step 54258	lr 0.08476	Loss 1.4055 (1.4698)	Prec@(1,5) (58.7%, 87.0%)	
07/02 06:59:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][100/703]	Step 54308	lr 0.08476	Loss 1.8074 (1.5042)	Prec@(1,5) (57.4%, 86.6%)	
07/02 06:59:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][150/703]	Step 54358	lr 0.08476	Loss 1.5853 (1.5184)	Prec@(1,5) (57.1%, 86.3%)	
07/02 06:59:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][200/703]	Step 54408	lr 0.08476	Loss 1.6096 (1.5255)	Prec@(1,5) (57.1%, 86.0%)	
07/02 06:59:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][250/703]	Step 54458	lr 0.08476	Loss 1.6946 (1.5349)	Prec@(1,5) (56.9%, 86.0%)	
07/02 06:59:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][300/703]	Step 54508	lr 0.08476	Loss 1.7599 (1.5402)	Prec@(1,5) (56.9%, 85.8%)	
07/02 06:59:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][350/703]	Step 54558	lr 0.08476	Loss 1.6387 (1.5501)	Prec@(1,5) (56.6%, 85.7%)	
07/02 06:59:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][400/703]	Step 54608	lr 0.08476	Loss 1.7711 (1.5534)	Prec@(1,5) (56.5%, 85.6%)	
07/02 06:59:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][450/703]	Step 54658	lr 0.08476	Loss 1.5278 (1.5567)	Prec@(1,5) (56.4%, 85.6%)	
07/02 06:59:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][500/703]	Step 54708	lr 0.08476	Loss 1.4703 (1.5639)	Prec@(1,5) (56.1%, 85.5%)	
07/02 06:59:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][550/703]	Step 54758	lr 0.08476	Loss 1.3874 (1.5701)	Prec@(1,5) (55.9%, 85.4%)	
07/02 06:59:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][600/703]	Step 54808	lr 0.08476	Loss 1.6291 (1.5765)	Prec@(1,5) (55.7%, 85.3%)	
07/02 06:59:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][650/703]	Step 54858	lr 0.08476	Loss 1.0267 (1.5762)	Prec@(1,5) (55.8%, 85.2%)	
07/02 06:59:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][700/703]	Step 54908	lr 0.08476	Loss 1.4286 (1.5774)	Prec@(1,5) (55.7%, 85.2%)	
07/02 06:59:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [77][703/703]	Step 54911	lr 0.08476	Loss 1.7340 (1.5777)	Prec@(1,5) (55.7%, 85.2%)	
07/02 06:59:38午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 77/299] Final Prec@1 55.7289%
07/02 06:59:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [77][50/79]	Step 54912	Loss 1.9631	Prec@(1,5) (48.0%, 78.8%)
07/02 06:59:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [77][78/79]	Step 54912	Loss 1.9783	Prec@(1,5) (48.0%, 78.9%)
07/02 06:59:39午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 77/299] Final Prec@1 47.9400%
07/02 06:59:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 06:59:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][50/703]	Step 54962	lr 0.08439	Loss 1.9203 (1.5145)	Prec@(1,5) (58.0%, 85.9%)	
07/02 06:59:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][100/703]	Step 55012	lr 0.08439	Loss 1.4810 (1.4784)	Prec@(1,5) (58.4%, 86.7%)	
07/02 06:59:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][150/703]	Step 55062	lr 0.08439	Loss 1.4467 (1.4946)	Prec@(1,5) (57.9%, 86.3%)	
07/02 06:59:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][200/703]	Step 55112	lr 0.08439	Loss 1.7805 (1.4952)	Prec@(1,5) (57.7%, 86.7%)	
07/02 06:59:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][250/703]	Step 55162	lr 0.08439	Loss 1.2310 (1.5091)	Prec@(1,5) (57.2%, 86.3%)	
07/02 06:59:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][300/703]	Step 55212	lr 0.08439	Loss 1.6085 (1.5259)	Prec@(1,5) (56.7%, 86.2%)	
07/02 07:00:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][350/703]	Step 55262	lr 0.08439	Loss 1.5790 (1.5350)	Prec@(1,5) (56.6%, 86.0%)	
07/02 07:00:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][400/703]	Step 55312	lr 0.08439	Loss 1.6961 (1.5476)	Prec@(1,5) (56.3%, 85.8%)	
07/02 07:00:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][450/703]	Step 55362	lr 0.08439	Loss 1.5662 (1.5545)	Prec@(1,5) (56.1%, 85.7%)	
07/02 07:00:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][500/703]	Step 55412	lr 0.08439	Loss 1.1412 (1.5596)	Prec@(1,5) (55.9%, 85.6%)	
07/02 07:00:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][550/703]	Step 55462	lr 0.08439	Loss 1.7343 (1.5612)	Prec@(1,5) (56.0%, 85.6%)	
07/02 07:00:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][600/703]	Step 55512	lr 0.08439	Loss 1.5701 (1.5632)	Prec@(1,5) (55.9%, 85.6%)	
07/02 07:00:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][650/703]	Step 55562	lr 0.08439	Loss 1.7733 (1.5693)	Prec@(1,5) (55.8%, 85.4%)	
07/02 07:00:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][700/703]	Step 55612	lr 0.08439	Loss 1.6282 (1.5752)	Prec@(1,5) (55.6%, 85.3%)	
07/02 07:00:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [78][703/703]	Step 55615	lr 0.08439	Loss 1.9422 (1.5757)	Prec@(1,5) (55.6%, 85.3%)	
07/02 07:00:24午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 78/299] Final Prec@1 55.5844%
07/02 07:00:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [78][50/79]	Step 55616	Loss 2.0259	Prec@(1,5) (47.1%, 77.6%)
07/02 07:00:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [78][78/79]	Step 55616	Loss 2.0351	Prec@(1,5) (46.6%, 77.6%)
07/02 07:00:25午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 78/299] Final Prec@1 46.6400%
07/02 07:00:25午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 07:00:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][50/703]	Step 55666	lr 0.08401	Loss 1.4837 (1.5398)	Prec@(1,5) (57.2%, 86.4%)	
07/02 07:00:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][100/703]	Step 55716	lr 0.08401	Loss 1.8053 (1.5294)	Prec@(1,5) (57.0%, 86.3%)	
07/02 07:00:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][150/703]	Step 55766	lr 0.08401	Loss 1.6103 (1.5097)	Prec@(1,5) (57.5%, 86.4%)	
07/02 07:00:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][200/703]	Step 55816	lr 0.08401	Loss 1.5992 (1.5077)	Prec@(1,5) (57.5%, 86.5%)	
07/02 07:00:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][250/703]	Step 55866	lr 0.08401	Loss 1.5484 (1.5203)	Prec@(1,5) (56.9%, 86.3%)	
07/02 07:00:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][300/703]	Step 55916	lr 0.08401	Loss 1.4117 (1.5297)	Prec@(1,5) (56.7%, 86.3%)	
07/02 07:00:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][350/703]	Step 55966	lr 0.08401	Loss 1.7096 (1.5425)	Prec@(1,5) (56.3%, 86.1%)	
07/02 07:00:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][400/703]	Step 56016	lr 0.08401	Loss 1.3503 (1.5498)	Prec@(1,5) (56.1%, 86.0%)	
07/02 07:00:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][450/703]	Step 56066	lr 0.08401	Loss 1.6183 (1.5560)	Prec@(1,5) (56.0%, 85.9%)	
07/02 07:00:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][500/703]	Step 56116	lr 0.08401	Loss 1.8431 (1.5596)	Prec@(1,5) (56.0%, 85.8%)	
07/02 07:01:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][550/703]	Step 56166	lr 0.08401	Loss 1.4534 (1.5661)	Prec@(1,5) (55.8%, 85.7%)	
07/02 07:01:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][600/703]	Step 56216	lr 0.08401	Loss 1.6948 (1.5702)	Prec@(1,5) (55.7%, 85.7%)	
07/02 07:01:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][650/703]	Step 56266	lr 0.08401	Loss 1.3770 (1.5762)	Prec@(1,5) (55.6%, 85.5%)	
07/02 07:01:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][700/703]	Step 56316	lr 0.08401	Loss 1.5377 (1.5801)	Prec@(1,5) (55.5%, 85.4%)	
07/02 07:01:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [79][703/703]	Step 56319	lr 0.08401	Loss 1.9322 (1.5810)	Prec@(1,5) (55.5%, 85.4%)	
07/02 07:01:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 79/299] Final Prec@1 55.4667%
07/02 07:01:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [79][50/79]	Step 56320	Loss 2.0063	Prec@(1,5) (47.7%, 77.9%)
07/02 07:01:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [79][78/79]	Step 56320	Loss 2.0106	Prec@(1,5) (47.2%, 77.8%)
07/02 07:01:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 79/299] Final Prec@1 47.2200%
07/02 07:01:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 07:01:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][50/703]	Step 56370	lr 0.08362	Loss 1.2697 (1.5282)	Prec@(1,5) (56.3%, 86.2%)	
07/02 07:01:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][100/703]	Step 56420	lr 0.08362	Loss 1.2249 (1.5256)	Prec@(1,5) (56.9%, 86.2%)	
07/02 07:01:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][150/703]	Step 56470	lr 0.08362	Loss 1.2661 (1.5145)	Prec@(1,5) (57.4%, 86.4%)	
07/02 07:01:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][200/703]	Step 56520	lr 0.08362	Loss 1.1894 (1.5310)	Prec@(1,5) (57.0%, 86.0%)	
07/02 07:01:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][250/703]	Step 56570	lr 0.08362	Loss 1.4228 (1.5327)	Prec@(1,5) (56.8%, 86.1%)	
07/02 07:01:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][300/703]	Step 56620	lr 0.08362	Loss 2.1457 (1.5389)	Prec@(1,5) (56.6%, 86.1%)	
07/02 07:01:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][350/703]	Step 56670	lr 0.08362	Loss 1.4064 (1.5450)	Prec@(1,5) (56.6%, 85.9%)	
07/02 07:01:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][400/703]	Step 56720	lr 0.08362	Loss 1.6061 (1.5461)	Prec@(1,5) (56.7%, 85.8%)	
07/02 07:01:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][450/703]	Step 56770	lr 0.08362	Loss 1.4302 (1.5530)	Prec@(1,5) (56.4%, 85.8%)	
07/02 07:01:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][500/703]	Step 56820	lr 0.08362	Loss 1.4216 (1.5627)	Prec@(1,5) (56.3%, 85.6%)	
07/02 07:01:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][550/703]	Step 56870	lr 0.08362	Loss 1.8701 (1.5674)	Prec@(1,5) (56.2%, 85.6%)	
07/02 07:01:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][600/703]	Step 56920	lr 0.08362	Loss 1.4030 (1.5659)	Prec@(1,5) (56.2%, 85.5%)	
07/02 07:01:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][650/703]	Step 56970	lr 0.08362	Loss 1.4224 (1.5707)	Prec@(1,5) (56.0%, 85.5%)	
07/02 07:01:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][700/703]	Step 57020	lr 0.08362	Loss 1.4709 (1.5700)	Prec@(1,5) (56.0%, 85.4%)	
07/02 07:01:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [80][703/703]	Step 57023	lr 0.08362	Loss 1.3417 (1.5698)	Prec@(1,5) (56.1%, 85.4%)	
07/02 07:01:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 80/299] Final Prec@1 56.0800%
07/02 07:01:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [80][50/79]	Step 57024	Loss 2.0396	Prec@(1,5) (46.3%, 78.3%)
07/02 07:01:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [80][78/79]	Step 57024	Loss 2.0397	Prec@(1,5) (46.8%, 77.9%)
07/02 07:01:58午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 80/299] Final Prec@1 46.8200%
07/02 07:01:59午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 07:02:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][50/703]	Step 57074	lr 0.08323	Loss 1.3880 (1.4766)	Prec@(1,5) (58.1%, 87.2%)	
07/02 07:02:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][100/703]	Step 57124	lr 0.08323	Loss 1.3839 (1.5093)	Prec@(1,5) (56.8%, 86.8%)	
07/02 07:02:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][150/703]	Step 57174	lr 0.08323	Loss 1.2912 (1.4917)	Prec@(1,5) (57.4%, 87.0%)	
07/02 07:02:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][200/703]	Step 57224	lr 0.08323	Loss 1.4410 (1.4913)	Prec@(1,5) (57.4%, 86.7%)	
07/02 07:02:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][250/703]	Step 57274	lr 0.08323	Loss 1.4969 (1.5001)	Prec@(1,5) (57.3%, 86.6%)	
07/02 07:02:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][300/703]	Step 57324	lr 0.08323	Loss 1.3757 (1.5102)	Prec@(1,5) (57.1%, 86.5%)	
07/02 07:02:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][350/703]	Step 57374	lr 0.08323	Loss 1.6696 (1.5278)	Prec@(1,5) (56.7%, 86.1%)	
07/02 07:02:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][400/703]	Step 57424	lr 0.08323	Loss 1.4623 (1.5359)	Prec@(1,5) (56.6%, 85.9%)	
07/02 07:02:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][450/703]	Step 57474	lr 0.08323	Loss 1.9560 (1.5361)	Prec@(1,5) (56.6%, 85.9%)	
07/02 07:02:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][500/703]	Step 57524	lr 0.08323	Loss 1.7643 (1.5439)	Prec@(1,5) (56.4%, 85.8%)	
07/02 07:02:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][550/703]	Step 57574	lr 0.08323	Loss 2.0162 (1.5502)	Prec@(1,5) (56.2%, 85.7%)	
07/02 07:02:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][600/703]	Step 57624	lr 0.08323	Loss 1.8137 (1.5563)	Prec@(1,5) (56.0%, 85.6%)	
07/02 07:02:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][650/703]	Step 57674	lr 0.08323	Loss 1.9035 (1.5593)	Prec@(1,5) (56.1%, 85.6%)	
07/02 07:02:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][700/703]	Step 57724	lr 0.08323	Loss 1.7500 (1.5665)	Prec@(1,5) (55.9%, 85.5%)	
07/02 07:02:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [81][703/703]	Step 57727	lr 0.08323	Loss 1.4849 (1.5668)	Prec@(1,5) (55.9%, 85.5%)	
07/02 07:02:43午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 81/299] Final Prec@1 55.9156%
07/02 07:02:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [81][50/79]	Step 57728	Loss 1.9865	Prec@(1,5) (48.0%, 79.0%)
07/02 07:02:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [81][78/79]	Step 57728	Loss 1.9615	Prec@(1,5) (48.5%, 79.5%)
07/02 07:02:45午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 81/299] Final Prec@1 48.4600%
07/02 07:02:45午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.3800%
07/02 07:02:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][50/703]	Step 57778	lr 0.08284	Loss 1.5796 (1.4710)	Prec@(1,5) (57.9%, 86.7%)	
07/02 07:02:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][100/703]	Step 57828	lr 0.08284	Loss 1.3206 (1.4780)	Prec@(1,5) (57.9%, 87.0%)	
07/02 07:02:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][150/703]	Step 57878	lr 0.08284	Loss 1.6902 (1.4995)	Prec@(1,5) (57.6%, 86.4%)	
07/02 07:02:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][200/703]	Step 57928	lr 0.08284	Loss 1.6333 (1.4936)	Prec@(1,5) (57.9%, 86.5%)	
07/02 07:03:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][250/703]	Step 57978	lr 0.08284	Loss 1.8169 (1.5043)	Prec@(1,5) (57.7%, 86.3%)	
07/02 07:03:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][300/703]	Step 58028	lr 0.08284	Loss 1.6963 (1.5114)	Prec@(1,5) (57.5%, 86.2%)	
07/02 07:03:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][350/703]	Step 58078	lr 0.08284	Loss 1.2832 (1.5170)	Prec@(1,5) (57.1%, 86.2%)	
07/02 07:03:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][400/703]	Step 58128	lr 0.08284	Loss 1.9398 (1.5244)	Prec@(1,5) (57.0%, 86.0%)	
07/02 07:03:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][450/703]	Step 58178	lr 0.08284	Loss 1.7132 (1.5335)	Prec@(1,5) (56.8%, 85.8%)	
07/02 07:03:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][500/703]	Step 58228	lr 0.08284	Loss 1.4472 (1.5397)	Prec@(1,5) (56.6%, 85.7%)	
07/02 07:03:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][550/703]	Step 58278	lr 0.08284	Loss 1.6935 (1.5397)	Prec@(1,5) (56.6%, 85.7%)	
07/02 07:03:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][600/703]	Step 58328	lr 0.08284	Loss 1.6054 (1.5427)	Prec@(1,5) (56.5%, 85.7%)	
07/02 07:03:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][650/703]	Step 58378	lr 0.08284	Loss 1.5119 (1.5482)	Prec@(1,5) (56.4%, 85.7%)	
07/02 07:03:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][700/703]	Step 58428	lr 0.08284	Loss 1.6930 (1.5527)	Prec@(1,5) (56.3%, 85.6%)	
07/02 07:03:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [82][703/703]	Step 58431	lr 0.08284	Loss 2.3001 (1.5546)	Prec@(1,5) (56.2%, 85.6%)	
07/02 07:03:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 82/299] Final Prec@1 56.2044%
07/02 07:03:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [82][50/79]	Step 58432	Loss 1.9001	Prec@(1,5) (50.5%, 79.4%)
07/02 07:03:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [82][78/79]	Step 58432	Loss 1.8980	Prec@(1,5) (49.7%, 79.4%)
07/02 07:03:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 82/299] Final Prec@1 49.7200%
07/02 07:03:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:03:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][50/703]	Step 58482	lr 0.08245	Loss 1.3049 (1.4525)	Prec@(1,5) (58.7%, 87.4%)	
07/02 07:03:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][100/703]	Step 58532	lr 0.08245	Loss 1.4788 (1.4875)	Prec@(1,5) (58.2%, 86.5%)	
07/02 07:03:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][150/703]	Step 58582	lr 0.08245	Loss 1.1229 (1.5003)	Prec@(1,5) (57.8%, 86.3%)	
07/02 07:03:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][200/703]	Step 58632	lr 0.08245	Loss 1.3574 (1.5148)	Prec@(1,5) (57.2%, 86.2%)	
07/02 07:03:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][250/703]	Step 58682	lr 0.08245	Loss 1.4559 (1.5206)	Prec@(1,5) (57.2%, 86.0%)	
07/02 07:03:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][300/703]	Step 58732	lr 0.08245	Loss 1.4206 (1.5238)	Prec@(1,5) (57.0%, 86.0%)	
07/02 07:03:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][350/703]	Step 58782	lr 0.08245	Loss 1.5136 (1.5255)	Prec@(1,5) (56.9%, 86.0%)	
07/02 07:03:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][400/703]	Step 58832	lr 0.08245	Loss 1.4854 (1.5317)	Prec@(1,5) (56.7%, 85.9%)	
07/02 07:03:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][450/703]	Step 58882	lr 0.08245	Loss 1.5816 (1.5385)	Prec@(1,5) (56.6%, 85.8%)	
07/02 07:04:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][500/703]	Step 58932	lr 0.08245	Loss 1.7047 (1.5470)	Prec@(1,5) (56.4%, 85.7%)	
07/02 07:04:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][550/703]	Step 58982	lr 0.08245	Loss 2.3249 (1.5527)	Prec@(1,5) (56.2%, 85.7%)	
07/02 07:04:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][600/703]	Step 59032	lr 0.08245	Loss 1.4623 (1.5567)	Prec@(1,5) (56.1%, 85.5%)	
07/02 07:04:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][650/703]	Step 59082	lr 0.08245	Loss 1.1745 (1.5581)	Prec@(1,5) (56.1%, 85.6%)	
07/02 07:04:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][700/703]	Step 59132	lr 0.08245	Loss 1.5344 (1.5602)	Prec@(1,5) (56.0%, 85.4%)	
07/02 07:04:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [83][703/703]	Step 59135	lr 0.08245	Loss 1.1178 (1.5600)	Prec@(1,5) (56.0%, 85.4%)	
07/02 07:04:15午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 83/299] Final Prec@1 56.0400%
07/02 07:04:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [83][50/79]	Step 59136	Loss 1.9980	Prec@(1,5) (47.5%, 78.0%)
07/02 07:04:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [83][78/79]	Step 59136	Loss 1.9828	Prec@(1,5) (48.0%, 78.1%)
07/02 07:04:17午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 83/299] Final Prec@1 47.9600%
07/02 07:04:17午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:04:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][50/703]	Step 59186	lr 0.08205	Loss 1.2058 (1.4738)	Prec@(1,5) (58.1%, 87.5%)	
07/02 07:04:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][100/703]	Step 59236	lr 0.08205	Loss 1.4001 (1.4770)	Prec@(1,5) (57.7%, 87.1%)	
07/02 07:04:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][150/703]	Step 59286	lr 0.08205	Loss 1.6461 (1.4829)	Prec@(1,5) (57.6%, 87.0%)	
07/02 07:04:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][200/703]	Step 59336	lr 0.08205	Loss 1.4165 (1.5043)	Prec@(1,5) (57.1%, 86.6%)	
07/02 07:04:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][250/703]	Step 59386	lr 0.08205	Loss 1.5421 (1.5116)	Prec@(1,5) (57.0%, 86.4%)	
07/02 07:04:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][300/703]	Step 59436	lr 0.08205	Loss 1.7051 (1.5173)	Prec@(1,5) (57.0%, 86.3%)	
07/02 07:04:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][350/703]	Step 59486	lr 0.08205	Loss 1.2672 (1.5163)	Prec@(1,5) (57.1%, 86.4%)	
07/02 07:04:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][400/703]	Step 59536	lr 0.08205	Loss 1.2589 (1.5234)	Prec@(1,5) (56.9%, 86.4%)	
07/02 07:04:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][450/703]	Step 59586	lr 0.08205	Loss 1.3993 (1.5270)	Prec@(1,5) (56.9%, 86.3%)	
07/02 07:04:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][500/703]	Step 59636	lr 0.08205	Loss 1.6561 (1.5295)	Prec@(1,5) (56.8%, 86.2%)	
07/02 07:04:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][550/703]	Step 59686	lr 0.08205	Loss 1.5976 (1.5319)	Prec@(1,5) (56.7%, 86.2%)	
07/02 07:04:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][600/703]	Step 59736	lr 0.08205	Loss 1.3285 (1.5396)	Prec@(1,5) (56.5%, 86.1%)	
07/02 07:04:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][650/703]	Step 59786	lr 0.08205	Loss 1.5740 (1.5455)	Prec@(1,5) (56.4%, 86.0%)	
07/02 07:05:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][700/703]	Step 59836	lr 0.08205	Loss 1.4084 (1.5477)	Prec@(1,5) (56.4%, 85.9%)	
07/02 07:05:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [84][703/703]	Step 59839	lr 0.08205	Loss 1.7719 (1.5482)	Prec@(1,5) (56.4%, 85.9%)	
07/02 07:05:02午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 84/299] Final Prec@1 56.3622%
07/02 07:05:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [84][50/79]	Step 59840	Loss 1.9640	Prec@(1,5) (47.9%, 78.6%)
07/02 07:05:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [84][78/79]	Step 59840	Loss 1.9738	Prec@(1,5) (48.0%, 78.5%)
07/02 07:05:04午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 84/299] Final Prec@1 48.0400%
07/02 07:05:04午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:05:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][50/703]	Step 59890	lr 0.08165	Loss 1.6512 (1.4571)	Prec@(1,5) (59.8%, 87.8%)	
07/02 07:05:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][100/703]	Step 59940	lr 0.08165	Loss 1.6003 (1.4709)	Prec@(1,5) (58.3%, 87.2%)	
07/02 07:05:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][150/703]	Step 59990	lr 0.08165	Loss 1.4142 (1.4685)	Prec@(1,5) (58.8%, 87.3%)	
07/02 07:05:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][200/703]	Step 60040	lr 0.08165	Loss 1.3387 (1.4647)	Prec@(1,5) (58.7%, 87.3%)	
07/02 07:05:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][250/703]	Step 60090	lr 0.08165	Loss 1.4598 (1.4860)	Prec@(1,5) (58.0%, 87.1%)	
07/02 07:05:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][300/703]	Step 60140	lr 0.08165	Loss 1.6556 (1.4994)	Prec@(1,5) (57.8%, 86.8%)	
07/02 07:05:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][350/703]	Step 60190	lr 0.08165	Loss 1.7299 (1.5096)	Prec@(1,5) (57.4%, 86.6%)	
07/02 07:05:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][400/703]	Step 60240	lr 0.08165	Loss 1.3736 (1.5146)	Prec@(1,5) (57.3%, 86.5%)	
07/02 07:05:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][450/703]	Step 60290	lr 0.08165	Loss 1.6399 (1.5212)	Prec@(1,5) (57.1%, 86.4%)	
07/02 07:05:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][500/703]	Step 60340	lr 0.08165	Loss 1.4809 (1.5292)	Prec@(1,5) (56.8%, 86.3%)	
07/02 07:05:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][550/703]	Step 60390	lr 0.08165	Loss 1.9430 (1.5364)	Prec@(1,5) (56.7%, 86.2%)	
07/02 07:05:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][600/703]	Step 60440	lr 0.08165	Loss 1.8165 (1.5366)	Prec@(1,5) (56.7%, 86.1%)	
07/02 07:05:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][650/703]	Step 60490	lr 0.08165	Loss 1.7613 (1.5388)	Prec@(1,5) (56.7%, 86.0%)	
07/02 07:05:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][700/703]	Step 60540	lr 0.08165	Loss 1.5092 (1.5433)	Prec@(1,5) (56.5%, 85.9%)	
07/02 07:05:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [85][703/703]	Step 60543	lr 0.08165	Loss 1.6613 (1.5441)	Prec@(1,5) (56.5%, 85.9%)	
07/02 07:05:49午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 85/299] Final Prec@1 56.5200%
07/02 07:05:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [85][50/79]	Step 60544	Loss 1.9696	Prec@(1,5) (47.1%, 78.7%)
07/02 07:05:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [85][78/79]	Step 60544	Loss 1.9504	Prec@(1,5) (48.5%, 79.0%)
07/02 07:05:50午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 85/299] Final Prec@1 48.5600%
07/02 07:05:51午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:05:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][50/703]	Step 60594	lr 0.08125	Loss 1.5225 (1.4621)	Prec@(1,5) (58.1%, 87.3%)	
07/02 07:05:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][100/703]	Step 60644	lr 0.08125	Loss 1.4693 (1.4635)	Prec@(1,5) (58.4%, 87.3%)	
07/02 07:06:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][150/703]	Step 60694	lr 0.08125	Loss 1.4778 (1.4645)	Prec@(1,5) (58.6%, 87.3%)	
07/02 07:06:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][200/703]	Step 60744	lr 0.08125	Loss 1.5720 (1.4744)	Prec@(1,5) (58.3%, 87.0%)	
07/02 07:06:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][250/703]	Step 60794	lr 0.08125	Loss 1.6041 (1.4885)	Prec@(1,5) (57.9%, 86.8%)	
07/02 07:06:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][300/703]	Step 60844	lr 0.08125	Loss 1.2016 (1.5016)	Prec@(1,5) (57.6%, 86.7%)	
07/02 07:06:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][350/703]	Step 60894	lr 0.08125	Loss 1.7316 (1.5034)	Prec@(1,5) (57.6%, 86.6%)	
07/02 07:06:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][400/703]	Step 60944	lr 0.08125	Loss 1.6778 (1.5056)	Prec@(1,5) (57.5%, 86.5%)	
07/02 07:06:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][450/703]	Step 60994	lr 0.08125	Loss 1.4901 (1.5120)	Prec@(1,5) (57.3%, 86.4%)	
07/02 07:06:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][500/703]	Step 61044	lr 0.08125	Loss 1.8206 (1.5198)	Prec@(1,5) (57.1%, 86.4%)	
07/02 07:06:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][550/703]	Step 61094	lr 0.08125	Loss 1.9401 (1.5195)	Prec@(1,5) (57.2%, 86.4%)	
07/02 07:06:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][600/703]	Step 61144	lr 0.08125	Loss 1.8118 (1.5263)	Prec@(1,5) (57.1%, 86.3%)	
07/02 07:06:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][650/703]	Step 61194	lr 0.08125	Loss 1.5693 (1.5322)	Prec@(1,5) (56.9%, 86.2%)	
07/02 07:06:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][700/703]	Step 61244	lr 0.08125	Loss 1.9795 (1.5365)	Prec@(1,5) (56.8%, 86.1%)	
07/02 07:06:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [86][703/703]	Step 61247	lr 0.08125	Loss 1.3157 (1.5367)	Prec@(1,5) (56.8%, 86.1%)	
07/02 07:06:34午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 86/299] Final Prec@1 56.8378%
07/02 07:06:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [86][50/79]	Step 61248	Loss 1.9190	Prec@(1,5) (49.0%, 78.9%)
07/02 07:06:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [86][78/79]	Step 61248	Loss 1.9194	Prec@(1,5) (49.3%, 79.3%)
07/02 07:06:36午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 86/299] Final Prec@1 49.3200%
07/02 07:06:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:06:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][50/703]	Step 61298	lr 0.08084	Loss 1.4915 (1.4446)	Prec@(1,5) (59.0%, 87.7%)	
07/02 07:06:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][100/703]	Step 61348	lr 0.08084	Loss 1.4389 (1.4605)	Prec@(1,5) (58.4%, 87.2%)	
07/02 07:06:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][150/703]	Step 61398	lr 0.08084	Loss 1.4448 (1.4568)	Prec@(1,5) (58.4%, 87.4%)	
07/02 07:06:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][200/703]	Step 61448	lr 0.08084	Loss 1.7693 (1.4825)	Prec@(1,5) (57.8%, 86.9%)	
07/02 07:06:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][250/703]	Step 61498	lr 0.08084	Loss 1.3712 (1.4810)	Prec@(1,5) (58.1%, 86.8%)	
07/02 07:06:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][300/703]	Step 61548	lr 0.08084	Loss 1.6046 (1.4824)	Prec@(1,5) (58.0%, 86.9%)	
07/02 07:06:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][350/703]	Step 61598	lr 0.08084	Loss 1.4332 (1.4941)	Prec@(1,5) (57.7%, 86.7%)	
07/02 07:07:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][400/703]	Step 61648	lr 0.08084	Loss 1.2306 (1.5028)	Prec@(1,5) (57.5%, 86.6%)	
07/02 07:07:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][450/703]	Step 61698	lr 0.08084	Loss 1.1514 (1.5053)	Prec@(1,5) (57.4%, 86.6%)	
07/02 07:07:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][500/703]	Step 61748	lr 0.08084	Loss 1.4752 (1.5125)	Prec@(1,5) (57.2%, 86.5%)	
07/02 07:07:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][550/703]	Step 61798	lr 0.08084	Loss 1.6763 (1.5224)	Prec@(1,5) (57.0%, 86.3%)	
07/02 07:07:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][600/703]	Step 61848	lr 0.08084	Loss 1.6100 (1.5264)	Prec@(1,5) (56.9%, 86.2%)	
07/02 07:07:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][650/703]	Step 61898	lr 0.08084	Loss 1.4349 (1.5314)	Prec@(1,5) (56.8%, 86.1%)	
07/02 07:07:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][700/703]	Step 61948	lr 0.08084	Loss 1.6332 (1.5384)	Prec@(1,5) (56.6%, 86.0%)	
07/02 07:07:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [87][703/703]	Step 61951	lr 0.08084	Loss 1.5498 (1.5394)	Prec@(1,5) (56.6%, 86.0%)	
07/02 07:07:21午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 87/299] Final Prec@1 56.5867%
07/02 07:07:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [87][50/79]	Step 61952	Loss 1.9664	Prec@(1,5) (48.3%, 77.9%)
07/02 07:07:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [87][78/79]	Step 61952	Loss 1.9568	Prec@(1,5) (48.3%, 78.3%)
07/02 07:07:23午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 87/299] Final Prec@1 48.3200%
07/02 07:07:23午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:07:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][50/703]	Step 62002	lr 0.08043	Loss 1.3870 (1.4675)	Prec@(1,5) (57.7%, 87.5%)	
07/02 07:07:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][100/703]	Step 62052	lr 0.08043	Loss 1.2721 (1.4452)	Prec@(1,5) (58.3%, 87.6%)	
07/02 07:07:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][150/703]	Step 62102	lr 0.08043	Loss 1.5154 (1.4558)	Prec@(1,5) (58.3%, 87.2%)	
07/02 07:07:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][200/703]	Step 62152	lr 0.08043	Loss 1.5988 (1.4721)	Prec@(1,5) (57.9%, 86.9%)	
07/02 07:07:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][250/703]	Step 62202	lr 0.08043	Loss 1.4711 (1.4949)	Prec@(1,5) (57.3%, 86.6%)	
07/02 07:07:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][300/703]	Step 62252	lr 0.08043	Loss 1.5627 (1.4952)	Prec@(1,5) (57.2%, 86.6%)	
07/02 07:07:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][350/703]	Step 62302	lr 0.08043	Loss 1.5680 (1.5054)	Prec@(1,5) (57.0%, 86.5%)	
07/02 07:07:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][400/703]	Step 62352	lr 0.08043	Loss 1.3341 (1.5137)	Prec@(1,5) (56.9%, 86.4%)	
07/02 07:07:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][450/703]	Step 62402	lr 0.08043	Loss 1.4900 (1.5137)	Prec@(1,5) (57.0%, 86.4%)	
07/02 07:07:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][500/703]	Step 62452	lr 0.08043	Loss 1.8070 (1.5199)	Prec@(1,5) (56.8%, 86.2%)	
07/02 07:07:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][550/703]	Step 62502	lr 0.08043	Loss 1.7087 (1.5243)	Prec@(1,5) (56.7%, 86.2%)	
07/02 07:08:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][600/703]	Step 62552	lr 0.08043	Loss 1.3640 (1.5272)	Prec@(1,5) (56.5%, 86.2%)	
07/02 07:08:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][650/703]	Step 62602	lr 0.08043	Loss 1.3581 (1.5320)	Prec@(1,5) (56.4%, 86.1%)	
07/02 07:08:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][700/703]	Step 62652	lr 0.08043	Loss 1.7948 (1.5386)	Prec@(1,5) (56.4%, 85.9%)	
07/02 07:08:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [88][703/703]	Step 62655	lr 0.08043	Loss 1.6511 (1.5393)	Prec@(1,5) (56.3%, 85.9%)	
07/02 07:08:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 88/299] Final Prec@1 56.3311%
07/02 07:08:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [88][50/79]	Step 62656	Loss 1.9711	Prec@(1,5) (47.7%, 78.7%)
07/02 07:08:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [88][78/79]	Step 62656	Loss 1.9953	Prec@(1,5) (47.5%, 78.4%)
07/02 07:08:11午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 88/299] Final Prec@1 47.5200%
07/02 07:08:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:08:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][50/703]	Step 62706	lr 0.08001	Loss 1.3339 (1.4762)	Prec@(1,5) (58.0%, 86.8%)	
07/02 07:08:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][100/703]	Step 62756	lr 0.08001	Loss 1.3107 (1.4537)	Prec@(1,5) (58.0%, 87.7%)	
07/02 07:08:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][150/703]	Step 62806	lr 0.08001	Loss 1.3723 (1.4585)	Prec@(1,5) (58.2%, 87.1%)	
07/02 07:08:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][200/703]	Step 62856	lr 0.08001	Loss 1.8825 (1.4723)	Prec@(1,5) (58.2%, 87.0%)	
07/02 07:08:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][250/703]	Step 62906	lr 0.08001	Loss 1.5832 (1.4867)	Prec@(1,5) (57.9%, 86.8%)	
07/02 07:08:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][300/703]	Step 62956	lr 0.08001	Loss 1.3084 (1.4854)	Prec@(1,5) (58.0%, 86.8%)	
07/02 07:08:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][350/703]	Step 63006	lr 0.08001	Loss 1.2434 (1.4856)	Prec@(1,5) (57.7%, 86.9%)	
07/02 07:08:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][400/703]	Step 63056	lr 0.08001	Loss 1.0076 (1.4847)	Prec@(1,5) (57.9%, 86.9%)	
07/02 07:08:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][450/703]	Step 63106	lr 0.08001	Loss 1.4500 (1.4901)	Prec@(1,5) (57.9%, 86.7%)	
07/02 07:08:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][500/703]	Step 63156	lr 0.08001	Loss 1.3359 (1.4955)	Prec@(1,5) (57.7%, 86.7%)	
07/02 07:08:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][550/703]	Step 63206	lr 0.08001	Loss 1.5025 (1.5014)	Prec@(1,5) (57.6%, 86.6%)	
07/02 07:08:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][600/703]	Step 63256	lr 0.08001	Loss 1.8259 (1.5063)	Prec@(1,5) (57.5%, 86.6%)	
07/02 07:08:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][650/703]	Step 63306	lr 0.08001	Loss 1.9087 (1.5143)	Prec@(1,5) (57.3%, 86.4%)	
07/02 07:08:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][700/703]	Step 63356	lr 0.08001	Loss 1.5626 (1.5188)	Prec@(1,5) (57.2%, 86.3%)	
07/02 07:08:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [89][703/703]	Step 63359	lr 0.08001	Loss 1.6395 (1.5184)	Prec@(1,5) (57.2%, 86.4%)	
07/02 07:08:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 89/299] Final Prec@1 57.1889%
07/02 07:08:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [89][50/79]	Step 63360	Loss 1.9638	Prec@(1,5) (47.6%, 78.9%)
07/02 07:08:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [89][78/79]	Step 63360	Loss 1.9774	Prec@(1,5) (47.5%, 79.0%)
07/02 07:08:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 89/299] Final Prec@1 47.4600%
07/02 07:08:58午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:09:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][50/703]	Step 63410	lr 0.0796	Loss 1.4584 (1.4609)	Prec@(1,5) (59.1%, 87.6%)	
07/02 07:09:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][100/703]	Step 63460	lr 0.0796	Loss 1.5405 (1.4756)	Prec@(1,5) (58.6%, 87.3%)	
07/02 07:09:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][150/703]	Step 63510	lr 0.0796	Loss 1.4575 (1.4750)	Prec@(1,5) (58.6%, 87.1%)	
07/02 07:09:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][200/703]	Step 63560	lr 0.0796	Loss 1.6686 (1.4689)	Prec@(1,5) (58.9%, 87.1%)	
07/02 07:09:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][250/703]	Step 63610	lr 0.0796	Loss 1.5280 (1.4828)	Prec@(1,5) (58.3%, 86.9%)	
07/02 07:09:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][300/703]	Step 63660	lr 0.0796	Loss 1.3685 (1.4873)	Prec@(1,5) (58.2%, 86.9%)	
07/02 07:09:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][350/703]	Step 63710	lr 0.0796	Loss 1.4473 (1.5016)	Prec@(1,5) (57.8%, 86.6%)	
07/02 07:09:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][400/703]	Step 63760	lr 0.0796	Loss 1.4859 (1.5133)	Prec@(1,5) (57.5%, 86.5%)	
07/02 07:09:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][450/703]	Step 63810	lr 0.0796	Loss 1.2240 (1.5155)	Prec@(1,5) (57.4%, 86.4%)	
07/02 07:09:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][500/703]	Step 63860	lr 0.0796	Loss 1.5411 (1.5103)	Prec@(1,5) (57.6%, 86.5%)	
07/02 07:09:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][550/703]	Step 63910	lr 0.0796	Loss 1.1930 (1.5133)	Prec@(1,5) (57.5%, 86.5%)	
07/02 07:09:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][600/703]	Step 63960	lr 0.0796	Loss 1.1665 (1.5115)	Prec@(1,5) (57.5%, 86.5%)	
07/02 07:09:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][650/703]	Step 64010	lr 0.0796	Loss 1.3991 (1.5169)	Prec@(1,5) (57.4%, 86.4%)	
07/02 07:09:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][700/703]	Step 64060	lr 0.0796	Loss 1.6933 (1.5193)	Prec@(1,5) (57.2%, 86.4%)	
07/02 07:09:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [90][703/703]	Step 64063	lr 0.0796	Loss 1.6037 (1.5201)	Prec@(1,5) (57.2%, 86.4%)	
07/02 07:09:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 90/299] Final Prec@1 57.2200%
07/02 07:09:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [90][50/79]	Step 64064	Loss 2.0213	Prec@(1,5) (48.4%, 77.7%)
07/02 07:09:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [90][78/79]	Step 64064	Loss 1.9845	Prec@(1,5) (48.5%, 78.5%)
07/02 07:09:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 90/299] Final Prec@1 48.5600%
07/02 07:09:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:09:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][50/703]	Step 64114	lr 0.07917	Loss 1.4467 (1.4542)	Prec@(1,5) (59.5%, 87.3%)	
07/02 07:09:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][100/703]	Step 64164	lr 0.07917	Loss 1.3964 (1.4244)	Prec@(1,5) (59.5%, 87.8%)	
07/02 07:09:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][150/703]	Step 64214	lr 0.07917	Loss 1.2689 (1.4442)	Prec@(1,5) (58.9%, 87.6%)	
07/02 07:09:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][200/703]	Step 64264	lr 0.07917	Loss 0.9759 (1.4380)	Prec@(1,5) (59.1%, 87.6%)	
07/02 07:09:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][250/703]	Step 64314	lr 0.07917	Loss 1.4544 (1.4527)	Prec@(1,5) (58.8%, 87.3%)	
07/02 07:10:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][300/703]	Step 64364	lr 0.07917	Loss 1.8561 (1.4746)	Prec@(1,5) (58.2%, 87.0%)	
07/02 07:10:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][350/703]	Step 64414	lr 0.07917	Loss 1.2945 (1.4860)	Prec@(1,5) (58.0%, 86.8%)	
07/02 07:10:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][400/703]	Step 64464	lr 0.07917	Loss 1.4694 (1.4864)	Prec@(1,5) (57.9%, 86.8%)	
07/02 07:10:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][450/703]	Step 64514	lr 0.07917	Loss 1.6739 (1.4934)	Prec@(1,5) (57.6%, 86.7%)	
07/02 07:10:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][500/703]	Step 64564	lr 0.07917	Loss 1.5313 (1.5001)	Prec@(1,5) (57.4%, 86.7%)	
07/02 07:10:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][550/703]	Step 64614	lr 0.07917	Loss 1.7158 (1.5037)	Prec@(1,5) (57.3%, 86.6%)	
07/02 07:10:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][600/703]	Step 64664	lr 0.07917	Loss 1.2569 (1.5038)	Prec@(1,5) (57.3%, 86.5%)	
07/02 07:10:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][650/703]	Step 64714	lr 0.07917	Loss 1.2666 (1.5084)	Prec@(1,5) (57.2%, 86.4%)	
07/02 07:10:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][700/703]	Step 64764	lr 0.07917	Loss 1.5866 (1.5098)	Prec@(1,5) (57.1%, 86.4%)	
07/02 07:10:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [91][703/703]	Step 64767	lr 0.07917	Loss 1.3854 (1.5098)	Prec@(1,5) (57.1%, 86.4%)	
07/02 07:10:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 91/299] Final Prec@1 57.1356%
07/02 07:10:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [91][50/79]	Step 64768	Loss 2.0606	Prec@(1,5) (46.2%, 77.1%)
07/02 07:10:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [91][78/79]	Step 64768	Loss 2.0346	Prec@(1,5) (47.0%, 77.3%)
07/02 07:10:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 91/299] Final Prec@1 46.9800%
07/02 07:10:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.7200%
07/02 07:10:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][50/703]	Step 64818	lr 0.07875	Loss 1.7428 (1.3838)	Prec@(1,5) (60.8%, 88.9%)	
07/02 07:10:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][100/703]	Step 64868	lr 0.07875	Loss 1.3168 (1.4193)	Prec@(1,5) (59.3%, 87.8%)	
07/02 07:10:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][150/703]	Step 64918	lr 0.07875	Loss 1.7203 (1.4422)	Prec@(1,5) (59.0%, 87.6%)	
07/02 07:10:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][200/703]	Step 64968	lr 0.07875	Loss 1.7316 (1.4563)	Prec@(1,5) (58.8%, 87.2%)	
07/02 07:10:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][250/703]	Step 65018	lr 0.07875	Loss 1.5376 (1.4707)	Prec@(1,5) (58.4%, 87.0%)	
07/02 07:10:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][300/703]	Step 65068	lr 0.07875	Loss 1.4910 (1.4701)	Prec@(1,5) (58.4%, 86.9%)	
07/02 07:10:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][350/703]	Step 65118	lr 0.07875	Loss 1.2876 (1.4722)	Prec@(1,5) (58.3%, 87.0%)	
07/02 07:10:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][400/703]	Step 65168	lr 0.07875	Loss 1.0557 (1.4704)	Prec@(1,5) (58.4%, 86.9%)	
07/02 07:10:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][450/703]	Step 65218	lr 0.07875	Loss 1.6180 (1.4746)	Prec@(1,5) (58.3%, 86.8%)	
07/02 07:11:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][500/703]	Step 65268	lr 0.07875	Loss 1.6921 (1.4765)	Prec@(1,5) (58.3%, 86.9%)	
07/02 07:11:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][550/703]	Step 65318	lr 0.07875	Loss 1.8272 (1.4830)	Prec@(1,5) (58.1%, 86.7%)	
07/02 07:11:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][600/703]	Step 65368	lr 0.07875	Loss 1.5317 (1.4894)	Prec@(1,5) (57.9%, 86.7%)	
07/02 07:11:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][650/703]	Step 65418	lr 0.07875	Loss 1.6712 (1.4941)	Prec@(1,5) (57.8%, 86.7%)	
07/02 07:11:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][700/703]	Step 65468	lr 0.07875	Loss 1.6376 (1.4993)	Prec@(1,5) (57.6%, 86.6%)	
07/02 07:11:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [92][703/703]	Step 65471	lr 0.07875	Loss 1.2541 (1.4988)	Prec@(1,5) (57.6%, 86.6%)	
07/02 07:11:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 92/299] Final Prec@1 57.6422%
07/02 07:11:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [92][50/79]	Step 65472	Loss 1.9088	Prec@(1,5) (49.9%, 79.4%)
07/02 07:11:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [92][78/79]	Step 65472	Loss 1.8973	Prec@(1,5) (49.8%, 79.9%)
07/02 07:11:13午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 92/299] Final Prec@1 49.8000%
07/02 07:11:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.8000%
07/02 07:11:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][50/703]	Step 65522	lr 0.07832	Loss 1.6404 (1.4563)	Prec@(1,5) (58.2%, 87.2%)	
07/02 07:11:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][100/703]	Step 65572	lr 0.07832	Loss 1.6140 (1.4006)	Prec@(1,5) (59.8%, 88.0%)	
07/02 07:11:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][150/703]	Step 65622	lr 0.07832	Loss 1.5837 (1.4149)	Prec@(1,5) (59.6%, 87.9%)	
07/02 07:11:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][200/703]	Step 65672	lr 0.07832	Loss 1.6100 (1.4367)	Prec@(1,5) (59.2%, 87.6%)	
07/02 07:11:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][250/703]	Step 65722	lr 0.07832	Loss 1.2568 (1.4425)	Prec@(1,5) (58.8%, 87.6%)	
07/02 07:11:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][300/703]	Step 65772	lr 0.07832	Loss 1.2333 (1.4565)	Prec@(1,5) (58.6%, 87.3%)	
07/02 07:11:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][350/703]	Step 65822	lr 0.07832	Loss 1.7814 (1.4659)	Prec@(1,5) (58.4%, 87.0%)	
07/02 07:11:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][400/703]	Step 65872	lr 0.07832	Loss 1.5433 (1.4698)	Prec@(1,5) (58.3%, 87.0%)	
07/02 07:11:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][450/703]	Step 65922	lr 0.07832	Loss 1.4866 (1.4740)	Prec@(1,5) (58.1%, 87.0%)	
07/02 07:11:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][500/703]	Step 65972	lr 0.07832	Loss 1.9147 (1.4823)	Prec@(1,5) (57.9%, 86.9%)	
07/02 07:11:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][550/703]	Step 66022	lr 0.07832	Loss 1.4512 (1.4894)	Prec@(1,5) (57.8%, 86.8%)	
07/02 07:11:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][600/703]	Step 66072	lr 0.07832	Loss 1.6306 (1.4929)	Prec@(1,5) (57.7%, 86.7%)	
07/02 07:11:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][650/703]	Step 66122	lr 0.07832	Loss 1.5672 (1.4991)	Prec@(1,5) (57.6%, 86.6%)	
07/02 07:11:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][700/703]	Step 66172	lr 0.07832	Loss 1.2669 (1.5004)	Prec@(1,5) (57.6%, 86.5%)	
07/02 07:11:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [93][703/703]	Step 66175	lr 0.07832	Loss 1.6813 (1.5012)	Prec@(1,5) (57.6%, 86.5%)	
07/02 07:11:57午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 93/299] Final Prec@1 57.5822%
07/02 07:11:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [93][50/79]	Step 66176	Loss 1.9592	Prec@(1,5) (48.7%, 78.8%)
07/02 07:11:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [93][78/79]	Step 66176	Loss 1.9790	Prec@(1,5) (48.4%, 78.1%)
07/02 07:11:59午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 93/299] Final Prec@1 48.3600%
07/02 07:11:59午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 49.8000%
07/02 07:12:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][50/703]	Step 66226	lr 0.07789	Loss 1.6615 (1.4331)	Prec@(1,5) (58.9%, 88.0%)	
07/02 07:12:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][100/703]	Step 66276	lr 0.07789	Loss 1.1342 (1.4156)	Prec@(1,5) (59.4%, 88.5%)	
07/02 07:12:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][150/703]	Step 66326	lr 0.07789	Loss 1.6641 (1.4394)	Prec@(1,5) (59.0%, 88.1%)	
07/02 07:12:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][200/703]	Step 66376	lr 0.07789	Loss 1.3608 (1.4509)	Prec@(1,5) (58.9%, 87.6%)	
07/02 07:12:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][250/703]	Step 66426	lr 0.07789	Loss 1.5117 (1.4451)	Prec@(1,5) (59.0%, 87.7%)	
07/02 07:12:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][300/703]	Step 66476	lr 0.07789	Loss 1.4549 (1.4501)	Prec@(1,5) (58.8%, 87.6%)	
07/02 07:12:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][350/703]	Step 66526	lr 0.07789	Loss 1.6917 (1.4553)	Prec@(1,5) (58.7%, 87.5%)	
07/02 07:12:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][400/703]	Step 66576	lr 0.07789	Loss 1.7778 (1.4630)	Prec@(1,5) (58.5%, 87.4%)	
07/02 07:12:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][450/703]	Step 66626	lr 0.07789	Loss 1.7666 (1.4698)	Prec@(1,5) (58.3%, 87.3%)	
07/02 07:12:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][500/703]	Step 66676	lr 0.07789	Loss 0.9403 (1.4731)	Prec@(1,5) (58.1%, 87.3%)	
07/02 07:12:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][550/703]	Step 66726	lr 0.07789	Loss 1.3447 (1.4815)	Prec@(1,5) (57.9%, 87.2%)	
07/02 07:12:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][600/703]	Step 66776	lr 0.07789	Loss 1.4461 (1.4869)	Prec@(1,5) (57.8%, 87.1%)	
07/02 07:12:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][650/703]	Step 66826	lr 0.07789	Loss 1.7406 (1.4928)	Prec@(1,5) (57.6%, 87.0%)	
07/02 07:12:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][700/703]	Step 66876	lr 0.07789	Loss 1.5123 (1.5007)	Prec@(1,5) (57.4%, 86.9%)	
07/02 07:12:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [94][703/703]	Step 66879	lr 0.07789	Loss 1.2815 (1.5009)	Prec@(1,5) (57.4%, 86.9%)	
07/02 07:12:46午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 94/299] Final Prec@1 57.4067%
07/02 07:12:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [94][50/79]	Step 66880	Loss 1.9626	Prec@(1,5) (49.9%, 78.4%)
07/02 07:12:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [94][78/79]	Step 66880	Loss 1.9390	Prec@(1,5) (50.5%, 78.4%)
07/02 07:12:48午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 94/299] Final Prec@1 50.4800%
07/02 07:12:48午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:12:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][50/703]	Step 66930	lr 0.07746	Loss 1.6807 (1.4234)	Prec@(1,5) (59.2%, 88.1%)	
07/02 07:12:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][100/703]	Step 66980	lr 0.07746	Loss 1.2394 (1.4184)	Prec@(1,5) (59.5%, 88.2%)	
07/02 07:12:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][150/703]	Step 67030	lr 0.07746	Loss 1.2729 (1.4241)	Prec@(1,5) (59.3%, 88.1%)	
07/02 07:13:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][200/703]	Step 67080	lr 0.07746	Loss 1.6487 (1.4381)	Prec@(1,5) (58.9%, 88.0%)	
07/02 07:13:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][250/703]	Step 67130	lr 0.07746	Loss 1.5504 (1.4389)	Prec@(1,5) (59.1%, 87.9%)	
07/02 07:13:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][300/703]	Step 67180	lr 0.07746	Loss 1.9010 (1.4349)	Prec@(1,5) (59.3%, 87.8%)	
07/02 07:13:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][350/703]	Step 67230	lr 0.07746	Loss 1.5557 (1.4454)	Prec@(1,5) (58.9%, 87.7%)	
07/02 07:13:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][400/703]	Step 67280	lr 0.07746	Loss 1.4375 (1.4553)	Prec@(1,5) (58.7%, 87.5%)	
07/02 07:13:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][450/703]	Step 67330	lr 0.07746	Loss 1.2404 (1.4678)	Prec@(1,5) (58.4%, 87.2%)	
07/02 07:13:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][500/703]	Step 67380	lr 0.07746	Loss 1.3957 (1.4747)	Prec@(1,5) (58.3%, 87.1%)	
07/02 07:13:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][550/703]	Step 67430	lr 0.07746	Loss 1.2959 (1.4783)	Prec@(1,5) (58.1%, 87.0%)	
07/02 07:13:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][600/703]	Step 67480	lr 0.07746	Loss 1.5921 (1.4854)	Prec@(1,5) (58.0%, 86.8%)	
07/02 07:13:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][650/703]	Step 67530	lr 0.07746	Loss 1.8547 (1.4897)	Prec@(1,5) (57.8%, 86.7%)	
07/02 07:13:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][700/703]	Step 67580	lr 0.07746	Loss 1.3572 (1.4939)	Prec@(1,5) (57.7%, 86.7%)	
07/02 07:13:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [95][703/703]	Step 67583	lr 0.07746	Loss 1.6026 (1.4943)	Prec@(1,5) (57.7%, 86.7%)	
07/02 07:13:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 95/299] Final Prec@1 57.7200%
07/02 07:13:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [95][50/79]	Step 67584	Loss 1.9932	Prec@(1,5) (49.2%, 78.3%)
07/02 07:13:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [95][78/79]	Step 67584	Loss 1.9747	Prec@(1,5) (49.1%, 78.9%)
07/02 07:13:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 95/299] Final Prec@1 49.1200%
07/02 07:13:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:13:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][50/703]	Step 67634	lr 0.07702	Loss 1.3725 (1.4519)	Prec@(1,5) (58.8%, 87.9%)	
07/02 07:13:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][100/703]	Step 67684	lr 0.07702	Loss 1.2058 (1.3958)	Prec@(1,5) (60.5%, 88.6%)	
07/02 07:13:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][150/703]	Step 67734	lr 0.07702	Loss 1.7185 (1.4057)	Prec@(1,5) (60.1%, 88.2%)	
07/02 07:13:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][200/703]	Step 67784	lr 0.07702	Loss 1.0754 (1.4230)	Prec@(1,5) (59.6%, 87.7%)	
07/02 07:13:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][250/703]	Step 67834	lr 0.07702	Loss 1.7248 (1.4396)	Prec@(1,5) (59.3%, 87.4%)	
07/02 07:13:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][300/703]	Step 67884	lr 0.07702	Loss 1.4792 (1.4510)	Prec@(1,5) (58.9%, 87.4%)	
07/02 07:13:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][350/703]	Step 67934	lr 0.07702	Loss 1.8448 (1.4571)	Prec@(1,5) (58.6%, 87.3%)	
07/02 07:14:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][400/703]	Step 67984	lr 0.07702	Loss 1.5054 (1.4631)	Prec@(1,5) (58.5%, 87.2%)	
07/02 07:14:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][450/703]	Step 68034	lr 0.07702	Loss 1.8813 (1.4706)	Prec@(1,5) (58.2%, 87.1%)	
07/02 07:14:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][500/703]	Step 68084	lr 0.07702	Loss 1.5497 (1.4730)	Prec@(1,5) (58.2%, 87.1%)	
07/02 07:14:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][550/703]	Step 68134	lr 0.07702	Loss 1.3927 (1.4812)	Prec@(1,5) (58.1%, 86.9%)	
07/02 07:14:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][600/703]	Step 68184	lr 0.07702	Loss 1.3087 (1.4866)	Prec@(1,5) (57.9%, 86.9%)	
07/02 07:14:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][650/703]	Step 68234	lr 0.07702	Loss 1.5403 (1.4896)	Prec@(1,5) (57.9%, 86.8%)	
07/02 07:14:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][700/703]	Step 68284	lr 0.07702	Loss 1.4757 (1.4890)	Prec@(1,5) (57.9%, 86.8%)	
07/02 07:14:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [96][703/703]	Step 68287	lr 0.07702	Loss 1.4608 (1.4892)	Prec@(1,5) (57.9%, 86.8%)	
07/02 07:14:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 96/299] Final Prec@1 57.8956%
07/02 07:14:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [96][50/79]	Step 68288	Loss 2.0345	Prec@(1,5) (46.8%, 77.6%)
07/02 07:14:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [96][78/79]	Step 68288	Loss 2.0591	Prec@(1,5) (46.8%, 77.4%)
07/02 07:14:22午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 96/299] Final Prec@1 46.7400%
07/02 07:14:22午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:14:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][50/703]	Step 68338	lr 0.07658	Loss 1.3411 (1.3881)	Prec@(1,5) (59.7%, 89.3%)	
07/02 07:14:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][100/703]	Step 68388	lr 0.07658	Loss 1.4266 (1.3761)	Prec@(1,5) (60.3%, 89.2%)	
07/02 07:14:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][150/703]	Step 68438	lr 0.07658	Loss 1.7043 (1.3939)	Prec@(1,5) (60.3%, 88.6%)	
07/02 07:14:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][200/703]	Step 68488	lr 0.07658	Loss 1.4855 (1.4171)	Prec@(1,5) (59.6%, 88.3%)	
07/02 07:14:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][250/703]	Step 68538	lr 0.07658	Loss 1.6744 (1.4377)	Prec@(1,5) (58.8%, 87.9%)	
07/02 07:14:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][300/703]	Step 68588	lr 0.07658	Loss 1.7879 (1.4407)	Prec@(1,5) (58.9%, 87.8%)	
07/02 07:14:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][350/703]	Step 68638	lr 0.07658	Loss 1.3394 (1.4466)	Prec@(1,5) (58.7%, 87.7%)	
07/02 07:14:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][400/703]	Step 68688	lr 0.07658	Loss 1.5722 (1.4519)	Prec@(1,5) (58.6%, 87.6%)	
07/02 07:14:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][450/703]	Step 68738	lr 0.07658	Loss 1.4827 (1.4602)	Prec@(1,5) (58.4%, 87.4%)	
07/02 07:14:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][500/703]	Step 68788	lr 0.07658	Loss 1.4888 (1.4622)	Prec@(1,5) (58.4%, 87.4%)	
07/02 07:14:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][550/703]	Step 68838	lr 0.07658	Loss 1.7548 (1.4680)	Prec@(1,5) (58.2%, 87.2%)	
07/02 07:15:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][600/703]	Step 68888	lr 0.07658	Loss 1.6572 (1.4745)	Prec@(1,5) (58.1%, 87.1%)	
07/02 07:15:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][650/703]	Step 68938	lr 0.07658	Loss 1.2972 (1.4818)	Prec@(1,5) (58.0%, 86.9%)	
07/02 07:15:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][700/703]	Step 68988	lr 0.07658	Loss 1.2679 (1.4851)	Prec@(1,5) (57.9%, 86.9%)	
07/02 07:15:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [97][703/703]	Step 68991	lr 0.07658	Loss 1.8560 (1.4854)	Prec@(1,5) (57.9%, 86.9%)	
07/02 07:15:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 97/299] Final Prec@1 57.9289%
07/02 07:15:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [97][50/79]	Step 68992	Loss 1.9551	Prec@(1,5) (47.9%, 79.1%)
07/02 07:15:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [97][78/79]	Step 68992	Loss 1.9373	Prec@(1,5) (48.7%, 79.1%)
07/02 07:15:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 97/299] Final Prec@1 48.6800%
07/02 07:15:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:15:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][50/703]	Step 69042	lr 0.07614	Loss 1.3531 (1.3958)	Prec@(1,5) (61.6%, 87.7%)	
07/02 07:15:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][100/703]	Step 69092	lr 0.07614	Loss 1.1749 (1.3985)	Prec@(1,5) (60.5%, 88.0%)	
07/02 07:15:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][150/703]	Step 69142	lr 0.07614	Loss 1.5202 (1.4076)	Prec@(1,5) (60.0%, 87.8%)	
07/02 07:15:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][200/703]	Step 69192	lr 0.07614	Loss 1.5392 (1.4035)	Prec@(1,5) (60.2%, 87.8%)	
07/02 07:15:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][250/703]	Step 69242	lr 0.07614	Loss 1.5498 (1.4060)	Prec@(1,5) (59.9%, 87.9%)	
07/02 07:15:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][300/703]	Step 69292	lr 0.07614	Loss 1.3850 (1.4175)	Prec@(1,5) (59.8%, 87.6%)	
07/02 07:15:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][350/703]	Step 69342	lr 0.07614	Loss 1.3529 (1.4284)	Prec@(1,5) (59.6%, 87.4%)	
07/02 07:15:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][400/703]	Step 69392	lr 0.07614	Loss 1.2832 (1.4352)	Prec@(1,5) (59.3%, 87.4%)	
07/02 07:15:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][450/703]	Step 69442	lr 0.07614	Loss 1.5657 (1.4401)	Prec@(1,5) (59.2%, 87.3%)	
07/02 07:15:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][500/703]	Step 69492	lr 0.07614	Loss 1.2625 (1.4481)	Prec@(1,5) (59.0%, 87.2%)	
07/02 07:15:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][550/703]	Step 69542	lr 0.07614	Loss 1.5386 (1.4591)	Prec@(1,5) (58.7%, 87.1%)	
07/02 07:15:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][600/703]	Step 69592	lr 0.07614	Loss 1.8286 (1.4702)	Prec@(1,5) (58.5%, 86.9%)	
07/02 07:15:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][650/703]	Step 69642	lr 0.07614	Loss 0.9017 (1.4731)	Prec@(1,5) (58.3%, 86.9%)	
07/02 07:15:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][700/703]	Step 69692	lr 0.07614	Loss 1.7331 (1.4752)	Prec@(1,5) (58.3%, 86.9%)	
07/02 07:15:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [98][703/703]	Step 69695	lr 0.07614	Loss 1.9108 (1.4756)	Prec@(1,5) (58.3%, 86.9%)	
07/02 07:15:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 98/299] Final Prec@1 58.2800%
07/02 07:15:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [98][50/79]	Step 69696	Loss 1.9021	Prec@(1,5) (48.8%, 80.7%)
07/02 07:15:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [98][78/79]	Step 69696	Loss 1.9145	Prec@(1,5) (49.1%, 79.9%)
07/02 07:15:54午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 98/299] Final Prec@1 49.0800%
07/02 07:15:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:15:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][50/703]	Step 69746	lr 0.0757	Loss 1.2338 (1.4209)	Prec@(1,5) (59.7%, 88.2%)	
07/02 07:16:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][100/703]	Step 69796	lr 0.0757	Loss 1.5770 (1.4360)	Prec@(1,5) (58.9%, 88.0%)	
07/02 07:16:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][150/703]	Step 69846	lr 0.0757	Loss 1.7796 (1.4176)	Prec@(1,5) (59.4%, 88.2%)	
07/02 07:16:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][200/703]	Step 69896	lr 0.0757	Loss 1.5822 (1.4145)	Prec@(1,5) (59.6%, 88.2%)	
07/02 07:16:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][250/703]	Step 69946	lr 0.0757	Loss 1.3386 (1.4217)	Prec@(1,5) (59.4%, 88.1%)	
07/02 07:16:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][300/703]	Step 69996	lr 0.0757	Loss 1.4621 (1.4281)	Prec@(1,5) (59.2%, 88.0%)	
07/02 07:16:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][350/703]	Step 70046	lr 0.0757	Loss 1.2347 (1.4386)	Prec@(1,5) (58.9%, 87.8%)	
07/02 07:16:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][400/703]	Step 70096	lr 0.0757	Loss 1.2672 (1.4413)	Prec@(1,5) (58.9%, 87.6%)	
07/02 07:16:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][450/703]	Step 70146	lr 0.0757	Loss 1.3580 (1.4452)	Prec@(1,5) (58.8%, 87.5%)	
07/02 07:16:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][500/703]	Step 70196	lr 0.0757	Loss 1.3353 (1.4500)	Prec@(1,5) (58.7%, 87.5%)	
07/02 07:16:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][550/703]	Step 70246	lr 0.0757	Loss 1.6324 (1.4540)	Prec@(1,5) (58.7%, 87.3%)	
07/02 07:16:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][600/703]	Step 70296	lr 0.0757	Loss 1.1486 (1.4549)	Prec@(1,5) (58.8%, 87.3%)	
07/02 07:16:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][650/703]	Step 70346	lr 0.0757	Loss 1.8126 (1.4625)	Prec@(1,5) (58.6%, 87.2%)	
07/02 07:16:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][700/703]	Step 70396	lr 0.0757	Loss 1.4135 (1.4691)	Prec@(1,5) (58.4%, 87.1%)	
07/02 07:16:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [99][703/703]	Step 70399	lr 0.0757	Loss 1.6138 (1.4698)	Prec@(1,5) (58.3%, 87.1%)	
07/02 07:16:40午後 finetuneTeacher_trainer.py:180 [INFO] Train: [ 99/299] Final Prec@1 58.3400%
07/02 07:16:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [99][50/79]	Step 70400	Loss 1.9073	Prec@(1,5) (50.5%, 80.2%)
07/02 07:16:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [99][78/79]	Step 70400	Loss 1.9230	Prec@(1,5) (50.2%, 80.3%)
07/02 07:16:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [ 99/299] Final Prec@1 50.2400%
07/02 07:16:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:16:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][50/703]	Step 70450	lr 0.07525	Loss 1.3305 (1.4183)	Prec@(1,5) (59.7%, 88.6%)	
07/02 07:16:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][100/703]	Step 70500	lr 0.07525	Loss 1.2738 (1.3853)	Prec@(1,5) (60.2%, 88.7%)	
07/02 07:16:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][150/703]	Step 70550	lr 0.07525	Loss 1.2804 (1.3972)	Prec@(1,5) (60.0%, 88.6%)	
07/02 07:16:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][200/703]	Step 70600	lr 0.07525	Loss 1.3997 (1.3968)	Prec@(1,5) (60.2%, 88.3%)	
07/02 07:16:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][250/703]	Step 70650	lr 0.07525	Loss 1.2775 (1.4070)	Prec@(1,5) (59.8%, 88.2%)	
07/02 07:17:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][300/703]	Step 70700	lr 0.07525	Loss 1.5782 (1.4162)	Prec@(1,5) (59.6%, 88.1%)	
07/02 07:17:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][350/703]	Step 70750	lr 0.07525	Loss 1.7254 (1.4240)	Prec@(1,5) (59.5%, 87.9%)	
07/02 07:17:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][400/703]	Step 70800	lr 0.07525	Loss 1.6217 (1.4265)	Prec@(1,5) (59.3%, 87.9%)	
07/02 07:17:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][450/703]	Step 70850	lr 0.07525	Loss 1.6323 (1.4342)	Prec@(1,5) (59.1%, 87.7%)	
07/02 07:17:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][500/703]	Step 70900	lr 0.07525	Loss 1.2650 (1.4384)	Prec@(1,5) (58.9%, 87.6%)	
07/02 07:17:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][550/703]	Step 70950	lr 0.07525	Loss 1.1161 (1.4418)	Prec@(1,5) (58.8%, 87.5%)	
07/02 07:17:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][600/703]	Step 71000	lr 0.07525	Loss 1.4587 (1.4474)	Prec@(1,5) (58.7%, 87.4%)	
07/02 07:17:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][650/703]	Step 71050	lr 0.07525	Loss 1.6128 (1.4586)	Prec@(1,5) (58.4%, 87.3%)	
07/02 07:17:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][700/703]	Step 71100	lr 0.07525	Loss 1.3284 (1.4611)	Prec@(1,5) (58.4%, 87.2%)	
07/02 07:17:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [100][703/703]	Step 71103	lr 0.07525	Loss 1.2860 (1.4606)	Prec@(1,5) (58.4%, 87.2%)	
07/02 07:17:29午後 finetuneTeacher_trainer.py:180 [INFO] Train: [100/299] Final Prec@1 58.4178%
07/02 07:17:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [100][50/79]	Step 71104	Loss 1.9933	Prec@(1,5) (48.6%, 78.4%)
07/02 07:17:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [100][78/79]	Step 71104	Loss 1.9758	Prec@(1,5) (48.3%, 78.6%)
07/02 07:17:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [100/299] Final Prec@1 48.3800%
07/02 07:17:31午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:17:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][50/703]	Step 71154	lr 0.0748	Loss 1.2121 (1.3652)	Prec@(1,5) (61.0%, 88.7%)	
07/02 07:17:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][100/703]	Step 71204	lr 0.0748	Loss 1.4434 (1.3813)	Prec@(1,5) (60.6%, 88.3%)	
07/02 07:17:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][150/703]	Step 71254	lr 0.0748	Loss 1.4806 (1.3862)	Prec@(1,5) (60.2%, 88.6%)	
07/02 07:17:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][200/703]	Step 71304	lr 0.0748	Loss 1.4810 (1.4021)	Prec@(1,5) (60.0%, 88.3%)	
07/02 07:17:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][250/703]	Step 71354	lr 0.0748	Loss 1.6195 (1.4193)	Prec@(1,5) (59.6%, 88.0%)	
07/02 07:17:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][300/703]	Step 71404	lr 0.0748	Loss 1.6843 (1.4241)	Prec@(1,5) (59.5%, 87.8%)	
07/02 07:17:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][350/703]	Step 71454	lr 0.0748	Loss 1.7003 (1.4341)	Prec@(1,5) (59.3%, 87.7%)	
07/02 07:17:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][400/703]	Step 71504	lr 0.0748	Loss 1.1760 (1.4367)	Prec@(1,5) (59.3%, 87.6%)	
07/02 07:18:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][450/703]	Step 71554	lr 0.0748	Loss 1.5217 (1.4503)	Prec@(1,5) (58.9%, 87.4%)	
07/02 07:18:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][500/703]	Step 71604	lr 0.0748	Loss 1.7670 (1.4531)	Prec@(1,5) (58.8%, 87.4%)	
07/02 07:18:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][550/703]	Step 71654	lr 0.0748	Loss 1.3979 (1.4608)	Prec@(1,5) (58.5%, 87.3%)	
07/02 07:18:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][600/703]	Step 71704	lr 0.0748	Loss 1.8762 (1.4641)	Prec@(1,5) (58.5%, 87.2%)	
07/02 07:18:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][650/703]	Step 71754	lr 0.0748	Loss 1.4189 (1.4687)	Prec@(1,5) (58.3%, 87.2%)	
07/02 07:18:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][700/703]	Step 71804	lr 0.0748	Loss 1.2268 (1.4725)	Prec@(1,5) (58.3%, 87.1%)	
07/02 07:18:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [101][703/703]	Step 71807	lr 0.0748	Loss 1.9056 (1.4726)	Prec@(1,5) (58.3%, 87.1%)	
07/02 07:18:16午後 finetuneTeacher_trainer.py:180 [INFO] Train: [101/299] Final Prec@1 58.2889%
07/02 07:18:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [101][50/79]	Step 71808	Loss 2.0018	Prec@(1,5) (47.9%, 79.2%)
07/02 07:18:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [101][78/79]	Step 71808	Loss 1.9720	Prec@(1,5) (47.9%, 79.5%)
07/02 07:18:18午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [101/299] Final Prec@1 47.9400%
07/02 07:18:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 50.4800%
07/02 07:18:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][50/703]	Step 71858	lr 0.07435	Loss 1.2895 (1.3748)	Prec@(1,5) (60.6%, 88.3%)	
07/02 07:18:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][100/703]	Step 71908	lr 0.07435	Loss 1.5718 (1.4141)	Prec@(1,5) (59.7%, 87.6%)	
07/02 07:18:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][150/703]	Step 71958	lr 0.07435	Loss 1.3694 (1.3840)	Prec@(1,5) (60.7%, 88.1%)	
07/02 07:18:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][200/703]	Step 72008	lr 0.07435	Loss 1.5802 (1.3840)	Prec@(1,5) (60.5%, 88.1%)	
07/02 07:18:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][250/703]	Step 72058	lr 0.07435	Loss 1.2997 (1.3854)	Prec@(1,5) (60.2%, 88.1%)	
07/02 07:18:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][300/703]	Step 72108	lr 0.07435	Loss 1.0225 (1.3936)	Prec@(1,5) (59.9%, 88.1%)	
07/02 07:18:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][350/703]	Step 72158	lr 0.07435	Loss 1.4069 (1.4083)	Prec@(1,5) (59.7%, 87.9%)	
07/02 07:18:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][400/703]	Step 72208	lr 0.07435	Loss 1.6960 (1.4203)	Prec@(1,5) (59.4%, 87.7%)	
07/02 07:18:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][450/703]	Step 72258	lr 0.07435	Loss 1.8005 (1.4238)	Prec@(1,5) (59.5%, 87.6%)	
07/02 07:18:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][500/703]	Step 72308	lr 0.07435	Loss 1.3094 (1.4303)	Prec@(1,5) (59.4%, 87.6%)	
07/02 07:18:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][550/703]	Step 72358	lr 0.07435	Loss 1.7814 (1.4412)	Prec@(1,5) (59.1%, 87.4%)	
07/02 07:18:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][600/703]	Step 72408	lr 0.07435	Loss 2.0663 (1.4455)	Prec@(1,5) (59.0%, 87.4%)	
07/02 07:18:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][650/703]	Step 72458	lr 0.07435	Loss 1.5727 (1.4498)	Prec@(1,5) (58.9%, 87.3%)	
07/02 07:19:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][700/703]	Step 72508	lr 0.07435	Loss 1.5069 (1.4526)	Prec@(1,5) (58.8%, 87.3%)	
07/02 07:19:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [102][703/703]	Step 72511	lr 0.07435	Loss 1.9915 (1.4542)	Prec@(1,5) (58.7%, 87.2%)	
07/02 07:19:03午後 finetuneTeacher_trainer.py:180 [INFO] Train: [102/299] Final Prec@1 58.7133%
07/02 07:19:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [102][50/79]	Step 72512	Loss 1.8461	Prec@(1,5) (51.2%, 80.4%)
07/02 07:19:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [102][78/79]	Step 72512	Loss 1.8488	Prec@(1,5) (51.6%, 80.9%)
07/02 07:19:05午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [102/299] Final Prec@1 51.6400%
07/02 07:19:05午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:19:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][50/703]	Step 72562	lr 0.07389	Loss 1.2840 (1.4250)	Prec@(1,5) (59.1%, 88.0%)	
07/02 07:19:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][100/703]	Step 72612	lr 0.07389	Loss 1.4181 (1.3801)	Prec@(1,5) (60.0%, 89.0%)	
07/02 07:19:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][150/703]	Step 72662	lr 0.07389	Loss 1.4316 (1.3908)	Prec@(1,5) (59.9%, 88.7%)	
07/02 07:19:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][200/703]	Step 72712	lr 0.07389	Loss 1.6582 (1.3921)	Prec@(1,5) (60.0%, 88.5%)	
07/02 07:19:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][250/703]	Step 72762	lr 0.07389	Loss 1.3979 (1.3908)	Prec@(1,5) (60.0%, 88.3%)	
07/02 07:19:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][300/703]	Step 72812	lr 0.07389	Loss 1.5611 (1.3942)	Prec@(1,5) (60.1%, 88.3%)	
07/02 07:19:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][350/703]	Step 72862	lr 0.07389	Loss 1.3329 (1.4109)	Prec@(1,5) (59.8%, 88.0%)	
07/02 07:19:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][400/703]	Step 72912	lr 0.07389	Loss 1.6254 (1.4120)	Prec@(1,5) (59.7%, 88.0%)	
07/02 07:19:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][450/703]	Step 72962	lr 0.07389	Loss 1.5189 (1.4210)	Prec@(1,5) (59.6%, 87.8%)	
07/02 07:19:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][500/703]	Step 73012	lr 0.07389	Loss 1.2281 (1.4238)	Prec@(1,5) (59.6%, 87.8%)	
07/02 07:19:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][550/703]	Step 73062	lr 0.07389	Loss 1.5083 (1.4297)	Prec@(1,5) (59.4%, 87.7%)	
07/02 07:19:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][600/703]	Step 73112	lr 0.07389	Loss 1.2878 (1.4377)	Prec@(1,5) (59.2%, 87.6%)	
07/02 07:19:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][650/703]	Step 73162	lr 0.07389	Loss 1.3620 (1.4386)	Prec@(1,5) (59.2%, 87.6%)	
07/02 07:19:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][700/703]	Step 73212	lr 0.07389	Loss 1.4161 (1.4437)	Prec@(1,5) (59.0%, 87.5%)	
07/02 07:19:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [103][703/703]	Step 73215	lr 0.07389	Loss 1.3581 (1.4440)	Prec@(1,5) (59.0%, 87.5%)	
07/02 07:19:51午後 finetuneTeacher_trainer.py:180 [INFO] Train: [103/299] Final Prec@1 59.0178%
07/02 07:19:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [103][50/79]	Step 73216	Loss 1.9263	Prec@(1,5) (50.6%, 78.6%)
07/02 07:19:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [103][78/79]	Step 73216	Loss 1.9157	Prec@(1,5) (50.4%, 79.3%)
07/02 07:19:52午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [103/299] Final Prec@1 50.3400%
07/02 07:19:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:19:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][50/703]	Step 73266	lr 0.07343	Loss 1.4148 (1.3822)	Prec@(1,5) (59.9%, 88.7%)	
07/02 07:19:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][100/703]	Step 73316	lr 0.07343	Loss 1.4666 (1.3567)	Prec@(1,5) (60.5%, 89.0%)	
07/02 07:20:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][150/703]	Step 73366	lr 0.07343	Loss 1.2479 (1.3587)	Prec@(1,5) (60.5%, 88.9%)	
07/02 07:20:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][200/703]	Step 73416	lr 0.07343	Loss 1.5272 (1.3760)	Prec@(1,5) (60.1%, 88.6%)	
07/02 07:20:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][250/703]	Step 73466	lr 0.07343	Loss 1.2937 (1.3884)	Prec@(1,5) (59.9%, 88.3%)	
07/02 07:20:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][300/703]	Step 73516	lr 0.07343	Loss 1.4586 (1.4018)	Prec@(1,5) (59.5%, 88.2%)	
07/02 07:20:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][350/703]	Step 73566	lr 0.07343	Loss 1.3437 (1.4194)	Prec@(1,5) (59.2%, 87.8%)	
07/02 07:20:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][400/703]	Step 73616	lr 0.07343	Loss 1.3514 (1.4228)	Prec@(1,5) (59.1%, 87.8%)	
07/02 07:20:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][450/703]	Step 73666	lr 0.07343	Loss 1.6971 (1.4261)	Prec@(1,5) (59.1%, 87.8%)	
07/02 07:20:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][500/703]	Step 73716	lr 0.07343	Loss 1.4116 (1.4291)	Prec@(1,5) (59.0%, 87.7%)	
07/02 07:20:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][550/703]	Step 73766	lr 0.07343	Loss 1.1419 (1.4295)	Prec@(1,5) (59.0%, 87.7%)	
07/02 07:20:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][600/703]	Step 73816	lr 0.07343	Loss 1.7297 (1.4333)	Prec@(1,5) (58.9%, 87.6%)	
07/02 07:20:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][650/703]	Step 73866	lr 0.07343	Loss 1.7183 (1.4419)	Prec@(1,5) (58.7%, 87.5%)	
07/02 07:20:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][700/703]	Step 73916	lr 0.07343	Loss 1.0753 (1.4453)	Prec@(1,5) (58.6%, 87.4%)	
07/02 07:20:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [104][703/703]	Step 73919	lr 0.07343	Loss 1.3828 (1.4454)	Prec@(1,5) (58.6%, 87.4%)	
07/02 07:20:31午後 finetuneTeacher_trainer.py:180 [INFO] Train: [104/299] Final Prec@1 58.6044%
07/02 07:20:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [104][50/79]	Step 73920	Loss 1.8491	Prec@(1,5) (50.7%, 80.8%)
07/02 07:20:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [104][78/79]	Step 73920	Loss 1.8636	Prec@(1,5) (50.4%, 80.8%)
07/02 07:20:33午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [104/299] Final Prec@1 50.3800%
07/02 07:20:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:20:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][50/703]	Step 73970	lr 0.07297	Loss 1.3916 (1.3251)	Prec@(1,5) (62.3%, 88.8%)	
07/02 07:20:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][100/703]	Step 74020	lr 0.07297	Loss 1.4521 (1.3418)	Prec@(1,5) (61.3%, 89.3%)	
07/02 07:20:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][150/703]	Step 74070	lr 0.07297	Loss 1.3595 (1.3626)	Prec@(1,5) (60.6%, 88.9%)	
07/02 07:20:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][200/703]	Step 74120	lr 0.07297	Loss 1.5761 (1.3645)	Prec@(1,5) (60.8%, 88.6%)	
07/02 07:20:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][250/703]	Step 74170	lr 0.07297	Loss 1.1337 (1.3787)	Prec@(1,5) (60.4%, 88.4%)	
07/02 07:20:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][300/703]	Step 74220	lr 0.07297	Loss 1.5248 (1.3866)	Prec@(1,5) (60.2%, 88.2%)	
07/02 07:20:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][350/703]	Step 74270	lr 0.07297	Loss 1.7637 (1.3966)	Prec@(1,5) (60.1%, 88.1%)	
07/02 07:21:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][400/703]	Step 74320	lr 0.07297	Loss 1.3626 (1.3996)	Prec@(1,5) (60.1%, 88.1%)	
07/02 07:21:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][450/703]	Step 74370	lr 0.07297	Loss 1.3724 (1.4071)	Prec@(1,5) (60.0%, 87.9%)	
07/02 07:21:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][500/703]	Step 74420	lr 0.07297	Loss 1.1778 (1.4124)	Prec@(1,5) (59.8%, 87.8%)	
07/02 07:21:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][550/703]	Step 74470	lr 0.07297	Loss 1.5465 (1.4204)	Prec@(1,5) (59.6%, 87.6%)	
07/02 07:21:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][600/703]	Step 74520	lr 0.07297	Loss 1.3291 (1.4245)	Prec@(1,5) (59.5%, 87.6%)	
07/02 07:21:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][650/703]	Step 74570	lr 0.07297	Loss 1.6786 (1.4299)	Prec@(1,5) (59.3%, 87.6%)	
07/02 07:21:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][700/703]	Step 74620	lr 0.07297	Loss 1.4972 (1.4346)	Prec@(1,5) (59.3%, 87.5%)	
07/02 07:21:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [105][703/703]	Step 74623	lr 0.07297	Loss 1.5564 (1.4349)	Prec@(1,5) (59.3%, 87.5%)	
07/02 07:21:17午後 finetuneTeacher_trainer.py:180 [INFO] Train: [105/299] Final Prec@1 59.2844%
07/02 07:21:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [105][50/79]	Step 74624	Loss 1.8949	Prec@(1,5) (50.2%, 78.9%)
07/02 07:21:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [105][78/79]	Step 74624	Loss 1.9140	Prec@(1,5) (49.8%, 78.8%)
07/02 07:21:19午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [105/299] Final Prec@1 49.9200%
07/02 07:21:19午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:21:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][50/703]	Step 74674	lr 0.07251	Loss 1.2948 (1.3206)	Prec@(1,5) (61.8%, 89.9%)	
07/02 07:21:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][100/703]	Step 74724	lr 0.07251	Loss 1.0998 (1.3165)	Prec@(1,5) (61.7%, 89.8%)	
07/02 07:21:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][150/703]	Step 74774	lr 0.07251	Loss 1.4901 (1.3395)	Prec@(1,5) (61.4%, 89.6%)	
07/02 07:21:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][200/703]	Step 74824	lr 0.07251	Loss 1.1828 (1.3609)	Prec@(1,5) (60.9%, 89.3%)	
07/02 07:21:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][250/703]	Step 74874	lr 0.07251	Loss 1.2746 (1.3680)	Prec@(1,5) (60.6%, 89.1%)	
07/02 07:21:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][300/703]	Step 74924	lr 0.07251	Loss 1.7122 (1.3827)	Prec@(1,5) (60.1%, 88.8%)	
07/02 07:21:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][350/703]	Step 74974	lr 0.07251	Loss 1.2936 (1.3980)	Prec@(1,5) (59.7%, 88.5%)	
07/02 07:21:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][400/703]	Step 75024	lr 0.07251	Loss 1.5887 (1.4102)	Prec@(1,5) (59.5%, 88.4%)	
07/02 07:21:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][450/703]	Step 75074	lr 0.07251	Loss 1.4465 (1.4178)	Prec@(1,5) (59.5%, 88.2%)	
07/02 07:21:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][500/703]	Step 75124	lr 0.07251	Loss 1.5870 (1.4238)	Prec@(1,5) (59.3%, 88.1%)	
07/02 07:21:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][550/703]	Step 75174	lr 0.07251	Loss 1.3121 (1.4251)	Prec@(1,5) (59.3%, 88.0%)	
07/02 07:21:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][600/703]	Step 75224	lr 0.07251	Loss 1.3271 (1.4276)	Prec@(1,5) (59.2%, 87.9%)	
07/02 07:21:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][650/703]	Step 75274	lr 0.07251	Loss 1.7475 (1.4330)	Prec@(1,5) (59.1%, 87.8%)	
07/02 07:22:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][700/703]	Step 75324	lr 0.07251	Loss 1.5900 (1.4397)	Prec@(1,5) (58.9%, 87.7%)	
07/02 07:22:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [106][703/703]	Step 75327	lr 0.07251	Loss 1.9788 (1.4408)	Prec@(1,5) (58.9%, 87.7%)	
07/02 07:22:02午後 finetuneTeacher_trainer.py:180 [INFO] Train: [106/299] Final Prec@1 58.8756%
07/02 07:22:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [106][50/79]	Step 75328	Loss 1.9277	Prec@(1,5) (49.2%, 79.6%)
07/02 07:22:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [106][78/79]	Step 75328	Loss 1.9573	Prec@(1,5) (48.3%, 79.0%)
07/02 07:22:04午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [106/299] Final Prec@1 48.3400%
07/02 07:22:04午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:22:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][50/703]	Step 75378	lr 0.07204	Loss 1.3440 (1.2822)	Prec@(1,5) (63.7%, 89.3%)	
07/02 07:22:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][100/703]	Step 75428	lr 0.07204	Loss 1.1342 (1.2860)	Prec@(1,5) (63.2%, 89.8%)	
07/02 07:22:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][150/703]	Step 75478	lr 0.07204	Loss 1.6863 (1.3056)	Prec@(1,5) (62.6%, 89.6%)	
07/02 07:22:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][200/703]	Step 75528	lr 0.07204	Loss 1.4369 (1.3324)	Prec@(1,5) (61.9%, 89.3%)	
07/02 07:22:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][250/703]	Step 75578	lr 0.07204	Loss 1.5440 (1.3463)	Prec@(1,5) (61.4%, 89.1%)	
07/02 07:22:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][300/703]	Step 75628	lr 0.07204	Loss 1.2361 (1.3548)	Prec@(1,5) (61.0%, 89.0%)	
07/02 07:22:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][350/703]	Step 75678	lr 0.07204	Loss 1.4524 (1.3608)	Prec@(1,5) (60.7%, 88.9%)	
07/02 07:22:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][400/703]	Step 75728	lr 0.07204	Loss 1.1176 (1.3716)	Prec@(1,5) (60.6%, 88.6%)	
07/02 07:22:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][450/703]	Step 75778	lr 0.07204	Loss 1.2895 (1.3802)	Prec@(1,5) (60.4%, 88.4%)	
07/02 07:22:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][500/703]	Step 75828	lr 0.07204	Loss 1.4211 (1.3906)	Prec@(1,5) (60.1%, 88.2%)	
07/02 07:22:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][550/703]	Step 75878	lr 0.07204	Loss 1.3054 (1.3987)	Prec@(1,5) (60.0%, 88.1%)	
07/02 07:22:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][600/703]	Step 75928	lr 0.07204	Loss 1.8486 (1.4059)	Prec@(1,5) (59.8%, 88.0%)	
07/02 07:22:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][650/703]	Step 75978	lr 0.07204	Loss 1.2303 (1.4143)	Prec@(1,5) (59.5%, 87.8%)	
07/02 07:22:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][700/703]	Step 76028	lr 0.07204	Loss 1.6177 (1.4192)	Prec@(1,5) (59.5%, 87.8%)	
07/02 07:22:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [107][703/703]	Step 76031	lr 0.07204	Loss 1.3763 (1.4193)	Prec@(1,5) (59.5%, 87.8%)	
07/02 07:22:48午後 finetuneTeacher_trainer.py:180 [INFO] Train: [107/299] Final Prec@1 59.5267%
07/02 07:22:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [107][50/79]	Step 76032	Loss 2.0178	Prec@(1,5) (47.7%, 77.5%)
07/02 07:22:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [107][78/79]	Step 76032	Loss 1.9815	Prec@(1,5) (48.7%, 78.3%)
07/02 07:22:50午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [107/299] Final Prec@1 48.7000%
07/02 07:22:50午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:22:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][50/703]	Step 76082	lr 0.07158	Loss 1.2703 (1.3691)	Prec@(1,5) (60.3%, 89.1%)	
07/02 07:22:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][100/703]	Step 76132	lr 0.07158	Loss 1.2332 (1.3258)	Prec@(1,5) (61.5%, 89.2%)	
07/02 07:23:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][150/703]	Step 76182	lr 0.07158	Loss 1.5011 (1.3461)	Prec@(1,5) (61.6%, 88.8%)	
07/02 07:23:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][200/703]	Step 76232	lr 0.07158	Loss 1.4320 (1.3507)	Prec@(1,5) (61.3%, 88.8%)	
07/02 07:23:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][250/703]	Step 76282	lr 0.07158	Loss 1.2626 (1.3525)	Prec@(1,5) (61.3%, 88.8%)	
07/02 07:23:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][300/703]	Step 76332	lr 0.07158	Loss 1.1606 (1.3506)	Prec@(1,5) (61.2%, 88.8%)	
07/02 07:23:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][350/703]	Step 76382	lr 0.07158	Loss 1.4612 (1.3665)	Prec@(1,5) (60.9%, 88.6%)	
07/02 07:23:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][400/703]	Step 76432	lr 0.07158	Loss 1.2811 (1.3810)	Prec@(1,5) (60.5%, 88.3%)	
07/02 07:23:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][450/703]	Step 76482	lr 0.07158	Loss 1.1119 (1.3870)	Prec@(1,5) (60.4%, 88.2%)	
07/02 07:23:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][500/703]	Step 76532	lr 0.07158	Loss 1.1995 (1.3929)	Prec@(1,5) (60.2%, 88.1%)	
07/02 07:23:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][550/703]	Step 76582	lr 0.07158	Loss 1.4180 (1.4021)	Prec@(1,5) (60.0%, 88.0%)	
07/02 07:23:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][600/703]	Step 76632	lr 0.07158	Loss 1.5195 (1.4084)	Prec@(1,5) (59.8%, 87.9%)	
07/02 07:23:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][650/703]	Step 76682	lr 0.07158	Loss 1.3087 (1.4139)	Prec@(1,5) (59.7%, 87.9%)	
07/02 07:23:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][700/703]	Step 76732	lr 0.07158	Loss 1.4207 (1.4174)	Prec@(1,5) (59.6%, 87.8%)	
07/02 07:23:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [108][703/703]	Step 76735	lr 0.07158	Loss 1.7628 (1.4184)	Prec@(1,5) (59.6%, 87.8%)	
07/02 07:23:32午後 finetuneTeacher_trainer.py:180 [INFO] Train: [108/299] Final Prec@1 59.6044%
07/02 07:23:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [108][50/79]	Step 76736	Loss 1.8574	Prec@(1,5) (50.6%, 81.3%)
07/02 07:23:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [108][78/79]	Step 76736	Loss 1.8667	Prec@(1,5) (50.8%, 81.2%)
07/02 07:23:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [108/299] Final Prec@1 50.8800%
07/02 07:23:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:23:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][50/703]	Step 76786	lr 0.07111	Loss 1.0513 (1.3092)	Prec@(1,5) (62.5%, 89.2%)	
07/02 07:23:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][100/703]	Step 76836	lr 0.07111	Loss 1.4522 (1.3331)	Prec@(1,5) (61.5%, 89.2%)	
07/02 07:23:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][150/703]	Step 76886	lr 0.07111	Loss 1.5361 (1.3538)	Prec@(1,5) (61.1%, 89.2%)	
07/02 07:23:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][200/703]	Step 76936	lr 0.07111	Loss 1.4853 (1.3590)	Prec@(1,5) (61.1%, 89.0%)	
07/02 07:23:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][250/703]	Step 76986	lr 0.07111	Loss 1.2709 (1.3559)	Prec@(1,5) (60.9%, 88.9%)	
07/02 07:23:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][300/703]	Step 77036	lr 0.07111	Loss 1.4342 (1.3620)	Prec@(1,5) (60.9%, 88.9%)	
07/02 07:23:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][350/703]	Step 77086	lr 0.07111	Loss 1.5151 (1.3715)	Prec@(1,5) (60.6%, 88.7%)	
07/02 07:24:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][400/703]	Step 77136	lr 0.07111	Loss 1.1801 (1.3753)	Prec@(1,5) (60.5%, 88.6%)	
07/02 07:24:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][450/703]	Step 77186	lr 0.07111	Loss 1.5079 (1.3829)	Prec@(1,5) (60.3%, 88.4%)	
07/02 07:24:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][500/703]	Step 77236	lr 0.07111	Loss 1.3420 (1.3921)	Prec@(1,5) (60.1%, 88.2%)	
07/02 07:24:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][550/703]	Step 77286	lr 0.07111	Loss 1.2462 (1.3944)	Prec@(1,5) (60.1%, 88.2%)	
07/02 07:24:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][600/703]	Step 77336	lr 0.07111	Loss 1.4302 (1.3968)	Prec@(1,5) (60.0%, 88.1%)	
07/02 07:24:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][650/703]	Step 77386	lr 0.07111	Loss 2.0670 (1.4072)	Prec@(1,5) (59.7%, 88.0%)	
07/02 07:24:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][700/703]	Step 77436	lr 0.07111	Loss 1.5228 (1.4151)	Prec@(1,5) (59.5%, 87.9%)	
07/02 07:24:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [109][703/703]	Step 77439	lr 0.07111	Loss 1.3933 (1.4149)	Prec@(1,5) (59.5%, 87.9%)	
07/02 07:24:19午後 finetuneTeacher_trainer.py:180 [INFO] Train: [109/299] Final Prec@1 59.5267%
07/02 07:24:20午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [109][50/79]	Step 77440	Loss 1.9062	Prec@(1,5) (50.4%, 79.4%)
07/02 07:24:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [109][78/79]	Step 77440	Loss 1.9119	Prec@(1,5) (50.0%, 79.4%)
07/02 07:24:21午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [109/299] Final Prec@1 49.9800%
07/02 07:24:21午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:24:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][50/703]	Step 77490	lr 0.07063	Loss 1.6620 (1.3278)	Prec@(1,5) (60.8%, 89.6%)	
07/02 07:24:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][100/703]	Step 77540	lr 0.07063	Loss 1.4454 (1.3197)	Prec@(1,5) (61.5%, 89.6%)	
07/02 07:24:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][150/703]	Step 77590	lr 0.07063	Loss 1.3913 (1.3378)	Prec@(1,5) (61.2%, 89.2%)	
07/02 07:24:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][200/703]	Step 77640	lr 0.07063	Loss 1.0568 (1.3466)	Prec@(1,5) (61.3%, 88.9%)	
07/02 07:24:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][250/703]	Step 77690	lr 0.07063	Loss 1.3128 (1.3576)	Prec@(1,5) (61.2%, 88.6%)	
07/02 07:24:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][300/703]	Step 77740	lr 0.07063	Loss 1.6268 (1.3657)	Prec@(1,5) (61.0%, 88.6%)	
07/02 07:24:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][350/703]	Step 77790	lr 0.07063	Loss 1.1898 (1.3737)	Prec@(1,5) (60.8%, 88.5%)	
07/02 07:24:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][400/703]	Step 77840	lr 0.07063	Loss 1.1413 (1.3831)	Prec@(1,5) (60.5%, 88.5%)	
07/02 07:24:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][450/703]	Step 77890	lr 0.07063	Loss 1.2689 (1.3905)	Prec@(1,5) (60.4%, 88.3%)	
07/02 07:24:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][500/703]	Step 77940	lr 0.07063	Loss 1.7621 (1.3944)	Prec@(1,5) (60.3%, 88.2%)	
07/02 07:24:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][550/703]	Step 77990	lr 0.07063	Loss 1.3845 (1.3988)	Prec@(1,5) (60.3%, 88.1%)	
07/02 07:24:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][600/703]	Step 78040	lr 0.07063	Loss 1.4280 (1.4051)	Prec@(1,5) (60.1%, 88.1%)	
07/02 07:25:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][650/703]	Step 78090	lr 0.07063	Loss 1.2673 (1.4105)	Prec@(1,5) (60.0%, 88.0%)	
07/02 07:25:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][700/703]	Step 78140	lr 0.07063	Loss 1.2494 (1.4100)	Prec@(1,5) (60.0%, 87.9%)	
07/02 07:25:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [110][703/703]	Step 78143	lr 0.07063	Loss 1.4468 (1.4106)	Prec@(1,5) (60.0%, 87.9%)	
07/02 07:25:06午後 finetuneTeacher_trainer.py:180 [INFO] Train: [110/299] Final Prec@1 60.0378%
07/02 07:25:07午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [110][50/79]	Step 78144	Loss 2.0827	Prec@(1,5) (46.5%, 78.2%)
07/02 07:25:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [110][78/79]	Step 78144	Loss 2.0516	Prec@(1,5) (47.3%, 78.2%)
07/02 07:25:08午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [110/299] Final Prec@1 47.3200%
07/02 07:25:08午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:25:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][50/703]	Step 78194	lr 0.07016	Loss 1.2525 (1.3298)	Prec@(1,5) (61.6%, 89.0%)	
07/02 07:25:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][100/703]	Step 78244	lr 0.07016	Loss 1.2248 (1.2926)	Prec@(1,5) (62.4%, 89.6%)	
07/02 07:25:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][150/703]	Step 78294	lr 0.07016	Loss 1.3911 (1.2994)	Prec@(1,5) (62.1%, 89.6%)	
07/02 07:25:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][200/703]	Step 78344	lr 0.07016	Loss 1.6526 (1.3296)	Prec@(1,5) (61.5%, 89.2%)	
07/02 07:25:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][250/703]	Step 78394	lr 0.07016	Loss 1.2152 (1.3295)	Prec@(1,5) (61.5%, 89.2%)	
07/02 07:25:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][300/703]	Step 78444	lr 0.07016	Loss 1.2767 (1.3420)	Prec@(1,5) (61.1%, 89.0%)	
07/02 07:25:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][350/703]	Step 78494	lr 0.07016	Loss 1.4541 (1.3609)	Prec@(1,5) (60.7%, 88.8%)	
07/02 07:25:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][400/703]	Step 78544	lr 0.07016	Loss 1.7340 (1.3696)	Prec@(1,5) (60.4%, 88.7%)	
07/02 07:25:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][450/703]	Step 78594	lr 0.07016	Loss 1.2266 (1.3769)	Prec@(1,5) (60.2%, 88.6%)	
07/02 07:25:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][500/703]	Step 78644	lr 0.07016	Loss 1.2504 (1.3803)	Prec@(1,5) (60.2%, 88.6%)	
07/02 07:25:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][550/703]	Step 78694	lr 0.07016	Loss 1.7009 (1.3876)	Prec@(1,5) (60.1%, 88.5%)	
07/02 07:25:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][600/703]	Step 78744	lr 0.07016	Loss 1.6965 (1.3929)	Prec@(1,5) (60.0%, 88.4%)	
07/02 07:25:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][650/703]	Step 78794	lr 0.07016	Loss 1.2558 (1.3980)	Prec@(1,5) (59.9%, 88.3%)	
07/02 07:25:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][700/703]	Step 78844	lr 0.07016	Loss 1.6239 (1.4059)	Prec@(1,5) (59.7%, 88.2%)	
07/02 07:25:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [111][703/703]	Step 78847	lr 0.07016	Loss 1.3295 (1.4058)	Prec@(1,5) (59.7%, 88.2%)	
07/02 07:25:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [111/299] Final Prec@1 59.7200%
07/02 07:25:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [111][50/79]	Step 78848	Loss 1.9164	Prec@(1,5) (49.0%, 79.4%)
07/02 07:25:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [111][78/79]	Step 78848	Loss 1.9461	Prec@(1,5) (48.6%, 79.3%)
07/02 07:25:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [111/299] Final Prec@1 48.5800%
07/02 07:25:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:25:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][50/703]	Step 78898	lr 0.06968	Loss 1.6147 (1.3194)	Prec@(1,5) (62.4%, 89.4%)	
07/02 07:26:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][100/703]	Step 78948	lr 0.06968	Loss 1.2685 (1.3040)	Prec@(1,5) (62.5%, 89.7%)	
07/02 07:26:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][150/703]	Step 78998	lr 0.06968	Loss 1.4055 (1.3210)	Prec@(1,5) (62.1%, 89.3%)	
07/02 07:26:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][200/703]	Step 79048	lr 0.06968	Loss 1.2291 (1.3209)	Prec@(1,5) (62.2%, 89.2%)	
07/02 07:26:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][250/703]	Step 79098	lr 0.06968	Loss 1.4035 (1.3306)	Prec@(1,5) (61.9%, 89.1%)	
07/02 07:26:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][300/703]	Step 79148	lr 0.06968	Loss 1.3769 (1.3455)	Prec@(1,5) (61.6%, 88.9%)	
07/02 07:26:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][350/703]	Step 79198	lr 0.06968	Loss 1.0579 (1.3528)	Prec@(1,5) (61.4%, 88.8%)	
07/02 07:26:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][400/703]	Step 79248	lr 0.06968	Loss 1.6625 (1.3624)	Prec@(1,5) (61.1%, 88.7%)	
07/02 07:26:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][450/703]	Step 79298	lr 0.06968	Loss 1.5384 (1.3705)	Prec@(1,5) (60.8%, 88.6%)	
07/02 07:26:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][500/703]	Step 79348	lr 0.06968	Loss 1.6258 (1.3799)	Prec@(1,5) (60.6%, 88.4%)	
07/02 07:26:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][550/703]	Step 79398	lr 0.06968	Loss 1.4156 (1.3907)	Prec@(1,5) (60.4%, 88.3%)	
07/02 07:26:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][600/703]	Step 79448	lr 0.06968	Loss 1.5832 (1.4005)	Prec@(1,5) (60.1%, 88.1%)	
07/02 07:26:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][650/703]	Step 79498	lr 0.06968	Loss 1.4879 (1.4022)	Prec@(1,5) (60.0%, 88.0%)	
07/02 07:26:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][700/703]	Step 79548	lr 0.06968	Loss 1.3778 (1.4060)	Prec@(1,5) (59.7%, 88.0%)	
07/02 07:26:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [112][703/703]	Step 79551	lr 0.06968	Loss 1.2951 (1.4067)	Prec@(1,5) (59.7%, 88.0%)	
07/02 07:26:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [112/299] Final Prec@1 59.7089%
07/02 07:26:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [112][50/79]	Step 79552	Loss 1.9807	Prec@(1,5) (49.8%, 78.9%)
07/02 07:26:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [112][78/79]	Step 79552	Loss 1.9359	Prec@(1,5) (50.3%, 79.4%)
07/02 07:26:40午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [112/299] Final Prec@1 50.2200%
07/02 07:26:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:26:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][50/703]	Step 79602	lr 0.0692	Loss 0.9673 (1.2954)	Prec@(1,5) (62.8%, 89.9%)	
07/02 07:26:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][100/703]	Step 79652	lr 0.0692	Loss 1.1397 (1.2702)	Prec@(1,5) (63.2%, 90.5%)	
07/02 07:26:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][150/703]	Step 79702	lr 0.0692	Loss 1.2134 (1.3190)	Prec@(1,5) (61.8%, 89.4%)	
07/02 07:26:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][200/703]	Step 79752	lr 0.0692	Loss 1.3230 (1.3354)	Prec@(1,5) (61.4%, 89.2%)	
07/02 07:26:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][250/703]	Step 79802	lr 0.0692	Loss 1.5798 (1.3495)	Prec@(1,5) (60.9%, 89.0%)	
07/02 07:27:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][300/703]	Step 79852	lr 0.0692	Loss 1.2165 (1.3565)	Prec@(1,5) (60.9%, 88.8%)	
07/02 07:27:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][350/703]	Step 79902	lr 0.0692	Loss 1.5910 (1.3615)	Prec@(1,5) (60.8%, 88.8%)	
07/02 07:27:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][400/703]	Step 79952	lr 0.0692	Loss 1.2160 (1.3695)	Prec@(1,5) (60.5%, 88.7%)	
07/02 07:27:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][450/703]	Step 80002	lr 0.0692	Loss 1.2369 (1.3706)	Prec@(1,5) (60.5%, 88.7%)	
07/02 07:27:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][500/703]	Step 80052	lr 0.0692	Loss 1.0951 (1.3729)	Prec@(1,5) (60.4%, 88.6%)	
07/02 07:27:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][550/703]	Step 80102	lr 0.0692	Loss 1.5857 (1.3809)	Prec@(1,5) (60.2%, 88.5%)	
07/02 07:27:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][600/703]	Step 80152	lr 0.0692	Loss 1.2838 (1.3870)	Prec@(1,5) (60.1%, 88.4%)	
07/02 07:27:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][650/703]	Step 80202	lr 0.0692	Loss 1.5217 (1.3913)	Prec@(1,5) (59.9%, 88.4%)	
07/02 07:27:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][700/703]	Step 80252	lr 0.0692	Loss 1.6740 (1.3938)	Prec@(1,5) (59.9%, 88.3%)	
07/02 07:27:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [113][703/703]	Step 80255	lr 0.0692	Loss 1.9541 (1.3945)	Prec@(1,5) (59.8%, 88.3%)	
07/02 07:27:25午後 finetuneTeacher_trainer.py:180 [INFO] Train: [113/299] Final Prec@1 59.8311%
07/02 07:27:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [113][50/79]	Step 80256	Loss 1.8356	Prec@(1,5) (51.4%, 80.7%)
07/02 07:27:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [113][78/79]	Step 80256	Loss 1.8587	Prec@(1,5) (50.8%, 80.4%)
07/02 07:27:27午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [113/299] Final Prec@1 50.8400%
07/02 07:27:27午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:27:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][50/703]	Step 80306	lr 0.06872	Loss 1.4049 (1.3327)	Prec@(1,5) (61.6%, 89.9%)	
07/02 07:27:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][100/703]	Step 80356	lr 0.06872	Loss 1.3086 (1.2957)	Prec@(1,5) (63.0%, 90.1%)	
07/02 07:27:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][150/703]	Step 80406	lr 0.06872	Loss 1.5505 (1.2911)	Prec@(1,5) (62.8%, 89.9%)	
07/02 07:27:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][200/703]	Step 80456	lr 0.06872	Loss 1.3682 (1.3073)	Prec@(1,5) (62.2%, 90.0%)	
07/02 07:27:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][250/703]	Step 80506	lr 0.06872	Loss 1.4116 (1.3137)	Prec@(1,5) (62.0%, 89.9%)	
07/02 07:27:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][300/703]	Step 80556	lr 0.06872	Loss 1.1839 (1.3308)	Prec@(1,5) (61.7%, 89.5%)	
07/02 07:27:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][350/703]	Step 80606	lr 0.06872	Loss 1.6043 (1.3431)	Prec@(1,5) (61.5%, 89.2%)	
07/02 07:27:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][400/703]	Step 80656	lr 0.06872	Loss 1.5247 (1.3509)	Prec@(1,5) (61.2%, 89.1%)	
07/02 07:27:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][450/703]	Step 80706	lr 0.06872	Loss 1.5181 (1.3527)	Prec@(1,5) (61.3%, 89.0%)	
07/02 07:28:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][500/703]	Step 80756	lr 0.06872	Loss 1.2698 (1.3520)	Prec@(1,5) (61.2%, 89.0%)	
07/02 07:28:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][550/703]	Step 80806	lr 0.06872	Loss 1.4288 (1.3599)	Prec@(1,5) (61.1%, 88.9%)	
07/02 07:28:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][600/703]	Step 80856	lr 0.06872	Loss 0.9259 (1.3653)	Prec@(1,5) (60.9%, 88.8%)	
07/02 07:28:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][650/703]	Step 80906	lr 0.06872	Loss 1.7540 (1.3739)	Prec@(1,5) (60.7%, 88.7%)	
07/02 07:28:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][700/703]	Step 80956	lr 0.06872	Loss 1.5274 (1.3813)	Prec@(1,5) (60.5%, 88.6%)	
07/02 07:28:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [114][703/703]	Step 80959	lr 0.06872	Loss 1.5287 (1.3813)	Prec@(1,5) (60.5%, 88.6%)	
07/02 07:28:13午後 finetuneTeacher_trainer.py:180 [INFO] Train: [114/299] Final Prec@1 60.4533%
07/02 07:28:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [114][50/79]	Step 80960	Loss 1.8655	Prec@(1,5) (51.5%, 80.1%)
07/02 07:28:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [114][78/79]	Step 80960	Loss 1.8691	Prec@(1,5) (51.2%, 80.2%)
07/02 07:28:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [114/299] Final Prec@1 51.2200%
07/02 07:28:15午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:28:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][50/703]	Step 81010	lr 0.06824	Loss 1.5279 (1.3242)	Prec@(1,5) (62.6%, 88.4%)	
07/02 07:28:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][100/703]	Step 81060	lr 0.06824	Loss 1.6394 (1.3142)	Prec@(1,5) (62.1%, 89.4%)	
07/02 07:28:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][150/703]	Step 81110	lr 0.06824	Loss 1.4684 (1.3058)	Prec@(1,5) (62.2%, 89.7%)	
07/02 07:28:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][200/703]	Step 81160	lr 0.06824	Loss 1.3983 (1.3063)	Prec@(1,5) (62.3%, 89.5%)	
07/02 07:28:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][250/703]	Step 81210	lr 0.06824	Loss 1.1257 (1.3197)	Prec@(1,5) (62.1%, 89.3%)	
07/02 07:28:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][300/703]	Step 81260	lr 0.06824	Loss 1.3461 (1.3319)	Prec@(1,5) (61.7%, 89.2%)	
07/02 07:28:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][350/703]	Step 81310	lr 0.06824	Loss 1.0763 (1.3296)	Prec@(1,5) (61.9%, 89.2%)	
07/02 07:28:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][400/703]	Step 81360	lr 0.06824	Loss 1.1534 (1.3359)	Prec@(1,5) (61.8%, 89.1%)	
07/02 07:28:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][450/703]	Step 81410	lr 0.06824	Loss 1.2860 (1.3410)	Prec@(1,5) (61.8%, 89.0%)	
07/02 07:28:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][500/703]	Step 81460	lr 0.06824	Loss 1.4974 (1.3510)	Prec@(1,5) (61.5%, 88.8%)	
07/02 07:28:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][550/703]	Step 81510	lr 0.06824	Loss 1.1247 (1.3527)	Prec@(1,5) (61.5%, 88.8%)	
07/02 07:28:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][600/703]	Step 81560	lr 0.06824	Loss 1.2050 (1.3602)	Prec@(1,5) (61.1%, 88.8%)	
07/02 07:28:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][650/703]	Step 81610	lr 0.06824	Loss 1.2535 (1.3630)	Prec@(1,5) (61.1%, 88.7%)	
07/02 07:28:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][700/703]	Step 81660	lr 0.06824	Loss 1.0829 (1.3681)	Prec@(1,5) (61.0%, 88.6%)	
07/02 07:28:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [115][703/703]	Step 81663	lr 0.06824	Loss 1.3312 (1.3686)	Prec@(1,5) (61.0%, 88.6%)	
07/02 07:28:58午後 finetuneTeacher_trainer.py:180 [INFO] Train: [115/299] Final Prec@1 60.9933%
07/02 07:28:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [115][50/79]	Step 81664	Loss 1.8880	Prec@(1,5) (50.5%, 81.1%)
07/02 07:28:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [115][78/79]	Step 81664	Loss 1.9000	Prec@(1,5) (50.8%, 80.3%)
07/02 07:29:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [115/299] Final Prec@1 50.7800%
07/02 07:29:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:29:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][50/703]	Step 81714	lr 0.06775	Loss 1.0822 (1.3183)	Prec@(1,5) (61.7%, 89.6%)	
07/02 07:29:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][100/703]	Step 81764	lr 0.06775	Loss 1.3809 (1.3161)	Prec@(1,5) (61.6%, 89.5%)	
07/02 07:29:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][150/703]	Step 81814	lr 0.06775	Loss 1.6903 (1.3191)	Prec@(1,5) (61.5%, 89.5%)	
07/02 07:29:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][200/703]	Step 81864	lr 0.06775	Loss 1.5215 (1.3174)	Prec@(1,5) (61.6%, 89.4%)	
07/02 07:29:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][250/703]	Step 81914	lr 0.06775	Loss 1.0597 (1.3152)	Prec@(1,5) (61.6%, 89.5%)	
07/02 07:29:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][300/703]	Step 81964	lr 0.06775	Loss 1.2091 (1.3148)	Prec@(1,5) (61.7%, 89.5%)	
07/02 07:29:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][350/703]	Step 82014	lr 0.06775	Loss 1.3863 (1.3284)	Prec@(1,5) (61.4%, 89.3%)	
07/02 07:29:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][400/703]	Step 82064	lr 0.06775	Loss 1.0041 (1.3398)	Prec@(1,5) (61.2%, 89.1%)	
07/02 07:29:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][450/703]	Step 82114	lr 0.06775	Loss 1.8028 (1.3506)	Prec@(1,5) (60.9%, 88.9%)	
07/02 07:29:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][500/703]	Step 82164	lr 0.06775	Loss 1.1572 (1.3585)	Prec@(1,5) (60.7%, 88.8%)	
07/02 07:29:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][550/703]	Step 82214	lr 0.06775	Loss 1.1705 (1.3607)	Prec@(1,5) (60.8%, 88.7%)	
07/02 07:29:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][600/703]	Step 82264	lr 0.06775	Loss 1.5382 (1.3652)	Prec@(1,5) (60.7%, 88.7%)	
07/02 07:29:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][650/703]	Step 82314	lr 0.06775	Loss 1.5814 (1.3672)	Prec@(1,5) (60.6%, 88.6%)	
07/02 07:29:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][700/703]	Step 82364	lr 0.06775	Loss 1.8960 (1.3737)	Prec@(1,5) (60.4%, 88.5%)	
07/02 07:29:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [116][703/703]	Step 82367	lr 0.06775	Loss 1.5990 (1.3744)	Prec@(1,5) (60.4%, 88.5%)	
07/02 07:29:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [116/299] Final Prec@1 60.4267%
07/02 07:29:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [116][50/79]	Step 82368	Loss 1.8970	Prec@(1,5) (50.1%, 80.3%)
07/02 07:29:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [116][78/79]	Step 82368	Loss 1.8915	Prec@(1,5) (50.8%, 80.1%)
07/02 07:29:47午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [116/299] Final Prec@1 50.7600%
07/02 07:29:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:29:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][50/703]	Step 82418	lr 0.06727	Loss 0.9272 (1.2689)	Prec@(1,5) (63.7%, 90.1%)	
07/02 07:29:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][100/703]	Step 82468	lr 0.06727	Loss 1.2110 (1.2668)	Prec@(1,5) (63.7%, 89.9%)	
07/02 07:29:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][150/703]	Step 82518	lr 0.06727	Loss 1.5975 (1.2807)	Prec@(1,5) (63.1%, 90.0%)	
07/02 07:30:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][200/703]	Step 82568	lr 0.06727	Loss 1.1810 (1.2879)	Prec@(1,5) (63.0%, 89.9%)	
07/02 07:30:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][250/703]	Step 82618	lr 0.06727	Loss 1.3438 (1.3018)	Prec@(1,5) (62.5%, 89.7%)	
07/02 07:30:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][300/703]	Step 82668	lr 0.06727	Loss 1.6404 (1.3197)	Prec@(1,5) (62.0%, 89.4%)	
07/02 07:30:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][350/703]	Step 82718	lr 0.06727	Loss 1.0561 (1.3250)	Prec@(1,5) (61.8%, 89.4%)	
07/02 07:30:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][400/703]	Step 82768	lr 0.06727	Loss 1.2993 (1.3368)	Prec@(1,5) (61.4%, 89.2%)	
07/02 07:30:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][450/703]	Step 82818	lr 0.06727	Loss 1.3370 (1.3408)	Prec@(1,5) (61.3%, 89.1%)	
07/02 07:30:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][500/703]	Step 82868	lr 0.06727	Loss 1.4081 (1.3501)	Prec@(1,5) (61.2%, 88.9%)	
07/02 07:30:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][550/703]	Step 82918	lr 0.06727	Loss 1.2933 (1.3535)	Prec@(1,5) (61.1%, 88.9%)	
07/02 07:30:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][600/703]	Step 82968	lr 0.06727	Loss 1.1910 (1.3590)	Prec@(1,5) (61.0%, 88.9%)	
07/02 07:30:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][650/703]	Step 83018	lr 0.06727	Loss 1.6338 (1.3672)	Prec@(1,5) (60.8%, 88.8%)	
07/02 07:30:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][700/703]	Step 83068	lr 0.06727	Loss 0.9387 (1.3655)	Prec@(1,5) (60.9%, 88.8%)	
07/02 07:30:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [117][703/703]	Step 83071	lr 0.06727	Loss 1.6079 (1.3660)	Prec@(1,5) (60.9%, 88.8%)	
07/02 07:30:32午後 finetuneTeacher_trainer.py:180 [INFO] Train: [117/299] Final Prec@1 60.8733%
07/02 07:30:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [117][50/79]	Step 83072	Loss 1.8763	Prec@(1,5) (50.4%, 80.7%)
07/02 07:30:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [117][78/79]	Step 83072	Loss 1.8955	Prec@(1,5) (50.1%, 80.3%)
07/02 07:30:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [117/299] Final Prec@1 50.0800%
07/02 07:30:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.6400%
07/02 07:30:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][50/703]	Step 83122	lr 0.06678	Loss 1.0758 (1.2689)	Prec@(1,5) (62.5%, 90.6%)	
07/02 07:30:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][100/703]	Step 83172	lr 0.06678	Loss 1.0475 (1.2893)	Prec@(1,5) (62.3%, 90.5%)	
07/02 07:30:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][150/703]	Step 83222	lr 0.06678	Loss 1.5133 (1.3118)	Prec@(1,5) (61.9%, 89.6%)	
07/02 07:30:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][200/703]	Step 83272	lr 0.06678	Loss 1.2160 (1.3217)	Prec@(1,5) (61.8%, 89.4%)	
07/02 07:30:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][250/703]	Step 83322	lr 0.06678	Loss 1.0588 (1.3279)	Prec@(1,5) (61.8%, 89.4%)	
07/02 07:30:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][300/703]	Step 83372	lr 0.06678	Loss 1.3008 (1.3357)	Prec@(1,5) (61.7%, 89.3%)	
07/02 07:30:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][350/703]	Step 83422	lr 0.06678	Loss 1.5609 (1.3408)	Prec@(1,5) (61.5%, 89.2%)	
07/02 07:30:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][400/703]	Step 83472	lr 0.06678	Loss 1.2506 (1.3430)	Prec@(1,5) (61.4%, 89.3%)	
07/02 07:31:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][450/703]	Step 83522	lr 0.06678	Loss 1.5184 (1.3476)	Prec@(1,5) (61.3%, 89.2%)	
07/02 07:31:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][500/703]	Step 83572	lr 0.06678	Loss 1.6228 (1.3515)	Prec@(1,5) (61.2%, 89.2%)	
07/02 07:31:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][550/703]	Step 83622	lr 0.06678	Loss 1.1605 (1.3546)	Prec@(1,5) (61.1%, 89.1%)	
07/02 07:31:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][600/703]	Step 83672	lr 0.06678	Loss 1.2065 (1.3543)	Prec@(1,5) (61.1%, 89.0%)	
07/02 07:31:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][650/703]	Step 83722	lr 0.06678	Loss 1.1516 (1.3580)	Prec@(1,5) (61.1%, 89.0%)	
07/02 07:31:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][700/703]	Step 83772	lr 0.06678	Loss 1.4684 (1.3609)	Prec@(1,5) (61.0%, 89.0%)	
07/02 07:31:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [118][703/703]	Step 83775	lr 0.06678	Loss 1.2964 (1.3609)	Prec@(1,5) (60.9%, 89.0%)	
07/02 07:31:16午後 finetuneTeacher_trainer.py:180 [INFO] Train: [118/299] Final Prec@1 60.9333%
07/02 07:31:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [118][50/79]	Step 83776	Loss 1.8733	Prec@(1,5) (50.9%, 79.5%)
07/02 07:31:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [118][78/79]	Step 83776	Loss 1.8455	Prec@(1,5) (51.8%, 79.9%)
07/02 07:31:18午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [118/299] Final Prec@1 51.7600%
07/02 07:31:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.7600%
07/02 07:31:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][50/703]	Step 83826	lr 0.06629	Loss 1.3436 (1.2873)	Prec@(1,5) (62.1%, 89.9%)	
07/02 07:31:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][100/703]	Step 83876	lr 0.06629	Loss 1.2153 (1.2679)	Prec@(1,5) (62.8%, 90.6%)	
07/02 07:31:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][150/703]	Step 83926	lr 0.06629	Loss 1.1697 (1.2798)	Prec@(1,5) (62.7%, 90.4%)	
07/02 07:31:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][200/703]	Step 83976	lr 0.06629	Loss 0.8714 (1.2815)	Prec@(1,5) (62.6%, 90.1%)	
07/02 07:31:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][250/703]	Step 84026	lr 0.06629	Loss 1.2023 (1.2971)	Prec@(1,5) (62.2%, 89.9%)	
07/02 07:31:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][300/703]	Step 84076	lr 0.06629	Loss 1.2062 (1.3015)	Prec@(1,5) (62.3%, 89.8%)	
07/02 07:31:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][350/703]	Step 84126	lr 0.06629	Loss 1.3476 (1.3062)	Prec@(1,5) (62.3%, 89.6%)	
07/02 07:31:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][400/703]	Step 84176	lr 0.06629	Loss 1.5890 (1.3182)	Prec@(1,5) (62.1%, 89.5%)	
07/02 07:31:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][450/703]	Step 84226	lr 0.06629	Loss 1.3303 (1.3269)	Prec@(1,5) (61.9%, 89.3%)	
07/02 07:31:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][500/703]	Step 84276	lr 0.06629	Loss 1.4491 (1.3363)	Prec@(1,5) (61.7%, 89.1%)	
07/02 07:31:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][550/703]	Step 84326	lr 0.06629	Loss 1.3644 (1.3392)	Prec@(1,5) (61.6%, 89.1%)	
07/02 07:31:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][600/703]	Step 84376	lr 0.06629	Loss 1.8272 (1.3414)	Prec@(1,5) (61.5%, 89.1%)	
07/02 07:31:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][650/703]	Step 84426	lr 0.06629	Loss 1.5446 (1.3463)	Prec@(1,5) (61.4%, 88.9%)	
07/02 07:32:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][700/703]	Step 84476	lr 0.06629	Loss 1.5401 (1.3540)	Prec@(1,5) (61.2%, 88.8%)	
07/02 07:32:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [119][703/703]	Step 84479	lr 0.06629	Loss 1.2788 (1.3544)	Prec@(1,5) (61.2%, 88.8%)	
07/02 07:32:01午後 finetuneTeacher_trainer.py:180 [INFO] Train: [119/299] Final Prec@1 61.2000%
07/02 07:32:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [119][50/79]	Step 84480	Loss 1.9884	Prec@(1,5) (50.1%, 78.6%)
07/02 07:32:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [119][78/79]	Step 84480	Loss 1.9829	Prec@(1,5) (49.5%, 79.1%)
07/02 07:32:03午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [119/299] Final Prec@1 49.4600%
07/02 07:32:03午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.7600%
07/02 07:32:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][50/703]	Step 84530	lr 0.0658	Loss 1.3173 (1.3022)	Prec@(1,5) (62.2%, 89.8%)	
07/02 07:32:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][100/703]	Step 84580	lr 0.0658	Loss 1.3572 (1.3043)	Prec@(1,5) (62.2%, 89.9%)	
07/02 07:32:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][150/703]	Step 84630	lr 0.0658	Loss 0.8792 (1.2903)	Prec@(1,5) (62.4%, 90.2%)	
07/02 07:32:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][200/703]	Step 84680	lr 0.0658	Loss 1.3890 (1.3028)	Prec@(1,5) (62.0%, 90.0%)	
07/02 07:32:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][250/703]	Step 84730	lr 0.0658	Loss 1.2207 (1.2998)	Prec@(1,5) (62.2%, 90.0%)	
07/02 07:32:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][300/703]	Step 84780	lr 0.0658	Loss 1.0969 (1.3088)	Prec@(1,5) (61.9%, 89.8%)	
07/02 07:32:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][350/703]	Step 84830	lr 0.0658	Loss 0.9599 (1.3159)	Prec@(1,5) (61.8%, 89.7%)	
07/02 07:32:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][400/703]	Step 84880	lr 0.0658	Loss 1.6804 (1.3261)	Prec@(1,5) (61.5%, 89.6%)	
07/02 07:32:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][450/703]	Step 84930	lr 0.0658	Loss 1.0920 (1.3252)	Prec@(1,5) (61.6%, 89.5%)	
07/02 07:32:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][500/703]	Step 84980	lr 0.0658	Loss 1.4417 (1.3313)	Prec@(1,5) (61.4%, 89.5%)	
07/02 07:32:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][550/703]	Step 85030	lr 0.0658	Loss 1.3045 (1.3366)	Prec@(1,5) (61.2%, 89.4%)	
07/02 07:32:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][600/703]	Step 85080	lr 0.0658	Loss 1.7355 (1.3417)	Prec@(1,5) (61.2%, 89.3%)	
07/02 07:32:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][650/703]	Step 85130	lr 0.0658	Loss 1.5491 (1.3486)	Prec@(1,5) (61.0%, 89.2%)	
07/02 07:32:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][700/703]	Step 85180	lr 0.0658	Loss 1.4052 (1.3526)	Prec@(1,5) (60.9%, 89.1%)	
07/02 07:32:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [120][703/703]	Step 85183	lr 0.0658	Loss 1.3252 (1.3521)	Prec@(1,5) (60.9%, 89.1%)	
07/02 07:32:49午後 finetuneTeacher_trainer.py:180 [INFO] Train: [120/299] Final Prec@1 60.9422%
07/02 07:32:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [120][50/79]	Step 85184	Loss 1.9016	Prec@(1,5) (50.3%, 80.3%)
07/02 07:32:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [120][78/79]	Step 85184	Loss 1.8944	Prec@(1,5) (50.1%, 80.1%)
07/02 07:32:50午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [120/299] Final Prec@1 50.0600%
07/02 07:32:51午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.7600%
07/02 07:32:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][50/703]	Step 85234	lr 0.0653	Loss 1.1971 (1.2622)	Prec@(1,5) (63.1%, 90.2%)	
07/02 07:32:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][100/703]	Step 85284	lr 0.0653	Loss 1.6291 (1.2428)	Prec@(1,5) (64.2%, 90.5%)	
07/02 07:33:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][150/703]	Step 85334	lr 0.0653	Loss 1.2428 (1.2515)	Prec@(1,5) (63.8%, 90.3%)	
07/02 07:33:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][200/703]	Step 85384	lr 0.0653	Loss 1.2885 (1.2566)	Prec@(1,5) (63.9%, 90.1%)	
07/02 07:33:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][250/703]	Step 85434	lr 0.0653	Loss 0.9355 (1.2691)	Prec@(1,5) (63.3%, 90.1%)	
07/02 07:33:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][300/703]	Step 85484	lr 0.0653	Loss 1.4246 (1.2742)	Prec@(1,5) (63.2%, 90.0%)	
07/02 07:33:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][350/703]	Step 85534	lr 0.0653	Loss 1.3749 (1.2905)	Prec@(1,5) (62.8%, 89.8%)	
07/02 07:33:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][400/703]	Step 85584	lr 0.0653	Loss 1.0223 (1.2996)	Prec@(1,5) (62.5%, 89.6%)	
07/02 07:33:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][450/703]	Step 85634	lr 0.0653	Loss 1.2203 (1.3028)	Prec@(1,5) (62.4%, 89.6%)	
07/02 07:33:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][500/703]	Step 85684	lr 0.0653	Loss 1.5379 (1.3157)	Prec@(1,5) (61.9%, 89.4%)	
07/02 07:33:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][550/703]	Step 85734	lr 0.0653	Loss 1.5350 (1.3250)	Prec@(1,5) (61.8%, 89.3%)	
07/02 07:33:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][600/703]	Step 85784	lr 0.0653	Loss 1.8189 (1.3291)	Prec@(1,5) (61.7%, 89.3%)	
07/02 07:33:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][650/703]	Step 85834	lr 0.0653	Loss 1.4197 (1.3353)	Prec@(1,5) (61.6%, 89.1%)	
07/02 07:33:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][700/703]	Step 85884	lr 0.0653	Loss 1.2596 (1.3390)	Prec@(1,5) (61.5%, 89.0%)	
07/02 07:33:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [121][703/703]	Step 85887	lr 0.0653	Loss 1.2687 (1.3388)	Prec@(1,5) (61.5%, 89.0%)	
07/02 07:33:35午後 finetuneTeacher_trainer.py:180 [INFO] Train: [121/299] Final Prec@1 61.4511%
07/02 07:33:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [121][50/79]	Step 85888	Loss 1.9094	Prec@(1,5) (50.0%, 80.6%)
07/02 07:33:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [121][78/79]	Step 85888	Loss 1.8612	Prec@(1,5) (50.6%, 81.1%)
07/02 07:33:36午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [121/299] Final Prec@1 50.5800%
07/02 07:33:37午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.7600%
07/02 07:33:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][50/703]	Step 85938	lr 0.06481	Loss 1.4078 (1.2440)	Prec@(1,5) (63.3%, 90.7%)	
07/02 07:33:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][100/703]	Step 85988	lr 0.06481	Loss 1.2201 (1.2385)	Prec@(1,5) (63.9%, 90.8%)	
07/02 07:33:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][150/703]	Step 86038	lr 0.06481	Loss 1.5458 (1.2503)	Prec@(1,5) (63.8%, 90.6%)	
07/02 07:33:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][200/703]	Step 86088	lr 0.06481	Loss 1.5322 (1.2728)	Prec@(1,5) (63.2%, 90.1%)	
07/02 07:33:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][250/703]	Step 86138	lr 0.06481	Loss 1.4150 (1.2856)	Prec@(1,5) (62.8%, 90.0%)	
07/02 07:33:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][300/703]	Step 86188	lr 0.06481	Loss 1.1727 (1.3027)	Prec@(1,5) (62.2%, 89.7%)	
07/02 07:33:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][350/703]	Step 86238	lr 0.06481	Loss 1.2809 (1.3116)	Prec@(1,5) (61.9%, 89.7%)	
07/02 07:34:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][400/703]	Step 86288	lr 0.06481	Loss 1.4467 (1.3171)	Prec@(1,5) (61.8%, 89.6%)	
07/02 07:34:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][450/703]	Step 86338	lr 0.06481	Loss 1.5336 (1.3239)	Prec@(1,5) (61.7%, 89.5%)	
07/02 07:34:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][500/703]	Step 86388	lr 0.06481	Loss 1.5318 (1.3258)	Prec@(1,5) (61.5%, 89.5%)	
07/02 07:34:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][550/703]	Step 86438	lr 0.06481	Loss 1.2123 (1.3263)	Prec@(1,5) (61.5%, 89.5%)	
07/02 07:34:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][600/703]	Step 86488	lr 0.06481	Loss 1.3595 (1.3310)	Prec@(1,5) (61.5%, 89.4%)	
07/02 07:34:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][650/703]	Step 86538	lr 0.06481	Loss 1.2986 (1.3332)	Prec@(1,5) (61.5%, 89.4%)	
07/02 07:34:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][700/703]	Step 86588	lr 0.06481	Loss 1.7018 (1.3388)	Prec@(1,5) (61.4%, 89.3%)	
07/02 07:34:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [122][703/703]	Step 86591	lr 0.06481	Loss 1.7337 (1.3398)	Prec@(1,5) (61.4%, 89.3%)	
07/02 07:34:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [122/299] Final Prec@1 61.3689%
07/02 07:34:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [122][50/79]	Step 86592	Loss 1.8405	Prec@(1,5) (51.0%, 81.7%)
07/02 07:34:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [122][78/79]	Step 86592	Loss 1.8338	Prec@(1,5) (51.3%, 81.5%)
07/02 07:34:21午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [122/299] Final Prec@1 51.3400%
07/02 07:34:22午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.7600%
07/02 07:34:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][50/703]	Step 86642	lr 0.06431	Loss 1.3228 (1.2518)	Prec@(1,5) (64.2%, 90.9%)	
07/02 07:34:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][100/703]	Step 86692	lr 0.06431	Loss 1.3103 (1.2478)	Prec@(1,5) (64.5%, 91.0%)	
07/02 07:34:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][150/703]	Step 86742	lr 0.06431	Loss 1.3494 (1.2522)	Prec@(1,5) (64.4%, 90.7%)	
07/02 07:34:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][200/703]	Step 86792	lr 0.06431	Loss 1.4292 (1.2576)	Prec@(1,5) (64.2%, 90.6%)	
07/02 07:34:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][250/703]	Step 86842	lr 0.06431	Loss 1.5308 (1.2768)	Prec@(1,5) (63.5%, 90.2%)	
07/02 07:34:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][300/703]	Step 86892	lr 0.06431	Loss 1.1402 (1.2849)	Prec@(1,5) (63.2%, 90.0%)	
07/02 07:34:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][350/703]	Step 86942	lr 0.06431	Loss 1.2647 (1.2950)	Prec@(1,5) (62.9%, 89.8%)	
07/02 07:34:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][400/703]	Step 86992	lr 0.06431	Loss 1.5134 (1.2908)	Prec@(1,5) (62.8%, 89.9%)	
07/02 07:34:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][450/703]	Step 87042	lr 0.06431	Loss 1.3512 (1.2927)	Prec@(1,5) (62.8%, 89.9%)	
07/02 07:34:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][500/703]	Step 87092	lr 0.06431	Loss 1.0419 (1.3038)	Prec@(1,5) (62.4%, 89.8%)	
07/02 07:34:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][550/703]	Step 87142	lr 0.06431	Loss 1.5180 (1.3132)	Prec@(1,5) (62.1%, 89.6%)	
07/02 07:35:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][600/703]	Step 87192	lr 0.06431	Loss 1.5231 (1.3212)	Prec@(1,5) (62.0%, 89.5%)	
07/02 07:35:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][650/703]	Step 87242	lr 0.06431	Loss 1.3880 (1.3251)	Prec@(1,5) (61.9%, 89.4%)	
07/02 07:35:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][700/703]	Step 87292	lr 0.06431	Loss 1.4741 (1.3314)	Prec@(1,5) (61.8%, 89.3%)	
07/02 07:35:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [123][703/703]	Step 87295	lr 0.06431	Loss 1.1918 (1.3321)	Prec@(1,5) (61.8%, 89.3%)	
07/02 07:35:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [123/299] Final Prec@1 61.7533%
07/02 07:35:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [123][50/79]	Step 87296	Loss 1.8006	Prec@(1,5) (51.8%, 81.2%)
07/02 07:35:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [123][78/79]	Step 87296	Loss 1.8359	Prec@(1,5) (51.8%, 80.6%)
07/02 07:35:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [123/299] Final Prec@1 51.8000%
07/02 07:35:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.8000%
07/02 07:35:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][50/703]	Step 87346	lr 0.06381	Loss 1.3766 (1.2167)	Prec@(1,5) (64.3%, 90.8%)	
07/02 07:35:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][100/703]	Step 87396	lr 0.06381	Loss 1.2718 (1.2066)	Prec@(1,5) (64.4%, 91.1%)	
07/02 07:35:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][150/703]	Step 87446	lr 0.06381	Loss 1.1695 (1.2289)	Prec@(1,5) (63.8%, 91.0%)	
07/02 07:35:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][200/703]	Step 87496	lr 0.06381	Loss 1.3978 (1.2438)	Prec@(1,5) (63.5%, 90.8%)	
07/02 07:35:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][250/703]	Step 87546	lr 0.06381	Loss 1.0596 (1.2493)	Prec@(1,5) (63.4%, 90.9%)	
07/02 07:35:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][300/703]	Step 87596	lr 0.06381	Loss 1.4405 (1.2660)	Prec@(1,5) (63.0%, 90.6%)	
07/02 07:35:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][350/703]	Step 87646	lr 0.06381	Loss 1.3859 (1.2762)	Prec@(1,5) (62.7%, 90.4%)	
07/02 07:35:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][400/703]	Step 87696	lr 0.06381	Loss 1.2024 (1.2863)	Prec@(1,5) (62.5%, 90.3%)	
07/02 07:35:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][450/703]	Step 87746	lr 0.06381	Loss 1.1707 (1.2953)	Prec@(1,5) (62.3%, 90.1%)	
07/02 07:35:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][500/703]	Step 87796	lr 0.06381	Loss 1.4730 (1.2999)	Prec@(1,5) (62.3%, 90.0%)	
07/02 07:35:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][550/703]	Step 87846	lr 0.06381	Loss 1.5522 (1.2998)	Prec@(1,5) (62.3%, 89.9%)	
07/02 07:35:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][600/703]	Step 87896	lr 0.06381	Loss 1.4092 (1.3002)	Prec@(1,5) (62.4%, 89.9%)	
07/02 07:35:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][650/703]	Step 87946	lr 0.06381	Loss 1.1418 (1.3097)	Prec@(1,5) (62.1%, 89.7%)	
07/02 07:35:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][700/703]	Step 87996	lr 0.06381	Loss 1.8316 (1.3148)	Prec@(1,5) (62.1%, 89.6%)	
07/02 07:35:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [124][703/703]	Step 87999	lr 0.06381	Loss 1.4172 (1.3152)	Prec@(1,5) (62.1%, 89.6%)	
07/02 07:35:55午後 finetuneTeacher_trainer.py:180 [INFO] Train: [124/299] Final Prec@1 62.0467%
07/02 07:35:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [124][50/79]	Step 88000	Loss 1.7987	Prec@(1,5) (51.8%, 81.9%)
07/02 07:35:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [124][78/79]	Step 88000	Loss 1.8233	Prec@(1,5) (51.5%, 81.4%)
07/02 07:35:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [124/299] Final Prec@1 51.4600%
07/02 07:35:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 51.8000%
07/02 07:36:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][50/703]	Step 88050	lr 0.06331	Loss 1.3773 (1.1965)	Prec@(1,5) (64.4%, 91.6%)	
07/02 07:36:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][100/703]	Step 88100	lr 0.06331	Loss 1.4119 (1.2017)	Prec@(1,5) (64.5%, 91.2%)	
07/02 07:36:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][150/703]	Step 88150	lr 0.06331	Loss 1.4642 (1.2139)	Prec@(1,5) (64.5%, 91.1%)	
07/02 07:36:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][200/703]	Step 88200	lr 0.06331	Loss 1.3928 (1.2247)	Prec@(1,5) (64.1%, 91.0%)	
07/02 07:36:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][250/703]	Step 88250	lr 0.06331	Loss 1.0799 (1.2370)	Prec@(1,5) (63.8%, 90.7%)	
07/02 07:36:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][300/703]	Step 88300	lr 0.06331	Loss 1.4926 (1.2516)	Prec@(1,5) (63.5%, 90.4%)	
07/02 07:36:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][350/703]	Step 88350	lr 0.06331	Loss 1.0229 (1.2608)	Prec@(1,5) (63.2%, 90.2%)	
07/02 07:36:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][400/703]	Step 88400	lr 0.06331	Loss 1.5225 (1.2732)	Prec@(1,5) (63.0%, 90.0%)	
07/02 07:36:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][450/703]	Step 88450	lr 0.06331	Loss 1.2932 (1.2828)	Prec@(1,5) (62.7%, 89.9%)	
07/02 07:36:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][500/703]	Step 88500	lr 0.06331	Loss 1.6233 (1.2870)	Prec@(1,5) (62.6%, 89.8%)	
07/02 07:36:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][550/703]	Step 88550	lr 0.06331	Loss 1.2357 (1.2904)	Prec@(1,5) (62.6%, 89.8%)	
07/02 07:36:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][600/703]	Step 88600	lr 0.06331	Loss 1.2590 (1.2977)	Prec@(1,5) (62.3%, 89.7%)	
07/02 07:36:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][650/703]	Step 88650	lr 0.06331	Loss 1.3433 (1.3008)	Prec@(1,5) (62.2%, 89.6%)	
07/02 07:36:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][700/703]	Step 88700	lr 0.06331	Loss 1.6012 (1.3069)	Prec@(1,5) (62.1%, 89.6%)	
07/02 07:36:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [125][703/703]	Step 88703	lr 0.06331	Loss 1.6284 (1.3078)	Prec@(1,5) (62.1%, 89.6%)	
07/02 07:36:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [125/299] Final Prec@1 62.0933%
07/02 07:36:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [125][50/79]	Step 88704	Loss 1.8449	Prec@(1,5) (51.5%, 81.3%)
07/02 07:36:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [125][78/79]	Step 88704	Loss 1.8299	Prec@(1,5) (52.1%, 81.4%)
07/02 07:36:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [125/299] Final Prec@1 52.1200%
07/02 07:36:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.1200%
07/02 07:36:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][50/703]	Step 88754	lr 0.06281	Loss 1.0679 (1.2649)	Prec@(1,5) (63.2%, 90.5%)	
07/02 07:36:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][100/703]	Step 88804	lr 0.06281	Loss 0.9158 (1.2541)	Prec@(1,5) (64.0%, 90.4%)	
07/02 07:36:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][150/703]	Step 88854	lr 0.06281	Loss 0.9612 (1.2335)	Prec@(1,5) (64.2%, 90.8%)	
07/02 07:36:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][200/703]	Step 88904	lr 0.06281	Loss 1.1600 (1.2367)	Prec@(1,5) (64.0%, 90.9%)	
07/02 07:36:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][250/703]	Step 88954	lr 0.06281	Loss 1.0191 (1.2339)	Prec@(1,5) (64.2%, 90.8%)	
07/02 07:37:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][300/703]	Step 89004	lr 0.06281	Loss 1.1414 (1.2473)	Prec@(1,5) (63.8%, 90.7%)	
07/02 07:37:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][350/703]	Step 89054	lr 0.06281	Loss 1.3577 (1.2593)	Prec@(1,5) (63.5%, 90.5%)	
07/02 07:37:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][400/703]	Step 89104	lr 0.06281	Loss 1.1014 (1.2670)	Prec@(1,5) (63.4%, 90.4%)	
07/02 07:37:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][450/703]	Step 89154	lr 0.06281	Loss 1.4424 (1.2727)	Prec@(1,5) (63.2%, 90.3%)	
07/02 07:37:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][500/703]	Step 89204	lr 0.06281	Loss 1.4040 (1.2766)	Prec@(1,5) (63.1%, 90.3%)	
07/02 07:37:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][550/703]	Step 89254	lr 0.06281	Loss 1.2807 (1.2827)	Prec@(1,5) (62.9%, 90.2%)	
07/02 07:37:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][600/703]	Step 89304	lr 0.06281	Loss 1.1699 (1.2846)	Prec@(1,5) (62.9%, 90.1%)	
07/02 07:37:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][650/703]	Step 89354	lr 0.06281	Loss 1.5286 (1.2880)	Prec@(1,5) (62.8%, 90.0%)	
07/02 07:37:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][700/703]	Step 89404	lr 0.06281	Loss 1.2769 (1.2969)	Prec@(1,5) (62.6%, 89.9%)	
07/02 07:37:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [126][703/703]	Step 89407	lr 0.06281	Loss 1.5040 (1.2980)	Prec@(1,5) (62.5%, 89.9%)	
07/02 07:37:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [126/299] Final Prec@1 62.5422%
07/02 07:37:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [126][50/79]	Step 89408	Loss 1.9126	Prec@(1,5) (49.7%, 80.7%)
07/02 07:37:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [126][78/79]	Step 89408	Loss 1.8731	Prec@(1,5) (50.4%, 80.9%)
07/02 07:37:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [126/299] Final Prec@1 50.3600%
07/02 07:37:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.1200%
07/02 07:37:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][50/703]	Step 89458	lr 0.06231	Loss 1.4267 (1.1914)	Prec@(1,5) (66.2%, 90.9%)	
07/02 07:37:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][100/703]	Step 89508	lr 0.06231	Loss 1.1113 (1.2094)	Prec@(1,5) (65.0%, 90.9%)	
07/02 07:37:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][150/703]	Step 89558	lr 0.06231	Loss 1.5885 (1.2185)	Prec@(1,5) (64.4%, 90.9%)	
07/02 07:37:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][200/703]	Step 89608	lr 0.06231	Loss 1.0054 (1.2358)	Prec@(1,5) (63.9%, 90.7%)	
07/02 07:37:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][250/703]	Step 89658	lr 0.06231	Loss 1.7803 (1.2552)	Prec@(1,5) (63.5%, 90.3%)	
07/02 07:37:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][300/703]	Step 89708	lr 0.06231	Loss 1.4256 (1.2584)	Prec@(1,5) (63.4%, 90.2%)	
07/02 07:37:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][350/703]	Step 89758	lr 0.06231	Loss 1.4568 (1.2672)	Prec@(1,5) (63.3%, 90.1%)	
07/02 07:37:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][400/703]	Step 89808	lr 0.06231	Loss 1.2579 (1.2697)	Prec@(1,5) (63.3%, 90.1%)	
07/02 07:37:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][450/703]	Step 89858	lr 0.06231	Loss 1.1869 (1.2762)	Prec@(1,5) (63.1%, 90.0%)	
07/02 07:38:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][500/703]	Step 89908	lr 0.06231	Loss 1.2355 (1.2813)	Prec@(1,5) (62.9%, 89.9%)	
07/02 07:38:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][550/703]	Step 89958	lr 0.06231	Loss 1.2719 (1.2844)	Prec@(1,5) (62.9%, 89.9%)	
07/02 07:38:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][600/703]	Step 90008	lr 0.06231	Loss 1.0168 (1.2891)	Prec@(1,5) (62.8%, 89.8%)	
07/02 07:38:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][650/703]	Step 90058	lr 0.06231	Loss 1.3830 (1.2916)	Prec@(1,5) (62.6%, 89.8%)	
07/02 07:38:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][700/703]	Step 90108	lr 0.06231	Loss 1.2654 (1.2947)	Prec@(1,5) (62.5%, 89.8%)	
07/02 07:38:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [127][703/703]	Step 90111	lr 0.06231	Loss 1.4359 (1.2950)	Prec@(1,5) (62.5%, 89.7%)	
07/02 07:38:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [127/299] Final Prec@1 62.5044%
07/02 07:38:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [127][50/79]	Step 90112	Loss 1.9228	Prec@(1,5) (49.8%, 79.5%)
07/02 07:38:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [127][78/79]	Step 90112	Loss 1.9191	Prec@(1,5) (50.3%, 79.9%)
07/02 07:38:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [127/299] Final Prec@1 50.3400%
07/02 07:38:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.1200%
07/02 07:38:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][50/703]	Step 90162	lr 0.0618	Loss 1.1154 (1.2602)	Prec@(1,5) (63.7%, 90.2%)	
07/02 07:38:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][100/703]	Step 90212	lr 0.0618	Loss 1.2586 (1.2190)	Prec@(1,5) (64.2%, 91.0%)	
07/02 07:38:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][150/703]	Step 90262	lr 0.0618	Loss 1.1105 (1.2239)	Prec@(1,5) (64.1%, 90.9%)	
07/02 07:38:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][200/703]	Step 90312	lr 0.0618	Loss 1.4678 (1.2333)	Prec@(1,5) (64.0%, 90.7%)	
07/02 07:38:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][250/703]	Step 90362	lr 0.0618	Loss 1.1683 (1.2404)	Prec@(1,5) (63.8%, 90.6%)	
07/02 07:38:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][300/703]	Step 90412	lr 0.0618	Loss 1.0191 (1.2468)	Prec@(1,5) (63.6%, 90.5%)	
07/02 07:38:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][350/703]	Step 90462	lr 0.0618	Loss 1.0636 (1.2473)	Prec@(1,5) (63.8%, 90.4%)	
07/02 07:38:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][400/703]	Step 90512	lr 0.0618	Loss 1.1388 (1.2499)	Prec@(1,5) (63.8%, 90.4%)	
07/02 07:38:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][450/703]	Step 90562	lr 0.0618	Loss 1.3119 (1.2578)	Prec@(1,5) (63.6%, 90.3%)	
07/02 07:38:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][500/703]	Step 90612	lr 0.0618	Loss 1.3680 (1.2659)	Prec@(1,5) (63.3%, 90.2%)	
07/02 07:38:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][550/703]	Step 90662	lr 0.0618	Loss 1.3984 (1.2708)	Prec@(1,5) (63.1%, 90.1%)	
07/02 07:38:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][600/703]	Step 90712	lr 0.0618	Loss 1.1877 (1.2738)	Prec@(1,5) (63.0%, 90.0%)	
07/02 07:38:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][650/703]	Step 90762	lr 0.0618	Loss 1.6407 (1.2790)	Prec@(1,5) (62.9%, 90.0%)	
07/02 07:38:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][700/703]	Step 90812	lr 0.0618	Loss 1.6861 (1.2854)	Prec@(1,5) (62.7%, 89.9%)	
07/02 07:38:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [128][703/703]	Step 90815	lr 0.0618	Loss 1.2108 (1.2852)	Prec@(1,5) (62.7%, 89.9%)	
07/02 07:38:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [128/299] Final Prec@1 62.7089%
07/02 07:39:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [128][50/79]	Step 90816	Loss 1.9091	Prec@(1,5) (50.6%, 79.9%)
07/02 07:39:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [128][78/79]	Step 90816	Loss 1.8983	Prec@(1,5) (50.5%, 80.1%)
07/02 07:39:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [128/299] Final Prec@1 50.5000%
07/02 07:39:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.1200%
07/02 07:39:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][50/703]	Step 90866	lr 0.0613	Loss 1.2405 (1.1980)	Prec@(1,5) (64.8%, 91.5%)	
07/02 07:39:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][100/703]	Step 90916	lr 0.0613	Loss 1.4193 (1.1914)	Prec@(1,5) (65.3%, 91.5%)	
07/02 07:39:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][150/703]	Step 90966	lr 0.0613	Loss 1.2459 (1.1842)	Prec@(1,5) (65.6%, 91.5%)	
07/02 07:39:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][200/703]	Step 91016	lr 0.0613	Loss 1.2388 (1.1986)	Prec@(1,5) (65.1%, 91.3%)	
07/02 07:39:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][250/703]	Step 91066	lr 0.0613	Loss 1.5761 (1.2085)	Prec@(1,5) (64.8%, 91.2%)	
07/02 07:39:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][300/703]	Step 91116	lr 0.0613	Loss 1.0822 (1.2269)	Prec@(1,5) (64.3%, 90.9%)	
07/02 07:39:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][350/703]	Step 91166	lr 0.0613	Loss 1.4502 (1.2521)	Prec@(1,5) (63.7%, 90.5%)	
07/02 07:39:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][400/703]	Step 91216	lr 0.0613	Loss 1.3229 (1.2585)	Prec@(1,5) (63.6%, 90.4%)	
07/02 07:39:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][450/703]	Step 91266	lr 0.0613	Loss 1.3541 (1.2623)	Prec@(1,5) (63.6%, 90.3%)	
07/02 07:39:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][500/703]	Step 91316	lr 0.0613	Loss 1.2267 (1.2688)	Prec@(1,5) (63.4%, 90.1%)	
07/02 07:39:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][550/703]	Step 91366	lr 0.0613	Loss 1.5588 (1.2722)	Prec@(1,5) (63.2%, 90.1%)	
07/02 07:39:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][600/703]	Step 91416	lr 0.0613	Loss 1.1610 (1.2786)	Prec@(1,5) (63.1%, 90.0%)	
07/02 07:39:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][650/703]	Step 91466	lr 0.0613	Loss 1.3330 (1.2808)	Prec@(1,5) (63.0%, 90.0%)	
07/02 07:39:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][700/703]	Step 91516	lr 0.0613	Loss 1.6843 (1.2868)	Prec@(1,5) (62.8%, 89.9%)	
07/02 07:39:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [129][703/703]	Step 91519	lr 0.0613	Loss 1.3899 (1.2874)	Prec@(1,5) (62.8%, 89.9%)	
07/02 07:39:46午後 finetuneTeacher_trainer.py:180 [INFO] Train: [129/299] Final Prec@1 62.7911%
07/02 07:39:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [129][50/79]	Step 91520	Loss 1.8850	Prec@(1,5) (50.2%, 79.8%)
07/02 07:39:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [129][78/79]	Step 91520	Loss 1.8692	Prec@(1,5) (51.1%, 80.0%)
07/02 07:39:48午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [129/299] Final Prec@1 51.1400%
07/02 07:39:48午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.1200%
07/02 07:39:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][50/703]	Step 91570	lr 0.06079	Loss 1.5792 (1.2247)	Prec@(1,5) (63.5%, 90.7%)	
07/02 07:39:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][100/703]	Step 91620	lr 0.06079	Loss 1.1383 (1.2020)	Prec@(1,5) (64.6%, 91.2%)	
07/02 07:39:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][150/703]	Step 91670	lr 0.06079	Loss 1.2133 (1.1891)	Prec@(1,5) (65.2%, 91.3%)	
07/02 07:40:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][200/703]	Step 91720	lr 0.06079	Loss 0.9485 (1.1930)	Prec@(1,5) (65.1%, 91.3%)	
07/02 07:40:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][250/703]	Step 91770	lr 0.06079	Loss 1.4064 (1.1953)	Prec@(1,5) (65.1%, 91.2%)	
07/02 07:40:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][300/703]	Step 91820	lr 0.06079	Loss 1.3622 (1.2050)	Prec@(1,5) (65.1%, 91.0%)	
07/02 07:40:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][350/703]	Step 91870	lr 0.06079	Loss 1.3361 (1.2192)	Prec@(1,5) (64.8%, 90.8%)	
07/02 07:40:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][400/703]	Step 91920	lr 0.06079	Loss 1.3161 (1.2299)	Prec@(1,5) (64.5%, 90.5%)	
07/02 07:40:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][450/703]	Step 91970	lr 0.06079	Loss 1.4132 (1.2358)	Prec@(1,5) (64.2%, 90.5%)	
07/02 07:40:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][500/703]	Step 92020	lr 0.06079	Loss 1.2064 (1.2458)	Prec@(1,5) (63.9%, 90.4%)	
07/02 07:40:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][550/703]	Step 92070	lr 0.06079	Loss 1.1794 (1.2524)	Prec@(1,5) (63.7%, 90.3%)	
07/02 07:40:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][600/703]	Step 92120	lr 0.06079	Loss 1.3873 (1.2558)	Prec@(1,5) (63.6%, 90.2%)	
07/02 07:40:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][650/703]	Step 92170	lr 0.06079	Loss 1.3498 (1.2606)	Prec@(1,5) (63.5%, 90.2%)	
07/02 07:40:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][700/703]	Step 92220	lr 0.06079	Loss 1.3013 (1.2670)	Prec@(1,5) (63.4%, 90.0%)	
07/02 07:40:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [130][703/703]	Step 92223	lr 0.06079	Loss 1.2554 (1.2673)	Prec@(1,5) (63.4%, 90.0%)	
07/02 07:40:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [130/299] Final Prec@1 63.3889%
07/02 07:40:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [130][50/79]	Step 92224	Loss 1.9743	Prec@(1,5) (50.1%, 78.6%)
07/02 07:40:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [130][78/79]	Step 92224	Loss 2.0004	Prec@(1,5) (49.4%, 78.5%)
07/02 07:40:35午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [130/299] Final Prec@1 49.4600%
07/02 07:40:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.1200%
07/02 07:40:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][50/703]	Step 92274	lr 0.06028	Loss 1.1553 (1.1970)	Prec@(1,5) (64.3%, 92.0%)	
07/02 07:40:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][100/703]	Step 92324	lr 0.06028	Loss 0.9789 (1.1852)	Prec@(1,5) (65.2%, 91.6%)	
07/02 07:40:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][150/703]	Step 92374	lr 0.06028	Loss 1.2990 (1.1764)	Prec@(1,5) (65.7%, 91.5%)	
07/02 07:40:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][200/703]	Step 92424	lr 0.06028	Loss 1.2952 (1.1960)	Prec@(1,5) (65.4%, 91.2%)	
07/02 07:40:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][250/703]	Step 92474	lr 0.06028	Loss 1.8679 (1.2010)	Prec@(1,5) (65.1%, 91.1%)	
07/02 07:40:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][300/703]	Step 92524	lr 0.06028	Loss 1.0949 (1.2088)	Prec@(1,5) (64.8%, 91.0%)	
07/02 07:40:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][350/703]	Step 92574	lr 0.06028	Loss 1.2189 (1.2113)	Prec@(1,5) (64.7%, 91.0%)	
07/02 07:41:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][400/703]	Step 92624	lr 0.06028	Loss 1.0286 (1.2208)	Prec@(1,5) (64.5%, 90.9%)	
07/02 07:41:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][450/703]	Step 92674	lr 0.06028	Loss 1.0223 (1.2287)	Prec@(1,5) (64.3%, 90.8%)	
07/02 07:41:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][500/703]	Step 92724	lr 0.06028	Loss 1.2706 (1.2350)	Prec@(1,5) (64.0%, 90.7%)	
07/02 07:41:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][550/703]	Step 92774	lr 0.06028	Loss 1.2132 (1.2393)	Prec@(1,5) (63.9%, 90.7%)	
07/02 07:41:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][600/703]	Step 92824	lr 0.06028	Loss 1.0898 (1.2468)	Prec@(1,5) (63.7%, 90.5%)	
07/02 07:41:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][650/703]	Step 92874	lr 0.06028	Loss 1.0523 (1.2536)	Prec@(1,5) (63.5%, 90.4%)	
07/02 07:41:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][700/703]	Step 92924	lr 0.06028	Loss 1.7428 (1.2602)	Prec@(1,5) (63.4%, 90.3%)	
07/02 07:41:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [131][703/703]	Step 92927	lr 0.06028	Loss 1.2190 (1.2614)	Prec@(1,5) (63.4%, 90.3%)	
07/02 07:41:19午後 finetuneTeacher_trainer.py:180 [INFO] Train: [131/299] Final Prec@1 63.3689%
07/02 07:41:20午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [131][50/79]	Step 92928	Loss 1.7767	Prec@(1,5) (53.4%, 81.9%)
07/02 07:41:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [131][78/79]	Step 92928	Loss 1.8044	Prec@(1,5) (52.9%, 81.2%)
07/02 07:41:21午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [131/299] Final Prec@1 52.8000%
07/02 07:41:21午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:41:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][50/703]	Step 92978	lr 0.05978	Loss 1.0864 (1.1814)	Prec@(1,5) (65.2%, 91.8%)	
07/02 07:41:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][100/703]	Step 93028	lr 0.05978	Loss 0.9248 (1.1635)	Prec@(1,5) (65.7%, 91.8%)	
07/02 07:41:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][150/703]	Step 93078	lr 0.05978	Loss 1.4201 (1.1715)	Prec@(1,5) (65.4%, 91.6%)	
07/02 07:41:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][200/703]	Step 93128	lr 0.05978	Loss 1.3211 (1.1923)	Prec@(1,5) (64.8%, 91.4%)	
07/02 07:41:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][250/703]	Step 93178	lr 0.05978	Loss 1.0975 (1.1936)	Prec@(1,5) (64.7%, 91.4%)	
07/02 07:41:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][300/703]	Step 93228	lr 0.05978	Loss 1.1719 (1.2091)	Prec@(1,5) (64.4%, 91.2%)	
07/02 07:41:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][350/703]	Step 93278	lr 0.05978	Loss 1.2123 (1.2148)	Prec@(1,5) (64.4%, 91.1%)	
07/02 07:41:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][400/703]	Step 93328	lr 0.05978	Loss 1.2271 (1.2141)	Prec@(1,5) (64.4%, 91.1%)	
07/02 07:41:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][450/703]	Step 93378	lr 0.05978	Loss 1.3931 (1.2205)	Prec@(1,5) (64.4%, 90.9%)	
07/02 07:41:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][500/703]	Step 93428	lr 0.05978	Loss 1.7606 (1.2306)	Prec@(1,5) (64.1%, 90.7%)	
07/02 07:41:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][550/703]	Step 93478	lr 0.05978	Loss 1.4055 (1.2373)	Prec@(1,5) (63.9%, 90.6%)	
07/02 07:41:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][600/703]	Step 93528	lr 0.05978	Loss 1.1342 (1.2446)	Prec@(1,5) (63.7%, 90.5%)	
07/02 07:42:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][650/703]	Step 93578	lr 0.05978	Loss 1.1962 (1.2489)	Prec@(1,5) (63.5%, 90.4%)	
07/02 07:42:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][700/703]	Step 93628	lr 0.05978	Loss 1.2094 (1.2570)	Prec@(1,5) (63.3%, 90.3%)	
07/02 07:42:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [132][703/703]	Step 93631	lr 0.05978	Loss 1.2443 (1.2569)	Prec@(1,5) (63.3%, 90.3%)	
07/02 07:42:06午後 finetuneTeacher_trainer.py:180 [INFO] Train: [132/299] Final Prec@1 63.3333%
07/02 07:42:07午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [132][50/79]	Step 93632	Loss 1.8523	Prec@(1,5) (51.4%, 80.6%)
07/02 07:42:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [132][78/79]	Step 93632	Loss 1.8744	Prec@(1,5) (50.7%, 80.2%)
07/02 07:42:08午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [132/299] Final Prec@1 50.6800%
07/02 07:42:08午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:42:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][50/703]	Step 93682	lr 0.05927	Loss 1.1917 (1.1755)	Prec@(1,5) (66.2%, 90.9%)	
07/02 07:42:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][100/703]	Step 93732	lr 0.05927	Loss 1.1813 (1.1665)	Prec@(1,5) (66.0%, 91.4%)	
07/02 07:42:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][150/703]	Step 93782	lr 0.05927	Loss 1.5663 (1.1763)	Prec@(1,5) (65.8%, 91.1%)	
07/02 07:42:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][200/703]	Step 93832	lr 0.05927	Loss 1.3383 (1.1903)	Prec@(1,5) (65.4%, 91.0%)	
07/02 07:42:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][250/703]	Step 93882	lr 0.05927	Loss 1.5592 (1.2024)	Prec@(1,5) (65.1%, 90.9%)	
07/02 07:42:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][300/703]	Step 93932	lr 0.05927	Loss 0.8804 (1.2044)	Prec@(1,5) (65.0%, 91.0%)	
07/02 07:42:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][350/703]	Step 93982	lr 0.05927	Loss 1.2550 (1.2102)	Prec@(1,5) (64.7%, 90.9%)	
07/02 07:42:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][400/703]	Step 94032	lr 0.05927	Loss 0.8006 (1.2173)	Prec@(1,5) (64.4%, 90.9%)	
07/02 07:42:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][450/703]	Step 94082	lr 0.05927	Loss 1.3066 (1.2232)	Prec@(1,5) (64.3%, 90.8%)	
07/02 07:42:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][500/703]	Step 94132	lr 0.05927	Loss 1.0281 (1.2248)	Prec@(1,5) (64.3%, 90.8%)	
07/02 07:42:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][550/703]	Step 94182	lr 0.05927	Loss 1.5570 (1.2331)	Prec@(1,5) (64.1%, 90.7%)	
07/02 07:42:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][600/703]	Step 94232	lr 0.05927	Loss 1.0873 (1.2395)	Prec@(1,5) (64.0%, 90.6%)	
07/02 07:42:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][650/703]	Step 94282	lr 0.05927	Loss 1.2057 (1.2441)	Prec@(1,5) (63.9%, 90.6%)	
07/02 07:42:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][700/703]	Step 94332	lr 0.05927	Loss 1.6303 (1.2534)	Prec@(1,5) (63.6%, 90.5%)	
07/02 07:42:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [133][703/703]	Step 94335	lr 0.05927	Loss 1.1530 (1.2535)	Prec@(1,5) (63.6%, 90.5%)	
07/02 07:42:52午後 finetuneTeacher_trainer.py:180 [INFO] Train: [133/299] Final Prec@1 63.5889%
07/02 07:42:53午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [133][50/79]	Step 94336	Loss 1.8932	Prec@(1,5) (50.6%, 80.3%)
07/02 07:42:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [133][78/79]	Step 94336	Loss 1.8907	Prec@(1,5) (50.5%, 80.5%)
07/02 07:42:54午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [133/299] Final Prec@1 50.4800%
07/02 07:42:54午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:42:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][50/703]	Step 94386	lr 0.05876	Loss 1.3883 (1.2176)	Prec@(1,5) (63.5%, 90.3%)	
07/02 07:43:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][100/703]	Step 94436	lr 0.05876	Loss 0.9184 (1.1701)	Prec@(1,5) (65.3%, 91.3%)	
07/02 07:43:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][150/703]	Step 94486	lr 0.05876	Loss 0.9437 (1.1701)	Prec@(1,5) (65.4%, 91.4%)	
07/02 07:43:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][200/703]	Step 94536	lr 0.05876	Loss 1.2408 (1.1727)	Prec@(1,5) (65.5%, 91.3%)	
07/02 07:43:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][250/703]	Step 94586	lr 0.05876	Loss 1.3017 (1.1729)	Prec@(1,5) (65.6%, 91.5%)	
07/02 07:43:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][300/703]	Step 94636	lr 0.05876	Loss 1.0744 (1.1792)	Prec@(1,5) (65.6%, 91.3%)	
07/02 07:43:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][350/703]	Step 94686	lr 0.05876	Loss 1.4438 (1.1917)	Prec@(1,5) (65.2%, 91.2%)	
07/02 07:43:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][400/703]	Step 94736	lr 0.05876	Loss 1.5958 (1.2057)	Prec@(1,5) (64.7%, 90.9%)	
07/02 07:43:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][450/703]	Step 94786	lr 0.05876	Loss 1.7366 (1.2155)	Prec@(1,5) (64.4%, 90.7%)	
07/02 07:43:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][500/703]	Step 94836	lr 0.05876	Loss 1.2738 (1.2242)	Prec@(1,5) (64.3%, 90.6%)	
07/02 07:43:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][550/703]	Step 94886	lr 0.05876	Loss 1.4342 (1.2313)	Prec@(1,5) (64.1%, 90.5%)	
07/02 07:43:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][600/703]	Step 94936	lr 0.05876	Loss 1.0929 (1.2359)	Prec@(1,5) (64.0%, 90.4%)	
07/02 07:43:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][650/703]	Step 94986	lr 0.05876	Loss 1.3109 (1.2391)	Prec@(1,5) (64.0%, 90.4%)	
07/02 07:43:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][700/703]	Step 95036	lr 0.05876	Loss 1.0883 (1.2471)	Prec@(1,5) (63.7%, 90.2%)	
07/02 07:43:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [134][703/703]	Step 95039	lr 0.05876	Loss 1.4925 (1.2477)	Prec@(1,5) (63.7%, 90.2%)	
07/02 07:43:40午後 finetuneTeacher_trainer.py:180 [INFO] Train: [134/299] Final Prec@1 63.7111%
07/02 07:43:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [134][50/79]	Step 95040	Loss 1.8379	Prec@(1,5) (52.1%, 81.4%)
07/02 07:43:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [134][78/79]	Step 95040	Loss 1.8260	Prec@(1,5) (52.0%, 81.6%)
07/02 07:43:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [134/299] Final Prec@1 52.0000%
07/02 07:43:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:43:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][50/703]	Step 95090	lr 0.05824	Loss 1.1403 (1.1192)	Prec@(1,5) (66.7%, 92.8%)	
07/02 07:43:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][100/703]	Step 95140	lr 0.05824	Loss 1.4296 (1.1583)	Prec@(1,5) (65.8%, 92.1%)	
07/02 07:43:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][150/703]	Step 95190	lr 0.05824	Loss 1.2401 (1.1606)	Prec@(1,5) (65.9%, 92.0%)	
07/02 07:43:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][200/703]	Step 95240	lr 0.05824	Loss 0.9334 (1.1728)	Prec@(1,5) (65.7%, 91.7%)	
07/02 07:43:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][250/703]	Step 95290	lr 0.05824	Loss 1.0367 (1.1773)	Prec@(1,5) (65.6%, 91.6%)	
07/02 07:44:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][300/703]	Step 95340	lr 0.05824	Loss 1.1290 (1.1880)	Prec@(1,5) (65.2%, 91.5%)	
07/02 07:44:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][350/703]	Step 95390	lr 0.05824	Loss 1.2797 (1.1977)	Prec@(1,5) (64.9%, 91.3%)	
07/02 07:44:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][400/703]	Step 95440	lr 0.05824	Loss 1.4563 (1.2076)	Prec@(1,5) (64.7%, 91.2%)	
07/02 07:44:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][450/703]	Step 95490	lr 0.05824	Loss 1.2818 (1.2135)	Prec@(1,5) (64.6%, 91.0%)	
07/02 07:44:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][500/703]	Step 95540	lr 0.05824	Loss 1.1816 (1.2238)	Prec@(1,5) (64.2%, 90.9%)	
07/02 07:44:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][550/703]	Step 95590	lr 0.05824	Loss 1.1972 (1.2299)	Prec@(1,5) (64.1%, 90.8%)	
07/02 07:44:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][600/703]	Step 95640	lr 0.05824	Loss 0.7558 (1.2359)	Prec@(1,5) (64.0%, 90.7%)	
07/02 07:44:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][650/703]	Step 95690	lr 0.05824	Loss 0.8863 (1.2440)	Prec@(1,5) (63.9%, 90.6%)	
07/02 07:44:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][700/703]	Step 95740	lr 0.05824	Loss 1.2051 (1.2485)	Prec@(1,5) (63.7%, 90.6%)	
07/02 07:44:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [135][703/703]	Step 95743	lr 0.05824	Loss 1.5566 (1.2495)	Prec@(1,5) (63.7%, 90.5%)	
07/02 07:44:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [135/299] Final Prec@1 63.7067%
07/02 07:44:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [135][50/79]	Step 95744	Loss 1.9049	Prec@(1,5) (50.4%, 79.6%)
07/02 07:44:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [135][78/79]	Step 95744	Loss 1.8885	Prec@(1,5) (50.8%, 80.2%)
07/02 07:44:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [135/299] Final Prec@1 50.8200%
07/02 07:44:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:44:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][50/703]	Step 95794	lr 0.05773	Loss 0.8519 (1.1524)	Prec@(1,5) (66.2%, 91.9%)	
07/02 07:44:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][100/703]	Step 95844	lr 0.05773	Loss 1.1618 (1.1360)	Prec@(1,5) (66.6%, 91.8%)	
07/02 07:44:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][150/703]	Step 95894	lr 0.05773	Loss 1.0048 (1.1423)	Prec@(1,5) (66.7%, 91.9%)	
07/02 07:44:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][200/703]	Step 95944	lr 0.05773	Loss 1.1451 (1.1528)	Prec@(1,5) (66.2%, 91.8%)	
07/02 07:44:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][250/703]	Step 95994	lr 0.05773	Loss 1.4898 (1.1605)	Prec@(1,5) (66.2%, 91.7%)	
07/02 07:44:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][300/703]	Step 96044	lr 0.05773	Loss 1.3153 (1.1777)	Prec@(1,5) (65.6%, 91.4%)	
07/02 07:44:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][350/703]	Step 96094	lr 0.05773	Loss 1.2240 (1.1846)	Prec@(1,5) (65.5%, 91.3%)	
07/02 07:44:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][400/703]	Step 96144	lr 0.05773	Loss 1.2870 (1.1947)	Prec@(1,5) (65.3%, 91.2%)	
07/02 07:44:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][450/703]	Step 96194	lr 0.05773	Loss 1.1128 (1.1992)	Prec@(1,5) (65.2%, 91.1%)	
07/02 07:45:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][500/703]	Step 96244	lr 0.05773	Loss 1.4062 (1.2043)	Prec@(1,5) (65.0%, 91.0%)	
07/02 07:45:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][550/703]	Step 96294	lr 0.05773	Loss 1.4848 (1.2136)	Prec@(1,5) (64.7%, 90.9%)	
07/02 07:45:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][600/703]	Step 96344	lr 0.05773	Loss 1.1963 (1.2183)	Prec@(1,5) (64.6%, 90.9%)	
07/02 07:45:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][650/703]	Step 96394	lr 0.05773	Loss 1.2652 (1.2279)	Prec@(1,5) (64.4%, 90.7%)	
07/02 07:45:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][700/703]	Step 96444	lr 0.05773	Loss 1.0408 (1.2355)	Prec@(1,5) (64.1%, 90.6%)	
07/02 07:45:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [136][703/703]	Step 96447	lr 0.05773	Loss 1.1708 (1.2365)	Prec@(1,5) (64.1%, 90.6%)	
07/02 07:45:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [136/299] Final Prec@1 64.1067%
07/02 07:45:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [136][50/79]	Step 96448	Loss 1.8193	Prec@(1,5) (52.7%, 81.4%)
07/02 07:45:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [136][78/79]	Step 96448	Loss 1.8097	Prec@(1,5) (52.5%, 81.9%)
07/02 07:45:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [136/299] Final Prec@1 52.4800%
07/02 07:45:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:45:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][50/703]	Step 96498	lr 0.05722	Loss 1.0595 (1.1314)	Prec@(1,5) (67.0%, 92.3%)	
07/02 07:45:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][100/703]	Step 96548	lr 0.05722	Loss 1.1111 (1.1281)	Prec@(1,5) (67.0%, 92.0%)	
07/02 07:45:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][150/703]	Step 96598	lr 0.05722	Loss 1.0889 (1.1250)	Prec@(1,5) (67.1%, 92.2%)	
07/02 07:45:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][200/703]	Step 96648	lr 0.05722	Loss 1.2513 (1.1462)	Prec@(1,5) (66.5%, 91.9%)	
07/02 07:45:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][250/703]	Step 96698	lr 0.05722	Loss 1.6174 (1.1630)	Prec@(1,5) (65.9%, 91.6%)	
07/02 07:45:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][300/703]	Step 96748	lr 0.05722	Loss 1.1615 (1.1774)	Prec@(1,5) (65.4%, 91.4%)	
07/02 07:45:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][350/703]	Step 96798	lr 0.05722	Loss 1.2309 (1.1860)	Prec@(1,5) (65.0%, 91.3%)	
07/02 07:45:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][400/703]	Step 96848	lr 0.05722	Loss 1.2174 (1.1936)	Prec@(1,5) (64.8%, 91.2%)	
07/02 07:45:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][450/703]	Step 96898	lr 0.05722	Loss 1.3672 (1.1984)	Prec@(1,5) (64.9%, 91.2%)	
07/02 07:45:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][500/703]	Step 96948	lr 0.05722	Loss 1.2868 (1.2009)	Prec@(1,5) (64.8%, 91.1%)	
07/02 07:45:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][550/703]	Step 96998	lr 0.05722	Loss 1.5349 (1.2039)	Prec@(1,5) (64.7%, 91.1%)	
07/02 07:45:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][600/703]	Step 97048	lr 0.05722	Loss 0.9561 (1.2118)	Prec@(1,5) (64.4%, 91.0%)	
07/02 07:45:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][650/703]	Step 97098	lr 0.05722	Loss 1.4612 (1.2199)	Prec@(1,5) (64.3%, 90.8%)	
07/02 07:45:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][700/703]	Step 97148	lr 0.05722	Loss 1.4082 (1.2246)	Prec@(1,5) (64.2%, 90.8%)	
07/02 07:45:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [137][703/703]	Step 97151	lr 0.05722	Loss 1.0620 (1.2251)	Prec@(1,5) (64.2%, 90.7%)	
07/02 07:45:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [137/299] Final Prec@1 64.1822%
07/02 07:46:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [137][50/79]	Step 97152	Loss 1.8211	Prec@(1,5) (52.4%, 81.7%)
07/02 07:46:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [137][78/79]	Step 97152	Loss 1.8250	Prec@(1,5) (52.4%, 81.6%)
07/02 07:46:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [137/299] Final Prec@1 52.4600%
07/02 07:46:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 52.8000%
07/02 07:46:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][50/703]	Step 97202	lr 0.0567	Loss 0.7246 (1.1950)	Prec@(1,5) (65.2%, 91.7%)	
07/02 07:46:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][100/703]	Step 97252	lr 0.0567	Loss 0.8650 (1.1429)	Prec@(1,5) (66.2%, 92.0%)	
07/02 07:46:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][150/703]	Step 97302	lr 0.0567	Loss 1.0312 (1.1400)	Prec@(1,5) (66.1%, 92.0%)	
07/02 07:46:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][200/703]	Step 97352	lr 0.0567	Loss 1.1902 (1.1471)	Prec@(1,5) (66.2%, 91.9%)	
07/02 07:46:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][250/703]	Step 97402	lr 0.0567	Loss 1.3152 (1.1578)	Prec@(1,5) (65.9%, 91.7%)	
07/02 07:46:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][300/703]	Step 97452	lr 0.0567	Loss 1.0597 (1.1618)	Prec@(1,5) (65.8%, 91.6%)	
07/02 07:46:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][350/703]	Step 97502	lr 0.0567	Loss 1.2966 (1.1727)	Prec@(1,5) (65.5%, 91.4%)	
07/02 07:46:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][400/703]	Step 97552	lr 0.0567	Loss 1.4016 (1.1794)	Prec@(1,5) (65.3%, 91.4%)	
07/02 07:46:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][450/703]	Step 97602	lr 0.0567	Loss 1.4682 (1.1926)	Prec@(1,5) (65.0%, 91.2%)	
07/02 07:46:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][500/703]	Step 97652	lr 0.0567	Loss 1.5279 (1.1953)	Prec@(1,5) (65.0%, 91.2%)	
07/02 07:46:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][550/703]	Step 97702	lr 0.0567	Loss 1.5576 (1.1995)	Prec@(1,5) (64.9%, 91.0%)	
07/02 07:46:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][600/703]	Step 97752	lr 0.0567	Loss 1.1077 (1.2031)	Prec@(1,5) (64.8%, 91.0%)	
07/02 07:46:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][650/703]	Step 97802	lr 0.0567	Loss 1.3093 (1.2108)	Prec@(1,5) (64.6%, 90.9%)	
07/02 07:46:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][700/703]	Step 97852	lr 0.0567	Loss 1.1154 (1.2149)	Prec@(1,5) (64.4%, 90.8%)	
07/02 07:46:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [138][703/703]	Step 97855	lr 0.0567	Loss 1.1601 (1.2147)	Prec@(1,5) (64.4%, 90.8%)	
07/02 07:46:47午後 finetuneTeacher_trainer.py:180 [INFO] Train: [138/299] Final Prec@1 64.4044%
07/02 07:46:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [138][50/79]	Step 97856	Loss 1.7843	Prec@(1,5) (54.1%, 81.6%)
07/02 07:46:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [138][78/79]	Step 97856	Loss 1.7884	Prec@(1,5) (53.4%, 81.7%)
07/02 07:46:49午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [138/299] Final Prec@1 53.4400%
07/02 07:46:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 53.4400%
07/02 07:46:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][50/703]	Step 97906	lr 0.05619	Loss 1.2017 (1.1247)	Prec@(1,5) (66.3%, 91.8%)	
07/02 07:46:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][100/703]	Step 97956	lr 0.05619	Loss 0.8622 (1.1138)	Prec@(1,5) (66.8%, 92.1%)	
07/02 07:46:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][150/703]	Step 98006	lr 0.05619	Loss 1.2713 (1.1171)	Prec@(1,5) (66.7%, 92.1%)	
07/02 07:47:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][200/703]	Step 98056	lr 0.05619	Loss 1.1245 (1.1247)	Prec@(1,5) (66.6%, 92.0%)	
07/02 07:47:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][250/703]	Step 98106	lr 0.05619	Loss 1.3908 (1.1376)	Prec@(1,5) (66.3%, 91.9%)	
07/02 07:47:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][300/703]	Step 98156	lr 0.05619	Loss 1.3801 (1.1436)	Prec@(1,5) (66.1%, 91.9%)	
07/02 07:47:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][350/703]	Step 98206	lr 0.05619	Loss 1.3119 (1.1588)	Prec@(1,5) (65.8%, 91.6%)	
07/02 07:47:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][400/703]	Step 98256	lr 0.05619	Loss 1.2901 (1.1690)	Prec@(1,5) (65.6%, 91.5%)	
07/02 07:47:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][450/703]	Step 98306	lr 0.05619	Loss 0.9179 (1.1757)	Prec@(1,5) (65.4%, 91.4%)	
07/02 07:47:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][500/703]	Step 98356	lr 0.05619	Loss 1.2156 (1.1826)	Prec@(1,5) (65.2%, 91.3%)	
07/02 07:47:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][550/703]	Step 98406	lr 0.05619	Loss 0.9440 (1.1869)	Prec@(1,5) (65.1%, 91.2%)	
07/02 07:47:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][600/703]	Step 98456	lr 0.05619	Loss 1.3451 (1.1944)	Prec@(1,5) (64.9%, 91.1%)	
07/02 07:47:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][650/703]	Step 98506	lr 0.05619	Loss 1.3730 (1.1990)	Prec@(1,5) (64.8%, 91.1%)	
07/02 07:47:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][700/703]	Step 98556	lr 0.05619	Loss 1.3856 (1.2028)	Prec@(1,5) (64.7%, 91.1%)	
07/02 07:47:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [139][703/703]	Step 98559	lr 0.05619	Loss 1.3613 (1.2036)	Prec@(1,5) (64.7%, 91.0%)	
07/02 07:47:34午後 finetuneTeacher_trainer.py:180 [INFO] Train: [139/299] Final Prec@1 64.7378%
07/02 07:47:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [139][50/79]	Step 98560	Loss 1.9127	Prec@(1,5) (50.9%, 80.2%)
07/02 07:47:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [139][78/79]	Step 98560	Loss 1.8816	Prec@(1,5) (51.1%, 80.9%)
07/02 07:47:36午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [139/299] Final Prec@1 51.0800%
07/02 07:47:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 53.4400%
07/02 07:47:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][50/703]	Step 98610	lr 0.05567	Loss 1.0665 (1.1243)	Prec@(1,5) (66.5%, 93.0%)	
07/02 07:47:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][100/703]	Step 98660	lr 0.05567	Loss 1.0327 (1.1102)	Prec@(1,5) (67.4%, 92.8%)	
07/02 07:47:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][150/703]	Step 98710	lr 0.05567	Loss 1.3613 (1.1117)	Prec@(1,5) (67.4%, 92.5%)	
07/02 07:47:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][200/703]	Step 98760	lr 0.05567	Loss 1.3909 (1.1167)	Prec@(1,5) (67.0%, 92.3%)	
07/02 07:47:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][250/703]	Step 98810	lr 0.05567	Loss 1.4546 (1.1377)	Prec@(1,5) (66.5%, 91.9%)	
07/02 07:47:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][300/703]	Step 98860	lr 0.05567	Loss 1.2705 (1.1495)	Prec@(1,5) (66.2%, 91.8%)	
07/02 07:47:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][350/703]	Step 98910	lr 0.05567	Loss 1.3640 (1.1560)	Prec@(1,5) (66.0%, 91.8%)	
07/02 07:48:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][400/703]	Step 98960	lr 0.05567	Loss 0.9750 (1.1596)	Prec@(1,5) (66.0%, 91.6%)	
07/02 07:48:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][450/703]	Step 99010	lr 0.05567	Loss 1.2895 (1.1673)	Prec@(1,5) (65.7%, 91.5%)	
07/02 07:48:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][500/703]	Step 99060	lr 0.05567	Loss 1.3253 (1.1837)	Prec@(1,5) (65.3%, 91.3%)	
07/02 07:48:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][550/703]	Step 99110	lr 0.05567	Loss 1.1733 (1.1890)	Prec@(1,5) (65.2%, 91.2%)	
07/02 07:48:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][600/703]	Step 99160	lr 0.05567	Loss 1.2451 (1.1946)	Prec@(1,5) (65.0%, 91.2%)	
07/02 07:48:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][650/703]	Step 99210	lr 0.05567	Loss 1.3613 (1.2024)	Prec@(1,5) (64.8%, 91.1%)	
07/02 07:48:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][700/703]	Step 99260	lr 0.05567	Loss 1.2895 (1.2074)	Prec@(1,5) (64.7%, 90.9%)	
07/02 07:48:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [140][703/703]	Step 99263	lr 0.05567	Loss 1.1387 (1.2066)	Prec@(1,5) (64.7%, 91.0%)	
07/02 07:48:21午後 finetuneTeacher_trainer.py:180 [INFO] Train: [140/299] Final Prec@1 64.7400%
07/02 07:48:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [140][50/79]	Step 99264	Loss 1.7795	Prec@(1,5) (52.4%, 82.3%)
07/02 07:48:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [140][78/79]	Step 99264	Loss 1.8003	Prec@(1,5) (52.4%, 82.2%)
07/02 07:48:23午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [140/299] Final Prec@1 52.4600%
07/02 07:48:23午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 53.4400%
07/02 07:48:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][50/703]	Step 99314	lr 0.05516	Loss 1.1659 (1.0946)	Prec@(1,5) (67.3%, 92.9%)	
07/02 07:48:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][100/703]	Step 99364	lr 0.05516	Loss 1.0541 (1.0723)	Prec@(1,5) (68.2%, 93.2%)	
07/02 07:48:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][150/703]	Step 99414	lr 0.05516	Loss 1.3631 (1.0765)	Prec@(1,5) (68.1%, 92.9%)	
07/02 07:48:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][200/703]	Step 99464	lr 0.05516	Loss 1.2708 (1.1012)	Prec@(1,5) (67.4%, 92.5%)	
07/02 07:48:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][250/703]	Step 99514	lr 0.05516	Loss 0.9671 (1.1154)	Prec@(1,5) (67.1%, 92.4%)	
07/02 07:48:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][300/703]	Step 99564	lr 0.05516	Loss 1.0254 (1.1274)	Prec@(1,5) (66.9%, 92.2%)	
07/02 07:48:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][350/703]	Step 99614	lr 0.05516	Loss 1.1193 (1.1347)	Prec@(1,5) (66.7%, 92.1%)	
07/02 07:48:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][400/703]	Step 99664	lr 0.05516	Loss 1.4075 (1.1409)	Prec@(1,5) (66.6%, 92.0%)	
07/02 07:48:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][450/703]	Step 99714	lr 0.05516	Loss 1.6591 (1.1520)	Prec@(1,5) (66.2%, 91.8%)	
07/02 07:48:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][500/703]	Step 99764	lr 0.05516	Loss 1.0453 (1.1629)	Prec@(1,5) (65.9%, 91.7%)	
07/02 07:48:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][550/703]	Step 99814	lr 0.05516	Loss 1.5878 (1.1740)	Prec@(1,5) (65.6%, 91.5%)	
07/02 07:49:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][600/703]	Step 99864	lr 0.05516	Loss 0.9738 (1.1829)	Prec@(1,5) (65.3%, 91.4%)	
07/02 07:49:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][650/703]	Step 99914	lr 0.05516	Loss 1.3220 (1.1874)	Prec@(1,5) (65.3%, 91.3%)	
07/02 07:49:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][700/703]	Step 99964	lr 0.05516	Loss 1.3561 (1.1883)	Prec@(1,5) (65.2%, 91.3%)	
07/02 07:49:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [141][703/703]	Step 99967	lr 0.05516	Loss 1.0411 (1.1886)	Prec@(1,5) (65.2%, 91.3%)	
07/02 07:49:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [141/299] Final Prec@1 65.2044%
07/02 07:49:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [141][50/79]	Step 99968	Loss 1.7369	Prec@(1,5) (55.4%, 82.0%)
07/02 07:49:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [141][78/79]	Step 99968	Loss 1.7500	Prec@(1,5) (54.9%, 82.0%)
07/02 07:49:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [141/299] Final Prec@1 54.9400%
07/02 07:49:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:49:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][50/703]	Step 100018	lr 0.05464	Loss 0.9333 (1.1083)	Prec@(1,5) (68.3%, 92.2%)	
07/02 07:49:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][100/703]	Step 100068	lr 0.05464	Loss 0.8356 (1.0946)	Prec@(1,5) (68.4%, 92.2%)	
07/02 07:49:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][150/703]	Step 100118	lr 0.05464	Loss 0.9432 (1.0980)	Prec@(1,5) (68.3%, 92.4%)	
07/02 07:49:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][200/703]	Step 100168	lr 0.05464	Loss 1.4162 (1.0969)	Prec@(1,5) (68.2%, 92.4%)	
07/02 07:49:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][250/703]	Step 100218	lr 0.05464	Loss 1.0104 (1.0990)	Prec@(1,5) (68.0%, 92.4%)	
07/02 07:49:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][300/703]	Step 100268	lr 0.05464	Loss 1.2571 (1.1131)	Prec@(1,5) (67.7%, 92.3%)	
07/02 07:49:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][350/703]	Step 100318	lr 0.05464	Loss 1.5688 (1.1273)	Prec@(1,5) (67.2%, 92.1%)	
07/02 07:49:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][400/703]	Step 100368	lr 0.05464	Loss 0.9676 (1.1406)	Prec@(1,5) (66.8%, 91.9%)	
07/02 07:49:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][450/703]	Step 100418	lr 0.05464	Loss 1.2655 (1.1459)	Prec@(1,5) (66.6%, 91.8%)	
07/02 07:49:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][500/703]	Step 100468	lr 0.05464	Loss 1.0540 (1.1487)	Prec@(1,5) (66.5%, 91.8%)	
07/02 07:49:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][550/703]	Step 100518	lr 0.05464	Loss 1.0750 (1.1562)	Prec@(1,5) (66.3%, 91.7%)	
07/02 07:49:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][600/703]	Step 100568	lr 0.05464	Loss 1.0627 (1.1672)	Prec@(1,5) (65.9%, 91.6%)	
07/02 07:49:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][650/703]	Step 100618	lr 0.05464	Loss 1.4021 (1.1713)	Prec@(1,5) (65.8%, 91.5%)	
07/02 07:49:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][700/703]	Step 100668	lr 0.05464	Loss 1.4496 (1.1787)	Prec@(1,5) (65.6%, 91.3%)	
07/02 07:49:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [142][703/703]	Step 100671	lr 0.05464	Loss 1.2843 (1.1790)	Prec@(1,5) (65.6%, 91.3%)	
07/02 07:49:52午後 finetuneTeacher_trainer.py:180 [INFO] Train: [142/299] Final Prec@1 65.6178%
07/02 07:49:53午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [142][50/79]	Step 100672	Loss 1.8794	Prec@(1,5) (52.5%, 79.6%)
07/02 07:49:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [142][78/79]	Step 100672	Loss 1.9247	Prec@(1,5) (51.7%, 79.4%)
07/02 07:49:54午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [142/299] Final Prec@1 51.7000%
07/02 07:49:54午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:49:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][50/703]	Step 100722	lr 0.05413	Loss 1.0909 (1.0805)	Prec@(1,5) (67.7%, 92.8%)	
07/02 07:50:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][100/703]	Step 100772	lr 0.05413	Loss 1.0218 (1.0515)	Prec@(1,5) (68.5%, 93.1%)	
07/02 07:50:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][150/703]	Step 100822	lr 0.05413	Loss 0.8504 (1.0712)	Prec@(1,5) (68.1%, 92.8%)	
07/02 07:50:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][200/703]	Step 100872	lr 0.05413	Loss 1.0253 (1.0999)	Prec@(1,5) (67.4%, 92.3%)	
07/02 07:50:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][250/703]	Step 100922	lr 0.05413	Loss 1.0640 (1.1137)	Prec@(1,5) (67.0%, 92.0%)	
07/02 07:50:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][300/703]	Step 100972	lr 0.05413	Loss 1.0258 (1.1200)	Prec@(1,5) (66.9%, 92.0%)	
07/02 07:50:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][350/703]	Step 101022	lr 0.05413	Loss 1.0272 (1.1278)	Prec@(1,5) (66.7%, 92.0%)	
07/02 07:50:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][400/703]	Step 101072	lr 0.05413	Loss 1.1100 (1.1383)	Prec@(1,5) (66.5%, 91.8%)	
07/02 07:50:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][450/703]	Step 101122	lr 0.05413	Loss 1.1709 (1.1476)	Prec@(1,5) (66.2%, 91.7%)	
07/02 07:50:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][500/703]	Step 101172	lr 0.05413	Loss 1.0408 (1.1558)	Prec@(1,5) (66.0%, 91.6%)	
07/02 07:50:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][550/703]	Step 101222	lr 0.05413	Loss 1.6104 (1.1605)	Prec@(1,5) (65.8%, 91.5%)	
07/02 07:50:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][600/703]	Step 101272	lr 0.05413	Loss 1.6339 (1.1696)	Prec@(1,5) (65.7%, 91.4%)	
07/02 07:50:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][650/703]	Step 101322	lr 0.05413	Loss 1.3864 (1.1726)	Prec@(1,5) (65.6%, 91.3%)	
07/02 07:50:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][700/703]	Step 101372	lr 0.05413	Loss 1.1581 (1.1742)	Prec@(1,5) (65.6%, 91.3%)	
07/02 07:50:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [143][703/703]	Step 101375	lr 0.05413	Loss 1.2050 (1.1741)	Prec@(1,5) (65.6%, 91.3%)	
07/02 07:50:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [143/299] Final Prec@1 65.6044%
07/02 07:50:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [143][50/79]	Step 101376	Loss 1.8112	Prec@(1,5) (52.9%, 82.4%)
07/02 07:50:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [143][78/79]	Step 101376	Loss 1.8160	Prec@(1,5) (52.9%, 82.1%)
07/02 07:50:41午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [143/299] Final Prec@1 52.9600%
07/02 07:50:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:50:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][50/703]	Step 101426	lr 0.05361	Loss 1.2263 (1.0502)	Prec@(1,5) (68.2%, 93.7%)	
07/02 07:50:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][100/703]	Step 101476	lr 0.05361	Loss 0.8553 (1.0534)	Prec@(1,5) (68.6%, 93.4%)	
07/02 07:50:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][150/703]	Step 101526	lr 0.05361	Loss 1.0380 (1.0687)	Prec@(1,5) (68.3%, 93.2%)	
07/02 07:50:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][200/703]	Step 101576	lr 0.05361	Loss 1.2951 (1.0708)	Prec@(1,5) (68.3%, 93.2%)	
07/02 07:50:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][250/703]	Step 101626	lr 0.05361	Loss 0.8183 (1.0780)	Prec@(1,5) (68.1%, 93.0%)	
07/02 07:51:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][300/703]	Step 101676	lr 0.05361	Loss 1.2439 (1.0910)	Prec@(1,5) (67.6%, 93.0%)	
07/02 07:51:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][350/703]	Step 101726	lr 0.05361	Loss 1.1061 (1.1043)	Prec@(1,5) (67.3%, 92.7%)	
07/02 07:51:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][400/703]	Step 101776	lr 0.05361	Loss 1.0800 (1.1189)	Prec@(1,5) (66.8%, 92.5%)	
07/02 07:51:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][450/703]	Step 101826	lr 0.05361	Loss 1.1672 (1.1237)	Prec@(1,5) (66.8%, 92.4%)	
07/02 07:51:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][500/703]	Step 101876	lr 0.05361	Loss 1.4829 (1.1298)	Prec@(1,5) (66.6%, 92.3%)	
07/02 07:51:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][550/703]	Step 101926	lr 0.05361	Loss 1.0592 (1.1428)	Prec@(1,5) (66.3%, 92.1%)	
07/02 07:51:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][600/703]	Step 101976	lr 0.05361	Loss 1.2777 (1.1545)	Prec@(1,5) (65.9%, 91.9%)	
07/02 07:51:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][650/703]	Step 102026	lr 0.05361	Loss 1.5412 (1.1614)	Prec@(1,5) (65.8%, 91.8%)	
07/02 07:51:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][700/703]	Step 102076	lr 0.05361	Loss 1.5709 (1.1641)	Prec@(1,5) (65.7%, 91.8%)	
07/02 07:51:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [144][703/703]	Step 102079	lr 0.05361	Loss 1.3647 (1.1638)	Prec@(1,5) (65.8%, 91.8%)	
07/02 07:51:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [144/299] Final Prec@1 65.7667%
07/02 07:51:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [144][50/79]	Step 102080	Loss 1.7509	Prec@(1,5) (53.2%, 82.2%)
07/02 07:51:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [144][78/79]	Step 102080	Loss 1.7731	Prec@(1,5) (53.0%, 82.1%)
07/02 07:51:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [144/299] Final Prec@1 52.9600%
07/02 07:51:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:51:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][50/703]	Step 102130	lr 0.05309	Loss 0.9683 (1.0700)	Prec@(1,5) (68.5%, 93.4%)	
07/02 07:51:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][100/703]	Step 102180	lr 0.05309	Loss 1.0107 (1.0655)	Prec@(1,5) (68.4%, 93.5%)	
07/02 07:51:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][150/703]	Step 102230	lr 0.05309	Loss 0.9522 (1.0618)	Prec@(1,5) (68.3%, 93.2%)	
07/02 07:51:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][200/703]	Step 102280	lr 0.05309	Loss 1.0435 (1.0811)	Prec@(1,5) (67.8%, 93.0%)	
07/02 07:51:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][250/703]	Step 102330	lr 0.05309	Loss 1.1827 (1.0924)	Prec@(1,5) (67.5%, 92.8%)	
07/02 07:51:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][300/703]	Step 102380	lr 0.05309	Loss 1.0997 (1.1069)	Prec@(1,5) (67.1%, 92.6%)	
07/02 07:51:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][350/703]	Step 102430	lr 0.05309	Loss 1.4459 (1.1170)	Prec@(1,5) (66.9%, 92.4%)	
07/02 07:51:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][400/703]	Step 102480	lr 0.05309	Loss 1.5211 (1.1229)	Prec@(1,5) (66.7%, 92.4%)	
07/02 07:51:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][450/703]	Step 102530	lr 0.05309	Loss 1.0655 (1.1299)	Prec@(1,5) (66.6%, 92.3%)	
07/02 07:52:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][500/703]	Step 102580	lr 0.05309	Loss 1.4703 (1.1392)	Prec@(1,5) (66.5%, 92.1%)	
07/02 07:52:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][550/703]	Step 102630	lr 0.05309	Loss 1.4154 (1.1437)	Prec@(1,5) (66.3%, 92.1%)	
07/02 07:52:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][600/703]	Step 102680	lr 0.05309	Loss 1.3345 (1.1489)	Prec@(1,5) (66.2%, 92.0%)	
07/02 07:52:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][650/703]	Step 102730	lr 0.05309	Loss 1.0730 (1.1540)	Prec@(1,5) (66.1%, 91.9%)	
07/02 07:52:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][700/703]	Step 102780	lr 0.05309	Loss 1.1021 (1.1587)	Prec@(1,5) (65.9%, 91.8%)	
07/02 07:52:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [145][703/703]	Step 102783	lr 0.05309	Loss 1.0276 (1.1589)	Prec@(1,5) (65.9%, 91.8%)	
07/02 07:52:13午後 finetuneTeacher_trainer.py:180 [INFO] Train: [145/299] Final Prec@1 65.8911%
07/02 07:52:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [145][50/79]	Step 102784	Loss 1.7276	Prec@(1,5) (53.0%, 83.5%)
07/02 07:52:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [145][78/79]	Step 102784	Loss 1.7413	Prec@(1,5) (53.0%, 83.0%)
07/02 07:52:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [145/299] Final Prec@1 53.0200%
07/02 07:52:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:52:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][50/703]	Step 102834	lr 0.05257	Loss 1.0282 (1.0735)	Prec@(1,5) (69.0%, 92.7%)	
07/02 07:52:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][100/703]	Step 102884	lr 0.05257	Loss 1.0550 (1.0611)	Prec@(1,5) (69.1%, 92.5%)	
07/02 07:52:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][150/703]	Step 102934	lr 0.05257	Loss 1.1528 (1.0723)	Prec@(1,5) (68.6%, 92.7%)	
07/02 07:52:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][200/703]	Step 102984	lr 0.05257	Loss 1.0616 (1.0774)	Prec@(1,5) (68.4%, 92.8%)	
07/02 07:52:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][250/703]	Step 103034	lr 0.05257	Loss 1.2620 (1.0962)	Prec@(1,5) (67.8%, 92.6%)	
07/02 07:52:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][300/703]	Step 103084	lr 0.05257	Loss 0.9091 (1.0971)	Prec@(1,5) (67.7%, 92.6%)	
07/02 07:52:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][350/703]	Step 103134	lr 0.05257	Loss 1.4442 (1.1103)	Prec@(1,5) (67.2%, 92.4%)	
07/02 07:52:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][400/703]	Step 103184	lr 0.05257	Loss 1.3773 (1.1223)	Prec@(1,5) (67.0%, 92.3%)	
07/02 07:52:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][450/703]	Step 103234	lr 0.05257	Loss 0.9825 (1.1233)	Prec@(1,5) (66.9%, 92.3%)	
07/02 07:52:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][500/703]	Step 103284	lr 0.05257	Loss 1.3410 (1.1309)	Prec@(1,5) (66.8%, 92.2%)	
07/02 07:52:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][550/703]	Step 103334	lr 0.05257	Loss 1.2048 (1.1416)	Prec@(1,5) (66.4%, 92.1%)	
07/02 07:52:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][600/703]	Step 103384	lr 0.05257	Loss 1.2079 (1.1439)	Prec@(1,5) (66.3%, 92.1%)	
07/02 07:52:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][650/703]	Step 103434	lr 0.05257	Loss 1.0927 (1.1470)	Prec@(1,5) (66.2%, 92.1%)	
07/02 07:52:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][700/703]	Step 103484	lr 0.05257	Loss 1.1525 (1.1548)	Prec@(1,5) (66.0%, 92.0%)	
07/02 07:52:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [146][703/703]	Step 103487	lr 0.05257	Loss 1.3519 (1.1554)	Prec@(1,5) (66.0%, 92.0%)	
07/02 07:52:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [146/299] Final Prec@1 65.9822%
07/02 07:53:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [146][50/79]	Step 103488	Loss 1.9714	Prec@(1,5) (51.1%, 80.0%)
07/02 07:53:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [146][78/79]	Step 103488	Loss 2.0012	Prec@(1,5) (50.5%, 79.3%)
07/02 07:53:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [146/299] Final Prec@1 50.5000%
07/02 07:53:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:53:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][50/703]	Step 103538	lr 0.05205	Loss 0.8881 (1.0547)	Prec@(1,5) (67.9%, 93.1%)	
07/02 07:53:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][100/703]	Step 103588	lr 0.05205	Loss 0.9421 (1.0573)	Prec@(1,5) (68.3%, 93.5%)	
07/02 07:53:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][150/703]	Step 103638	lr 0.05205	Loss 0.7374 (1.0528)	Prec@(1,5) (68.8%, 93.3%)	
07/02 07:53:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][200/703]	Step 103688	lr 0.05205	Loss 1.0547 (1.0698)	Prec@(1,5) (68.5%, 93.0%)	
07/02 07:53:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][250/703]	Step 103738	lr 0.05205	Loss 1.1751 (1.0843)	Prec@(1,5) (68.0%, 92.8%)	
07/02 07:53:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][300/703]	Step 103788	lr 0.05205	Loss 1.0977 (1.0960)	Prec@(1,5) (67.6%, 92.8%)	
07/02 07:53:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][350/703]	Step 103838	lr 0.05205	Loss 1.1901 (1.0977)	Prec@(1,5) (67.5%, 92.7%)	
07/02 07:53:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][400/703]	Step 103888	lr 0.05205	Loss 1.1897 (1.1079)	Prec@(1,5) (67.3%, 92.5%)	
07/02 07:53:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][450/703]	Step 103938	lr 0.05205	Loss 1.4071 (1.1166)	Prec@(1,5) (67.2%, 92.4%)	
07/02 07:53:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][500/703]	Step 103988	lr 0.05205	Loss 1.1963 (1.1235)	Prec@(1,5) (66.9%, 92.3%)	
07/02 07:53:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][550/703]	Step 104038	lr 0.05205	Loss 1.1612 (1.1293)	Prec@(1,5) (66.7%, 92.2%)	
07/02 07:53:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][600/703]	Step 104088	lr 0.05205	Loss 1.2413 (1.1357)	Prec@(1,5) (66.4%, 92.1%)	
07/02 07:53:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][650/703]	Step 104138	lr 0.05205	Loss 1.2312 (1.1414)	Prec@(1,5) (66.3%, 92.0%)	
07/02 07:53:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][700/703]	Step 104188	lr 0.05205	Loss 1.3150 (1.1420)	Prec@(1,5) (66.2%, 92.0%)	
07/02 07:53:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [147][703/703]	Step 104191	lr 0.05205	Loss 1.1317 (1.1425)	Prec@(1,5) (66.2%, 92.0%)	
07/02 07:53:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [147/299] Final Prec@1 66.2222%
07/02 07:53:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [147][50/79]	Step 104192	Loss 1.8123	Prec@(1,5) (53.2%, 81.8%)
07/02 07:53:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [147][78/79]	Step 104192	Loss 1.7965	Prec@(1,5) (53.3%, 81.7%)
07/02 07:53:47午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [147/299] Final Prec@1 53.3400%
07/02 07:53:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:53:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][50/703]	Step 104242	lr 0.05154	Loss 0.8727 (1.0212)	Prec@(1,5) (70.1%, 93.1%)	
07/02 07:53:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][100/703]	Step 104292	lr 0.05154	Loss 1.1836 (1.0282)	Prec@(1,5) (69.6%, 93.6%)	
07/02 07:53:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][150/703]	Step 104342	lr 0.05154	Loss 0.9379 (1.0336)	Prec@(1,5) (69.3%, 93.6%)	
07/02 07:54:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][200/703]	Step 104392	lr 0.05154	Loss 1.3334 (1.0378)	Prec@(1,5) (69.2%, 93.5%)	
07/02 07:54:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][250/703]	Step 104442	lr 0.05154	Loss 0.8765 (1.0600)	Prec@(1,5) (68.5%, 93.2%)	
07/02 07:54:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][300/703]	Step 104492	lr 0.05154	Loss 1.0414 (1.0711)	Prec@(1,5) (68.1%, 93.1%)	
07/02 07:54:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][350/703]	Step 104542	lr 0.05154	Loss 0.9368 (1.0796)	Prec@(1,5) (67.9%, 93.0%)	
07/02 07:54:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][400/703]	Step 104592	lr 0.05154	Loss 1.0475 (1.0932)	Prec@(1,5) (67.5%, 92.7%)	
07/02 07:54:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][450/703]	Step 104642	lr 0.05154	Loss 1.3197 (1.1066)	Prec@(1,5) (67.2%, 92.5%)	
07/02 07:54:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][500/703]	Step 104692	lr 0.05154	Loss 1.4493 (1.1151)	Prec@(1,5) (67.0%, 92.3%)	
07/02 07:54:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][550/703]	Step 104742	lr 0.05154	Loss 1.4424 (1.1235)	Prec@(1,5) (66.8%, 92.2%)	
07/02 07:54:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][600/703]	Step 104792	lr 0.05154	Loss 1.2139 (1.1283)	Prec@(1,5) (66.6%, 92.1%)	
07/02 07:54:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][650/703]	Step 104842	lr 0.05154	Loss 1.1326 (1.1330)	Prec@(1,5) (66.6%, 92.1%)	
07/02 07:54:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][700/703]	Step 104892	lr 0.05154	Loss 1.2429 (1.1388)	Prec@(1,5) (66.4%, 92.0%)	
07/02 07:54:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [148][703/703]	Step 104895	lr 0.05154	Loss 1.0916 (1.1386)	Prec@(1,5) (66.4%, 92.0%)	
07/02 07:54:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [148/299] Final Prec@1 66.4333%
07/02 07:54:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [148][50/79]	Step 104896	Loss 1.7805	Prec@(1,5) (53.1%, 81.7%)
07/02 07:54:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [148][78/79]	Step 104896	Loss 1.8232	Prec@(1,5) (52.6%, 81.4%)
07/02 07:54:35午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [148/299] Final Prec@1 52.5600%
07/02 07:54:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:54:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][50/703]	Step 104946	lr 0.05102	Loss 0.9195 (1.0166)	Prec@(1,5) (70.6%, 93.6%)	
07/02 07:54:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][100/703]	Step 104996	lr 0.05102	Loss 1.1014 (1.0416)	Prec@(1,5) (69.1%, 93.4%)	
07/02 07:54:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][150/703]	Step 105046	lr 0.05102	Loss 1.0007 (1.0416)	Prec@(1,5) (68.8%, 93.5%)	
07/02 07:54:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][200/703]	Step 105096	lr 0.05102	Loss 1.2920 (1.0437)	Prec@(1,5) (68.9%, 93.4%)	
07/02 07:54:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][250/703]	Step 105146	lr 0.05102	Loss 1.1250 (1.0507)	Prec@(1,5) (68.7%, 93.3%)	
07/02 07:54:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][300/703]	Step 105196	lr 0.05102	Loss 1.3294 (1.0652)	Prec@(1,5) (68.2%, 93.2%)	
07/02 07:54:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][350/703]	Step 105246	lr 0.05102	Loss 0.9342 (1.0788)	Prec@(1,5) (67.9%, 93.0%)	
07/02 07:55:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][400/703]	Step 105296	lr 0.05102	Loss 1.0612 (1.0902)	Prec@(1,5) (67.5%, 92.8%)	
07/02 07:55:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][450/703]	Step 105346	lr 0.05102	Loss 1.0198 (1.0988)	Prec@(1,5) (67.3%, 92.7%)	
07/02 07:55:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][500/703]	Step 105396	lr 0.05102	Loss 1.3913 (1.1066)	Prec@(1,5) (67.1%, 92.6%)	
07/02 07:55:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][550/703]	Step 105446	lr 0.05102	Loss 1.2992 (1.1122)	Prec@(1,5) (66.9%, 92.5%)	
07/02 07:55:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][600/703]	Step 105496	lr 0.05102	Loss 1.2013 (1.1170)	Prec@(1,5) (66.8%, 92.5%)	
07/02 07:55:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][650/703]	Step 105546	lr 0.05102	Loss 1.1868 (1.1245)	Prec@(1,5) (66.7%, 92.4%)	
07/02 07:55:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][700/703]	Step 105596	lr 0.05102	Loss 0.9617 (1.1292)	Prec@(1,5) (66.6%, 92.3%)	
07/02 07:55:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [149][703/703]	Step 105599	lr 0.05102	Loss 1.1595 (1.1298)	Prec@(1,5) (66.6%, 92.2%)	
07/02 07:55:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [149/299] Final Prec@1 66.5978%
07/02 07:55:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [149][50/79]	Step 105600	Loss 1.8163	Prec@(1,5) (52.1%, 81.5%)
07/02 07:55:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [149][78/79]	Step 105600	Loss 1.7940	Prec@(1,5) (52.6%, 82.0%)
07/02 07:55:22午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [149/299] Final Prec@1 52.5800%
07/02 07:55:22午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:55:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][50/703]	Step 105650	lr 0.0505	Loss 1.1494 (1.0072)	Prec@(1,5) (70.5%, 94.4%)	
07/02 07:55:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][100/703]	Step 105700	lr 0.0505	Loss 0.9442 (1.0011)	Prec@(1,5) (69.7%, 94.1%)	
07/02 07:55:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][150/703]	Step 105750	lr 0.0505	Loss 1.0621 (1.0160)	Prec@(1,5) (69.4%, 93.6%)	
07/02 07:55:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][200/703]	Step 105800	lr 0.0505	Loss 0.9156 (1.0167)	Prec@(1,5) (69.6%, 93.7%)	
07/02 07:55:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][250/703]	Step 105850	lr 0.0505	Loss 1.1743 (1.0286)	Prec@(1,5) (69.2%, 93.5%)	
07/02 07:55:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][300/703]	Step 105900	lr 0.0505	Loss 1.0568 (1.0479)	Prec@(1,5) (68.7%, 93.1%)	
07/02 07:55:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][350/703]	Step 105950	lr 0.0505	Loss 1.2120 (1.0550)	Prec@(1,5) (68.5%, 93.1%)	
07/02 07:55:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][400/703]	Step 106000	lr 0.0505	Loss 1.0447 (1.0664)	Prec@(1,5) (68.2%, 93.0%)	
07/02 07:55:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][450/703]	Step 106050	lr 0.0505	Loss 1.4118 (1.0778)	Prec@(1,5) (67.8%, 92.8%)	
07/02 07:55:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][500/703]	Step 106100	lr 0.0505	Loss 1.2832 (1.0849)	Prec@(1,5) (67.7%, 92.7%)	
07/02 07:55:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][550/703]	Step 106150	lr 0.0505	Loss 1.3058 (1.0944)	Prec@(1,5) (67.6%, 92.6%)	
07/02 07:56:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][600/703]	Step 106200	lr 0.0505	Loss 1.4328 (1.1065)	Prec@(1,5) (67.2%, 92.4%)	
07/02 07:56:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][650/703]	Step 106250	lr 0.0505	Loss 1.0805 (1.1096)	Prec@(1,5) (67.2%, 92.3%)	
07/02 07:56:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][700/703]	Step 106300	lr 0.0505	Loss 1.5945 (1.1181)	Prec@(1,5) (67.0%, 92.3%)	
07/02 07:56:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [150][703/703]	Step 106303	lr 0.0505	Loss 1.0963 (1.1188)	Prec@(1,5) (67.0%, 92.3%)	
07/02 07:56:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [150/299] Final Prec@1 66.9511%
07/02 07:56:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [150][50/79]	Step 106304	Loss 1.8137	Prec@(1,5) (52.5%, 81.6%)
07/02 07:56:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [150][78/79]	Step 106304	Loss 1.7956	Prec@(1,5) (52.8%, 82.1%)
07/02 07:56:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [150/299] Final Prec@1 52.8400%
07/02 07:56:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:56:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][50/703]	Step 106354	lr 0.04998	Loss 0.8734 (1.0385)	Prec@(1,5) (69.7%, 93.2%)	
07/02 07:56:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][100/703]	Step 106404	lr 0.04998	Loss 0.9246 (1.0410)	Prec@(1,5) (69.3%, 93.1%)	
07/02 07:56:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][150/703]	Step 106454	lr 0.04998	Loss 0.7937 (1.0218)	Prec@(1,5) (69.8%, 93.4%)	
07/02 07:56:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][200/703]	Step 106504	lr 0.04998	Loss 0.9655 (1.0175)	Prec@(1,5) (69.8%, 93.6%)	
07/02 07:56:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][250/703]	Step 106554	lr 0.04998	Loss 0.9751 (1.0286)	Prec@(1,5) (69.5%, 93.5%)	
07/02 07:56:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][300/703]	Step 106604	lr 0.04998	Loss 1.2177 (1.0445)	Prec@(1,5) (69.0%, 93.3%)	
07/02 07:56:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][350/703]	Step 106654	lr 0.04998	Loss 1.1220 (1.0555)	Prec@(1,5) (68.6%, 93.2%)	
07/02 07:56:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][400/703]	Step 106704	lr 0.04998	Loss 1.6283 (1.0698)	Prec@(1,5) (68.2%, 92.9%)	
07/02 07:56:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][450/703]	Step 106754	lr 0.04998	Loss 1.0645 (1.0802)	Prec@(1,5) (68.0%, 92.8%)	
07/02 07:56:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][500/703]	Step 106804	lr 0.04998	Loss 1.0541 (1.0887)	Prec@(1,5) (67.8%, 92.7%)	
07/02 07:56:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][550/703]	Step 106854	lr 0.04998	Loss 1.4865 (1.0914)	Prec@(1,5) (67.6%, 92.7%)	
07/02 07:56:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][600/703]	Step 106904	lr 0.04998	Loss 1.3307 (1.0992)	Prec@(1,5) (67.4%, 92.6%)	
07/02 07:56:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][650/703]	Step 106954	lr 0.04998	Loss 1.2076 (1.1046)	Prec@(1,5) (67.3%, 92.5%)	
07/02 07:56:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][700/703]	Step 107004	lr 0.04998	Loss 1.3698 (1.1118)	Prec@(1,5) (67.1%, 92.4%)	
07/02 07:56:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [151][703/703]	Step 107007	lr 0.04998	Loss 1.3431 (1.1116)	Prec@(1,5) (67.1%, 92.4%)	
07/02 07:56:54午後 finetuneTeacher_trainer.py:180 [INFO] Train: [151/299] Final Prec@1 67.0822%
07/02 07:56:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [151][50/79]	Step 107008	Loss 1.7719	Prec@(1,5) (53.2%, 82.5%)
07/02 07:56:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [151][78/79]	Step 107008	Loss 1.7852	Prec@(1,5) (52.7%, 82.5%)
07/02 07:56:56午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [151/299] Final Prec@1 52.7400%
07/02 07:56:56午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:57:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][50/703]	Step 107058	lr 0.04946	Loss 0.9812 (1.0304)	Prec@(1,5) (69.7%, 93.8%)	
07/02 07:57:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][100/703]	Step 107108	lr 0.04946	Loss 1.2517 (1.0036)	Prec@(1,5) (70.2%, 94.0%)	
07/02 07:57:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][150/703]	Step 107158	lr 0.04946	Loss 0.7134 (0.9918)	Prec@(1,5) (70.4%, 94.0%)	
07/02 07:57:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][200/703]	Step 107208	lr 0.04946	Loss 1.3539 (1.0140)	Prec@(1,5) (69.8%, 93.8%)	
07/02 07:57:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][250/703]	Step 107258	lr 0.04946	Loss 0.9350 (1.0214)	Prec@(1,5) (69.5%, 93.5%)	
07/02 07:57:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][300/703]	Step 107308	lr 0.04946	Loss 1.2781 (1.0280)	Prec@(1,5) (69.4%, 93.4%)	
07/02 07:57:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][350/703]	Step 107358	lr 0.04946	Loss 1.0444 (1.0425)	Prec@(1,5) (69.0%, 93.2%)	
07/02 07:57:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][400/703]	Step 107408	lr 0.04946	Loss 1.0360 (1.0501)	Prec@(1,5) (68.9%, 93.1%)	
07/02 07:57:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][450/703]	Step 107458	lr 0.04946	Loss 1.2228 (1.0620)	Prec@(1,5) (68.6%, 92.9%)	
07/02 07:57:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][500/703]	Step 107508	lr 0.04946	Loss 1.1432 (1.0755)	Prec@(1,5) (68.2%, 92.8%)	
07/02 07:57:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][550/703]	Step 107558	lr 0.04946	Loss 1.1008 (1.0799)	Prec@(1,5) (68.1%, 92.7%)	
07/02 07:57:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][600/703]	Step 107608	lr 0.04946	Loss 0.8772 (1.0869)	Prec@(1,5) (67.9%, 92.6%)	
07/02 07:57:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][650/703]	Step 107658	lr 0.04946	Loss 1.3507 (1.0899)	Prec@(1,5) (67.9%, 92.6%)	
07/02 07:57:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][700/703]	Step 107708	lr 0.04946	Loss 1.2093 (1.0960)	Prec@(1,5) (67.7%, 92.5%)	
07/02 07:57:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [152][703/703]	Step 107711	lr 0.04946	Loss 0.9479 (1.0954)	Prec@(1,5) (67.7%, 92.5%)	
07/02 07:57:40午後 finetuneTeacher_trainer.py:180 [INFO] Train: [152/299] Final Prec@1 67.7333%
07/02 07:57:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [152][50/79]	Step 107712	Loss 1.8449	Prec@(1,5) (53.9%, 81.7%)
07/02 07:57:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [152][78/79]	Step 107712	Loss 1.8547	Prec@(1,5) (53.5%, 81.4%)
07/02 07:57:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [152/299] Final Prec@1 53.4800%
07/02 07:57:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:57:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][50/703]	Step 107762	lr 0.04895	Loss 1.1024 (1.0067)	Prec@(1,5) (69.5%, 93.7%)	
07/02 07:57:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][100/703]	Step 107812	lr 0.04895	Loss 1.0526 (0.9818)	Prec@(1,5) (70.6%, 94.1%)	
07/02 07:57:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][150/703]	Step 107862	lr 0.04895	Loss 1.0878 (0.9906)	Prec@(1,5) (70.4%, 94.1%)	
07/02 07:57:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][200/703]	Step 107912	lr 0.04895	Loss 1.1944 (1.0006)	Prec@(1,5) (70.0%, 94.0%)	
07/02 07:57:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][250/703]	Step 107962	lr 0.04895	Loss 1.1402 (1.0056)	Prec@(1,5) (70.0%, 94.0%)	
07/02 07:58:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][300/703]	Step 108012	lr 0.04895	Loss 1.2118 (1.0224)	Prec@(1,5) (69.5%, 93.7%)	
07/02 07:58:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][350/703]	Step 108062	lr 0.04895	Loss 1.2661 (1.0407)	Prec@(1,5) (69.0%, 93.4%)	
07/02 07:58:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][400/703]	Step 108112	lr 0.04895	Loss 0.8368 (1.0549)	Prec@(1,5) (68.7%, 93.2%)	
07/02 07:58:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][450/703]	Step 108162	lr 0.04895	Loss 0.9801 (1.0700)	Prec@(1,5) (68.4%, 93.0%)	
07/02 07:58:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][500/703]	Step 108212	lr 0.04895	Loss 1.2337 (1.0813)	Prec@(1,5) (68.0%, 92.8%)	
07/02 07:58:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][550/703]	Step 108262	lr 0.04895	Loss 1.1198 (1.0881)	Prec@(1,5) (67.8%, 92.8%)	
07/02 07:58:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][600/703]	Step 108312	lr 0.04895	Loss 1.0962 (1.0963)	Prec@(1,5) (67.6%, 92.7%)	
07/02 07:58:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][650/703]	Step 108362	lr 0.04895	Loss 1.3593 (1.1021)	Prec@(1,5) (67.5%, 92.6%)	
07/02 07:58:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][700/703]	Step 108412	lr 0.04895	Loss 1.1402 (1.1068)	Prec@(1,5) (67.4%, 92.6%)	
07/02 07:58:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [153][703/703]	Step 108415	lr 0.04895	Loss 0.9851 (1.1072)	Prec@(1,5) (67.3%, 92.6%)	
07/02 07:58:26午後 finetuneTeacher_trainer.py:180 [INFO] Train: [153/299] Final Prec@1 67.3444%
07/02 07:58:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [153][50/79]	Step 108416	Loss 1.7902	Prec@(1,5) (53.4%, 81.9%)
07/02 07:58:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [153][78/79]	Step 108416	Loss 1.7725	Prec@(1,5) (53.7%, 82.0%)
07/02 07:58:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [153/299] Final Prec@1 53.7600%
07/02 07:58:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:58:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][50/703]	Step 108466	lr 0.04843	Loss 1.1601 (0.9907)	Prec@(1,5) (70.3%, 94.2%)	
07/02 07:58:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][100/703]	Step 108516	lr 0.04843	Loss 0.8769 (0.9858)	Prec@(1,5) (70.4%, 94.2%)	
07/02 07:58:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][150/703]	Step 108566	lr 0.04843	Loss 1.1683 (0.9982)	Prec@(1,5) (70.1%, 93.9%)	
07/02 07:58:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][200/703]	Step 108616	lr 0.04843	Loss 0.9110 (1.0098)	Prec@(1,5) (69.5%, 93.9%)	
07/02 07:58:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][250/703]	Step 108666	lr 0.04843	Loss 0.8701 (1.0198)	Prec@(1,5) (69.5%, 93.7%)	
07/02 07:58:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][300/703]	Step 108716	lr 0.04843	Loss 1.2412 (1.0357)	Prec@(1,5) (68.9%, 93.4%)	
07/02 07:58:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][350/703]	Step 108766	lr 0.04843	Loss 0.9172 (1.0397)	Prec@(1,5) (68.8%, 93.4%)	
07/02 07:58:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][400/703]	Step 108816	lr 0.04843	Loss 1.2773 (1.0505)	Prec@(1,5) (68.6%, 93.2%)	
07/02 07:58:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][450/703]	Step 108866	lr 0.04843	Loss 1.0742 (1.0619)	Prec@(1,5) (68.4%, 93.1%)	
07/02 07:59:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][500/703]	Step 108916	lr 0.04843	Loss 1.2066 (1.0747)	Prec@(1,5) (68.0%, 92.9%)	
07/02 07:59:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][550/703]	Step 108966	lr 0.04843	Loss 1.4539 (1.0794)	Prec@(1,5) (67.9%, 92.9%)	
07/02 07:59:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][600/703]	Step 109016	lr 0.04843	Loss 1.1479 (1.0817)	Prec@(1,5) (67.8%, 92.8%)	
07/02 07:59:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][650/703]	Step 109066	lr 0.04843	Loss 1.5134 (1.0880)	Prec@(1,5) (67.6%, 92.8%)	
07/02 07:59:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][700/703]	Step 109116	lr 0.04843	Loss 0.9220 (1.0960)	Prec@(1,5) (67.5%, 92.6%)	
07/02 07:59:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [154][703/703]	Step 109119	lr 0.04843	Loss 1.1181 (1.0957)	Prec@(1,5) (67.5%, 92.6%)	
07/02 07:59:13午後 finetuneTeacher_trainer.py:180 [INFO] Train: [154/299] Final Prec@1 67.5200%
07/02 07:59:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [154][50/79]	Step 109120	Loss 1.7979	Prec@(1,5) (54.1%, 82.1%)
07/02 07:59:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [154][78/79]	Step 109120	Loss 1.8362	Prec@(1,5) (52.8%, 81.1%)
07/02 07:59:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [154/299] Final Prec@1 52.8200%
07/02 07:59:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 07:59:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][50/703]	Step 109170	lr 0.04791	Loss 1.1347 (1.0050)	Prec@(1,5) (69.5%, 93.6%)	
07/02 07:59:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][100/703]	Step 109220	lr 0.04791	Loss 1.3240 (0.9778)	Prec@(1,5) (70.4%, 94.3%)	
07/02 07:59:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][150/703]	Step 109270	lr 0.04791	Loss 0.9142 (0.9928)	Prec@(1,5) (70.1%, 94.0%)	
07/02 07:59:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][200/703]	Step 109320	lr 0.04791	Loss 1.1365 (0.9987)	Prec@(1,5) (69.9%, 93.8%)	
07/02 07:59:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][250/703]	Step 109370	lr 0.04791	Loss 1.2889 (1.0081)	Prec@(1,5) (69.7%, 93.8%)	
07/02 07:59:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][300/703]	Step 109420	lr 0.04791	Loss 0.9059 (1.0174)	Prec@(1,5) (69.4%, 93.7%)	
07/02 07:59:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][350/703]	Step 109470	lr 0.04791	Loss 1.2066 (1.0249)	Prec@(1,5) (69.3%, 93.7%)	
07/02 07:59:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][400/703]	Step 109520	lr 0.04791	Loss 1.1170 (1.0318)	Prec@(1,5) (69.3%, 93.5%)	
07/02 07:59:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][450/703]	Step 109570	lr 0.04791	Loss 1.4973 (1.0405)	Prec@(1,5) (69.1%, 93.4%)	
07/02 07:59:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][500/703]	Step 109620	lr 0.04791	Loss 1.0952 (1.0528)	Prec@(1,5) (68.8%, 93.2%)	
07/02 07:59:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][550/703]	Step 109670	lr 0.04791	Loss 1.4351 (1.0614)	Prec@(1,5) (68.6%, 93.1%)	
07/02 07:59:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][600/703]	Step 109720	lr 0.04791	Loss 0.9221 (1.0697)	Prec@(1,5) (68.4%, 93.0%)	
07/02 07:59:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][650/703]	Step 109770	lr 0.04791	Loss 1.0196 (1.0778)	Prec@(1,5) (68.2%, 92.9%)	
07/02 07:59:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][700/703]	Step 109820	lr 0.04791	Loss 1.0953 (1.0828)	Prec@(1,5) (68.0%, 92.8%)	
07/02 07:59:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [155][703/703]	Step 109823	lr 0.04791	Loss 1.1811 (1.0833)	Prec@(1,5) (68.0%, 92.8%)	
07/02 07:59:58午後 finetuneTeacher_trainer.py:180 [INFO] Train: [155/299] Final Prec@1 68.0022%
07/02 07:59:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [155][50/79]	Step 109824	Loss 1.7671	Prec@(1,5) (53.4%, 83.3%)
07/02 08:00:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [155][78/79]	Step 109824	Loss 1.8011	Prec@(1,5) (53.2%, 82.3%)
07/02 08:00:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [155/299] Final Prec@1 53.1800%
07/02 08:00:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.9400%
07/02 08:00:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][50/703]	Step 109874	lr 0.04739	Loss 1.2319 (0.9989)	Prec@(1,5) (71.4%, 93.7%)	
07/02 08:00:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][100/703]	Step 109924	lr 0.04739	Loss 0.8726 (0.9880)	Prec@(1,5) (71.0%, 93.9%)	
07/02 08:00:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][150/703]	Step 109974	lr 0.04739	Loss 1.0879 (0.9831)	Prec@(1,5) (70.7%, 94.0%)	
07/02 08:00:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][200/703]	Step 110024	lr 0.04739	Loss 1.1462 (0.9725)	Prec@(1,5) (71.1%, 94.2%)	
07/02 08:00:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][250/703]	Step 110074	lr 0.04739	Loss 1.2543 (0.9893)	Prec@(1,5) (70.7%, 93.9%)	
07/02 08:00:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][300/703]	Step 110124	lr 0.04739	Loss 1.0152 (0.9997)	Prec@(1,5) (70.3%, 93.8%)	
07/02 08:00:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][350/703]	Step 110174	lr 0.04739	Loss 1.0202 (1.0086)	Prec@(1,5) (69.9%, 93.7%)	
07/02 08:00:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][400/703]	Step 110224	lr 0.04739	Loss 0.6817 (1.0182)	Prec@(1,5) (69.6%, 93.5%)	
07/02 08:00:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][450/703]	Step 110274	lr 0.04739	Loss 1.0464 (1.0245)	Prec@(1,5) (69.6%, 93.5%)	
07/02 08:00:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][500/703]	Step 110324	lr 0.04739	Loss 1.3310 (1.0350)	Prec@(1,5) (69.2%, 93.3%)	
07/02 08:00:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][550/703]	Step 110374	lr 0.04739	Loss 0.9098 (1.0430)	Prec@(1,5) (69.0%, 93.2%)	
07/02 08:00:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][600/703]	Step 110424	lr 0.04739	Loss 0.7181 (1.0498)	Prec@(1,5) (68.8%, 93.1%)	
07/02 08:00:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][650/703]	Step 110474	lr 0.04739	Loss 1.0085 (1.0564)	Prec@(1,5) (68.6%, 93.0%)	
07/02 08:00:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][700/703]	Step 110524	lr 0.04739	Loss 1.2683 (1.0616)	Prec@(1,5) (68.5%, 92.9%)	
07/02 08:00:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [156][703/703]	Step 110527	lr 0.04739	Loss 0.9596 (1.0612)	Prec@(1,5) (68.5%, 92.9%)	
07/02 08:00:44午後 finetuneTeacher_trainer.py:180 [INFO] Train: [156/299] Final Prec@1 68.5000%
07/02 08:00:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [156][50/79]	Step 110528	Loss 1.7461	Prec@(1,5) (55.3%, 82.6%)
07/02 08:00:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [156][78/79]	Step 110528	Loss 1.7259	Prec@(1,5) (55.3%, 83.3%)
07/02 08:00:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [156/299] Final Prec@1 55.3200%
07/02 08:00:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:00:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][50/703]	Step 110578	lr 0.04687	Loss 1.0601 (0.9850)	Prec@(1,5) (70.4%, 94.2%)	
07/02 08:00:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][100/703]	Step 110628	lr 0.04687	Loss 1.1636 (0.9887)	Prec@(1,5) (70.3%, 94.1%)	
07/02 08:00:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][150/703]	Step 110678	lr 0.04687	Loss 1.0304 (0.9735)	Prec@(1,5) (70.9%, 94.3%)	
07/02 08:00:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][200/703]	Step 110728	lr 0.04687	Loss 0.9614 (0.9927)	Prec@(1,5) (70.4%, 94.0%)	
07/02 08:01:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][250/703]	Step 110778	lr 0.04687	Loss 0.9562 (0.9929)	Prec@(1,5) (70.5%, 94.0%)	
07/02 08:01:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][300/703]	Step 110828	lr 0.04687	Loss 0.9662 (0.9955)	Prec@(1,5) (70.5%, 94.0%)	
07/02 08:01:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][350/703]	Step 110878	lr 0.04687	Loss 1.0890 (1.0024)	Prec@(1,5) (70.3%, 93.8%)	
07/02 08:01:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][400/703]	Step 110928	lr 0.04687	Loss 0.9890 (1.0093)	Prec@(1,5) (70.1%, 93.7%)	
07/02 08:01:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][450/703]	Step 110978	lr 0.04687	Loss 0.9664 (1.0193)	Prec@(1,5) (69.8%, 93.5%)	
07/02 08:01:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][500/703]	Step 111028	lr 0.04687	Loss 1.2313 (1.0288)	Prec@(1,5) (69.5%, 93.5%)	
07/02 08:01:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][550/703]	Step 111078	lr 0.04687	Loss 1.3658 (1.0351)	Prec@(1,5) (69.2%, 93.4%)	
07/02 08:01:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][600/703]	Step 111128	lr 0.04687	Loss 1.1963 (1.0434)	Prec@(1,5) (69.0%, 93.4%)	
07/02 08:01:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][650/703]	Step 111178	lr 0.04687	Loss 1.3210 (1.0475)	Prec@(1,5) (68.9%, 93.3%)	
07/02 08:01:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][700/703]	Step 111228	lr 0.04687	Loss 1.3011 (1.0550)	Prec@(1,5) (68.6%, 93.2%)	
07/02 08:01:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [157][703/703]	Step 111231	lr 0.04687	Loss 1.2886 (1.0553)	Prec@(1,5) (68.6%, 93.2%)	
07/02 08:01:30午後 finetuneTeacher_trainer.py:180 [INFO] Train: [157/299] Final Prec@1 68.6000%
07/02 08:01:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [157][50/79]	Step 111232	Loss 1.8585	Prec@(1,5) (52.2%, 81.5%)
07/02 08:01:32午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [157][78/79]	Step 111232	Loss 1.8790	Prec@(1,5) (52.1%, 81.3%)
07/02 08:01:32午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [157/299] Final Prec@1 52.0400%
07/02 08:01:32午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:01:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][50/703]	Step 111282	lr 0.04636	Loss 1.1499 (0.9921)	Prec@(1,5) (69.9%, 94.0%)	
07/02 08:01:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][100/703]	Step 111332	lr 0.04636	Loss 1.1058 (0.9790)	Prec@(1,5) (70.9%, 94.1%)	
07/02 08:01:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][150/703]	Step 111382	lr 0.04636	Loss 0.9900 (0.9740)	Prec@(1,5) (70.9%, 94.2%)	
07/02 08:01:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][200/703]	Step 111432	lr 0.04636	Loss 0.8038 (0.9659)	Prec@(1,5) (71.3%, 94.3%)	
07/02 08:01:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][250/703]	Step 111482	lr 0.04636	Loss 1.0279 (0.9697)	Prec@(1,5) (70.9%, 94.3%)	
07/02 08:01:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][300/703]	Step 111532	lr 0.04636	Loss 1.2101 (0.9835)	Prec@(1,5) (70.3%, 94.2%)	
07/02 08:01:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][350/703]	Step 111582	lr 0.04636	Loss 1.1623 (0.9964)	Prec@(1,5) (70.0%, 93.8%)	
07/02 08:01:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][400/703]	Step 111632	lr 0.04636	Loss 1.0189 (1.0015)	Prec@(1,5) (69.9%, 93.8%)	
07/02 08:02:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][450/703]	Step 111682	lr 0.04636	Loss 0.9774 (1.0127)	Prec@(1,5) (69.6%, 93.7%)	
07/02 08:02:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][500/703]	Step 111732	lr 0.04636	Loss 1.5923 (1.0217)	Prec@(1,5) (69.3%, 93.7%)	
07/02 08:02:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][550/703]	Step 111782	lr 0.04636	Loss 1.2749 (1.0309)	Prec@(1,5) (69.0%, 93.7%)	
07/02 08:02:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][600/703]	Step 111832	lr 0.04636	Loss 1.3500 (1.0408)	Prec@(1,5) (68.8%, 93.5%)	
07/02 08:02:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][650/703]	Step 111882	lr 0.04636	Loss 1.0752 (1.0486)	Prec@(1,5) (68.5%, 93.4%)	
07/02 08:02:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][700/703]	Step 111932	lr 0.04636	Loss 1.3356 (1.0546)	Prec@(1,5) (68.4%, 93.3%)	
07/02 08:02:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [158][703/703]	Step 111935	lr 0.04636	Loss 0.9527 (1.0544)	Prec@(1,5) (68.4%, 93.3%)	
07/02 08:02:17午後 finetuneTeacher_trainer.py:180 [INFO] Train: [158/299] Final Prec@1 68.3778%
07/02 08:02:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [158][50/79]	Step 111936	Loss 1.7834	Prec@(1,5) (53.3%, 82.4%)
07/02 08:02:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [158][78/79]	Step 111936	Loss 1.7990	Prec@(1,5) (53.3%, 81.8%)
07/02 08:02:18午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [158/299] Final Prec@1 53.4000%
07/02 08:02:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:02:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][50/703]	Step 111986	lr 0.04584	Loss 1.0182 (0.9375)	Prec@(1,5) (71.5%, 94.4%)	
07/02 08:02:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][100/703]	Step 112036	lr 0.04584	Loss 0.9146 (0.9453)	Prec@(1,5) (71.6%, 94.4%)	
07/02 08:02:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][150/703]	Step 112086	lr 0.04584	Loss 0.8166 (0.9648)	Prec@(1,5) (71.2%, 94.1%)	
07/02 08:02:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][200/703]	Step 112136	lr 0.04584	Loss 1.2036 (0.9728)	Prec@(1,5) (71.0%, 94.0%)	
07/02 08:02:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][250/703]	Step 112186	lr 0.04584	Loss 1.2309 (0.9810)	Prec@(1,5) (70.8%, 93.9%)	
07/02 08:02:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][300/703]	Step 112236	lr 0.04584	Loss 1.0437 (0.9915)	Prec@(1,5) (70.4%, 93.8%)	
07/02 08:02:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][350/703]	Step 112286	lr 0.04584	Loss 1.0157 (0.9948)	Prec@(1,5) (70.3%, 93.8%)	
07/02 08:02:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][400/703]	Step 112336	lr 0.04584	Loss 0.9720 (1.0030)	Prec@(1,5) (70.0%, 93.7%)	
07/02 08:02:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][450/703]	Step 112386	lr 0.04584	Loss 1.1195 (1.0119)	Prec@(1,5) (69.8%, 93.6%)	
07/02 08:02:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][500/703]	Step 112436	lr 0.04584	Loss 1.2114 (1.0193)	Prec@(1,5) (69.6%, 93.5%)	
07/02 08:02:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][550/703]	Step 112486	lr 0.04584	Loss 0.9498 (1.0255)	Prec@(1,5) (69.4%, 93.4%)	
07/02 08:02:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][600/703]	Step 112536	lr 0.04584	Loss 1.2433 (1.0323)	Prec@(1,5) (69.2%, 93.3%)	
07/02 08:02:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][650/703]	Step 112586	lr 0.04584	Loss 1.1826 (1.0319)	Prec@(1,5) (69.3%, 93.3%)	
07/02 08:03:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][700/703]	Step 112636	lr 0.04584	Loss 0.8484 (1.0360)	Prec@(1,5) (69.1%, 93.3%)	
07/02 08:03:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [159][703/703]	Step 112639	lr 0.04584	Loss 0.8864 (1.0357)	Prec@(1,5) (69.1%, 93.3%)	
07/02 08:03:01午後 finetuneTeacher_trainer.py:180 [INFO] Train: [159/299] Final Prec@1 69.0822%
07/02 08:03:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [159][50/79]	Step 112640	Loss 1.7868	Prec@(1,5) (52.8%, 82.1%)
07/02 08:03:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [159][78/79]	Step 112640	Loss 1.7959	Prec@(1,5) (52.9%, 81.9%)
07/02 08:03:04午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [159/299] Final Prec@1 52.9400%
07/02 08:03:04午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:03:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][50/703]	Step 112690	lr 0.04533	Loss 0.7590 (0.9895)	Prec@(1,5) (70.2%, 94.2%)	
07/02 08:03:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][100/703]	Step 112740	lr 0.04533	Loss 1.0560 (0.9745)	Prec@(1,5) (70.2%, 94.4%)	
07/02 08:03:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][150/703]	Step 112790	lr 0.04533	Loss 0.9536 (0.9659)	Prec@(1,5) (70.8%, 94.5%)	
07/02 08:03:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][200/703]	Step 112840	lr 0.04533	Loss 1.0640 (0.9695)	Prec@(1,5) (70.5%, 94.6%)	
07/02 08:03:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][250/703]	Step 112890	lr 0.04533	Loss 0.8990 (0.9671)	Prec@(1,5) (70.8%, 94.5%)	
07/02 08:03:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][300/703]	Step 112940	lr 0.04533	Loss 1.0702 (0.9715)	Prec@(1,5) (70.7%, 94.4%)	
07/02 08:03:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][350/703]	Step 112990	lr 0.04533	Loss 0.9529 (0.9857)	Prec@(1,5) (70.3%, 94.2%)	
07/02 08:03:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][400/703]	Step 113040	lr 0.04533	Loss 0.9641 (0.9943)	Prec@(1,5) (70.1%, 93.9%)	
07/02 08:03:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][450/703]	Step 113090	lr 0.04533	Loss 0.8103 (1.0008)	Prec@(1,5) (70.0%, 93.8%)	
07/02 08:03:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][500/703]	Step 113140	lr 0.04533	Loss 1.1392 (1.0157)	Prec@(1,5) (69.6%, 93.6%)	
07/02 08:03:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][550/703]	Step 113190	lr 0.04533	Loss 1.0674 (1.0192)	Prec@(1,5) (69.5%, 93.6%)	
07/02 08:03:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][600/703]	Step 113240	lr 0.04533	Loss 1.1391 (1.0266)	Prec@(1,5) (69.3%, 93.5%)	
07/02 08:03:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][650/703]	Step 113290	lr 0.04533	Loss 0.6277 (1.0269)	Prec@(1,5) (69.3%, 93.5%)	
07/02 08:03:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][700/703]	Step 113340	lr 0.04533	Loss 1.0645 (1.0328)	Prec@(1,5) (69.1%, 93.5%)	
07/02 08:03:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [160][703/703]	Step 113343	lr 0.04533	Loss 1.1613 (1.0333)	Prec@(1,5) (69.1%, 93.5%)	
07/02 08:03:48午後 finetuneTeacher_trainer.py:180 [INFO] Train: [160/299] Final Prec@1 69.0800%
07/02 08:03:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [160][50/79]	Step 113344	Loss 1.8602	Prec@(1,5) (52.5%, 81.6%)
07/02 08:03:49午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [160][78/79]	Step 113344	Loss 1.8168	Prec@(1,5) (52.9%, 82.2%)
07/02 08:03:49午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [160/299] Final Prec@1 52.8400%
07/02 08:03:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:03:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][50/703]	Step 113394	lr 0.04481	Loss 0.9942 (0.9644)	Prec@(1,5) (71.2%, 94.2%)	
07/02 08:03:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][100/703]	Step 113444	lr 0.04481	Loss 0.8825 (0.9493)	Prec@(1,5) (71.5%, 94.7%)	
07/02 08:03:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][150/703]	Step 113494	lr 0.04481	Loss 0.8619 (0.9461)	Prec@(1,5) (71.5%, 94.6%)	
07/02 08:04:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][200/703]	Step 113544	lr 0.04481	Loss 0.7141 (0.9534)	Prec@(1,5) (71.3%, 94.5%)	
07/02 08:04:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][250/703]	Step 113594	lr 0.04481	Loss 1.1277 (0.9532)	Prec@(1,5) (71.4%, 94.5%)	
07/02 08:04:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][300/703]	Step 113644	lr 0.04481	Loss 1.0390 (0.9642)	Prec@(1,5) (71.1%, 94.2%)	
07/02 08:04:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][350/703]	Step 113694	lr 0.04481	Loss 1.5312 (0.9785)	Prec@(1,5) (70.7%, 94.0%)	
07/02 08:04:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][400/703]	Step 113744	lr 0.04481	Loss 0.9496 (0.9863)	Prec@(1,5) (70.5%, 94.0%)	
07/02 08:04:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][450/703]	Step 113794	lr 0.04481	Loss 1.1877 (0.9932)	Prec@(1,5) (70.3%, 93.9%)	
07/02 08:04:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][500/703]	Step 113844	lr 0.04481	Loss 0.9326 (0.9994)	Prec@(1,5) (70.1%, 93.9%)	
07/02 08:04:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][550/703]	Step 113894	lr 0.04481	Loss 0.8970 (1.0062)	Prec@(1,5) (70.0%, 93.9%)	
07/02 08:04:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][600/703]	Step 113944	lr 0.04481	Loss 0.8432 (1.0077)	Prec@(1,5) (69.9%, 93.8%)	
07/02 08:04:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][650/703]	Step 113994	lr 0.04481	Loss 1.3771 (1.0118)	Prec@(1,5) (69.8%, 93.8%)	
07/02 08:04:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][700/703]	Step 114044	lr 0.04481	Loss 1.0061 (1.0174)	Prec@(1,5) (69.7%, 93.7%)	
07/02 08:04:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [161][703/703]	Step 114047	lr 0.04481	Loss 1.0024 (1.0183)	Prec@(1,5) (69.7%, 93.7%)	
07/02 08:04:34午後 finetuneTeacher_trainer.py:180 [INFO] Train: [161/299] Final Prec@1 69.6600%
07/02 08:04:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [161][50/79]	Step 114048	Loss 1.8281	Prec@(1,5) (53.8%, 82.7%)
07/02 08:04:35午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [161][78/79]	Step 114048	Loss 1.7862	Prec@(1,5) (54.1%, 83.1%)
07/02 08:04:35午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [161/299] Final Prec@1 54.1200%
07/02 08:04:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:04:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][50/703]	Step 114098	lr 0.0443	Loss 1.1506 (0.9498)	Prec@(1,5) (70.9%, 94.5%)	
07/02 08:04:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][100/703]	Step 114148	lr 0.0443	Loss 0.9617 (0.9403)	Prec@(1,5) (71.2%, 94.5%)	
07/02 08:04:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][150/703]	Step 114198	lr 0.0443	Loss 0.9152 (0.9265)	Prec@(1,5) (71.6%, 94.7%)	
07/02 08:04:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][200/703]	Step 114248	lr 0.0443	Loss 0.7106 (0.9368)	Prec@(1,5) (71.5%, 94.6%)	
07/02 08:04:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][250/703]	Step 114298	lr 0.0443	Loss 0.8267 (0.9461)	Prec@(1,5) (71.1%, 94.6%)	
07/02 08:04:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][300/703]	Step 114348	lr 0.0443	Loss 0.8530 (0.9478)	Prec@(1,5) (71.2%, 94.5%)	
07/02 08:04:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][350/703]	Step 114398	lr 0.0443	Loss 1.0437 (0.9563)	Prec@(1,5) (71.0%, 94.4%)	
07/02 08:05:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][400/703]	Step 114448	lr 0.0443	Loss 0.9109 (0.9705)	Prec@(1,5) (70.5%, 94.2%)	
07/02 08:05:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][450/703]	Step 114498	lr 0.0443	Loss 1.2956 (0.9827)	Prec@(1,5) (70.1%, 94.0%)	
07/02 08:05:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][500/703]	Step 114548	lr 0.0443	Loss 0.8754 (0.9892)	Prec@(1,5) (70.1%, 94.0%)	
07/02 08:05:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][550/703]	Step 114598	lr 0.0443	Loss 1.2821 (0.9931)	Prec@(1,5) (70.0%, 93.9%)	
07/02 08:05:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][600/703]	Step 114648	lr 0.0443	Loss 1.2896 (0.9995)	Prec@(1,5) (70.0%, 93.8%)	
07/02 08:05:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][650/703]	Step 114698	lr 0.0443	Loss 1.4470 (1.0086)	Prec@(1,5) (69.8%, 93.7%)	
07/02 08:05:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][700/703]	Step 114748	lr 0.0443	Loss 1.3372 (1.0163)	Prec@(1,5) (69.6%, 93.6%)	
07/02 08:05:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [162][703/703]	Step 114751	lr 0.0443	Loss 0.8301 (1.0163)	Prec@(1,5) (69.6%, 93.6%)	
07/02 08:05:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [162/299] Final Prec@1 69.6333%
07/02 08:05:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [162][50/79]	Step 114752	Loss 1.7561	Prec@(1,5) (53.9%, 82.5%)
07/02 08:05:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [162][78/79]	Step 114752	Loss 1.7199	Prec@(1,5) (54.7%, 83.1%)
07/02 08:05:22午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [162/299] Final Prec@1 54.7000%
07/02 08:05:22午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:05:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][50/703]	Step 114802	lr 0.04378	Loss 0.9550 (0.9194)	Prec@(1,5) (72.0%, 94.5%)	
07/02 08:05:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][100/703]	Step 114852	lr 0.04378	Loss 1.3173 (0.9122)	Prec@(1,5) (72.5%, 94.8%)	
07/02 08:05:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][150/703]	Step 114902	lr 0.04378	Loss 0.7364 (0.9227)	Prec@(1,5) (72.3%, 94.6%)	
07/02 08:05:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][200/703]	Step 114952	lr 0.04378	Loss 0.9303 (0.9339)	Prec@(1,5) (72.1%, 94.6%)	
07/02 08:05:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][250/703]	Step 115002	lr 0.04378	Loss 0.9247 (0.9410)	Prec@(1,5) (71.8%, 94.6%)	
07/02 08:05:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][300/703]	Step 115052	lr 0.04378	Loss 0.7390 (0.9434)	Prec@(1,5) (71.8%, 94.5%)	
07/02 08:05:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][350/703]	Step 115102	lr 0.04378	Loss 0.9530 (0.9545)	Prec@(1,5) (71.4%, 94.4%)	
07/02 08:05:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][400/703]	Step 115152	lr 0.04378	Loss 0.9459 (0.9582)	Prec@(1,5) (71.4%, 94.3%)	
07/02 08:05:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][450/703]	Step 115202	lr 0.04378	Loss 0.9289 (0.9619)	Prec@(1,5) (71.2%, 94.3%)	
07/02 08:05:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][500/703]	Step 115252	lr 0.04378	Loss 0.9302 (0.9682)	Prec@(1,5) (71.0%, 94.2%)	
07/02 08:05:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][550/703]	Step 115302	lr 0.04378	Loss 1.2446 (0.9769)	Prec@(1,5) (70.7%, 94.1%)	
07/02 08:06:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][600/703]	Step 115352	lr 0.04378	Loss 1.0575 (0.9842)	Prec@(1,5) (70.5%, 94.0%)	
07/02 08:06:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][650/703]	Step 115402	lr 0.04378	Loss 1.1474 (0.9908)	Prec@(1,5) (70.3%, 93.9%)	
07/02 08:06:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][700/703]	Step 115452	lr 0.04378	Loss 0.9717 (0.9939)	Prec@(1,5) (70.2%, 93.9%)	
07/02 08:06:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [163][703/703]	Step 115455	lr 0.04378	Loss 1.0477 (0.9943)	Prec@(1,5) (70.2%, 93.9%)	
07/02 08:06:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [163/299] Final Prec@1 70.2222%
07/02 08:06:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [163][50/79]	Step 115456	Loss 1.7092	Prec@(1,5) (55.3%, 84.1%)
07/02 08:06:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [163][78/79]	Step 115456	Loss 1.7173	Prec@(1,5) (54.9%, 83.9%)
07/02 08:06:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [163/299] Final Prec@1 54.9400%
07/02 08:06:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:06:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][50/703]	Step 115506	lr 0.04327	Loss 0.7905 (0.8629)	Prec@(1,5) (74.5%, 95.6%)	
07/02 08:06:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][100/703]	Step 115556	lr 0.04327	Loss 1.1976 (0.8805)	Prec@(1,5) (73.7%, 95.5%)	
07/02 08:06:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][150/703]	Step 115606	lr 0.04327	Loss 1.0200 (0.9051)	Prec@(1,5) (73.0%, 95.1%)	
07/02 08:06:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][200/703]	Step 115656	lr 0.04327	Loss 0.6836 (0.8999)	Prec@(1,5) (73.2%, 95.1%)	
07/02 08:06:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][250/703]	Step 115706	lr 0.04327	Loss 1.1618 (0.9244)	Prec@(1,5) (72.4%, 94.7%)	
07/02 08:06:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][300/703]	Step 115756	lr 0.04327	Loss 1.0888 (0.9298)	Prec@(1,5) (72.1%, 94.6%)	
07/02 08:06:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][350/703]	Step 115806	lr 0.04327	Loss 1.1946 (0.9414)	Prec@(1,5) (71.7%, 94.5%)	
07/02 08:06:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][400/703]	Step 115856	lr 0.04327	Loss 0.9366 (0.9482)	Prec@(1,5) (71.6%, 94.4%)	
07/02 08:06:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][450/703]	Step 115906	lr 0.04327	Loss 1.0499 (0.9563)	Prec@(1,5) (71.3%, 94.4%)	
07/02 08:06:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][500/703]	Step 115956	lr 0.04327	Loss 0.9231 (0.9648)	Prec@(1,5) (71.1%, 94.2%)	
07/02 08:06:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][550/703]	Step 116006	lr 0.04327	Loss 1.1120 (0.9707)	Prec@(1,5) (70.9%, 94.1%)	
07/02 08:06:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][600/703]	Step 116056	lr 0.04327	Loss 1.1719 (0.9816)	Prec@(1,5) (70.7%, 94.0%)	
07/02 08:06:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][650/703]	Step 116106	lr 0.04327	Loss 1.0142 (0.9893)	Prec@(1,5) (70.5%, 93.9%)	
07/02 08:06:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][700/703]	Step 116156	lr 0.04327	Loss 1.0649 (0.9948)	Prec@(1,5) (70.5%, 93.8%)	
07/02 08:06:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [164][703/703]	Step 116159	lr 0.04327	Loss 1.0343 (0.9952)	Prec@(1,5) (70.4%, 93.8%)	
07/02 08:06:54午後 finetuneTeacher_trainer.py:180 [INFO] Train: [164/299] Final Prec@1 70.4333%
07/02 08:06:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [164][50/79]	Step 116160	Loss 1.7867	Prec@(1,5) (53.6%, 83.1%)
07/02 08:06:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [164][78/79]	Step 116160	Loss 1.7711	Prec@(1,5) (53.9%, 83.3%)
07/02 08:06:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [164/299] Final Prec@1 53.8600%
07/02 08:06:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:06:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][50/703]	Step 116210	lr 0.04276	Loss 1.0722 (0.9249)	Prec@(1,5) (72.7%, 94.8%)	
07/02 08:07:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][100/703]	Step 116260	lr 0.04276	Loss 0.8053 (0.9127)	Prec@(1,5) (73.2%, 94.9%)	
07/02 08:07:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][150/703]	Step 116310	lr 0.04276	Loss 1.0490 (0.8992)	Prec@(1,5) (73.5%, 95.0%)	
07/02 08:07:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][200/703]	Step 116360	lr 0.04276	Loss 1.0361 (0.9054)	Prec@(1,5) (73.1%, 95.0%)	
07/02 08:07:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][250/703]	Step 116410	lr 0.04276	Loss 1.0476 (0.9164)	Prec@(1,5) (72.6%, 94.9%)	
07/02 08:07:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][300/703]	Step 116460	lr 0.04276	Loss 0.9595 (0.9252)	Prec@(1,5) (72.3%, 94.8%)	
07/02 08:07:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][350/703]	Step 116510	lr 0.04276	Loss 1.0327 (0.9275)	Prec@(1,5) (72.2%, 94.8%)	
07/02 08:07:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][400/703]	Step 116560	lr 0.04276	Loss 1.0560 (0.9388)	Prec@(1,5) (71.8%, 94.7%)	
07/02 08:07:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][450/703]	Step 116610	lr 0.04276	Loss 1.0077 (0.9494)	Prec@(1,5) (71.5%, 94.6%)	
07/02 08:07:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][500/703]	Step 116660	lr 0.04276	Loss 1.1943 (0.9577)	Prec@(1,5) (71.3%, 94.5%)	
07/02 08:07:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][550/703]	Step 116710	lr 0.04276	Loss 0.8037 (0.9639)	Prec@(1,5) (71.2%, 94.4%)	
07/02 08:07:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][600/703]	Step 116760	lr 0.04276	Loss 1.0092 (0.9686)	Prec@(1,5) (71.0%, 94.3%)	
07/02 08:07:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][650/703]	Step 116810	lr 0.04276	Loss 0.9620 (0.9740)	Prec@(1,5) (70.8%, 94.2%)	
07/02 08:07:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][700/703]	Step 116860	lr 0.04276	Loss 1.0648 (0.9803)	Prec@(1,5) (70.6%, 94.1%)	
07/02 08:07:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [165][703/703]	Step 116863	lr 0.04276	Loss 0.9384 (0.9809)	Prec@(1,5) (70.6%, 94.1%)	
07/02 08:07:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [165/299] Final Prec@1 70.6267%
07/02 08:07:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [165][50/79]	Step 116864	Loss 1.7148	Prec@(1,5) (55.3%, 83.2%)
07/02 08:07:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [165][78/79]	Step 116864	Loss 1.7752	Prec@(1,5) (54.1%, 82.4%)
07/02 08:07:41午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [165/299] Final Prec@1 54.1400%
07/02 08:07:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:07:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][50/703]	Step 116914	lr 0.04224	Loss 0.5538 (0.9014)	Prec@(1,5) (72.8%, 94.6%)	
07/02 08:07:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][100/703]	Step 116964	lr 0.04224	Loss 1.0916 (0.8861)	Prec@(1,5) (73.3%, 95.1%)	
07/02 08:07:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][150/703]	Step 117014	lr 0.04224	Loss 0.9093 (0.8888)	Prec@(1,5) (73.3%, 95.1%)	
07/02 08:07:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][200/703]	Step 117064	lr 0.04224	Loss 0.8705 (0.8931)	Prec@(1,5) (73.2%, 95.0%)	
07/02 08:07:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][250/703]	Step 117114	lr 0.04224	Loss 0.6754 (0.8943)	Prec@(1,5) (73.2%, 95.0%)	
07/02 08:07:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][300/703]	Step 117164	lr 0.04224	Loss 0.8993 (0.9044)	Prec@(1,5) (72.9%, 95.0%)	
07/02 08:08:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][350/703]	Step 117214	lr 0.04224	Loss 0.9576 (0.9174)	Prec@(1,5) (72.5%, 94.9%)	
07/02 08:08:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][400/703]	Step 117264	lr 0.04224	Loss 0.8267 (0.9257)	Prec@(1,5) (72.2%, 94.8%)	
07/02 08:08:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][450/703]	Step 117314	lr 0.04224	Loss 0.9351 (0.9301)	Prec@(1,5) (72.1%, 94.7%)	
07/02 08:08:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][500/703]	Step 117364	lr 0.04224	Loss 0.9205 (0.9387)	Prec@(1,5) (71.8%, 94.6%)	
07/02 08:08:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][550/703]	Step 117414	lr 0.04224	Loss 0.6836 (0.9488)	Prec@(1,5) (71.5%, 94.5%)	
07/02 08:08:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][600/703]	Step 117464	lr 0.04224	Loss 1.1355 (0.9552)	Prec@(1,5) (71.2%, 94.5%)	
07/02 08:08:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][650/703]	Step 117514	lr 0.04224	Loss 0.8509 (0.9628)	Prec@(1,5) (71.0%, 94.4%)	
07/02 08:08:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][700/703]	Step 117564	lr 0.04224	Loss 1.1228 (0.9695)	Prec@(1,5) (70.9%, 94.3%)	
07/02 08:08:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [166][703/703]	Step 117567	lr 0.04224	Loss 1.1493 (0.9697)	Prec@(1,5) (70.9%, 94.3%)	
07/02 08:08:25午後 finetuneTeacher_trainer.py:180 [INFO] Train: [166/299] Final Prec@1 70.8578%
07/02 08:08:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [166][50/79]	Step 117568	Loss 1.6949	Prec@(1,5) (56.1%, 83.3%)
07/02 08:08:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [166][78/79]	Step 117568	Loss 1.7131	Prec@(1,5) (55.2%, 83.4%)
07/02 08:08:26午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [166/299] Final Prec@1 55.1800%
07/02 08:08:26午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:08:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][50/703]	Step 117618	lr 0.04173	Loss 0.9825 (0.9032)	Prec@(1,5) (73.9%, 94.9%)	
07/02 08:08:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][100/703]	Step 117668	lr 0.04173	Loss 0.9984 (0.8831)	Prec@(1,5) (73.9%, 95.6%)	
07/02 08:08:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][150/703]	Step 117718	lr 0.04173	Loss 0.8946 (0.8766)	Prec@(1,5) (73.9%, 95.4%)	
07/02 08:08:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][200/703]	Step 117768	lr 0.04173	Loss 0.6744 (0.8764)	Prec@(1,5) (73.8%, 95.2%)	
07/02 08:08:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][250/703]	Step 117818	lr 0.04173	Loss 0.9750 (0.8878)	Prec@(1,5) (73.4%, 95.2%)	
07/02 08:08:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][300/703]	Step 117868	lr 0.04173	Loss 0.8773 (0.8960)	Prec@(1,5) (73.1%, 95.0%)	
07/02 08:08:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][350/703]	Step 117918	lr 0.04173	Loss 0.7572 (0.9026)	Prec@(1,5) (72.9%, 95.0%)	
07/02 08:08:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][400/703]	Step 117968	lr 0.04173	Loss 0.6570 (0.9115)	Prec@(1,5) (72.7%, 94.9%)	
07/02 08:08:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][450/703]	Step 118018	lr 0.04173	Loss 1.0306 (0.9224)	Prec@(1,5) (72.4%, 94.9%)	
07/02 08:08:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][500/703]	Step 118068	lr 0.04173	Loss 0.9966 (0.9305)	Prec@(1,5) (72.1%, 94.7%)	
07/02 08:09:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][550/703]	Step 118118	lr 0.04173	Loss 1.0547 (0.9363)	Prec@(1,5) (72.0%, 94.6%)	
07/02 08:09:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][600/703]	Step 118168	lr 0.04173	Loss 1.2838 (0.9425)	Prec@(1,5) (71.8%, 94.5%)	
07/02 08:09:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][650/703]	Step 118218	lr 0.04173	Loss 1.0318 (0.9480)	Prec@(1,5) (71.6%, 94.5%)	
07/02 08:09:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][700/703]	Step 118268	lr 0.04173	Loss 1.1488 (0.9560)	Prec@(1,5) (71.4%, 94.4%)	
07/02 08:09:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [167][703/703]	Step 118271	lr 0.04173	Loss 1.3444 (0.9566)	Prec@(1,5) (71.4%, 94.4%)	
07/02 08:09:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [167/299] Final Prec@1 71.4089%
07/02 08:09:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [167][50/79]	Step 118272	Loss 1.7849	Prec@(1,5) (54.6%, 82.9%)
07/02 08:09:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [167][78/79]	Step 118272	Loss 1.8175	Prec@(1,5) (54.1%, 82.1%)
07/02 08:09:12午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [167/299] Final Prec@1 54.0600%
07/02 08:09:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:09:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][50/703]	Step 118322	lr 0.04122	Loss 0.9670 (0.8299)	Prec@(1,5) (74.7%, 95.9%)	
07/02 08:09:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][100/703]	Step 118372	lr 0.04122	Loss 0.8825 (0.8216)	Prec@(1,5) (75.1%, 95.8%)	
07/02 08:09:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][150/703]	Step 118422	lr 0.04122	Loss 0.8665 (0.8529)	Prec@(1,5) (74.1%, 95.5%)	
07/02 08:09:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][200/703]	Step 118472	lr 0.04122	Loss 1.0793 (0.8698)	Prec@(1,5) (73.8%, 95.3%)	
07/02 08:09:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][250/703]	Step 118522	lr 0.04122	Loss 0.7616 (0.8720)	Prec@(1,5) (73.7%, 95.3%)	
07/02 08:09:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][300/703]	Step 118572	lr 0.04122	Loss 0.7840 (0.8734)	Prec@(1,5) (73.7%, 95.2%)	
07/02 08:09:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][350/703]	Step 118622	lr 0.04122	Loss 0.8562 (0.8820)	Prec@(1,5) (73.3%, 95.2%)	
07/02 08:09:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][400/703]	Step 118672	lr 0.04122	Loss 0.8383 (0.8957)	Prec@(1,5) (72.8%, 95.1%)	
07/02 08:09:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][450/703]	Step 118722	lr 0.04122	Loss 0.8723 (0.9084)	Prec@(1,5) (72.5%, 95.0%)	
07/02 08:09:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][500/703]	Step 118772	lr 0.04122	Loss 0.7979 (0.9192)	Prec@(1,5) (72.1%, 94.8%)	
07/02 08:09:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][550/703]	Step 118822	lr 0.04122	Loss 0.9880 (0.9264)	Prec@(1,5) (72.0%, 94.7%)	
07/02 08:09:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][600/703]	Step 118872	lr 0.04122	Loss 1.1195 (0.9318)	Prec@(1,5) (71.8%, 94.6%)	
07/02 08:09:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][650/703]	Step 118922	lr 0.04122	Loss 0.9765 (0.9417)	Prec@(1,5) (71.5%, 94.5%)	
07/02 08:09:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][700/703]	Step 118972	lr 0.04122	Loss 1.2318 (0.9504)	Prec@(1,5) (71.3%, 94.4%)	
07/02 08:09:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [168][703/703]	Step 118975	lr 0.04122	Loss 1.0332 (0.9508)	Prec@(1,5) (71.3%, 94.4%)	
07/02 08:09:57午後 finetuneTeacher_trainer.py:180 [INFO] Train: [168/299] Final Prec@1 71.2756%
07/02 08:09:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [168][50/79]	Step 118976	Loss 1.7613	Prec@(1,5) (54.3%, 83.0%)
07/02 08:09:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [168][78/79]	Step 118976	Loss 1.7687	Prec@(1,5) (54.0%, 83.4%)
07/02 08:09:58午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [168/299] Final Prec@1 54.0400%
07/02 08:09:58午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:10:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][50/703]	Step 119026	lr 0.04072	Loss 0.9763 (0.8494)	Prec@(1,5) (73.6%, 96.1%)	
07/02 08:10:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][100/703]	Step 119076	lr 0.04072	Loss 0.6798 (0.8198)	Prec@(1,5) (74.7%, 96.5%)	
07/02 08:10:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][150/703]	Step 119126	lr 0.04072	Loss 1.0854 (0.8279)	Prec@(1,5) (74.9%, 96.2%)	
07/02 08:10:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][200/703]	Step 119176	lr 0.04072	Loss 0.9150 (0.8421)	Prec@(1,5) (74.3%, 96.0%)	
07/02 08:10:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][250/703]	Step 119226	lr 0.04072	Loss 0.9229 (0.8487)	Prec@(1,5) (74.2%, 95.9%)	
07/02 08:10:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][300/703]	Step 119276	lr 0.04072	Loss 0.7904 (0.8572)	Prec@(1,5) (74.0%, 95.8%)	
07/02 08:10:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][350/703]	Step 119326	lr 0.04072	Loss 0.9209 (0.8710)	Prec@(1,5) (73.6%, 95.5%)	
07/02 08:10:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][400/703]	Step 119376	lr 0.04072	Loss 1.0230 (0.8861)	Prec@(1,5) (73.2%, 95.4%)	
07/02 08:10:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][450/703]	Step 119426	lr 0.04072	Loss 0.8681 (0.8938)	Prec@(1,5) (72.9%, 95.4%)	
07/02 08:10:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][500/703]	Step 119476	lr 0.04072	Loss 1.4617 (0.9073)	Prec@(1,5) (72.5%, 95.2%)	
07/02 08:10:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][550/703]	Step 119526	lr 0.04072	Loss 1.2457 (0.9194)	Prec@(1,5) (72.1%, 95.0%)	
07/02 08:10:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][600/703]	Step 119576	lr 0.04072	Loss 1.1339 (0.9247)	Prec@(1,5) (72.0%, 95.0%)	
07/02 08:10:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][650/703]	Step 119626	lr 0.04072	Loss 1.2153 (0.9298)	Prec@(1,5) (71.8%, 94.9%)	
07/02 08:10:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][700/703]	Step 119676	lr 0.04072	Loss 0.9328 (0.9359)	Prec@(1,5) (71.7%, 94.8%)	
07/02 08:10:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [169][703/703]	Step 119679	lr 0.04072	Loss 0.8791 (0.9363)	Prec@(1,5) (71.7%, 94.8%)	
07/02 08:10:42午後 finetuneTeacher_trainer.py:180 [INFO] Train: [169/299] Final Prec@1 71.7000%
07/02 08:10:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [169][50/79]	Step 119680	Loss 1.8483	Prec@(1,5) (54.0%, 81.4%)
07/02 08:10:44午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [169][78/79]	Step 119680	Loss 1.8540	Prec@(1,5) (53.3%, 81.4%)
07/02 08:10:44午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [169/299] Final Prec@1 53.3200%
07/02 08:10:44午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:10:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][50/703]	Step 119730	lr 0.04021	Loss 0.7117 (0.8835)	Prec@(1,5) (73.0%, 95.8%)	
07/02 08:10:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][100/703]	Step 119780	lr 0.04021	Loss 0.8058 (0.8631)	Prec@(1,5) (74.1%, 96.0%)	
07/02 08:10:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][150/703]	Step 119830	lr 0.04021	Loss 0.8821 (0.8603)	Prec@(1,5) (73.7%, 95.9%)	
07/02 08:10:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][200/703]	Step 119880	lr 0.04021	Loss 0.9653 (0.8633)	Prec@(1,5) (73.4%, 96.0%)	
07/02 08:11:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][250/703]	Step 119930	lr 0.04021	Loss 0.9116 (0.8792)	Prec@(1,5) (72.9%, 95.7%)	
07/02 08:11:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][300/703]	Step 119980	lr 0.04021	Loss 0.8268 (0.8860)	Prec@(1,5) (72.7%, 95.6%)	
07/02 08:11:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][350/703]	Step 120030	lr 0.04021	Loss 0.7497 (0.8888)	Prec@(1,5) (72.7%, 95.5%)	
07/02 08:11:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][400/703]	Step 120080	lr 0.04021	Loss 0.8319 (0.8924)	Prec@(1,5) (72.5%, 95.4%)	
07/02 08:11:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][450/703]	Step 120130	lr 0.04021	Loss 1.0935 (0.9011)	Prec@(1,5) (72.3%, 95.3%)	
07/02 08:11:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][500/703]	Step 120180	lr 0.04021	Loss 0.9438 (0.9102)	Prec@(1,5) (72.1%, 95.2%)	
07/02 08:11:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][550/703]	Step 120230	lr 0.04021	Loss 1.0645 (0.9164)	Prec@(1,5) (72.0%, 95.0%)	
07/02 08:11:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][600/703]	Step 120280	lr 0.04021	Loss 1.2503 (0.9241)	Prec@(1,5) (71.8%, 95.0%)	
07/02 08:11:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][650/703]	Step 120330	lr 0.04021	Loss 0.9735 (0.9275)	Prec@(1,5) (71.7%, 94.9%)	
07/02 08:11:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][700/703]	Step 120380	lr 0.04021	Loss 1.3758 (0.9367)	Prec@(1,5) (71.4%, 94.8%)	
07/02 08:11:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [170][703/703]	Step 120383	lr 0.04021	Loss 0.7615 (0.9369)	Prec@(1,5) (71.4%, 94.8%)	
07/02 08:11:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [170/299] Final Prec@1 71.4244%
07/02 08:11:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [170][50/79]	Step 120384	Loss 1.7307	Prec@(1,5) (54.8%, 83.2%)
07/02 08:11:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [170][78/79]	Step 120384	Loss 1.7518	Prec@(1,5) (55.0%, 83.0%)
07/02 08:11:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [170/299] Final Prec@1 54.9800%
07/02 08:11:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:11:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][50/703]	Step 120434	lr 0.0397	Loss 1.1137 (0.8277)	Prec@(1,5) (74.7%, 96.2%)	
07/02 08:11:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][100/703]	Step 120484	lr 0.0397	Loss 1.1429 (0.8239)	Prec@(1,5) (74.4%, 96.3%)	
07/02 08:11:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][150/703]	Step 120534	lr 0.0397	Loss 0.8293 (0.8187)	Prec@(1,5) (75.1%, 96.3%)	
07/02 08:11:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][200/703]	Step 120584	lr 0.0397	Loss 0.6332 (0.8295)	Prec@(1,5) (74.6%, 96.1%)	
07/02 08:11:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][250/703]	Step 120634	lr 0.0397	Loss 0.9337 (0.8352)	Prec@(1,5) (74.5%, 95.9%)	
07/02 08:11:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][300/703]	Step 120684	lr 0.0397	Loss 0.7422 (0.8496)	Prec@(1,5) (74.0%, 95.7%)	
07/02 08:11:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][350/703]	Step 120734	lr 0.0397	Loss 0.9918 (0.8601)	Prec@(1,5) (73.6%, 95.6%)	
07/02 08:11:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][400/703]	Step 120784	lr 0.0397	Loss 0.8367 (0.8703)	Prec@(1,5) (73.3%, 95.4%)	
07/02 08:11:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][450/703]	Step 120834	lr 0.0397	Loss 0.7739 (0.8739)	Prec@(1,5) (73.3%, 95.4%)	
07/02 08:12:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][500/703]	Step 120884	lr 0.0397	Loss 1.0158 (0.8904)	Prec@(1,5) (72.8%, 95.2%)	
07/02 08:12:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][550/703]	Step 120934	lr 0.0397	Loss 0.8113 (0.9039)	Prec@(1,5) (72.4%, 95.0%)	
07/02 08:12:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][600/703]	Step 120984	lr 0.0397	Loss 1.1185 (0.9105)	Prec@(1,5) (72.2%, 94.9%)	
07/02 08:12:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][650/703]	Step 121034	lr 0.0397	Loss 1.0670 (0.9166)	Prec@(1,5) (72.0%, 94.8%)	
07/02 08:12:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][700/703]	Step 121084	lr 0.0397	Loss 1.0226 (0.9225)	Prec@(1,5) (71.9%, 94.7%)	
07/02 08:12:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [171][703/703]	Step 121087	lr 0.0397	Loss 0.7924 (0.9226)	Prec@(1,5) (71.9%, 94.7%)	
07/02 08:12:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [171/299] Final Prec@1 71.9133%
07/02 08:12:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [171][50/79]	Step 121088	Loss 1.7053	Prec@(1,5) (55.0%, 83.7%)
07/02 08:12:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [171][78/79]	Step 121088	Loss 1.7400	Prec@(1,5) (54.6%, 83.3%)
07/02 08:12:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [171/299] Final Prec@1 54.6800%
07/02 08:12:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:12:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][50/703]	Step 121138	lr 0.0392	Loss 0.8290 (0.8188)	Prec@(1,5) (74.7%, 96.1%)	
07/02 08:12:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][100/703]	Step 121188	lr 0.0392	Loss 0.8631 (0.8201)	Prec@(1,5) (74.2%, 96.1%)	
07/02 08:12:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][150/703]	Step 121238	lr 0.0392	Loss 0.7368 (0.8231)	Prec@(1,5) (74.3%, 96.0%)	
07/02 08:12:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][200/703]	Step 121288	lr 0.0392	Loss 0.9376 (0.8264)	Prec@(1,5) (74.2%, 96.0%)	
07/02 08:12:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][250/703]	Step 121338	lr 0.0392	Loss 1.0897 (0.8368)	Prec@(1,5) (74.1%, 95.9%)	
07/02 08:12:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][300/703]	Step 121388	lr 0.0392	Loss 0.8213 (0.8478)	Prec@(1,5) (73.9%, 95.7%)	
07/02 08:12:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][350/703]	Step 121438	lr 0.0392	Loss 0.7705 (0.8560)	Prec@(1,5) (73.7%, 95.6%)	
07/02 08:12:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][400/703]	Step 121488	lr 0.0392	Loss 0.8784 (0.8658)	Prec@(1,5) (73.5%, 95.5%)	
07/02 08:12:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][450/703]	Step 121538	lr 0.0392	Loss 0.8381 (0.8725)	Prec@(1,5) (73.4%, 95.4%)	
07/02 08:12:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][500/703]	Step 121588	lr 0.0392	Loss 0.9537 (0.8780)	Prec@(1,5) (73.3%, 95.4%)	
07/02 08:12:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][550/703]	Step 121638	lr 0.0392	Loss 1.2817 (0.8904)	Prec@(1,5) (73.0%, 95.2%)	
07/02 08:12:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][600/703]	Step 121688	lr 0.0392	Loss 0.9699 (0.8955)	Prec@(1,5) (72.9%, 95.1%)	
07/02 08:12:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][650/703]	Step 121738	lr 0.0392	Loss 0.9789 (0.9018)	Prec@(1,5) (72.7%, 95.0%)	
07/02 08:12:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][700/703]	Step 121788	lr 0.0392	Loss 1.0639 (0.9095)	Prec@(1,5) (72.5%, 95.0%)	
07/02 08:12:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [172][703/703]	Step 121791	lr 0.0392	Loss 0.9993 (0.9107)	Prec@(1,5) (72.4%, 94.9%)	
07/02 08:12:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [172/299] Final Prec@1 72.4378%
07/02 08:13:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [172][50/79]	Step 121792	Loss 1.7613	Prec@(1,5) (55.3%, 82.3%)
07/02 08:13:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [172][78/79]	Step 121792	Loss 1.7649	Prec@(1,5) (54.9%, 82.4%)
07/02 08:13:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [172/299] Final Prec@1 54.8800%
07/02 08:13:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.3200%
07/02 08:13:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][50/703]	Step 121842	lr 0.03869	Loss 0.5921 (0.8286)	Prec@(1,5) (75.9%, 96.0%)	
07/02 08:13:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][100/703]	Step 121892	lr 0.03869	Loss 0.8186 (0.8093)	Prec@(1,5) (76.2%, 96.2%)	
07/02 08:13:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][150/703]	Step 121942	lr 0.03869	Loss 0.9483 (0.8123)	Prec@(1,5) (75.9%, 96.2%)	
07/02 08:13:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][200/703]	Step 121992	lr 0.03869	Loss 0.9048 (0.8214)	Prec@(1,5) (75.5%, 96.0%)	
07/02 08:13:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][250/703]	Step 122042	lr 0.03869	Loss 1.1307 (0.8300)	Prec@(1,5) (75.2%, 95.8%)	
07/02 08:13:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][300/703]	Step 122092	lr 0.03869	Loss 0.9114 (0.8400)	Prec@(1,5) (74.8%, 95.6%)	
07/02 08:13:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][350/703]	Step 122142	lr 0.03869	Loss 0.9131 (0.8430)	Prec@(1,5) (74.6%, 95.6%)	
07/02 08:13:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][400/703]	Step 122192	lr 0.03869	Loss 0.9076 (0.8534)	Prec@(1,5) (74.2%, 95.6%)	
07/02 08:13:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][450/703]	Step 122242	lr 0.03869	Loss 0.9297 (0.8611)	Prec@(1,5) (74.0%, 95.5%)	
07/02 08:13:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][500/703]	Step 122292	lr 0.03869	Loss 0.8847 (0.8663)	Prec@(1,5) (73.8%, 95.5%)	
07/02 08:13:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][550/703]	Step 122342	lr 0.03869	Loss 0.8612 (0.8739)	Prec@(1,5) (73.6%, 95.4%)	
07/02 08:13:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][600/703]	Step 122392	lr 0.03869	Loss 1.0017 (0.8848)	Prec@(1,5) (73.3%, 95.2%)	
07/02 08:13:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][650/703]	Step 122442	lr 0.03869	Loss 1.4171 (0.8909)	Prec@(1,5) (73.1%, 95.1%)	
07/02 08:13:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][700/703]	Step 122492	lr 0.03869	Loss 0.8053 (0.8995)	Prec@(1,5) (72.9%, 95.0%)	
07/02 08:13:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [173][703/703]	Step 122495	lr 0.03869	Loss 0.9690 (0.9001)	Prec@(1,5) (72.9%, 95.0%)	
07/02 08:13:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [173/299] Final Prec@1 72.8933%
07/02 08:13:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [173][50/79]	Step 122496	Loss 1.7729	Prec@(1,5) (55.5%, 82.5%)
07/02 08:13:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [173][78/79]	Step 122496	Loss 1.7925	Prec@(1,5) (55.5%, 82.0%)
07/02 08:13:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [173/299] Final Prec@1 55.5400%
07/02 08:13:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.5400%
07/02 08:13:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][50/703]	Step 122546	lr 0.03819	Loss 0.8841 (0.8327)	Prec@(1,5) (75.4%, 96.2%)	
07/02 08:13:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][100/703]	Step 122596	lr 0.03819	Loss 0.9363 (0.7976)	Prec@(1,5) (76.1%, 96.4%)	
07/02 08:13:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][150/703]	Step 122646	lr 0.03819	Loss 0.6968 (0.7959)	Prec@(1,5) (75.9%, 96.3%)	
07/02 08:13:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][200/703]	Step 122696	lr 0.03819	Loss 0.8078 (0.8073)	Prec@(1,5) (75.5%, 96.2%)	
07/02 08:14:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][250/703]	Step 122746	lr 0.03819	Loss 0.6350 (0.8130)	Prec@(1,5) (75.3%, 96.1%)	
07/02 08:14:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][300/703]	Step 122796	lr 0.03819	Loss 0.7000 (0.8263)	Prec@(1,5) (74.9%, 95.9%)	
07/02 08:14:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][350/703]	Step 122846	lr 0.03819	Loss 1.0595 (0.8338)	Prec@(1,5) (74.7%, 95.9%)	
07/02 08:14:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][400/703]	Step 122896	lr 0.03819	Loss 0.7153 (0.8458)	Prec@(1,5) (74.4%, 95.7%)	
07/02 08:14:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][450/703]	Step 122946	lr 0.03819	Loss 1.0298 (0.8604)	Prec@(1,5) (74.0%, 95.5%)	
07/02 08:14:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][500/703]	Step 122996	lr 0.03819	Loss 1.0487 (0.8711)	Prec@(1,5) (73.7%, 95.4%)	
07/02 08:14:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][550/703]	Step 123046	lr 0.03819	Loss 1.0489 (0.8786)	Prec@(1,5) (73.5%, 95.3%)	
07/02 08:14:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][600/703]	Step 123096	lr 0.03819	Loss 1.2195 (0.8845)	Prec@(1,5) (73.3%, 95.2%)	
07/02 08:14:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][650/703]	Step 123146	lr 0.03819	Loss 0.9167 (0.8897)	Prec@(1,5) (73.2%, 95.2%)	
07/02 08:14:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][700/703]	Step 123196	lr 0.03819	Loss 0.8303 (0.8942)	Prec@(1,5) (73.0%, 95.1%)	
07/02 08:14:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [174][703/703]	Step 123199	lr 0.03819	Loss 0.9539 (0.8942)	Prec@(1,5) (73.0%, 95.1%)	
07/02 08:14:30午後 finetuneTeacher_trainer.py:180 [INFO] Train: [174/299] Final Prec@1 73.0244%
07/02 08:14:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [174][50/79]	Step 123200	Loss 1.7264	Prec@(1,5) (55.9%, 82.5%)
07/02 08:14:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [174][78/79]	Step 123200	Loss 1.7216	Prec@(1,5) (55.1%, 83.1%)
07/02 08:14:31午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [174/299] Final Prec@1 55.1400%
07/02 08:14:31午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.5400%
07/02 08:14:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][50/703]	Step 123250	lr 0.03769	Loss 0.6872 (0.7615)	Prec@(1,5) (76.8%, 96.7%)	
07/02 08:14:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][100/703]	Step 123300	lr 0.03769	Loss 0.7981 (0.7704)	Prec@(1,5) (76.3%, 96.5%)	
07/02 08:14:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][150/703]	Step 123350	lr 0.03769	Loss 0.8729 (0.7793)	Prec@(1,5) (76.1%, 96.3%)	
07/02 08:14:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][200/703]	Step 123400	lr 0.03769	Loss 0.9003 (0.7812)	Prec@(1,5) (76.0%, 96.3%)	
07/02 08:14:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][250/703]	Step 123450	lr 0.03769	Loss 1.0124 (0.7912)	Prec@(1,5) (75.6%, 96.1%)	
07/02 08:14:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][300/703]	Step 123500	lr 0.03769	Loss 0.8222 (0.7989)	Prec@(1,5) (75.6%, 96.0%)	
07/02 08:14:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][350/703]	Step 123550	lr 0.03769	Loss 0.6496 (0.8057)	Prec@(1,5) (75.3%, 95.9%)	
07/02 08:14:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][400/703]	Step 123600	lr 0.03769	Loss 0.7645 (0.8154)	Prec@(1,5) (75.1%, 95.9%)	
07/02 08:14:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][450/703]	Step 123650	lr 0.03769	Loss 0.8574 (0.8288)	Prec@(1,5) (74.6%, 95.8%)	
07/02 08:15:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][500/703]	Step 123700	lr 0.03769	Loss 1.1178 (0.8377)	Prec@(1,5) (74.4%, 95.7%)	
07/02 08:15:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][550/703]	Step 123750	lr 0.03769	Loss 0.6529 (0.8449)	Prec@(1,5) (74.2%, 95.7%)	
07/02 08:15:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][600/703]	Step 123800	lr 0.03769	Loss 0.9769 (0.8564)	Prec@(1,5) (73.9%, 95.5%)	
07/02 08:15:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][650/703]	Step 123850	lr 0.03769	Loss 0.8726 (0.8641)	Prec@(1,5) (73.7%, 95.4%)	
07/02 08:15:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][700/703]	Step 123900	lr 0.03769	Loss 1.0097 (0.8693)	Prec@(1,5) (73.5%, 95.4%)	
07/02 08:15:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [175][703/703]	Step 123903	lr 0.03769	Loss 1.1146 (0.8691)	Prec@(1,5) (73.5%, 95.4%)	
07/02 08:15:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [175/299] Final Prec@1 73.4778%
07/02 08:15:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [175][50/79]	Step 123904	Loss 1.7505	Prec@(1,5) (56.0%, 82.6%)
07/02 08:15:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [175][78/79]	Step 123904	Loss 1.7553	Prec@(1,5) (55.5%, 82.8%)
07/02 08:15:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [175/299] Final Prec@1 55.4600%
07/02 08:15:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.5400%
07/02 08:15:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][50/703]	Step 123954	lr 0.03719	Loss 0.7281 (0.7684)	Prec@(1,5) (77.4%, 95.8%)	
07/02 08:15:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][100/703]	Step 124004	lr 0.03719	Loss 0.6315 (0.7480)	Prec@(1,5) (77.6%, 96.3%)	
07/02 08:15:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][150/703]	Step 124054	lr 0.03719	Loss 0.8283 (0.7587)	Prec@(1,5) (76.9%, 96.3%)	
07/02 08:15:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][200/703]	Step 124104	lr 0.03719	Loss 0.8350 (0.7765)	Prec@(1,5) (76.2%, 96.1%)	
07/02 08:15:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][250/703]	Step 124154	lr 0.03719	Loss 0.8049 (0.7907)	Prec@(1,5) (75.8%, 96.0%)	
07/02 08:15:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][300/703]	Step 124204	lr 0.03719	Loss 0.7563 (0.7950)	Prec@(1,5) (75.7%, 96.0%)	
07/02 08:15:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][350/703]	Step 124254	lr 0.03719	Loss 0.9311 (0.8093)	Prec@(1,5) (75.2%, 95.9%)	
07/02 08:15:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][400/703]	Step 124304	lr 0.03719	Loss 0.8036 (0.8227)	Prec@(1,5) (74.9%, 95.7%)	
07/02 08:15:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][450/703]	Step 124354	lr 0.03719	Loss 0.9231 (0.8288)	Prec@(1,5) (74.7%, 95.7%)	
07/02 08:15:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][500/703]	Step 124404	lr 0.03719	Loss 0.7373 (0.8337)	Prec@(1,5) (74.5%, 95.7%)	
07/02 08:15:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][550/703]	Step 124454	lr 0.03719	Loss 0.9606 (0.8446)	Prec@(1,5) (74.2%, 95.6%)	
07/02 08:15:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][600/703]	Step 124504	lr 0.03719	Loss 0.9394 (0.8490)	Prec@(1,5) (74.2%, 95.5%)	
07/02 08:15:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][650/703]	Step 124554	lr 0.03719	Loss 0.7696 (0.8565)	Prec@(1,5) (74.0%, 95.4%)	
07/02 08:15:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][700/703]	Step 124604	lr 0.03719	Loss 0.9261 (0.8649)	Prec@(1,5) (73.7%, 95.3%)	
07/02 08:15:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [176][703/703]	Step 124607	lr 0.03719	Loss 0.6045 (0.8642)	Prec@(1,5) (73.7%, 95.4%)	
07/02 08:15:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [176/299] Final Prec@1 73.7289%
07/02 08:16:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [176][50/79]	Step 124608	Loss 1.8043	Prec@(1,5) (54.4%, 82.2%)
07/02 08:16:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [176][78/79]	Step 124608	Loss 1.7823	Prec@(1,5) (54.3%, 82.7%)
07/02 08:16:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [176/299] Final Prec@1 54.3600%
07/02 08:16:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.5400%
07/02 08:16:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][50/703]	Step 124658	lr 0.03669	Loss 0.5602 (0.7658)	Prec@(1,5) (76.3%, 96.6%)	
07/02 08:16:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][100/703]	Step 124708	lr 0.03669	Loss 0.9002 (0.7503)	Prec@(1,5) (77.2%, 96.7%)	
07/02 08:16:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][150/703]	Step 124758	lr 0.03669	Loss 0.7411 (0.7544)	Prec@(1,5) (77.1%, 96.5%)	
07/02 08:16:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][200/703]	Step 124808	lr 0.03669	Loss 1.0024 (0.7647)	Prec@(1,5) (76.8%, 96.5%)	
07/02 08:16:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][250/703]	Step 124858	lr 0.03669	Loss 0.9512 (0.7739)	Prec@(1,5) (76.5%, 96.4%)	
07/02 08:16:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][300/703]	Step 124908	lr 0.03669	Loss 0.8692 (0.7864)	Prec@(1,5) (76.1%, 96.2%)	
07/02 08:16:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][350/703]	Step 124958	lr 0.03669	Loss 0.9091 (0.7998)	Prec@(1,5) (75.6%, 96.1%)	
07/02 08:16:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][400/703]	Step 125008	lr 0.03669	Loss 0.6719 (0.8028)	Prec@(1,5) (75.6%, 96.2%)	
07/02 08:16:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][450/703]	Step 125058	lr 0.03669	Loss 0.6294 (0.8106)	Prec@(1,5) (75.5%, 96.1%)	
07/02 08:16:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][500/703]	Step 125108	lr 0.03669	Loss 0.7609 (0.8218)	Prec@(1,5) (75.1%, 95.9%)	
07/02 08:16:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][550/703]	Step 125158	lr 0.03669	Loss 1.0662 (0.8275)	Prec@(1,5) (74.9%, 95.9%)	
07/02 08:16:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][600/703]	Step 125208	lr 0.03669	Loss 1.0228 (0.8368)	Prec@(1,5) (74.6%, 95.7%)	
07/02 08:16:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][650/703]	Step 125258	lr 0.03669	Loss 0.7792 (0.8458)	Prec@(1,5) (74.4%, 95.6%)	
07/02 08:16:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][700/703]	Step 125308	lr 0.03669	Loss 1.0379 (0.8523)	Prec@(1,5) (74.2%, 95.5%)	
07/02 08:16:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [177][703/703]	Step 125311	lr 0.03669	Loss 0.7314 (0.8521)	Prec@(1,5) (74.2%, 95.5%)	
07/02 08:16:44午後 finetuneTeacher_trainer.py:180 [INFO] Train: [177/299] Final Prec@1 74.1911%
07/02 08:16:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [177][50/79]	Step 125312	Loss 1.8178	Prec@(1,5) (53.7%, 82.2%)
07/02 08:16:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [177][78/79]	Step 125312	Loss 1.8125	Prec@(1,5) (53.9%, 81.9%)
07/02 08:16:45午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [177/299] Final Prec@1 53.9000%
07/02 08:16:45午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.5400%
07/02 08:16:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][50/703]	Step 125362	lr 0.03619	Loss 0.5294 (0.7425)	Prec@(1,5) (77.7%, 97.2%)	
07/02 08:16:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][100/703]	Step 125412	lr 0.03619	Loss 0.6097 (0.7423)	Prec@(1,5) (77.6%, 96.9%)	
07/02 08:16:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][150/703]	Step 125462	lr 0.03619	Loss 0.7264 (0.7566)	Prec@(1,5) (77.3%, 96.6%)	
07/02 08:16:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][200/703]	Step 125512	lr 0.03619	Loss 0.6750 (0.7631)	Prec@(1,5) (77.0%, 96.5%)	
07/02 08:17:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][250/703]	Step 125562	lr 0.03619	Loss 0.8196 (0.7729)	Prec@(1,5) (76.6%, 96.4%)	
07/02 08:17:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][300/703]	Step 125612	lr 0.03619	Loss 1.0112 (0.7788)	Prec@(1,5) (76.5%, 96.2%)	
07/02 08:17:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][350/703]	Step 125662	lr 0.03619	Loss 1.2365 (0.7873)	Prec@(1,5) (76.3%, 96.1%)	
07/02 08:17:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][400/703]	Step 125712	lr 0.03619	Loss 0.5597 (0.7933)	Prec@(1,5) (76.1%, 96.1%)	
07/02 08:17:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][450/703]	Step 125762	lr 0.03619	Loss 0.8981 (0.8051)	Prec@(1,5) (75.8%, 96.0%)	
07/02 08:17:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][500/703]	Step 125812	lr 0.03619	Loss 0.7906 (0.8164)	Prec@(1,5) (75.4%, 95.9%)	
07/02 08:17:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][550/703]	Step 125862	lr 0.03619	Loss 1.2399 (0.8265)	Prec@(1,5) (75.1%, 95.8%)	
07/02 08:17:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][600/703]	Step 125912	lr 0.03619	Loss 0.9690 (0.8369)	Prec@(1,5) (74.7%, 95.6%)	
07/02 08:17:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][650/703]	Step 125962	lr 0.03619	Loss 0.8857 (0.8446)	Prec@(1,5) (74.5%, 95.6%)	
07/02 08:17:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][700/703]	Step 126012	lr 0.03619	Loss 0.7565 (0.8502)	Prec@(1,5) (74.3%, 95.5%)	
07/02 08:17:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [178][703/703]	Step 126015	lr 0.03619	Loss 0.8788 (0.8510)	Prec@(1,5) (74.2%, 95.5%)	
07/02 08:17:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [178/299] Final Prec@1 74.2422%
07/02 08:17:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [178][50/79]	Step 126016	Loss 1.7756	Prec@(1,5) (56.5%, 81.7%)
07/02 08:17:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [178][78/79]	Step 126016	Loss 1.7588	Prec@(1,5) (56.1%, 82.1%)
07/02 08:17:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [178/299] Final Prec@1 56.1600%
07/02 08:17:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.1600%
07/02 08:17:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][50/703]	Step 126066	lr 0.0357	Loss 0.5903 (0.7390)	Prec@(1,5) (77.3%, 96.8%)	
07/02 08:17:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][100/703]	Step 126116	lr 0.0357	Loss 0.7318 (0.7396)	Prec@(1,5) (77.1%, 96.9%)	
07/02 08:17:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][150/703]	Step 126166	lr 0.0357	Loss 0.7887 (0.7418)	Prec@(1,5) (77.3%, 96.8%)	
07/02 08:17:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][200/703]	Step 126216	lr 0.0357	Loss 0.5179 (0.7481)	Prec@(1,5) (77.1%, 96.7%)	
07/02 08:17:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][250/703]	Step 126266	lr 0.0357	Loss 0.6868 (0.7547)	Prec@(1,5) (76.9%, 96.7%)	
07/02 08:17:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][300/703]	Step 126316	lr 0.0357	Loss 0.9819 (0.7637)	Prec@(1,5) (76.6%, 96.5%)	
07/02 08:17:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][350/703]	Step 126366	lr 0.0357	Loss 0.8656 (0.7775)	Prec@(1,5) (76.2%, 96.4%)	
07/02 08:17:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][400/703]	Step 126416	lr 0.0357	Loss 0.8450 (0.7849)	Prec@(1,5) (76.0%, 96.3%)	
07/02 08:17:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][450/703]	Step 126466	lr 0.0357	Loss 0.9568 (0.7948)	Prec@(1,5) (75.6%, 96.2%)	
07/02 08:18:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][500/703]	Step 126516	lr 0.0357	Loss 1.2661 (0.7999)	Prec@(1,5) (75.5%, 96.1%)	
07/02 08:18:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][550/703]	Step 126566	lr 0.0357	Loss 0.8851 (0.8040)	Prec@(1,5) (75.4%, 96.1%)	
07/02 08:18:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][600/703]	Step 126616	lr 0.0357	Loss 1.0638 (0.8083)	Prec@(1,5) (75.3%, 96.0%)	
07/02 08:18:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][650/703]	Step 126666	lr 0.0357	Loss 0.9843 (0.8153)	Prec@(1,5) (75.1%, 95.9%)	
07/02 08:18:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][700/703]	Step 126716	lr 0.0357	Loss 0.7422 (0.8227)	Prec@(1,5) (74.8%, 95.9%)	
07/02 08:18:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [179][703/703]	Step 126719	lr 0.0357	Loss 0.8249 (0.8231)	Prec@(1,5) (74.8%, 95.9%)	
07/02 08:18:13午後 finetuneTeacher_trainer.py:180 [INFO] Train: [179/299] Final Prec@1 74.8267%
07/02 08:18:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [179][50/79]	Step 126720	Loss 1.7638	Prec@(1,5) (55.3%, 83.2%)
07/02 08:18:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [179][78/79]	Step 126720	Loss 1.7783	Prec@(1,5) (55.3%, 83.0%)
07/02 08:18:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [179/299] Final Prec@1 55.2800%
07/02 08:18:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.1600%
07/02 08:18:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][50/703]	Step 126770	lr 0.0352	Loss 0.5937 (0.7000)	Prec@(1,5) (78.6%, 97.0%)	
07/02 08:18:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][100/703]	Step 126820	lr 0.0352	Loss 0.7595 (0.7128)	Prec@(1,5) (78.3%, 96.7%)	
07/02 08:18:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][150/703]	Step 126870	lr 0.0352	Loss 0.6849 (0.7349)	Prec@(1,5) (77.7%, 96.6%)	
07/02 08:18:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][200/703]	Step 126920	lr 0.0352	Loss 0.6431 (0.7424)	Prec@(1,5) (77.5%, 96.7%)	
07/02 08:18:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][250/703]	Step 126970	lr 0.0352	Loss 0.8198 (0.7433)	Prec@(1,5) (77.4%, 96.7%)	
07/02 08:18:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][300/703]	Step 127020	lr 0.0352	Loss 0.7210 (0.7566)	Prec@(1,5) (77.0%, 96.6%)	
07/02 08:18:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][350/703]	Step 127070	lr 0.0352	Loss 0.7157 (0.7681)	Prec@(1,5) (76.6%, 96.5%)	
07/02 08:18:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][400/703]	Step 127120	lr 0.0352	Loss 0.9704 (0.7805)	Prec@(1,5) (76.2%, 96.4%)	
07/02 08:18:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][450/703]	Step 127170	lr 0.0352	Loss 0.6007 (0.7842)	Prec@(1,5) (76.1%, 96.4%)	
07/02 08:18:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][500/703]	Step 127220	lr 0.0352	Loss 0.9488 (0.7931)	Prec@(1,5) (75.8%, 96.3%)	
07/02 08:18:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][550/703]	Step 127270	lr 0.0352	Loss 1.1022 (0.8021)	Prec@(1,5) (75.5%, 96.2%)	
07/02 08:18:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][600/703]	Step 127320	lr 0.0352	Loss 0.8514 (0.8083)	Prec@(1,5) (75.4%, 96.2%)	
07/02 08:18:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][650/703]	Step 127370	lr 0.0352	Loss 0.7455 (0.8122)	Prec@(1,5) (75.3%, 96.1%)	
07/02 08:18:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][700/703]	Step 127420	lr 0.0352	Loss 0.8110 (0.8156)	Prec@(1,5) (75.1%, 96.0%)	
07/02 08:18:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [180][703/703]	Step 127423	lr 0.0352	Loss 0.8909 (0.8156)	Prec@(1,5) (75.1%, 96.0%)	
07/02 08:18:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [180/299] Final Prec@1 75.1200%
07/02 08:18:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [180][50/79]	Step 127424	Loss 1.7752	Prec@(1,5) (56.6%, 82.7%)
07/02 08:18:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [180][78/79]	Step 127424	Loss 1.7483	Prec@(1,5) (56.6%, 83.1%)
07/02 08:18:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [180/299] Final Prec@1 56.5800%
07/02 08:18:58午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:19:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][50/703]	Step 127474	lr 0.03471	Loss 0.9273 (0.7154)	Prec@(1,5) (78.4%, 96.7%)	
07/02 08:19:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][100/703]	Step 127524	lr 0.03471	Loss 0.5836 (0.7151)	Prec@(1,5) (78.1%, 97.0%)	
07/02 08:19:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][150/703]	Step 127574	lr 0.03471	Loss 0.9634 (0.7319)	Prec@(1,5) (77.4%, 96.9%)	
07/02 08:19:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][200/703]	Step 127624	lr 0.03471	Loss 0.9518 (0.7397)	Prec@(1,5) (77.1%, 96.8%)	
07/02 08:19:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][250/703]	Step 127674	lr 0.03471	Loss 0.8734 (0.7462)	Prec@(1,5) (77.0%, 96.8%)	
07/02 08:19:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][300/703]	Step 127724	lr 0.03471	Loss 0.9558 (0.7483)	Prec@(1,5) (76.9%, 96.7%)	
07/02 08:19:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][350/703]	Step 127774	lr 0.03471	Loss 0.7024 (0.7593)	Prec@(1,5) (76.7%, 96.6%)	
07/02 08:19:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][400/703]	Step 127824	lr 0.03471	Loss 0.7295 (0.7651)	Prec@(1,5) (76.5%, 96.6%)	
07/02 08:19:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][450/703]	Step 127874	lr 0.03471	Loss 0.9730 (0.7717)	Prec@(1,5) (76.3%, 96.5%)	
07/02 08:19:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][500/703]	Step 127924	lr 0.03471	Loss 1.0139 (0.7836)	Prec@(1,5) (76.0%, 96.3%)	
07/02 08:19:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][550/703]	Step 127974	lr 0.03471	Loss 0.6662 (0.7909)	Prec@(1,5) (75.8%, 96.3%)	
07/02 08:19:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][600/703]	Step 128024	lr 0.03471	Loss 0.6413 (0.7979)	Prec@(1,5) (75.6%, 96.2%)	
07/02 08:19:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][650/703]	Step 128074	lr 0.03471	Loss 1.1138 (0.8027)	Prec@(1,5) (75.5%, 96.2%)	
07/02 08:19:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][700/703]	Step 128124	lr 0.03471	Loss 1.2432 (0.8104)	Prec@(1,5) (75.2%, 96.1%)	
07/02 08:19:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [181][703/703]	Step 128127	lr 0.03471	Loss 0.8949 (0.8105)	Prec@(1,5) (75.3%, 96.1%)	
07/02 08:19:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [181/299] Final Prec@1 75.2444%
07/02 08:19:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [181][50/79]	Step 128128	Loss 1.7495	Prec@(1,5) (56.0%, 82.8%)
07/02 08:19:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [181][78/79]	Step 128128	Loss 1.7458	Prec@(1,5) (55.9%, 82.9%)
07/02 08:19:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [181/299] Final Prec@1 55.9400%
07/02 08:19:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:19:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][50/703]	Step 128178	lr 0.03422	Loss 0.6102 (0.7338)	Prec@(1,5) (77.4%, 97.2%)	
07/02 08:19:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][100/703]	Step 128228	lr 0.03422	Loss 0.8900 (0.7137)	Prec@(1,5) (78.1%, 97.2%)	
07/02 08:19:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][150/703]	Step 128278	lr 0.03422	Loss 0.7634 (0.7084)	Prec@(1,5) (78.3%, 97.2%)	
07/02 08:19:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][200/703]	Step 128328	lr 0.03422	Loss 0.7296 (0.7164)	Prec@(1,5) (78.1%, 97.2%)	
07/02 08:19:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][250/703]	Step 128378	lr 0.03422	Loss 0.5665 (0.7321)	Prec@(1,5) (77.6%, 97.0%)	
07/02 08:20:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][300/703]	Step 128428	lr 0.03422	Loss 0.7120 (0.7382)	Prec@(1,5) (77.3%, 96.9%)	
07/02 08:20:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][350/703]	Step 128478	lr 0.03422	Loss 0.8299 (0.7477)	Prec@(1,5) (77.1%, 96.8%)	
07/02 08:20:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][400/703]	Step 128528	lr 0.03422	Loss 0.6906 (0.7568)	Prec@(1,5) (76.8%, 96.7%)	
07/02 08:20:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][450/703]	Step 128578	lr 0.03422	Loss 0.7196 (0.7642)	Prec@(1,5) (76.6%, 96.6%)	
07/02 08:20:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][500/703]	Step 128628	lr 0.03422	Loss 1.0238 (0.7722)	Prec@(1,5) (76.3%, 96.6%)	
07/02 08:20:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][550/703]	Step 128678	lr 0.03422	Loss 0.8646 (0.7787)	Prec@(1,5) (76.2%, 96.5%)	
07/02 08:20:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][600/703]	Step 128728	lr 0.03422	Loss 0.4404 (0.7838)	Prec@(1,5) (76.0%, 96.4%)	
07/02 08:20:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][650/703]	Step 128778	lr 0.03422	Loss 0.9458 (0.7886)	Prec@(1,5) (75.8%, 96.4%)	
07/02 08:20:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][700/703]	Step 128828	lr 0.03422	Loss 0.8105 (0.7973)	Prec@(1,5) (75.5%, 96.3%)	
07/02 08:20:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [182][703/703]	Step 128831	lr 0.03422	Loss 0.8437 (0.7975)	Prec@(1,5) (75.5%, 96.3%)	
07/02 08:20:25午後 finetuneTeacher_trainer.py:180 [INFO] Train: [182/299] Final Prec@1 75.5000%
07/02 08:20:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [182][50/79]	Step 128832	Loss 1.8234	Prec@(1,5) (55.2%, 83.1%)
07/02 08:20:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [182][78/79]	Step 128832	Loss 1.8200	Prec@(1,5) (55.2%, 83.1%)
07/02 08:20:27午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [182/299] Final Prec@1 55.2200%
07/02 08:20:27午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:20:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][50/703]	Step 128882	lr 0.03373	Loss 0.6261 (0.7161)	Prec@(1,5) (78.2%, 97.0%)	
07/02 08:20:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][100/703]	Step 128932	lr 0.03373	Loss 0.7423 (0.7111)	Prec@(1,5) (78.3%, 97.2%)	
07/02 08:20:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][150/703]	Step 128982	lr 0.03373	Loss 0.8333 (0.7190)	Prec@(1,5) (77.9%, 97.0%)	
07/02 08:20:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][200/703]	Step 129032	lr 0.03373	Loss 0.7938 (0.7259)	Prec@(1,5) (77.6%, 97.1%)	
07/02 08:20:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][250/703]	Step 129082	lr 0.03373	Loss 0.5225 (0.7243)	Prec@(1,5) (77.6%, 97.1%)	
07/02 08:20:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][300/703]	Step 129132	lr 0.03373	Loss 0.6392 (0.7269)	Prec@(1,5) (77.5%, 97.0%)	
07/02 08:20:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][350/703]	Step 129182	lr 0.03373	Loss 0.9203 (0.7386)	Prec@(1,5) (77.2%, 96.9%)	
07/02 08:20:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][400/703]	Step 129232	lr 0.03373	Loss 0.6171 (0.7427)	Prec@(1,5) (77.0%, 96.9%)	
07/02 08:20:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][450/703]	Step 129282	lr 0.03373	Loss 0.7357 (0.7538)	Prec@(1,5) (76.6%, 96.7%)	
07/02 08:20:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][500/703]	Step 129332	lr 0.03373	Loss 0.9745 (0.7625)	Prec@(1,5) (76.4%, 96.6%)	
07/02 08:21:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][550/703]	Step 129382	lr 0.03373	Loss 1.0937 (0.7665)	Prec@(1,5) (76.3%, 96.5%)	
07/02 08:21:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][600/703]	Step 129432	lr 0.03373	Loss 0.6636 (0.7766)	Prec@(1,5) (76.0%, 96.4%)	
07/02 08:21:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][650/703]	Step 129482	lr 0.03373	Loss 0.8931 (0.7814)	Prec@(1,5) (75.8%, 96.4%)	
07/02 08:21:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][700/703]	Step 129532	lr 0.03373	Loss 1.0362 (0.7897)	Prec@(1,5) (75.6%, 96.3%)	
07/02 08:21:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [183][703/703]	Step 129535	lr 0.03373	Loss 0.9445 (0.7900)	Prec@(1,5) (75.6%, 96.3%)	
07/02 08:21:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [183/299] Final Prec@1 75.5756%
07/02 08:21:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [183][50/79]	Step 129536	Loss 1.7633	Prec@(1,5) (56.0%, 83.6%)
07/02 08:21:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [183][78/79]	Step 129536	Loss 1.7830	Prec@(1,5) (55.9%, 83.4%)
07/02 08:21:11午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [183/299] Final Prec@1 55.8600%
07/02 08:21:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:21:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][50/703]	Step 129586	lr 0.03325	Loss 0.5138 (0.6892)	Prec@(1,5) (78.9%, 97.2%)	
07/02 08:21:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][100/703]	Step 129636	lr 0.03325	Loss 0.8689 (0.6817)	Prec@(1,5) (79.1%, 97.2%)	
07/02 08:21:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][150/703]	Step 129686	lr 0.03325	Loss 0.4797 (0.6773)	Prec@(1,5) (79.3%, 97.3%)	
07/02 08:21:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][200/703]	Step 129736	lr 0.03325	Loss 0.8484 (0.6892)	Prec@(1,5) (78.9%, 97.2%)	
07/02 08:21:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][250/703]	Step 129786	lr 0.03325	Loss 0.8219 (0.6990)	Prec@(1,5) (78.5%, 97.2%)	
07/02 08:21:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][300/703]	Step 129836	lr 0.03325	Loss 0.8218 (0.7121)	Prec@(1,5) (78.3%, 97.0%)	
07/02 08:21:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][350/703]	Step 129886	lr 0.03325	Loss 0.6557 (0.7134)	Prec@(1,5) (78.2%, 97.0%)	
07/02 08:21:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][400/703]	Step 129936	lr 0.03325	Loss 0.9295 (0.7290)	Prec@(1,5) (77.7%, 96.8%)	
07/02 08:21:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][450/703]	Step 129986	lr 0.03325	Loss 0.7416 (0.7401)	Prec@(1,5) (77.3%, 96.7%)	
07/02 08:21:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][500/703]	Step 130036	lr 0.03325	Loss 0.7040 (0.7512)	Prec@(1,5) (77.0%, 96.5%)	
07/02 08:21:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][550/703]	Step 130086	lr 0.03325	Loss 0.6604 (0.7583)	Prec@(1,5) (76.8%, 96.4%)	
07/02 08:21:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][600/703]	Step 130136	lr 0.03325	Loss 0.8056 (0.7686)	Prec@(1,5) (76.4%, 96.4%)	
07/02 08:21:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][650/703]	Step 130186	lr 0.03325	Loss 0.8546 (0.7768)	Prec@(1,5) (76.1%, 96.3%)	
07/02 08:21:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][700/703]	Step 130236	lr 0.03325	Loss 0.5650 (0.7806)	Prec@(1,5) (76.0%, 96.3%)	
07/02 08:21:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [184][703/703]	Step 130239	lr 0.03325	Loss 1.0032 (0.7817)	Prec@(1,5) (76.0%, 96.3%)	
07/02 08:21:55午後 finetuneTeacher_trainer.py:180 [INFO] Train: [184/299] Final Prec@1 75.9600%
07/02 08:21:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [184][50/79]	Step 130240	Loss 1.7534	Prec@(1,5) (55.2%, 83.1%)
07/02 08:21:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [184][78/79]	Step 130240	Loss 1.7454	Prec@(1,5) (55.6%, 83.8%)
07/02 08:21:56午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [184/299] Final Prec@1 55.6000%
07/02 08:21:56午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:22:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][50/703]	Step 130290	lr 0.03276	Loss 0.5693 (0.6564)	Prec@(1,5) (80.1%, 97.9%)	
07/02 08:22:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][100/703]	Step 130340	lr 0.03276	Loss 0.7741 (0.6644)	Prec@(1,5) (79.6%, 97.4%)	
07/02 08:22:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][150/703]	Step 130390	lr 0.03276	Loss 0.7148 (0.6795)	Prec@(1,5) (78.9%, 97.3%)	
07/02 08:22:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][200/703]	Step 130440	lr 0.03276	Loss 0.6554 (0.6775)	Prec@(1,5) (79.0%, 97.5%)	
07/02 08:22:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][250/703]	Step 130490	lr 0.03276	Loss 0.6462 (0.6864)	Prec@(1,5) (78.8%, 97.4%)	
07/02 08:22:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][300/703]	Step 130540	lr 0.03276	Loss 0.5778 (0.6971)	Prec@(1,5) (78.6%, 97.3%)	
07/02 08:22:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][350/703]	Step 130590	lr 0.03276	Loss 0.8377 (0.7073)	Prec@(1,5) (78.3%, 97.1%)	
07/02 08:22:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][400/703]	Step 130640	lr 0.03276	Loss 1.0365 (0.7171)	Prec@(1,5) (78.1%, 97.0%)	
07/02 08:22:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][450/703]	Step 130690	lr 0.03276	Loss 0.9373 (0.7311)	Prec@(1,5) (77.6%, 96.9%)	
07/02 08:22:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][500/703]	Step 130740	lr 0.03276	Loss 0.8957 (0.7380)	Prec@(1,5) (77.3%, 96.8%)	
07/02 08:22:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][550/703]	Step 130790	lr 0.03276	Loss 0.9255 (0.7489)	Prec@(1,5) (77.0%, 96.7%)	
07/02 08:22:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][600/703]	Step 130840	lr 0.03276	Loss 0.8352 (0.7549)	Prec@(1,5) (76.9%, 96.7%)	
07/02 08:22:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][650/703]	Step 130890	lr 0.03276	Loss 0.5865 (0.7621)	Prec@(1,5) (76.7%, 96.5%)	
07/02 08:22:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][700/703]	Step 130940	lr 0.03276	Loss 0.8565 (0.7699)	Prec@(1,5) (76.4%, 96.5%)	
07/02 08:22:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [185][703/703]	Step 130943	lr 0.03276	Loss 0.9751 (0.7706)	Prec@(1,5) (76.4%, 96.5%)	
07/02 08:22:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [185/299] Final Prec@1 76.4200%
07/02 08:22:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [185][50/79]	Step 130944	Loss 1.8396	Prec@(1,5) (53.6%, 81.5%)
07/02 08:22:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [185][78/79]	Step 130944	Loss 1.8577	Prec@(1,5) (53.6%, 81.6%)
07/02 08:22:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [185/299] Final Prec@1 53.6200%
07/02 08:22:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:22:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][50/703]	Step 130994	lr 0.03228	Loss 0.5242 (0.6658)	Prec@(1,5) (80.2%, 97.7%)	
07/02 08:22:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][100/703]	Step 131044	lr 0.03228	Loss 0.7076 (0.6707)	Prec@(1,5) (79.8%, 97.5%)	
07/02 08:22:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][150/703]	Step 131094	lr 0.03228	Loss 0.5806 (0.6673)	Prec@(1,5) (79.8%, 97.4%)	
07/02 08:22:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][200/703]	Step 131144	lr 0.03228	Loss 0.7529 (0.6761)	Prec@(1,5) (79.5%, 97.4%)	
07/02 08:22:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][250/703]	Step 131194	lr 0.03228	Loss 0.8835 (0.6751)	Prec@(1,5) (79.4%, 97.4%)	
07/02 08:23:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][300/703]	Step 131244	lr 0.03228	Loss 0.6739 (0.6766)	Prec@(1,5) (79.2%, 97.5%)	
07/02 08:23:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][350/703]	Step 131294	lr 0.03228	Loss 0.7057 (0.6912)	Prec@(1,5) (78.9%, 97.3%)	
07/02 08:23:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][400/703]	Step 131344	lr 0.03228	Loss 0.6705 (0.7005)	Prec@(1,5) (78.6%, 97.2%)	
07/02 08:23:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][450/703]	Step 131394	lr 0.03228	Loss 0.6716 (0.7052)	Prec@(1,5) (78.5%, 97.1%)	
07/02 08:23:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][500/703]	Step 131444	lr 0.03228	Loss 0.8468 (0.7160)	Prec@(1,5) (78.2%, 96.9%)	
07/02 08:23:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][550/703]	Step 131494	lr 0.03228	Loss 0.7180 (0.7264)	Prec@(1,5) (77.8%, 96.8%)	
07/02 08:23:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][600/703]	Step 131544	lr 0.03228	Loss 0.6972 (0.7351)	Prec@(1,5) (77.5%, 96.8%)	
07/02 08:23:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][650/703]	Step 131594	lr 0.03228	Loss 0.9171 (0.7417)	Prec@(1,5) (77.2%, 96.7%)	
07/02 08:23:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][700/703]	Step 131644	lr 0.03228	Loss 0.9135 (0.7501)	Prec@(1,5) (77.0%, 96.6%)	
07/02 08:23:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [186][703/703]	Step 131647	lr 0.03228	Loss 0.9761 (0.7505)	Prec@(1,5) (77.0%, 96.6%)	
07/02 08:23:26午後 finetuneTeacher_trainer.py:180 [INFO] Train: [186/299] Final Prec@1 76.9889%
07/02 08:23:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [186][50/79]	Step 131648	Loss 1.8041	Prec@(1,5) (55.3%, 82.5%)
07/02 08:23:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [186][78/79]	Step 131648	Loss 1.7609	Prec@(1,5) (55.7%, 83.1%)
07/02 08:23:27午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [186/299] Final Prec@1 55.7000%
07/02 08:23:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:23:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][50/703]	Step 131698	lr 0.0318	Loss 0.4436 (0.6477)	Prec@(1,5) (79.9%, 97.5%)	
07/02 08:23:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][100/703]	Step 131748	lr 0.0318	Loss 0.5928 (0.6681)	Prec@(1,5) (79.5%, 97.2%)	
07/02 08:23:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][150/703]	Step 131798	lr 0.0318	Loss 0.6817 (0.6676)	Prec@(1,5) (79.7%, 97.2%)	
07/02 08:23:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][200/703]	Step 131848	lr 0.0318	Loss 0.8219 (0.6663)	Prec@(1,5) (79.6%, 97.3%)	
07/02 08:23:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][250/703]	Step 131898	lr 0.0318	Loss 0.9549 (0.6718)	Prec@(1,5) (79.3%, 97.4%)	
07/02 08:23:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][300/703]	Step 131948	lr 0.0318	Loss 1.1055 (0.6813)	Prec@(1,5) (79.1%, 97.4%)	
07/02 08:23:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][350/703]	Step 131998	lr 0.0318	Loss 0.6410 (0.6888)	Prec@(1,5) (78.8%, 97.3%)	
07/02 08:23:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][400/703]	Step 132048	lr 0.0318	Loss 0.8619 (0.7033)	Prec@(1,5) (78.3%, 97.1%)	
07/02 08:23:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][450/703]	Step 132098	lr 0.0318	Loss 0.7362 (0.7095)	Prec@(1,5) (78.0%, 97.1%)	
07/02 08:23:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][500/703]	Step 132148	lr 0.0318	Loss 0.6616 (0.7245)	Prec@(1,5) (77.6%, 97.0%)	
07/02 08:24:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][550/703]	Step 132198	lr 0.0318	Loss 0.7239 (0.7285)	Prec@(1,5) (77.5%, 96.9%)	
07/02 08:24:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][600/703]	Step 132248	lr 0.0318	Loss 0.8300 (0.7338)	Prec@(1,5) (77.3%, 96.8%)	
07/02 08:24:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][650/703]	Step 132298	lr 0.0318	Loss 0.6865 (0.7406)	Prec@(1,5) (77.0%, 96.8%)	
07/02 08:24:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][700/703]	Step 132348	lr 0.0318	Loss 0.9915 (0.7498)	Prec@(1,5) (76.8%, 96.7%)	
07/02 08:24:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [187][703/703]	Step 132351	lr 0.0318	Loss 0.7519 (0.7505)	Prec@(1,5) (76.8%, 96.6%)	
07/02 08:24:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [187/299] Final Prec@1 76.8267%
07/02 08:24:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [187][50/79]	Step 132352	Loss 1.7742	Prec@(1,5) (55.0%, 83.5%)
07/02 08:24:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [187][78/79]	Step 132352	Loss 1.7354	Prec@(1,5) (55.5%, 83.8%)
07/02 08:24:13午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [187/299] Final Prec@1 55.4400%
07/02 08:24:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:24:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][50/703]	Step 132402	lr 0.03132	Loss 0.5661 (0.6516)	Prec@(1,5) (80.4%, 98.0%)	
07/02 08:24:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][100/703]	Step 132452	lr 0.03132	Loss 0.7314 (0.6299)	Prec@(1,5) (81.2%, 97.9%)	
07/02 08:24:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][150/703]	Step 132502	lr 0.03132	Loss 0.6377 (0.6408)	Prec@(1,5) (80.9%, 97.7%)	
07/02 08:24:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][200/703]	Step 132552	lr 0.03132	Loss 0.4776 (0.6466)	Prec@(1,5) (80.5%, 97.7%)	
07/02 08:24:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][250/703]	Step 132602	lr 0.03132	Loss 0.7514 (0.6573)	Prec@(1,5) (80.3%, 97.5%)	
07/02 08:24:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][300/703]	Step 132652	lr 0.03132	Loss 0.5145 (0.6688)	Prec@(1,5) (79.8%, 97.5%)	
07/02 08:24:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][350/703]	Step 132702	lr 0.03132	Loss 0.8971 (0.6859)	Prec@(1,5) (79.1%, 97.4%)	
07/02 08:24:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][400/703]	Step 132752	lr 0.03132	Loss 0.6683 (0.6897)	Prec@(1,5) (79.1%, 97.3%)	
07/02 08:24:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][450/703]	Step 132802	lr 0.03132	Loss 0.7167 (0.6945)	Prec@(1,5) (78.9%, 97.2%)	
07/02 08:24:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][500/703]	Step 132852	lr 0.03132	Loss 1.0248 (0.7003)	Prec@(1,5) (78.6%, 97.2%)	
07/02 08:24:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][550/703]	Step 132902	lr 0.03132	Loss 0.9304 (0.7065)	Prec@(1,5) (78.4%, 97.1%)	
07/02 08:24:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][600/703]	Step 132952	lr 0.03132	Loss 0.8160 (0.7132)	Prec@(1,5) (78.2%, 97.0%)	
07/02 08:24:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][650/703]	Step 133002	lr 0.03132	Loss 0.7504 (0.7225)	Prec@(1,5) (77.9%, 96.9%)	
07/02 08:24:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][700/703]	Step 133052	lr 0.03132	Loss 0.6436 (0.7291)	Prec@(1,5) (77.7%, 96.9%)	
07/02 08:24:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [188][703/703]	Step 133055	lr 0.03132	Loss 1.0759 (0.7299)	Prec@(1,5) (77.7%, 96.9%)	
07/02 08:24:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [188/299] Final Prec@1 77.6800%
07/02 08:24:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [188][50/79]	Step 133056	Loss 1.7682	Prec@(1,5) (55.3%, 84.3%)
07/02 08:24:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [188][78/79]	Step 133056	Loss 1.7627	Prec@(1,5) (55.6%, 84.1%)
07/02 08:24:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [188/299] Final Prec@1 55.6200%
07/02 08:24:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:25:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][50/703]	Step 133106	lr 0.03084	Loss 0.7073 (0.6534)	Prec@(1,5) (79.8%, 98.0%)	
07/02 08:25:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][100/703]	Step 133156	lr 0.03084	Loss 0.7775 (0.6365)	Prec@(1,5) (80.5%, 97.9%)	
07/02 08:25:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][150/703]	Step 133206	lr 0.03084	Loss 0.6594 (0.6410)	Prec@(1,5) (80.3%, 97.8%)	
07/02 08:25:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][200/703]	Step 133256	lr 0.03084	Loss 0.6058 (0.6495)	Prec@(1,5) (80.0%, 97.7%)	
07/02 08:25:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][250/703]	Step 133306	lr 0.03084	Loss 0.4177 (0.6545)	Prec@(1,5) (79.7%, 97.7%)	
07/02 08:25:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][300/703]	Step 133356	lr 0.03084	Loss 0.9214 (0.6673)	Prec@(1,5) (79.2%, 97.6%)	
07/02 08:25:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][350/703]	Step 133406	lr 0.03084	Loss 0.8090 (0.6799)	Prec@(1,5) (78.8%, 97.4%)	
07/02 08:25:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][400/703]	Step 133456	lr 0.03084	Loss 0.7946 (0.6927)	Prec@(1,5) (78.4%, 97.3%)	
07/02 08:25:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][450/703]	Step 133506	lr 0.03084	Loss 0.8771 (0.7025)	Prec@(1,5) (78.2%, 97.1%)	
07/02 08:25:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][500/703]	Step 133556	lr 0.03084	Loss 0.7198 (0.7105)	Prec@(1,5) (78.0%, 97.0%)	
07/02 08:25:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][550/703]	Step 133606	lr 0.03084	Loss 0.9035 (0.7177)	Prec@(1,5) (77.8%, 97.0%)	
07/02 08:25:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][600/703]	Step 133656	lr 0.03084	Loss 0.8198 (0.7242)	Prec@(1,5) (77.6%, 96.9%)	
07/02 08:25:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][650/703]	Step 133706	lr 0.03084	Loss 0.8049 (0.7339)	Prec@(1,5) (77.3%, 96.8%)	
07/02 08:25:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][700/703]	Step 133756	lr 0.03084	Loss 0.8596 (0.7401)	Prec@(1,5) (77.1%, 96.7%)	
07/02 08:25:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [189][703/703]	Step 133759	lr 0.03084	Loss 0.7781 (0.7405)	Prec@(1,5) (77.1%, 96.8%)	
07/02 08:25:42午後 finetuneTeacher_trainer.py:180 [INFO] Train: [189/299] Final Prec@1 77.1356%
07/02 08:25:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [189][50/79]	Step 133760	Loss 1.7883	Prec@(1,5) (55.4%, 83.6%)
07/02 08:25:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [189][78/79]	Step 133760	Loss 1.8091	Prec@(1,5) (54.9%, 83.2%)
07/02 08:25:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [189/299] Final Prec@1 54.8600%
07/02 08:25:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:25:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][50/703]	Step 133810	lr 0.03037	Loss 0.5795 (0.6185)	Prec@(1,5) (81.2%, 98.0%)	
07/02 08:25:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][100/703]	Step 133860	lr 0.03037	Loss 0.7723 (0.6422)	Prec@(1,5) (80.2%, 97.7%)	
07/02 08:25:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][150/703]	Step 133910	lr 0.03037	Loss 0.4662 (0.6423)	Prec@(1,5) (80.2%, 97.6%)	
07/02 08:25:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][200/703]	Step 133960	lr 0.03037	Loss 0.6623 (0.6613)	Prec@(1,5) (79.6%, 97.5%)	
07/02 08:25:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][250/703]	Step 134010	lr 0.03037	Loss 0.4640 (0.6631)	Prec@(1,5) (79.5%, 97.4%)	
07/02 08:26:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][300/703]	Step 134060	lr 0.03037	Loss 0.6339 (0.6655)	Prec@(1,5) (79.4%, 97.4%)	
07/02 08:26:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][350/703]	Step 134110	lr 0.03037	Loss 0.7696 (0.6704)	Prec@(1,5) (79.2%, 97.4%)	
07/02 08:26:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][400/703]	Step 134160	lr 0.03037	Loss 0.6604 (0.6805)	Prec@(1,5) (78.9%, 97.3%)	
07/02 08:26:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][450/703]	Step 134210	lr 0.03037	Loss 0.6933 (0.6880)	Prec@(1,5) (78.7%, 97.2%)	
07/02 08:26:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][500/703]	Step 134260	lr 0.03037	Loss 0.7118 (0.6908)	Prec@(1,5) (78.5%, 97.2%)	
07/02 08:26:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][550/703]	Step 134310	lr 0.03037	Loss 0.9808 (0.7018)	Prec@(1,5) (78.2%, 97.1%)	
07/02 08:26:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][600/703]	Step 134360	lr 0.03037	Loss 1.0498 (0.7101)	Prec@(1,5) (78.0%, 97.0%)	
07/02 08:26:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][650/703]	Step 134410	lr 0.03037	Loss 0.7563 (0.7154)	Prec@(1,5) (77.8%, 97.0%)	
07/02 08:26:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][700/703]	Step 134460	lr 0.03037	Loss 0.8829 (0.7210)	Prec@(1,5) (77.6%, 97.0%)	
07/02 08:26:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [190][703/703]	Step 134463	lr 0.03037	Loss 0.9824 (0.7215)	Prec@(1,5) (77.6%, 97.0%)	
07/02 08:26:26午後 finetuneTeacher_trainer.py:180 [INFO] Train: [190/299] Final Prec@1 77.5844%
07/02 08:26:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [190][50/79]	Step 134464	Loss 1.7579	Prec@(1,5) (55.9%, 83.5%)
07/02 08:26:27午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [190][78/79]	Step 134464	Loss 1.7573	Prec@(1,5) (56.1%, 83.1%)
07/02 08:26:27午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [190/299] Final Prec@1 56.1400%
07/02 08:26:27午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:26:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][50/703]	Step 134514	lr 0.02989	Loss 0.6209 (0.6285)	Prec@(1,5) (80.6%, 97.9%)	
07/02 08:26:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][100/703]	Step 134564	lr 0.02989	Loss 0.5515 (0.6202)	Prec@(1,5) (80.8%, 98.0%)	
07/02 08:26:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][150/703]	Step 134614	lr 0.02989	Loss 0.8927 (0.6263)	Prec@(1,5) (80.4%, 98.0%)	
07/02 08:26:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][200/703]	Step 134664	lr 0.02989	Loss 0.6796 (0.6342)	Prec@(1,5) (80.2%, 97.9%)	
07/02 08:26:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][250/703]	Step 134714	lr 0.02989	Loss 0.5574 (0.6371)	Prec@(1,5) (80.1%, 97.8%)	
07/02 08:26:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][300/703]	Step 134764	lr 0.02989	Loss 0.7942 (0.6434)	Prec@(1,5) (79.9%, 97.7%)	
07/02 08:26:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][350/703]	Step 134814	lr 0.02989	Loss 0.6164 (0.6540)	Prec@(1,5) (79.6%, 97.6%)	
07/02 08:26:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][400/703]	Step 134864	lr 0.02989	Loss 0.7078 (0.6651)	Prec@(1,5) (79.1%, 97.5%)	
07/02 08:26:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][450/703]	Step 134914	lr 0.02989	Loss 0.6517 (0.6724)	Prec@(1,5) (78.9%, 97.4%)	
07/02 08:26:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][500/703]	Step 134964	lr 0.02989	Loss 0.8218 (0.6808)	Prec@(1,5) (78.7%, 97.3%)	
07/02 08:27:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][550/703]	Step 135014	lr 0.02989	Loss 0.6171 (0.6834)	Prec@(1,5) (78.7%, 97.3%)	
07/02 08:27:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][600/703]	Step 135064	lr 0.02989	Loss 0.7411 (0.6919)	Prec@(1,5) (78.4%, 97.2%)	
07/02 08:27:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][650/703]	Step 135114	lr 0.02989	Loss 0.6191 (0.6968)	Prec@(1,5) (78.3%, 97.2%)	
07/02 08:27:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][700/703]	Step 135164	lr 0.02989	Loss 0.5699 (0.7035)	Prec@(1,5) (78.1%, 97.1%)	
07/02 08:27:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [191][703/703]	Step 135167	lr 0.02989	Loss 1.0932 (0.7042)	Prec@(1,5) (78.1%, 97.1%)	
07/02 08:27:10午後 finetuneTeacher_trainer.py:180 [INFO] Train: [191/299] Final Prec@1 78.0667%
07/02 08:27:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [191][50/79]	Step 135168	Loss 1.7841	Prec@(1,5) (55.4%, 83.2%)
07/02 08:27:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [191][78/79]	Step 135168	Loss 1.7713	Prec@(1,5) (56.0%, 83.5%)
07/02 08:27:11午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [191/299] Final Prec@1 55.9600%
07/02 08:27:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:27:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][50/703]	Step 135218	lr 0.02942	Loss 0.4631 (0.5713)	Prec@(1,5) (82.8%, 98.3%)	
07/02 08:27:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][100/703]	Step 135268	lr 0.02942	Loss 1.0592 (0.5944)	Prec@(1,5) (81.9%, 98.2%)	
07/02 08:27:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][150/703]	Step 135318	lr 0.02942	Loss 0.4630 (0.6176)	Prec@(1,5) (81.3%, 97.9%)	
07/02 08:27:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][200/703]	Step 135368	lr 0.02942	Loss 0.6343 (0.6261)	Prec@(1,5) (81.0%, 97.7%)	
07/02 08:27:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][250/703]	Step 135418	lr 0.02942	Loss 0.6795 (0.6378)	Prec@(1,5) (80.5%, 97.6%)	
07/02 08:27:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][300/703]	Step 135468	lr 0.02942	Loss 0.7244 (0.6414)	Prec@(1,5) (80.3%, 97.6%)	
07/02 08:27:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][350/703]	Step 135518	lr 0.02942	Loss 0.7846 (0.6507)	Prec@(1,5) (79.8%, 97.6%)	
07/02 08:27:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][400/703]	Step 135568	lr 0.02942	Loss 0.8235 (0.6599)	Prec@(1,5) (79.5%, 97.5%)	
07/02 08:27:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][450/703]	Step 135618	lr 0.02942	Loss 0.6793 (0.6645)	Prec@(1,5) (79.3%, 97.5%)	
07/02 08:27:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][500/703]	Step 135668	lr 0.02942	Loss 0.8747 (0.6735)	Prec@(1,5) (79.0%, 97.3%)	
07/02 08:27:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][550/703]	Step 135718	lr 0.02942	Loss 0.6871 (0.6791)	Prec@(1,5) (79.0%, 97.3%)	
07/02 08:27:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][600/703]	Step 135768	lr 0.02942	Loss 0.9319 (0.6863)	Prec@(1,5) (78.7%, 97.2%)	
07/02 08:27:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][650/703]	Step 135818	lr 0.02942	Loss 0.8569 (0.6930)	Prec@(1,5) (78.5%, 97.2%)	
07/02 08:27:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][700/703]	Step 135868	lr 0.02942	Loss 0.6739 (0.7024)	Prec@(1,5) (78.2%, 97.1%)	
07/02 08:27:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [192][703/703]	Step 135871	lr 0.02942	Loss 0.9417 (0.7030)	Prec@(1,5) (78.2%, 97.1%)	
07/02 08:27:54午後 finetuneTeacher_trainer.py:180 [INFO] Train: [192/299] Final Prec@1 78.2156%
07/02 08:27:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [192][50/79]	Step 135872	Loss 1.8098	Prec@(1,5) (55.8%, 83.0%)
07/02 08:27:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [192][78/79]	Step 135872	Loss 1.7788	Prec@(1,5) (56.2%, 83.3%)
07/02 08:27:56午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [192/299] Final Prec@1 56.2000%
07/02 08:27:56午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/02 08:28:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][50/703]	Step 135922	lr 0.02896	Loss 0.5267 (0.6237)	Prec@(1,5) (80.6%, 97.7%)	
07/02 08:28:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][100/703]	Step 135972	lr 0.02896	Loss 0.6329 (0.6058)	Prec@(1,5) (81.0%, 97.9%)	
07/02 08:28:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][150/703]	Step 136022	lr 0.02896	Loss 0.6875 (0.6063)	Prec@(1,5) (81.1%, 97.9%)	
07/02 08:28:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][200/703]	Step 136072	lr 0.02896	Loss 0.6889 (0.6126)	Prec@(1,5) (81.1%, 97.8%)	
07/02 08:28:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][250/703]	Step 136122	lr 0.02896	Loss 0.6471 (0.6185)	Prec@(1,5) (80.8%, 97.8%)	
07/02 08:28:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][300/703]	Step 136172	lr 0.02896	Loss 0.7037 (0.6231)	Prec@(1,5) (80.6%, 97.8%)	
07/02 08:28:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][350/703]	Step 136222	lr 0.02896	Loss 0.3855 (0.6287)	Prec@(1,5) (80.5%, 97.8%)	
07/02 08:28:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][400/703]	Step 136272	lr 0.02896	Loss 0.7044 (0.6323)	Prec@(1,5) (80.4%, 97.8%)	
07/02 08:28:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][450/703]	Step 136322	lr 0.02896	Loss 0.6774 (0.6421)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:28:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][500/703]	Step 136372	lr 0.02896	Loss 0.4399 (0.6528)	Prec@(1,5) (79.7%, 97.5%)	
07/02 08:28:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][550/703]	Step 136422	lr 0.02896	Loss 0.7569 (0.6610)	Prec@(1,5) (79.6%, 97.5%)	
07/02 08:28:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][600/703]	Step 136472	lr 0.02896	Loss 0.5574 (0.6668)	Prec@(1,5) (79.3%, 97.4%)	
07/02 08:28:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][650/703]	Step 136522	lr 0.02896	Loss 0.8706 (0.6733)	Prec@(1,5) (79.1%, 97.4%)	
07/02 08:28:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][700/703]	Step 136572	lr 0.02896	Loss 0.8223 (0.6791)	Prec@(1,5) (78.9%, 97.4%)	
07/02 08:28:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [193][703/703]	Step 136575	lr 0.02896	Loss 0.8417 (0.6796)	Prec@(1,5) (78.9%, 97.4%)	
07/02 08:28:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [193/299] Final Prec@1 78.8889%
07/02 08:28:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [193][50/79]	Step 136576	Loss 1.7048	Prec@(1,5) (57.8%, 84.4%)
07/02 08:28:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [193][78/79]	Step 136576	Loss 1.7125	Prec@(1,5) (57.0%, 84.4%)
07/02 08:28:41午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [193/299] Final Prec@1 56.9600%
07/02 08:28:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.9600%
07/02 08:28:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][50/703]	Step 136626	lr 0.02849	Loss 0.5241 (0.5584)	Prec@(1,5) (83.3%, 98.3%)	
07/02 08:28:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][100/703]	Step 136676	lr 0.02849	Loss 0.6640 (0.5643)	Prec@(1,5) (83.0%, 98.2%)	
07/02 08:28:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][150/703]	Step 136726	lr 0.02849	Loss 0.6301 (0.5666)	Prec@(1,5) (82.7%, 98.3%)	
07/02 08:28:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][200/703]	Step 136776	lr 0.02849	Loss 0.4847 (0.5702)	Prec@(1,5) (82.6%, 98.3%)	
07/02 08:28:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][250/703]	Step 136826	lr 0.02849	Loss 0.7739 (0.5823)	Prec@(1,5) (82.2%, 98.2%)	
07/02 08:29:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][300/703]	Step 136876	lr 0.02849	Loss 0.6431 (0.5918)	Prec@(1,5) (81.8%, 98.1%)	
07/02 08:29:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][350/703]	Step 136926	lr 0.02849	Loss 0.8053 (0.6023)	Prec@(1,5) (81.5%, 97.9%)	
07/02 08:29:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][400/703]	Step 136976	lr 0.02849	Loss 0.8035 (0.6081)	Prec@(1,5) (81.2%, 97.8%)	
07/02 08:29:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][450/703]	Step 137026	lr 0.02849	Loss 0.7535 (0.6109)	Prec@(1,5) (81.1%, 97.8%)	
07/02 08:29:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][500/703]	Step 137076	lr 0.02849	Loss 0.6145 (0.6179)	Prec@(1,5) (80.8%, 97.8%)	
07/02 08:29:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][550/703]	Step 137126	lr 0.02849	Loss 0.6910 (0.6256)	Prec@(1,5) (80.5%, 97.8%)	
07/02 08:29:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][600/703]	Step 137176	lr 0.02849	Loss 0.6898 (0.6338)	Prec@(1,5) (80.3%, 97.7%)	
07/02 08:29:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][650/703]	Step 137226	lr 0.02849	Loss 0.7179 (0.6385)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:29:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][700/703]	Step 137276	lr 0.02849	Loss 0.7475 (0.6463)	Prec@(1,5) (79.9%, 97.6%)	
07/02 08:29:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [194][703/703]	Step 137279	lr 0.02849	Loss 0.7269 (0.6466)	Prec@(1,5) (79.9%, 97.6%)	
07/02 08:29:24午後 finetuneTeacher_trainer.py:180 [INFO] Train: [194/299] Final Prec@1 79.9356%
07/02 08:29:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [194][50/79]	Step 137280	Loss 1.7015	Prec@(1,5) (57.7%, 84.0%)
07/02 08:29:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [194][78/79]	Step 137280	Loss 1.7356	Prec@(1,5) (56.5%, 83.5%)
07/02 08:29:26午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [194/299] Final Prec@1 56.5400%
07/02 08:29:26午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.9600%
07/02 08:29:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][50/703]	Step 137330	lr 0.02803	Loss 0.4184 (0.5957)	Prec@(1,5) (82.4%, 97.7%)	
07/02 08:29:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][100/703]	Step 137380	lr 0.02803	Loss 0.4326 (0.5828)	Prec@(1,5) (82.2%, 98.0%)	
07/02 08:29:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][150/703]	Step 137430	lr 0.02803	Loss 0.5762 (0.5933)	Prec@(1,5) (81.9%, 98.0%)	
07/02 08:29:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][200/703]	Step 137480	lr 0.02803	Loss 0.7399 (0.5878)	Prec@(1,5) (82.0%, 98.0%)	
07/02 08:29:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][250/703]	Step 137530	lr 0.02803	Loss 0.4755 (0.5882)	Prec@(1,5) (81.8%, 98.1%)	
07/02 08:29:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][300/703]	Step 137580	lr 0.02803	Loss 0.5619 (0.5980)	Prec@(1,5) (81.4%, 98.0%)	
07/02 08:29:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][350/703]	Step 137630	lr 0.02803	Loss 0.4895 (0.6063)	Prec@(1,5) (81.1%, 98.0%)	
07/02 08:29:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][400/703]	Step 137680	lr 0.02803	Loss 0.6356 (0.6160)	Prec@(1,5) (80.8%, 97.9%)	
07/02 08:29:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][450/703]	Step 137730	lr 0.02803	Loss 0.7874 (0.6227)	Prec@(1,5) (80.6%, 97.9%)	
07/02 08:29:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][500/703]	Step 137780	lr 0.02803	Loss 0.5588 (0.6265)	Prec@(1,5) (80.4%, 97.8%)	
07/02 08:30:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][550/703]	Step 137830	lr 0.02803	Loss 0.9387 (0.6356)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:30:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][600/703]	Step 137880	lr 0.02803	Loss 0.7292 (0.6411)	Prec@(1,5) (79.9%, 97.7%)	
07/02 08:30:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][650/703]	Step 137930	lr 0.02803	Loss 0.6698 (0.6473)	Prec@(1,5) (79.7%, 97.7%)	
07/02 08:30:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][700/703]	Step 137980	lr 0.02803	Loss 0.8544 (0.6587)	Prec@(1,5) (79.4%, 97.5%)	
07/02 08:30:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [195][703/703]	Step 137983	lr 0.02803	Loss 0.6879 (0.6588)	Prec@(1,5) (79.4%, 97.5%)	
07/02 08:30:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [195/299] Final Prec@1 79.3622%
07/02 08:30:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [195][50/79]	Step 137984	Loss 1.7539	Prec@(1,5) (58.2%, 83.5%)
07/02 08:30:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [195][78/79]	Step 137984	Loss 1.7695	Prec@(1,5) (57.1%, 83.2%)
07/02 08:30:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [195/299] Final Prec@1 57.0800%
07/02 08:30:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.0800%
07/02 08:30:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][50/703]	Step 138034	lr 0.02757	Loss 0.4945 (0.5929)	Prec@(1,5) (81.6%, 98.2%)	
07/02 08:30:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][100/703]	Step 138084	lr 0.02757	Loss 0.6395 (0.5775)	Prec@(1,5) (82.1%, 98.2%)	
07/02 08:30:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][150/703]	Step 138134	lr 0.02757	Loss 0.4674 (0.5681)	Prec@(1,5) (82.4%, 98.2%)	
07/02 08:30:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][200/703]	Step 138184	lr 0.02757	Loss 0.6712 (0.5722)	Prec@(1,5) (82.5%, 98.2%)	
07/02 08:30:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][250/703]	Step 138234	lr 0.02757	Loss 0.6191 (0.5789)	Prec@(1,5) (82.2%, 98.1%)	
07/02 08:30:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][300/703]	Step 138284	lr 0.02757	Loss 0.7888 (0.5885)	Prec@(1,5) (81.9%, 98.1%)	
07/02 08:30:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][350/703]	Step 138334	lr 0.02757	Loss 0.7130 (0.5968)	Prec@(1,5) (81.6%, 98.1%)	
07/02 08:30:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][400/703]	Step 138384	lr 0.02757	Loss 0.6495 (0.6027)	Prec@(1,5) (81.3%, 98.0%)	
07/02 08:30:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][450/703]	Step 138434	lr 0.02757	Loss 0.8230 (0.6113)	Prec@(1,5) (81.0%, 98.0%)	
07/02 08:30:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][500/703]	Step 138484	lr 0.02757	Loss 0.7318 (0.6176)	Prec@(1,5) (80.8%, 97.9%)	
07/02 08:30:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][550/703]	Step 138534	lr 0.02757	Loss 0.6448 (0.6262)	Prec@(1,5) (80.6%, 97.9%)	
07/02 08:30:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][600/703]	Step 138584	lr 0.02757	Loss 0.6252 (0.6303)	Prec@(1,5) (80.5%, 97.8%)	
07/02 08:30:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][650/703]	Step 138634	lr 0.02757	Loss 0.7502 (0.6348)	Prec@(1,5) (80.3%, 97.8%)	
07/02 08:30:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][700/703]	Step 138684	lr 0.02757	Loss 0.7825 (0.6432)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:30:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [196][703/703]	Step 138687	lr 0.02757	Loss 0.7554 (0.6431)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:30:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [196/299] Final Prec@1 80.0489%
07/02 08:30:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [196][50/79]	Step 138688	Loss 1.7941	Prec@(1,5) (55.0%, 83.7%)
07/02 08:30:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [196][78/79]	Step 138688	Loss 1.7933	Prec@(1,5) (55.1%, 83.8%)
07/02 08:30:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [196/299] Final Prec@1 55.0800%
07/02 08:30:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.0800%
07/02 08:30:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][50/703]	Step 138738	lr 0.02711	Loss 0.3452 (0.5417)	Prec@(1,5) (83.3%, 98.4%)	
07/02 08:31:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][100/703]	Step 138788	lr 0.02711	Loss 0.7821 (0.5691)	Prec@(1,5) (82.6%, 98.3%)	
07/02 08:31:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][150/703]	Step 138838	lr 0.02711	Loss 0.6165 (0.5612)	Prec@(1,5) (82.5%, 98.5%)	
07/02 08:31:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][200/703]	Step 138888	lr 0.02711	Loss 0.6606 (0.5659)	Prec@(1,5) (82.3%, 98.4%)	
07/02 08:31:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][250/703]	Step 138938	lr 0.02711	Loss 0.4284 (0.5761)	Prec@(1,5) (81.9%, 98.3%)	
07/02 08:31:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][300/703]	Step 138988	lr 0.02711	Loss 0.6486 (0.5871)	Prec@(1,5) (81.6%, 98.2%)	
07/02 08:31:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][350/703]	Step 139038	lr 0.02711	Loss 0.6586 (0.5898)	Prec@(1,5) (81.6%, 98.1%)	
07/02 08:31:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][400/703]	Step 139088	lr 0.02711	Loss 0.7548 (0.5987)	Prec@(1,5) (81.4%, 98.0%)	
07/02 08:31:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][450/703]	Step 139138	lr 0.02711	Loss 0.6334 (0.6109)	Prec@(1,5) (81.0%, 97.9%)	
07/02 08:31:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][500/703]	Step 139188	lr 0.02711	Loss 0.5821 (0.6184)	Prec@(1,5) (80.8%, 97.9%)	
07/02 08:31:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][550/703]	Step 139238	lr 0.02711	Loss 0.6373 (0.6224)	Prec@(1,5) (80.7%, 97.9%)	
07/02 08:31:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][600/703]	Step 139288	lr 0.02711	Loss 0.4696 (0.6256)	Prec@(1,5) (80.5%, 97.8%)	
07/02 08:31:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][650/703]	Step 139338	lr 0.02711	Loss 0.5344 (0.6337)	Prec@(1,5) (80.2%, 97.8%)	
07/02 08:31:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][700/703]	Step 139388	lr 0.02711	Loss 0.6331 (0.6395)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:31:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [197][703/703]	Step 139391	lr 0.02711	Loss 0.7089 (0.6397)	Prec@(1,5) (80.1%, 97.7%)	
07/02 08:31:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [197/299] Final Prec@1 80.0533%
07/02 08:31:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [197][50/79]	Step 139392	Loss 1.7437	Prec@(1,5) (57.3%, 83.7%)
07/02 08:31:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [197][78/79]	Step 139392	Loss 1.7676	Prec@(1,5) (56.8%, 84.0%)
07/02 08:31:40午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [197/299] Final Prec@1 56.8000%
07/02 08:31:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.0800%
07/02 08:31:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][50/703]	Step 139442	lr 0.02665	Loss 0.4124 (0.5308)	Prec@(1,5) (84.4%, 98.2%)	
07/02 08:31:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][100/703]	Step 139492	lr 0.02665	Loss 0.4895 (0.5302)	Prec@(1,5) (84.0%, 98.4%)	
07/02 08:31:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][150/703]	Step 139542	lr 0.02665	Loss 0.6158 (0.5293)	Prec@(1,5) (84.0%, 98.4%)	
07/02 08:31:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][200/703]	Step 139592	lr 0.02665	Loss 0.5389 (0.5367)	Prec@(1,5) (83.7%, 98.4%)	
07/02 08:31:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][250/703]	Step 139642	lr 0.02665	Loss 0.6990 (0.5532)	Prec@(1,5) (83.1%, 98.4%)	
07/02 08:31:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][300/703]	Step 139692	lr 0.02665	Loss 0.6064 (0.5663)	Prec@(1,5) (82.5%, 98.2%)	
07/02 08:32:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][350/703]	Step 139742	lr 0.02665	Loss 0.5838 (0.5764)	Prec@(1,5) (82.2%, 98.2%)	
07/02 08:32:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][400/703]	Step 139792	lr 0.02665	Loss 0.6496 (0.5894)	Prec@(1,5) (81.8%, 98.1%)	
07/02 08:32:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][450/703]	Step 139842	lr 0.02665	Loss 0.5704 (0.5938)	Prec@(1,5) (81.6%, 98.1%)	
07/02 08:32:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][500/703]	Step 139892	lr 0.02665	Loss 0.5059 (0.6058)	Prec@(1,5) (81.3%, 98.0%)	
07/02 08:32:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][550/703]	Step 139942	lr 0.02665	Loss 0.9204 (0.6108)	Prec@(1,5) (81.1%, 98.0%)	
07/02 08:32:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][600/703]	Step 139992	lr 0.02665	Loss 0.7189 (0.6165)	Prec@(1,5) (80.9%, 98.0%)	
07/02 08:32:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][650/703]	Step 140042	lr 0.02665	Loss 0.6604 (0.6242)	Prec@(1,5) (80.5%, 97.9%)	
07/02 08:32:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][700/703]	Step 140092	lr 0.02665	Loss 0.8208 (0.6300)	Prec@(1,5) (80.3%, 97.8%)	
07/02 08:32:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [198][703/703]	Step 140095	lr 0.02665	Loss 0.7916 (0.6303)	Prec@(1,5) (80.3%, 97.8%)	
07/02 08:32:23午後 finetuneTeacher_trainer.py:180 [INFO] Train: [198/299] Final Prec@1 80.3311%
07/02 08:32:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [198][50/79]	Step 140096	Loss 1.7029	Prec@(1,5) (56.9%, 83.8%)
07/02 08:32:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [198][78/79]	Step 140096	Loss 1.7142	Prec@(1,5) (56.6%, 83.9%)
07/02 08:32:25午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [198/299] Final Prec@1 56.5800%
07/02 08:32:25午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.0800%
07/02 08:32:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][50/703]	Step 140146	lr 0.0262	Loss 0.6526 (0.5575)	Prec@(1,5) (83.0%, 97.8%)	
07/02 08:32:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][100/703]	Step 140196	lr 0.0262	Loss 0.5756 (0.5553)	Prec@(1,5) (82.9%, 98.1%)	
07/02 08:32:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][150/703]	Step 140246	lr 0.0262	Loss 0.4426 (0.5523)	Prec@(1,5) (83.0%, 98.2%)	
07/02 08:32:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][200/703]	Step 140296	lr 0.0262	Loss 0.5255 (0.5482)	Prec@(1,5) (83.2%, 98.3%)	
07/02 08:32:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][250/703]	Step 140346	lr 0.0262	Loss 0.4189 (0.5423)	Prec@(1,5) (83.4%, 98.4%)	
07/02 08:32:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][300/703]	Step 140396	lr 0.0262	Loss 0.8027 (0.5486)	Prec@(1,5) (83.2%, 98.3%)	
07/02 08:32:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][350/703]	Step 140446	lr 0.0262	Loss 0.6020 (0.5601)	Prec@(1,5) (82.8%, 98.3%)	
07/02 08:32:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][400/703]	Step 140496	lr 0.0262	Loss 0.4119 (0.5688)	Prec@(1,5) (82.5%, 98.2%)	
07/02 08:32:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][450/703]	Step 140546	lr 0.0262	Loss 0.7868 (0.5737)	Prec@(1,5) (82.3%, 98.1%)	
07/02 08:32:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][500/703]	Step 140596	lr 0.0262	Loss 0.8006 (0.5815)	Prec@(1,5) (82.1%, 98.1%)	
07/02 08:32:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][550/703]	Step 140646	lr 0.0262	Loss 0.5196 (0.5889)	Prec@(1,5) (81.8%, 98.1%)	
07/02 08:33:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][600/703]	Step 140696	lr 0.0262	Loss 0.6738 (0.5958)	Prec@(1,5) (81.5%, 98.0%)	
07/02 08:33:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][650/703]	Step 140746	lr 0.0262	Loss 0.7101 (0.6052)	Prec@(1,5) (81.2%, 97.9%)	
07/02 08:33:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][700/703]	Step 140796	lr 0.0262	Loss 0.7708 (0.6119)	Prec@(1,5) (81.0%, 97.9%)	
07/02 08:33:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [199][703/703]	Step 140799	lr 0.0262	Loss 0.8629 (0.6120)	Prec@(1,5) (81.0%, 97.9%)	
07/02 08:33:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [199/299] Final Prec@1 81.0133%
07/02 08:33:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [199][50/79]	Step 140800	Loss 1.7404	Prec@(1,5) (57.9%, 83.5%)
07/02 08:33:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [199][78/79]	Step 140800	Loss 1.7563	Prec@(1,5) (57.5%, 83.8%)
07/02 08:33:08午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [199/299] Final Prec@1 57.4400%
07/02 08:33:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.4400%
07/02 08:33:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][50/703]	Step 140850	lr 0.02575	Loss 0.5193 (0.5523)	Prec@(1,5) (83.4%, 98.3%)	
07/02 08:33:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][100/703]	Step 140900	lr 0.02575	Loss 0.6390 (0.5329)	Prec@(1,5) (83.9%, 98.5%)	
07/02 08:33:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][150/703]	Step 140950	lr 0.02575	Loss 0.3515 (0.5293)	Prec@(1,5) (83.9%, 98.6%)	
07/02 08:33:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][200/703]	Step 141000	lr 0.02575	Loss 0.6618 (0.5382)	Prec@(1,5) (83.5%, 98.5%)	
07/02 08:33:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][250/703]	Step 141050	lr 0.02575	Loss 0.5151 (0.5430)	Prec@(1,5) (83.3%, 98.5%)	
07/02 08:33:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][300/703]	Step 141100	lr 0.02575	Loss 0.6420 (0.5500)	Prec@(1,5) (83.1%, 98.4%)	
07/02 08:33:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][350/703]	Step 141150	lr 0.02575	Loss 0.7065 (0.5502)	Prec@(1,5) (83.0%, 98.5%)	
07/02 08:33:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][400/703]	Step 141200	lr 0.02575	Loss 0.5681 (0.5523)	Prec@(1,5) (82.9%, 98.4%)	
07/02 08:33:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][450/703]	Step 141250	lr 0.02575	Loss 0.7214 (0.5625)	Prec@(1,5) (82.6%, 98.3%)	
07/02 08:33:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][500/703]	Step 141300	lr 0.02575	Loss 0.5857 (0.5685)	Prec@(1,5) (82.4%, 98.3%)	
07/02 08:33:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][550/703]	Step 141350	lr 0.02575	Loss 0.7497 (0.5733)	Prec@(1,5) (82.2%, 98.2%)	
07/02 08:33:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][600/703]	Step 141400	lr 0.02575	Loss 0.8164 (0.5800)	Prec@(1,5) (82.0%, 98.2%)	
07/02 08:33:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][650/703]	Step 141450	lr 0.02575	Loss 0.5985 (0.5880)	Prec@(1,5) (81.7%, 98.1%)	
07/02 08:33:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][700/703]	Step 141500	lr 0.02575	Loss 0.8029 (0.5956)	Prec@(1,5) (81.5%, 98.0%)	
07/02 08:33:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [200][703/703]	Step 141503	lr 0.02575	Loss 0.8196 (0.5960)	Prec@(1,5) (81.5%, 98.0%)	
07/02 08:33:51午後 finetuneTeacher_trainer.py:180 [INFO] Train: [200/299] Final Prec@1 81.4956%
07/02 08:33:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [200][50/79]	Step 141504	Loss 1.8008	Prec@(1,5) (55.7%, 83.6%)
07/02 08:33:52午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [200][78/79]	Step 141504	Loss 1.7817	Prec@(1,5) (56.0%, 83.7%)
07/02 08:33:53午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [200/299] Final Prec@1 56.0800%
07/02 08:33:53午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.4400%
07/02 08:33:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][50/703]	Step 141554	lr 0.0253	Loss 0.4589 (0.5109)	Prec@(1,5) (84.6%, 98.7%)	
07/02 08:34:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][100/703]	Step 141604	lr 0.0253	Loss 0.7378 (0.5010)	Prec@(1,5) (84.6%, 98.8%)	
07/02 08:34:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][150/703]	Step 141654	lr 0.0253	Loss 0.5458 (0.4950)	Prec@(1,5) (84.9%, 98.9%)	
07/02 08:34:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][200/703]	Step 141704	lr 0.0253	Loss 0.7657 (0.4951)	Prec@(1,5) (84.8%, 98.8%)	
07/02 08:34:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][250/703]	Step 141754	lr 0.0253	Loss 0.6152 (0.5016)	Prec@(1,5) (84.6%, 98.7%)	
07/02 08:34:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][300/703]	Step 141804	lr 0.0253	Loss 0.6659 (0.5079)	Prec@(1,5) (84.3%, 98.5%)	
07/02 08:34:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][350/703]	Step 141854	lr 0.0253	Loss 0.6086 (0.5187)	Prec@(1,5) (84.0%, 98.5%)	
07/02 08:34:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][400/703]	Step 141904	lr 0.0253	Loss 0.5903 (0.5226)	Prec@(1,5) (83.9%, 98.5%)	
07/02 08:34:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][450/703]	Step 141954	lr 0.0253	Loss 0.6959 (0.5317)	Prec@(1,5) (83.5%, 98.4%)	
07/02 08:34:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][500/703]	Step 142004	lr 0.0253	Loss 0.7179 (0.5423)	Prec@(1,5) (83.1%, 98.4%)	
07/02 08:34:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][550/703]	Step 142054	lr 0.0253	Loss 0.7714 (0.5510)	Prec@(1,5) (82.8%, 98.4%)	
07/02 08:34:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][600/703]	Step 142104	lr 0.0253	Loss 0.6375 (0.5616)	Prec@(1,5) (82.5%, 98.3%)	
07/02 08:34:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][650/703]	Step 142154	lr 0.0253	Loss 0.6768 (0.5688)	Prec@(1,5) (82.3%, 98.2%)	
07/02 08:34:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][700/703]	Step 142204	lr 0.0253	Loss 0.6510 (0.5761)	Prec@(1,5) (82.1%, 98.1%)	
07/02 08:34:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [201][703/703]	Step 142207	lr 0.0253	Loss 0.7482 (0.5766)	Prec@(1,5) (82.1%, 98.1%)	
07/02 08:34:35午後 finetuneTeacher_trainer.py:180 [INFO] Train: [201/299] Final Prec@1 82.0667%
07/02 08:34:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [201][50/79]	Step 142208	Loss 1.7182	Prec@(1,5) (57.5%, 84.7%)
07/02 08:34:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [201][78/79]	Step 142208	Loss 1.7549	Prec@(1,5) (57.3%, 83.9%)
07/02 08:34:36午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [201/299] Final Prec@1 57.3200%
07/02 08:34:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.4400%
07/02 08:34:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][50/703]	Step 142258	lr 0.02486	Loss 0.3768 (0.4950)	Prec@(1,5) (85.0%, 98.7%)	
07/02 08:34:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][100/703]	Step 142308	lr 0.02486	Loss 0.3720 (0.4883)	Prec@(1,5) (85.3%, 98.9%)	
07/02 08:34:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][150/703]	Step 142358	lr 0.02486	Loss 0.4148 (0.4928)	Prec@(1,5) (85.0%, 98.9%)	
07/02 08:34:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][200/703]	Step 142408	lr 0.02486	Loss 0.5116 (0.5017)	Prec@(1,5) (84.6%, 98.8%)	
07/02 08:34:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][250/703]	Step 142458	lr 0.02486	Loss 0.6441 (0.5050)	Prec@(1,5) (84.5%, 98.8%)	
07/02 08:34:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][300/703]	Step 142508	lr 0.02486	Loss 0.5121 (0.5119)	Prec@(1,5) (84.3%, 98.7%)	
07/02 08:34:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][350/703]	Step 142558	lr 0.02486	Loss 0.6455 (0.5184)	Prec@(1,5) (84.0%, 98.7%)	
07/02 08:35:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][400/703]	Step 142608	lr 0.02486	Loss 0.6258 (0.5223)	Prec@(1,5) (83.8%, 98.6%)	
07/02 08:35:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][450/703]	Step 142658	lr 0.02486	Loss 0.7377 (0.5289)	Prec@(1,5) (83.6%, 98.6%)	
07/02 08:35:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][500/703]	Step 142708	lr 0.02486	Loss 0.7645 (0.5392)	Prec@(1,5) (83.2%, 98.5%)	
07/02 08:35:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][550/703]	Step 142758	lr 0.02486	Loss 0.5816 (0.5462)	Prec@(1,5) (83.0%, 98.4%)	
07/02 08:35:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][600/703]	Step 142808	lr 0.02486	Loss 0.7604 (0.5552)	Prec@(1,5) (82.7%, 98.4%)	
07/02 08:35:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][650/703]	Step 142858	lr 0.02486	Loss 0.5377 (0.5668)	Prec@(1,5) (82.4%, 98.2%)	
07/02 08:35:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][700/703]	Step 142908	lr 0.02486	Loss 0.8059 (0.5736)	Prec@(1,5) (82.2%, 98.2%)	
07/02 08:35:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [202][703/703]	Step 142911	lr 0.02486	Loss 0.3860 (0.5736)	Prec@(1,5) (82.2%, 98.2%)	
07/02 08:35:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [202/299] Final Prec@1 82.2044%
07/02 08:35:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [202][50/79]	Step 142912	Loss 1.7898	Prec@(1,5) (56.4%, 83.7%)
07/02 08:35:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [202][78/79]	Step 142912	Loss 1.7929	Prec@(1,5) (57.2%, 83.6%)
07/02 08:35:21午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [202/299] Final Prec@1 57.1600%
07/02 08:35:21午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.4400%
07/02 08:35:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][50/703]	Step 142962	lr 0.02442	Loss 0.7366 (0.4787)	Prec@(1,5) (85.3%, 98.9%)	
07/02 08:35:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][100/703]	Step 143012	lr 0.02442	Loss 0.7425 (0.4726)	Prec@(1,5) (85.7%, 98.9%)	
07/02 08:35:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][150/703]	Step 143062	lr 0.02442	Loss 0.3676 (0.4847)	Prec@(1,5) (85.2%, 98.9%)	
07/02 08:35:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][200/703]	Step 143112	lr 0.02442	Loss 0.3738 (0.4931)	Prec@(1,5) (84.8%, 98.8%)	
07/02 08:35:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][250/703]	Step 143162	lr 0.02442	Loss 0.4135 (0.5030)	Prec@(1,5) (84.5%, 98.8%)	
07/02 08:35:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][300/703]	Step 143212	lr 0.02442	Loss 0.5239 (0.5157)	Prec@(1,5) (84.0%, 98.7%)	
07/02 08:35:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][350/703]	Step 143262	lr 0.02442	Loss 0.5614 (0.5260)	Prec@(1,5) (83.7%, 98.7%)	
07/02 08:35:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][400/703]	Step 143312	lr 0.02442	Loss 0.6172 (0.5327)	Prec@(1,5) (83.5%, 98.6%)	
07/02 08:35:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][450/703]	Step 143362	lr 0.02442	Loss 0.6757 (0.5401)	Prec@(1,5) (83.2%, 98.5%)	
07/02 08:35:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][500/703]	Step 143412	lr 0.02442	Loss 0.5150 (0.5436)	Prec@(1,5) (83.2%, 98.5%)	
07/02 08:35:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][550/703]	Step 143462	lr 0.02442	Loss 0.4495 (0.5513)	Prec@(1,5) (82.9%, 98.4%)	
07/02 08:35:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][600/703]	Step 143512	lr 0.02442	Loss 0.5852 (0.5543)	Prec@(1,5) (82.8%, 98.4%)	
07/02 08:36:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][650/703]	Step 143562	lr 0.02442	Loss 0.4844 (0.5577)	Prec@(1,5) (82.7%, 98.3%)	
07/02 08:36:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][700/703]	Step 143612	lr 0.02442	Loss 0.5745 (0.5611)	Prec@(1,5) (82.5%, 98.3%)	
07/02 08:36:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [203][703/703]	Step 143615	lr 0.02442	Loss 0.6579 (0.5619)	Prec@(1,5) (82.5%, 98.3%)	
07/02 08:36:04午後 finetuneTeacher_trainer.py:180 [INFO] Train: [203/299] Final Prec@1 82.5289%
07/02 08:36:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [203][50/79]	Step 143616	Loss 1.7353	Prec@(1,5) (57.9%, 84.4%)
07/02 08:36:06午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [203][78/79]	Step 143616	Loss 1.7306	Prec@(1,5) (57.6%, 84.5%)
07/02 08:36:06午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [203/299] Final Prec@1 57.6000%
07/02 08:36:06午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6000%
07/02 08:36:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][50/703]	Step 143666	lr 0.02398	Loss 0.6272 (0.4802)	Prec@(1,5) (85.2%, 98.6%)	
07/02 08:36:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][100/703]	Step 143716	lr 0.02398	Loss 0.4174 (0.4674)	Prec@(1,5) (85.8%, 98.8%)	
07/02 08:36:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][150/703]	Step 143766	lr 0.02398	Loss 0.3862 (0.4589)	Prec@(1,5) (86.0%, 99.0%)	
07/02 08:36:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][200/703]	Step 143816	lr 0.02398	Loss 0.5154 (0.4616)	Prec@(1,5) (86.0%, 99.0%)	
07/02 08:36:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][250/703]	Step 143866	lr 0.02398	Loss 0.4661 (0.4688)	Prec@(1,5) (85.8%, 98.9%)	
07/02 08:36:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][300/703]	Step 143916	lr 0.02398	Loss 0.4760 (0.4762)	Prec@(1,5) (85.5%, 98.8%)	
07/02 08:36:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][350/703]	Step 143966	lr 0.02398	Loss 0.7465 (0.4838)	Prec@(1,5) (85.3%, 98.8%)	
07/02 08:36:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][400/703]	Step 144016	lr 0.02398	Loss 0.5957 (0.4962)	Prec@(1,5) (84.8%, 98.7%)	
07/02 08:36:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][450/703]	Step 144066	lr 0.02398	Loss 0.4122 (0.5066)	Prec@(1,5) (84.5%, 98.6%)	
07/02 08:36:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][500/703]	Step 144116	lr 0.02398	Loss 0.4694 (0.5135)	Prec@(1,5) (84.3%, 98.6%)	
07/02 08:36:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][550/703]	Step 144166	lr 0.02398	Loss 0.6604 (0.5197)	Prec@(1,5) (84.0%, 98.6%)	
07/02 08:36:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][600/703]	Step 144216	lr 0.02398	Loss 0.6395 (0.5270)	Prec@(1,5) (83.7%, 98.5%)	
07/02 08:36:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][650/703]	Step 144266	lr 0.02398	Loss 0.8278 (0.5385)	Prec@(1,5) (83.3%, 98.5%)	
07/02 08:36:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][700/703]	Step 144316	lr 0.02398	Loss 0.7549 (0.5508)	Prec@(1,5) (83.0%, 98.4%)	
07/02 08:36:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [204][703/703]	Step 144319	lr 0.02398	Loss 0.5447 (0.5511)	Prec@(1,5) (83.0%, 98.4%)	
07/02 08:36:50午後 finetuneTeacher_trainer.py:180 [INFO] Train: [204/299] Final Prec@1 82.9489%
07/02 08:36:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [204][50/79]	Step 144320	Loss 1.7612	Prec@(1,5) (56.1%, 83.5%)
07/02 08:36:51午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [204][78/79]	Step 144320	Loss 1.7599	Prec@(1,5) (56.7%, 83.7%)
07/02 08:36:51午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [204/299] Final Prec@1 56.7000%
07/02 08:36:51午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6000%
07/02 08:36:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][50/703]	Step 144370	lr 0.02354	Loss 0.3684 (0.4742)	Prec@(1,5) (85.5%, 98.6%)	
07/02 08:36:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][100/703]	Step 144420	lr 0.02354	Loss 0.3838 (0.4590)	Prec@(1,5) (86.0%, 98.8%)	
07/02 08:37:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][150/703]	Step 144470	lr 0.02354	Loss 0.4250 (0.4803)	Prec@(1,5) (85.3%, 98.8%)	
07/02 08:37:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][200/703]	Step 144520	lr 0.02354	Loss 0.3462 (0.4818)	Prec@(1,5) (85.2%, 98.8%)	
07/02 08:37:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][250/703]	Step 144570	lr 0.02354	Loss 0.6969 (0.4802)	Prec@(1,5) (85.3%, 98.9%)	
07/02 08:37:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][300/703]	Step 144620	lr 0.02354	Loss 0.6966 (0.4829)	Prec@(1,5) (85.2%, 98.8%)	
07/02 08:37:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][350/703]	Step 144670	lr 0.02354	Loss 0.5535 (0.4861)	Prec@(1,5) (85.2%, 98.8%)	
07/02 08:37:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][400/703]	Step 144720	lr 0.02354	Loss 0.6228 (0.4954)	Prec@(1,5) (84.8%, 98.8%)	
07/02 08:37:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][450/703]	Step 144770	lr 0.02354	Loss 0.7052 (0.5015)	Prec@(1,5) (84.6%, 98.7%)	
07/02 08:37:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][500/703]	Step 144820	lr 0.02354	Loss 0.5384 (0.5084)	Prec@(1,5) (84.3%, 98.7%)	
07/02 08:37:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][550/703]	Step 144870	lr 0.02354	Loss 0.6855 (0.5136)	Prec@(1,5) (84.2%, 98.7%)	
07/02 08:37:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][600/703]	Step 144920	lr 0.02354	Loss 0.4574 (0.5203)	Prec@(1,5) (83.9%, 98.6%)	
07/02 08:37:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][650/703]	Step 144970	lr 0.02354	Loss 0.6218 (0.5247)	Prec@(1,5) (83.8%, 98.6%)	
07/02 08:37:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][700/703]	Step 145020	lr 0.02354	Loss 0.8049 (0.5294)	Prec@(1,5) (83.6%, 98.5%)	
07/02 08:37:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [205][703/703]	Step 145023	lr 0.02354	Loss 0.4838 (0.5293)	Prec@(1,5) (83.6%, 98.5%)	
07/02 08:37:37午後 finetuneTeacher_trainer.py:180 [INFO] Train: [205/299] Final Prec@1 83.6400%
07/02 08:37:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [205][50/79]	Step 145024	Loss 1.7333	Prec@(1,5) (58.0%, 84.8%)
07/02 08:37:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [205][78/79]	Step 145024	Loss 1.7243	Prec@(1,5) (57.7%, 84.9%)
07/02 08:37:39午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [205/299] Final Prec@1 57.6800%
07/02 08:37:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6800%
07/02 08:37:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][50/703]	Step 145074	lr 0.02311	Loss 0.2879 (0.4532)	Prec@(1,5) (85.7%, 99.3%)	
07/02 08:37:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][100/703]	Step 145124	lr 0.02311	Loss 0.3597 (0.4507)	Prec@(1,5) (86.1%, 99.2%)	
07/02 08:37:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][150/703]	Step 145174	lr 0.02311	Loss 0.4397 (0.4472)	Prec@(1,5) (86.2%, 99.1%)	
07/02 08:37:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][200/703]	Step 145224	lr 0.02311	Loss 0.3627 (0.4482)	Prec@(1,5) (86.2%, 99.1%)	
07/02 08:37:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][250/703]	Step 145274	lr 0.02311	Loss 0.3913 (0.4493)	Prec@(1,5) (86.2%, 99.0%)	
07/02 08:37:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][300/703]	Step 145324	lr 0.02311	Loss 0.3497 (0.4547)	Prec@(1,5) (86.0%, 99.1%)	
07/02 08:38:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][350/703]	Step 145374	lr 0.02311	Loss 0.3479 (0.4609)	Prec@(1,5) (85.9%, 99.0%)	
07/02 08:38:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][400/703]	Step 145424	lr 0.02311	Loss 0.5238 (0.4715)	Prec@(1,5) (85.4%, 99.0%)	
07/02 08:38:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][450/703]	Step 145474	lr 0.02311	Loss 0.3601 (0.4814)	Prec@(1,5) (85.1%, 98.9%)	
07/02 08:38:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][500/703]	Step 145524	lr 0.02311	Loss 0.3808 (0.4921)	Prec@(1,5) (84.8%, 98.8%)	
07/02 08:38:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][550/703]	Step 145574	lr 0.02311	Loss 0.4921 (0.5002)	Prec@(1,5) (84.4%, 98.7%)	
07/02 08:38:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][600/703]	Step 145624	lr 0.02311	Loss 0.6779 (0.5083)	Prec@(1,5) (84.1%, 98.7%)	
07/02 08:38:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][650/703]	Step 145674	lr 0.02311	Loss 0.5273 (0.5143)	Prec@(1,5) (84.0%, 98.6%)	
07/02 08:38:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][700/703]	Step 145724	lr 0.02311	Loss 0.5603 (0.5194)	Prec@(1,5) (83.8%, 98.6%)	
07/02 08:38:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [206][703/703]	Step 145727	lr 0.02311	Loss 0.6075 (0.5206)	Prec@(1,5) (83.7%, 98.6%)	
07/02 08:38:21午後 finetuneTeacher_trainer.py:180 [INFO] Train: [206/299] Final Prec@1 83.7400%
07/02 08:38:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [206][50/79]	Step 145728	Loss 1.8022	Prec@(1,5) (56.8%, 82.8%)
07/02 08:38:22午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [206][78/79]	Step 145728	Loss 1.7613	Prec@(1,5) (57.6%, 83.3%)
07/02 08:38:22午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [206/299] Final Prec@1 57.6800%
07/02 08:38:22午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6800%
07/02 08:38:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][50/703]	Step 145778	lr 0.02268	Loss 0.3358 (0.4722)	Prec@(1,5) (85.5%, 98.7%)	
07/02 08:38:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][100/703]	Step 145828	lr 0.02268	Loss 0.5014 (0.4551)	Prec@(1,5) (85.9%, 99.0%)	
07/02 08:38:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][150/703]	Step 145878	lr 0.02268	Loss 0.4471 (0.4540)	Prec@(1,5) (85.9%, 99.1%)	
07/02 08:38:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][200/703]	Step 145928	lr 0.02268	Loss 0.5262 (0.4530)	Prec@(1,5) (86.0%, 99.1%)	
07/02 08:38:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][250/703]	Step 145978	lr 0.02268	Loss 0.2968 (0.4522)	Prec@(1,5) (86.0%, 99.1%)	
07/02 08:38:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][300/703]	Step 146028	lr 0.02268	Loss 0.5638 (0.4592)	Prec@(1,5) (85.9%, 99.0%)	
07/02 08:38:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][350/703]	Step 146078	lr 0.02268	Loss 0.5984 (0.4665)	Prec@(1,5) (85.6%, 99.0%)	
07/02 08:38:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][400/703]	Step 146128	lr 0.02268	Loss 0.4016 (0.4710)	Prec@(1,5) (85.4%, 98.9%)	
07/02 08:38:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][450/703]	Step 146178	lr 0.02268	Loss 0.4891 (0.4755)	Prec@(1,5) (85.3%, 98.9%)	
07/02 08:38:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][500/703]	Step 146228	lr 0.02268	Loss 0.5044 (0.4813)	Prec@(1,5) (85.1%, 98.9%)	
07/02 08:38:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][550/703]	Step 146278	lr 0.02268	Loss 0.6722 (0.4867)	Prec@(1,5) (84.9%, 98.8%)	
07/02 08:38:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][600/703]	Step 146328	lr 0.02268	Loss 0.4831 (0.4951)	Prec@(1,5) (84.6%, 98.8%)	
07/02 08:39:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][650/703]	Step 146378	lr 0.02268	Loss 0.4655 (0.5026)	Prec@(1,5) (84.4%, 98.7%)	
07/02 08:39:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][700/703]	Step 146428	lr 0.02268	Loss 0.7361 (0.5099)	Prec@(1,5) (84.2%, 98.7%)	
07/02 08:39:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [207][703/703]	Step 146431	lr 0.02268	Loss 0.6211 (0.5103)	Prec@(1,5) (84.1%, 98.7%)	
07/02 08:39:04午後 finetuneTeacher_trainer.py:180 [INFO] Train: [207/299] Final Prec@1 84.1244%
07/02 08:39:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [207][50/79]	Step 146432	Loss 1.8020	Prec@(1,5) (56.3%, 83.2%)
07/02 08:39:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [207][78/79]	Step 146432	Loss 1.7776	Prec@(1,5) (56.4%, 83.9%)
07/02 08:39:05午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [207/299] Final Prec@1 56.3400%
07/02 08:39:05午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6800%
07/02 08:39:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][50/703]	Step 146482	lr 0.02225	Loss 0.4352 (0.4543)	Prec@(1,5) (86.2%, 99.0%)	
07/02 08:39:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][100/703]	Step 146532	lr 0.02225	Loss 0.4127 (0.4357)	Prec@(1,5) (86.8%, 99.1%)	
07/02 08:39:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][150/703]	Step 146582	lr 0.02225	Loss 0.4641 (0.4385)	Prec@(1,5) (86.6%, 99.1%)	
07/02 08:39:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][200/703]	Step 146632	lr 0.02225	Loss 0.4838 (0.4348)	Prec@(1,5) (86.6%, 99.1%)	
07/02 08:39:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][250/703]	Step 146682	lr 0.02225	Loss 0.3700 (0.4415)	Prec@(1,5) (86.4%, 99.1%)	
07/02 08:39:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][300/703]	Step 146732	lr 0.02225	Loss 0.4428 (0.4474)	Prec@(1,5) (86.3%, 99.1%)	
07/02 08:39:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][350/703]	Step 146782	lr 0.02225	Loss 0.4778 (0.4533)	Prec@(1,5) (86.0%, 99.0%)	
07/02 08:39:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][400/703]	Step 146832	lr 0.02225	Loss 0.5313 (0.4599)	Prec@(1,5) (85.8%, 98.9%)	
07/02 08:39:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][450/703]	Step 146882	lr 0.02225	Loss 0.5435 (0.4652)	Prec@(1,5) (85.7%, 98.8%)	
07/02 08:39:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][500/703]	Step 146932	lr 0.02225	Loss 0.4907 (0.4719)	Prec@(1,5) (85.4%, 98.8%)	
07/02 08:39:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][550/703]	Step 146982	lr 0.02225	Loss 0.4286 (0.4790)	Prec@(1,5) (85.2%, 98.8%)	
07/02 08:39:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][600/703]	Step 147032	lr 0.02225	Loss 0.7054 (0.4864)	Prec@(1,5) (85.0%, 98.7%)	
07/02 08:39:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][650/703]	Step 147082	lr 0.02225	Loss 0.5510 (0.4944)	Prec@(1,5) (84.7%, 98.7%)	
07/02 08:39:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][700/703]	Step 147132	lr 0.02225	Loss 0.5512 (0.4994)	Prec@(1,5) (84.5%, 98.6%)	
07/02 08:39:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [208][703/703]	Step 147135	lr 0.02225	Loss 0.4522 (0.4998)	Prec@(1,5) (84.5%, 98.6%)	
07/02 08:39:47午後 finetuneTeacher_trainer.py:180 [INFO] Train: [208/299] Final Prec@1 84.5044%
07/02 08:39:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [208][50/79]	Step 147136	Loss 1.7878	Prec@(1,5) (56.5%, 84.4%)
07/02 08:39:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [208][78/79]	Step 147136	Loss 1.7809	Prec@(1,5) (56.9%, 84.1%)
07/02 08:39:49午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [208/299] Final Prec@1 56.9200%
07/02 08:39:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6800%
07/02 08:39:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][50/703]	Step 147186	lr 0.02183	Loss 0.4413 (0.4348)	Prec@(1,5) (86.9%, 98.9%)	
07/02 08:39:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][100/703]	Step 147236	lr 0.02183	Loss 0.6132 (0.4319)	Prec@(1,5) (87.0%, 99.1%)	
07/02 08:39:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][150/703]	Step 147286	lr 0.02183	Loss 0.4260 (0.4335)	Prec@(1,5) (87.0%, 99.1%)	
07/02 08:40:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][200/703]	Step 147336	lr 0.02183	Loss 0.3583 (0.4350)	Prec@(1,5) (86.9%, 99.1%)	
07/02 08:40:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][250/703]	Step 147386	lr 0.02183	Loss 0.5697 (0.4388)	Prec@(1,5) (86.6%, 99.1%)	
07/02 08:40:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][300/703]	Step 147436	lr 0.02183	Loss 0.5427 (0.4405)	Prec@(1,5) (86.6%, 99.1%)	
07/02 08:40:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][350/703]	Step 147486	lr 0.02183	Loss 0.3860 (0.4408)	Prec@(1,5) (86.5%, 99.1%)	
07/02 08:40:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][400/703]	Step 147536	lr 0.02183	Loss 0.6206 (0.4518)	Prec@(1,5) (86.0%, 99.0%)	
07/02 08:40:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][450/703]	Step 147586	lr 0.02183	Loss 0.6266 (0.4534)	Prec@(1,5) (86.0%, 99.0%)	
07/02 08:40:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][500/703]	Step 147636	lr 0.02183	Loss 0.4010 (0.4574)	Prec@(1,5) (85.9%, 99.0%)	
07/02 08:40:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][550/703]	Step 147686	lr 0.02183	Loss 0.7123 (0.4627)	Prec@(1,5) (85.7%, 98.9%)	
07/02 08:40:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][600/703]	Step 147736	lr 0.02183	Loss 0.4933 (0.4674)	Prec@(1,5) (85.5%, 98.9%)	
07/02 08:40:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][650/703]	Step 147786	lr 0.02183	Loss 0.5923 (0.4750)	Prec@(1,5) (85.2%, 98.9%)	
07/02 08:40:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][700/703]	Step 147836	lr 0.02183	Loss 0.7731 (0.4815)	Prec@(1,5) (84.9%, 98.8%)	
07/02 08:40:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [209][703/703]	Step 147839	lr 0.02183	Loss 0.4791 (0.4814)	Prec@(1,5) (84.9%, 98.8%)	
07/02 08:40:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [209/299] Final Prec@1 84.9156%
07/02 08:40:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [209][50/79]	Step 147840	Loss 1.8210	Prec@(1,5) (57.0%, 83.2%)
07/02 08:40:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [209][78/79]	Step 147840	Loss 1.7943	Prec@(1,5) (57.1%, 83.6%)
07/02 08:40:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [209/299] Final Prec@1 57.1600%
07/02 08:40:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6800%
07/02 08:40:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][50/703]	Step 147890	lr 0.0214	Loss 0.4716 (0.4218)	Prec@(1,5) (87.2%, 98.9%)	
07/02 08:40:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][100/703]	Step 147940	lr 0.0214	Loss 0.3330 (0.4100)	Prec@(1,5) (87.7%, 99.1%)	
07/02 08:40:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][150/703]	Step 147990	lr 0.0214	Loss 0.5360 (0.4134)	Prec@(1,5) (87.4%, 99.1%)	
07/02 08:40:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][200/703]	Step 148040	lr 0.0214	Loss 0.4245 (0.4159)	Prec@(1,5) (87.2%, 99.1%)	
07/02 08:40:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][250/703]	Step 148090	lr 0.0214	Loss 0.6256 (0.4210)	Prec@(1,5) (87.1%, 99.1%)	
07/02 08:40:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][300/703]	Step 148140	lr 0.0214	Loss 0.3419 (0.4261)	Prec@(1,5) (86.9%, 99.1%)	
07/02 08:40:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][350/703]	Step 148190	lr 0.0214	Loss 0.3298 (0.4318)	Prec@(1,5) (86.7%, 99.0%)	
07/02 08:40:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][400/703]	Step 148240	lr 0.0214	Loss 0.5417 (0.4387)	Prec@(1,5) (86.5%, 99.0%)	
07/02 08:41:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][450/703]	Step 148290	lr 0.0214	Loss 0.7550 (0.4478)	Prec@(1,5) (86.2%, 99.0%)	
07/02 08:41:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][500/703]	Step 148340	lr 0.0214	Loss 0.3923 (0.4534)	Prec@(1,5) (86.0%, 99.0%)	
07/02 08:41:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][550/703]	Step 148390	lr 0.0214	Loss 0.4177 (0.4570)	Prec@(1,5) (85.9%, 98.9%)	
07/02 08:41:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][600/703]	Step 148440	lr 0.0214	Loss 0.4147 (0.4623)	Prec@(1,5) (85.7%, 98.9%)	
07/02 08:41:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][650/703]	Step 148490	lr 0.0214	Loss 0.4766 (0.4684)	Prec@(1,5) (85.5%, 98.9%)	
07/02 08:41:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][700/703]	Step 148540	lr 0.0214	Loss 0.3213 (0.4728)	Prec@(1,5) (85.3%, 98.9%)	
07/02 08:41:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [210][703/703]	Step 148543	lr 0.0214	Loss 0.5276 (0.4730)	Prec@(1,5) (85.3%, 98.8%)	
07/02 08:41:18午後 finetuneTeacher_trainer.py:180 [INFO] Train: [210/299] Final Prec@1 85.2822%
07/02 08:41:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [210][50/79]	Step 148544	Loss 1.7657	Prec@(1,5) (57.6%, 84.3%)
07/02 08:41:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [210][78/79]	Step 148544	Loss 1.7492	Prec@(1,5) (57.6%, 84.7%)
07/02 08:41:19午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [210/299] Final Prec@1 57.5600%
07/02 08:41:19午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.6800%
07/02 08:41:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][50/703]	Step 148594	lr 0.02099	Loss 0.3339 (0.3905)	Prec@(1,5) (88.0%, 99.3%)	
07/02 08:41:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][100/703]	Step 148644	lr 0.02099	Loss 0.4101 (0.4015)	Prec@(1,5) (87.3%, 99.3%)	
07/02 08:41:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][150/703]	Step 148694	lr 0.02099	Loss 0.4390 (0.4024)	Prec@(1,5) (87.4%, 99.3%)	
07/02 08:41:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][200/703]	Step 148744	lr 0.02099	Loss 0.4860 (0.4063)	Prec@(1,5) (87.3%, 99.2%)	
07/02 08:41:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][250/703]	Step 148794	lr 0.02099	Loss 0.2748 (0.4077)	Prec@(1,5) (87.3%, 99.3%)	
07/02 08:41:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][300/703]	Step 148844	lr 0.02099	Loss 0.3246 (0.4170)	Prec@(1,5) (87.1%, 99.2%)	
07/02 08:41:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][350/703]	Step 148894	lr 0.02099	Loss 0.5203 (0.4235)	Prec@(1,5) (86.8%, 99.2%)	
07/02 08:41:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][400/703]	Step 148944	lr 0.02099	Loss 0.4684 (0.4321)	Prec@(1,5) (86.6%, 99.1%)	
07/02 08:41:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][450/703]	Step 148994	lr 0.02099	Loss 0.3955 (0.4364)	Prec@(1,5) (86.4%, 99.1%)	
07/02 08:41:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][500/703]	Step 149044	lr 0.02099	Loss 0.5066 (0.4423)	Prec@(1,5) (86.3%, 99.1%)	
07/02 08:41:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][550/703]	Step 149094	lr 0.02099	Loss 0.4477 (0.4471)	Prec@(1,5) (86.1%, 99.0%)	
07/02 08:41:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][600/703]	Step 149144	lr 0.02099	Loss 0.5337 (0.4487)	Prec@(1,5) (86.1%, 99.0%)	
07/02 08:41:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][650/703]	Step 149194	lr 0.02099	Loss 0.6252 (0.4524)	Prec@(1,5) (85.9%, 99.0%)	
07/02 08:42:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][700/703]	Step 149244	lr 0.02099	Loss 0.5075 (0.4553)	Prec@(1,5) (85.8%, 99.0%)	
07/02 08:42:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [211][703/703]	Step 149247	lr 0.02099	Loss 0.6708 (0.4560)	Prec@(1,5) (85.8%, 99.0%)	
07/02 08:42:03午後 finetuneTeacher_trainer.py:180 [INFO] Train: [211/299] Final Prec@1 85.8000%
07/02 08:42:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [211][50/79]	Step 149248	Loss 1.7321	Prec@(1,5) (58.4%, 85.6%)
07/02 08:42:04午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [211][78/79]	Step 149248	Loss 1.7131	Prec@(1,5) (58.7%, 85.4%)
07/02 08:42:04午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [211/299] Final Prec@1 58.7000%
07/02 08:42:05午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 58.7000%
07/02 08:42:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][50/703]	Step 149298	lr 0.02057	Loss 0.3958 (0.4017)	Prec@(1,5) (87.8%, 99.3%)	
07/02 08:42:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][100/703]	Step 149348	lr 0.02057	Loss 0.2377 (0.3834)	Prec@(1,5) (88.1%, 99.4%)	
07/02 08:42:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][150/703]	Step 149398	lr 0.02057	Loss 0.3781 (0.3854)	Prec@(1,5) (88.1%, 99.3%)	
07/02 08:42:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][200/703]	Step 149448	lr 0.02057	Loss 0.7142 (0.3878)	Prec@(1,5) (88.0%, 99.2%)	
07/02 08:42:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][250/703]	Step 149498	lr 0.02057	Loss 0.5040 (0.3973)	Prec@(1,5) (87.7%, 99.2%)	
07/02 08:42:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][300/703]	Step 149548	lr 0.02057	Loss 0.3105 (0.4040)	Prec@(1,5) (87.4%, 99.2%)	
07/02 08:42:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][350/703]	Step 149598	lr 0.02057	Loss 0.2577 (0.4096)	Prec@(1,5) (87.2%, 99.2%)	
07/02 08:42:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][400/703]	Step 149648	lr 0.02057	Loss 0.3695 (0.4172)	Prec@(1,5) (87.0%, 99.1%)	
07/02 08:42:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][450/703]	Step 149698	lr 0.02057	Loss 0.4594 (0.4253)	Prec@(1,5) (86.7%, 99.1%)	
07/02 08:42:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][500/703]	Step 149748	lr 0.02057	Loss 0.5496 (0.4289)	Prec@(1,5) (86.6%, 99.1%)	
07/02 08:42:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][550/703]	Step 149798	lr 0.02057	Loss 0.3135 (0.4320)	Prec@(1,5) (86.5%, 99.1%)	
07/02 08:42:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][600/703]	Step 149848	lr 0.02057	Loss 0.5511 (0.4386)	Prec@(1,5) (86.3%, 99.0%)	
07/02 08:42:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][650/703]	Step 149898	lr 0.02057	Loss 0.5797 (0.4483)	Prec@(1,5) (85.9%, 99.0%)	
07/02 08:42:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][700/703]	Step 149948	lr 0.02057	Loss 0.3515 (0.4537)	Prec@(1,5) (85.7%, 99.0%)	
07/02 08:42:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [212][703/703]	Step 149951	lr 0.02057	Loss 0.6032 (0.4543)	Prec@(1,5) (85.7%, 99.0%)	
07/02 08:42:47午後 finetuneTeacher_trainer.py:180 [INFO] Train: [212/299] Final Prec@1 85.7022%
07/02 08:42:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [212][50/79]	Step 149952	Loss 1.8013	Prec@(1,5) (57.4%, 84.1%)
07/02 08:42:48午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [212][78/79]	Step 149952	Loss 1.7850	Prec@(1,5) (57.2%, 84.1%)
07/02 08:42:48午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [212/299] Final Prec@1 57.2200%
07/02 08:42:48午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 58.7000%
07/02 08:42:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][50/703]	Step 150002	lr 0.02016	Loss 0.3630 (0.3793)	Prec@(1,5) (88.8%, 99.4%)	
07/02 08:42:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][100/703]	Step 150052	lr 0.02016	Loss 0.3190 (0.3832)	Prec@(1,5) (88.4%, 99.4%)	
07/02 08:42:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][150/703]	Step 150102	lr 0.02016	Loss 0.2446 (0.3976)	Prec@(1,5) (87.9%, 99.2%)	
07/02 08:43:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][200/703]	Step 150152	lr 0.02016	Loss 0.3632 (0.4030)	Prec@(1,5) (87.7%, 99.2%)	
07/02 08:43:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][250/703]	Step 150202	lr 0.02016	Loss 0.3517 (0.4044)	Prec@(1,5) (87.6%, 99.2%)	
07/02 08:43:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][300/703]	Step 150252	lr 0.02016	Loss 0.5463 (0.4107)	Prec@(1,5) (87.5%, 99.2%)	
07/02 08:43:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][350/703]	Step 150302	lr 0.02016	Loss 0.4838 (0.4138)	Prec@(1,5) (87.4%, 99.1%)	
07/02 08:43:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][400/703]	Step 150352	lr 0.02016	Loss 0.3317 (0.4142)	Prec@(1,5) (87.4%, 99.1%)	
07/02 08:43:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][450/703]	Step 150402	lr 0.02016	Loss 0.4783 (0.4181)	Prec@(1,5) (87.3%, 99.1%)	
07/02 08:43:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][500/703]	Step 150452	lr 0.02016	Loss 0.4443 (0.4210)	Prec@(1,5) (87.1%, 99.1%)	
07/02 08:43:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][550/703]	Step 150502	lr 0.02016	Loss 0.4968 (0.4250)	Prec@(1,5) (87.0%, 99.0%)	
07/02 08:43:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][600/703]	Step 150552	lr 0.02016	Loss 0.4360 (0.4300)	Prec@(1,5) (86.8%, 99.0%)	
07/02 08:43:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][650/703]	Step 150602	lr 0.02016	Loss 0.2844 (0.4334)	Prec@(1,5) (86.6%, 99.0%)	
07/02 08:43:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][700/703]	Step 150652	lr 0.02016	Loss 0.3889 (0.4393)	Prec@(1,5) (86.4%, 99.0%)	
07/02 08:43:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [213][703/703]	Step 150655	lr 0.02016	Loss 0.5517 (0.4393)	Prec@(1,5) (86.4%, 99.0%)	
07/02 08:43:32午後 finetuneTeacher_trainer.py:180 [INFO] Train: [213/299] Final Prec@1 86.4289%
07/02 08:43:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [213][50/79]	Step 150656	Loss 1.7493	Prec@(1,5) (57.7%, 84.4%)
07/02 08:43:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [213][78/79]	Step 150656	Loss 1.7356	Prec@(1,5) (58.2%, 84.4%)
07/02 08:43:33午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [213/299] Final Prec@1 58.1400%
07/02 08:43:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 58.7000%
07/02 08:43:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][50/703]	Step 150706	lr 0.01975	Loss 0.3098 (0.3623)	Prec@(1,5) (88.8%, 99.5%)	
07/02 08:43:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][100/703]	Step 150756	lr 0.01975	Loss 0.4349 (0.3649)	Prec@(1,5) (89.2%, 99.5%)	
07/02 08:43:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][150/703]	Step 150806	lr 0.01975	Loss 0.6128 (0.3729)	Prec@(1,5) (89.0%, 99.4%)	
07/02 08:43:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][200/703]	Step 150856	lr 0.01975	Loss 0.2797 (0.3765)	Prec@(1,5) (88.7%, 99.4%)	
07/02 08:43:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][250/703]	Step 150906	lr 0.01975	Loss 0.3937 (0.3836)	Prec@(1,5) (88.3%, 99.3%)	
07/02 08:43:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][300/703]	Step 150956	lr 0.01975	Loss 0.3688 (0.3872)	Prec@(1,5) (88.2%, 99.2%)	
07/02 08:43:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][350/703]	Step 151006	lr 0.01975	Loss 0.5444 (0.3918)	Prec@(1,5) (88.1%, 99.2%)	
07/02 08:43:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][400/703]	Step 151056	lr 0.01975	Loss 0.3000 (0.3940)	Prec@(1,5) (88.0%, 99.3%)	
07/02 08:44:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][450/703]	Step 151106	lr 0.01975	Loss 0.7143 (0.3978)	Prec@(1,5) (87.9%, 99.2%)	
07/02 08:44:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][500/703]	Step 151156	lr 0.01975	Loss 0.3682 (0.4050)	Prec@(1,5) (87.6%, 99.2%)	
07/02 08:44:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][550/703]	Step 151206	lr 0.01975	Loss 0.6500 (0.4120)	Prec@(1,5) (87.3%, 99.2%)	
07/02 08:44:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][600/703]	Step 151256	lr 0.01975	Loss 0.5482 (0.4168)	Prec@(1,5) (87.1%, 99.2%)	
07/02 08:44:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][650/703]	Step 151306	lr 0.01975	Loss 0.6013 (0.4214)	Prec@(1,5) (86.9%, 99.1%)	
07/02 08:44:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][700/703]	Step 151356	lr 0.01975	Loss 0.7791 (0.4275)	Prec@(1,5) (86.7%, 99.1%)	
07/02 08:44:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [214][703/703]	Step 151359	lr 0.01975	Loss 0.3280 (0.4277)	Prec@(1,5) (86.7%, 99.1%)	
07/02 08:44:16午後 finetuneTeacher_trainer.py:180 [INFO] Train: [214/299] Final Prec@1 86.7067%
07/02 08:44:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [214][50/79]	Step 151360	Loss 1.7205	Prec@(1,5) (58.9%, 85.1%)
07/02 08:44:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [214][78/79]	Step 151360	Loss 1.7408	Prec@(1,5) (58.8%, 84.6%)
07/02 08:44:18午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [214/299] Final Prec@1 58.7800%
07/02 08:44:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 58.7800%
07/02 08:44:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][50/703]	Step 151410	lr 0.01935	Loss 0.4531 (0.3907)	Prec@(1,5) (88.1%, 99.4%)	
07/02 08:44:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][100/703]	Step 151460	lr 0.01935	Loss 0.2896 (0.3673)	Prec@(1,5) (89.0%, 99.4%)	
07/02 08:44:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][150/703]	Step 151510	lr 0.01935	Loss 0.4577 (0.3753)	Prec@(1,5) (88.7%, 99.3%)	
07/02 08:44:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][200/703]	Step 151560	lr 0.01935	Loss 0.2791 (0.3788)	Prec@(1,5) (88.5%, 99.3%)	
07/02 08:44:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][250/703]	Step 151610	lr 0.01935	Loss 0.4739 (0.3837)	Prec@(1,5) (88.3%, 99.3%)	
07/02 08:44:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][300/703]	Step 151660	lr 0.01935	Loss 0.5225 (0.3878)	Prec@(1,5) (88.1%, 99.3%)	
07/02 08:44:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][350/703]	Step 151710	lr 0.01935	Loss 0.4339 (0.3875)	Prec@(1,5) (88.1%, 99.3%)	
07/02 08:44:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][400/703]	Step 151760	lr 0.01935	Loss 0.4910 (0.3911)	Prec@(1,5) (88.1%, 99.3%)	
07/02 08:44:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][450/703]	Step 151810	lr 0.01935	Loss 0.3307 (0.3929)	Prec@(1,5) (88.0%, 99.3%)	
07/02 08:44:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][500/703]	Step 151860	lr 0.01935	Loss 0.4012 (0.3942)	Prec@(1,5) (88.0%, 99.2%)	
07/02 08:44:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][550/703]	Step 151910	lr 0.01935	Loss 0.5037 (0.3983)	Prec@(1,5) (87.8%, 99.2%)	
07/02 08:44:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][600/703]	Step 151960	lr 0.01935	Loss 0.5943 (0.4030)	Prec@(1,5) (87.7%, 99.2%)	
07/02 08:44:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][650/703]	Step 152010	lr 0.01935	Loss 0.4165 (0.4085)	Prec@(1,5) (87.4%, 99.2%)	
07/02 08:45:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][700/703]	Step 152060	lr 0.01935	Loss 0.3968 (0.4125)	Prec@(1,5) (87.3%, 99.1%)	
07/02 08:45:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [215][703/703]	Step 152063	lr 0.01935	Loss 0.5506 (0.4132)	Prec@(1,5) (87.2%, 99.1%)	
07/02 08:45:00午後 finetuneTeacher_trainer.py:180 [INFO] Train: [215/299] Final Prec@1 87.2356%
07/02 08:45:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [215][50/79]	Step 152064	Loss 1.6957	Prec@(1,5) (60.1%, 85.3%)
07/02 08:45:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [215][78/79]	Step 152064	Loss 1.7207	Prec@(1,5) (59.6%, 85.0%)
07/02 08:45:02午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [215/299] Final Prec@1 59.5800%
07/02 08:45:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:45:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][50/703]	Step 152114	lr 0.01895	Loss 0.5311 (0.3654)	Prec@(1,5) (89.2%, 99.5%)	
07/02 08:45:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][100/703]	Step 152164	lr 0.01895	Loss 0.2185 (0.3490)	Prec@(1,5) (89.8%, 99.6%)	
07/02 08:45:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][150/703]	Step 152214	lr 0.01895	Loss 0.3234 (0.3480)	Prec@(1,5) (89.5%, 99.6%)	
07/02 08:45:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][200/703]	Step 152264	lr 0.01895	Loss 0.3330 (0.3469)	Prec@(1,5) (89.5%, 99.6%)	
07/02 08:45:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][250/703]	Step 152314	lr 0.01895	Loss 0.3794 (0.3539)	Prec@(1,5) (89.3%, 99.5%)	
07/02 08:45:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][300/703]	Step 152364	lr 0.01895	Loss 0.3572 (0.3553)	Prec@(1,5) (89.3%, 99.5%)	
07/02 08:45:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][350/703]	Step 152414	lr 0.01895	Loss 0.3664 (0.3598)	Prec@(1,5) (89.0%, 99.5%)	
07/02 08:45:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][400/703]	Step 152464	lr 0.01895	Loss 0.3578 (0.3656)	Prec@(1,5) (88.9%, 99.5%)	
07/02 08:45:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][450/703]	Step 152514	lr 0.01895	Loss 0.3497 (0.3718)	Prec@(1,5) (88.7%, 99.4%)	
07/02 08:45:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][500/703]	Step 152564	lr 0.01895	Loss 0.3603 (0.3777)	Prec@(1,5) (88.4%, 99.4%)	
07/02 08:45:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][550/703]	Step 152614	lr 0.01895	Loss 0.3539 (0.3840)	Prec@(1,5) (88.2%, 99.4%)	
07/02 08:45:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][600/703]	Step 152664	lr 0.01895	Loss 0.4208 (0.3901)	Prec@(1,5) (88.0%, 99.3%)	
07/02 08:45:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][650/703]	Step 152714	lr 0.01895	Loss 0.6841 (0.3996)	Prec@(1,5) (87.7%, 99.3%)	
07/02 08:45:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][700/703]	Step 152764	lr 0.01895	Loss 0.5562 (0.4072)	Prec@(1,5) (87.4%, 99.2%)	
07/02 08:45:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [216][703/703]	Step 152767	lr 0.01895	Loss 0.6690 (0.4085)	Prec@(1,5) (87.4%, 99.2%)	
07/02 08:45:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [216/299] Final Prec@1 87.3756%
07/02 08:45:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [216][50/79]	Step 152768	Loss 1.8482	Prec@(1,5) (56.8%, 82.8%)
07/02 08:45:47午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [216][78/79]	Step 152768	Loss 1.8436	Prec@(1,5) (56.8%, 83.1%)
07/02 08:45:47午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [216/299] Final Prec@1 56.7800%
07/02 08:45:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:45:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][50/703]	Step 152818	lr 0.01855	Loss 0.3829 (0.3898)	Prec@(1,5) (87.9%, 99.2%)	
07/02 08:45:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][100/703]	Step 152868	lr 0.01855	Loss 0.4405 (0.3772)	Prec@(1,5) (88.6%, 99.3%)	
07/02 08:45:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][150/703]	Step 152918	lr 0.01855	Loss 0.3603 (0.3763)	Prec@(1,5) (88.6%, 99.3%)	
07/02 08:45:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][200/703]	Step 152968	lr 0.01855	Loss 0.4083 (0.3694)	Prec@(1,5) (88.7%, 99.4%)	
07/02 08:46:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][250/703]	Step 153018	lr 0.01855	Loss 0.5075 (0.3718)	Prec@(1,5) (88.6%, 99.3%)	
07/02 08:46:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][300/703]	Step 153068	lr 0.01855	Loss 0.2651 (0.3744)	Prec@(1,5) (88.6%, 99.3%)	
07/02 08:46:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][350/703]	Step 153118	lr 0.01855	Loss 0.2628 (0.3757)	Prec@(1,5) (88.6%, 99.3%)	
07/02 08:46:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][400/703]	Step 153168	lr 0.01855	Loss 0.4088 (0.3788)	Prec@(1,5) (88.5%, 99.3%)	
07/02 08:46:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][450/703]	Step 153218	lr 0.01855	Loss 0.4264 (0.3838)	Prec@(1,5) (88.3%, 99.3%)	
07/02 08:46:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][500/703]	Step 153268	lr 0.01855	Loss 0.1985 (0.3850)	Prec@(1,5) (88.3%, 99.3%)	
07/02 08:46:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][550/703]	Step 153318	lr 0.01855	Loss 0.7434 (0.3910)	Prec@(1,5) (88.1%, 99.2%)	
07/02 08:46:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][600/703]	Step 153368	lr 0.01855	Loss 0.3986 (0.3939)	Prec@(1,5) (88.0%, 99.2%)	
07/02 08:46:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][650/703]	Step 153418	lr 0.01855	Loss 0.2322 (0.3962)	Prec@(1,5) (87.9%, 99.2%)	
07/02 08:46:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][700/703]	Step 153468	lr 0.01855	Loss 0.4504 (0.3985)	Prec@(1,5) (87.8%, 99.2%)	
07/02 08:46:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [217][703/703]	Step 153471	lr 0.01855	Loss 0.5443 (0.3986)	Prec@(1,5) (87.8%, 99.2%)	
07/02 08:46:31午後 finetuneTeacher_trainer.py:180 [INFO] Train: [217/299] Final Prec@1 87.8356%
07/02 08:46:32午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [217][50/79]	Step 153472	Loss 1.8163	Prec@(1,5) (58.5%, 83.6%)
07/02 08:46:32午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [217][78/79]	Step 153472	Loss 1.7460	Prec@(1,5) (59.0%, 84.5%)
07/02 08:46:32午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [217/299] Final Prec@1 59.0200%
07/02 08:46:32午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:46:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][50/703]	Step 153522	lr 0.01816	Loss 0.2548 (0.3380)	Prec@(1,5) (89.6%, 99.6%)	
07/02 08:46:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][100/703]	Step 153572	lr 0.01816	Loss 0.3139 (0.3351)	Prec@(1,5) (89.6%, 99.6%)	
07/02 08:46:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][150/703]	Step 153622	lr 0.01816	Loss 0.3310 (0.3318)	Prec@(1,5) (89.9%, 99.5%)	
07/02 08:46:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][200/703]	Step 153672	lr 0.01816	Loss 0.2135 (0.3327)	Prec@(1,5) (90.0%, 99.5%)	
07/02 08:46:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][250/703]	Step 153722	lr 0.01816	Loss 0.3093 (0.3335)	Prec@(1,5) (89.9%, 99.5%)	
07/02 08:46:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][300/703]	Step 153772	lr 0.01816	Loss 0.3365 (0.3389)	Prec@(1,5) (89.6%, 99.5%)	
07/02 08:46:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][350/703]	Step 153822	lr 0.01816	Loss 0.4146 (0.3419)	Prec@(1,5) (89.5%, 99.5%)	
07/02 08:46:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][400/703]	Step 153872	lr 0.01816	Loss 0.3158 (0.3489)	Prec@(1,5) (89.3%, 99.5%)	
07/02 08:47:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][450/703]	Step 153922	lr 0.01816	Loss 0.4429 (0.3549)	Prec@(1,5) (89.2%, 99.5%)	
07/02 08:47:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][500/703]	Step 153972	lr 0.01816	Loss 0.3981 (0.3603)	Prec@(1,5) (89.0%, 99.4%)	
07/02 08:47:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][550/703]	Step 154022	lr 0.01816	Loss 0.3072 (0.3644)	Prec@(1,5) (88.8%, 99.4%)	
07/02 08:47:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][600/703]	Step 154072	lr 0.01816	Loss 0.3122 (0.3672)	Prec@(1,5) (88.7%, 99.4%)	
07/02 08:47:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][650/703]	Step 154122	lr 0.01816	Loss 0.5786 (0.3710)	Prec@(1,5) (88.5%, 99.4%)	
07/02 08:47:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][700/703]	Step 154172	lr 0.01816	Loss 0.6547 (0.3780)	Prec@(1,5) (88.3%, 99.3%)	
07/02 08:47:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [218][703/703]	Step 154175	lr 0.01816	Loss 0.4517 (0.3782)	Prec@(1,5) (88.3%, 99.3%)	
07/02 08:47:15午後 finetuneTeacher_trainer.py:180 [INFO] Train: [218/299] Final Prec@1 88.2667%
07/02 08:47:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [218][50/79]	Step 154176	Loss 1.8115	Prec@(1,5) (57.5%, 84.6%)
07/02 08:47:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [218][78/79]	Step 154176	Loss 1.8156	Prec@(1,5) (57.5%, 84.1%)
07/02 08:47:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [218/299] Final Prec@1 57.5000%
07/02 08:47:17午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:47:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][50/703]	Step 154226	lr 0.01777	Loss 0.3633 (0.3324)	Prec@(1,5) (90.2%, 99.3%)	
07/02 08:47:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][100/703]	Step 154276	lr 0.01777	Loss 0.2377 (0.3261)	Prec@(1,5) (90.5%, 99.5%)	
07/02 08:47:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][150/703]	Step 154326	lr 0.01777	Loss 0.3297 (0.3236)	Prec@(1,5) (90.5%, 99.5%)	
07/02 08:47:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][200/703]	Step 154376	lr 0.01777	Loss 0.3974 (0.3275)	Prec@(1,5) (90.2%, 99.5%)	
07/02 08:47:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][250/703]	Step 154426	lr 0.01777	Loss 0.1872 (0.3255)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:47:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][300/703]	Step 154476	lr 0.01777	Loss 0.3301 (0.3266)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:47:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][350/703]	Step 154526	lr 0.01777	Loss 0.2718 (0.3291)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:47:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][400/703]	Step 154576	lr 0.01777	Loss 0.3024 (0.3338)	Prec@(1,5) (90.0%, 99.5%)	
07/02 08:47:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][450/703]	Step 154626	lr 0.01777	Loss 0.3606 (0.3382)	Prec@(1,5) (89.8%, 99.5%)	
07/02 08:47:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][500/703]	Step 154676	lr 0.01777	Loss 0.3461 (0.3412)	Prec@(1,5) (89.7%, 99.5%)	
07/02 08:47:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][550/703]	Step 154726	lr 0.01777	Loss 0.3731 (0.3480)	Prec@(1,5) (89.5%, 99.5%)	
07/02 08:47:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][600/703]	Step 154776	lr 0.01777	Loss 0.4682 (0.3547)	Prec@(1,5) (89.2%, 99.4%)	
07/02 08:47:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][650/703]	Step 154826	lr 0.01777	Loss 0.4211 (0.3594)	Prec@(1,5) (89.0%, 99.4%)	
07/02 08:47:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][700/703]	Step 154876	lr 0.01777	Loss 0.3202 (0.3646)	Prec@(1,5) (88.9%, 99.4%)	
07/02 08:47:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [219][703/703]	Step 154879	lr 0.01777	Loss 0.3381 (0.3648)	Prec@(1,5) (88.9%, 99.4%)	
07/02 08:48:00午後 finetuneTeacher_trainer.py:180 [INFO] Train: [219/299] Final Prec@1 88.8511%
07/02 08:48:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [219][50/79]	Step 154880	Loss 1.8042	Prec@(1,5) (58.0%, 83.7%)
07/02 08:48:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [219][78/79]	Step 154880	Loss 1.7805	Prec@(1,5) (58.2%, 84.3%)
07/02 08:48:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [219/299] Final Prec@1 58.2000%
07/02 08:48:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:48:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][50/703]	Step 154930	lr 0.01738	Loss 0.2830 (0.3013)	Prec@(1,5) (91.2%, 99.7%)	
07/02 08:48:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][100/703]	Step 154980	lr 0.01738	Loss 0.2814 (0.3187)	Prec@(1,5) (90.3%, 99.6%)	
07/02 08:48:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][150/703]	Step 155030	lr 0.01738	Loss 0.3083 (0.3200)	Prec@(1,5) (90.4%, 99.5%)	
07/02 08:48:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][200/703]	Step 155080	lr 0.01738	Loss 0.3564 (0.3177)	Prec@(1,5) (90.5%, 99.5%)	
07/02 08:48:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][250/703]	Step 155130	lr 0.01738	Loss 0.2496 (0.3187)	Prec@(1,5) (90.5%, 99.6%)	
07/02 08:48:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][300/703]	Step 155180	lr 0.01738	Loss 0.4535 (0.3230)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:48:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][350/703]	Step 155230	lr 0.01738	Loss 0.3880 (0.3266)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:48:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][400/703]	Step 155280	lr 0.01738	Loss 0.3112 (0.3300)	Prec@(1,5) (90.1%, 99.5%)	
07/02 08:48:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][450/703]	Step 155330	lr 0.01738	Loss 0.3312 (0.3317)	Prec@(1,5) (90.0%, 99.5%)	
07/02 08:48:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][500/703]	Step 155380	lr 0.01738	Loss 0.2337 (0.3350)	Prec@(1,5) (89.9%, 99.5%)	
07/02 08:48:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][550/703]	Step 155430	lr 0.01738	Loss 0.4355 (0.3398)	Prec@(1,5) (89.7%, 99.5%)	
07/02 08:48:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][600/703]	Step 155480	lr 0.01738	Loss 0.4064 (0.3443)	Prec@(1,5) (89.6%, 99.4%)	
07/02 08:48:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][650/703]	Step 155530	lr 0.01738	Loss 0.5578 (0.3502)	Prec@(1,5) (89.4%, 99.4%)	
07/02 08:48:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][700/703]	Step 155580	lr 0.01738	Loss 0.4876 (0.3545)	Prec@(1,5) (89.2%, 99.4%)	
07/02 08:48:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [220][703/703]	Step 155583	lr 0.01738	Loss 0.3171 (0.3547)	Prec@(1,5) (89.2%, 99.4%)	
07/02 08:48:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [220/299] Final Prec@1 89.2022%
07/02 08:48:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [220][50/79]	Step 155584	Loss 1.7286	Prec@(1,5) (59.2%, 84.4%)
07/02 08:48:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [220][78/79]	Step 155584	Loss 1.7684	Prec@(1,5) (58.5%, 84.2%)
07/02 08:48:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [220/299] Final Prec@1 58.4800%
07/02 08:48:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:48:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][50/703]	Step 155634	lr 0.01699	Loss 0.3121 (0.3156)	Prec@(1,5) (90.9%, 99.7%)	
07/02 08:48:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][100/703]	Step 155684	lr 0.01699	Loss 0.2909 (0.2978)	Prec@(1,5) (91.3%, 99.7%)	
07/02 08:48:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][150/703]	Step 155734	lr 0.01699	Loss 0.4653 (0.3051)	Prec@(1,5) (91.1%, 99.7%)	
07/02 08:48:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][200/703]	Step 155784	lr 0.01699	Loss 0.3075 (0.3077)	Prec@(1,5) (90.9%, 99.6%)	
07/02 08:49:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][250/703]	Step 155834	lr 0.01699	Loss 0.2878 (0.3081)	Prec@(1,5) (90.9%, 99.6%)	
07/02 08:49:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][300/703]	Step 155884	lr 0.01699	Loss 0.4768 (0.3146)	Prec@(1,5) (90.6%, 99.6%)	
07/02 08:49:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][350/703]	Step 155934	lr 0.01699	Loss 0.3324 (0.3192)	Prec@(1,5) (90.4%, 99.5%)	
07/02 08:49:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][400/703]	Step 155984	lr 0.01699	Loss 0.3582 (0.3233)	Prec@(1,5) (90.4%, 99.5%)	
07/02 08:49:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][450/703]	Step 156034	lr 0.01699	Loss 0.4505 (0.3271)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:49:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][500/703]	Step 156084	lr 0.01699	Loss 0.3526 (0.3327)	Prec@(1,5) (90.0%, 99.5%)	
07/02 08:49:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][550/703]	Step 156134	lr 0.01699	Loss 0.3180 (0.3375)	Prec@(1,5) (89.8%, 99.5%)	
07/02 08:49:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][600/703]	Step 156184	lr 0.01699	Loss 0.5083 (0.3438)	Prec@(1,5) (89.6%, 99.5%)	
07/02 08:49:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][650/703]	Step 156234	lr 0.01699	Loss 0.6030 (0.3498)	Prec@(1,5) (89.4%, 99.4%)	
07/02 08:49:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][700/703]	Step 156284	lr 0.01699	Loss 0.3611 (0.3536)	Prec@(1,5) (89.3%, 99.4%)	
07/02 08:49:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [221][703/703]	Step 156287	lr 0.01699	Loss 0.4856 (0.3537)	Prec@(1,5) (89.2%, 99.4%)	
07/02 08:49:30午後 finetuneTeacher_trainer.py:180 [INFO] Train: [221/299] Final Prec@1 89.2378%
07/02 08:49:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [221][50/79]	Step 156288	Loss 1.8088	Prec@(1,5) (57.6%, 84.4%)
07/02 08:49:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [221][78/79]	Step 156288	Loss 1.7812	Prec@(1,5) (57.4%, 84.5%)
07/02 08:49:31午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [221/299] Final Prec@1 57.4200%
07/02 08:49:31午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:49:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][50/703]	Step 156338	lr 0.01661	Loss 0.3280 (0.2986)	Prec@(1,5) (91.6%, 99.7%)	
07/02 08:49:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][100/703]	Step 156388	lr 0.01661	Loss 0.2719 (0.2916)	Prec@(1,5) (91.8%, 99.7%)	
07/02 08:49:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][150/703]	Step 156438	lr 0.01661	Loss 0.2050 (0.2861)	Prec@(1,5) (92.0%, 99.7%)	
07/02 08:49:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][200/703]	Step 156488	lr 0.01661	Loss 0.3641 (0.2908)	Prec@(1,5) (91.7%, 99.6%)	
07/02 08:49:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][250/703]	Step 156538	lr 0.01661	Loss 0.3690 (0.2968)	Prec@(1,5) (91.4%, 99.6%)	
07/02 08:49:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][300/703]	Step 156588	lr 0.01661	Loss 0.2152 (0.3025)	Prec@(1,5) (91.2%, 99.6%)	
07/02 08:49:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][350/703]	Step 156638	lr 0.01661	Loss 0.5562 (0.3065)	Prec@(1,5) (91.0%, 99.6%)	
07/02 08:49:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][400/703]	Step 156688	lr 0.01661	Loss 0.3695 (0.3137)	Prec@(1,5) (90.8%, 99.6%)	
07/02 08:50:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][450/703]	Step 156738	lr 0.01661	Loss 0.2812 (0.3201)	Prec@(1,5) (90.5%, 99.5%)	
07/02 08:50:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][500/703]	Step 156788	lr 0.01661	Loss 0.4630 (0.3248)	Prec@(1,5) (90.3%, 99.5%)	
07/02 08:50:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][550/703]	Step 156838	lr 0.01661	Loss 0.5845 (0.3293)	Prec@(1,5) (90.1%, 99.5%)	
07/02 08:50:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][600/703]	Step 156888	lr 0.01661	Loss 0.3672 (0.3330)	Prec@(1,5) (90.0%, 99.5%)	
07/02 08:50:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][650/703]	Step 156938	lr 0.01661	Loss 0.2891 (0.3359)	Prec@(1,5) (89.9%, 99.5%)	
07/02 08:50:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][700/703]	Step 156988	lr 0.01661	Loss 0.4145 (0.3406)	Prec@(1,5) (89.7%, 99.5%)	
07/02 08:50:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [222][703/703]	Step 156991	lr 0.01661	Loss 0.3721 (0.3412)	Prec@(1,5) (89.7%, 99.5%)	
07/02 08:50:15午後 finetuneTeacher_trainer.py:180 [INFO] Train: [222/299] Final Prec@1 89.6956%
07/02 08:50:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [222][50/79]	Step 156992	Loss 1.7621	Prec@(1,5) (58.6%, 84.7%)
07/02 08:50:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [222][78/79]	Step 156992	Loss 1.7692	Prec@(1,5) (58.4%, 84.3%)
07/02 08:50:17午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [222/299] Final Prec@1 58.3400%
07/02 08:50:17午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:50:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][50/703]	Step 157042	lr 0.01624	Loss 0.1976 (0.2838)	Prec@(1,5) (92.1%, 99.6%)	
07/02 08:50:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][100/703]	Step 157092	lr 0.01624	Loss 0.2507 (0.2876)	Prec@(1,5) (91.7%, 99.6%)	
07/02 08:50:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][150/703]	Step 157142	lr 0.01624	Loss 0.3262 (0.2874)	Prec@(1,5) (91.6%, 99.6%)	
07/02 08:50:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][200/703]	Step 157192	lr 0.01624	Loss 0.2901 (0.2935)	Prec@(1,5) (91.4%, 99.6%)	
07/02 08:50:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][250/703]	Step 157242	lr 0.01624	Loss 0.4709 (0.2952)	Prec@(1,5) (91.2%, 99.6%)	
07/02 08:50:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][300/703]	Step 157292	lr 0.01624	Loss 0.2228 (0.2977)	Prec@(1,5) (91.1%, 99.6%)	
07/02 08:50:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][350/703]	Step 157342	lr 0.01624	Loss 0.2246 (0.2994)	Prec@(1,5) (90.9%, 99.6%)	
07/02 08:50:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][400/703]	Step 157392	lr 0.01624	Loss 0.2071 (0.3035)	Prec@(1,5) (90.8%, 99.6%)	
07/02 08:50:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][450/703]	Step 157442	lr 0.01624	Loss 0.3663 (0.3087)	Prec@(1,5) (90.7%, 99.6%)	
07/02 08:50:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][500/703]	Step 157492	lr 0.01624	Loss 0.2696 (0.3119)	Prec@(1,5) (90.6%, 99.6%)	
07/02 08:50:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][550/703]	Step 157542	lr 0.01624	Loss 0.3574 (0.3169)	Prec@(1,5) (90.4%, 99.6%)	
07/02 08:50:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][600/703]	Step 157592	lr 0.01624	Loss 0.4960 (0.3202)	Prec@(1,5) (90.3%, 99.6%)	
07/02 08:50:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][650/703]	Step 157642	lr 0.01624	Loss 0.3656 (0.3252)	Prec@(1,5) (90.1%, 99.5%)	
07/02 08:51:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][700/703]	Step 157692	lr 0.01624	Loss 0.3063 (0.3297)	Prec@(1,5) (89.9%, 99.5%)	
07/02 08:51:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [223][703/703]	Step 157695	lr 0.01624	Loss 0.5743 (0.3303)	Prec@(1,5) (89.9%, 99.5%)	
07/02 08:51:00午後 finetuneTeacher_trainer.py:180 [INFO] Train: [223/299] Final Prec@1 89.8778%
07/02 08:51:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [223][50/79]	Step 157696	Loss 1.7446	Prec@(1,5) (58.2%, 85.5%)
07/02 08:51:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [223][78/79]	Step 157696	Loss 1.7427	Prec@(1,5) (58.2%, 85.2%)
07/02 08:51:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [223/299] Final Prec@1 58.2000%
07/02 08:51:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:51:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][50/703]	Step 157746	lr 0.01587	Loss 0.3284 (0.3003)	Prec@(1,5) (91.1%, 99.7%)	
07/02 08:51:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][100/703]	Step 157796	lr 0.01587	Loss 0.2739 (0.2923)	Prec@(1,5) (91.2%, 99.7%)	
07/02 08:51:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][150/703]	Step 157846	lr 0.01587	Loss 0.2577 (0.2899)	Prec@(1,5) (91.4%, 99.7%)	
07/02 08:51:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][200/703]	Step 157896	lr 0.01587	Loss 0.3439 (0.2887)	Prec@(1,5) (91.4%, 99.7%)	
07/02 08:51:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][250/703]	Step 157946	lr 0.01587	Loss 0.5105 (0.2912)	Prec@(1,5) (91.4%, 99.7%)	
07/02 08:51:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][300/703]	Step 157996	lr 0.01587	Loss 0.2256 (0.2917)	Prec@(1,5) (91.3%, 99.7%)	
07/02 08:51:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][350/703]	Step 158046	lr 0.01587	Loss 0.3077 (0.2985)	Prec@(1,5) (91.1%, 99.7%)	
07/02 08:51:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][400/703]	Step 158096	lr 0.01587	Loss 0.4152 (0.3021)	Prec@(1,5) (91.0%, 99.7%)	
07/02 08:51:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][450/703]	Step 158146	lr 0.01587	Loss 0.3506 (0.3053)	Prec@(1,5) (90.9%, 99.6%)	
07/02 08:51:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][500/703]	Step 158196	lr 0.01587	Loss 0.2726 (0.3093)	Prec@(1,5) (90.7%, 99.6%)	
07/02 08:51:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][550/703]	Step 158246	lr 0.01587	Loss 0.2880 (0.3134)	Prec@(1,5) (90.6%, 99.6%)	
07/02 08:51:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][600/703]	Step 158296	lr 0.01587	Loss 0.4676 (0.3176)	Prec@(1,5) (90.4%, 99.6%)	
07/02 08:51:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][650/703]	Step 158346	lr 0.01587	Loss 0.4417 (0.3227)	Prec@(1,5) (90.2%, 99.6%)	
07/02 08:51:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][700/703]	Step 158396	lr 0.01587	Loss 0.5282 (0.3259)	Prec@(1,5) (90.1%, 99.5%)	
07/02 08:51:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [224][703/703]	Step 158399	lr 0.01587	Loss 0.2713 (0.3259)	Prec@(1,5) (90.1%, 99.5%)	
07/02 08:51:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [224/299] Final Prec@1 90.0844%
07/02 08:51:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [224][50/79]	Step 158400	Loss 1.6613	Prec@(1,5) (59.3%, 85.4%)
07/02 08:51:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [224][78/79]	Step 158400	Loss 1.7010	Prec@(1,5) (59.2%, 85.3%)
07/02 08:51:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [224/299] Final Prec@1 59.2200%
07/02 08:51:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.5800%
07/02 08:51:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][50/703]	Step 158450	lr 0.0155	Loss 0.2409 (0.2538)	Prec@(1,5) (92.6%, 99.7%)	
07/02 08:51:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][100/703]	Step 158500	lr 0.0155	Loss 0.2020 (0.2506)	Prec@(1,5) (92.6%, 99.8%)	
07/02 08:51:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][150/703]	Step 158550	lr 0.0155	Loss 0.3007 (0.2491)	Prec@(1,5) (92.8%, 99.7%)	
07/02 08:52:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][200/703]	Step 158600	lr 0.0155	Loss 0.2845 (0.2506)	Prec@(1,5) (92.6%, 99.7%)	
07/02 08:52:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][250/703]	Step 158650	lr 0.0155	Loss 0.2478 (0.2545)	Prec@(1,5) (92.5%, 99.8%)	
07/02 08:52:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][300/703]	Step 158700	lr 0.0155	Loss 0.2043 (0.2608)	Prec@(1,5) (92.3%, 99.8%)	
07/02 08:52:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][350/703]	Step 158750	lr 0.0155	Loss 0.2986 (0.2643)	Prec@(1,5) (92.2%, 99.8%)	
07/02 08:52:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][400/703]	Step 158800	lr 0.0155	Loss 0.3295 (0.2721)	Prec@(1,5) (91.9%, 99.7%)	
07/02 08:52:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][450/703]	Step 158850	lr 0.0155	Loss 0.2527 (0.2768)	Prec@(1,5) (91.8%, 99.7%)	
07/02 08:52:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][500/703]	Step 158900	lr 0.0155	Loss 0.2723 (0.2830)	Prec@(1,5) (91.5%, 99.7%)	
07/02 08:52:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][550/703]	Step 158950	lr 0.0155	Loss 0.2548 (0.2892)	Prec@(1,5) (91.3%, 99.7%)	
07/02 08:52:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][600/703]	Step 159000	lr 0.0155	Loss 0.4002 (0.2966)	Prec@(1,5) (91.0%, 99.7%)	
07/02 08:52:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][650/703]	Step 159050	lr 0.0155	Loss 0.3752 (0.3020)	Prec@(1,5) (90.8%, 99.6%)	
07/02 08:52:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][700/703]	Step 159100	lr 0.0155	Loss 0.3731 (0.3069)	Prec@(1,5) (90.7%, 99.6%)	
07/02 08:52:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [225][703/703]	Step 159103	lr 0.0155	Loss 0.3319 (0.3071)	Prec@(1,5) (90.7%, 99.6%)	
07/02 08:52:30午後 finetuneTeacher_trainer.py:180 [INFO] Train: [225/299] Final Prec@1 90.6622%
07/02 08:52:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [225][50/79]	Step 159104	Loss 1.7014	Prec@(1,5) (59.9%, 84.9%)
07/02 08:52:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [225][78/79]	Step 159104	Loss 1.7205	Prec@(1,5) (59.9%, 84.6%)
07/02 08:52:31午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [225/299] Final Prec@1 59.8800%
07/02 08:52:32午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.8800%
07/02 08:52:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][50/703]	Step 159154	lr 0.01513	Loss 0.1365 (0.2718)	Prec@(1,5) (91.8%, 99.9%)	
07/02 08:52:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][100/703]	Step 159204	lr 0.01513	Loss 0.3499 (0.2745)	Prec@(1,5) (91.7%, 99.7%)	
07/02 08:52:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][150/703]	Step 159254	lr 0.01513	Loss 0.2051 (0.2715)	Prec@(1,5) (91.9%, 99.7%)	
07/02 08:52:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][200/703]	Step 159304	lr 0.01513	Loss 0.4662 (0.2684)	Prec@(1,5) (92.0%, 99.7%)	
07/02 08:52:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][250/703]	Step 159354	lr 0.01513	Loss 0.3227 (0.2702)	Prec@(1,5) (91.9%, 99.7%)	
07/02 08:52:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][300/703]	Step 159404	lr 0.01513	Loss 0.3629 (0.2732)	Prec@(1,5) (91.9%, 99.7%)	
07/02 08:52:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][350/703]	Step 159454	lr 0.01513	Loss 0.3551 (0.2793)	Prec@(1,5) (91.7%, 99.7%)	
07/02 08:52:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][400/703]	Step 159504	lr 0.01513	Loss 0.2856 (0.2831)	Prec@(1,5) (91.6%, 99.7%)	
07/02 08:53:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][450/703]	Step 159554	lr 0.01513	Loss 0.2538 (0.2841)	Prec@(1,5) (91.5%, 99.7%)	
07/02 08:53:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][500/703]	Step 159604	lr 0.01513	Loss 0.2701 (0.2841)	Prec@(1,5) (91.6%, 99.7%)	
07/02 08:53:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][550/703]	Step 159654	lr 0.01513	Loss 0.4016 (0.2860)	Prec@(1,5) (91.5%, 99.7%)	
07/02 08:53:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][600/703]	Step 159704	lr 0.01513	Loss 0.3785 (0.2891)	Prec@(1,5) (91.5%, 99.7%)	
07/02 08:53:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][650/703]	Step 159754	lr 0.01513	Loss 0.6096 (0.2931)	Prec@(1,5) (91.3%, 99.7%)	
07/02 08:53:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][700/703]	Step 159804	lr 0.01513	Loss 0.3944 (0.2976)	Prec@(1,5) (91.1%, 99.6%)	
07/02 08:53:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [226][703/703]	Step 159807	lr 0.01513	Loss 0.1872 (0.2978)	Prec@(1,5) (91.1%, 99.6%)	
07/02 08:53:16午後 finetuneTeacher_trainer.py:180 [INFO] Train: [226/299] Final Prec@1 91.0978%
07/02 08:53:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [226][50/79]	Step 159808	Loss 1.7323	Prec@(1,5) (59.6%, 85.4%)
07/02 08:53:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [226][78/79]	Step 159808	Loss 1.7587	Prec@(1,5) (58.7%, 85.0%)
07/02 08:53:17午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [226/299] Final Prec@1 58.7600%
07/02 08:53:17午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.8800%
07/02 08:53:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][50/703]	Step 159858	lr 0.01477	Loss 0.3096 (0.2583)	Prec@(1,5) (92.8%, 99.9%)	
07/02 08:53:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][100/703]	Step 159908	lr 0.01477	Loss 0.2455 (0.2464)	Prec@(1,5) (93.3%, 99.8%)	
07/02 08:53:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][150/703]	Step 159958	lr 0.01477	Loss 0.2618 (0.2594)	Prec@(1,5) (92.9%, 99.8%)	
07/02 08:53:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][200/703]	Step 160008	lr 0.01477	Loss 0.3989 (0.2569)	Prec@(1,5) (92.8%, 99.8%)	
07/02 08:53:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][250/703]	Step 160058	lr 0.01477	Loss 0.1891 (0.2526)	Prec@(1,5) (92.9%, 99.8%)	
07/02 08:53:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][300/703]	Step 160108	lr 0.01477	Loss 0.2650 (0.2507)	Prec@(1,5) (92.9%, 99.8%)	
07/02 08:53:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][350/703]	Step 160158	lr 0.01477	Loss 0.1975 (0.2534)	Prec@(1,5) (92.8%, 99.7%)	
07/02 08:53:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][400/703]	Step 160208	lr 0.01477	Loss 0.3762 (0.2586)	Prec@(1,5) (92.6%, 99.8%)	
07/02 08:53:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][450/703]	Step 160258	lr 0.01477	Loss 0.3604 (0.2610)	Prec@(1,5) (92.5%, 99.8%)	
07/02 08:53:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][500/703]	Step 160308	lr 0.01477	Loss 0.3634 (0.2622)	Prec@(1,5) (92.5%, 99.8%)	
07/02 08:53:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][550/703]	Step 160358	lr 0.01477	Loss 0.3568 (0.2640)	Prec@(1,5) (92.4%, 99.7%)	
07/02 08:53:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][600/703]	Step 160408	lr 0.01477	Loss 0.2483 (0.2680)	Prec@(1,5) (92.2%, 99.7%)	
07/02 08:53:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][650/703]	Step 160458	lr 0.01477	Loss 0.3717 (0.2721)	Prec@(1,5) (92.0%, 99.7%)	
07/02 08:54:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][700/703]	Step 160508	lr 0.01477	Loss 0.3526 (0.2751)	Prec@(1,5) (91.9%, 99.7%)	
07/02 08:54:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [227][703/703]	Step 160511	lr 0.01477	Loss 0.1682 (0.2751)	Prec@(1,5) (91.9%, 99.7%)	
07/02 08:54:00午後 finetuneTeacher_trainer.py:180 [INFO] Train: [227/299] Final Prec@1 91.8889%
07/02 08:54:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [227][50/79]	Step 160512	Loss 1.8103	Prec@(1,5) (58.9%, 83.9%)
07/02 08:54:02午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [227][78/79]	Step 160512	Loss 1.7645	Prec@(1,5) (59.6%, 84.5%)
07/02 08:54:02午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [227/299] Final Prec@1 59.5800%
07/02 08:54:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.8800%
07/02 08:54:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][50/703]	Step 160562	lr 0.01442	Loss 0.2168 (0.2411)	Prec@(1,5) (93.2%, 99.7%)	
07/02 08:54:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][100/703]	Step 160612	lr 0.01442	Loss 0.1795 (0.2410)	Prec@(1,5) (93.1%, 99.7%)	
07/02 08:54:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][150/703]	Step 160662	lr 0.01442	Loss 0.1640 (0.2477)	Prec@(1,5) (92.9%, 99.7%)	
07/02 08:54:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][200/703]	Step 160712	lr 0.01442	Loss 0.1693 (0.2491)	Prec@(1,5) (92.8%, 99.7%)	
07/02 08:54:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][250/703]	Step 160762	lr 0.01442	Loss 0.2442 (0.2499)	Prec@(1,5) (92.9%, 99.8%)	
07/02 08:54:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][300/703]	Step 160812	lr 0.01442	Loss 0.2461 (0.2471)	Prec@(1,5) (92.9%, 99.8%)	
07/02 08:54:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][350/703]	Step 160862	lr 0.01442	Loss 0.1632 (0.2511)	Prec@(1,5) (92.8%, 99.8%)	
07/02 08:54:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][400/703]	Step 160912	lr 0.01442	Loss 0.3089 (0.2520)	Prec@(1,5) (92.8%, 99.8%)	
07/02 08:54:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][450/703]	Step 160962	lr 0.01442	Loss 0.3440 (0.2550)	Prec@(1,5) (92.6%, 99.8%)	
07/02 08:54:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][500/703]	Step 161012	lr 0.01442	Loss 0.2310 (0.2581)	Prec@(1,5) (92.5%, 99.7%)	
07/02 08:54:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][550/703]	Step 161062	lr 0.01442	Loss 0.4222 (0.2613)	Prec@(1,5) (92.5%, 99.7%)	
07/02 08:54:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][600/703]	Step 161112	lr 0.01442	Loss 0.2597 (0.2638)	Prec@(1,5) (92.4%, 99.7%)	
07/02 08:54:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][650/703]	Step 161162	lr 0.01442	Loss 0.4103 (0.2665)	Prec@(1,5) (92.3%, 99.7%)	
07/02 08:54:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][700/703]	Step 161212	lr 0.01442	Loss 0.2778 (0.2683)	Prec@(1,5) (92.2%, 99.7%)	
07/02 08:54:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [228][703/703]	Step 161215	lr 0.01442	Loss 0.1934 (0.2683)	Prec@(1,5) (92.2%, 99.7%)	
07/02 08:54:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [228/299] Final Prec@1 92.2044%
07/02 08:54:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [228][50/79]	Step 161216	Loss 1.7448	Prec@(1,5) (59.9%, 85.0%)
07/02 08:54:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [228][78/79]	Step 161216	Loss 1.7510	Prec@(1,5) (59.8%, 84.8%)
07/02 08:54:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [228/299] Final Prec@1 59.8200%
07/02 08:54:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 59.8800%
07/02 08:54:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][50/703]	Step 161266	lr 0.01406	Loss 0.2230 (0.2424)	Prec@(1,5) (93.1%, 99.7%)	
07/02 08:54:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][100/703]	Step 161316	lr 0.01406	Loss 0.2139 (0.2304)	Prec@(1,5) (93.6%, 99.8%)	
07/02 08:54:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][150/703]	Step 161366	lr 0.01406	Loss 0.2813 (0.2273)	Prec@(1,5) (93.7%, 99.8%)	
07/02 08:54:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][200/703]	Step 161416	lr 0.01406	Loss 0.3337 (0.2293)	Prec@(1,5) (93.8%, 99.8%)	
07/02 08:55:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][250/703]	Step 161466	lr 0.01406	Loss 0.2648 (0.2298)	Prec@(1,5) (93.6%, 99.8%)	
07/02 08:55:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][300/703]	Step 161516	lr 0.01406	Loss 0.2805 (0.2326)	Prec@(1,5) (93.6%, 99.8%)	
07/02 08:55:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][350/703]	Step 161566	lr 0.01406	Loss 0.2158 (0.2358)	Prec@(1,5) (93.5%, 99.8%)	
07/02 08:55:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][400/703]	Step 161616	lr 0.01406	Loss 0.2281 (0.2383)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:55:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][450/703]	Step 161666	lr 0.01406	Loss 0.2477 (0.2384)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:55:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][500/703]	Step 161716	lr 0.01406	Loss 0.3152 (0.2427)	Prec@(1,5) (93.2%, 99.8%)	
07/02 08:55:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][550/703]	Step 161766	lr 0.01406	Loss 0.2391 (0.2478)	Prec@(1,5) (93.0%, 99.7%)	
07/02 08:55:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][600/703]	Step 161816	lr 0.01406	Loss 0.2983 (0.2526)	Prec@(1,5) (92.8%, 99.7%)	
07/02 08:55:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][650/703]	Step 161866	lr 0.01406	Loss 0.4585 (0.2558)	Prec@(1,5) (92.6%, 99.7%)	
07/02 08:55:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][700/703]	Step 161916	lr 0.01406	Loss 0.1751 (0.2580)	Prec@(1,5) (92.6%, 99.7%)	
07/02 08:55:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [229][703/703]	Step 161919	lr 0.01406	Loss 0.4377 (0.2583)	Prec@(1,5) (92.6%, 99.7%)	
07/02 08:55:29午後 finetuneTeacher_trainer.py:180 [INFO] Train: [229/299] Final Prec@1 92.5622%
07/02 08:55:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [229][50/79]	Step 161920	Loss 1.6812	Prec@(1,5) (60.1%, 86.0%)
07/02 08:55:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [229][78/79]	Step 161920	Loss 1.6866	Prec@(1,5) (60.5%, 85.8%)
07/02 08:55:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [229/299] Final Prec@1 60.4600%
07/02 08:55:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.4600%
07/02 08:55:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][50/703]	Step 161970	lr 0.01371	Loss 0.2281 (0.2235)	Prec@(1,5) (94.1%, 99.8%)	
07/02 08:55:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][100/703]	Step 162020	lr 0.01371	Loss 0.2696 (0.2252)	Prec@(1,5) (93.7%, 99.8%)	
07/02 08:55:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][150/703]	Step 162070	lr 0.01371	Loss 0.2614 (0.2251)	Prec@(1,5) (93.7%, 99.8%)	
07/02 08:55:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][200/703]	Step 162120	lr 0.01371	Loss 0.1606 (0.2236)	Prec@(1,5) (93.8%, 99.8%)	
07/02 08:55:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][250/703]	Step 162170	lr 0.01371	Loss 0.1840 (0.2281)	Prec@(1,5) (93.5%, 99.8%)	
07/02 08:55:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][300/703]	Step 162220	lr 0.01371	Loss 0.2263 (0.2309)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:55:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][350/703]	Step 162270	lr 0.01371	Loss 0.1639 (0.2333)	Prec@(1,5) (93.3%, 99.8%)	
07/02 08:55:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][400/703]	Step 162320	lr 0.01371	Loss 0.1352 (0.2339)	Prec@(1,5) (93.3%, 99.8%)	
07/02 08:55:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][450/703]	Step 162370	lr 0.01371	Loss 0.2215 (0.2358)	Prec@(1,5) (93.3%, 99.8%)	
07/02 08:56:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][500/703]	Step 162420	lr 0.01371	Loss 0.2239 (0.2380)	Prec@(1,5) (93.2%, 99.8%)	
07/02 08:56:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][550/703]	Step 162470	lr 0.01371	Loss 0.1653 (0.2403)	Prec@(1,5) (93.2%, 99.8%)	
07/02 08:56:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][600/703]	Step 162520	lr 0.01371	Loss 0.2514 (0.2440)	Prec@(1,5) (93.0%, 99.8%)	
07/02 08:56:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][650/703]	Step 162570	lr 0.01371	Loss 0.3138 (0.2463)	Prec@(1,5) (92.9%, 99.8%)	
07/02 08:56:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][700/703]	Step 162620	lr 0.01371	Loss 0.2453 (0.2507)	Prec@(1,5) (92.8%, 99.8%)	
07/02 08:56:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [230][703/703]	Step 162623	lr 0.01371	Loss 0.2533 (0.2508)	Prec@(1,5) (92.8%, 99.8%)	
07/02 08:56:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [230/299] Final Prec@1 92.7889%
07/02 08:56:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [230][50/79]	Step 162624	Loss 1.6830	Prec@(1,5) (59.8%, 84.5%)
07/02 08:56:16午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [230][78/79]	Step 162624	Loss 1.7055	Prec@(1,5) (59.6%, 84.6%)
07/02 08:56:16午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [230/299] Final Prec@1 59.6400%
07/02 08:56:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.4600%
07/02 08:56:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][50/703]	Step 162674	lr 0.01337	Loss 0.1128 (0.2289)	Prec@(1,5) (93.3%, 99.7%)	
07/02 08:56:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][100/703]	Step 162724	lr 0.01337	Loss 0.1951 (0.2263)	Prec@(1,5) (93.3%, 99.8%)	
07/02 08:56:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][150/703]	Step 162774	lr 0.01337	Loss 0.2569 (0.2244)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:56:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][200/703]	Step 162824	lr 0.01337	Loss 0.2264 (0.2248)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:56:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][250/703]	Step 162874	lr 0.01337	Loss 0.1706 (0.2240)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:56:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][300/703]	Step 162924	lr 0.01337	Loss 0.2503 (0.2231)	Prec@(1,5) (93.6%, 99.8%)	
07/02 08:56:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][350/703]	Step 162974	lr 0.01337	Loss 0.2404 (0.2251)	Prec@(1,5) (93.5%, 99.8%)	
07/02 08:56:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][400/703]	Step 163024	lr 0.01337	Loss 0.1163 (0.2249)	Prec@(1,5) (93.6%, 99.8%)	
07/02 08:56:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][450/703]	Step 163074	lr 0.01337	Loss 0.3472 (0.2277)	Prec@(1,5) (93.5%, 99.8%)	
07/02 08:56:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][500/703]	Step 163124	lr 0.01337	Loss 0.2111 (0.2294)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:56:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][550/703]	Step 163174	lr 0.01337	Loss 0.2180 (0.2320)	Prec@(1,5) (93.4%, 99.8%)	
07/02 08:56:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][600/703]	Step 163224	lr 0.01337	Loss 0.3341 (0.2339)	Prec@(1,5) (93.3%, 99.8%)	
07/02 08:56:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][650/703]	Step 163274	lr 0.01337	Loss 0.2690 (0.2355)	Prec@(1,5) (93.2%, 99.8%)	
07/02 08:56:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][700/703]	Step 163324	lr 0.01337	Loss 0.2263 (0.2370)	Prec@(1,5) (93.2%, 99.8%)	
07/02 08:56:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [231][703/703]	Step 163327	lr 0.01337	Loss 0.4052 (0.2373)	Prec@(1,5) (93.2%, 99.8%)	
07/02 08:56:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [231/299] Final Prec@1 93.1978%
07/02 08:57:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [231][50/79]	Step 163328	Loss 1.7776	Prec@(1,5) (59.1%, 84.9%)
07/02 08:57:01午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [231][78/79]	Step 163328	Loss 1.7104	Prec@(1,5) (60.7%, 85.5%)
07/02 08:57:01午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [231/299] Final Prec@1 60.6400%
07/02 08:57:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.6400%
07/02 08:57:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][50/703]	Step 163378	lr 0.01303	Loss 0.1657 (0.2024)	Prec@(1,5) (94.6%, 99.9%)	
07/02 08:57:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][100/703]	Step 163428	lr 0.01303	Loss 0.1063 (0.1977)	Prec@(1,5) (94.6%, 99.9%)	
07/02 08:57:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][150/703]	Step 163478	lr 0.01303	Loss 0.2407 (0.1962)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:57:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][200/703]	Step 163528	lr 0.01303	Loss 0.2081 (0.1966)	Prec@(1,5) (94.7%, 99.9%)	
07/02 08:57:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][250/703]	Step 163578	lr 0.01303	Loss 0.3946 (0.2007)	Prec@(1,5) (94.6%, 99.9%)	
07/02 08:57:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][300/703]	Step 163628	lr 0.01303	Loss 0.2172 (0.2040)	Prec@(1,5) (94.4%, 99.9%)	
07/02 08:57:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][350/703]	Step 163678	lr 0.01303	Loss 0.3193 (0.2054)	Prec@(1,5) (94.4%, 99.9%)	
07/02 08:57:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][400/703]	Step 163728	lr 0.01303	Loss 0.2458 (0.2059)	Prec@(1,5) (94.4%, 99.9%)	
07/02 08:57:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][450/703]	Step 163778	lr 0.01303	Loss 0.1734 (0.2092)	Prec@(1,5) (94.3%, 99.8%)	
07/02 08:57:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][500/703]	Step 163828	lr 0.01303	Loss 0.2194 (0.2114)	Prec@(1,5) (94.2%, 99.8%)	
07/02 08:57:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][550/703]	Step 163878	lr 0.01303	Loss 0.1487 (0.2135)	Prec@(1,5) (94.2%, 99.8%)	
07/02 08:57:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][600/703]	Step 163928	lr 0.01303	Loss 0.3108 (0.2135)	Prec@(1,5) (94.1%, 99.8%)	
07/02 08:57:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][650/703]	Step 163978	lr 0.01303	Loss 0.3249 (0.2165)	Prec@(1,5) (94.0%, 99.8%)	
07/02 08:57:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][700/703]	Step 164028	lr 0.01303	Loss 0.2810 (0.2199)	Prec@(1,5) (93.8%, 99.8%)	
07/02 08:57:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [232][703/703]	Step 164031	lr 0.01303	Loss 0.2529 (0.2202)	Prec@(1,5) (93.8%, 99.8%)	
07/02 08:57:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [232/299] Final Prec@1 93.8200%
07/02 08:57:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [232][50/79]	Step 164032	Loss 1.7341	Prec@(1,5) (59.9%, 85.7%)
07/02 08:57:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [232][78/79]	Step 164032	Loss 1.7257	Prec@(1,5) (59.8%, 85.5%)
07/02 08:57:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [232/299] Final Prec@1 59.7200%
07/02 08:57:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.6400%
07/02 08:57:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][50/703]	Step 164082	lr 0.01269	Loss 0.1056 (0.2061)	Prec@(1,5) (94.7%, 99.9%)	
07/02 08:57:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][100/703]	Step 164132	lr 0.01269	Loss 0.2304 (0.1973)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:57:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][150/703]	Step 164182	lr 0.01269	Loss 0.3117 (0.1941)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:57:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][200/703]	Step 164232	lr 0.01269	Loss 0.2352 (0.1941)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:58:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][250/703]	Step 164282	lr 0.01269	Loss 0.2368 (0.1930)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:58:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][300/703]	Step 164332	lr 0.01269	Loss 0.1967 (0.1931)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:58:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][350/703]	Step 164382	lr 0.01269	Loss 0.2018 (0.1940)	Prec@(1,5) (94.7%, 99.9%)	
07/02 08:58:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][400/703]	Step 164432	lr 0.01269	Loss 0.2376 (0.1981)	Prec@(1,5) (94.6%, 99.9%)	
07/02 08:58:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][450/703]	Step 164482	lr 0.01269	Loss 0.1324 (0.2013)	Prec@(1,5) (94.4%, 99.9%)	
07/02 08:58:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][500/703]	Step 164532	lr 0.01269	Loss 0.2384 (0.2045)	Prec@(1,5) (94.3%, 99.9%)	
07/02 08:58:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][550/703]	Step 164582	lr 0.01269	Loss 0.2749 (0.2069)	Prec@(1,5) (94.2%, 99.9%)	
07/02 08:58:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][600/703]	Step 164632	lr 0.01269	Loss 0.1371 (0.2099)	Prec@(1,5) (94.1%, 99.8%)	
07/02 08:58:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][650/703]	Step 164682	lr 0.01269	Loss 0.2651 (0.2131)	Prec@(1,5) (94.0%, 99.8%)	
07/02 08:58:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][700/703]	Step 164732	lr 0.01269	Loss 0.2064 (0.2159)	Prec@(1,5) (93.9%, 99.8%)	
07/02 08:58:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [233][703/703]	Step 164735	lr 0.01269	Loss 0.2914 (0.2160)	Prec@(1,5) (93.9%, 99.8%)	
07/02 08:58:29午後 finetuneTeacher_trainer.py:180 [INFO] Train: [233/299] Final Prec@1 93.8889%
07/02 08:58:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [233][50/79]	Step 164736	Loss 1.7149	Prec@(1,5) (61.0%, 85.1%)
07/02 08:58:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [233][78/79]	Step 164736	Loss 1.7595	Prec@(1,5) (60.0%, 84.6%)
07/02 08:58:31午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [233/299] Final Prec@1 59.9600%
07/02 08:58:31午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.6400%
07/02 08:58:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][50/703]	Step 164786	lr 0.01236	Loss 0.2504 (0.2045)	Prec@(1,5) (94.6%, 99.7%)	
07/02 08:58:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][100/703]	Step 164836	lr 0.01236	Loss 0.1862 (0.1962)	Prec@(1,5) (94.9%, 99.8%)	
07/02 08:58:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][150/703]	Step 164886	lr 0.01236	Loss 0.1829 (0.1989)	Prec@(1,5) (94.8%, 99.8%)	
07/02 08:58:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][200/703]	Step 164936	lr 0.01236	Loss 0.2706 (0.1977)	Prec@(1,5) (94.7%, 99.8%)	
07/02 08:58:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][250/703]	Step 164986	lr 0.01236	Loss 0.1990 (0.1996)	Prec@(1,5) (94.7%, 99.8%)	
07/02 08:58:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][300/703]	Step 165036	lr 0.01236	Loss 0.2068 (0.1983)	Prec@(1,5) (94.7%, 99.9%)	
07/02 08:58:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][350/703]	Step 165086	lr 0.01236	Loss 0.2033 (0.1987)	Prec@(1,5) (94.7%, 99.9%)	
07/02 08:58:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][400/703]	Step 165136	lr 0.01236	Loss 0.1294 (0.1996)	Prec@(1,5) (94.6%, 99.9%)	
07/02 08:58:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][450/703]	Step 165186	lr 0.01236	Loss 0.2615 (0.2034)	Prec@(1,5) (94.5%, 99.8%)	
07/02 08:59:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][500/703]	Step 165236	lr 0.01236	Loss 0.2327 (0.2057)	Prec@(1,5) (94.4%, 99.8%)	
07/02 08:59:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][550/703]	Step 165286	lr 0.01236	Loss 0.2825 (0.2087)	Prec@(1,5) (94.3%, 99.8%)	
07/02 08:59:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][600/703]	Step 165336	lr 0.01236	Loss 0.3118 (0.2104)	Prec@(1,5) (94.2%, 99.8%)	
07/02 08:59:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][650/703]	Step 165386	lr 0.01236	Loss 0.1852 (0.2124)	Prec@(1,5) (94.2%, 99.8%)	
07/02 08:59:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][700/703]	Step 165436	lr 0.01236	Loss 0.3046 (0.2145)	Prec@(1,5) (94.0%, 99.8%)	
07/02 08:59:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [234][703/703]	Step 165439	lr 0.01236	Loss 0.2475 (0.2150)	Prec@(1,5) (94.0%, 99.8%)	
07/02 08:59:14午後 finetuneTeacher_trainer.py:180 [INFO] Train: [234/299] Final Prec@1 94.0156%
07/02 08:59:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [234][50/79]	Step 165440	Loss 1.7063	Prec@(1,5) (59.5%, 85.5%)
07/02 08:59:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [234][78/79]	Step 165440	Loss 1.7468	Prec@(1,5) (59.4%, 85.1%)
07/02 08:59:15午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [234/299] Final Prec@1 59.3600%
07/02 08:59:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.6400%
07/02 08:59:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][50/703]	Step 165490	lr 0.01203	Loss 0.1301 (0.1834)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:59:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][100/703]	Step 165540	lr 0.01203	Loss 0.1032 (0.1765)	Prec@(1,5) (95.3%, 99.9%)	
07/02 08:59:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][150/703]	Step 165590	lr 0.01203	Loss 0.1755 (0.1797)	Prec@(1,5) (95.2%, 99.9%)	
07/02 08:59:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][200/703]	Step 165640	lr 0.01203	Loss 0.1844 (0.1752)	Prec@(1,5) (95.4%, 99.9%)	
07/02 08:59:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][250/703]	Step 165690	lr 0.01203	Loss 0.1789 (0.1784)	Prec@(1,5) (95.2%, 99.9%)	
07/02 08:59:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][300/703]	Step 165740	lr 0.01203	Loss 0.1981 (0.1807)	Prec@(1,5) (95.1%, 99.9%)	
07/02 08:59:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][350/703]	Step 165790	lr 0.01203	Loss 0.0914 (0.1828)	Prec@(1,5) (95.1%, 99.9%)	
07/02 08:59:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][400/703]	Step 165840	lr 0.01203	Loss 0.2970 (0.1811)	Prec@(1,5) (95.1%, 99.9%)	
07/02 08:59:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][450/703]	Step 165890	lr 0.01203	Loss 0.1445 (0.1838)	Prec@(1,5) (95.1%, 99.9%)	
07/02 08:59:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][500/703]	Step 165940	lr 0.01203	Loss 0.2208 (0.1864)	Prec@(1,5) (94.9%, 99.9%)	
07/02 08:59:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][550/703]	Step 165990	lr 0.01203	Loss 0.1819 (0.1879)	Prec@(1,5) (94.9%, 99.9%)	
07/02 08:59:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][600/703]	Step 166040	lr 0.01203	Loss 0.2481 (0.1897)	Prec@(1,5) (94.9%, 99.9%)	
07/02 08:59:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][650/703]	Step 166090	lr 0.01203	Loss 0.2537 (0.1904)	Prec@(1,5) (94.9%, 99.9%)	
07/02 08:59:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][700/703]	Step 166140	lr 0.01203	Loss 0.1411 (0.1925)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:59:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [235][703/703]	Step 166143	lr 0.01203	Loss 0.2983 (0.1929)	Prec@(1,5) (94.8%, 99.9%)	
07/02 08:59:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [235/299] Final Prec@1 94.8000%
07/02 09:00:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [235][50/79]	Step 166144	Loss 1.6423	Prec@(1,5) (61.7%, 85.7%)
07/02 09:00:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [235][78/79]	Step 166144	Loss 1.6750	Prec@(1,5) (60.7%, 85.8%)
07/02 09:00:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [235/299] Final Prec@1 60.7600%
07/02 09:00:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.7600%
07/02 09:00:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][50/703]	Step 166194	lr 0.01171	Loss 0.1459 (0.1756)	Prec@(1,5) (95.0%, 100.0%)	
07/02 09:00:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][100/703]	Step 166244	lr 0.01171	Loss 0.1296 (0.1750)	Prec@(1,5) (95.2%, 100.0%)	
07/02 09:00:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][150/703]	Step 166294	lr 0.01171	Loss 0.1074 (0.1686)	Prec@(1,5) (95.5%, 100.0%)	
07/02 09:00:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][200/703]	Step 166344	lr 0.01171	Loss 0.2213 (0.1707)	Prec@(1,5) (95.4%, 100.0%)	
07/02 09:00:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][250/703]	Step 166394	lr 0.01171	Loss 0.1552 (0.1785)	Prec@(1,5) (95.2%, 99.9%)	
07/02 09:00:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][300/703]	Step 166444	lr 0.01171	Loss 0.0889 (0.1799)	Prec@(1,5) (95.2%, 99.9%)	
07/02 09:00:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][350/703]	Step 166494	lr 0.01171	Loss 0.1404 (0.1820)	Prec@(1,5) (95.1%, 99.9%)	
07/02 09:00:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][400/703]	Step 166544	lr 0.01171	Loss 0.2000 (0.1850)	Prec@(1,5) (95.1%, 99.9%)	
07/02 09:00:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][450/703]	Step 166594	lr 0.01171	Loss 0.2273 (0.1863)	Prec@(1,5) (95.0%, 99.9%)	
07/02 09:00:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][500/703]	Step 166644	lr 0.01171	Loss 0.3080 (0.1891)	Prec@(1,5) (94.9%, 99.9%)	
07/02 09:00:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][550/703]	Step 166694	lr 0.01171	Loss 0.2392 (0.1909)	Prec@(1,5) (94.9%, 99.9%)	
07/02 09:00:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][600/703]	Step 166744	lr 0.01171	Loss 0.2485 (0.1924)	Prec@(1,5) (94.9%, 99.9%)	
07/02 09:00:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][650/703]	Step 166794	lr 0.01171	Loss 0.2976 (0.1952)	Prec@(1,5) (94.7%, 99.9%)	
07/02 09:00:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][700/703]	Step 166844	lr 0.01171	Loss 0.3597 (0.1977)	Prec@(1,5) (94.7%, 99.9%)	
07/02 09:00:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [236][703/703]	Step 166847	lr 0.01171	Loss 0.2461 (0.1980)	Prec@(1,5) (94.6%, 99.9%)	
07/02 09:00:44午後 finetuneTeacher_trainer.py:180 [INFO] Train: [236/299] Final Prec@1 94.6400%
07/02 09:00:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [236][50/79]	Step 166848	Loss 1.7044	Prec@(1,5) (60.7%, 84.9%)
07/02 09:00:45午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [236][78/79]	Step 166848	Loss 1.6994	Prec@(1,5) (61.1%, 85.0%)
07/02 09:00:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [236/299] Final Prec@1 61.0800%
07/02 09:00:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.0800%
07/02 09:00:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][50/703]	Step 166898	lr 0.01139	Loss 0.1715 (0.1649)	Prec@(1,5) (95.7%, 100.0%)	
07/02 09:00:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][100/703]	Step 166948	lr 0.01139	Loss 0.1706 (0.1701)	Prec@(1,5) (95.6%, 100.0%)	
07/02 09:00:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][150/703]	Step 166998	lr 0.01139	Loss 0.1586 (0.1685)	Prec@(1,5) (95.7%, 100.0%)	
07/02 09:00:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][200/703]	Step 167048	lr 0.01139	Loss 0.2201 (0.1645)	Prec@(1,5) (95.9%, 100.0%)	
07/02 09:01:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][250/703]	Step 167098	lr 0.01139	Loss 0.1457 (0.1646)	Prec@(1,5) (95.9%, 100.0%)	
07/02 09:01:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][300/703]	Step 167148	lr 0.01139	Loss 0.1269 (0.1684)	Prec@(1,5) (95.8%, 100.0%)	
07/02 09:01:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][350/703]	Step 167198	lr 0.01139	Loss 0.1833 (0.1708)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:01:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][400/703]	Step 167248	lr 0.01139	Loss 0.1524 (0.1725)	Prec@(1,5) (95.6%, 99.9%)	
07/02 09:01:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][450/703]	Step 167298	lr 0.01139	Loss 0.1440 (0.1746)	Prec@(1,5) (95.6%, 99.9%)	
07/02 09:01:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][500/703]	Step 167348	lr 0.01139	Loss 0.5003 (0.1759)	Prec@(1,5) (95.5%, 99.9%)	
07/02 09:01:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][550/703]	Step 167398	lr 0.01139	Loss 0.1383 (0.1800)	Prec@(1,5) (95.4%, 99.9%)	
07/02 09:01:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][600/703]	Step 167448	lr 0.01139	Loss 0.2556 (0.1823)	Prec@(1,5) (95.3%, 99.9%)	
07/02 09:01:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][650/703]	Step 167498	lr 0.01139	Loss 0.1871 (0.1839)	Prec@(1,5) (95.2%, 99.9%)	
07/02 09:01:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][700/703]	Step 167548	lr 0.01139	Loss 0.2809 (0.1856)	Prec@(1,5) (95.2%, 99.9%)	
07/02 09:01:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [237][703/703]	Step 167551	lr 0.01139	Loss 0.1943 (0.1858)	Prec@(1,5) (95.2%, 99.9%)	
07/02 09:01:29午後 finetuneTeacher_trainer.py:180 [INFO] Train: [237/299] Final Prec@1 95.1556%
07/02 09:01:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [237][50/79]	Step 167552	Loss 1.7212	Prec@(1,5) (60.4%, 84.4%)
07/02 09:01:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [237][78/79]	Step 167552	Loss 1.6948	Prec@(1,5) (60.7%, 85.2%)
07/02 09:01:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [237/299] Final Prec@1 60.6800%
07/02 09:01:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.0800%
07/02 09:01:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][50/703]	Step 167602	lr 0.01107	Loss 0.1847 (0.1800)	Prec@(1,5) (95.1%, 99.8%)	
07/02 09:01:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][100/703]	Step 167652	lr 0.01107	Loss 0.0875 (0.1716)	Prec@(1,5) (95.6%, 99.8%)	
07/02 09:01:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][150/703]	Step 167702	lr 0.01107	Loss 0.1549 (0.1699)	Prec@(1,5) (95.6%, 99.8%)	
07/02 09:01:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][200/703]	Step 167752	lr 0.01107	Loss 0.1354 (0.1680)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:01:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][250/703]	Step 167802	lr 0.01107	Loss 0.3555 (0.1675)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:01:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][300/703]	Step 167852	lr 0.01107	Loss 0.2361 (0.1670)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:01:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][350/703]	Step 167902	lr 0.01107	Loss 0.1736 (0.1681)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:01:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][400/703]	Step 167952	lr 0.01107	Loss 0.1331 (0.1704)	Prec@(1,5) (95.6%, 99.9%)	
07/02 09:01:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][450/703]	Step 168002	lr 0.01107	Loss 0.3032 (0.1729)	Prec@(1,5) (95.5%, 99.9%)	
07/02 09:02:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][500/703]	Step 168052	lr 0.01107	Loss 0.0988 (0.1724)	Prec@(1,5) (95.5%, 99.9%)	
07/02 09:02:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][550/703]	Step 168102	lr 0.01107	Loss 0.1893 (0.1730)	Prec@(1,5) (95.5%, 99.9%)	
07/02 09:02:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][600/703]	Step 168152	lr 0.01107	Loss 0.1601 (0.1747)	Prec@(1,5) (95.4%, 99.9%)	
07/02 09:02:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][650/703]	Step 168202	lr 0.01107	Loss 0.3404 (0.1754)	Prec@(1,5) (95.4%, 99.9%)	
07/02 09:02:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][700/703]	Step 168252	lr 0.01107	Loss 0.1791 (0.1765)	Prec@(1,5) (95.4%, 99.9%)	
07/02 09:02:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [238][703/703]	Step 168255	lr 0.01107	Loss 0.0831 (0.1764)	Prec@(1,5) (95.4%, 99.9%)	
07/02 09:02:13午後 finetuneTeacher_trainer.py:180 [INFO] Train: [238/299] Final Prec@1 95.3667%
07/02 09:02:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [238][50/79]	Step 168256	Loss 1.6309	Prec@(1,5) (62.1%, 86.3%)
07/02 09:02:15午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [238][78/79]	Step 168256	Loss 1.6578	Prec@(1,5) (61.8%, 86.1%)
07/02 09:02:15午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [238/299] Final Prec@1 61.7600%
07/02 09:02:15午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7600%
07/02 09:02:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][50/703]	Step 168306	lr 0.01076	Loss 0.1905 (0.1401)	Prec@(1,5) (96.5%, 99.9%)	
07/02 09:02:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][100/703]	Step 168356	lr 0.01076	Loss 0.1668 (0.1431)	Prec@(1,5) (96.3%, 100.0%)	
07/02 09:02:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][150/703]	Step 168406	lr 0.01076	Loss 0.1429 (0.1435)	Prec@(1,5) (96.5%, 100.0%)	
07/02 09:02:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][200/703]	Step 168456	lr 0.01076	Loss 0.1136 (0.1443)	Prec@(1,5) (96.4%, 99.9%)	
07/02 09:02:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][250/703]	Step 168506	lr 0.01076	Loss 0.1861 (0.1451)	Prec@(1,5) (96.4%, 99.9%)	
07/02 09:02:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][300/703]	Step 168556	lr 0.01076	Loss 0.1395 (0.1463)	Prec@(1,5) (96.4%, 99.9%)	
07/02 09:02:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][350/703]	Step 168606	lr 0.01076	Loss 0.1484 (0.1476)	Prec@(1,5) (96.4%, 99.9%)	
07/02 09:02:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][400/703]	Step 168656	lr 0.01076	Loss 0.1626 (0.1495)	Prec@(1,5) (96.3%, 99.9%)	
07/02 09:02:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][450/703]	Step 168706	lr 0.01076	Loss 0.1493 (0.1516)	Prec@(1,5) (96.2%, 99.9%)	
07/02 09:02:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][500/703]	Step 168756	lr 0.01076	Loss 0.1874 (0.1543)	Prec@(1,5) (96.1%, 99.9%)	
07/02 09:02:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][550/703]	Step 168806	lr 0.01076	Loss 0.1823 (0.1582)	Prec@(1,5) (96.0%, 99.9%)	
07/02 09:02:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][600/703]	Step 168856	lr 0.01076	Loss 0.1793 (0.1616)	Prec@(1,5) (95.9%, 99.9%)	
07/02 09:02:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][650/703]	Step 168906	lr 0.01076	Loss 0.2512 (0.1634)	Prec@(1,5) (95.8%, 99.9%)	
07/02 09:02:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][700/703]	Step 168956	lr 0.01076	Loss 0.2122 (0.1654)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:02:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [239][703/703]	Step 168959	lr 0.01076	Loss 0.1043 (0.1654)	Prec@(1,5) (95.7%, 99.9%)	
07/02 09:02:58午後 finetuneTeacher_trainer.py:180 [INFO] Train: [239/299] Final Prec@1 95.7311%
07/02 09:02:59午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [239][50/79]	Step 168960	Loss 1.6697	Prec@(1,5) (61.2%, 85.7%)
07/02 09:03:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [239][78/79]	Step 168960	Loss 1.6659	Prec@(1,5) (61.5%, 85.6%)
07/02 09:03:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [239/299] Final Prec@1 61.4600%
07/02 09:03:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7600%
07/02 09:03:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][50/703]	Step 169010	lr 0.01045	Loss 0.1335 (0.1421)	Prec@(1,5) (96.9%, 99.9%)	
07/02 09:03:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][100/703]	Step 169060	lr 0.01045	Loss 0.1750 (0.1337)	Prec@(1,5) (97.0%, 99.9%)	
07/02 09:03:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][150/703]	Step 169110	lr 0.01045	Loss 0.2666 (0.1345)	Prec@(1,5) (96.9%, 99.9%)	
07/02 09:03:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][200/703]	Step 169160	lr 0.01045	Loss 0.1012 (0.1393)	Prec@(1,5) (96.7%, 99.9%)	
07/02 09:03:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][250/703]	Step 169210	lr 0.01045	Loss 0.1693 (0.1430)	Prec@(1,5) (96.5%, 99.9%)	
07/02 09:03:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][300/703]	Step 169260	lr 0.01045	Loss 0.1770 (0.1439)	Prec@(1,5) (96.5%, 99.9%)	
07/02 09:03:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][350/703]	Step 169310	lr 0.01045	Loss 0.1883 (0.1450)	Prec@(1,5) (96.5%, 99.9%)	
07/02 09:03:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][400/703]	Step 169360	lr 0.01045	Loss 0.2192 (0.1460)	Prec@(1,5) (96.4%, 99.9%)	
07/02 09:03:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][450/703]	Step 169410	lr 0.01045	Loss 0.1754 (0.1496)	Prec@(1,5) (96.3%, 99.9%)	
07/02 09:03:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][500/703]	Step 169460	lr 0.01045	Loss 0.1046 (0.1521)	Prec@(1,5) (96.2%, 99.9%)	
07/02 09:03:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][550/703]	Step 169510	lr 0.01045	Loss 0.1429 (0.1539)	Prec@(1,5) (96.1%, 99.9%)	
07/02 09:03:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][600/703]	Step 169560	lr 0.01045	Loss 0.1489 (0.1559)	Prec@(1,5) (96.1%, 99.9%)	
07/02 09:03:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][650/703]	Step 169610	lr 0.01045	Loss 0.1528 (0.1577)	Prec@(1,5) (96.0%, 99.9%)	
07/02 09:03:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][700/703]	Step 169660	lr 0.01045	Loss 0.1936 (0.1602)	Prec@(1,5) (95.9%, 99.9%)	
07/02 09:03:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [240][703/703]	Step 169663	lr 0.01045	Loss 0.2130 (0.1603)	Prec@(1,5) (95.9%, 99.9%)	
07/02 09:03:42午後 finetuneTeacher_trainer.py:180 [INFO] Train: [240/299] Final Prec@1 95.8689%
07/02 09:03:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [240][50/79]	Step 169664	Loss 1.7066	Prec@(1,5) (61.3%, 85.2%)
07/02 09:03:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [240][78/79]	Step 169664	Loss 1.7008	Prec@(1,5) (61.5%, 85.1%)
07/02 09:03:44午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [240/299] Final Prec@1 61.5400%
07/02 09:03:44午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7600%
07/02 09:03:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][50/703]	Step 169714	lr 0.01015	Loss 0.1532 (0.1343)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:03:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][100/703]	Step 169764	lr 0.01015	Loss 0.1573 (0.1375)	Prec@(1,5) (96.9%, 100.0%)	
07/02 09:03:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][150/703]	Step 169814	lr 0.01015	Loss 0.1046 (0.1379)	Prec@(1,5) (96.7%, 100.0%)	
07/02 09:03:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][200/703]	Step 169864	lr 0.01015	Loss 0.1484 (0.1397)	Prec@(1,5) (96.6%, 100.0%)	
07/02 09:04:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][250/703]	Step 169914	lr 0.01015	Loss 0.1999 (0.1411)	Prec@(1,5) (96.4%, 100.0%)	
07/02 09:04:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][300/703]	Step 169964	lr 0.01015	Loss 0.0727 (0.1420)	Prec@(1,5) (96.4%, 100.0%)	
07/02 09:04:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][350/703]	Step 170014	lr 0.01015	Loss 0.1142 (0.1443)	Prec@(1,5) (96.3%, 100.0%)	
07/02 09:04:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][400/703]	Step 170064	lr 0.01015	Loss 0.1720 (0.1457)	Prec@(1,5) (96.3%, 100.0%)	
07/02 09:04:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][450/703]	Step 170114	lr 0.01015	Loss 0.2149 (0.1482)	Prec@(1,5) (96.3%, 99.9%)	
07/02 09:04:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][500/703]	Step 170164	lr 0.01015	Loss 0.1328 (0.1488)	Prec@(1,5) (96.2%, 99.9%)	
07/02 09:04:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][550/703]	Step 170214	lr 0.01015	Loss 0.0993 (0.1512)	Prec@(1,5) (96.2%, 99.9%)	
07/02 09:04:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][600/703]	Step 170264	lr 0.01015	Loss 0.1876 (0.1524)	Prec@(1,5) (96.2%, 99.9%)	
07/02 09:04:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][650/703]	Step 170314	lr 0.01015	Loss 0.1470 (0.1548)	Prec@(1,5) (96.1%, 99.9%)	
07/02 09:04:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][700/703]	Step 170364	lr 0.01015	Loss 0.2218 (0.1547)	Prec@(1,5) (96.1%, 99.9%)	
07/02 09:04:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [241][703/703]	Step 170367	lr 0.01015	Loss 0.1834 (0.1550)	Prec@(1,5) (96.1%, 99.9%)	
07/02 09:04:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [241/299] Final Prec@1 96.0644%
07/02 09:04:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [241][50/79]	Step 170368	Loss 1.6629	Prec@(1,5) (61.7%, 86.2%)
07/02 09:04:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [241][78/79]	Step 170368	Loss 1.6533	Prec@(1,5) (61.6%, 86.2%)
07/02 09:04:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [241/299] Final Prec@1 61.6400%
07/02 09:04:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7600%
07/02 09:04:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][50/703]	Step 170418	lr 0.00985	Loss 0.0963 (0.1359)	Prec@(1,5) (96.6%, 100.0%)	
07/02 09:04:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][100/703]	Step 170468	lr 0.00985	Loss 0.0771 (0.1329)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:04:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][150/703]	Step 170518	lr 0.00985	Loss 0.1463 (0.1319)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:04:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][200/703]	Step 170568	lr 0.00985	Loss 0.1208 (0.1342)	Prec@(1,5) (96.7%, 100.0%)	
07/02 09:04:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][250/703]	Step 170618	lr 0.00985	Loss 0.1482 (0.1355)	Prec@(1,5) (96.7%, 100.0%)	
07/02 09:04:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][300/703]	Step 170668	lr 0.00985	Loss 0.1320 (0.1345)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:04:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][350/703]	Step 170718	lr 0.00985	Loss 0.0894 (0.1352)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:04:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][400/703]	Step 170768	lr 0.00985	Loss 0.1193 (0.1367)	Prec@(1,5) (96.7%, 100.0%)	
07/02 09:04:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][450/703]	Step 170818	lr 0.00985	Loss 0.1531 (0.1384)	Prec@(1,5) (96.6%, 100.0%)	
07/02 09:04:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][500/703]	Step 170868	lr 0.00985	Loss 0.1468 (0.1398)	Prec@(1,5) (96.6%, 100.0%)	
07/02 09:05:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][550/703]	Step 170918	lr 0.00985	Loss 0.2139 (0.1413)	Prec@(1,5) (96.5%, 100.0%)	
07/02 09:05:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][600/703]	Step 170968	lr 0.00985	Loss 0.1160 (0.1425)	Prec@(1,5) (96.5%, 100.0%)	
07/02 09:05:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][650/703]	Step 171018	lr 0.00985	Loss 0.1881 (0.1446)	Prec@(1,5) (96.4%, 100.0%)	
07/02 09:05:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][700/703]	Step 171068	lr 0.00985	Loss 0.1649 (0.1465)	Prec@(1,5) (96.4%, 100.0%)	
07/02 09:05:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [242][703/703]	Step 171071	lr 0.00985	Loss 0.1271 (0.1466)	Prec@(1,5) (96.4%, 100.0%)	
07/02 09:05:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [242/299] Final Prec@1 96.3600%
07/02 09:05:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [242][50/79]	Step 171072	Loss 1.6831	Prec@(1,5) (60.7%, 85.3%)
07/02 09:05:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [242][78/79]	Step 171072	Loss 1.6545	Prec@(1,5) (61.5%, 85.6%)
07/02 09:05:13午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [242/299] Final Prec@1 61.4200%
07/02 09:05:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7600%
07/02 09:05:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][50/703]	Step 171122	lr 0.00956	Loss 0.1270 (0.1227)	Prec@(1,5) (97.2%, 100.0%)	
07/02 09:05:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][100/703]	Step 171172	lr 0.00956	Loss 0.1291 (0.1217)	Prec@(1,5) (97.2%, 100.0%)	
07/02 09:05:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][150/703]	Step 171222	lr 0.00956	Loss 0.1627 (0.1247)	Prec@(1,5) (97.2%, 100.0%)	
07/02 09:05:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][200/703]	Step 171272	lr 0.00956	Loss 0.1707 (0.1272)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:05:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][250/703]	Step 171322	lr 0.00956	Loss 0.1314 (0.1280)	Prec@(1,5) (97.0%, 99.9%)	
07/02 09:05:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][300/703]	Step 171372	lr 0.00956	Loss 0.0618 (0.1272)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:05:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][350/703]	Step 171422	lr 0.00956	Loss 0.0731 (0.1275)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:05:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][400/703]	Step 171472	lr 0.00956	Loss 0.1235 (0.1267)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:05:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][450/703]	Step 171522	lr 0.00956	Loss 0.1109 (0.1274)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:05:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][500/703]	Step 171572	lr 0.00956	Loss 0.1381 (0.1282)	Prec@(1,5) (97.0%, 100.0%)	
07/02 09:05:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][550/703]	Step 171622	lr 0.00956	Loss 0.2189 (0.1298)	Prec@(1,5) (96.9%, 100.0%)	
07/02 09:05:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][600/703]	Step 171672	lr 0.00956	Loss 0.1175 (0.1311)	Prec@(1,5) (96.9%, 100.0%)	
07/02 09:05:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][650/703]	Step 171722	lr 0.00956	Loss 0.1449 (0.1335)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:05:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][700/703]	Step 171772	lr 0.00956	Loss 0.2030 (0.1346)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:05:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [243][703/703]	Step 171775	lr 0.00956	Loss 0.1247 (0.1346)	Prec@(1,5) (96.8%, 100.0%)	
07/02 09:05:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [243/299] Final Prec@1 96.7444%
07/02 09:05:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [243][50/79]	Step 171776	Loss 1.6725	Prec@(1,5) (61.1%, 85.5%)
07/02 09:05:58午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [243][78/79]	Step 171776	Loss 1.6639	Prec@(1,5) (61.4%, 86.0%)
07/02 09:05:58午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [243/299] Final Prec@1 61.3800%
07/02 09:05:58午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7600%
07/02 09:06:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][50/703]	Step 171826	lr 0.00927	Loss 0.1192 (0.1079)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:06:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][100/703]	Step 171876	lr 0.00927	Loss 0.0854 (0.1093)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:06:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][150/703]	Step 171926	lr 0.00927	Loss 0.0858 (0.1090)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:06:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][200/703]	Step 171976	lr 0.00927	Loss 0.1376 (0.1104)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:06:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][250/703]	Step 172026	lr 0.00927	Loss 0.1113 (0.1128)	Prec@(1,5) (97.6%, 100.0%)	
07/02 09:06:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][300/703]	Step 172076	lr 0.00927	Loss 0.0996 (0.1136)	Prec@(1,5) (97.6%, 100.0%)	
07/02 09:06:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][350/703]	Step 172126	lr 0.00927	Loss 0.1981 (0.1150)	Prec@(1,5) (97.5%, 100.0%)	
07/02 09:06:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][400/703]	Step 172176	lr 0.00927	Loss 0.1372 (0.1149)	Prec@(1,5) (97.5%, 100.0%)	
07/02 09:06:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][450/703]	Step 172226	lr 0.00927	Loss 0.1288 (0.1166)	Prec@(1,5) (97.5%, 100.0%)	
07/02 09:06:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][500/703]	Step 172276	lr 0.00927	Loss 0.1209 (0.1176)	Prec@(1,5) (97.4%, 100.0%)	
07/02 09:06:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][550/703]	Step 172326	lr 0.00927	Loss 0.1925 (0.1192)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:06:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][600/703]	Step 172376	lr 0.00927	Loss 0.0802 (0.1208)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:06:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][650/703]	Step 172426	lr 0.00927	Loss 0.2102 (0.1235)	Prec@(1,5) (97.2%, 100.0%)	
07/02 09:06:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][700/703]	Step 172476	lr 0.00927	Loss 0.1614 (0.1252)	Prec@(1,5) (97.1%, 100.0%)	
07/02 09:06:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [244][703/703]	Step 172479	lr 0.00927	Loss 0.1093 (0.1253)	Prec@(1,5) (97.1%, 100.0%)	
07/02 09:06:42午後 finetuneTeacher_trainer.py:180 [INFO] Train: [244/299] Final Prec@1 97.1022%
07/02 09:06:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [244][50/79]	Step 172480	Loss 1.6708	Prec@(1,5) (61.4%, 85.1%)
07/02 09:06:43午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [244][78/79]	Step 172480	Loss 1.6738	Prec@(1,5) (61.8%, 85.3%)
07/02 09:06:43午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [244/299] Final Prec@1 61.7800%
07/02 09:06:44午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 61.7800%
07/02 09:06:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][50/703]	Step 172530	lr 0.00899	Loss 0.1248 (0.1263)	Prec@(1,5) (97.3%, 99.9%)	
07/02 09:06:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][100/703]	Step 172580	lr 0.00899	Loss 0.0971 (0.1176)	Prec@(1,5) (97.5%, 99.9%)	
07/02 09:06:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][150/703]	Step 172630	lr 0.00899	Loss 0.1108 (0.1169)	Prec@(1,5) (97.4%, 99.9%)	
07/02 09:06:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][200/703]	Step 172680	lr 0.00899	Loss 0.0922 (0.1145)	Prec@(1,5) (97.5%, 99.9%)	
07/02 09:07:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][250/703]	Step 172730	lr 0.00899	Loss 0.1610 (0.1161)	Prec@(1,5) (97.4%, 99.9%)	
07/02 09:07:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][300/703]	Step 172780	lr 0.00899	Loss 0.1419 (0.1144)	Prec@(1,5) (97.5%, 100.0%)	
07/02 09:07:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][350/703]	Step 172830	lr 0.00899	Loss 0.0789 (0.1160)	Prec@(1,5) (97.4%, 100.0%)	
07/02 09:07:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][400/703]	Step 172880	lr 0.00899	Loss 0.1148 (0.1173)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:07:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][450/703]	Step 172930	lr 0.00899	Loss 0.1273 (0.1179)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:07:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][500/703]	Step 172980	lr 0.00899	Loss 0.1405 (0.1182)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:07:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][550/703]	Step 173030	lr 0.00899	Loss 0.1110 (0.1188)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:07:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][600/703]	Step 173080	lr 0.00899	Loss 0.0967 (0.1212)	Prec@(1,5) (97.2%, 100.0%)	
07/02 09:07:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][650/703]	Step 173130	lr 0.00899	Loss 0.1437 (0.1226)	Prec@(1,5) (97.1%, 100.0%)	
07/02 09:07:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][700/703]	Step 173180	lr 0.00899	Loss 0.0645 (0.1237)	Prec@(1,5) (97.1%, 100.0%)	
07/02 09:07:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [245][703/703]	Step 173183	lr 0.00899	Loss 0.1651 (0.1238)	Prec@(1,5) (97.1%, 100.0%)	
07/02 09:07:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [245/299] Final Prec@1 97.0867%
07/02 09:07:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [245][50/79]	Step 173184	Loss 1.6729	Prec@(1,5) (61.8%, 85.6%)
07/02 09:07:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [245][78/79]	Step 173184	Loss 1.6511	Prec@(1,5) (62.2%, 86.1%)
07/02 09:07:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [245/299] Final Prec@1 62.2200%
07/02 09:07:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.2200%
07/02 09:07:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][50/703]	Step 173234	lr 0.00871	Loss 0.1237 (0.1077)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:07:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][100/703]	Step 173284	lr 0.00871	Loss 0.1058 (0.1056)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:07:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][150/703]	Step 173334	lr 0.00871	Loss 0.0772 (0.1056)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:07:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][200/703]	Step 173384	lr 0.00871	Loss 0.1956 (0.1076)	Prec@(1,5) (97.6%, 100.0%)	
07/02 09:07:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][250/703]	Step 173434	lr 0.00871	Loss 0.1272 (0.1068)	Prec@(1,5) (97.6%, 100.0%)	
07/02 09:07:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][300/703]	Step 173484	lr 0.00871	Loss 0.1175 (0.1063)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:07:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][350/703]	Step 173534	lr 0.00871	Loss 0.0887 (0.1053)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:07:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][400/703]	Step 173584	lr 0.00871	Loss 0.1303 (0.1054)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:07:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][450/703]	Step 173634	lr 0.00871	Loss 0.0903 (0.1069)	Prec@(1,5) (97.6%, 100.0%)	
07/02 09:08:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][500/703]	Step 173684	lr 0.00871	Loss 0.0548 (0.1083)	Prec@(1,5) (97.6%, 100.0%)	
07/02 09:08:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][550/703]	Step 173734	lr 0.00871	Loss 0.1701 (0.1101)	Prec@(1,5) (97.5%, 100.0%)	
07/02 09:08:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][600/703]	Step 173784	lr 0.00871	Loss 0.1220 (0.1120)	Prec@(1,5) (97.5%, 100.0%)	
07/02 09:08:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][650/703]	Step 173834	lr 0.00871	Loss 0.1086 (0.1139)	Prec@(1,5) (97.4%, 100.0%)	
07/02 09:08:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][700/703]	Step 173884	lr 0.00871	Loss 0.1188 (0.1162)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:08:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [246][703/703]	Step 173887	lr 0.00871	Loss 0.1086 (0.1163)	Prec@(1,5) (97.3%, 100.0%)	
07/02 09:08:12午後 finetuneTeacher_trainer.py:180 [INFO] Train: [246/299] Final Prec@1 97.3400%
07/02 09:08:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [246][50/79]	Step 173888	Loss 1.6495	Prec@(1,5) (61.7%, 86.0%)
07/02 09:08:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [246][78/79]	Step 173888	Loss 1.6290	Prec@(1,5) (62.0%, 86.4%)
07/02 09:08:13午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [246/299] Final Prec@1 61.9800%
07/02 09:08:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.2200%
07/02 09:08:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][50/703]	Step 173938	lr 0.00843	Loss 0.0995 (0.1034)	Prec@(1,5) (97.9%, 100.0%)	
07/02 09:08:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][100/703]	Step 173988	lr 0.00843	Loss 0.0755 (0.1021)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:08:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][150/703]	Step 174038	lr 0.00843	Loss 0.0587 (0.1047)	Prec@(1,5) (97.9%, 100.0%)	
07/02 09:08:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][200/703]	Step 174088	lr 0.00843	Loss 0.0901 (0.1053)	Prec@(1,5) (97.8%, 100.0%)	
07/02 09:08:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][250/703]	Step 174138	lr 0.00843	Loss 0.0813 (0.1047)	Prec@(1,5) (97.8%, 100.0%)	
07/02 09:08:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][300/703]	Step 174188	lr 0.00843	Loss 0.1276 (0.1043)	Prec@(1,5) (97.9%, 100.0%)	
07/02 09:08:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][350/703]	Step 174238	lr 0.00843	Loss 0.0845 (0.1062)	Prec@(1,5) (97.8%, 100.0%)	
07/02 09:08:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][400/703]	Step 174288	lr 0.00843	Loss 0.0915 (0.1074)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:08:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][450/703]	Step 174338	lr 0.00843	Loss 0.0816 (0.1063)	Prec@(1,5) (97.8%, 100.0%)	
07/02 09:08:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][500/703]	Step 174388	lr 0.00843	Loss 0.1367 (0.1070)	Prec@(1,5) (97.8%, 100.0%)	
07/02 09:08:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][550/703]	Step 174438	lr 0.00843	Loss 0.0736 (0.1080)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:08:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][600/703]	Step 174488	lr 0.00843	Loss 0.0687 (0.1083)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:08:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][650/703]	Step 174538	lr 0.00843	Loss 0.1034 (0.1084)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:08:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][700/703]	Step 174588	lr 0.00843	Loss 0.1056 (0.1100)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:08:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [247][703/703]	Step 174591	lr 0.00843	Loss 0.1631 (0.1100)	Prec@(1,5) (97.7%, 100.0%)	
07/02 09:08:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [247/299] Final Prec@1 97.6711%
07/02 09:08:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [247][50/79]	Step 174592	Loss 1.6509	Prec@(1,5) (61.4%, 86.2%)
07/02 09:08:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [247][78/79]	Step 174592	Loss 1.6366	Prec@(1,5) (61.5%, 86.7%)
07/02 09:08:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [247/299] Final Prec@1 61.4800%
07/02 09:08:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.2200%
07/02 09:09:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][50/703]	Step 174642	lr 0.00816	Loss 0.0721 (0.0890)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:09:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][100/703]	Step 174692	lr 0.00816	Loss 0.0534 (0.0863)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:09:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][150/703]	Step 174742	lr 0.00816	Loss 0.0934 (0.0849)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:09:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][200/703]	Step 174792	lr 0.00816	Loss 0.0519 (0.0858)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:09:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][250/703]	Step 174842	lr 0.00816	Loss 0.1205 (0.0885)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:09:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][300/703]	Step 174892	lr 0.00816	Loss 0.0443 (0.0887)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:09:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][350/703]	Step 174942	lr 0.00816	Loss 0.0914 (0.0901)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:09:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][400/703]	Step 174992	lr 0.00816	Loss 0.0654 (0.0915)	Prec@(1,5) (98.2%, 100.0%)	
07/02 09:09:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][450/703]	Step 175042	lr 0.00816	Loss 0.0687 (0.0922)	Prec@(1,5) (98.2%, 100.0%)	
07/02 09:09:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][500/703]	Step 175092	lr 0.00816	Loss 0.0492 (0.0924)	Prec@(1,5) (98.2%, 100.0%)	
07/02 09:09:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][550/703]	Step 175142	lr 0.00816	Loss 0.0775 (0.0937)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:09:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][600/703]	Step 175192	lr 0.00816	Loss 0.0909 (0.0949)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:09:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][650/703]	Step 175242	lr 0.00816	Loss 0.1099 (0.0962)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:09:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][700/703]	Step 175292	lr 0.00816	Loss 0.2376 (0.0975)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:09:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [248][703/703]	Step 175295	lr 0.00816	Loss 0.0996 (0.0975)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:09:41午後 finetuneTeacher_trainer.py:180 [INFO] Train: [248/299] Final Prec@1 97.9956%
07/02 09:09:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [248][50/79]	Step 175296	Loss 1.6321	Prec@(1,5) (62.6%, 85.9%)
07/02 09:09:42午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [248][78/79]	Step 175296	Loss 1.6414	Prec@(1,5) (62.4%, 86.3%)
07/02 09:09:42午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [248/299] Final Prec@1 62.3400%
07/02 09:09:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.3400%
07/02 09:09:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][50/703]	Step 175346	lr 0.00789	Loss 0.1571 (0.0823)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:09:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][100/703]	Step 175396	lr 0.00789	Loss 0.1152 (0.0858)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:09:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][150/703]	Step 175446	lr 0.00789	Loss 0.0952 (0.0852)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:09:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][200/703]	Step 175496	lr 0.00789	Loss 0.0675 (0.0859)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:10:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][250/703]	Step 175546	lr 0.00789	Loss 0.0562 (0.0878)	Prec@(1,5) (98.2%, 100.0%)	
07/02 09:10:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][300/703]	Step 175596	lr 0.00789	Loss 0.0640 (0.0879)	Prec@(1,5) (98.2%, 100.0%)	
07/02 09:10:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][350/703]	Step 175646	lr 0.00789	Loss 0.0546 (0.0894)	Prec@(1,5) (98.2%, 100.0%)	
07/02 09:10:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][400/703]	Step 175696	lr 0.00789	Loss 0.1144 (0.0903)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:10:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][450/703]	Step 175746	lr 0.00789	Loss 0.0913 (0.0911)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:10:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][500/703]	Step 175796	lr 0.00789	Loss 0.0789 (0.0918)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:10:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][550/703]	Step 175846	lr 0.00789	Loss 0.1265 (0.0929)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:10:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][600/703]	Step 175896	lr 0.00789	Loss 0.0932 (0.0938)	Prec@(1,5) (98.1%, 100.0%)	
07/02 09:10:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][650/703]	Step 175946	lr 0.00789	Loss 0.0854 (0.0945)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:10:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][700/703]	Step 175996	lr 0.00789	Loss 0.0592 (0.0949)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:10:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [249][703/703]	Step 175999	lr 0.00789	Loss 0.1334 (0.0949)	Prec@(1,5) (98.0%, 100.0%)	
07/02 09:10:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [249/299] Final Prec@1 98.0067%
07/02 09:10:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [249][50/79]	Step 176000	Loss 1.6241	Prec@(1,5) (62.3%, 86.5%)
07/02 09:10:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [249][78/79]	Step 176000	Loss 1.6095	Prec@(1,5) (62.9%, 86.2%)
07/02 09:10:30午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [249/299] Final Prec@1 62.8400%
07/02 09:10:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.8400%
07/02 09:10:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][50/703]	Step 176050	lr 0.00763	Loss 0.1195 (0.0858)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:10:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][100/703]	Step 176100	lr 0.00763	Loss 0.0988 (0.0816)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:10:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][150/703]	Step 176150	lr 0.00763	Loss 0.1798 (0.0816)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:10:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][200/703]	Step 176200	lr 0.00763	Loss 0.0679 (0.0825)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:10:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][250/703]	Step 176250	lr 0.00763	Loss 0.0680 (0.0826)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:10:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][300/703]	Step 176300	lr 0.00763	Loss 0.1051 (0.0818)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:10:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][350/703]	Step 176350	lr 0.00763	Loss 0.1226 (0.0830)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:10:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][400/703]	Step 176400	lr 0.00763	Loss 0.0972 (0.0838)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:10:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][450/703]	Step 176450	lr 0.00763	Loss 0.0939 (0.0841)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:11:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][500/703]	Step 176500	lr 0.00763	Loss 0.1143 (0.0854)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:11:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][550/703]	Step 176550	lr 0.00763	Loss 0.0716 (0.0855)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:11:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][600/703]	Step 176600	lr 0.00763	Loss 0.1094 (0.0865)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:11:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][650/703]	Step 176650	lr 0.00763	Loss 0.0548 (0.0865)	Prec@(1,5) (98.4%, 100.0%)	
07/02 09:11:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][700/703]	Step 176700	lr 0.00763	Loss 0.0729 (0.0868)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:11:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [250][703/703]	Step 176703	lr 0.00763	Loss 0.0865 (0.0868)	Prec@(1,5) (98.3%, 100.0%)	
07/02 09:11:13午後 finetuneTeacher_trainer.py:180 [INFO] Train: [250/299] Final Prec@1 98.3400%
07/02 09:11:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [250][50/79]	Step 176704	Loss 1.6463	Prec@(1,5) (61.8%, 86.1%)
07/02 09:11:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [250][78/79]	Step 176704	Loss 1.6065	Prec@(1,5) (62.7%, 86.6%)
07/02 09:11:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [250/299] Final Prec@1 62.6600%
07/02 09:11:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.8400%
07/02 09:11:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][50/703]	Step 176754	lr 0.00737	Loss 0.0580 (0.0798)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][100/703]	Step 176804	lr 0.00737	Loss 0.1717 (0.0778)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][150/703]	Step 176854	lr 0.00737	Loss 0.1004 (0.0755)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][200/703]	Step 176904	lr 0.00737	Loss 0.0979 (0.0759)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][250/703]	Step 176954	lr 0.00737	Loss 0.0545 (0.0763)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][300/703]	Step 177004	lr 0.00737	Loss 0.0624 (0.0771)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][350/703]	Step 177054	lr 0.00737	Loss 0.1242 (0.0773)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][400/703]	Step 177104	lr 0.00737	Loss 0.0792 (0.0776)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][450/703]	Step 177154	lr 0.00737	Loss 0.1067 (0.0780)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][500/703]	Step 177204	lr 0.00737	Loss 0.0568 (0.0791)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][550/703]	Step 177254	lr 0.00737	Loss 0.0875 (0.0795)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:11:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][600/703]	Step 177304	lr 0.00737	Loss 0.0699 (0.0806)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:11:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][650/703]	Step 177354	lr 0.00737	Loss 0.0465 (0.0813)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:11:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][700/703]	Step 177404	lr 0.00737	Loss 0.0896 (0.0817)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:11:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [251][703/703]	Step 177407	lr 0.00737	Loss 0.0704 (0.0818)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:11:59午後 finetuneTeacher_trainer.py:180 [INFO] Train: [251/299] Final Prec@1 98.4689%
07/02 09:12:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [251][50/79]	Step 177408	Loss 1.6194	Prec@(1,5) (62.7%, 86.2%)
07/02 09:12:00午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [251][78/79]	Step 177408	Loss 1.6263	Prec@(1,5) (62.3%, 86.2%)
07/02 09:12:00午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [251/299] Final Prec@1 62.3600%
07/02 09:12:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.8400%
07/02 09:12:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][50/703]	Step 177458	lr 0.00712	Loss 0.0368 (0.0699)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][100/703]	Step 177508	lr 0.00712	Loss 0.0778 (0.0712)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][150/703]	Step 177558	lr 0.00712	Loss 0.0920 (0.0699)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:12:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][200/703]	Step 177608	lr 0.00712	Loss 0.0853 (0.0709)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][250/703]	Step 177658	lr 0.00712	Loss 0.0844 (0.0717)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][300/703]	Step 177708	lr 0.00712	Loss 0.1206 (0.0718)	Prec@(1,5) (98.7%, 100.0%)	
07/02 09:12:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][350/703]	Step 177758	lr 0.00712	Loss 0.0499 (0.0721)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][400/703]	Step 177808	lr 0.00712	Loss 0.0689 (0.0740)	Prec@(1,5) (98.7%, 100.0%)	
07/02 09:12:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][450/703]	Step 177858	lr 0.00712	Loss 0.0591 (0.0742)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:12:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][500/703]	Step 177908	lr 0.00712	Loss 0.0386 (0.0749)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:12:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][550/703]	Step 177958	lr 0.00712	Loss 0.0645 (0.0758)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:12:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][600/703]	Step 178008	lr 0.00712	Loss 0.0371 (0.0763)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:12:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][650/703]	Step 178058	lr 0.00712	Loss 0.0768 (0.0769)	Prec@(1,5) (98.6%, 100.0%)	
07/02 09:12:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][700/703]	Step 178108	lr 0.00712	Loss 0.0785 (0.0774)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:12:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [252][703/703]	Step 178111	lr 0.00712	Loss 0.1264 (0.0774)	Prec@(1,5) (98.5%, 100.0%)	
07/02 09:12:43午後 finetuneTeacher_trainer.py:180 [INFO] Train: [252/299] Final Prec@1 98.5444%
07/02 09:12:44午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [252][50/79]	Step 178112	Loss 1.5993	Prec@(1,5) (62.8%, 86.5%)
07/02 09:12:44午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [252][78/79]	Step 178112	Loss 1.5974	Prec@(1,5) (62.5%, 86.8%)
07/02 09:12:44午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [252/299] Final Prec@1 62.5600%
07/02 09:12:44午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.8400%
07/02 09:12:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][50/703]	Step 178162	lr 0.00688	Loss 0.1091 (0.0694)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][100/703]	Step 178212	lr 0.00688	Loss 0.0359 (0.0699)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:12:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][150/703]	Step 178262	lr 0.00688	Loss 0.0929 (0.0696)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:12:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][200/703]	Step 178312	lr 0.00688	Loss 0.1146 (0.0682)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:13:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][250/703]	Step 178362	lr 0.00688	Loss 0.0426 (0.0688)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][300/703]	Step 178412	lr 0.00688	Loss 0.0753 (0.0688)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][350/703]	Step 178462	lr 0.00688	Loss 0.1518 (0.0707)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][400/703]	Step 178512	lr 0.00688	Loss 0.0490 (0.0701)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][450/703]	Step 178562	lr 0.00688	Loss 0.0601 (0.0705)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][500/703]	Step 178612	lr 0.00688	Loss 0.0629 (0.0706)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][550/703]	Step 178662	lr 0.00688	Loss 0.0677 (0.0714)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][600/703]	Step 178712	lr 0.00688	Loss 0.0312 (0.0715)	Prec@(1,5) (98.7%, 100.0%)	
07/02 09:13:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][650/703]	Step 178762	lr 0.00688	Loss 0.1166 (0.0721)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][700/703]	Step 178812	lr 0.00688	Loss 0.0558 (0.0724)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [253][703/703]	Step 178815	lr 0.00688	Loss 0.1223 (0.0724)	Prec@(1,5) (98.8%, 100.0%)	
07/02 09:13:27午後 finetuneTeacher_trainer.py:180 [INFO] Train: [253/299] Final Prec@1 98.7578%
07/02 09:13:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [253][50/79]	Step 178816	Loss 1.6051	Prec@(1,5) (62.5%, 87.0%)
07/02 09:13:28午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [253][78/79]	Step 178816	Loss 1.6063	Prec@(1,5) (62.7%, 86.8%)
07/02 09:13:28午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [253/299] Final Prec@1 62.6800%
07/02 09:13:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 62.8400%
07/02 09:13:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][50/703]	Step 178866	lr 0.00663	Loss 0.0845 (0.0677)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][100/703]	Step 178916	lr 0.00663	Loss 0.0767 (0.0643)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:13:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][150/703]	Step 178966	lr 0.00663	Loss 0.0390 (0.0619)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][200/703]	Step 179016	lr 0.00663	Loss 0.0746 (0.0610)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:13:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][250/703]	Step 179066	lr 0.00663	Loss 0.0974 (0.0613)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][300/703]	Step 179116	lr 0.00663	Loss 0.0947 (0.0622)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][350/703]	Step 179166	lr 0.00663	Loss 0.0301 (0.0634)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][400/703]	Step 179216	lr 0.00663	Loss 0.0983 (0.0637)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][450/703]	Step 179266	lr 0.00663	Loss 0.0468 (0.0643)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:13:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][500/703]	Step 179316	lr 0.00663	Loss 0.0912 (0.0645)	Prec@(1,5) (99.0%, 100.0%)	
07/02 09:14:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][550/703]	Step 179366	lr 0.00663	Loss 0.1573 (0.0653)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:14:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][600/703]	Step 179416	lr 0.00663	Loss 0.1109 (0.0658)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:14:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][650/703]	Step 179466	lr 0.00663	Loss 0.0725 (0.0665)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:14:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][700/703]	Step 179516	lr 0.00663	Loss 0.0585 (0.0667)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:14:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [254][703/703]	Step 179519	lr 0.00663	Loss 0.1144 (0.0668)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:14:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [254/299] Final Prec@1 98.9000%
07/02 09:14:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [254][50/79]	Step 179520	Loss 1.5587	Prec@(1,5) (63.6%, 87.3%)
07/02 09:14:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [254][78/79]	Step 179520	Loss 1.5867	Prec@(1,5) (63.2%, 86.9%)
07/02 09:14:12午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [254/299] Final Prec@1 63.2600%
07/02 09:14:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 63.2600%
07/02 09:14:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][50/703]	Step 179570	lr 0.0064	Loss 0.0321 (0.0624)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][100/703]	Step 179620	lr 0.0064	Loss 0.0691 (0.0589)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][150/703]	Step 179670	lr 0.0064	Loss 0.0298 (0.0576)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][200/703]	Step 179720	lr 0.0064	Loss 0.0452 (0.0577)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:14:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][250/703]	Step 179770	lr 0.0064	Loss 0.0488 (0.0597)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][300/703]	Step 179820	lr 0.0064	Loss 0.0617 (0.0603)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][350/703]	Step 179870	lr 0.0064	Loss 0.0893 (0.0600)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][400/703]	Step 179920	lr 0.0064	Loss 0.1165 (0.0606)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][450/703]	Step 179970	lr 0.0064	Loss 0.0688 (0.0609)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:14:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][500/703]	Step 180020	lr 0.0064	Loss 0.0324 (0.0619)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][550/703]	Step 180070	lr 0.0064	Loss 0.0405 (0.0617)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][600/703]	Step 180120	lr 0.0064	Loss 0.0366 (0.0622)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][650/703]	Step 180170	lr 0.0064	Loss 0.0549 (0.0624)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][700/703]	Step 180220	lr 0.0064	Loss 0.0603 (0.0629)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [255][703/703]	Step 180223	lr 0.0064	Loss 0.1025 (0.0630)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:14:55午後 finetuneTeacher_trainer.py:180 [INFO] Train: [255/299] Final Prec@1 99.0800%
07/02 09:14:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [255][50/79]	Step 180224	Loss 1.6347	Prec@(1,5) (62.4%, 86.3%)
07/02 09:14:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [255][78/79]	Step 180224	Loss 1.5813	Prec@(1,5) (63.1%, 86.7%)
07/02 09:14:56午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [255/299] Final Prec@1 63.1000%
07/02 09:14:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 63.2600%
07/02 09:15:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][50/703]	Step 180274	lr 0.00616	Loss 0.0368 (0.0589)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][100/703]	Step 180324	lr 0.00616	Loss 0.0288 (0.0582)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][150/703]	Step 180374	lr 0.00616	Loss 0.0866 (0.0568)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][200/703]	Step 180424	lr 0.00616	Loss 0.0629 (0.0566)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][250/703]	Step 180474	lr 0.00616	Loss 0.0358 (0.0557)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][300/703]	Step 180524	lr 0.00616	Loss 0.0556 (0.0567)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][350/703]	Step 180574	lr 0.00616	Loss 0.0383 (0.0577)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][400/703]	Step 180624	lr 0.00616	Loss 0.0351 (0.0583)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:15:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][450/703]	Step 180674	lr 0.00616	Loss 0.0599 (0.0587)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][500/703]	Step 180724	lr 0.00616	Loss 0.0373 (0.0589)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][550/703]	Step 180774	lr 0.00616	Loss 0.0784 (0.0593)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][600/703]	Step 180824	lr 0.00616	Loss 0.0873 (0.0594)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][650/703]	Step 180874	lr 0.00616	Loss 0.0481 (0.0596)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][700/703]	Step 180924	lr 0.00616	Loss 0.0582 (0.0605)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [256][703/703]	Step 180927	lr 0.00616	Loss 0.0809 (0.0605)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [256/299] Final Prec@1 99.0978%
07/02 09:15:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [256][50/79]	Step 180928	Loss 1.5339	Prec@(1,5) (63.9%, 87.0%)
07/02 09:15:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [256][78/79]	Step 180928	Loss 1.5635	Prec@(1,5) (63.3%, 86.9%)
07/02 09:15:40午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [256/299] Final Prec@1 63.2800%
07/02 09:15:41午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 63.2800%
07/02 09:15:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][50/703]	Step 180978	lr 0.00593	Loss 0.0659 (0.0621)	Prec@(1,5) (98.9%, 100.0%)	
07/02 09:15:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][100/703]	Step 181028	lr 0.00593	Loss 0.0485 (0.0594)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][150/703]	Step 181078	lr 0.00593	Loss 0.0563 (0.0567)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][200/703]	Step 181128	lr 0.00593	Loss 0.0626 (0.0557)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:15:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][250/703]	Step 181178	lr 0.00593	Loss 0.0453 (0.0559)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][300/703]	Step 181228	lr 0.00593	Loss 0.0285 (0.0549)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:16:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][350/703]	Step 181278	lr 0.00593	Loss 0.0845 (0.0548)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][400/703]	Step 181328	lr 0.00593	Loss 0.1102 (0.0548)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:16:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][450/703]	Step 181378	lr 0.00593	Loss 0.0532 (0.0550)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:16:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][500/703]	Step 181428	lr 0.00593	Loss 0.0547 (0.0555)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:16:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][550/703]	Step 181478	lr 0.00593	Loss 0.0884 (0.0559)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][600/703]	Step 181528	lr 0.00593	Loss 0.0746 (0.0561)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][650/703]	Step 181578	lr 0.00593	Loss 0.0823 (0.0569)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][700/703]	Step 181628	lr 0.00593	Loss 0.0470 (0.0571)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [257][703/703]	Step 181631	lr 0.00593	Loss 0.0696 (0.0571)	Prec@(1,5) (99.1%, 100.0%)	
07/02 09:16:24午後 finetuneTeacher_trainer.py:180 [INFO] Train: [257/299] Final Prec@1 99.1289%
07/02 09:16:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [257][50/79]	Step 181632	Loss 1.6052	Prec@(1,5) (62.6%, 85.9%)
07/02 09:16:25午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [257][78/79]	Step 181632	Loss 1.5754	Prec@(1,5) (63.3%, 86.4%)
07/02 09:16:25午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [257/299] Final Prec@1 63.3000%
07/02 09:16:26午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 63.3000%
07/02 09:16:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][50/703]	Step 181682	lr 0.00571	Loss 0.0248 (0.0514)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:16:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][100/703]	Step 181732	lr 0.00571	Loss 0.0260 (0.0502)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:16:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][150/703]	Step 181782	lr 0.00571	Loss 0.0400 (0.0513)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:16:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][200/703]	Step 181832	lr 0.00571	Loss 0.0362 (0.0512)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:16:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][250/703]	Step 181882	lr 0.00571	Loss 0.0440 (0.0514)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:16:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][300/703]	Step 181932	lr 0.00571	Loss 0.0299 (0.0513)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:16:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][350/703]	Step 181982	lr 0.00571	Loss 0.0543 (0.0524)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:16:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][400/703]	Step 182032	lr 0.00571	Loss 0.0607 (0.0526)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:16:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][450/703]	Step 182082	lr 0.00571	Loss 0.0607 (0.0524)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:16:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][500/703]	Step 182132	lr 0.00571	Loss 0.0389 (0.0525)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][550/703]	Step 182182	lr 0.00571	Loss 0.0307 (0.0531)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][600/703]	Step 182232	lr 0.00571	Loss 0.0578 (0.0532)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][650/703]	Step 182282	lr 0.00571	Loss 0.0442 (0.0536)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][700/703]	Step 182332	lr 0.00571	Loss 0.0398 (0.0538)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [258][703/703]	Step 182335	lr 0.00571	Loss 0.0361 (0.0540)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:10午後 finetuneTeacher_trainer.py:180 [INFO] Train: [258/299] Final Prec@1 99.2911%
07/02 09:17:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [258][50/79]	Step 182336	Loss 1.5400	Prec@(1,5) (62.9%, 87.5%)
07/02 09:17:11午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [258][78/79]	Step 182336	Loss 1.5477	Prec@(1,5) (63.2%, 87.1%)
07/02 09:17:11午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [258/299] Final Prec@1 63.1400%
07/02 09:17:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 63.3000%
07/02 09:17:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][50/703]	Step 182386	lr 0.00549	Loss 0.0381 (0.0479)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:17:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][100/703]	Step 182436	lr 0.00549	Loss 0.0643 (0.0475)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][150/703]	Step 182486	lr 0.00549	Loss 0.0235 (0.0465)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][200/703]	Step 182536	lr 0.00549	Loss 0.0287 (0.0460)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][250/703]	Step 182586	lr 0.00549	Loss 0.0380 (0.0465)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][300/703]	Step 182636	lr 0.00549	Loss 0.0438 (0.0472)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][350/703]	Step 182686	lr 0.00549	Loss 0.0553 (0.0484)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][400/703]	Step 182736	lr 0.00549	Loss 0.0241 (0.0488)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][450/703]	Step 182786	lr 0.00549	Loss 0.0510 (0.0482)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][500/703]	Step 182836	lr 0.00549	Loss 0.0683 (0.0487)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][550/703]	Step 182886	lr 0.00549	Loss 0.0572 (0.0491)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][600/703]	Step 182936	lr 0.00549	Loss 0.0288 (0.0496)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][650/703]	Step 182986	lr 0.00549	Loss 0.1119 (0.0500)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:17:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][700/703]	Step 183036	lr 0.00549	Loss 0.0587 (0.0508)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [259][703/703]	Step 183039	lr 0.00549	Loss 0.1602 (0.0510)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:17:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [259/299] Final Prec@1 99.3356%
07/02 09:17:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [259][50/79]	Step 183040	Loss 1.5015	Prec@(1,5) (65.2%, 87.4%)
07/02 09:17:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [259][78/79]	Step 183040	Loss 1.5303	Prec@(1,5) (64.7%, 87.5%)
07/02 09:17:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [259/299] Final Prec@1 64.7000%
07/02 09:17:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:18:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][50/703]	Step 183090	lr 0.00528	Loss 0.0434 (0.0494)	Prec@(1,5) (99.2%, 100.0%)	
07/02 09:18:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][100/703]	Step 183140	lr 0.00528	Loss 0.0463 (0.0490)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:18:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][150/703]	Step 183190	lr 0.00528	Loss 0.0453 (0.0493)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][200/703]	Step 183240	lr 0.00528	Loss 0.0830 (0.0496)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:18:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][250/703]	Step 183290	lr 0.00528	Loss 0.1205 (0.0495)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][300/703]	Step 183340	lr 0.00528	Loss 0.0410 (0.0492)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][350/703]	Step 183390	lr 0.00528	Loss 0.0356 (0.0494)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][400/703]	Step 183440	lr 0.00528	Loss 0.0614 (0.0494)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][450/703]	Step 183490	lr 0.00528	Loss 0.0267 (0.0493)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][500/703]	Step 183540	lr 0.00528	Loss 0.0570 (0.0496)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][550/703]	Step 183590	lr 0.00528	Loss 0.0694 (0.0500)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][600/703]	Step 183640	lr 0.00528	Loss 0.0350 (0.0501)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:18:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][650/703]	Step 183690	lr 0.00528	Loss 0.0654 (0.0506)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:18:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][700/703]	Step 183740	lr 0.00528	Loss 0.0343 (0.0515)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:18:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [260][703/703]	Step 183743	lr 0.00528	Loss 0.0283 (0.0515)	Prec@(1,5) (99.3%, 100.0%)	
07/02 09:18:40午後 finetuneTeacher_trainer.py:180 [INFO] Train: [260/299] Final Prec@1 99.3111%
07/02 09:18:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [260][50/79]	Step 183744	Loss 1.5689	Prec@(1,5) (63.4%, 86.5%)
07/02 09:18:41午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [260][78/79]	Step 183744	Loss 1.5692	Prec@(1,5) (63.5%, 86.8%)
07/02 09:18:41午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [260/299] Final Prec@1 63.4800%
07/02 09:18:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:18:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][50/703]	Step 183794	lr 0.00507	Loss 0.0481 (0.0437)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:18:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][100/703]	Step 183844	lr 0.00507	Loss 0.0275 (0.0463)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:18:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][150/703]	Step 183894	lr 0.00507	Loss 0.0366 (0.0461)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:18:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][200/703]	Step 183944	lr 0.00507	Loss 0.0337 (0.0465)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:18:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][250/703]	Step 183994	lr 0.00507	Loss 0.0542 (0.0464)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][300/703]	Step 184044	lr 0.00507	Loss 0.0534 (0.0474)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][350/703]	Step 184094	lr 0.00507	Loss 0.0601 (0.0472)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][400/703]	Step 184144	lr 0.00507	Loss 0.0493 (0.0469)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][450/703]	Step 184194	lr 0.00507	Loss 0.0435 (0.0472)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][500/703]	Step 184244	lr 0.00507	Loss 0.0384 (0.0476)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][550/703]	Step 184294	lr 0.00507	Loss 0.0553 (0.0479)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][600/703]	Step 184344	lr 0.00507	Loss 0.0369 (0.0477)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][650/703]	Step 184394	lr 0.00507	Loss 0.0857 (0.0476)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][700/703]	Step 184444	lr 0.00507	Loss 0.0476 (0.0477)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [261][703/703]	Step 184447	lr 0.00507	Loss 0.0541 (0.0478)	Prec@(1,5) (99.4%, 100.0%)	
07/02 09:19:25午後 finetuneTeacher_trainer.py:180 [INFO] Train: [261/299] Final Prec@1 99.3844%
07/02 09:19:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [261][50/79]	Step 184448	Loss 1.5880	Prec@(1,5) (62.9%, 86.6%)
07/02 09:19:26午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [261][78/79]	Step 184448	Loss 1.5583	Prec@(1,5) (63.6%, 86.9%)
07/02 09:19:26午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [261/299] Final Prec@1 63.6600%
07/02 09:19:26午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:19:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][50/703]	Step 184498	lr 0.00487	Loss 0.0461 (0.0428)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:19:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][100/703]	Step 184548	lr 0.00487	Loss 0.0217 (0.0415)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][150/703]	Step 184598	lr 0.00487	Loss 0.0311 (0.0412)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][200/703]	Step 184648	lr 0.00487	Loss 0.0289 (0.0407)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][250/703]	Step 184698	lr 0.00487	Loss 0.0266 (0.0405)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][300/703]	Step 184748	lr 0.00487	Loss 0.0324 (0.0409)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][350/703]	Step 184798	lr 0.00487	Loss 0.0298 (0.0413)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][400/703]	Step 184848	lr 0.00487	Loss 0.0423 (0.0411)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][450/703]	Step 184898	lr 0.00487	Loss 0.0408 (0.0410)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][500/703]	Step 184948	lr 0.00487	Loss 0.0386 (0.0413)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:19:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][550/703]	Step 184998	lr 0.00487	Loss 0.0464 (0.0419)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:20:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][600/703]	Step 185048	lr 0.00487	Loss 0.1205 (0.0423)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:20:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][650/703]	Step 185098	lr 0.00487	Loss 0.0246 (0.0424)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:20:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][700/703]	Step 185148	lr 0.00487	Loss 0.0492 (0.0427)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:20:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [262][703/703]	Step 185151	lr 0.00487	Loss 0.0443 (0.0428)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:20:08午後 finetuneTeacher_trainer.py:180 [INFO] Train: [262/299] Final Prec@1 99.5333%
07/02 09:20:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [262][50/79]	Step 185152	Loss 1.5648	Prec@(1,5) (64.0%, 87.0%)
07/02 09:20:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [262][78/79]	Step 185152	Loss 1.5586	Prec@(1,5) (64.0%, 87.0%)
07/02 09:20:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [262/299] Final Prec@1 64.0200%
07/02 09:20:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:20:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][50/703]	Step 185202	lr 0.00467	Loss 0.0225 (0.0387)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][100/703]	Step 185252	lr 0.00467	Loss 0.0348 (0.0383)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][150/703]	Step 185302	lr 0.00467	Loss 0.0226 (0.0376)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][200/703]	Step 185352	lr 0.00467	Loss 0.0354 (0.0383)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][250/703]	Step 185402	lr 0.00467	Loss 0.0640 (0.0387)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][300/703]	Step 185452	lr 0.00467	Loss 0.0583 (0.0385)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][350/703]	Step 185502	lr 0.00467	Loss 0.0605 (0.0393)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:20:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][400/703]	Step 185552	lr 0.00467	Loss 0.0396 (0.0401)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][450/703]	Step 185602	lr 0.00467	Loss 0.0310 (0.0402)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][500/703]	Step 185652	lr 0.00467	Loss 0.0424 (0.0405)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][550/703]	Step 185702	lr 0.00467	Loss 0.0381 (0.0411)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][600/703]	Step 185752	lr 0.00467	Loss 0.0281 (0.0414)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][650/703]	Step 185802	lr 0.00467	Loss 0.0260 (0.0415)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][700/703]	Step 185852	lr 0.00467	Loss 0.0364 (0.0420)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:20:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [263][703/703]	Step 185855	lr 0.00467	Loss 0.0545 (0.0420)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:20:52午後 finetuneTeacher_trainer.py:180 [INFO] Train: [263/299] Final Prec@1 99.5489%
07/02 09:20:53午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [263][50/79]	Step 185856	Loss 1.5126	Prec@(1,5) (64.2%, 87.2%)
07/02 09:20:53午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [263][78/79]	Step 185856	Loss 1.5293	Prec@(1,5) (64.2%, 86.9%)
07/02 09:20:53午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [263/299] Final Prec@1 64.2200%
07/02 09:20:54午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:20:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][50/703]	Step 185906	lr 0.00448	Loss 0.0393 (0.0422)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:21:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][100/703]	Step 185956	lr 0.00448	Loss 0.0568 (0.0402)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:21:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][150/703]	Step 186006	lr 0.00448	Loss 0.0348 (0.0413)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:21:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][200/703]	Step 186056	lr 0.00448	Loss 0.0364 (0.0409)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][250/703]	Step 186106	lr 0.00448	Loss 0.0502 (0.0406)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][300/703]	Step 186156	lr 0.00448	Loss 0.0291 (0.0405)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][350/703]	Step 186206	lr 0.00448	Loss 0.0275 (0.0402)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][400/703]	Step 186256	lr 0.00448	Loss 0.0270 (0.0398)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][450/703]	Step 186306	lr 0.00448	Loss 0.0278 (0.0397)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][500/703]	Step 186356	lr 0.00448	Loss 0.0232 (0.0395)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][550/703]	Step 186406	lr 0.00448	Loss 0.0579 (0.0394)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][600/703]	Step 186456	lr 0.00448	Loss 0.0499 (0.0395)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][650/703]	Step 186506	lr 0.00448	Loss 0.0362 (0.0399)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][700/703]	Step 186556	lr 0.00448	Loss 0.0650 (0.0403)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [264][703/703]	Step 186559	lr 0.00448	Loss 0.0345 (0.0403)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:37午後 finetuneTeacher_trainer.py:180 [INFO] Train: [264/299] Final Prec@1 99.6333%
07/02 09:21:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [264][50/79]	Step 186560	Loss 1.5180	Prec@(1,5) (64.9%, 87.4%)
07/02 09:21:38午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [264][78/79]	Step 186560	Loss 1.5410	Prec@(1,5) (64.1%, 87.1%)
07/02 09:21:38午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [264/299] Final Prec@1 64.1400%
07/02 09:21:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:21:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][50/703]	Step 186610	lr 0.00429	Loss 0.0189 (0.0414)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:21:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][100/703]	Step 186660	lr 0.00429	Loss 0.0254 (0.0401)	Prec@(1,5) (99.5%, 100.0%)	
07/02 09:21:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][150/703]	Step 186710	lr 0.00429	Loss 0.0170 (0.0374)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][200/703]	Step 186760	lr 0.00429	Loss 0.0534 (0.0370)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][250/703]	Step 186810	lr 0.00429	Loss 0.0431 (0.0375)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:21:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][300/703]	Step 186860	lr 0.00429	Loss 0.0284 (0.0375)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][350/703]	Step 186910	lr 0.00429	Loss 0.0362 (0.0374)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][400/703]	Step 186960	lr 0.00429	Loss 0.0683 (0.0373)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][450/703]	Step 187010	lr 0.00429	Loss 0.0252 (0.0372)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][500/703]	Step 187060	lr 0.00429	Loss 0.0358 (0.0372)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][550/703]	Step 187110	lr 0.00429	Loss 0.0535 (0.0372)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][600/703]	Step 187160	lr 0.00429	Loss 0.0482 (0.0370)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][650/703]	Step 187210	lr 0.00429	Loss 0.0437 (0.0376)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][700/703]	Step 187260	lr 0.00429	Loss 0.0385 (0.0378)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [265][703/703]	Step 187263	lr 0.00429	Loss 0.0451 (0.0379)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:22午後 finetuneTeacher_trainer.py:180 [INFO] Train: [265/299] Final Prec@1 99.6089%
07/02 09:22:23午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [265][50/79]	Step 187264	Loss 1.5280	Prec@(1,5) (64.4%, 87.2%)
07/02 09:22:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [265][78/79]	Step 187264	Loss 1.5387	Prec@(1,5) (64.4%, 87.0%)
07/02 09:22:24午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [265/299] Final Prec@1 64.4000%
07/02 09:22:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:22:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][50/703]	Step 187314	lr 0.0041	Loss 0.0325 (0.0351)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:22:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][100/703]	Step 187364	lr 0.0041	Loss 0.0188 (0.0358)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:22:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][150/703]	Step 187414	lr 0.0041	Loss 0.0451 (0.0360)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][200/703]	Step 187464	lr 0.0041	Loss 0.0392 (0.0364)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][250/703]	Step 187514	lr 0.0041	Loss 0.0259 (0.0363)	Prec@(1,5) (99.6%, 100.0%)	
07/02 09:22:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][300/703]	Step 187564	lr 0.0041	Loss 0.0383 (0.0362)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][350/703]	Step 187614	lr 0.0041	Loss 0.0248 (0.0360)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][400/703]	Step 187664	lr 0.0041	Loss 0.0357 (0.0358)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][450/703]	Step 187714	lr 0.0041	Loss 0.0300 (0.0359)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][500/703]	Step 187764	lr 0.0041	Loss 0.0303 (0.0361)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:22:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][550/703]	Step 187814	lr 0.0041	Loss 0.0448 (0.0358)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][600/703]	Step 187864	lr 0.0041	Loss 0.0729 (0.0359)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][650/703]	Step 187914	lr 0.0041	Loss 0.0755 (0.0361)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][700/703]	Step 187964	lr 0.0041	Loss 0.0184 (0.0363)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [266][703/703]	Step 187967	lr 0.0041	Loss 0.0324 (0.0363)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:07午後 finetuneTeacher_trainer.py:180 [INFO] Train: [266/299] Final Prec@1 99.6644%
07/02 09:23:08午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [266][50/79]	Step 187968	Loss 1.4942	Prec@(1,5) (64.5%, 87.8%)
07/02 09:23:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [266][78/79]	Step 187968	Loss 1.4896	Prec@(1,5) (64.6%, 87.6%)
07/02 09:23:09午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [266/299] Final Prec@1 64.6000%
07/02 09:23:09午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7000%
07/02 09:23:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][50/703]	Step 188018	lr 0.00393	Loss 0.0279 (0.0312)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:23:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][100/703]	Step 188068	lr 0.00393	Loss 0.0235 (0.0319)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:23:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][150/703]	Step 188118	lr 0.00393	Loss 0.0448 (0.0331)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][200/703]	Step 188168	lr 0.00393	Loss 0.0335 (0.0334)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][250/703]	Step 188218	lr 0.00393	Loss 0.0353 (0.0333)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:23:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][300/703]	Step 188268	lr 0.00393	Loss 0.0207 (0.0332)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][350/703]	Step 188318	lr 0.00393	Loss 0.0435 (0.0338)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][400/703]	Step 188368	lr 0.00393	Loss 0.0341 (0.0341)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][450/703]	Step 188418	lr 0.00393	Loss 0.0292 (0.0340)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][500/703]	Step 188468	lr 0.00393	Loss 0.0229 (0.0338)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][550/703]	Step 188518	lr 0.00393	Loss 0.0359 (0.0341)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][600/703]	Step 188568	lr 0.00393	Loss 0.0480 (0.0341)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][650/703]	Step 188618	lr 0.00393	Loss 0.0543 (0.0344)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][700/703]	Step 188668	lr 0.00393	Loss 0.0429 (0.0348)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [267][703/703]	Step 188671	lr 0.00393	Loss 0.0541 (0.0348)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:23:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [267/299] Final Prec@1 99.6956%
07/02 09:23:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [267][50/79]	Step 188672	Loss 1.5495	Prec@(1,5) (64.1%, 87.0%)
07/02 09:23:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [267][78/79]	Step 188672	Loss 1.5137	Prec@(1,5) (64.8%, 87.5%)
07/02 09:23:54午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [267/299] Final Prec@1 64.8200%
07/02 09:23:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.8200%
07/02 09:23:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][50/703]	Step 188722	lr 0.00375	Loss 0.0471 (0.0338)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:24:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][100/703]	Step 188772	lr 0.00375	Loss 0.0190 (0.0323)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:24:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][150/703]	Step 188822	lr 0.00375	Loss 0.0485 (0.0320)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:24:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][200/703]	Step 188872	lr 0.00375	Loss 0.0285 (0.0325)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][250/703]	Step 188922	lr 0.00375	Loss 0.0310 (0.0315)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][300/703]	Step 188972	lr 0.00375	Loss 0.0149 (0.0313)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][350/703]	Step 189022	lr 0.00375	Loss 0.0453 (0.0313)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][400/703]	Step 189072	lr 0.00375	Loss 0.0164 (0.0312)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][450/703]	Step 189122	lr 0.00375	Loss 0.0170 (0.0314)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][500/703]	Step 189172	lr 0.00375	Loss 0.0369 (0.0314)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][550/703]	Step 189222	lr 0.00375	Loss 0.0430 (0.0318)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][600/703]	Step 189272	lr 0.00375	Loss 0.0237 (0.0319)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][650/703]	Step 189322	lr 0.00375	Loss 0.0262 (0.0320)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][700/703]	Step 189372	lr 0.00375	Loss 0.0505 (0.0320)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [268][703/703]	Step 189375	lr 0.00375	Loss 0.0349 (0.0320)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:38午後 finetuneTeacher_trainer.py:180 [INFO] Train: [268/299] Final Prec@1 99.7667%
07/02 09:24:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [268][50/79]	Step 189376	Loss 1.4749	Prec@(1,5) (66.0%, 87.9%)
07/02 09:24:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [268][78/79]	Step 189376	Loss 1.5060	Prec@(1,5) (64.5%, 87.4%)
07/02 09:24:40午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [268/299] Final Prec@1 64.5400%
07/02 09:24:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.8200%
07/02 09:24:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][50/703]	Step 189426	lr 0.00359	Loss 0.0278 (0.0303)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][100/703]	Step 189476	lr 0.00359	Loss 0.0249 (0.0306)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][150/703]	Step 189526	lr 0.00359	Loss 0.0210 (0.0308)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][200/703]	Step 189576	lr 0.00359	Loss 0.0195 (0.0306)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][250/703]	Step 189626	lr 0.00359	Loss 0.0337 (0.0310)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:24:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][300/703]	Step 189676	lr 0.00359	Loss 0.0358 (0.0308)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][350/703]	Step 189726	lr 0.00359	Loss 0.0206 (0.0307)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][400/703]	Step 189776	lr 0.00359	Loss 0.0301 (0.0310)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][450/703]	Step 189826	lr 0.00359	Loss 0.0240 (0.0313)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][500/703]	Step 189876	lr 0.00359	Loss 0.0590 (0.0315)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:25:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][550/703]	Step 189926	lr 0.00359	Loss 0.0165 (0.0317)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][600/703]	Step 189976	lr 0.00359	Loss 0.0356 (0.0320)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][650/703]	Step 190026	lr 0.00359	Loss 0.0198 (0.0322)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][700/703]	Step 190076	lr 0.00359	Loss 0.0270 (0.0324)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:25:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [269][703/703]	Step 190079	lr 0.00359	Loss 0.0254 (0.0324)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:25:23午後 finetuneTeacher_trainer.py:180 [INFO] Train: [269/299] Final Prec@1 99.7489%
07/02 09:25:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [269][50/79]	Step 190080	Loss 1.4960	Prec@(1,5) (65.2%, 87.1%)
07/02 09:25:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [269][78/79]	Step 190080	Loss 1.5010	Prec@(1,5) (64.9%, 87.7%)
07/02 09:25:24午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [269/299] Final Prec@1 64.8600%
07/02 09:25:25午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.8600%
07/02 09:25:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][50/703]	Step 190130	lr 0.00342	Loss 0.0314 (0.0285)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][100/703]	Step 190180	lr 0.00342	Loss 0.0239 (0.0286)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][150/703]	Step 190230	lr 0.00342	Loss 0.0289 (0.0295)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][200/703]	Step 190280	lr 0.00342	Loss 0.0236 (0.0292)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][250/703]	Step 190330	lr 0.00342	Loss 0.0367 (0.0297)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][300/703]	Step 190380	lr 0.00342	Loss 0.0271 (0.0296)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][350/703]	Step 190430	lr 0.00342	Loss 0.0283 (0.0301)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][400/703]	Step 190480	lr 0.00342	Loss 0.0344 (0.0302)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][450/703]	Step 190530	lr 0.00342	Loss 0.0198 (0.0300)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][500/703]	Step 190580	lr 0.00342	Loss 0.0490 (0.0301)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:25:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][550/703]	Step 190630	lr 0.00342	Loss 0.0313 (0.0304)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][600/703]	Step 190680	lr 0.00342	Loss 0.0214 (0.0303)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][650/703]	Step 190730	lr 0.00342	Loss 0.0272 (0.0301)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][700/703]	Step 190780	lr 0.00342	Loss 0.0422 (0.0301)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [270][703/703]	Step 190783	lr 0.00342	Loss 0.0335 (0.0301)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:09午後 finetuneTeacher_trainer.py:180 [INFO] Train: [270/299] Final Prec@1 99.7956%
07/02 09:26:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [270][50/79]	Step 190784	Loss 1.5265	Prec@(1,5) (64.2%, 87.5%)
07/02 09:26:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [270][78/79]	Step 190784	Loss 1.5045	Prec@(1,5) (64.6%, 87.6%)
07/02 09:26:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [270/299] Final Prec@1 64.5800%
07/02 09:26:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.8600%
07/02 09:26:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][50/703]	Step 190834	lr 0.00327	Loss 0.0225 (0.0285)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][100/703]	Step 190884	lr 0.00327	Loss 0.0372 (0.0272)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:26:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][150/703]	Step 190934	lr 0.00327	Loss 0.0334 (0.0267)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:26:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][200/703]	Step 190984	lr 0.00327	Loss 0.0290 (0.0267)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:26:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][250/703]	Step 191034	lr 0.00327	Loss 0.0146 (0.0276)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][300/703]	Step 191084	lr 0.00327	Loss 0.0252 (0.0278)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][350/703]	Step 191134	lr 0.00327	Loss 0.0282 (0.0279)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][400/703]	Step 191184	lr 0.00327	Loss 0.0201 (0.0281)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][450/703]	Step 191234	lr 0.00327	Loss 0.0181 (0.0285)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][500/703]	Step 191284	lr 0.00327	Loss 0.0377 (0.0289)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][550/703]	Step 191334	lr 0.00327	Loss 0.0339 (0.0291)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][600/703]	Step 191384	lr 0.00327	Loss 0.0267 (0.0294)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][650/703]	Step 191434	lr 0.00327	Loss 0.0252 (0.0294)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][700/703]	Step 191484	lr 0.00327	Loss 0.0336 (0.0293)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [271][703/703]	Step 191487	lr 0.00327	Loss 0.0618 (0.0293)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:26:54午後 finetuneTeacher_trainer.py:180 [INFO] Train: [271/299] Final Prec@1 99.8044%
07/02 09:26:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [271][50/79]	Step 191488	Loss 1.4895	Prec@(1,5) (64.9%, 87.3%)
07/02 09:26:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [271][78/79]	Step 191488	Loss 1.5114	Prec@(1,5) (65.0%, 87.0%)
07/02 09:26:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [271/299] Final Prec@1 64.9600%
07/02 09:26:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.9600%
07/02 09:26:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][50/703]	Step 191538	lr 0.00311	Loss 0.0199 (0.0264)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:27:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][100/703]	Step 191588	lr 0.00311	Loss 0.0590 (0.0284)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][150/703]	Step 191638	lr 0.00311	Loss 0.0302 (0.0279)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][200/703]	Step 191688	lr 0.00311	Loss 0.0164 (0.0276)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][250/703]	Step 191738	lr 0.00311	Loss 0.0321 (0.0273)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][300/703]	Step 191788	lr 0.00311	Loss 0.0266 (0.0278)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][350/703]	Step 191838	lr 0.00311	Loss 0.0183 (0.0281)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][400/703]	Step 191888	lr 0.00311	Loss 0.0277 (0.0281)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][450/703]	Step 191938	lr 0.00311	Loss 0.0295 (0.0281)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][500/703]	Step 191988	lr 0.00311	Loss 0.0216 (0.0286)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][550/703]	Step 192038	lr 0.00311	Loss 0.0112 (0.0285)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][600/703]	Step 192088	lr 0.00311	Loss 0.0715 (0.0286)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][650/703]	Step 192138	lr 0.00311	Loss 0.0375 (0.0289)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][700/703]	Step 192188	lr 0.00311	Loss 0.0241 (0.0290)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [272][703/703]	Step 192191	lr 0.00311	Loss 0.0272 (0.0290)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:38午後 finetuneTeacher_trainer.py:180 [INFO] Train: [272/299] Final Prec@1 99.7822%
07/02 09:27:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [272][50/79]	Step 192192	Loss 1.4858	Prec@(1,5) (65.2%, 87.7%)
07/02 09:27:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [272][78/79]	Step 192192	Loss 1.4720	Prec@(1,5) (65.4%, 88.0%)
07/02 09:27:40午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [272/299] Final Prec@1 65.3600%
07/02 09:27:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.3600%
07/02 09:27:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][50/703]	Step 192242	lr 0.00297	Loss 0.0203 (0.0267)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:27:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][100/703]	Step 192292	lr 0.00297	Loss 0.0383 (0.0282)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:27:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][150/703]	Step 192342	lr 0.00297	Loss 0.0273 (0.0276)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:27:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][200/703]	Step 192392	lr 0.00297	Loss 0.0314 (0.0266)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:27:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][250/703]	Step 192442	lr 0.00297	Loss 0.0182 (0.0265)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:27:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][300/703]	Step 192492	lr 0.00297	Loss 0.0277 (0.0270)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:28:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][350/703]	Step 192542	lr 0.00297	Loss 0.0283 (0.0269)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:28:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][400/703]	Step 192592	lr 0.00297	Loss 0.0260 (0.0270)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:28:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][450/703]	Step 192642	lr 0.00297	Loss 0.0226 (0.0275)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:28:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][500/703]	Step 192692	lr 0.00297	Loss 0.0295 (0.0277)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][550/703]	Step 192742	lr 0.00297	Loss 0.0219 (0.0280)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][600/703]	Step 192792	lr 0.00297	Loss 0.0286 (0.0279)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][650/703]	Step 192842	lr 0.00297	Loss 0.0392 (0.0279)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][700/703]	Step 192892	lr 0.00297	Loss 0.0244 (0.0280)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [273][703/703]	Step 192895	lr 0.00297	Loss 0.0290 (0.0280)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:23午後 finetuneTeacher_trainer.py:180 [INFO] Train: [273/299] Final Prec@1 99.8400%
07/02 09:28:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [273][50/79]	Step 192896	Loss 1.4803	Prec@(1,5) (65.6%, 88.0%)
07/02 09:28:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [273][78/79]	Step 192896	Loss 1.4628	Prec@(1,5) (65.6%, 88.3%)
07/02 09:28:24午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [273/299] Final Prec@1 65.6000%
07/02 09:28:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6000%
07/02 09:28:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][50/703]	Step 192946	lr 0.00282	Loss 0.0205 (0.0255)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][100/703]	Step 192996	lr 0.00282	Loss 0.0235 (0.0257)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][150/703]	Step 193046	lr 0.00282	Loss 0.0270 (0.0257)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][200/703]	Step 193096	lr 0.00282	Loss 0.0386 (0.0256)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][250/703]	Step 193146	lr 0.00282	Loss 0.0149 (0.0256)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][300/703]	Step 193196	lr 0.00282	Loss 0.0275 (0.0261)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][350/703]	Step 193246	lr 0.00282	Loss 0.0168 (0.0262)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][400/703]	Step 193296	lr 0.00282	Loss 0.0261 (0.0263)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][450/703]	Step 193346	lr 0.00282	Loss 0.0252 (0.0266)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][500/703]	Step 193396	lr 0.00282	Loss 0.0256 (0.0269)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:28:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][550/703]	Step 193446	lr 0.00282	Loss 0.0237 (0.0269)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][600/703]	Step 193496	lr 0.00282	Loss 0.0334 (0.0273)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][650/703]	Step 193546	lr 0.00282	Loss 0.0360 (0.0277)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][700/703]	Step 193596	lr 0.00282	Loss 0.0257 (0.0278)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [274][703/703]	Step 193599	lr 0.00282	Loss 0.0185 (0.0278)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:08午後 finetuneTeacher_trainer.py:180 [INFO] Train: [274/299] Final Prec@1 99.8200%
07/02 09:29:09午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [274][50/79]	Step 193600	Loss 1.4646	Prec@(1,5) (65.4%, 87.5%)
07/02 09:29:10午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [274][78/79]	Step 193600	Loss 1.4647	Prec@(1,5) (65.6%, 87.6%)
07/02 09:29:10午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [274/299] Final Prec@1 65.5600%
07/02 09:29:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6000%
07/02 09:29:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][50/703]	Step 193650	lr 0.00269	Loss 0.0182 (0.0254)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][100/703]	Step 193700	lr 0.00269	Loss 0.0160 (0.0255)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][150/703]	Step 193750	lr 0.00269	Loss 0.0225 (0.0255)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][200/703]	Step 193800	lr 0.00269	Loss 0.0495 (0.0260)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][250/703]	Step 193850	lr 0.00269	Loss 0.0140 (0.0257)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][300/703]	Step 193900	lr 0.00269	Loss 0.0394 (0.0257)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][350/703]	Step 193950	lr 0.00269	Loss 0.0242 (0.0261)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][400/703]	Step 194000	lr 0.00269	Loss 0.0252 (0.0263)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][450/703]	Step 194050	lr 0.00269	Loss 0.0224 (0.0264)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][500/703]	Step 194100	lr 0.00269	Loss 0.0144 (0.0263)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][550/703]	Step 194150	lr 0.00269	Loss 0.0182 (0.0265)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][600/703]	Step 194200	lr 0.00269	Loss 0.0292 (0.0265)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][650/703]	Step 194250	lr 0.00269	Loss 0.0291 (0.0267)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][700/703]	Step 194300	lr 0.00269	Loss 0.0197 (0.0266)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [275][703/703]	Step 194303	lr 0.00269	Loss 0.0233 (0.0265)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:29:52午後 finetuneTeacher_trainer.py:180 [INFO] Train: [275/299] Final Prec@1 99.8133%
07/02 09:29:53午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [275][50/79]	Step 194304	Loss 1.4671	Prec@(1,5) (65.1%, 87.5%)
07/02 09:29:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [275][78/79]	Step 194304	Loss 1.4802	Prec@(1,5) (65.1%, 87.6%)
07/02 09:29:54午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [275/299] Final Prec@1 65.1000%
07/02 09:29:54午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6000%
07/02 09:29:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][50/703]	Step 194354	lr 0.00256	Loss 0.0235 (0.0276)	Prec@(1,5) (99.7%, 100.0%)	
07/02 09:30:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][100/703]	Step 194404	lr 0.00256	Loss 0.0226 (0.0262)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][150/703]	Step 194454	lr 0.00256	Loss 0.0740 (0.0264)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][200/703]	Step 194504	lr 0.00256	Loss 0.0248 (0.0267)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][250/703]	Step 194554	lr 0.00256	Loss 0.0233 (0.0264)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][300/703]	Step 194604	lr 0.00256	Loss 0.0208 (0.0265)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][350/703]	Step 194654	lr 0.00256	Loss 0.0198 (0.0272)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][400/703]	Step 194704	lr 0.00256	Loss 0.0170 (0.0273)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][450/703]	Step 194754	lr 0.00256	Loss 0.0197 (0.0270)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][500/703]	Step 194804	lr 0.00256	Loss 0.0237 (0.0269)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][550/703]	Step 194854	lr 0.00256	Loss 0.0170 (0.0268)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][600/703]	Step 194904	lr 0.00256	Loss 0.0180 (0.0271)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][650/703]	Step 194954	lr 0.00256	Loss 0.0613 (0.0272)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][700/703]	Step 195004	lr 0.00256	Loss 0.0189 (0.0271)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [276][703/703]	Step 195007	lr 0.00256	Loss 0.0322 (0.0271)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:30:35午後 finetuneTeacher_trainer.py:180 [INFO] Train: [276/299] Final Prec@1 99.8267%
07/02 09:30:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [276][50/79]	Step 195008	Loss 1.4607	Prec@(1,5) (65.5%, 87.4%)
07/02 09:30:36午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [276][78/79]	Step 195008	Loss 1.4590	Prec@(1,5) (65.7%, 87.6%)
07/02 09:30:36午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [276/299] Final Prec@1 65.6400%
07/02 09:30:37午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:30:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][50/703]	Step 195058	lr 0.00243	Loss 0.0199 (0.0248)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][100/703]	Step 195108	lr 0.00243	Loss 0.0316 (0.0238)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][150/703]	Step 195158	lr 0.00243	Loss 0.0174 (0.0252)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][200/703]	Step 195208	lr 0.00243	Loss 0.0475 (0.0251)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][250/703]	Step 195258	lr 0.00243	Loss 0.0145 (0.0256)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][300/703]	Step 195308	lr 0.00243	Loss 0.0170 (0.0253)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:30:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][350/703]	Step 195358	lr 0.00243	Loss 0.0198 (0.0252)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][400/703]	Step 195408	lr 0.00243	Loss 0.0267 (0.0255)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][450/703]	Step 195458	lr 0.00243	Loss 0.0147 (0.0259)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][500/703]	Step 195508	lr 0.00243	Loss 0.0296 (0.0261)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][550/703]	Step 195558	lr 0.00243	Loss 0.0271 (0.0261)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][600/703]	Step 195608	lr 0.00243	Loss 0.0194 (0.0260)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][650/703]	Step 195658	lr 0.00243	Loss 0.0181 (0.0258)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][700/703]	Step 195708	lr 0.00243	Loss 0.0178 (0.0259)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [277][703/703]	Step 195711	lr 0.00243	Loss 0.0218 (0.0259)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:31:19午後 finetuneTeacher_trainer.py:180 [INFO] Train: [277/299] Final Prec@1 99.8400%
07/02 09:31:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [277][50/79]	Step 195712	Loss 1.4636	Prec@(1,5) (66.3%, 88.0%)
07/02 09:31:20午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [277][78/79]	Step 195712	Loss 1.4721	Prec@(1,5) (65.6%, 87.9%)
07/02 09:31:20午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [277/299] Final Prec@1 65.6400%
07/02 09:31:20午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:31:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][50/703]	Step 195762	lr 0.00231	Loss 0.0341 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][100/703]	Step 195812	lr 0.00231	Loss 0.0236 (0.0238)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][150/703]	Step 195862	lr 0.00231	Loss 0.0408 (0.0249)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][200/703]	Step 195912	lr 0.00231	Loss 0.0466 (0.0247)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][250/703]	Step 195962	lr 0.00231	Loss 0.0176 (0.0250)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][300/703]	Step 196012	lr 0.00231	Loss 0.0698 (0.0248)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][350/703]	Step 196062	lr 0.00231	Loss 0.0325 (0.0244)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][400/703]	Step 196112	lr 0.00231	Loss 0.0278 (0.0244)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][450/703]	Step 196162	lr 0.00231	Loss 0.0156 (0.0245)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][500/703]	Step 196212	lr 0.00231	Loss 0.0239 (0.0244)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][550/703]	Step 196262	lr 0.00231	Loss 0.0097 (0.0243)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][600/703]	Step 196312	lr 0.00231	Loss 0.0145 (0.0245)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:31:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][650/703]	Step 196362	lr 0.00231	Loss 0.0320 (0.0249)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][700/703]	Step 196412	lr 0.00231	Loss 0.0216 (0.0252)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [278][703/703]	Step 196415	lr 0.00231	Loss 0.0218 (0.0252)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:01午後 finetuneTeacher_trainer.py:180 [INFO] Train: [278/299] Final Prec@1 99.8511%
07/02 09:32:02午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [278][50/79]	Step 196416	Loss 1.4774	Prec@(1,5) (64.7%, 88.2%)
07/02 09:32:03午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [278][78/79]	Step 196416	Loss 1.4837	Prec@(1,5) (64.8%, 88.1%)
07/02 09:32:03午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [278/299] Final Prec@1 64.8200%
07/02 09:32:03午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:32:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][50/703]	Step 196466	lr 0.00219	Loss 0.0208 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][100/703]	Step 196516	lr 0.00219	Loss 0.0221 (0.0242)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][150/703]	Step 196566	lr 0.00219	Loss 0.0200 (0.0240)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][200/703]	Step 196616	lr 0.00219	Loss 0.0174 (0.0242)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][250/703]	Step 196666	lr 0.00219	Loss 0.0336 (0.0244)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][300/703]	Step 196716	lr 0.00219	Loss 0.0199 (0.0243)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][350/703]	Step 196766	lr 0.00219	Loss 0.0231 (0.0248)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:32:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][400/703]	Step 196816	lr 0.00219	Loss 0.0183 (0.0246)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][450/703]	Step 196866	lr 0.00219	Loss 0.0295 (0.0249)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][500/703]	Step 196916	lr 0.00219	Loss 0.0195 (0.0248)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][550/703]	Step 196966	lr 0.00219	Loss 0.0320 (0.0248)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][600/703]	Step 197016	lr 0.00219	Loss 0.0284 (0.0251)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:32:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][650/703]	Step 197066	lr 0.00219	Loss 0.0546 (0.0250)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:32:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][700/703]	Step 197116	lr 0.00219	Loss 0.0132 (0.0249)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [279][703/703]	Step 197119	lr 0.00219	Loss 0.0244 (0.0249)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [279/299] Final Prec@1 99.8511%
07/02 09:32:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [279][50/79]	Step 197120	Loss 1.4593	Prec@(1,5) (65.3%, 87.9%)
07/02 09:32:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [279][78/79]	Step 197120	Loss 1.4633	Prec@(1,5) (65.4%, 87.8%)
07/02 09:32:46午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [279/299] Final Prec@1 65.4000%
07/02 09:32:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:32:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][50/703]	Step 197170	lr 0.00208	Loss 0.0318 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][100/703]	Step 197220	lr 0.00208	Loss 0.0131 (0.0232)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][150/703]	Step 197270	lr 0.00208	Loss 0.0188 (0.0234)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:32:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][200/703]	Step 197320	lr 0.00208	Loss 0.0326 (0.0239)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][250/703]	Step 197370	lr 0.00208	Loss 0.0224 (0.0233)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][300/703]	Step 197420	lr 0.00208	Loss 0.0194 (0.0239)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][350/703]	Step 197470	lr 0.00208	Loss 0.0170 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][400/703]	Step 197520	lr 0.00208	Loss 0.0180 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][450/703]	Step 197570	lr 0.00208	Loss 0.0118 (0.0234)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][500/703]	Step 197620	lr 0.00208	Loss 0.0177 (0.0234)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][550/703]	Step 197670	lr 0.00208	Loss 0.0249 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][600/703]	Step 197720	lr 0.00208	Loss 0.0363 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][650/703]	Step 197770	lr 0.00208	Loss 0.0153 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][700/703]	Step 197820	lr 0.00208	Loss 0.0320 (0.0238)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [280][703/703]	Step 197823	lr 0.00208	Loss 0.0238 (0.0238)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:28午後 finetuneTeacher_trainer.py:180 [INFO] Train: [280/299] Final Prec@1 99.8733%
07/02 09:33:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [280][50/79]	Step 197824	Loss 1.4755	Prec@(1,5) (64.7%, 88.4%)
07/02 09:33:29午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [280][78/79]	Step 197824	Loss 1.4629	Prec@(1,5) (65.3%, 88.0%)
07/02 09:33:29午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [280/299] Final Prec@1 65.3200%
07/02 09:33:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:33:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][50/703]	Step 197874	lr 0.00198	Loss 0.0234 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][100/703]	Step 197924	lr 0.00198	Loss 0.0249 (0.0227)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:33:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][150/703]	Step 197974	lr 0.00198	Loss 0.0167 (0.0234)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:33:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][200/703]	Step 198024	lr 0.00198	Loss 0.0220 (0.0230)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:33:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][250/703]	Step 198074	lr 0.00198	Loss 0.0178 (0.0231)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:33:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][300/703]	Step 198124	lr 0.00198	Loss 0.0309 (0.0232)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][350/703]	Step 198174	lr 0.00198	Loss 0.0264 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][400/703]	Step 198224	lr 0.00198	Loss 0.0134 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][450/703]	Step 198274	lr 0.00198	Loss 0.0350 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:33:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][500/703]	Step 198324	lr 0.00198	Loss 0.0244 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][550/703]	Step 198374	lr 0.00198	Loss 0.0309 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][600/703]	Step 198424	lr 0.00198	Loss 0.0250 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][650/703]	Step 198474	lr 0.00198	Loss 0.0237 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][700/703]	Step 198524	lr 0.00198	Loss 0.0168 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [281][703/703]	Step 198527	lr 0.00198	Loss 0.0142 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:11午後 finetuneTeacher_trainer.py:180 [INFO] Train: [281/299] Final Prec@1 99.8600%
07/02 09:34:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [281][50/79]	Step 198528	Loss 1.4926	Prec@(1,5) (64.5%, 87.2%)
07/02 09:34:12午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [281][78/79]	Step 198528	Loss 1.4658	Prec@(1,5) (65.3%, 87.9%)
07/02 09:34:12午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [281/299] Final Prec@1 65.3400%
07/02 09:34:12午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:34:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][50/703]	Step 198578	lr 0.00188	Loss 0.0135 (0.0222)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:34:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][100/703]	Step 198628	lr 0.00188	Loss 0.0191 (0.0232)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][150/703]	Step 198678	lr 0.00188	Loss 0.0231 (0.0234)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][200/703]	Step 198728	lr 0.00188	Loss 0.0201 (0.0241)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][250/703]	Step 198778	lr 0.00188	Loss 0.0204 (0.0238)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:34:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][300/703]	Step 198828	lr 0.00188	Loss 0.0202 (0.0237)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][350/703]	Step 198878	lr 0.00188	Loss 0.0153 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][400/703]	Step 198928	lr 0.00188	Loss 0.0167 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][450/703]	Step 198978	lr 0.00188	Loss 0.0159 (0.0233)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][500/703]	Step 199028	lr 0.00188	Loss 0.0269 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][550/703]	Step 199078	lr 0.00188	Loss 0.0183 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][600/703]	Step 199128	lr 0.00188	Loss 0.0217 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][650/703]	Step 199178	lr 0.00188	Loss 0.0127 (0.0235)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][700/703]	Step 199228	lr 0.00188	Loss 0.0355 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [282][703/703]	Step 199231	lr 0.00188	Loss 0.0399 (0.0236)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:34:53午後 finetuneTeacher_trainer.py:180 [INFO] Train: [282/299] Final Prec@1 99.8800%
07/02 09:34:54午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [282][50/79]	Step 199232	Loss 1.4833	Prec@(1,5) (64.6%, 87.3%)
07/02 09:34:55午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [282][78/79]	Step 199232	Loss 1.4597	Prec@(1,5) (65.3%, 87.6%)
07/02 09:34:55午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [282/299] Final Prec@1 65.3600%
07/02 09:34:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:34:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][50/703]	Step 199282	lr 0.00178	Loss 0.0193 (0.0220)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][100/703]	Step 199332	lr 0.00178	Loss 0.0507 (0.0224)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][150/703]	Step 199382	lr 0.00178	Loss 0.0179 (0.0224)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][200/703]	Step 199432	lr 0.00178	Loss 0.0238 (0.0221)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][250/703]	Step 199482	lr 0.00178	Loss 0.0227 (0.0221)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][300/703]	Step 199532	lr 0.00178	Loss 0.0218 (0.0222)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][350/703]	Step 199582	lr 0.00178	Loss 0.0211 (0.0223)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][400/703]	Step 199632	lr 0.00178	Loss 0.0138 (0.0224)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][450/703]	Step 199682	lr 0.00178	Loss 0.0200 (0.0225)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][500/703]	Step 199732	lr 0.00178	Loss 0.0100 (0.0228)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][550/703]	Step 199782	lr 0.00178	Loss 0.0209 (0.0227)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][600/703]	Step 199832	lr 0.00178	Loss 0.0255 (0.0228)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][650/703]	Step 199882	lr 0.00178	Loss 0.0096 (0.0227)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][700/703]	Step 199932	lr 0.00178	Loss 0.0277 (0.0227)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [283][703/703]	Step 199935	lr 0.00178	Loss 0.0217 (0.0227)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:38午後 finetuneTeacher_trainer.py:180 [INFO] Train: [283/299] Final Prec@1 99.8911%
07/02 09:35:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [283][50/79]	Step 199936	Loss 1.4652	Prec@(1,5) (64.7%, 87.8%)
07/02 09:35:39午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [283][78/79]	Step 199936	Loss 1.4598	Prec@(1,5) (65.3%, 87.9%)
07/02 09:35:39午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [283/299] Final Prec@1 65.3400%
07/02 09:35:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:35:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][50/703]	Step 199986	lr 0.00169	Loss 0.0191 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][100/703]	Step 200036	lr 0.00169	Loss 0.0223 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][150/703]	Step 200086	lr 0.00169	Loss 0.0223 (0.0216)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][200/703]	Step 200136	lr 0.00169	Loss 0.0170 (0.0219)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][250/703]	Step 200186	lr 0.00169	Loss 0.0258 (0.0223)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][300/703]	Step 200236	lr 0.00169	Loss 0.0204 (0.0224)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:35:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][350/703]	Step 200286	lr 0.00169	Loss 0.0299 (0.0223)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][400/703]	Step 200336	lr 0.00169	Loss 0.0266 (0.0221)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][450/703]	Step 200386	lr 0.00169	Loss 0.0471 (0.0222)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][500/703]	Step 200436	lr 0.00169	Loss 0.0159 (0.0221)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][550/703]	Step 200486	lr 0.00169	Loss 0.0212 (0.0222)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][600/703]	Step 200536	lr 0.00169	Loss 0.0259 (0.0222)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][650/703]	Step 200586	lr 0.00169	Loss 0.0160 (0.0224)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][700/703]	Step 200636	lr 0.00169	Loss 0.0172 (0.0225)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [284][703/703]	Step 200639	lr 0.00169	Loss 0.0256 (0.0225)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:20午後 finetuneTeacher_trainer.py:180 [INFO] Train: [284/299] Final Prec@1 99.8867%
07/02 09:36:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [284][50/79]	Step 200640	Loss 1.4796	Prec@(1,5) (64.8%, 87.2%)
07/02 09:36:21午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [284][78/79]	Step 200640	Loss 1.4492	Prec@(1,5) (65.2%, 88.0%)
07/02 09:36:21午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [284/299] Final Prec@1 65.1400%
07/02 09:36:21午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6400%
07/02 09:36:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][50/703]	Step 200690	lr 0.00161	Loss 0.0148 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][100/703]	Step 200740	lr 0.00161	Loss 0.0387 (0.0217)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][150/703]	Step 200790	lr 0.00161	Loss 0.0171 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][200/703]	Step 200840	lr 0.00161	Loss 0.0164 (0.0220)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][250/703]	Step 200890	lr 0.00161	Loss 0.0281 (0.0219)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][300/703]	Step 200940	lr 0.00161	Loss 0.0194 (0.0219)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][350/703]	Step 200990	lr 0.00161	Loss 0.0180 (0.0218)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][400/703]	Step 201040	lr 0.00161	Loss 0.0151 (0.0217)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][450/703]	Step 201090	lr 0.00161	Loss 0.0243 (0.0216)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][500/703]	Step 201140	lr 0.00161	Loss 0.0257 (0.0217)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][550/703]	Step 201190	lr 0.00161	Loss 0.0136 (0.0216)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:36:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][600/703]	Step 201240	lr 0.00161	Loss 0.0157 (0.0218)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][650/703]	Step 201290	lr 0.00161	Loss 0.0133 (0.0220)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][700/703]	Step 201340	lr 0.00161	Loss 0.0185 (0.0222)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [285][703/703]	Step 201343	lr 0.00161	Loss 0.0221 (0.0222)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:04午後 finetuneTeacher_trainer.py:180 [INFO] Train: [285/299] Final Prec@1 99.8933%
07/02 09:37:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [285][50/79]	Step 201344	Loss 1.4314	Prec@(1,5) (66.6%, 87.8%)
07/02 09:37:06午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [285][78/79]	Step 201344	Loss 1.4607	Prec@(1,5) (65.7%, 87.7%)
07/02 09:37:06午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [285/299] Final Prec@1 65.6800%
07/02 09:37:06午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6800%
07/02 09:37:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][50/703]	Step 201394	lr 0.00153	Loss 0.0230 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][100/703]	Step 201444	lr 0.00153	Loss 0.0251 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][150/703]	Step 201494	lr 0.00153	Loss 0.0186 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:19午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][200/703]	Step 201544	lr 0.00153	Loss 0.0219 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:22午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][250/703]	Step 201594	lr 0.00153	Loss 0.0166 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][300/703]	Step 201644	lr 0.00153	Loss 0.0236 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][350/703]	Step 201694	lr 0.00153	Loss 0.0172 (0.0216)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][400/703]	Step 201744	lr 0.00153	Loss 0.0109 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][450/703]	Step 201794	lr 0.00153	Loss 0.0219 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][500/703]	Step 201844	lr 0.00153	Loss 0.0159 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][550/703]	Step 201894	lr 0.00153	Loss 0.0154 (0.0211)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][600/703]	Step 201944	lr 0.00153	Loss 0.0290 (0.0211)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][650/703]	Step 201994	lr 0.00153	Loss 0.0281 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][700/703]	Step 202044	lr 0.00153	Loss 0.0462 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [286][703/703]	Step 202047	lr 0.00153	Loss 0.0644 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:49午後 finetuneTeacher_trainer.py:180 [INFO] Train: [286/299] Final Prec@1 99.9067%
07/02 09:37:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [286][50/79]	Step 202048	Loss 1.4501	Prec@(1,5) (65.6%, 88.0%)
07/02 09:37:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [286][78/79]	Step 202048	Loss 1.4571	Prec@(1,5) (65.4%, 87.9%)
07/02 09:37:50午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [286/299] Final Prec@1 65.4000%
07/02 09:37:50午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.6800%
07/02 09:37:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][50/703]	Step 202098	lr 0.00146	Loss 0.0244 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:37:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][100/703]	Step 202148	lr 0.00146	Loss 0.0382 (0.0219)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][150/703]	Step 202198	lr 0.00146	Loss 0.0236 (0.0214)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][200/703]	Step 202248	lr 0.00146	Loss 0.0220 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][250/703]	Step 202298	lr 0.00146	Loss 0.0197 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][300/703]	Step 202348	lr 0.00146	Loss 0.0236 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][350/703]	Step 202398	lr 0.00146	Loss 0.0166 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][400/703]	Step 202448	lr 0.00146	Loss 0.0284 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][450/703]	Step 202498	lr 0.00146	Loss 0.0158 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][500/703]	Step 202548	lr 0.00146	Loss 0.0101 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][550/703]	Step 202598	lr 0.00146	Loss 0.0139 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][600/703]	Step 202648	lr 0.00146	Loss 0.0238 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][650/703]	Step 202698	lr 0.00146	Loss 0.0196 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][700/703]	Step 202748	lr 0.00146	Loss 0.0183 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [287][703/703]	Step 202751	lr 0.00146	Loss 0.0198 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:33午後 finetuneTeacher_trainer.py:180 [INFO] Train: [287/299] Final Prec@1 99.9289%
07/02 09:38:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [287][50/79]	Step 202752	Loss 1.4245	Prec@(1,5) (66.2%, 87.7%)
07/02 09:38:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [287][78/79]	Step 202752	Loss 1.4393	Prec@(1,5) (65.8%, 87.3%)
07/02 09:38:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [287/299] Final Prec@1 65.7200%
07/02 09:38:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7200%
07/02 09:38:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][50/703]	Step 202802	lr 0.00139	Loss 0.0309 (0.0210)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][100/703]	Step 202852	lr 0.00139	Loss 0.0242 (0.0215)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][150/703]	Step 202902	lr 0.00139	Loss 0.0166 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][200/703]	Step 202952	lr 0.00139	Loss 0.0166 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][250/703]	Step 203002	lr 0.00139	Loss 0.0153 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][300/703]	Step 203052	lr 0.00139	Loss 0.0215 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][350/703]	Step 203102	lr 0.00139	Loss 0.0199 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:38:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][400/703]	Step 203152	lr 0.00139	Loss 0.0176 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][450/703]	Step 203202	lr 0.00139	Loss 0.0255 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][500/703]	Step 203252	lr 0.00139	Loss 0.0287 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][550/703]	Step 203302	lr 0.00139	Loss 0.0169 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][600/703]	Step 203352	lr 0.00139	Loss 0.0358 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][650/703]	Step 203402	lr 0.00139	Loss 0.0161 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][700/703]	Step 203452	lr 0.00139	Loss 0.0202 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [288][703/703]	Step 203455	lr 0.00139	Loss 0.0207 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:18午後 finetuneTeacher_trainer.py:180 [INFO] Train: [288/299] Final Prec@1 99.9022%
07/02 09:39:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [288][50/79]	Step 203456	Loss 1.5110	Prec@(1,5) (64.9%, 87.4%)
07/02 09:39:19午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [288][78/79]	Step 203456	Loss 1.4736	Prec@(1,5) (65.4%, 87.7%)
07/02 09:39:19午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [288/299] Final Prec@1 65.3600%
07/02 09:39:19午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7200%
07/02 09:39:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][50/703]	Step 203506	lr 0.00133	Loss 0.0233 (0.0219)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:39:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][100/703]	Step 203556	lr 0.00133	Loss 0.0542 (0.0212)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:39:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][150/703]	Step 203606	lr 0.00133	Loss 0.0151 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][200/703]	Step 203656	lr 0.00133	Loss 0.0273 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][250/703]	Step 203706	lr 0.00133	Loss 0.0276 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][300/703]	Step 203756	lr 0.00133	Loss 0.0207 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][350/703]	Step 203806	lr 0.00133	Loss 0.0134 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][400/703]	Step 203856	lr 0.00133	Loss 0.0183 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][450/703]	Step 203906	lr 0.00133	Loss 0.0089 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][500/703]	Step 203956	lr 0.00133	Loss 0.0166 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][550/703]	Step 204006	lr 0.00133	Loss 0.0572 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:39:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][600/703]	Step 204056	lr 0.00133	Loss 0.0150 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][650/703]	Step 204106	lr 0.00133	Loss 0.0406 (0.0210)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][700/703]	Step 204156	lr 0.00133	Loss 0.0093 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [289][703/703]	Step 204159	lr 0.00133	Loss 0.0138 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:04午後 finetuneTeacher_trainer.py:180 [INFO] Train: [289/299] Final Prec@1 99.9133%
07/02 09:40:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [289][50/79]	Step 204160	Loss 1.4466	Prec@(1,5) (65.0%, 88.0%)
07/02 09:40:05午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [289][78/79]	Step 204160	Loss 1.4441	Prec@(1,5) (65.5%, 88.0%)
07/02 09:40:05午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [289/299] Final Prec@1 65.5200%
07/02 09:40:06午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7200%
07/02 09:40:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][50/703]	Step 204210	lr 0.00127	Loss 0.0476 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][100/703]	Step 204260	lr 0.00127	Loss 0.0144 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][150/703]	Step 204310	lr 0.00127	Loss 0.0149 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][200/703]	Step 204360	lr 0.00127	Loss 0.0219 (0.0211)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][250/703]	Step 204410	lr 0.00127	Loss 0.0165 (0.0210)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][300/703]	Step 204460	lr 0.00127	Loss 0.0192 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][350/703]	Step 204510	lr 0.00127	Loss 0.0194 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][400/703]	Step 204560	lr 0.00127	Loss 0.0319 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][450/703]	Step 204610	lr 0.00127	Loss 0.0259 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][500/703]	Step 204660	lr 0.00127	Loss 0.0223 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][550/703]	Step 204710	lr 0.00127	Loss 0.0216 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:42午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][600/703]	Step 204760	lr 0.00127	Loss 0.0091 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][650/703]	Step 204810	lr 0.00127	Loss 0.0262 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][700/703]	Step 204860	lr 0.00127	Loss 0.0109 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [290][703/703]	Step 204863	lr 0.00127	Loss 0.0262 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:49午後 finetuneTeacher_trainer.py:180 [INFO] Train: [290/299] Final Prec@1 99.9044%
07/02 09:40:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [290][50/79]	Step 204864	Loss 1.3837	Prec@(1,5) (66.6%, 88.5%)
07/02 09:40:50午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [290][78/79]	Step 204864	Loss 1.4510	Prec@(1,5) (65.6%, 87.6%)
07/02 09:40:50午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [290/299] Final Prec@1 65.5800%
07/02 09:40:50午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7200%
07/02 09:40:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][50/703]	Step 204914	lr 0.00122	Loss 0.0184 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:40:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][100/703]	Step 204964	lr 0.00122	Loss 0.0108 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][150/703]	Step 205014	lr 0.00122	Loss 0.0222 (0.0200)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][200/703]	Step 205064	lr 0.00122	Loss 0.0171 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][250/703]	Step 205114	lr 0.00122	Loss 0.0217 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][300/703]	Step 205164	lr 0.00122	Loss 0.0215 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][350/703]	Step 205214	lr 0.00122	Loss 0.0168 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][400/703]	Step 205264	lr 0.00122	Loss 0.0180 (0.0203)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][450/703]	Step 205314	lr 0.00122	Loss 0.0282 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][500/703]	Step 205364	lr 0.00122	Loss 0.0224 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][550/703]	Step 205414	lr 0.00122	Loss 0.0120 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][600/703]	Step 205464	lr 0.00122	Loss 0.0547 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][650/703]	Step 205514	lr 0.00122	Loss 0.0212 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][700/703]	Step 205564	lr 0.00122	Loss 0.0170 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [291][703/703]	Step 205567	lr 0.00122	Loss 0.0140 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:32午後 finetuneTeacher_trainer.py:180 [INFO] Train: [291/299] Final Prec@1 99.9000%
07/02 09:41:33午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [291][50/79]	Step 205568	Loss 1.4727	Prec@(1,5) (64.4%, 87.7%)
07/02 09:41:34午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [291][78/79]	Step 205568	Loss 1.4474	Prec@(1,5) (65.4%, 87.8%)
07/02 09:41:34午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [291/299] Final Prec@1 65.4200%
07/02 09:41:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7200%
07/02 09:41:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][50/703]	Step 205618	lr 0.00117	Loss 0.0260 (0.0200)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:41:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][100/703]	Step 205668	lr 0.00117	Loss 0.0208 (0.0202)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:41:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][150/703]	Step 205718	lr 0.00117	Loss 0.0159 (0.0199)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:41:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][200/703]	Step 205768	lr 0.00117	Loss 0.0212 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][250/703]	Step 205818	lr 0.00117	Loss 0.0138 (0.0200)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][300/703]	Step 205868	lr 0.00117	Loss 0.0144 (0.0199)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][350/703]	Step 205918	lr 0.00117	Loss 0.0173 (0.0203)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:41:58午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][400/703]	Step 205968	lr 0.00117	Loss 0.0182 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][450/703]	Step 206018	lr 0.00117	Loss 0.0230 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][500/703]	Step 206068	lr 0.00117	Loss 0.0217 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][550/703]	Step 206118	lr 0.00117	Loss 0.0148 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][600/703]	Step 206168	lr 0.00117	Loss 0.0205 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][650/703]	Step 206218	lr 0.00117	Loss 0.0328 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][700/703]	Step 206268	lr 0.00117	Loss 0.0299 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:16午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [292][703/703]	Step 206271	lr 0.00117	Loss 0.0159 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:16午後 finetuneTeacher_trainer.py:180 [INFO] Train: [292/299] Final Prec@1 99.9222%
07/02 09:42:17午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [292][50/79]	Step 206272	Loss 1.4464	Prec@(1,5) (65.6%, 87.8%)
07/02 09:42:18午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [292][78/79]	Step 206272	Loss 1.4518	Prec@(1,5) (65.4%, 88.2%)
07/02 09:42:18午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [292/299] Final Prec@1 65.4200%
07/02 09:42:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7200%
07/02 09:42:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][50/703]	Step 206322	lr 0.00113	Loss 0.0084 (0.0236)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:42:25午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][100/703]	Step 206372	lr 0.00113	Loss 0.0143 (0.0216)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:28午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][150/703]	Step 206422	lr 0.00113	Loss 0.0262 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:31午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][200/703]	Step 206472	lr 0.00113	Loss 0.0132 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][250/703]	Step 206522	lr 0.00113	Loss 0.0164 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][300/703]	Step 206572	lr 0.00113	Loss 0.0261 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][350/703]	Step 206622	lr 0.00113	Loss 0.0148 (0.0208)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][400/703]	Step 206672	lr 0.00113	Loss 0.0196 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][450/703]	Step 206722	lr 0.00113	Loss 0.0216 (0.0210)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:48午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][500/703]	Step 206772	lr 0.00113	Loss 0.0137 (0.0211)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][550/703]	Step 206822	lr 0.00113	Loss 0.0200 (0.0211)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][600/703]	Step 206872	lr 0.00113	Loss 0.0206 (0.0212)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:42:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][650/703]	Step 206922	lr 0.00113	Loss 0.0315 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][700/703]	Step 206972	lr 0.00113	Loss 0.0185 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [293][703/703]	Step 206975	lr 0.00113	Loss 0.0106 (0.0213)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:01午後 finetuneTeacher_trainer.py:180 [INFO] Train: [293/299] Final Prec@1 99.9067%
07/02 09:43:02午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [293][50/79]	Step 206976	Loss 1.4506	Prec@(1,5) (65.7%, 87.9%)
07/02 09:43:02午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [293][78/79]	Step 206976	Loss 1.4421	Prec@(1,5) (65.8%, 88.0%)
07/02 09:43:02午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [293/299] Final Prec@1 65.7400%
07/02 09:43:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.7400%
07/02 09:43:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][50/703]	Step 207026	lr 0.0011	Loss 0.0222 (0.0190)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][100/703]	Step 207076	lr 0.0011	Loss 0.0175 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][150/703]	Step 207126	lr 0.0011	Loss 0.0212 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][200/703]	Step 207176	lr 0.0011	Loss 0.0110 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][250/703]	Step 207226	lr 0.0011	Loss 0.0265 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][300/703]	Step 207276	lr 0.0011	Loss 0.0206 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][350/703]	Step 207326	lr 0.0011	Loss 0.0202 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][400/703]	Step 207376	lr 0.0011	Loss 0.0219 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][450/703]	Step 207426	lr 0.0011	Loss 0.0197 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][500/703]	Step 207476	lr 0.0011	Loss 0.0264 (0.0200)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][550/703]	Step 207526	lr 0.0011	Loss 0.0207 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][600/703]	Step 207576	lr 0.0011	Loss 0.0160 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][650/703]	Step 207626	lr 0.0011	Loss 0.0286 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][700/703]	Step 207676	lr 0.0011	Loss 0.0121 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:45午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [294][703/703]	Step 207679	lr 0.0011	Loss 0.0320 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:43:45午後 finetuneTeacher_trainer.py:180 [INFO] Train: [294/299] Final Prec@1 99.8978%
07/02 09:43:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [294][50/79]	Step 207680	Loss 1.4447	Prec@(1,5) (65.2%, 88.3%)
07/02 09:43:46午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [294][78/79]	Step 207680	Loss 1.4257	Prec@(1,5) (65.9%, 88.4%)
07/02 09:43:47午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [294/299] Final Prec@1 65.8200%
07/02 09:43:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.8200%
07/02 09:43:51午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][50/703]	Step 207730	lr 0.00107	Loss 0.0140 (0.0192)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:43:54午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][100/703]	Step 207780	lr 0.00107	Loss 0.0113 (0.0195)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:43:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][150/703]	Step 207830	lr 0.00107	Loss 0.0168 (0.0189)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][200/703]	Step 207880	lr 0.00107	Loss 0.0205 (0.0190)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][250/703]	Step 207930	lr 0.00107	Loss 0.0121 (0.0191)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][300/703]	Step 207980	lr 0.00107	Loss 0.0144 (0.0190)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][350/703]	Step 208030	lr 0.00107	Loss 0.0156 (0.0190)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][400/703]	Step 208080	lr 0.00107	Loss 0.0336 (0.0192)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][450/703]	Step 208130	lr 0.00107	Loss 0.0134 (0.0191)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][500/703]	Step 208180	lr 0.00107	Loss 0.0118 (0.0192)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][550/703]	Step 208230	lr 0.00107	Loss 0.0127 (0.0194)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][600/703]	Step 208280	lr 0.00107	Loss 0.0141 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][650/703]	Step 208330	lr 0.00107	Loss 0.0117 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][700/703]	Step 208380	lr 0.00107	Loss 0.0110 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [295][703/703]	Step 208383	lr 0.00107	Loss 0.0126 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:29午後 finetuneTeacher_trainer.py:180 [INFO] Train: [295/299] Final Prec@1 99.9267%
07/02 09:44:30午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [295][50/79]	Step 208384	Loss 1.4817	Prec@(1,5) (65.4%, 87.3%)
07/02 09:44:31午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [295][78/79]	Step 208384	Loss 1.4709	Prec@(1,5) (65.4%, 87.4%)
07/02 09:44:31午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [295/299] Final Prec@1 65.4000%
07/02 09:44:31午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.8200%
07/02 09:44:34午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][50/703]	Step 208434	lr 0.00104	Loss 0.0341 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:37午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][100/703]	Step 208484	lr 0.00104	Loss 0.0103 (0.0190)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:40午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][150/703]	Step 208534	lr 0.00104	Loss 0.0121 (0.0187)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:43午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][200/703]	Step 208584	lr 0.00104	Loss 0.0245 (0.0190)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][250/703]	Step 208634	lr 0.00104	Loss 0.0232 (0.0191)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][300/703]	Step 208684	lr 0.00104	Loss 0.0282 (0.0194)	Prec@(1,5) (100.0%, 100.0%)	
07/02 09:44:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][350/703]	Step 208734	lr 0.00104	Loss 0.0199 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][400/703]	Step 208784	lr 0.00104	Loss 0.0295 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:44:57午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][450/703]	Step 208834	lr 0.00104	Loss 0.0138 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:00午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][500/703]	Step 208884	lr 0.00104	Loss 0.0188 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:03午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][550/703]	Step 208934	lr 0.00104	Loss 0.0223 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:06午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][600/703]	Step 208984	lr 0.00104	Loss 0.0241 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:09午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][650/703]	Step 209034	lr 0.00104	Loss 0.0126 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][700/703]	Step 209084	lr 0.00104	Loss 0.0170 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:12午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [296][703/703]	Step 209087	lr 0.00104	Loss 0.0155 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:12午後 finetuneTeacher_trainer.py:180 [INFO] Train: [296/299] Final Prec@1 99.9400%
07/02 09:45:13午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [296][50/79]	Step 209088	Loss 1.4186	Prec@(1,5) (65.7%, 88.1%)
07/02 09:45:14午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [296][78/79]	Step 209088	Loss 1.4733	Prec@(1,5) (65.0%, 87.5%)
07/02 09:45:14午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [296/299] Final Prec@1 65.0400%
07/02 09:45:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 65.8200%
07/02 09:45:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][50/703]	Step 209138	lr 0.00102	Loss 0.0131 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][100/703]	Step 209188	lr 0.00102	Loss 0.0325 (0.0203)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][150/703]	Step 209238	lr 0.00102	Loss 0.0180 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:26午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][200/703]	Step 209288	lr 0.00102	Loss 0.0281 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:29午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][250/703]	Step 209338	lr 0.00102	Loss 0.0180 (0.0202)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:32午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][300/703]	Step 209388	lr 0.00102	Loss 0.0269 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:35午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][350/703]	Step 209438	lr 0.00102	Loss 0.0171 (0.0206)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][400/703]	Step 209488	lr 0.00102	Loss 0.0172 (0.0203)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:41午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][450/703]	Step 209538	lr 0.00102	Loss 0.0191 (0.0201)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][500/703]	Step 209588	lr 0.00102	Loss 0.0198 (0.0199)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:46午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][550/703]	Step 209638	lr 0.00102	Loss 0.0160 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:49午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][600/703]	Step 209688	lr 0.00102	Loss 0.0099 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:52午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][650/703]	Step 209738	lr 0.00102	Loss 0.0156 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][700/703]	Step 209788	lr 0.00102	Loss 0.0190 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:55午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [297][703/703]	Step 209791	lr 0.00102	Loss 0.0171 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:45:56午後 finetuneTeacher_trainer.py:180 [INFO] Train: [297/299] Final Prec@1 99.9356%
07/02 09:45:56午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [297][50/79]	Step 209792	Loss 1.4175	Prec@(1,5) (66.7%, 88.2%)
07/02 09:45:57午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [297][78/79]	Step 209792	Loss 1.4246	Prec@(1,5) (66.3%, 88.4%)
07/02 09:45:57午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [297/299] Final Prec@1 66.3200%
07/02 09:45:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 66.3200%
07/02 09:46:01午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][50/703]	Step 209842	lr 0.00101	Loss 0.0125 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:04午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][100/703]	Step 209892	lr 0.00101	Loss 0.0227 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:07午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][150/703]	Step 209942	lr 0.00101	Loss 0.0185 (0.0209)	Prec@(1,5) (99.8%, 100.0%)	
07/02 09:46:10午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][200/703]	Step 209992	lr 0.00101	Loss 0.0142 (0.0210)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:13午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][250/703]	Step 210042	lr 0.00101	Loss 0.0153 (0.0209)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:15午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][300/703]	Step 210092	lr 0.00101	Loss 0.0143 (0.0211)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:18午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][350/703]	Step 210142	lr 0.00101	Loss 0.0325 (0.0210)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:21午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][400/703]	Step 210192	lr 0.00101	Loss 0.0308 (0.0207)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:24午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][450/703]	Step 210242	lr 0.00101	Loss 0.0240 (0.0205)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:27午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][500/703]	Step 210292	lr 0.00101	Loss 0.0210 (0.0203)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:30午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][550/703]	Step 210342	lr 0.00101	Loss 0.0199 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:33午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][600/703]	Step 210392	lr 0.00101	Loss 0.0189 (0.0203)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:36午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][650/703]	Step 210442	lr 0.00101	Loss 0.0220 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:38午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][700/703]	Step 210492	lr 0.00101	Loss 0.0156 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:39午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [298][703/703]	Step 210495	lr 0.00101	Loss 0.0227 (0.0204)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:39午後 finetuneTeacher_trainer.py:180 [INFO] Train: [298/299] Final Prec@1 99.9044%
07/02 09:46:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [298][50/79]	Step 210496	Loss 1.4645	Prec@(1,5) (65.3%, 87.8%)
07/02 09:46:40午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [298][78/79]	Step 210496	Loss 1.4519	Prec@(1,5) (65.6%, 87.7%)
07/02 09:46:40午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [298/299] Final Prec@1 65.6000%
07/02 09:46:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 66.3200%
07/02 09:46:44午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][50/703]	Step 210546	lr 0.001	Loss 0.0210 (0.0192)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:47午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][100/703]	Step 210596	lr 0.001	Loss 0.0211 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:50午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][150/703]	Step 210646	lr 0.001	Loss 0.0189 (0.0198)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:53午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][200/703]	Step 210696	lr 0.001	Loss 0.0201 (0.0193)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:56午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][250/703]	Step 210746	lr 0.001	Loss 0.0113 (0.0192)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:46:59午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][300/703]	Step 210796	lr 0.001	Loss 0.0172 (0.0192)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:02午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][350/703]	Step 210846	lr 0.001	Loss 0.0180 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:05午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][400/703]	Step 210896	lr 0.001	Loss 0.0292 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:08午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][450/703]	Step 210946	lr 0.001	Loss 0.0182 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:11午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][500/703]	Step 210996	lr 0.001	Loss 0.0206 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:14午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][550/703]	Step 211046	lr 0.001	Loss 0.0231 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:17午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][600/703]	Step 211096	lr 0.001	Loss 0.0124 (0.0196)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:20午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][650/703]	Step 211146	lr 0.001	Loss 0.0192 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][700/703]	Step 211196	lr 0.001	Loss 0.0127 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:23午後 finetuneTeacher_trainer.py:170 [INFO] Train: Epoch: [299][703/703]	Step 211199	lr 0.001	Loss 0.0163 (0.0197)	Prec@(1,5) (99.9%, 100.0%)	
07/02 09:47:23午後 finetuneTeacher_trainer.py:180 [INFO] Train: [299/299] Final Prec@1 99.9222%
07/02 09:47:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [299][50/79]	Step 211200	Loss 1.4278	Prec@(1,5) (66.2%, 87.9%)
07/02 09:47:24午後 finetuneTeacher_trainer.py:208 [INFO] Valid: Epoch: [299][78/79]	Step 211200	Loss 1.4305	Prec@(1,5) (66.0%, 88.1%)
07/02 09:47:24午後 finetuneTeacher_trainer.py:215 [INFO] Valid: [299/299] Final Prec@1 66.0400%
07/02 09:47:25午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 66.3200%
07/02 09:47:25午後 finetuneTeacher_main.py:56 [INFO] Final best Prec@1 = 66.3200%
