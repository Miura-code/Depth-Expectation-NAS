07/04 08:33:08PM parser.py:28 [INFO] 
07/04 08:33:08PM parser.py:29 [INFO] Parameters:
07/04 08:33:08PM parser.py:31 [INFO] BATCH_SIZE=64
07/04 08:33:08PM parser.py:31 [INFO] CUTOUT_LENGTH=16
07/04 08:33:08PM parser.py:31 [INFO] DATA_PATH=../data/
07/04 08:33:08PM parser.py:31 [INFO] DATASET=cifar100
07/04 08:33:08PM parser.py:31 [INFO] EPOCHS=200
07/04 08:33:08PM parser.py:31 [INFO] EXP_NAME=TORCHVISION-20240704-203308
07/04 08:33:08PM parser.py:31 [INFO] GPUS=[0]
07/04 08:33:08PM parser.py:31 [INFO] LOCAL_RANK=0
07/04 08:33:08PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
07/04 08:33:08PM parser.py:31 [INFO] MODEL_NAME=densenet121
07/04 08:33:08PM parser.py:31 [INFO] NAME=VALID_HIPA
07/04 08:33:08PM parser.py:31 [INFO] PATH=results/teacher/cifar100/densenet121/VALID_HIPA/TORCHVISION-20240704-203308
07/04 08:33:08PM parser.py:31 [INFO] PLOT_PATH=results/teacher/cifar100/densenet121/VALID_HIPA/TORCHVISION-20240704-203308/plots
07/04 08:33:08PM parser.py:31 [INFO] PRINT_FREQ=50
07/04 08:33:08PM parser.py:31 [INFO] RESUME_PATH=None
07/04 08:33:08PM parser.py:31 [INFO] SAVE=TORCHVISION
07/04 08:33:08PM parser.py:31 [INFO] SEED=0
07/04 08:33:08PM parser.py:31 [INFO] TRAIN_PORTION=0.9
07/04 08:33:08PM parser.py:31 [INFO] W_GRAD_CLIP=100.0
07/04 08:33:08PM parser.py:31 [INFO] W_LR=0.1
07/04 08:33:08PM parser.py:31 [INFO] W_LR_MIN=0.001
07/04 08:33:08PM parser.py:31 [INFO] W_MOMENTUM=0.9
07/04 08:33:08PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
07/04 08:33:08PM parser.py:31 [INFO] WORKERS=4
07/04 08:33:08PM parser.py:32 [INFO] 
07/04 08:33:15PM finetuneTeacher_trainer.py:113 [INFO] --> No loaded checkpoint!
07/04 08:33:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][50/703]	Step 50	lr 0.1	Loss 5.4499 (5.6474)	Prec@(1,5) (2.3%, 11.1%)	
07/04 08:33:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][100/703]	Step 100	lr 0.1	Loss 4.7750 (5.3152)	Prec@(1,5) (2.8%, 12.1%)	
07/04 08:33:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][150/703]	Step 150	lr 0.1	Loss 4.2501 (5.0527)	Prec@(1,5) (3.4%, 13.8%)	
07/04 08:33:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][200/703]	Step 200	lr 0.1	Loss 4.6146 (4.8870)	Prec@(1,5) (3.6%, 15.2%)	
07/04 08:33:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][250/703]	Step 250	lr 0.1	Loss 4.2446 (4.7675)	Prec@(1,5) (4.0%, 16.3%)	
07/04 08:33:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][300/703]	Step 300	lr 0.1	Loss 4.1900 (4.6658)	Prec@(1,5) (4.2%, 17.4%)	
07/04 08:33:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][350/703]	Step 350	lr 0.1	Loss 4.1609 (4.5921)	Prec@(1,5) (4.6%, 18.2%)	
07/04 08:33:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][400/703]	Step 400	lr 0.1	Loss 3.9886 (4.5311)	Prec@(1,5) (5.0%, 19.0%)	
07/04 08:33:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][450/703]	Step 450	lr 0.1	Loss 4.0780 (4.4765)	Prec@(1,5) (5.3%, 19.9%)	
07/04 08:33:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][500/703]	Step 500	lr 0.1	Loss 3.9798 (4.4300)	Prec@(1,5) (5.6%, 20.7%)	
07/04 08:33:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][550/703]	Step 550	lr 0.1	Loss 3.7723 (4.3946)	Prec@(1,5) (5.8%, 21.2%)	
07/04 08:34:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][600/703]	Step 600	lr 0.1	Loss 3.8507 (4.3650)	Prec@(1,5) (6.0%, 21.8%)	
07/04 08:34:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][650/703]	Step 650	lr 0.1	Loss 4.0681 (4.3402)	Prec@(1,5) (6.2%, 22.2%)	
07/04 08:34:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][700/703]	Step 700	lr 0.1	Loss 3.9943 (4.3118)	Prec@(1,5) (6.4%, 22.7%)	
07/04 08:34:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [0][703/703]	Step 703	lr 0.1	Loss 3.8480 (4.3102)	Prec@(1,5) (6.5%, 22.8%)	
07/04 08:34:15PM finetuneTeacher_trainer.py:185 [INFO] Train: [  0/199] Final Prec@1 6.4533%
07/04 08:34:16PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [0][50/79]	Step 704	Loss 4.0073	Prec@(1,5) (9.2%, 29.1%)
07/04 08:34:16PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [0][78/79]	Step 704	Loss 3.9999	Prec@(1,5) (9.1%, 29.3%)
07/04 08:34:16PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  0/199] Final Prec@1 9.0800%
07/04 08:34:17PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 9.0800%
07/04 08:34:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][50/703]	Step 754	lr 0.1	Loss 4.1101 (3.9906)	Prec@(1,5) (8.7%, 28.5%)	
07/04 08:34:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][100/703]	Step 804	lr 0.1	Loss 4.0605 (3.9421)	Prec@(1,5) (9.1%, 30.0%)	
07/04 08:34:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][150/703]	Step 854	lr 0.1	Loss 3.8067 (3.9264)	Prec@(1,5) (9.4%, 30.1%)	
07/04 08:34:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][200/703]	Step 904	lr 0.1	Loss 4.0037 (3.8906)	Prec@(1,5) (10.0%, 31.1%)	
07/04 08:34:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][250/703]	Step 954	lr 0.1	Loss 3.8724 (3.8636)	Prec@(1,5) (10.5%, 32.0%)	
07/04 08:34:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][300/703]	Step 1004	lr 0.1	Loss 3.8476 (3.8574)	Prec@(1,5) (10.5%, 32.2%)	
07/04 08:34:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][350/703]	Step 1054	lr 0.1	Loss 3.8195 (3.8463)	Prec@(1,5) (10.6%, 32.4%)	
07/04 08:34:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][400/703]	Step 1104	lr 0.1	Loss 3.7536 (3.8321)	Prec@(1,5) (10.9%, 32.9%)	
07/04 08:34:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][450/703]	Step 1154	lr 0.1	Loss 3.6041 (3.8173)	Prec@(1,5) (11.1%, 33.4%)	
07/04 08:34:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][500/703]	Step 1204	lr 0.1	Loss 3.5710 (3.8122)	Prec@(1,5) (11.2%, 33.4%)	
07/04 08:34:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][550/703]	Step 1254	lr 0.1	Loss 3.6100 (3.7957)	Prec@(1,5) (11.4%, 33.8%)	
07/04 08:34:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][600/703]	Step 1304	lr 0.1	Loss 3.7619 (3.7833)	Prec@(1,5) (11.6%, 34.3%)	
07/04 08:34:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][650/703]	Step 1354	lr 0.1	Loss 3.9973 (3.7768)	Prec@(1,5) (11.7%, 34.5%)	
07/04 08:35:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][700/703]	Step 1404	lr 0.1	Loss 3.7880 (3.7759)	Prec@(1,5) (11.8%, 34.5%)	
07/04 08:35:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [1][703/703]	Step 1407	lr 0.1	Loss 3.7373 (3.7753)	Prec@(1,5) (11.8%, 34.6%)	
07/04 08:35:03PM finetuneTeacher_trainer.py:185 [INFO] Train: [  1/199] Final Prec@1 11.7889%
07/04 08:35:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [1][50/79]	Step 1408	Loss 3.6811	Prec@(1,5) (12.4%, 37.6%)
07/04 08:35:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [1][78/79]	Step 1408	Loss 3.6799	Prec@(1,5) (12.7%, 37.7%)
07/04 08:35:05PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  1/199] Final Prec@1 12.6600%
07/04 08:35:05PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 12.6600%
07/04 08:35:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][50/703]	Step 1458	lr 0.1	Loss 3.6321 (3.6766)	Prec@(1,5) (13.0%, 37.0%)	
07/04 08:35:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][100/703]	Step 1508	lr 0.1	Loss 3.9427 (3.6419)	Prec@(1,5) (13.7%, 38.4%)	
07/04 08:35:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][150/703]	Step 1558	lr 0.1	Loss 3.2790 (3.6221)	Prec@(1,5) (14.2%, 39.0%)	
07/04 08:35:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][200/703]	Step 1608	lr 0.1	Loss 3.3918 (3.6122)	Prec@(1,5) (14.5%, 39.5%)	
07/04 08:35:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][250/703]	Step 1658	lr 0.1	Loss 3.5378 (3.6092)	Prec@(1,5) (14.6%, 39.5%)	
07/04 08:35:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][300/703]	Step 1708	lr 0.1	Loss 3.2903 (3.6027)	Prec@(1,5) (14.6%, 39.6%)	
07/04 08:35:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][350/703]	Step 1758	lr 0.1	Loss 3.3453 (3.5952)	Prec@(1,5) (14.7%, 39.6%)	
07/04 08:35:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][400/703]	Step 1808	lr 0.1	Loss 3.5140 (3.6016)	Prec@(1,5) (14.5%, 39.5%)	
07/04 08:35:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][450/703]	Step 1858	lr 0.1	Loss 3.6579 (3.6068)	Prec@(1,5) (14.4%, 39.4%)	
07/04 08:35:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][500/703]	Step 1908	lr 0.1	Loss 3.6188 (3.6000)	Prec@(1,5) (14.5%, 39.6%)	
07/04 08:35:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][550/703]	Step 1958	lr 0.1	Loss 3.8357 (3.5932)	Prec@(1,5) (14.5%, 39.7%)	
07/04 08:35:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][600/703]	Step 2008	lr 0.1	Loss 3.6401 (3.5845)	Prec@(1,5) (14.6%, 40.0%)	
07/04 08:35:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][650/703]	Step 2058	lr 0.1	Loss 3.5588 (3.5765)	Prec@(1,5) (14.8%, 40.2%)	
07/04 08:35:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][700/703]	Step 2108	lr 0.1	Loss 3.2777 (3.5668)	Prec@(1,5) (15.0%, 40.5%)	
07/04 08:35:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [2][703/703]	Step 2111	lr 0.1	Loss 3.7293 (3.5669)	Prec@(1,5) (15.0%, 40.5%)	
07/04 08:35:52PM finetuneTeacher_trainer.py:185 [INFO] Train: [  2/199] Final Prec@1 14.9867%
07/04 08:35:53PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [2][50/79]	Step 2112	Loss 3.4773	Prec@(1,5) (16.0%, 44.0%)
07/04 08:35:54PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [2][78/79]	Step 2112	Loss 3.4804	Prec@(1,5) (16.2%, 44.1%)
07/04 08:35:54PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  2/199] Final Prec@1 16.2400%
07/04 08:35:54PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 16.2400%
07/04 08:35:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][50/703]	Step 2162	lr 0.1	Loss 3.3221 (3.4339)	Prec@(1,5) (16.9%, 44.7%)	
07/04 08:36:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][100/703]	Step 2212	lr 0.1	Loss 3.3872 (3.4048)	Prec@(1,5) (17.2%, 45.8%)	
07/04 08:36:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][150/703]	Step 2262	lr 0.1	Loss 3.4443 (3.3947)	Prec@(1,5) (17.4%, 45.9%)	
07/04 08:36:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][200/703]	Step 2312	lr 0.1	Loss 3.0059 (3.3809)	Prec@(1,5) (17.5%, 46.3%)	
07/04 08:36:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][250/703]	Step 2362	lr 0.1	Loss 3.3254 (3.3678)	Prec@(1,5) (17.8%, 46.4%)	
07/04 08:36:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][300/703]	Step 2412	lr 0.1	Loss 3.1862 (3.3653)	Prec@(1,5) (17.8%, 46.4%)	
07/04 08:36:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][350/703]	Step 2462	lr 0.1	Loss 3.5118 (3.3669)	Prec@(1,5) (18.1%, 46.3%)	
07/04 08:36:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][400/703]	Step 2512	lr 0.1	Loss 3.4354 (3.3692)	Prec@(1,5) (17.9%, 46.3%)	
07/04 08:36:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][450/703]	Step 2562	lr 0.1	Loss 3.3705 (3.3589)	Prec@(1,5) (18.2%, 46.6%)	
07/04 08:36:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][500/703]	Step 2612	lr 0.1	Loss 3.2772 (3.3502)	Prec@(1,5) (18.3%, 46.8%)	
07/04 08:36:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][550/703]	Step 2662	lr 0.1	Loss 3.2152 (3.3428)	Prec@(1,5) (18.5%, 47.0%)	
07/04 08:36:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][600/703]	Step 2712	lr 0.1	Loss 3.4909 (3.3440)	Prec@(1,5) (18.5%, 46.9%)	
07/04 08:36:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][650/703]	Step 2762	lr 0.1	Loss 3.1387 (3.3422)	Prec@(1,5) (18.5%, 47.0%)	
07/04 08:36:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][700/703]	Step 2812	lr 0.1	Loss 2.9946 (3.3389)	Prec@(1,5) (18.7%, 47.1%)	
07/04 08:36:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [3][703/703]	Step 2815	lr 0.1	Loss 3.3745 (3.3387)	Prec@(1,5) (18.7%, 47.0%)	
07/04 08:36:39PM finetuneTeacher_trainer.py:185 [INFO] Train: [  3/199] Final Prec@1 18.6511%
07/04 08:36:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [3][50/79]	Step 2816	Loss 3.2755	Prec@(1,5) (19.3%, 48.9%)
07/04 08:36:41PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [3][78/79]	Step 2816	Loss 3.2855	Prec@(1,5) (19.2%, 48.7%)
07/04 08:36:41PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  3/199] Final Prec@1 19.1400%
07/04 08:36:41PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 19.1400%
07/04 08:36:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][50/703]	Step 2866	lr 0.1	Loss 3.3305 (3.2614)	Prec@(1,5) (19.6%, 48.8%)	
07/04 08:36:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][100/703]	Step 2916	lr 0.1	Loss 3.2378 (3.2367)	Prec@(1,5) (20.2%, 49.5%)	
07/04 08:36:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][150/703]	Step 2966	lr 0.1	Loss 3.0329 (3.2145)	Prec@(1,5) (20.9%, 50.1%)	
07/04 08:36:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][200/703]	Step 3016	lr 0.1	Loss 3.2320 (3.2087)	Prec@(1,5) (20.9%, 50.1%)	
07/04 08:36:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][250/703]	Step 3066	lr 0.1	Loss 3.4700 (3.1983)	Prec@(1,5) (21.2%, 50.4%)	
07/04 08:37:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][300/703]	Step 3116	lr 0.1	Loss 2.9677 (3.1907)	Prec@(1,5) (21.4%, 50.7%)	
07/04 08:37:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][350/703]	Step 3166	lr 0.1	Loss 3.1831 (3.1893)	Prec@(1,5) (21.6%, 50.8%)	
07/04 08:37:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][400/703]	Step 3216	lr 0.1	Loss 3.2282 (3.1809)	Prec@(1,5) (21.7%, 51.0%)	
07/04 08:37:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][450/703]	Step 3266	lr 0.1	Loss 3.4097 (3.1814)	Prec@(1,5) (21.7%, 51.0%)	
07/04 08:37:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][500/703]	Step 3316	lr 0.1	Loss 3.2844 (3.1834)	Prec@(1,5) (21.6%, 50.9%)	
07/04 08:37:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][550/703]	Step 3366	lr 0.1	Loss 3.2958 (3.1812)	Prec@(1,5) (21.7%, 51.0%)	
07/04 08:37:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][600/703]	Step 3416	lr 0.1	Loss 2.9758 (3.1762)	Prec@(1,5) (21.8%, 51.1%)	
07/04 08:37:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][650/703]	Step 3466	lr 0.1	Loss 2.9476 (3.1715)	Prec@(1,5) (21.8%, 51.2%)	
07/04 08:37:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][700/703]	Step 3516	lr 0.1	Loss 3.6578 (3.1713)	Prec@(1,5) (21.9%, 51.2%)	
07/04 08:37:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [4][703/703]	Step 3519	lr 0.1	Loss 3.4444 (3.1707)	Prec@(1,5) (21.9%, 51.2%)	
07/04 08:37:28PM finetuneTeacher_trainer.py:185 [INFO] Train: [  4/199] Final Prec@1 21.8933%
07/04 08:37:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [4][50/79]	Step 3520	Loss 3.1665	Prec@(1,5) (22.6%, 52.1%)
07/04 08:37:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [4][78/79]	Step 3520	Loss 3.1954	Prec@(1,5) (22.1%, 51.3%)
07/04 08:37:30PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  4/199] Final Prec@1 22.0800%
07/04 08:37:30PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 22.0800%
07/04 08:37:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][50/703]	Step 3570	lr 0.1	Loss 3.3236 (3.0728)	Prec@(1,5) (23.2%, 54.0%)	
07/04 08:37:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][100/703]	Step 3620	lr 0.1	Loss 2.8264 (3.0514)	Prec@(1,5) (23.9%, 54.2%)	
07/04 08:37:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][150/703]	Step 3670	lr 0.1	Loss 3.0762 (3.0645)	Prec@(1,5) (24.0%, 53.9%)	
07/04 08:37:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][200/703]	Step 3720	lr 0.1	Loss 3.0496 (3.0668)	Prec@(1,5) (23.6%, 53.7%)	
07/04 08:37:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][250/703]	Step 3770	lr 0.1	Loss 3.1324 (3.0720)	Prec@(1,5) (23.5%, 53.6%)	
07/04 08:37:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][300/703]	Step 3820	lr 0.1	Loss 2.9404 (3.0614)	Prec@(1,5) (23.7%, 54.0%)	
07/04 08:37:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][350/703]	Step 3870	lr 0.1	Loss 3.1643 (3.0630)	Prec@(1,5) (23.6%, 54.0%)	
07/04 08:37:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][400/703]	Step 3920	lr 0.1	Loss 2.9757 (3.0552)	Prec@(1,5) (23.7%, 54.2%)	
07/04 08:38:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][450/703]	Step 3970	lr 0.1	Loss 3.3809 (3.0517)	Prec@(1,5) (23.7%, 54.3%)	
07/04 08:38:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][500/703]	Step 4020	lr 0.1	Loss 3.1192 (3.0501)	Prec@(1,5) (23.8%, 54.5%)	
07/04 08:38:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][550/703]	Step 4070	lr 0.1	Loss 2.8139 (3.0490)	Prec@(1,5) (23.9%, 54.5%)	
07/04 08:38:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][600/703]	Step 4120	lr 0.1	Loss 3.5561 (3.0467)	Prec@(1,5) (24.0%, 54.6%)	
07/04 08:38:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][650/703]	Step 4170	lr 0.1	Loss 3.2694 (3.0471)	Prec@(1,5) (24.0%, 54.6%)	
07/04 08:38:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][700/703]	Step 4220	lr 0.1	Loss 2.5457 (3.0425)	Prec@(1,5) (24.1%, 54.7%)	
07/04 08:38:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [5][703/703]	Step 4223	lr 0.1	Loss 2.8681 (3.0430)	Prec@(1,5) (24.1%, 54.6%)	
07/04 08:38:17PM finetuneTeacher_trainer.py:185 [INFO] Train: [  5/199] Final Prec@1 24.0756%
07/04 08:38:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [5][50/79]	Step 4224	Loss 3.2925	Prec@(1,5) (21.7%, 50.7%)
07/04 08:38:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [5][78/79]	Step 4224	Loss 3.3137	Prec@(1,5) (21.1%, 49.9%)
07/04 08:38:19PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  5/199] Final Prec@1 21.1600%
07/04 08:38:19PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 22.0800%
07/04 08:38:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][50/703]	Step 4274	lr 0.1	Loss 2.7166 (2.9889)	Prec@(1,5) (25.5%, 55.7%)	
07/04 08:38:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][100/703]	Step 4324	lr 0.1	Loss 2.6931 (2.9763)	Prec@(1,5) (25.0%, 55.9%)	
07/04 08:38:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][150/703]	Step 4374	lr 0.1	Loss 2.8847 (2.9539)	Prec@(1,5) (25.3%, 56.4%)	
07/04 08:38:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][200/703]	Step 4424	lr 0.1	Loss 3.1639 (2.9619)	Prec@(1,5) (25.5%, 56.3%)	
07/04 08:38:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][250/703]	Step 4474	lr 0.1	Loss 2.9292 (2.9690)	Prec@(1,5) (25.4%, 56.2%)	
07/04 08:38:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][300/703]	Step 4524	lr 0.1	Loss 3.3953 (2.9700)	Prec@(1,5) (25.4%, 56.2%)	
07/04 08:38:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][350/703]	Step 4574	lr 0.1	Loss 3.1163 (2.9713)	Prec@(1,5) (25.4%, 56.2%)	
07/04 08:38:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][400/703]	Step 4624	lr 0.1	Loss 2.5650 (2.9663)	Prec@(1,5) (25.4%, 56.2%)	
07/04 08:38:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][450/703]	Step 4674	lr 0.1	Loss 2.8442 (2.9578)	Prec@(1,5) (25.6%, 56.6%)	
07/04 08:38:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][500/703]	Step 4724	lr 0.1	Loss 2.7521 (2.9544)	Prec@(1,5) (25.6%, 56.7%)	
07/04 08:38:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][550/703]	Step 4774	lr 0.1	Loss 2.8612 (2.9549)	Prec@(1,5) (25.7%, 56.8%)	
07/04 08:38:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][600/703]	Step 4824	lr 0.1	Loss 2.8907 (2.9495)	Prec@(1,5) (25.7%, 56.9%)	
07/04 08:39:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][650/703]	Step 4874	lr 0.1	Loss 2.8806 (2.9456)	Prec@(1,5) (25.8%, 57.1%)	
07/04 08:39:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][700/703]	Step 4924	lr 0.1	Loss 3.2134 (2.9431)	Prec@(1,5) (25.9%, 57.1%)	
07/04 08:39:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [6][703/703]	Step 4927	lr 0.1	Loss 3.2906 (2.9437)	Prec@(1,5) (25.9%, 57.1%)	
07/04 08:39:05PM finetuneTeacher_trainer.py:185 [INFO] Train: [  6/199] Final Prec@1 25.9133%
07/04 08:39:06PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [6][50/79]	Step 4928	Loss 3.0354	Prec@(1,5) (25.3%, 54.5%)
07/04 08:39:06PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [6][78/79]	Step 4928	Loss 3.0591	Prec@(1,5) (24.9%, 54.1%)
07/04 08:39:06PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  6/199] Final Prec@1 24.8400%
07/04 08:39:07PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 24.8400%
07/04 08:39:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][50/703]	Step 4978	lr 0.1	Loss 2.8760 (2.9335)	Prec@(1,5) (27.6%, 57.5%)	
07/04 08:39:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][100/703]	Step 5028	lr 0.1	Loss 2.9997 (2.9053)	Prec@(1,5) (27.6%, 57.9%)	
07/04 08:39:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][150/703]	Step 5078	lr 0.1	Loss 2.8197 (2.8878)	Prec@(1,5) (27.7%, 58.6%)	
07/04 08:39:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][200/703]	Step 5128	lr 0.1	Loss 2.4125 (2.8993)	Prec@(1,5) (27.5%, 58.1%)	
07/04 08:39:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][250/703]	Step 5178	lr 0.1	Loss 2.7567 (2.9005)	Prec@(1,5) (27.3%, 58.1%)	
07/04 08:39:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][300/703]	Step 5228	lr 0.1	Loss 3.2396 (2.8861)	Prec@(1,5) (27.5%, 58.4%)	
07/04 08:39:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][350/703]	Step 5278	lr 0.1	Loss 3.2049 (2.8955)	Prec@(1,5) (27.3%, 58.3%)	
07/04 08:39:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][400/703]	Step 5328	lr 0.1	Loss 2.8942 (2.8877)	Prec@(1,5) (27.4%, 58.4%)	
07/04 08:39:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][450/703]	Step 5378	lr 0.1	Loss 2.8879 (2.8880)	Prec@(1,5) (27.4%, 58.4%)	
07/04 08:39:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][500/703]	Step 5428	lr 0.1	Loss 2.4943 (2.8871)	Prec@(1,5) (27.4%, 58.5%)	
07/04 08:39:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][550/703]	Step 5478	lr 0.1	Loss 2.9385 (2.8835)	Prec@(1,5) (27.4%, 58.6%)	
07/04 08:39:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][600/703]	Step 5528	lr 0.1	Loss 2.7835 (2.8811)	Prec@(1,5) (27.5%, 58.7%)	
07/04 08:39:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][650/703]	Step 5578	lr 0.1	Loss 2.4471 (2.8776)	Prec@(1,5) (27.6%, 58.7%)	
07/04 08:39:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][700/703]	Step 5628	lr 0.1	Loss 2.8485 (2.8789)	Prec@(1,5) (27.5%, 58.7%)	
07/04 08:39:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [7][703/703]	Step 5631	lr 0.1	Loss 2.7977 (2.8795)	Prec@(1,5) (27.5%, 58.7%)	
07/04 08:39:54PM finetuneTeacher_trainer.py:185 [INFO] Train: [  7/199] Final Prec@1 27.4867%
07/04 08:39:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [7][50/79]	Step 5632	Loss 3.0210	Prec@(1,5) (26.3%, 55.0%)
07/04 08:39:56PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [7][78/79]	Step 5632	Loss 3.0110	Prec@(1,5) (26.7%, 55.4%)
07/04 08:39:56PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  7/199] Final Prec@1 26.6800%
07/04 08:39:56PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 26.6800%
07/04 08:40:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][50/703]	Step 5682	lr 0.1	Loss 2.3042 (2.8727)	Prec@(1,5) (27.4%, 58.7%)	
07/04 08:40:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][100/703]	Step 5732	lr 0.1	Loss 2.7458 (2.8484)	Prec@(1,5) (27.5%, 59.2%)	
07/04 08:40:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][150/703]	Step 5782	lr 0.1	Loss 2.9221 (2.8454)	Prec@(1,5) (27.7%, 59.7%)	
07/04 08:40:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][200/703]	Step 5832	lr 0.1	Loss 2.7906 (2.8414)	Prec@(1,5) (27.4%, 59.7%)	
07/04 08:40:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][250/703]	Step 5882	lr 0.1	Loss 2.8041 (2.8457)	Prec@(1,5) (27.4%, 59.6%)	
07/04 08:40:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][300/703]	Step 5932	lr 0.1	Loss 3.2334 (2.8445)	Prec@(1,5) (27.8%, 59.6%)	
07/04 08:40:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][350/703]	Step 5982	lr 0.1	Loss 2.8763 (2.8454)	Prec@(1,5) (27.9%, 59.5%)	
07/04 08:40:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][400/703]	Step 6032	lr 0.1	Loss 2.7521 (2.8321)	Prec@(1,5) (28.2%, 59.9%)	
07/04 08:40:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][450/703]	Step 6082	lr 0.1	Loss 2.8381 (2.8320)	Prec@(1,5) (28.2%, 60.0%)	
07/04 08:40:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][500/703]	Step 6132	lr 0.1	Loss 3.2124 (2.8326)	Prec@(1,5) (28.2%, 59.9%)	
07/04 08:40:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][550/703]	Step 6182	lr 0.1	Loss 2.9044 (2.8268)	Prec@(1,5) (28.4%, 60.1%)	
07/04 08:40:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][600/703]	Step 6232	lr 0.1	Loss 2.8435 (2.8295)	Prec@(1,5) (28.3%, 60.0%)	
07/04 08:40:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][650/703]	Step 6282	lr 0.1	Loss 3.0352 (2.8298)	Prec@(1,5) (28.3%, 60.0%)	
07/04 08:40:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][700/703]	Step 6332	lr 0.1	Loss 2.4450 (2.8236)	Prec@(1,5) (28.4%, 60.2%)	
07/04 08:40:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [8][703/703]	Step 6335	lr 0.1	Loss 2.6629 (2.8234)	Prec@(1,5) (28.4%, 60.2%)	
07/04 08:40:43PM finetuneTeacher_trainer.py:185 [INFO] Train: [  8/199] Final Prec@1 28.4200%
07/04 08:40:44PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [8][50/79]	Step 6336	Loss 2.9497	Prec@(1,5) (26.4%, 58.1%)
07/04 08:40:44PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [8][78/79]	Step 6336	Loss 2.9397	Prec@(1,5) (26.9%, 57.5%)
07/04 08:40:44PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  8/199] Final Prec@1 26.8800%
07/04 08:40:45PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 26.8800%
07/04 08:40:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][50/703]	Step 6386	lr 0.1	Loss 2.9947 (2.7897)	Prec@(1,5) (29.6%, 60.5%)	
07/04 08:40:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][100/703]	Step 6436	lr 0.1	Loss 2.5631 (2.7770)	Prec@(1,5) (29.5%, 60.7%)	
07/04 08:40:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][150/703]	Step 6486	lr 0.1	Loss 2.8973 (2.7871)	Prec@(1,5) (29.3%, 60.8%)	
07/04 08:40:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][200/703]	Step 6536	lr 0.1	Loss 2.8939 (2.7848)	Prec@(1,5) (29.4%, 60.7%)	
07/04 08:41:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][250/703]	Step 6586	lr 0.1	Loss 2.7104 (2.7793)	Prec@(1,5) (29.4%, 60.9%)	
07/04 08:41:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][300/703]	Step 6636	lr 0.1	Loss 2.5086 (2.7815)	Prec@(1,5) (29.4%, 61.0%)	
07/04 08:41:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][350/703]	Step 6686	lr 0.1	Loss 2.6977 (2.7825)	Prec@(1,5) (29.3%, 61.0%)	
07/04 08:41:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][400/703]	Step 6736	lr 0.1	Loss 2.7690 (2.7808)	Prec@(1,5) (29.4%, 61.2%)	
07/04 08:41:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][450/703]	Step 6786	lr 0.1	Loss 2.6729 (2.7776)	Prec@(1,5) (29.5%, 61.2%)	
07/04 08:41:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][500/703]	Step 6836	lr 0.1	Loss 2.5501 (2.7727)	Prec@(1,5) (29.6%, 61.3%)	
07/04 08:41:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][550/703]	Step 6886	lr 0.1	Loss 2.8443 (2.7652)	Prec@(1,5) (29.7%, 61.4%)	
07/04 08:41:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][600/703]	Step 6936	lr 0.1	Loss 2.9252 (2.7691)	Prec@(1,5) (29.6%, 61.4%)	
07/04 08:41:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][650/703]	Step 6986	lr 0.1	Loss 2.8320 (2.7688)	Prec@(1,5) (29.6%, 61.3%)	
07/04 08:41:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][700/703]	Step 7036	lr 0.1	Loss 2.5982 (2.7691)	Prec@(1,5) (29.6%, 61.3%)	
07/04 08:41:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [9][703/703]	Step 7039	lr 0.1	Loss 2.6229 (2.7685)	Prec@(1,5) (29.6%, 61.3%)	
07/04 08:41:31PM finetuneTeacher_trainer.py:185 [INFO] Train: [  9/199] Final Prec@1 29.6222%
07/04 08:41:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [9][50/79]	Step 7040	Loss 2.8347	Prec@(1,5) (29.4%, 60.8%)
07/04 08:41:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [9][78/79]	Step 7040	Loss 2.8309	Prec@(1,5) (28.9%, 60.5%)
07/04 08:41:33PM finetuneTeacher_trainer.py:220 [INFO] Valid: [  9/199] Final Prec@1 28.9200%
07/04 08:41:33PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 28.9200%
07/04 08:41:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][50/703]	Step 7090	lr 0.1	Loss 2.5075 (2.7148)	Prec@(1,5) (30.2%, 62.4%)	
07/04 08:41:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][100/703]	Step 7140	lr 0.1	Loss 2.5649 (2.7118)	Prec@(1,5) (30.4%, 62.0%)	
07/04 08:41:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][150/703]	Step 7190	lr 0.1	Loss 2.5691 (2.7017)	Prec@(1,5) (31.1%, 62.4%)	
07/04 08:41:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][200/703]	Step 7240	lr 0.1	Loss 2.9414 (2.7119)	Prec@(1,5) (30.7%, 62.2%)	
07/04 08:41:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][250/703]	Step 7290	lr 0.1	Loss 3.0919 (2.7154)	Prec@(1,5) (30.6%, 62.3%)	
07/04 08:41:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][300/703]	Step 7340	lr 0.1	Loss 2.7954 (2.7182)	Prec@(1,5) (30.7%, 62.3%)	
07/04 08:41:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][350/703]	Step 7390	lr 0.1	Loss 2.6921 (2.7228)	Prec@(1,5) (30.5%, 62.2%)	
07/04 08:42:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][400/703]	Step 7440	lr 0.1	Loss 2.7673 (2.7186)	Prec@(1,5) (30.6%, 62.4%)	
07/04 08:42:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][450/703]	Step 7490	lr 0.1	Loss 2.9145 (2.7201)	Prec@(1,5) (30.5%, 62.4%)	
07/04 08:42:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][500/703]	Step 7540	lr 0.1	Loss 2.8064 (2.7206)	Prec@(1,5) (30.5%, 62.3%)	
07/04 08:42:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][550/703]	Step 7590	lr 0.1	Loss 2.7026 (2.7167)	Prec@(1,5) (30.6%, 62.5%)	
07/04 08:42:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][600/703]	Step 7640	lr 0.1	Loss 2.6359 (2.7166)	Prec@(1,5) (30.6%, 62.5%)	
07/04 08:42:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][650/703]	Step 7690	lr 0.1	Loss 2.7246 (2.7131)	Prec@(1,5) (30.7%, 62.7%)	
07/04 08:42:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][700/703]	Step 7740	lr 0.1	Loss 2.5051 (2.7130)	Prec@(1,5) (30.7%, 62.7%)	
07/04 08:42:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [10][703/703]	Step 7743	lr 0.1	Loss 2.6882 (2.7130)	Prec@(1,5) (30.7%, 62.7%)	
07/04 08:42:20PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 10/199] Final Prec@1 30.7444%
07/04 08:42:21PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [10][50/79]	Step 7744	Loss 2.9819	Prec@(1,5) (26.6%, 57.6%)
07/04 08:42:21PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [10][78/79]	Step 7744	Loss 2.9960	Prec@(1,5) (26.6%, 57.7%)
07/04 08:42:21PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 10/199] Final Prec@1 26.5800%
07/04 08:42:22PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 28.9200%
07/04 08:42:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][50/703]	Step 7794	lr 0.1	Loss 2.6993 (2.7216)	Prec@(1,5) (29.4%, 63.5%)	
07/04 08:42:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][100/703]	Step 7844	lr 0.1	Loss 2.6723 (2.6909)	Prec@(1,5) (30.6%, 64.2%)	
07/04 08:42:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][150/703]	Step 7894	lr 0.1	Loss 2.7419 (2.6902)	Prec@(1,5) (30.4%, 64.2%)	
07/04 08:42:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][200/703]	Step 7944	lr 0.1	Loss 2.5088 (2.6852)	Prec@(1,5) (30.8%, 64.0%)	
07/04 08:42:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][250/703]	Step 7994	lr 0.1	Loss 2.8712 (2.6861)	Prec@(1,5) (30.8%, 63.7%)	
07/04 08:42:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][300/703]	Step 8044	lr 0.1	Loss 2.7697 (2.6770)	Prec@(1,5) (30.9%, 63.9%)	
07/04 08:42:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][350/703]	Step 8094	lr 0.1	Loss 2.4988 (2.6841)	Prec@(1,5) (30.9%, 63.7%)	
07/04 08:42:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][400/703]	Step 8144	lr 0.1	Loss 2.3211 (2.6772)	Prec@(1,5) (31.1%, 63.8%)	
07/04 08:42:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][450/703]	Step 8194	lr 0.1	Loss 2.8747 (2.6692)	Prec@(1,5) (31.2%, 64.1%)	
07/04 08:42:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][500/703]	Step 8244	lr 0.1	Loss 2.6299 (2.6748)	Prec@(1,5) (31.2%, 63.9%)	
07/04 08:42:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][550/703]	Step 8294	lr 0.1	Loss 2.6191 (2.6687)	Prec@(1,5) (31.4%, 64.0%)	
07/04 08:43:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][600/703]	Step 8344	lr 0.1	Loss 2.7610 (2.6681)	Prec@(1,5) (31.4%, 64.0%)	
07/04 08:43:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][650/703]	Step 8394	lr 0.1	Loss 2.8095 (2.6717)	Prec@(1,5) (31.3%, 63.9%)	
07/04 08:43:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][700/703]	Step 8444	lr 0.1	Loss 2.3455 (2.6727)	Prec@(1,5) (31.3%, 63.9%)	
07/04 08:43:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [11][703/703]	Step 8447	lr 0.1	Loss 2.8198 (2.6731)	Prec@(1,5) (31.3%, 63.9%)	
07/04 08:43:08PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 11/199] Final Prec@1 31.3244%
07/04 08:43:10PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [11][50/79]	Step 8448	Loss 2.7946	Prec@(1,5) (29.3%, 61.7%)
07/04 08:43:10PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [11][78/79]	Step 8448	Loss 2.8155	Prec@(1,5) (28.7%, 61.2%)
07/04 08:43:10PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 11/199] Final Prec@1 28.7200%
07/04 08:43:10PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 28.9200%
07/04 08:43:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][50/703]	Step 8498	lr 0.1	Loss 3.0126 (2.6415)	Prec@(1,5) (33.2%, 64.3%)	
07/04 08:43:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][100/703]	Step 8548	lr 0.1	Loss 2.6641 (2.6282)	Prec@(1,5) (32.4%, 64.7%)	
07/04 08:43:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][150/703]	Step 8598	lr 0.1	Loss 2.5055 (2.6226)	Prec@(1,5) (32.5%, 64.7%)	
07/04 08:43:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][200/703]	Step 8648	lr 0.1	Loss 2.5313 (2.6237)	Prec@(1,5) (32.4%, 64.8%)	
07/04 08:43:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][250/703]	Step 8698	lr 0.1	Loss 2.2557 (2.6230)	Prec@(1,5) (32.3%, 64.9%)	
07/04 08:43:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][300/703]	Step 8748	lr 0.1	Loss 2.4058 (2.6232)	Prec@(1,5) (32.4%, 64.8%)	
07/04 08:43:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][350/703]	Step 8798	lr 0.1	Loss 2.5544 (2.6256)	Prec@(1,5) (32.3%, 64.9%)	
07/04 08:43:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][400/703]	Step 8848	lr 0.1	Loss 2.5545 (2.6251)	Prec@(1,5) (32.4%, 65.0%)	
07/04 08:43:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][450/703]	Step 8898	lr 0.1	Loss 2.5628 (2.6254)	Prec@(1,5) (32.3%, 65.0%)	
07/04 08:43:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][500/703]	Step 8948	lr 0.1	Loss 2.9240 (2.6294)	Prec@(1,5) (32.2%, 64.8%)	
07/04 08:43:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][550/703]	Step 8998	lr 0.1	Loss 2.7225 (2.6271)	Prec@(1,5) (32.2%, 64.9%)	
07/04 08:43:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][600/703]	Step 9048	lr 0.1	Loss 2.6584 (2.6279)	Prec@(1,5) (32.2%, 64.9%)	
07/04 08:43:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][650/703]	Step 9098	lr 0.1	Loss 2.3265 (2.6281)	Prec@(1,5) (32.2%, 64.8%)	
07/04 08:43:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][700/703]	Step 9148	lr 0.1	Loss 2.4559 (2.6291)	Prec@(1,5) (32.2%, 64.8%)	
07/04 08:43:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [12][703/703]	Step 9151	lr 0.1	Loss 2.7317 (2.6294)	Prec@(1,5) (32.2%, 64.8%)	
07/04 08:43:57PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 12/199] Final Prec@1 32.1800%
07/04 08:43:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [12][50/79]	Step 9152	Loss 2.8897	Prec@(1,5) (29.7%, 59.2%)
07/04 08:43:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [12][78/79]	Step 9152	Loss 2.8913	Prec@(1,5) (29.5%, 59.3%)
07/04 08:43:59PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 12/199] Final Prec@1 29.5400%
07/04 08:43:59PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 29.5400%
07/04 08:44:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][50/703]	Step 9202	lr 0.1	Loss 2.8651 (2.6251)	Prec@(1,5) (32.8%, 63.5%)	
07/04 08:44:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][100/703]	Step 9252	lr 0.1	Loss 2.8103 (2.6057)	Prec@(1,5) (32.8%, 64.8%)	
07/04 08:44:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][150/703]	Step 9302	lr 0.1	Loss 2.6111 (2.5791)	Prec@(1,5) (33.3%, 65.4%)	
07/04 08:44:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][200/703]	Step 9352	lr 0.1	Loss 2.6533 (2.5828)	Prec@(1,5) (33.2%, 65.4%)	
07/04 08:44:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][250/703]	Step 9402	lr 0.1	Loss 2.5881 (2.5875)	Prec@(1,5) (33.0%, 65.4%)	
07/04 08:44:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][300/703]	Step 9452	lr 0.1	Loss 2.4806 (2.5863)	Prec@(1,5) (33.3%, 65.5%)	
07/04 08:44:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][350/703]	Step 9502	lr 0.1	Loss 2.5651 (2.5911)	Prec@(1,5) (33.0%, 65.4%)	
07/04 08:44:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][400/703]	Step 9552	lr 0.1	Loss 2.7452 (2.5892)	Prec@(1,5) (32.9%, 65.5%)	
07/04 08:44:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][450/703]	Step 9602	lr 0.1	Loss 2.7827 (2.5860)	Prec@(1,5) (33.0%, 65.5%)	
07/04 08:44:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][500/703]	Step 9652	lr 0.1	Loss 2.5338 (2.5802)	Prec@(1,5) (33.2%, 65.6%)	
07/04 08:44:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][550/703]	Step 9702	lr 0.1	Loss 2.7414 (2.5801)	Prec@(1,5) (33.2%, 65.6%)	
07/04 08:44:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][600/703]	Step 9752	lr 0.1	Loss 2.6020 (2.5763)	Prec@(1,5) (33.2%, 65.7%)	
07/04 08:44:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][650/703]	Step 9802	lr 0.1	Loss 2.3542 (2.5789)	Prec@(1,5) (33.2%, 65.6%)	
07/04 08:44:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][700/703]	Step 9852	lr 0.1	Loss 2.9403 (2.5785)	Prec@(1,5) (33.3%, 65.6%)	
07/04 08:44:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [13][703/703]	Step 9855	lr 0.1	Loss 2.8745 (2.5787)	Prec@(1,5) (33.3%, 65.6%)	
07/04 08:44:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 13/199] Final Prec@1 33.2556%
07/04 08:44:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [13][50/79]	Step 9856	Loss 2.8434	Prec@(1,5) (28.9%, 60.3%)
07/04 08:44:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [13][78/79]	Step 9856	Loss 2.8406	Prec@(1,5) (29.2%, 60.4%)
07/04 08:44:47PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 13/199] Final Prec@1 29.1400%
07/04 08:44:47PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 29.5400%
07/04 08:44:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][50/703]	Step 9906	lr 0.1	Loss 2.5155 (2.4920)	Prec@(1,5) (35.4%, 69.1%)	
07/04 08:44:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][100/703]	Step 9956	lr 0.1	Loss 2.3433 (2.4996)	Prec@(1,5) (35.1%, 67.9%)	
07/04 08:44:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][150/703]	Step 10006	lr 0.1	Loss 2.3344 (2.5263)	Prec@(1,5) (34.9%, 67.2%)	
07/04 08:45:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][200/703]	Step 10056	lr 0.1	Loss 2.6306 (2.5268)	Prec@(1,5) (34.6%, 67.2%)	
07/04 08:45:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][250/703]	Step 10106	lr 0.1	Loss 2.5877 (2.5422)	Prec@(1,5) (34.2%, 66.8%)	
07/04 08:45:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][300/703]	Step 10156	lr 0.1	Loss 2.3597 (2.5390)	Prec@(1,5) (34.1%, 66.9%)	
07/04 08:45:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][350/703]	Step 10206	lr 0.1	Loss 2.8369 (2.5456)	Prec@(1,5) (34.2%, 66.8%)	
07/04 08:45:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][400/703]	Step 10256	lr 0.1	Loss 2.8468 (2.5472)	Prec@(1,5) (34.1%, 66.7%)	
07/04 08:45:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][450/703]	Step 10306	lr 0.1	Loss 2.8086 (2.5534)	Prec@(1,5) (34.1%, 66.5%)	
07/04 08:45:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][500/703]	Step 10356	lr 0.1	Loss 2.5195 (2.5521)	Prec@(1,5) (34.1%, 66.5%)	
07/04 08:45:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][550/703]	Step 10406	lr 0.1	Loss 2.5259 (2.5514)	Prec@(1,5) (34.1%, 66.5%)	
07/04 08:45:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][600/703]	Step 10456	lr 0.1	Loss 2.3761 (2.5494)	Prec@(1,5) (34.2%, 66.5%)	
07/04 08:45:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][650/703]	Step 10506	lr 0.1	Loss 2.4401 (2.5423)	Prec@(1,5) (34.3%, 66.6%)	
07/04 08:45:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][700/703]	Step 10556	lr 0.1	Loss 2.2149 (2.5483)	Prec@(1,5) (34.2%, 66.5%)	
07/04 08:45:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [14][703/703]	Step 10559	lr 0.1	Loss 2.8470 (2.5494)	Prec@(1,5) (34.2%, 66.5%)	
07/04 08:45:34PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 14/199] Final Prec@1 34.1644%
07/04 08:45:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [14][50/79]	Step 10560	Loss 2.7359	Prec@(1,5) (29.4%, 62.3%)
07/04 08:45:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [14][78/79]	Step 10560	Loss 2.7530	Prec@(1,5) (29.8%, 61.6%)
07/04 08:45:36PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 14/199] Final Prec@1 29.8400%
07/04 08:45:36PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 29.8400%
07/04 08:45:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][50/703]	Step 10610	lr 0.1	Loss 2.2484 (2.5117)	Prec@(1,5) (33.5%, 67.2%)	
07/04 08:45:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][100/703]	Step 10660	lr 0.1	Loss 2.2513 (2.5134)	Prec@(1,5) (34.2%, 67.3%)	
07/04 08:45:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][150/703]	Step 10710	lr 0.1	Loss 2.4722 (2.5281)	Prec@(1,5) (33.8%, 66.9%)	
07/04 08:45:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][200/703]	Step 10760	lr 0.1	Loss 2.5766 (2.5392)	Prec@(1,5) (33.7%, 66.5%)	
07/04 08:45:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][250/703]	Step 10810	lr 0.1	Loss 3.1765 (2.5343)	Prec@(1,5) (33.7%, 66.8%)	
07/04 08:45:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][300/703]	Step 10860	lr 0.1	Loss 2.7721 (2.5363)	Prec@(1,5) (33.9%, 66.8%)	
07/04 08:45:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][350/703]	Step 10910	lr 0.1	Loss 2.5725 (2.5359)	Prec@(1,5) (34.2%, 66.7%)	
07/04 08:46:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][400/703]	Step 10960	lr 0.1	Loss 2.3129 (2.5374)	Prec@(1,5) (34.2%, 66.7%)	
07/04 08:46:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][450/703]	Step 11010	lr 0.1	Loss 2.8145 (2.5315)	Prec@(1,5) (34.2%, 66.9%)	
07/04 08:46:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][500/703]	Step 11060	lr 0.1	Loss 2.6617 (2.5329)	Prec@(1,5) (34.2%, 66.8%)	
07/04 08:46:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][550/703]	Step 11110	lr 0.1	Loss 2.5664 (2.5270)	Prec@(1,5) (34.3%, 67.0%)	
07/04 08:46:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][600/703]	Step 11160	lr 0.1	Loss 2.9967 (2.5292)	Prec@(1,5) (34.3%, 67.0%)	
07/04 08:46:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][650/703]	Step 11210	lr 0.1	Loss 2.7651 (2.5310)	Prec@(1,5) (34.3%, 67.0%)	
07/04 08:46:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][700/703]	Step 11260	lr 0.1	Loss 2.5276 (2.5262)	Prec@(1,5) (34.4%, 67.1%)	
07/04 08:46:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [15][703/703]	Step 11263	lr 0.1	Loss 2.4899 (2.5256)	Prec@(1,5) (34.4%, 67.1%)	
07/04 08:46:22PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 15/199] Final Prec@1 34.4178%
07/04 08:46:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [15][50/79]	Step 11264	Loss 2.9927	Prec@(1,5) (27.1%, 59.1%)
07/04 08:46:24PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [15][78/79]	Step 11264	Loss 3.0317	Prec@(1,5) (27.1%, 58.3%)
07/04 08:46:24PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 15/199] Final Prec@1 27.1000%
07/04 08:46:24PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 29.8400%
07/04 08:46:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][50/703]	Step 11314	lr 0.1	Loss 2.7029 (2.4982)	Prec@(1,5) (34.9%, 67.8%)	
07/04 08:46:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][100/703]	Step 11364	lr 0.1	Loss 2.6470 (2.5236)	Prec@(1,5) (34.2%, 67.0%)	
07/04 08:46:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][150/703]	Step 11414	lr 0.1	Loss 2.3550 (2.5222)	Prec@(1,5) (34.3%, 67.1%)	
07/04 08:46:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][200/703]	Step 11464	lr 0.1	Loss 2.1655 (2.5077)	Prec@(1,5) (34.6%, 67.7%)	
07/04 08:46:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][250/703]	Step 11514	lr 0.1	Loss 2.4116 (2.5121)	Prec@(1,5) (34.6%, 67.4%)	
07/04 08:46:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][300/703]	Step 11564	lr 0.1	Loss 2.7534 (2.5110)	Prec@(1,5) (34.6%, 67.3%)	
07/04 08:46:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][350/703]	Step 11614	lr 0.1	Loss 2.5116 (2.5018)	Prec@(1,5) (34.9%, 67.5%)	
07/04 08:46:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][400/703]	Step 11664	lr 0.1	Loss 2.4984 (2.5020)	Prec@(1,5) (34.9%, 67.5%)	
07/04 08:46:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][450/703]	Step 11714	lr 0.1	Loss 2.5950 (2.4990)	Prec@(1,5) (35.1%, 67.6%)	
07/04 08:46:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][500/703]	Step 11764	lr 0.1	Loss 2.2659 (2.5024)	Prec@(1,5) (35.0%, 67.4%)	
07/04 08:46:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][550/703]	Step 11814	lr 0.1	Loss 2.3478 (2.5021)	Prec@(1,5) (35.1%, 67.4%)	
07/04 08:47:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][600/703]	Step 11864	lr 0.1	Loss 2.4752 (2.5017)	Prec@(1,5) (35.0%, 67.3%)	
07/04 08:47:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][650/703]	Step 11914	lr 0.1	Loss 2.5122 (2.5016)	Prec@(1,5) (35.0%, 67.3%)	
07/04 08:47:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][700/703]	Step 11964	lr 0.1	Loss 2.2941 (2.4998)	Prec@(1,5) (35.1%, 67.4%)	
07/04 08:47:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [16][703/703]	Step 11967	lr 0.1	Loss 2.8378 (2.5007)	Prec@(1,5) (35.0%, 67.4%)	
07/04 08:47:07PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 16/199] Final Prec@1 35.0422%
07/04 08:47:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [16][50/79]	Step 11968	Loss 2.7316	Prec@(1,5) (31.4%, 63.3%)
07/04 08:47:09PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [16][78/79]	Step 11968	Loss 2.6984	Prec@(1,5) (31.7%, 63.8%)
07/04 08:47:09PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 16/199] Final Prec@1 31.7000%
07/04 08:47:09PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 31.7000%
07/04 08:47:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][50/703]	Step 12018	lr 0.1	Loss 2.3161 (2.4244)	Prec@(1,5) (36.1%, 69.3%)	
07/04 08:47:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][100/703]	Step 12068	lr 0.1	Loss 2.7823 (2.4264)	Prec@(1,5) (36.5%, 69.2%)	
07/04 08:47:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][150/703]	Step 12118	lr 0.1	Loss 2.5838 (2.4568)	Prec@(1,5) (36.0%, 68.3%)	
07/04 08:47:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][200/703]	Step 12168	lr 0.1	Loss 2.6403 (2.4590)	Prec@(1,5) (36.0%, 68.0%)	
07/04 08:47:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][250/703]	Step 12218	lr 0.1	Loss 2.4181 (2.4746)	Prec@(1,5) (35.7%, 67.5%)	
07/04 08:47:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][300/703]	Step 12268	lr 0.1	Loss 2.4447 (2.4726)	Prec@(1,5) (35.7%, 67.7%)	
07/04 08:47:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][350/703]	Step 12318	lr 0.1	Loss 2.3963 (2.4694)	Prec@(1,5) (35.7%, 67.9%)	
07/04 08:47:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][400/703]	Step 12368	lr 0.1	Loss 2.5323 (2.4648)	Prec@(1,5) (35.8%, 68.0%)	
07/04 08:47:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][450/703]	Step 12418	lr 0.1	Loss 2.4196 (2.4656)	Prec@(1,5) (35.8%, 68.1%)	
07/04 08:47:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][500/703]	Step 12468	lr 0.1	Loss 2.1888 (2.4676)	Prec@(1,5) (35.7%, 68.0%)	
07/04 08:47:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][550/703]	Step 12518	lr 0.1	Loss 2.8165 (2.4648)	Prec@(1,5) (35.8%, 68.1%)	
07/04 08:47:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][600/703]	Step 12568	lr 0.1	Loss 2.4702 (2.4662)	Prec@(1,5) (35.8%, 68.1%)	
07/04 08:47:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][650/703]	Step 12618	lr 0.1	Loss 2.5120 (2.4710)	Prec@(1,5) (35.7%, 68.0%)	
07/04 08:47:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][700/703]	Step 12668	lr 0.1	Loss 2.7066 (2.4730)	Prec@(1,5) (35.6%, 68.0%)	
07/04 08:47:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [17][703/703]	Step 12671	lr 0.1	Loss 2.6512 (2.4732)	Prec@(1,5) (35.6%, 68.0%)	
07/04 08:47:56PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 17/199] Final Prec@1 35.5711%
07/04 08:47:57PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [17][50/79]	Step 12672	Loss 2.8006	Prec@(1,5) (30.4%, 61.9%)
07/04 08:47:57PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [17][78/79]	Step 12672	Loss 2.8169	Prec@(1,5) (30.0%, 61.2%)
07/04 08:47:57PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 17/199] Final Prec@1 30.0200%
07/04 08:47:58PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 31.7000%
07/04 08:48:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][50/703]	Step 12722	lr 0.1	Loss 2.0512 (2.4939)	Prec@(1,5) (36.0%, 68.2%)	
07/04 08:48:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][100/703]	Step 12772	lr 0.1	Loss 2.5579 (2.4663)	Prec@(1,5) (36.0%, 68.4%)	
07/04 08:48:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][150/703]	Step 12822	lr 0.1	Loss 2.5109 (2.4544)	Prec@(1,5) (36.1%, 68.7%)	
07/04 08:48:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][200/703]	Step 12872	lr 0.1	Loss 2.1837 (2.4414)	Prec@(1,5) (36.3%, 68.9%)	
07/04 08:48:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][250/703]	Step 12922	lr 0.1	Loss 2.6293 (2.4395)	Prec@(1,5) (36.2%, 69.1%)	
07/04 08:48:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][300/703]	Step 12972	lr 0.1	Loss 2.5335 (2.4293)	Prec@(1,5) (36.4%, 69.2%)	
07/04 08:48:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][350/703]	Step 13022	lr 0.1	Loss 2.2818 (2.4323)	Prec@(1,5) (36.3%, 69.1%)	
07/04 08:48:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][400/703]	Step 13072	lr 0.1	Loss 2.5765 (2.4325)	Prec@(1,5) (36.5%, 69.1%)	
07/04 08:48:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][450/703]	Step 13122	lr 0.1	Loss 2.6799 (2.4384)	Prec@(1,5) (36.5%, 69.1%)	
07/04 08:48:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][500/703]	Step 13172	lr 0.1	Loss 2.5651 (2.4385)	Prec@(1,5) (36.5%, 69.1%)	
07/04 08:48:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][550/703]	Step 13222	lr 0.1	Loss 2.3546 (2.4405)	Prec@(1,5) (36.4%, 68.9%)	
07/04 08:48:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][600/703]	Step 13272	lr 0.1	Loss 2.0257 (2.4421)	Prec@(1,5) (36.4%, 68.9%)	
07/04 08:48:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][650/703]	Step 13322	lr 0.1	Loss 2.2518 (2.4403)	Prec@(1,5) (36.5%, 69.0%)	
07/04 08:48:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][700/703]	Step 13372	lr 0.1	Loss 2.4996 (2.4394)	Prec@(1,5) (36.5%, 69.0%)	
07/04 08:48:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [18][703/703]	Step 13375	lr 0.1	Loss 2.9058 (2.4402)	Prec@(1,5) (36.5%, 69.0%)	
07/04 08:48:45PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 18/199] Final Prec@1 36.4667%
07/04 08:48:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [18][50/79]	Step 13376	Loss 2.7381	Prec@(1,5) (31.7%, 63.8%)
07/04 08:48:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [18][78/79]	Step 13376	Loss 2.7119	Prec@(1,5) (31.9%, 64.1%)
07/04 08:48:46PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 18/199] Final Prec@1 31.9000%
07/04 08:48:47PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 31.9000%
07/04 08:48:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][50/703]	Step 13426	lr 0.1	Loss 2.5633 (2.4594)	Prec@(1,5) (36.3%, 68.6%)	
07/04 08:48:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][100/703]	Step 13476	lr 0.1	Loss 2.4737 (2.4043)	Prec@(1,5) (37.5%, 69.2%)	
07/04 08:48:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][150/703]	Step 13526	lr 0.1	Loss 2.2533 (2.4102)	Prec@(1,5) (37.2%, 69.5%)	
07/04 08:49:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][200/703]	Step 13576	lr 0.1	Loss 2.8019 (2.4206)	Prec@(1,5) (37.0%, 69.3%)	
07/04 08:49:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][250/703]	Step 13626	lr 0.1	Loss 2.5275 (2.4287)	Prec@(1,5) (36.7%, 69.0%)	
07/04 08:49:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][300/703]	Step 13676	lr 0.1	Loss 2.4143 (2.4193)	Prec@(1,5) (36.8%, 69.2%)	
07/04 08:49:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][350/703]	Step 13726	lr 0.1	Loss 2.5381 (2.4258)	Prec@(1,5) (36.6%, 69.0%)	
07/04 08:49:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][400/703]	Step 13776	lr 0.1	Loss 2.5312 (2.4240)	Prec@(1,5) (36.7%, 69.1%)	
07/04 08:49:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][450/703]	Step 13826	lr 0.1	Loss 2.5651 (2.4164)	Prec@(1,5) (36.9%, 69.2%)	
07/04 08:49:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][500/703]	Step 13876	lr 0.1	Loss 2.5529 (2.4211)	Prec@(1,5) (36.8%, 69.2%)	
07/04 08:49:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][550/703]	Step 13926	lr 0.1	Loss 2.3203 (2.4213)	Prec@(1,5) (36.8%, 69.2%)	
07/04 08:49:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][600/703]	Step 13976	lr 0.1	Loss 2.5290 (2.4214)	Prec@(1,5) (36.8%, 69.3%)	
07/04 08:49:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][650/703]	Step 14026	lr 0.1	Loss 2.4723 (2.4250)	Prec@(1,5) (36.8%, 69.2%)	
07/04 08:49:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][700/703]	Step 14076	lr 0.1	Loss 2.6908 (2.4258)	Prec@(1,5) (36.8%, 69.2%)	
07/04 08:49:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [19][703/703]	Step 14079	lr 0.1	Loss 2.5768 (2.4256)	Prec@(1,5) (36.8%, 69.3%)	
07/04 08:49:34PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 19/199] Final Prec@1 36.7956%
07/04 08:49:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [19][50/79]	Step 14080	Loss 2.5977	Prec@(1,5) (33.7%, 65.4%)
07/04 08:49:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [19][78/79]	Step 14080	Loss 2.5905	Prec@(1,5) (34.0%, 65.8%)
07/04 08:49:35PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 19/199] Final Prec@1 33.9800%
07/04 08:49:36PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 33.9800%
07/04 08:49:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][50/703]	Step 14130	lr 0.1	Loss 2.1705 (2.3765)	Prec@(1,5) (38.1%, 70.1%)	
07/04 08:49:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][100/703]	Step 14180	lr 0.1	Loss 2.1994 (2.3999)	Prec@(1,5) (37.5%, 69.9%)	
07/04 08:49:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][150/703]	Step 14230	lr 0.1	Loss 2.3267 (2.3958)	Prec@(1,5) (37.2%, 69.9%)	
07/04 08:49:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][200/703]	Step 14280	lr 0.1	Loss 2.5546 (2.3943)	Prec@(1,5) (37.4%, 69.7%)	
07/04 08:49:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][250/703]	Step 14330	lr 0.1	Loss 2.7111 (2.3959)	Prec@(1,5) (37.4%, 69.8%)	
07/04 08:49:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][300/703]	Step 14380	lr 0.1	Loss 2.0449 (2.3926)	Prec@(1,5) (37.5%, 69.8%)	
07/04 08:49:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][350/703]	Step 14430	lr 0.1	Loss 2.5665 (2.3940)	Prec@(1,5) (37.5%, 69.9%)	
07/04 08:50:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][400/703]	Step 14480	lr 0.1	Loss 2.1709 (2.3971)	Prec@(1,5) (37.4%, 69.8%)	
07/04 08:50:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][450/703]	Step 14530	lr 0.1	Loss 2.3591 (2.3945)	Prec@(1,5) (37.4%, 69.9%)	
07/04 08:50:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][500/703]	Step 14580	lr 0.1	Loss 2.3007 (2.3985)	Prec@(1,5) (37.3%, 69.9%)	
07/04 08:50:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][550/703]	Step 14630	lr 0.1	Loss 2.7634 (2.4044)	Prec@(1,5) (37.2%, 69.7%)	
07/04 08:50:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][600/703]	Step 14680	lr 0.1	Loss 2.3484 (2.4004)	Prec@(1,5) (37.3%, 69.9%)	
07/04 08:50:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][650/703]	Step 14730	lr 0.1	Loss 2.4130 (2.3997)	Prec@(1,5) (37.3%, 69.9%)	
07/04 08:50:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][700/703]	Step 14780	lr 0.1	Loss 2.3315 (2.4039)	Prec@(1,5) (37.2%, 69.9%)	
07/04 08:50:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [20][703/703]	Step 14783	lr 0.1	Loss 2.4029 (2.4042)	Prec@(1,5) (37.2%, 69.9%)	
07/04 08:50:21PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 20/199] Final Prec@1 37.2000%
07/04 08:50:22PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [20][50/79]	Step 14784	Loss 2.6512	Prec@(1,5) (32.9%, 64.6%)
07/04 08:50:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [20][78/79]	Step 14784	Loss 2.6847	Prec@(1,5) (32.4%, 63.9%)
07/04 08:50:23PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 20/199] Final Prec@1 32.3800%
07/04 08:50:23PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 33.9800%
07/04 08:50:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][50/703]	Step 14834	lr 0.1	Loss 2.3749 (2.4818)	Prec@(1,5) (35.4%, 67.8%)	
07/04 08:50:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][100/703]	Step 14884	lr 0.1	Loss 2.3572 (2.3980)	Prec@(1,5) (36.9%, 69.5%)	
07/04 08:50:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][150/703]	Step 14934	lr 0.1	Loss 2.0280 (2.3723)	Prec@(1,5) (37.5%, 70.0%)	
07/04 08:50:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][200/703]	Step 14984	lr 0.1	Loss 2.1722 (2.3703)	Prec@(1,5) (37.7%, 70.0%)	
07/04 08:50:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][250/703]	Step 15034	lr 0.1	Loss 2.3100 (2.3749)	Prec@(1,5) (37.8%, 69.9%)	
07/04 08:50:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][300/703]	Step 15084	lr 0.1	Loss 2.2150 (2.3848)	Prec@(1,5) (37.7%, 69.8%)	
07/04 08:50:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][350/703]	Step 15134	lr 0.1	Loss 1.8868 (2.3795)	Prec@(1,5) (37.9%, 69.9%)	
07/04 08:50:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][400/703]	Step 15184	lr 0.1	Loss 2.3706 (2.3808)	Prec@(1,5) (37.8%, 69.9%)	
07/04 08:50:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][450/703]	Step 15234	lr 0.1	Loss 2.3237 (2.3843)	Prec@(1,5) (37.7%, 69.9%)	
07/04 08:50:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][500/703]	Step 15284	lr 0.1	Loss 2.0755 (2.3882)	Prec@(1,5) (37.6%, 69.9%)	
07/04 08:50:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][550/703]	Step 15334	lr 0.1	Loss 2.2987 (2.3891)	Prec@(1,5) (37.6%, 69.9%)	
07/04 08:51:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][600/703]	Step 15384	lr 0.1	Loss 2.4815 (2.3895)	Prec@(1,5) (37.6%, 69.9%)	
07/04 08:51:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][650/703]	Step 15434	lr 0.1	Loss 2.3487 (2.3911)	Prec@(1,5) (37.6%, 69.8%)	
07/04 08:51:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][700/703]	Step 15484	lr 0.1	Loss 2.6217 (2.3947)	Prec@(1,5) (37.6%, 69.7%)	
07/04 08:51:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [21][703/703]	Step 15487	lr 0.1	Loss 2.4350 (2.3951)	Prec@(1,5) (37.5%, 69.7%)	
07/04 08:51:10PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 21/199] Final Prec@1 37.5356%
07/04 08:51:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [21][50/79]	Step 15488	Loss 2.6676	Prec@(1,5) (32.9%, 64.6%)
07/04 08:51:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [21][78/79]	Step 15488	Loss 2.6428	Prec@(1,5) (33.2%, 65.1%)
07/04 08:51:11PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 21/199] Final Prec@1 33.1800%
07/04 08:51:12PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 33.9800%
07/04 08:51:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][50/703]	Step 15538	lr 0.1	Loss 2.5605 (2.3903)	Prec@(1,5) (36.2%, 70.2%)	
07/04 08:51:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][100/703]	Step 15588	lr 0.1	Loss 2.5216 (2.3866)	Prec@(1,5) (37.3%, 70.2%)	
07/04 08:51:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][150/703]	Step 15638	lr 0.1	Loss 2.0904 (2.3783)	Prec@(1,5) (37.6%, 70.5%)	
07/04 08:51:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][200/703]	Step 15688	lr 0.1	Loss 2.5650 (2.3705)	Prec@(1,5) (37.9%, 70.7%)	
07/04 08:51:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][250/703]	Step 15738	lr 0.1	Loss 2.0626 (2.3666)	Prec@(1,5) (38.0%, 70.7%)	
07/04 08:51:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][300/703]	Step 15788	lr 0.1	Loss 2.5496 (2.3709)	Prec@(1,5) (37.8%, 70.7%)	
07/04 08:51:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][350/703]	Step 15838	lr 0.1	Loss 2.3297 (2.3720)	Prec@(1,5) (37.9%, 70.7%)	
07/04 08:51:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][400/703]	Step 15888	lr 0.1	Loss 2.3234 (2.3772)	Prec@(1,5) (37.7%, 70.6%)	
07/04 08:51:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][450/703]	Step 15938	lr 0.1	Loss 2.7067 (2.3815)	Prec@(1,5) (37.5%, 70.5%)	
07/04 08:51:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][500/703]	Step 15988	lr 0.1	Loss 2.2624 (2.3797)	Prec@(1,5) (37.5%, 70.5%)	
07/04 08:51:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][550/703]	Step 16038	lr 0.1	Loss 1.9746 (2.3730)	Prec@(1,5) (37.8%, 70.6%)	
07/04 08:51:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][600/703]	Step 16088	lr 0.1	Loss 2.3670 (2.3664)	Prec@(1,5) (38.0%, 70.7%)	
07/04 08:51:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][650/703]	Step 16138	lr 0.1	Loss 2.3403 (2.3694)	Prec@(1,5) (38.0%, 70.6%)	
07/04 08:51:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][700/703]	Step 16188	lr 0.1	Loss 2.7575 (2.3748)	Prec@(1,5) (37.9%, 70.5%)	
07/04 08:51:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [22][703/703]	Step 16191	lr 0.1	Loss 2.7716 (2.3754)	Prec@(1,5) (37.9%, 70.5%)	
07/04 08:51:58PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 22/199] Final Prec@1 37.8867%
07/04 08:51:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [22][50/79]	Step 16192	Loss 2.6128	Prec@(1,5) (35.3%, 65.2%)
07/04 08:52:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [22][78/79]	Step 16192	Loss 2.6219	Prec@(1,5) (35.0%, 65.3%)
07/04 08:52:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 22/199] Final Prec@1 35.0200%
07/04 08:52:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 35.0200%
07/04 08:52:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][50/703]	Step 16242	lr 0.1	Loss 2.2393 (2.4193)	Prec@(1,5) (38.4%, 69.5%)	
07/04 08:52:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][100/703]	Step 16292	lr 0.1	Loss 2.5692 (2.3567)	Prec@(1,5) (39.5%, 70.4%)	
07/04 08:52:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][150/703]	Step 16342	lr 0.1	Loss 2.3404 (2.3498)	Prec@(1,5) (39.0%, 70.6%)	
07/04 08:52:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][200/703]	Step 16392	lr 0.1	Loss 2.4169 (2.3534)	Prec@(1,5) (38.7%, 70.4%)	
07/04 08:52:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][250/703]	Step 16442	lr 0.1	Loss 2.2823 (2.3368)	Prec@(1,5) (39.0%, 70.8%)	
07/04 08:52:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][300/703]	Step 16492	lr 0.1	Loss 2.5622 (2.3397)	Prec@(1,5) (39.0%, 70.6%)	
07/04 08:52:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][350/703]	Step 16542	lr 0.1	Loss 2.2269 (2.3396)	Prec@(1,5) (39.0%, 70.6%)	
07/04 08:52:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][400/703]	Step 16592	lr 0.1	Loss 2.1159 (2.3438)	Prec@(1,5) (38.8%, 70.8%)	
07/04 08:52:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][450/703]	Step 16642	lr 0.1	Loss 2.0531 (2.3490)	Prec@(1,5) (38.6%, 70.6%)	
07/04 08:52:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][500/703]	Step 16692	lr 0.1	Loss 2.3459 (2.3510)	Prec@(1,5) (38.5%, 70.5%)	
07/04 08:52:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][550/703]	Step 16742	lr 0.1	Loss 2.1330 (2.3531)	Prec@(1,5) (38.5%, 70.5%)	
07/04 08:52:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][600/703]	Step 16792	lr 0.1	Loss 2.7155 (2.3564)	Prec@(1,5) (38.3%, 70.4%)	
07/04 08:52:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][650/703]	Step 16842	lr 0.1	Loss 2.3033 (2.3579)	Prec@(1,5) (38.2%, 70.4%)	
07/04 08:52:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][700/703]	Step 16892	lr 0.1	Loss 2.1897 (2.3598)	Prec@(1,5) (38.1%, 70.4%)	
07/04 08:52:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [23][703/703]	Step 16895	lr 0.1	Loss 2.4721 (2.3598)	Prec@(1,5) (38.1%, 70.4%)	
07/04 08:52:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 23/199] Final Prec@1 38.1489%
07/04 08:52:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [23][50/79]	Step 16896	Loss 2.4450	Prec@(1,5) (36.3%, 69.2%)
07/04 08:52:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [23][78/79]	Step 16896	Loss 2.4551	Prec@(1,5) (36.6%, 68.7%)
07/04 08:52:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 23/199] Final Prec@1 36.6000%
07/04 08:52:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.6000%
07/04 08:52:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][50/703]	Step 16946	lr 0.1	Loss 2.5414 (2.3000)	Prec@(1,5) (38.5%, 72.6%)	
07/04 08:52:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][100/703]	Step 16996	lr 0.1	Loss 2.2822 (2.3258)	Prec@(1,5) (38.2%, 71.4%)	
07/04 08:52:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][150/703]	Step 17046	lr 0.1	Loss 2.2977 (2.3569)	Prec@(1,5) (37.9%, 70.6%)	
07/04 08:53:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][200/703]	Step 17096	lr 0.1	Loss 2.3959 (2.3589)	Prec@(1,5) (38.0%, 70.6%)	
07/04 08:53:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][250/703]	Step 17146	lr 0.1	Loss 2.4987 (2.3487)	Prec@(1,5) (38.1%, 70.9%)	
07/04 08:53:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][300/703]	Step 17196	lr 0.1	Loss 2.3196 (2.3492)	Prec@(1,5) (38.1%, 70.7%)	
07/04 08:53:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][350/703]	Step 17246	lr 0.1	Loss 2.2863 (2.3490)	Prec@(1,5) (38.2%, 70.7%)	
07/04 08:53:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][400/703]	Step 17296	lr 0.1	Loss 2.3794 (2.3450)	Prec@(1,5) (38.3%, 70.7%)	
07/04 08:53:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][450/703]	Step 17346	lr 0.1	Loss 2.6584 (2.3491)	Prec@(1,5) (38.3%, 70.6%)	
07/04 08:53:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][500/703]	Step 17396	lr 0.1	Loss 2.5552 (2.3453)	Prec@(1,5) (38.3%, 70.8%)	
07/04 08:53:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][550/703]	Step 17446	lr 0.1	Loss 2.1203 (2.3475)	Prec@(1,5) (38.3%, 70.8%)	
07/04 08:53:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][600/703]	Step 17496	lr 0.1	Loss 2.1705 (2.3482)	Prec@(1,5) (38.2%, 70.8%)	
07/04 08:53:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][650/703]	Step 17546	lr 0.1	Loss 2.1128 (2.3477)	Prec@(1,5) (38.3%, 70.8%)	
07/04 08:53:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][700/703]	Step 17596	lr 0.1	Loss 2.4872 (2.3481)	Prec@(1,5) (38.2%, 70.7%)	
07/04 08:53:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [24][703/703]	Step 17599	lr 0.1	Loss 2.7676 (2.3488)	Prec@(1,5) (38.2%, 70.7%)	
07/04 08:53:34PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 24/199] Final Prec@1 38.2022%
07/04 08:53:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [24][50/79]	Step 17600	Loss 2.5651	Prec@(1,5) (35.2%, 66.6%)
07/04 08:53:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [24][78/79]	Step 17600	Loss 2.5644	Prec@(1,5) (35.2%, 66.5%)
07/04 08:53:36PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 24/199] Final Prec@1 35.2200%
07/04 08:53:36PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.6000%
07/04 08:53:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][50/703]	Step 17650	lr 0.1	Loss 2.0942 (2.3255)	Prec@(1,5) (39.0%, 71.3%)	
07/04 08:53:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][100/703]	Step 17700	lr 0.1	Loss 2.0467 (2.3103)	Prec@(1,5) (39.1%, 71.5%)	
07/04 08:53:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][150/703]	Step 17750	lr 0.1	Loss 2.2976 (2.3154)	Prec@(1,5) (38.9%, 71.6%)	
07/04 08:53:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][200/703]	Step 17800	lr 0.1	Loss 2.1537 (2.3103)	Prec@(1,5) (39.0%, 71.9%)	
07/04 08:53:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][250/703]	Step 17850	lr 0.1	Loss 2.2513 (2.3139)	Prec@(1,5) (39.0%, 71.6%)	
07/04 08:53:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][300/703]	Step 17900	lr 0.1	Loss 2.6599 (2.3213)	Prec@(1,5) (39.0%, 71.4%)	
07/04 08:53:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][350/703]	Step 17950	lr 0.1	Loss 2.1893 (2.3257)	Prec@(1,5) (38.7%, 71.5%)	
07/04 08:54:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][400/703]	Step 18000	lr 0.1	Loss 2.1169 (2.3292)	Prec@(1,5) (38.8%, 71.2%)	
07/04 08:54:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][450/703]	Step 18050	lr 0.1	Loss 2.0279 (2.3300)	Prec@(1,5) (38.6%, 71.2%)	
07/04 08:54:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][500/703]	Step 18100	lr 0.1	Loss 2.4899 (2.3393)	Prec@(1,5) (38.5%, 71.1%)	
07/04 08:54:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][550/703]	Step 18150	lr 0.1	Loss 2.6811 (2.3393)	Prec@(1,5) (38.5%, 71.1%)	
07/04 08:54:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][600/703]	Step 18200	lr 0.1	Loss 2.3987 (2.3362)	Prec@(1,5) (38.5%, 71.1%)	
07/04 08:54:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][650/703]	Step 18250	lr 0.1	Loss 2.7721 (2.3415)	Prec@(1,5) (38.4%, 71.0%)	
07/04 08:54:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][700/703]	Step 18300	lr 0.1	Loss 2.4760 (2.3421)	Prec@(1,5) (38.5%, 71.0%)	
07/04 08:54:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [25][703/703]	Step 18303	lr 0.1	Loss 2.3181 (2.3426)	Prec@(1,5) (38.4%, 71.0%)	
07/04 08:54:23PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 25/199] Final Prec@1 38.4222%
07/04 08:54:24PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [25][50/79]	Step 18304	Loss 2.7065	Prec@(1,5) (32.8%, 63.9%)
07/04 08:54:24PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [25][78/79]	Step 18304	Loss 2.6826	Prec@(1,5) (32.6%, 64.3%)
07/04 08:54:25PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 25/199] Final Prec@1 32.6400%
07/04 08:54:25PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.6000%
07/04 08:54:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][50/703]	Step 18354	lr 0.1	Loss 2.1452 (2.3744)	Prec@(1,5) (38.3%, 70.4%)	
07/04 08:54:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][100/703]	Step 18404	lr 0.1	Loss 2.3722 (2.3447)	Prec@(1,5) (39.0%, 71.1%)	
07/04 08:54:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][150/703]	Step 18454	lr 0.1	Loss 2.0897 (2.3315)	Prec@(1,5) (38.8%, 71.4%)	
07/04 08:54:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][200/703]	Step 18504	lr 0.1	Loss 2.3189 (2.3252)	Prec@(1,5) (39.0%, 71.4%)	
07/04 08:54:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][250/703]	Step 18554	lr 0.1	Loss 2.3438 (2.3234)	Prec@(1,5) (39.1%, 71.3%)	
07/04 08:54:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][300/703]	Step 18604	lr 0.1	Loss 2.2882 (2.3121)	Prec@(1,5) (39.2%, 71.7%)	
07/04 08:54:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][350/703]	Step 18654	lr 0.1	Loss 2.4853 (2.3057)	Prec@(1,5) (39.3%, 71.8%)	
07/04 08:54:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][400/703]	Step 18704	lr 0.1	Loss 2.3376 (2.3123)	Prec@(1,5) (39.2%, 71.6%)	
07/04 08:54:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][450/703]	Step 18754	lr 0.1	Loss 2.7163 (2.3144)	Prec@(1,5) (39.1%, 71.6%)	
07/04 08:54:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][500/703]	Step 18804	lr 0.1	Loss 2.5654 (2.3208)	Prec@(1,5) (39.0%, 71.5%)	
07/04 08:55:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][550/703]	Step 18854	lr 0.1	Loss 2.2781 (2.3138)	Prec@(1,5) (39.1%, 71.6%)	
07/04 08:55:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][600/703]	Step 18904	lr 0.1	Loss 2.7625 (2.3152)	Prec@(1,5) (39.0%, 71.5%)	
07/04 08:55:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][650/703]	Step 18954	lr 0.1	Loss 2.0319 (2.3173)	Prec@(1,5) (39.1%, 71.5%)	
07/04 08:55:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][700/703]	Step 19004	lr 0.1	Loss 2.4146 (2.3156)	Prec@(1,5) (39.1%, 71.6%)	
07/04 08:55:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [26][703/703]	Step 19007	lr 0.1	Loss 2.2556 (2.3156)	Prec@(1,5) (39.1%, 71.6%)	
07/04 08:55:13PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 26/199] Final Prec@1 39.0978%
07/04 08:55:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [26][50/79]	Step 19008	Loss 2.6573	Prec@(1,5) (34.1%, 64.8%)
07/04 08:55:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [26][78/79]	Step 19008	Loss 2.6037	Prec@(1,5) (34.9%, 65.9%)
07/04 08:55:14PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 26/199] Final Prec@1 34.8600%
07/04 08:55:14PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.6000%
07/04 08:55:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][50/703]	Step 19058	lr 0.1	Loss 2.2959 (2.3283)	Prec@(1,5) (39.0%, 70.9%)	
07/04 08:55:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][100/703]	Step 19108	lr 0.1	Loss 2.2831 (2.3014)	Prec@(1,5) (39.5%, 71.7%)	
07/04 08:55:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][150/703]	Step 19158	lr 0.1	Loss 2.1032 (2.3038)	Prec@(1,5) (39.3%, 71.5%)	
07/04 08:55:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][200/703]	Step 19208	lr 0.1	Loss 1.9728 (2.3027)	Prec@(1,5) (39.5%, 71.9%)	
07/04 08:55:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][250/703]	Step 19258	lr 0.1	Loss 2.2589 (2.3037)	Prec@(1,5) (39.6%, 71.7%)	
07/04 08:55:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][300/703]	Step 19308	lr 0.1	Loss 2.5177 (2.3066)	Prec@(1,5) (39.5%, 71.6%)	
07/04 08:55:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][350/703]	Step 19358	lr 0.1	Loss 2.6214 (2.3135)	Prec@(1,5) (39.3%, 71.5%)	
07/04 08:55:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][400/703]	Step 19408	lr 0.1	Loss 2.5146 (2.3087)	Prec@(1,5) (39.4%, 71.5%)	
07/04 08:55:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][450/703]	Step 19458	lr 0.1	Loss 2.3409 (2.3061)	Prec@(1,5) (39.3%, 71.5%)	
07/04 08:55:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][500/703]	Step 19508	lr 0.1	Loss 2.5955 (2.3082)	Prec@(1,5) (39.3%, 71.4%)	
07/04 08:55:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][550/703]	Step 19558	lr 0.1	Loss 2.6421 (2.3095)	Prec@(1,5) (39.2%, 71.5%)	
07/04 08:55:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][600/703]	Step 19608	lr 0.1	Loss 2.5647 (2.3121)	Prec@(1,5) (39.2%, 71.4%)	
07/04 08:55:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][650/703]	Step 19658	lr 0.1	Loss 2.1844 (2.3111)	Prec@(1,5) (39.2%, 71.5%)	
07/04 08:56:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][700/703]	Step 19708	lr 0.1	Loss 2.3652 (2.3096)	Prec@(1,5) (39.2%, 71.6%)	
07/04 08:56:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [27][703/703]	Step 19711	lr 0.1	Loss 2.2928 (2.3092)	Prec@(1,5) (39.2%, 71.6%)	
07/04 08:56:01PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 27/199] Final Prec@1 39.2333%
07/04 08:56:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [27][50/79]	Step 19712	Loss 2.5133	Prec@(1,5) (36.5%, 66.9%)
07/04 08:56:03PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [27][78/79]	Step 19712	Loss 2.5165	Prec@(1,5) (35.9%, 67.3%)
07/04 08:56:03PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 27/199] Final Prec@1 35.9200%
07/04 08:56:03PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.6000%
07/04 08:56:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][50/703]	Step 19762	lr 0.1	Loss 2.1112 (2.2273)	Prec@(1,5) (41.4%, 72.6%)	
07/04 08:56:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][100/703]	Step 19812	lr 0.1	Loss 2.1021 (2.2341)	Prec@(1,5) (41.1%, 72.6%)	
07/04 08:56:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][150/703]	Step 19862	lr 0.1	Loss 2.2932 (2.2305)	Prec@(1,5) (40.9%, 73.2%)	
07/04 08:56:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][200/703]	Step 19912	lr 0.1	Loss 2.4137 (2.2518)	Prec@(1,5) (40.3%, 72.9%)	
07/04 08:56:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][250/703]	Step 19962	lr 0.1	Loss 2.6299 (2.2609)	Prec@(1,5) (40.0%, 72.7%)	
07/04 08:56:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][300/703]	Step 20012	lr 0.1	Loss 2.5089 (2.2644)	Prec@(1,5) (40.0%, 72.7%)	
07/04 08:56:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][350/703]	Step 20062	lr 0.1	Loss 2.3692 (2.2698)	Prec@(1,5) (39.9%, 72.5%)	
07/04 08:56:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][400/703]	Step 20112	lr 0.1	Loss 2.1330 (2.2716)	Prec@(1,5) (39.9%, 72.4%)	
07/04 08:56:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][450/703]	Step 20162	lr 0.1	Loss 2.2787 (2.2770)	Prec@(1,5) (39.8%, 72.3%)	
07/04 08:56:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][500/703]	Step 20212	lr 0.1	Loss 2.1995 (2.2758)	Prec@(1,5) (39.9%, 72.4%)	
07/04 08:56:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][550/703]	Step 20262	lr 0.1	Loss 2.7593 (2.2777)	Prec@(1,5) (39.8%, 72.4%)	
07/04 08:56:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][600/703]	Step 20312	lr 0.1	Loss 2.3719 (2.2812)	Prec@(1,5) (39.8%, 72.2%)	
07/04 08:56:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][650/703]	Step 20362	lr 0.1	Loss 2.5631 (2.2865)	Prec@(1,5) (39.7%, 72.1%)	
07/04 08:56:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][700/703]	Step 20412	lr 0.1	Loss 2.8379 (2.2879)	Prec@(1,5) (39.7%, 72.1%)	
07/04 08:56:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [28][703/703]	Step 20415	lr 0.1	Loss 2.3391 (2.2879)	Prec@(1,5) (39.7%, 72.1%)	
07/04 08:56:50PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 28/199] Final Prec@1 39.6778%
07/04 08:56:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [28][50/79]	Step 20416	Loss 2.5809	Prec@(1,5) (34.3%, 66.2%)
07/04 08:56:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [28][78/79]	Step 20416	Loss 2.5431	Prec@(1,5) (34.9%, 66.6%)
07/04 08:56:52PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 28/199] Final Prec@1 34.9400%
07/04 08:56:52PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 36.6000%
07/04 08:56:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][50/703]	Step 20466	lr 0.1	Loss 1.9432 (2.2901)	Prec@(1,5) (40.7%, 72.6%)	
07/04 08:56:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][100/703]	Step 20516	lr 0.1	Loss 2.3616 (2.2888)	Prec@(1,5) (40.0%, 72.5%)	
07/04 08:57:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][150/703]	Step 20566	lr 0.1	Loss 2.0406 (2.2847)	Prec@(1,5) (39.8%, 72.2%)	
07/04 08:57:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][200/703]	Step 20616	lr 0.1	Loss 2.1976 (2.2763)	Prec@(1,5) (40.0%, 72.6%)	
07/04 08:57:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][250/703]	Step 20666	lr 0.1	Loss 2.6193 (2.2844)	Prec@(1,5) (40.0%, 72.5%)	
07/04 08:57:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][300/703]	Step 20716	lr 0.1	Loss 2.0694 (2.2809)	Prec@(1,5) (40.0%, 72.5%)	
07/04 08:57:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][350/703]	Step 20766	lr 0.1	Loss 2.5744 (2.2751)	Prec@(1,5) (40.0%, 72.7%)	
07/04 08:57:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][400/703]	Step 20816	lr 0.1	Loss 2.2194 (2.2728)	Prec@(1,5) (40.0%, 72.8%)	
07/04 08:57:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][450/703]	Step 20866	lr 0.1	Loss 2.5689 (2.2766)	Prec@(1,5) (39.9%, 72.7%)	
07/04 08:57:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][500/703]	Step 20916	lr 0.1	Loss 2.1125 (2.2763)	Prec@(1,5) (40.0%, 72.6%)	
07/04 08:57:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][550/703]	Step 20966	lr 0.1	Loss 2.1227 (2.2787)	Prec@(1,5) (40.0%, 72.6%)	
07/04 08:57:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][600/703]	Step 21016	lr 0.1	Loss 2.1895 (2.2811)	Prec@(1,5) (40.0%, 72.6%)	
07/04 08:57:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][650/703]	Step 21066	lr 0.1	Loss 2.1157 (2.2796)	Prec@(1,5) (40.1%, 72.5%)	
07/04 08:57:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][700/703]	Step 21116	lr 0.1	Loss 2.5562 (2.2810)	Prec@(1,5) (40.0%, 72.5%)	
07/04 08:57:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [29][703/703]	Step 21119	lr 0.1	Loss 2.2340 (2.2809)	Prec@(1,5) (40.0%, 72.4%)	
07/04 08:57:39PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 29/199] Final Prec@1 40.0067%
07/04 08:57:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [29][50/79]	Step 21120	Loss 2.4624	Prec@(1,5) (37.1%, 69.4%)
07/04 08:57:41PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [29][78/79]	Step 21120	Loss 2.4622	Prec@(1,5) (37.1%, 69.5%)
07/04 08:57:41PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 29/199] Final Prec@1 37.1200%
07/04 08:57:41PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.1200%
07/04 08:57:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][50/703]	Step 21170	lr 0.1	Loss 2.3071 (2.2221)	Prec@(1,5) (40.6%, 73.8%)	
07/04 08:57:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][100/703]	Step 21220	lr 0.1	Loss 2.1351 (2.2413)	Prec@(1,5) (40.7%, 73.2%)	
07/04 08:57:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][150/703]	Step 21270	lr 0.1	Loss 2.4075 (2.2557)	Prec@(1,5) (40.5%, 72.7%)	
07/04 08:57:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][200/703]	Step 21320	lr 0.1	Loss 2.4009 (2.2501)	Prec@(1,5) (40.6%, 72.6%)	
07/04 08:57:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][250/703]	Step 21370	lr 0.1	Loss 2.3966 (2.2535)	Prec@(1,5) (40.6%, 72.7%)	
07/04 08:58:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][300/703]	Step 21420	lr 0.1	Loss 2.2170 (2.2639)	Prec@(1,5) (40.3%, 72.6%)	
07/04 08:58:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][350/703]	Step 21470	lr 0.1	Loss 2.0228 (2.2726)	Prec@(1,5) (40.1%, 72.5%)	
07/04 08:58:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][400/703]	Step 21520	lr 0.1	Loss 2.1827 (2.2694)	Prec@(1,5) (40.2%, 72.5%)	
07/04 08:58:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][450/703]	Step 21570	lr 0.1	Loss 2.4737 (2.2706)	Prec@(1,5) (40.1%, 72.5%)	
07/04 08:58:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][500/703]	Step 21620	lr 0.1	Loss 2.3620 (2.2726)	Prec@(1,5) (40.0%, 72.4%)	
07/04 08:58:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][550/703]	Step 21670	lr 0.1	Loss 2.5854 (2.2764)	Prec@(1,5) (40.0%, 72.3%)	
07/04 08:58:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][600/703]	Step 21720	lr 0.1	Loss 2.3785 (2.2743)	Prec@(1,5) (40.1%, 72.4%)	
07/04 08:58:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][650/703]	Step 21770	lr 0.1	Loss 2.4333 (2.2769)	Prec@(1,5) (40.0%, 72.3%)	
07/04 08:58:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][700/703]	Step 21820	lr 0.1	Loss 2.2120 (2.2776)	Prec@(1,5) (40.0%, 72.3%)	
07/04 08:58:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [30][703/703]	Step 21823	lr 0.1	Loss 2.3586 (2.2776)	Prec@(1,5) (40.0%, 72.2%)	
07/04 08:58:28PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 30/199] Final Prec@1 40.0378%
07/04 08:58:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [30][50/79]	Step 21824	Loss 2.4678	Prec@(1,5) (37.0%, 67.9%)
07/04 08:58:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [30][78/79]	Step 21824	Loss 2.4660	Prec@(1,5) (36.9%, 68.0%)
07/04 08:58:29PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 30/199] Final Prec@1 36.9400%
07/04 08:58:29PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.1200%
07/04 08:58:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][50/703]	Step 21874	lr 0.1	Loss 2.1601 (2.1945)	Prec@(1,5) (42.0%, 75.0%)	
07/04 08:58:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][100/703]	Step 21924	lr 0.1	Loss 2.1566 (2.2098)	Prec@(1,5) (40.8%, 74.0%)	
07/04 08:58:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][150/703]	Step 21974	lr 0.1	Loss 2.2626 (2.2201)	Prec@(1,5) (40.6%, 73.5%)	
07/04 08:58:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][200/703]	Step 22024	lr 0.1	Loss 2.4086 (2.2382)	Prec@(1,5) (40.3%, 73.1%)	
07/04 08:58:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][250/703]	Step 22074	lr 0.1	Loss 2.1175 (2.2403)	Prec@(1,5) (40.4%, 73.0%)	
07/04 08:58:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][300/703]	Step 22124	lr 0.1	Loss 2.2207 (2.2410)	Prec@(1,5) (40.6%, 72.9%)	
07/04 08:58:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][350/703]	Step 22174	lr 0.1	Loss 2.5407 (2.2451)	Prec@(1,5) (40.6%, 72.8%)	
07/04 08:58:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][400/703]	Step 22224	lr 0.1	Loss 2.5900 (2.2523)	Prec@(1,5) (40.6%, 72.6%)	
07/04 08:59:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][450/703]	Step 22274	lr 0.1	Loss 2.3554 (2.2552)	Prec@(1,5) (40.5%, 72.6%)	
07/04 08:59:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][500/703]	Step 22324	lr 0.1	Loss 2.0439 (2.2523)	Prec@(1,5) (40.6%, 72.6%)	
07/04 08:59:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][550/703]	Step 22374	lr 0.1	Loss 2.2596 (2.2543)	Prec@(1,5) (40.6%, 72.6%)	
07/04 08:59:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][600/703]	Step 22424	lr 0.1	Loss 2.2314 (2.2549)	Prec@(1,5) (40.6%, 72.6%)	
07/04 08:59:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][650/703]	Step 22474	lr 0.1	Loss 2.3130 (2.2582)	Prec@(1,5) (40.5%, 72.7%)	
07/04 08:59:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][700/703]	Step 22524	lr 0.1	Loss 2.7051 (2.2599)	Prec@(1,5) (40.4%, 72.7%)	
07/04 08:59:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [31][703/703]	Step 22527	lr 0.1	Loss 2.0820 (2.2605)	Prec@(1,5) (40.4%, 72.7%)	
07/04 08:59:17PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 31/199] Final Prec@1 40.4444%
07/04 08:59:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [31][50/79]	Step 22528	Loss 2.6133	Prec@(1,5) (33.9%, 66.7%)
07/04 08:59:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [31][78/79]	Step 22528	Loss 2.5974	Prec@(1,5) (34.8%, 66.6%)
07/04 08:59:18PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 31/199] Final Prec@1 34.7200%
07/04 08:59:18PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.1200%
07/04 08:59:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][50/703]	Step 22578	lr 0.1	Loss 2.0642 (2.2447)	Prec@(1,5) (41.7%, 72.8%)	
07/04 08:59:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][100/703]	Step 22628	lr 0.1	Loss 2.0929 (2.2264)	Prec@(1,5) (41.3%, 73.6%)	
07/04 08:59:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][150/703]	Step 22678	lr 0.1	Loss 2.1613 (2.2175)	Prec@(1,5) (41.5%, 73.6%)	
07/04 08:59:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][200/703]	Step 22728	lr 0.1	Loss 1.8867 (2.2019)	Prec@(1,5) (41.9%, 74.1%)	
07/04 08:59:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][250/703]	Step 22778	lr 0.1	Loss 2.1840 (2.2072)	Prec@(1,5) (41.6%, 73.9%)	
07/04 08:59:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][300/703]	Step 22828	lr 0.1	Loss 2.2951 (2.2174)	Prec@(1,5) (41.4%, 73.7%)	
07/04 08:59:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][350/703]	Step 22878	lr 0.1	Loss 2.4240 (2.2169)	Prec@(1,5) (41.3%, 73.7%)	
07/04 08:59:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][400/703]	Step 22928	lr 0.1	Loss 2.1754 (2.2255)	Prec@(1,5) (41.2%, 73.6%)	
07/04 08:59:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][450/703]	Step 22978	lr 0.1	Loss 2.0449 (2.2312)	Prec@(1,5) (41.0%, 73.4%)	
07/04 08:59:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][500/703]	Step 23028	lr 0.1	Loss 2.1878 (2.2379)	Prec@(1,5) (40.9%, 73.3%)	
07/04 08:59:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][550/703]	Step 23078	lr 0.1	Loss 2.2095 (2.2452)	Prec@(1,5) (40.7%, 73.2%)	
07/04 08:59:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][600/703]	Step 23128	lr 0.1	Loss 2.2361 (2.2457)	Prec@(1,5) (40.7%, 73.1%)	
07/04 09:00:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][650/703]	Step 23178	lr 0.1	Loss 1.8540 (2.2507)	Prec@(1,5) (40.6%, 73.1%)	
07/04 09:00:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][700/703]	Step 23228	lr 0.1	Loss 2.1406 (2.2529)	Prec@(1,5) (40.5%, 73.0%)	
07/04 09:00:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [32][703/703]	Step 23231	lr 0.1	Loss 2.0206 (2.2526)	Prec@(1,5) (40.5%, 73.0%)	
07/04 09:00:04PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 32/199] Final Prec@1 40.5311%
07/04 09:00:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [32][50/79]	Step 23232	Loss 2.4854	Prec@(1,5) (36.1%, 68.9%)
07/04 09:00:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [32][78/79]	Step 23232	Loss 2.4745	Prec@(1,5) (36.3%, 68.6%)
07/04 09:00:05PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 32/199] Final Prec@1 36.3000%
07/04 09:00:06PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.1200%
07/04 09:00:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][50/703]	Step 23282	lr 0.1	Loss 1.8158 (2.2702)	Prec@(1,5) (39.7%, 72.8%)	
07/04 09:00:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][100/703]	Step 23332	lr 0.1	Loss 2.1683 (2.2239)	Prec@(1,5) (41.1%, 73.5%)	
07/04 09:00:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][150/703]	Step 23382	lr 0.1	Loss 2.7218 (2.2259)	Prec@(1,5) (41.0%, 73.5%)	
07/04 09:00:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][200/703]	Step 23432	lr 0.1	Loss 2.7220 (2.2488)	Prec@(1,5) (40.4%, 73.0%)	
07/04 09:00:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][250/703]	Step 23482	lr 0.1	Loss 2.7405 (2.2476)	Prec@(1,5) (40.5%, 73.0%)	
07/04 09:00:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][300/703]	Step 23532	lr 0.1	Loss 2.0488 (2.2483)	Prec@(1,5) (40.4%, 73.1%)	
07/04 09:00:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][350/703]	Step 23582	lr 0.1	Loss 2.2836 (2.2420)	Prec@(1,5) (40.5%, 73.3%)	
07/04 09:00:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][400/703]	Step 23632	lr 0.1	Loss 2.1664 (2.2435)	Prec@(1,5) (40.5%, 73.2%)	
07/04 09:00:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][450/703]	Step 23682	lr 0.1	Loss 2.4923 (2.2511)	Prec@(1,5) (40.5%, 72.9%)	
07/04 09:00:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][500/703]	Step 23732	lr 0.1	Loss 1.8370 (2.2482)	Prec@(1,5) (40.5%, 72.9%)	
07/04 09:00:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][550/703]	Step 23782	lr 0.1	Loss 2.3465 (2.2517)	Prec@(1,5) (40.4%, 72.8%)	
07/04 09:00:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][600/703]	Step 23832	lr 0.1	Loss 2.1175 (2.2550)	Prec@(1,5) (40.4%, 72.7%)	
07/04 09:00:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][650/703]	Step 23882	lr 0.1	Loss 2.4974 (2.2585)	Prec@(1,5) (40.4%, 72.6%)	
07/04 09:00:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][700/703]	Step 23932	lr 0.1	Loss 2.0786 (2.2577)	Prec@(1,5) (40.5%, 72.6%)	
07/04 09:00:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [33][703/703]	Step 23935	lr 0.1	Loss 2.4932 (2.2579)	Prec@(1,5) (40.4%, 72.6%)	
07/04 09:00:49PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 33/199] Final Prec@1 40.4311%
07/04 09:00:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [33][50/79]	Step 23936	Loss 2.4600	Prec@(1,5) (36.7%, 68.8%)
07/04 09:00:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [33][78/79]	Step 23936	Loss 2.4361	Prec@(1,5) (37.2%, 69.3%)
07/04 09:00:51PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 33/199] Final Prec@1 37.1600%
07/04 09:00:51PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 37.1600%
07/04 09:00:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][50/703]	Step 23986	lr 0.1	Loss 2.1747 (2.2674)	Prec@(1,5) (40.0%, 72.5%)	
07/04 09:00:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][100/703]	Step 24036	lr 0.1	Loss 2.4594 (2.2426)	Prec@(1,5) (40.4%, 73.1%)	
07/04 09:01:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][150/703]	Step 24086	lr 0.1	Loss 2.0915 (2.2191)	Prec@(1,5) (40.9%, 73.6%)	
07/04 09:01:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][200/703]	Step 24136	lr 0.1	Loss 2.3060 (2.2151)	Prec@(1,5) (41.1%, 73.7%)	
07/04 09:01:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][250/703]	Step 24186	lr 0.1	Loss 2.3419 (2.2110)	Prec@(1,5) (41.5%, 73.8%)	
07/04 09:01:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][300/703]	Step 24236	lr 0.1	Loss 2.3098 (2.2226)	Prec@(1,5) (41.3%, 73.4%)	
07/04 09:01:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][350/703]	Step 24286	lr 0.1	Loss 2.0400 (2.2142)	Prec@(1,5) (41.5%, 73.6%)	
07/04 09:01:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][400/703]	Step 24336	lr 0.1	Loss 2.8483 (2.2233)	Prec@(1,5) (41.3%, 73.4%)	
07/04 09:01:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][450/703]	Step 24386	lr 0.1	Loss 2.0556 (2.2234)	Prec@(1,5) (41.4%, 73.3%)	
07/04 09:01:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][500/703]	Step 24436	lr 0.1	Loss 2.0510 (2.2299)	Prec@(1,5) (41.2%, 73.2%)	
07/04 09:01:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][550/703]	Step 24486	lr 0.1	Loss 2.5426 (2.2271)	Prec@(1,5) (41.2%, 73.3%)	
07/04 09:01:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][600/703]	Step 24536	lr 0.1	Loss 2.2480 (2.2341)	Prec@(1,5) (41.2%, 73.1%)	
07/04 09:01:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][650/703]	Step 24586	lr 0.1	Loss 2.4409 (2.2352)	Prec@(1,5) (41.1%, 73.1%)	
07/04 09:01:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][700/703]	Step 24636	lr 0.1	Loss 2.2269 (2.2380)	Prec@(1,5) (41.0%, 73.0%)	
07/04 09:01:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [34][703/703]	Step 24639	lr 0.1	Loss 2.5208 (2.2376)	Prec@(1,5) (41.0%, 73.0%)	
07/04 09:01:38PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 34/199] Final Prec@1 41.0333%
07/04 09:01:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [34][50/79]	Step 24640	Loss 2.3493	Prec@(1,5) (40.2%, 70.6%)
07/04 09:01:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [34][78/79]	Step 24640	Loss 2.3801	Prec@(1,5) (39.4%, 69.9%)
07/04 09:01:39PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 34/199] Final Prec@1 39.4000%
07/04 09:01:40PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:01:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][50/703]	Step 24690	lr 0.1	Loss 2.3780 (2.2227)	Prec@(1,5) (41.9%, 73.2%)	
07/04 09:01:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][100/703]	Step 24740	lr 0.1	Loss 2.3882 (2.2362)	Prec@(1,5) (40.8%, 73.1%)	
07/04 09:01:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][150/703]	Step 24790	lr 0.1	Loss 2.1475 (2.2014)	Prec@(1,5) (41.5%, 73.9%)	
07/04 09:01:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][200/703]	Step 24840	lr 0.1	Loss 2.2712 (2.2035)	Prec@(1,5) (41.5%, 73.7%)	
07/04 09:01:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][250/703]	Step 24890	lr 0.1	Loss 2.2810 (2.2185)	Prec@(1,5) (41.2%, 73.3%)	
07/04 09:02:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][300/703]	Step 24940	lr 0.1	Loss 2.2743 (2.2145)	Prec@(1,5) (41.3%, 73.4%)	
07/04 09:02:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][350/703]	Step 24990	lr 0.1	Loss 1.8777 (2.2115)	Prec@(1,5) (41.3%, 73.5%)	
07/04 09:02:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][400/703]	Step 25040	lr 0.1	Loss 2.3146 (2.2231)	Prec@(1,5) (41.1%, 73.2%)	
07/04 09:02:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][450/703]	Step 25090	lr 0.1	Loss 2.4360 (2.2245)	Prec@(1,5) (41.0%, 73.1%)	
07/04 09:02:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][500/703]	Step 25140	lr 0.1	Loss 2.4285 (2.2255)	Prec@(1,5) (41.0%, 73.2%)	
07/04 09:02:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][550/703]	Step 25190	lr 0.1	Loss 2.4124 (2.2299)	Prec@(1,5) (41.0%, 73.1%)	
07/04 09:02:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][600/703]	Step 25240	lr 0.1	Loss 2.3285 (2.2337)	Prec@(1,5) (40.9%, 73.0%)	
07/04 09:02:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][650/703]	Step 25290	lr 0.1	Loss 2.3485 (2.2359)	Prec@(1,5) (40.9%, 73.0%)	
07/04 09:02:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][700/703]	Step 25340	lr 0.1	Loss 2.3030 (2.2333)	Prec@(1,5) (40.9%, 73.0%)	
07/04 09:02:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [35][703/703]	Step 25343	lr 0.1	Loss 2.4488 (2.2339)	Prec@(1,5) (40.8%, 73.0%)	
07/04 09:02:27PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 35/199] Final Prec@1 40.8333%
07/04 09:02:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [35][50/79]	Step 25344	Loss 2.5616	Prec@(1,5) (35.5%, 67.0%)
07/04 09:02:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [35][78/79]	Step 25344	Loss 2.5514	Prec@(1,5) (35.7%, 67.2%)
07/04 09:02:28PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 35/199] Final Prec@1 35.7000%
07/04 09:02:28PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:02:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][50/703]	Step 25394	lr 0.1	Loss 1.7398 (2.2388)	Prec@(1,5) (40.4%, 73.0%)	
07/04 09:02:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][100/703]	Step 25444	lr 0.1	Loss 2.5178 (2.2392)	Prec@(1,5) (39.8%, 73.0%)	
07/04 09:02:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][150/703]	Step 25494	lr 0.1	Loss 2.3076 (2.2231)	Prec@(1,5) (40.1%, 73.6%)	
07/04 09:02:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][200/703]	Step 25544	lr 0.1	Loss 2.0740 (2.2278)	Prec@(1,5) (40.3%, 73.6%)	
07/04 09:02:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][250/703]	Step 25594	lr 0.1	Loss 2.1204 (2.2214)	Prec@(1,5) (40.6%, 73.7%)	
07/04 09:02:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][300/703]	Step 25644	lr 0.1	Loss 2.0404 (2.2194)	Prec@(1,5) (40.8%, 73.7%)	
07/04 09:02:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][350/703]	Step 25694	lr 0.1	Loss 2.3009 (2.2247)	Prec@(1,5) (40.8%, 73.6%)	
07/04 09:02:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][400/703]	Step 25744	lr 0.1	Loss 2.3056 (2.2309)	Prec@(1,5) (40.6%, 73.4%)	
07/04 09:02:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][450/703]	Step 25794	lr 0.1	Loss 1.8429 (2.2337)	Prec@(1,5) (40.5%, 73.3%)	
07/04 09:03:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][500/703]	Step 25844	lr 0.1	Loss 2.2171 (2.2310)	Prec@(1,5) (40.7%, 73.3%)	
07/04 09:03:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][550/703]	Step 25894	lr 0.1	Loss 1.8450 (2.2320)	Prec@(1,5) (40.8%, 73.3%)	
07/04 09:03:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][600/703]	Step 25944	lr 0.1	Loss 2.1242 (2.2319)	Prec@(1,5) (40.7%, 73.3%)	
07/04 09:03:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][650/703]	Step 25994	lr 0.1	Loss 2.0837 (2.2327)	Prec@(1,5) (40.6%, 73.3%)	
07/04 09:03:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][700/703]	Step 26044	lr 0.1	Loss 2.1450 (2.2352)	Prec@(1,5) (40.6%, 73.3%)	
07/04 09:03:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [36][703/703]	Step 26047	lr 0.1	Loss 2.5796 (2.2364)	Prec@(1,5) (40.5%, 73.2%)	
07/04 09:03:16PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 36/199] Final Prec@1 40.5444%
07/04 09:03:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [36][50/79]	Step 26048	Loss 2.6997	Prec@(1,5) (33.0%, 63.7%)
07/04 09:03:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [36][78/79]	Step 26048	Loss 2.7118	Prec@(1,5) (33.3%, 63.9%)
07/04 09:03:18PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 36/199] Final Prec@1 33.3200%
07/04 09:03:18PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:03:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][50/703]	Step 26098	lr 0.1	Loss 1.6014 (2.1959)	Prec@(1,5) (42.0%, 74.7%)	
07/04 09:03:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][100/703]	Step 26148	lr 0.1	Loss 2.4465 (2.2182)	Prec@(1,5) (41.7%, 74.1%)	
07/04 09:03:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][150/703]	Step 26198	lr 0.1	Loss 2.1554 (2.2031)	Prec@(1,5) (41.7%, 74.4%)	
07/04 09:03:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][200/703]	Step 26248	lr 0.1	Loss 2.2351 (2.2076)	Prec@(1,5) (41.6%, 74.2%)	
07/04 09:03:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][250/703]	Step 26298	lr 0.1	Loss 2.1744 (2.2097)	Prec@(1,5) (41.5%, 73.9%)	
07/04 09:03:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][300/703]	Step 26348	lr 0.1	Loss 2.4714 (2.2201)	Prec@(1,5) (41.3%, 73.6%)	
07/04 09:03:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][350/703]	Step 26398	lr 0.1	Loss 2.6611 (2.2239)	Prec@(1,5) (41.1%, 73.4%)	
07/04 09:03:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][400/703]	Step 26448	lr 0.1	Loss 2.0033 (2.2267)	Prec@(1,5) (41.1%, 73.3%)	
07/04 09:03:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][450/703]	Step 26498	lr 0.1	Loss 1.9624 (2.2267)	Prec@(1,5) (41.1%, 73.3%)	
07/04 09:03:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][500/703]	Step 26548	lr 0.1	Loss 1.8783 (2.2214)	Prec@(1,5) (41.1%, 73.4%)	
07/04 09:03:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][550/703]	Step 26598	lr 0.1	Loss 2.5099 (2.2231)	Prec@(1,5) (41.1%, 73.3%)	
07/04 09:03:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][600/703]	Step 26648	lr 0.1	Loss 2.6152 (2.2262)	Prec@(1,5) (41.1%, 73.2%)	
07/04 09:04:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][650/703]	Step 26698	lr 0.1	Loss 2.4469 (2.2235)	Prec@(1,5) (41.2%, 73.3%)	
07/04 09:04:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][700/703]	Step 26748	lr 0.1	Loss 2.0424 (2.2245)	Prec@(1,5) (41.2%, 73.3%)	
07/04 09:04:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [37][703/703]	Step 26751	lr 0.1	Loss 2.2050 (2.2248)	Prec@(1,5) (41.2%, 73.3%)	
07/04 09:04:05PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 37/199] Final Prec@1 41.1956%
07/04 09:04:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [37][50/79]	Step 26752	Loss 2.5462	Prec@(1,5) (34.9%, 66.7%)
07/04 09:04:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [37][78/79]	Step 26752	Loss 2.5420	Prec@(1,5) (34.6%, 67.3%)
07/04 09:04:07PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 37/199] Final Prec@1 34.6200%
07/04 09:04:07PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:04:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][50/703]	Step 26802	lr 0.1	Loss 2.2512 (2.2674)	Prec@(1,5) (39.5%, 72.6%)	
07/04 09:04:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][100/703]	Step 26852	lr 0.1	Loss 2.2966 (2.2432)	Prec@(1,5) (40.7%, 72.8%)	
07/04 09:04:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][150/703]	Step 26902	lr 0.1	Loss 2.5910 (2.2369)	Prec@(1,5) (40.7%, 73.0%)	
07/04 09:04:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][200/703]	Step 26952	lr 0.1	Loss 1.9742 (2.2228)	Prec@(1,5) (41.2%, 73.4%)	
07/04 09:04:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][250/703]	Step 27002	lr 0.1	Loss 2.1910 (2.2217)	Prec@(1,5) (41.3%, 73.3%)	
07/04 09:04:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][300/703]	Step 27052	lr 0.1	Loss 2.2681 (2.2169)	Prec@(1,5) (41.4%, 73.4%)	
07/04 09:04:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][350/703]	Step 27102	lr 0.1	Loss 2.2650 (2.2138)	Prec@(1,5) (41.4%, 73.5%)	
07/04 09:04:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][400/703]	Step 27152	lr 0.1	Loss 1.8525 (2.2193)	Prec@(1,5) (41.3%, 73.4%)	
07/04 09:04:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][450/703]	Step 27202	lr 0.1	Loss 1.9826 (2.2182)	Prec@(1,5) (41.3%, 73.4%)	
07/04 09:04:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][500/703]	Step 27252	lr 0.1	Loss 2.5169 (2.2199)	Prec@(1,5) (41.3%, 73.4%)	
07/04 09:04:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][550/703]	Step 27302	lr 0.1	Loss 1.8355 (2.2175)	Prec@(1,5) (41.4%, 73.5%)	
07/04 09:04:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][600/703]	Step 27352	lr 0.1	Loss 2.1666 (2.2197)	Prec@(1,5) (41.3%, 73.5%)	
07/04 09:04:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][650/703]	Step 27402	lr 0.1	Loss 2.5523 (2.2225)	Prec@(1,5) (41.3%, 73.5%)	
07/04 09:04:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][700/703]	Step 27452	lr 0.1	Loss 2.9545 (2.2257)	Prec@(1,5) (41.2%, 73.5%)	
07/04 09:04:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [38][703/703]	Step 27455	lr 0.1	Loss 2.4638 (2.2262)	Prec@(1,5) (41.2%, 73.5%)	
07/04 09:04:52PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 38/199] Final Prec@1 41.1622%
07/04 09:04:53PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [38][50/79]	Step 27456	Loss 2.4004	Prec@(1,5) (38.2%, 69.2%)
07/04 09:04:54PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [38][78/79]	Step 27456	Loss 2.4163	Prec@(1,5) (37.8%, 69.3%)
07/04 09:04:54PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 38/199] Final Prec@1 37.8800%
07/04 09:04:54PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:04:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][50/703]	Step 27506	lr 0.1	Loss 2.6205 (2.2292)	Prec@(1,5) (40.9%, 73.2%)	
07/04 09:05:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][100/703]	Step 27556	lr 0.1	Loss 2.4113 (2.2208)	Prec@(1,5) (40.6%, 73.6%)	
07/04 09:05:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][150/703]	Step 27606	lr 0.1	Loss 2.1147 (2.2019)	Prec@(1,5) (40.7%, 74.0%)	
07/04 09:05:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][200/703]	Step 27656	lr 0.1	Loss 2.2965 (2.2027)	Prec@(1,5) (40.9%, 74.1%)	
07/04 09:05:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][250/703]	Step 27706	lr 0.1	Loss 2.2659 (2.2140)	Prec@(1,5) (40.8%, 73.7%)	
07/04 09:05:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][300/703]	Step 27756	lr 0.1	Loss 2.3031 (2.2083)	Prec@(1,5) (40.9%, 73.8%)	
07/04 09:05:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][350/703]	Step 27806	lr 0.1	Loss 2.4830 (2.2050)	Prec@(1,5) (41.1%, 73.8%)	
07/04 09:05:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][400/703]	Step 27856	lr 0.1	Loss 2.4931 (2.2128)	Prec@(1,5) (40.9%, 73.6%)	
07/04 09:05:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][450/703]	Step 27906	lr 0.1	Loss 2.1991 (2.2110)	Prec@(1,5) (40.9%, 73.7%)	
07/04 09:05:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][500/703]	Step 27956	lr 0.1	Loss 2.4930 (2.2112)	Prec@(1,5) (41.0%, 73.6%)	
07/04 09:05:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][550/703]	Step 28006	lr 0.1	Loss 2.0828 (2.2144)	Prec@(1,5) (40.9%, 73.6%)	
07/04 09:05:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][600/703]	Step 28056	lr 0.1	Loss 2.3326 (2.2160)	Prec@(1,5) (40.9%, 73.5%)	
07/04 09:05:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][650/703]	Step 28106	lr 0.1	Loss 2.0957 (2.2162)	Prec@(1,5) (41.0%, 73.5%)	
07/04 09:05:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][700/703]	Step 28156	lr 0.1	Loss 2.2790 (2.2131)	Prec@(1,5) (41.1%, 73.6%)	
07/04 09:05:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [39][703/703]	Step 28159	lr 0.1	Loss 2.6225 (2.2136)	Prec@(1,5) (41.1%, 73.6%)	
07/04 09:05:38PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 39/199] Final Prec@1 41.0622%
07/04 09:05:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [39][50/79]	Step 28160	Loss 2.4735	Prec@(1,5) (37.1%, 68.3%)
07/04 09:05:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [39][78/79]	Step 28160	Loss 2.5079	Prec@(1,5) (36.2%, 68.2%)
07/04 09:05:40PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 39/199] Final Prec@1 36.2200%
07/04 09:05:40PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:05:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][50/703]	Step 28210	lr 0.1	Loss 2.3773 (2.2406)	Prec@(1,5) (40.6%, 73.0%)	
07/04 09:05:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][100/703]	Step 28260	lr 0.1	Loss 2.3474 (2.2153)	Prec@(1,5) (41.4%, 73.5%)	
07/04 09:05:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][150/703]	Step 28310	lr 0.1	Loss 2.2442 (2.1990)	Prec@(1,5) (41.4%, 74.1%)	
07/04 09:05:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][200/703]	Step 28360	lr 0.1	Loss 2.4470 (2.1960)	Prec@(1,5) (41.6%, 73.9%)	
07/04 09:05:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][250/703]	Step 28410	lr 0.1	Loss 2.1162 (2.1926)	Prec@(1,5) (41.6%, 73.9%)	
07/04 09:06:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][300/703]	Step 28460	lr 0.1	Loss 2.4122 (2.1911)	Prec@(1,5) (41.7%, 73.9%)	
07/04 09:06:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][350/703]	Step 28510	lr 0.1	Loss 1.7796 (2.1908)	Prec@(1,5) (41.5%, 73.9%)	
07/04 09:06:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][400/703]	Step 28560	lr 0.1	Loss 2.2695 (2.1936)	Prec@(1,5) (41.6%, 73.9%)	
07/04 09:06:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][450/703]	Step 28610	lr 0.1	Loss 2.0352 (2.1958)	Prec@(1,5) (41.5%, 73.8%)	
07/04 09:06:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][500/703]	Step 28660	lr 0.1	Loss 1.9505 (2.2054)	Prec@(1,5) (41.3%, 73.6%)	
07/04 09:06:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][550/703]	Step 28710	lr 0.1	Loss 2.5164 (2.2109)	Prec@(1,5) (41.2%, 73.5%)	
07/04 09:06:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][600/703]	Step 28760	lr 0.1	Loss 2.0882 (2.2094)	Prec@(1,5) (41.2%, 73.6%)	
07/04 09:06:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][650/703]	Step 28810	lr 0.1	Loss 2.1728 (2.2132)	Prec@(1,5) (41.1%, 73.5%)	
07/04 09:06:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][700/703]	Step 28860	lr 0.1	Loss 2.2061 (2.2127)	Prec@(1,5) (41.1%, 73.4%)	
07/04 09:06:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [40][703/703]	Step 28863	lr 0.1	Loss 2.8662 (2.2136)	Prec@(1,5) (41.1%, 73.4%)	
07/04 09:06:28PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 40/199] Final Prec@1 41.0844%
07/04 09:06:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [40][50/79]	Step 28864	Loss 2.6649	Prec@(1,5) (34.5%, 64.9%)
07/04 09:06:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [40][78/79]	Step 28864	Loss 2.6353	Prec@(1,5) (34.8%, 65.5%)
07/04 09:06:29PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 40/199] Final Prec@1 34.8000%
07/04 09:06:29PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:06:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][50/703]	Step 28914	lr 0.1	Loss 2.3236 (2.2017)	Prec@(1,5) (41.2%, 73.0%)	
07/04 09:06:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][100/703]	Step 28964	lr 0.1	Loss 2.1363 (2.1689)	Prec@(1,5) (41.5%, 73.9%)	
07/04 09:06:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][150/703]	Step 29014	lr 0.1	Loss 2.2124 (2.1499)	Prec@(1,5) (41.9%, 74.5%)	
07/04 09:06:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][200/703]	Step 29064	lr 0.1	Loss 2.0390 (2.1524)	Prec@(1,5) (42.1%, 74.4%)	
07/04 09:06:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][250/703]	Step 29114	lr 0.1	Loss 2.9114 (2.1529)	Prec@(1,5) (42.2%, 74.6%)	
07/04 09:06:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][300/703]	Step 29164	lr 0.1	Loss 2.2077 (2.1636)	Prec@(1,5) (41.8%, 74.4%)	
07/04 09:06:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][350/703]	Step 29214	lr 0.1	Loss 2.1945 (2.1732)	Prec@(1,5) (41.7%, 74.2%)	
07/04 09:06:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][400/703]	Step 29264	lr 0.1	Loss 1.7137 (2.1835)	Prec@(1,5) (41.6%, 74.1%)	
07/04 09:07:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][450/703]	Step 29314	lr 0.1	Loss 2.2584 (2.1885)	Prec@(1,5) (41.5%, 74.1%)	
07/04 09:07:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][500/703]	Step 29364	lr 0.1	Loss 2.1983 (2.1888)	Prec@(1,5) (41.5%, 74.1%)	
07/04 09:07:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][550/703]	Step 29414	lr 0.1	Loss 2.4778 (2.1908)	Prec@(1,5) (41.5%, 74.1%)	
07/04 09:07:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][600/703]	Step 29464	lr 0.1	Loss 2.3630 (2.1956)	Prec@(1,5) (41.6%, 74.0%)	
07/04 09:07:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][650/703]	Step 29514	lr 0.1	Loss 1.9995 (2.1984)	Prec@(1,5) (41.5%, 73.9%)	
07/04 09:07:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][700/703]	Step 29564	lr 0.1	Loss 2.4571 (2.2037)	Prec@(1,5) (41.4%, 73.8%)	
07/04 09:07:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [41][703/703]	Step 29567	lr 0.1	Loss 1.9784 (2.2032)	Prec@(1,5) (41.4%, 73.9%)	
07/04 09:07:17PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 41/199] Final Prec@1 41.4467%
07/04 09:07:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [41][50/79]	Step 29568	Loss 2.4506	Prec@(1,5) (37.8%, 68.4%)
07/04 09:07:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [41][78/79]	Step 29568	Loss 2.4982	Prec@(1,5) (37.2%, 67.4%)
07/04 09:07:18PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 41/199] Final Prec@1 37.1200%
07/04 09:07:19PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:07:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][50/703]	Step 29618	lr 0.1	Loss 2.0684 (2.2701)	Prec@(1,5) (39.9%, 72.5%)	
07/04 09:07:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][100/703]	Step 29668	lr 0.1	Loss 1.8938 (2.1720)	Prec@(1,5) (41.9%, 74.7%)	
07/04 09:07:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][150/703]	Step 29718	lr 0.1	Loss 2.3768 (2.1805)	Prec@(1,5) (42.0%, 74.7%)	
07/04 09:07:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][200/703]	Step 29768	lr 0.1	Loss 2.3638 (2.1849)	Prec@(1,5) (42.3%, 74.4%)	
07/04 09:07:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][250/703]	Step 29818	lr 0.1	Loss 2.1184 (2.1875)	Prec@(1,5) (42.4%, 74.4%)	
07/04 09:07:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][300/703]	Step 29868	lr 0.1	Loss 1.7544 (2.1843)	Prec@(1,5) (42.3%, 74.5%)	
07/04 09:07:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][350/703]	Step 29918	lr 0.1	Loss 2.3456 (2.1846)	Prec@(1,5) (42.3%, 74.4%)	
07/04 09:07:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][400/703]	Step 29968	lr 0.1	Loss 2.2843 (2.1866)	Prec@(1,5) (42.2%, 74.3%)	
07/04 09:07:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][450/703]	Step 30018	lr 0.1	Loss 2.3479 (2.1921)	Prec@(1,5) (42.0%, 74.1%)	
07/04 09:07:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][500/703]	Step 30068	lr 0.1	Loss 2.2796 (2.1978)	Prec@(1,5) (41.9%, 74.0%)	
07/04 09:07:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][550/703]	Step 30118	lr 0.1	Loss 2.1891 (2.1964)	Prec@(1,5) (41.9%, 74.1%)	
07/04 09:07:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][600/703]	Step 30168	lr 0.1	Loss 2.0501 (2.1987)	Prec@(1,5) (41.8%, 74.1%)	
07/04 09:08:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][650/703]	Step 30218	lr 0.1	Loss 2.5534 (2.2012)	Prec@(1,5) (41.7%, 74.1%)	
07/04 09:08:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][700/703]	Step 30268	lr 0.1	Loss 2.0917 (2.2013)	Prec@(1,5) (41.7%, 74.0%)	
07/04 09:08:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [42][703/703]	Step 30271	lr 0.1	Loss 2.2994 (2.2017)	Prec@(1,5) (41.7%, 74.0%)	
07/04 09:08:05PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 42/199] Final Prec@1 41.6733%
07/04 09:08:06PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [42][50/79]	Step 30272	Loss 2.5118	Prec@(1,5) (36.6%, 67.2%)
07/04 09:08:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [42][78/79]	Step 30272	Loss 2.4878	Prec@(1,5) (37.8%, 67.8%)
07/04 09:08:07PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 42/199] Final Prec@1 37.8200%
07/04 09:08:07PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:08:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][50/703]	Step 30322	lr 0.1	Loss 2.3438 (2.1877)	Prec@(1,5) (40.8%, 74.8%)	
07/04 09:08:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][100/703]	Step 30372	lr 0.1	Loss 2.0818 (2.1471)	Prec@(1,5) (42.2%, 75.3%)	
07/04 09:08:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][150/703]	Step 30422	lr 0.1	Loss 2.8496 (2.1643)	Prec@(1,5) (42.1%, 75.1%)	
07/04 09:08:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][200/703]	Step 30472	lr 0.1	Loss 2.4301 (2.1823)	Prec@(1,5) (41.7%, 74.7%)	
07/04 09:08:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][250/703]	Step 30522	lr 0.1	Loss 2.0749 (2.1821)	Prec@(1,5) (41.7%, 74.6%)	
07/04 09:08:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][300/703]	Step 30572	lr 0.1	Loss 2.8252 (2.1766)	Prec@(1,5) (41.7%, 74.7%)	
07/04 09:08:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][350/703]	Step 30622	lr 0.1	Loss 2.0323 (2.1806)	Prec@(1,5) (41.6%, 74.5%)	
07/04 09:08:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][400/703]	Step 30672	lr 0.1	Loss 2.3354 (2.1814)	Prec@(1,5) (41.6%, 74.4%)	
07/04 09:08:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][450/703]	Step 30722	lr 0.1	Loss 1.9557 (2.1860)	Prec@(1,5) (41.6%, 74.2%)	
07/04 09:08:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][500/703]	Step 30772	lr 0.1	Loss 1.9500 (2.1875)	Prec@(1,5) (41.7%, 74.3%)	
07/04 09:08:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][550/703]	Step 30822	lr 0.1	Loss 2.2389 (2.1865)	Prec@(1,5) (41.9%, 74.3%)	
07/04 09:08:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][600/703]	Step 30872	lr 0.1	Loss 2.2718 (2.1892)	Prec@(1,5) (41.7%, 74.2%)	
07/04 09:08:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][650/703]	Step 30922	lr 0.1	Loss 2.3956 (2.1911)	Prec@(1,5) (41.7%, 74.2%)	
07/04 09:08:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][700/703]	Step 30972	lr 0.1	Loss 2.4928 (2.1924)	Prec@(1,5) (41.7%, 74.1%)	
07/04 09:08:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [43][703/703]	Step 30975	lr 0.1	Loss 2.1156 (2.1920)	Prec@(1,5) (41.7%, 74.1%)	
07/04 09:08:53PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 43/199] Final Prec@1 41.7067%
07/04 09:08:54PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [43][50/79]	Step 30976	Loss 2.4413	Prec@(1,5) (37.5%, 68.5%)
07/04 09:08:54PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [43][78/79]	Step 30976	Loss 2.4401	Prec@(1,5) (38.1%, 68.9%)
07/04 09:08:54PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 43/199] Final Prec@1 38.0800%
07/04 09:08:54PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:08:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][50/703]	Step 31026	lr 0.1	Loss 1.9670 (2.2182)	Prec@(1,5) (40.7%, 73.6%)	
07/04 09:09:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][100/703]	Step 31076	lr 0.1	Loss 2.5679 (2.1951)	Prec@(1,5) (41.6%, 74.3%)	
07/04 09:09:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][150/703]	Step 31126	lr 0.1	Loss 2.1390 (2.1751)	Prec@(1,5) (42.3%, 74.4%)	
07/04 09:09:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][200/703]	Step 31176	lr 0.1	Loss 2.2047 (2.1718)	Prec@(1,5) (42.3%, 74.5%)	
07/04 09:09:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][250/703]	Step 31226	lr 0.1	Loss 1.9930 (2.1679)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:09:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][300/703]	Step 31276	lr 0.1	Loss 2.1357 (2.1654)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:09:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][350/703]	Step 31326	lr 0.1	Loss 2.1777 (2.1688)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:09:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][400/703]	Step 31376	lr 0.1	Loss 2.2017 (2.1750)	Prec@(1,5) (42.3%, 74.4%)	
07/04 09:09:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][450/703]	Step 31426	lr 0.1	Loss 1.7683 (2.1750)	Prec@(1,5) (42.2%, 74.4%)	
07/04 09:09:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][500/703]	Step 31476	lr 0.1	Loss 2.3356 (2.1773)	Prec@(1,5) (42.1%, 74.3%)	
07/04 09:09:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][550/703]	Step 31526	lr 0.1	Loss 1.8725 (2.1838)	Prec@(1,5) (41.9%, 74.2%)	
07/04 09:09:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][600/703]	Step 31576	lr 0.1	Loss 1.9743 (2.1853)	Prec@(1,5) (41.9%, 74.2%)	
07/04 09:09:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][650/703]	Step 31626	lr 0.1	Loss 2.3102 (2.1894)	Prec@(1,5) (41.8%, 74.2%)	
07/04 09:09:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][700/703]	Step 31676	lr 0.1	Loss 1.8625 (2.1889)	Prec@(1,5) (41.8%, 74.2%)	
07/04 09:09:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [44][703/703]	Step 31679	lr 0.1	Loss 2.4464 (2.1894)	Prec@(1,5) (41.8%, 74.2%)	
07/04 09:09:42PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 44/199] Final Prec@1 41.8222%
07/04 09:09:43PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [44][50/79]	Step 31680	Loss 2.3670	Prec@(1,5) (38.7%, 70.0%)
07/04 09:09:43PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [44][78/79]	Step 31680	Loss 2.3640	Prec@(1,5) (38.8%, 70.4%)
07/04 09:09:43PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 44/199] Final Prec@1 38.8600%
07/04 09:09:44PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:09:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][50/703]	Step 31730	lr 0.1	Loss 2.1601 (2.1809)	Prec@(1,5) (43.0%, 74.4%)	
07/04 09:09:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][100/703]	Step 31780	lr 0.1	Loss 2.3820 (2.1316)	Prec@(1,5) (43.4%, 75.1%)	
07/04 09:09:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][150/703]	Step 31830	lr 0.1	Loss 2.0007 (2.1542)	Prec@(1,5) (42.8%, 74.6%)	
07/04 09:09:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][200/703]	Step 31880	lr 0.1	Loss 1.8555 (2.1495)	Prec@(1,5) (42.9%, 74.9%)	
07/04 09:10:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][250/703]	Step 31930	lr 0.1	Loss 2.4849 (2.1602)	Prec@(1,5) (42.8%, 74.8%)	
07/04 09:10:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][300/703]	Step 31980	lr 0.1	Loss 2.1650 (2.1543)	Prec@(1,5) (42.9%, 74.9%)	
07/04 09:10:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][350/703]	Step 32030	lr 0.1	Loss 1.9221 (2.1632)	Prec@(1,5) (42.6%, 74.7%)	
07/04 09:10:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][400/703]	Step 32080	lr 0.1	Loss 2.1987 (2.1674)	Prec@(1,5) (42.5%, 74.5%)	
07/04 09:10:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][450/703]	Step 32130	lr 0.1	Loss 2.4729 (2.1649)	Prec@(1,5) (42.5%, 74.6%)	
07/04 09:10:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][500/703]	Step 32180	lr 0.1	Loss 2.0925 (2.1655)	Prec@(1,5) (42.6%, 74.5%)	
07/04 09:10:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][550/703]	Step 32230	lr 0.1	Loss 2.2350 (2.1672)	Prec@(1,5) (42.5%, 74.5%)	
07/04 09:10:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][600/703]	Step 32280	lr 0.1	Loss 1.9626 (2.1724)	Prec@(1,5) (42.4%, 74.3%)	
07/04 09:10:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][650/703]	Step 32330	lr 0.1	Loss 2.0704 (2.1759)	Prec@(1,5) (42.4%, 74.3%)	
07/04 09:10:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][700/703]	Step 32380	lr 0.1	Loss 2.7160 (2.1754)	Prec@(1,5) (42.5%, 74.3%)	
07/04 09:10:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [45][703/703]	Step 32383	lr 0.1	Loss 2.2353 (2.1763)	Prec@(1,5) (42.4%, 74.3%)	
07/04 09:10:31PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 45/199] Final Prec@1 42.4267%
07/04 09:10:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [45][50/79]	Step 32384	Loss 2.5293	Prec@(1,5) (35.9%, 66.2%)
07/04 09:10:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [45][78/79]	Step 32384	Loss 2.4790	Prec@(1,5) (37.0%, 67.3%)
07/04 09:10:33PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 45/199] Final Prec@1 36.9200%
07/04 09:10:33PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:10:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][50/703]	Step 32434	lr 0.1	Loss 2.0050 (2.2503)	Prec@(1,5) (40.5%, 73.2%)	
07/04 09:10:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][100/703]	Step 32484	lr 0.1	Loss 1.9336 (2.2116)	Prec@(1,5) (41.8%, 73.6%)	
07/04 09:10:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][150/703]	Step 32534	lr 0.1	Loss 1.8040 (2.1978)	Prec@(1,5) (41.9%, 73.8%)	
07/04 09:10:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][200/703]	Step 32584	lr 0.1	Loss 2.5189 (2.1892)	Prec@(1,5) (42.1%, 74.0%)	
07/04 09:10:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][250/703]	Step 32634	lr 0.1	Loss 2.3546 (2.1919)	Prec@(1,5) (42.2%, 73.8%)	
07/04 09:10:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][300/703]	Step 32684	lr 0.1	Loss 1.8840 (2.2000)	Prec@(1,5) (42.1%, 73.7%)	
07/04 09:10:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][350/703]	Step 32734	lr 0.1	Loss 2.4283 (2.2025)	Prec@(1,5) (41.9%, 73.7%)	
07/04 09:11:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][400/703]	Step 32784	lr 0.1	Loss 2.0872 (2.2013)	Prec@(1,5) (41.9%, 73.7%)	
07/04 09:11:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][450/703]	Step 32834	lr 0.1	Loss 2.1823 (2.1980)	Prec@(1,5) (41.9%, 73.9%)	
07/04 09:11:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][500/703]	Step 32884	lr 0.1	Loss 2.1221 (2.1997)	Prec@(1,5) (41.9%, 73.7%)	
07/04 09:11:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][550/703]	Step 32934	lr 0.1	Loss 1.8259 (2.1999)	Prec@(1,5) (41.9%, 73.7%)	
07/04 09:11:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][600/703]	Step 32984	lr 0.1	Loss 2.1475 (2.1996)	Prec@(1,5) (41.9%, 73.7%)	
07/04 09:11:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][650/703]	Step 33034	lr 0.1	Loss 2.4910 (2.1992)	Prec@(1,5) (42.0%, 73.7%)	
07/04 09:11:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][700/703]	Step 33084	lr 0.1	Loss 2.0702 (2.2013)	Prec@(1,5) (42.0%, 73.7%)	
07/04 09:11:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [46][703/703]	Step 33087	lr 0.1	Loss 2.3148 (2.2015)	Prec@(1,5) (42.0%, 73.7%)	
07/04 09:11:20PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 46/199] Final Prec@1 41.9778%
07/04 09:11:21PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [46][50/79]	Step 33088	Loss 2.4485	Prec@(1,5) (37.7%, 69.2%)
07/04 09:11:22PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [46][78/79]	Step 33088	Loss 2.4235	Prec@(1,5) (38.4%, 69.4%)
07/04 09:11:22PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 46/199] Final Prec@1 38.3600%
07/04 09:11:22PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:11:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][50/703]	Step 33138	lr 0.1	Loss 2.2942 (2.2052)	Prec@(1,5) (41.4%, 73.3%)	
07/04 09:11:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][100/703]	Step 33188	lr 0.1	Loss 2.1256 (2.1688)	Prec@(1,5) (42.0%, 73.9%)	
07/04 09:11:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][150/703]	Step 33238	lr 0.1	Loss 2.6848 (2.1682)	Prec@(1,5) (42.3%, 74.3%)	
07/04 09:11:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][200/703]	Step 33288	lr 0.1	Loss 2.0214 (2.1690)	Prec@(1,5) (42.1%, 74.2%)	
07/04 09:11:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][250/703]	Step 33338	lr 0.1	Loss 1.9114 (2.1755)	Prec@(1,5) (42.0%, 74.2%)	
07/04 09:11:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][300/703]	Step 33388	lr 0.1	Loss 2.3152 (2.1706)	Prec@(1,5) (42.1%, 74.2%)	
07/04 09:11:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][350/703]	Step 33438	lr 0.1	Loss 2.1929 (2.1659)	Prec@(1,5) (42.2%, 74.4%)	
07/04 09:11:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][400/703]	Step 33488	lr 0.1	Loss 2.4445 (2.1735)	Prec@(1,5) (42.0%, 74.3%)	
07/04 09:11:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][450/703]	Step 33538	lr 0.1	Loss 2.2804 (2.1702)	Prec@(1,5) (42.0%, 74.4%)	
07/04 09:11:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][500/703]	Step 33588	lr 0.1	Loss 2.4395 (2.1709)	Prec@(1,5) (41.9%, 74.5%)	
07/04 09:11:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][550/703]	Step 33638	lr 0.1	Loss 2.3283 (2.1835)	Prec@(1,5) (41.7%, 74.2%)	
07/04 09:12:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][600/703]	Step 33688	lr 0.1	Loss 2.2412 (2.1802)	Prec@(1,5) (41.8%, 74.3%)	
07/04 09:12:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][650/703]	Step 33738	lr 0.1	Loss 2.0772 (2.1770)	Prec@(1,5) (41.9%, 74.3%)	
07/04 09:12:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][700/703]	Step 33788	lr 0.1	Loss 2.2862 (2.1821)	Prec@(1,5) (41.7%, 74.2%)	
07/04 09:12:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [47][703/703]	Step 33791	lr 0.1	Loss 2.1232 (2.1824)	Prec@(1,5) (41.7%, 74.2%)	
07/04 09:12:09PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 47/199] Final Prec@1 41.7311%
07/04 09:12:10PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [47][50/79]	Step 33792	Loss 2.3510	Prec@(1,5) (39.4%, 71.7%)
07/04 09:12:10PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [47][78/79]	Step 33792	Loss 2.3559	Prec@(1,5) (39.2%, 71.2%)
07/04 09:12:10PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 47/199] Final Prec@1 39.1400%
07/04 09:12:10PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:12:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][50/703]	Step 33842	lr 0.1	Loss 2.4210 (2.2212)	Prec@(1,5) (40.7%, 73.7%)	
07/04 09:12:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][100/703]	Step 33892	lr 0.1	Loss 1.8757 (2.1622)	Prec@(1,5) (42.0%, 74.8%)	
07/04 09:12:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][150/703]	Step 33942	lr 0.1	Loss 1.9290 (2.1647)	Prec@(1,5) (41.9%, 74.6%)	
07/04 09:12:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][200/703]	Step 33992	lr 0.1	Loss 2.3303 (2.1546)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:12:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][250/703]	Step 34042	lr 0.1	Loss 1.9672 (2.1436)	Prec@(1,5) (42.9%, 75.0%)	
07/04 09:12:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][300/703]	Step 34092	lr 0.1	Loss 1.9314 (2.1564)	Prec@(1,5) (42.6%, 74.8%)	
07/04 09:12:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][350/703]	Step 34142	lr 0.1	Loss 2.0580 (2.1578)	Prec@(1,5) (42.6%, 74.7%)	
07/04 09:12:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][400/703]	Step 34192	lr 0.1	Loss 2.1915 (2.1647)	Prec@(1,5) (42.5%, 74.6%)	
07/04 09:12:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][450/703]	Step 34242	lr 0.1	Loss 2.0482 (2.1661)	Prec@(1,5) (42.5%, 74.6%)	
07/04 09:12:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][500/703]	Step 34292	lr 0.1	Loss 2.2330 (2.1610)	Prec@(1,5) (42.6%, 74.6%)	
07/04 09:12:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][550/703]	Step 34342	lr 0.1	Loss 2.2641 (2.1690)	Prec@(1,5) (42.5%, 74.4%)	
07/04 09:12:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][600/703]	Step 34392	lr 0.1	Loss 2.4215 (2.1706)	Prec@(1,5) (42.4%, 74.4%)	
07/04 09:12:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][650/703]	Step 34442	lr 0.1	Loss 2.3353 (2.1721)	Prec@(1,5) (42.3%, 74.3%)	
07/04 09:12:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][700/703]	Step 34492	lr 0.1	Loss 1.8039 (2.1734)	Prec@(1,5) (42.3%, 74.2%)	
07/04 09:12:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [48][703/703]	Step 34495	lr 0.1	Loss 1.9436 (2.1731)	Prec@(1,5) (42.3%, 74.2%)	
07/04 09:12:58PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 48/199] Final Prec@1 42.3444%
07/04 09:12:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [48][50/79]	Step 34496	Loss 2.4271	Prec@(1,5) (37.8%, 69.7%)
07/04 09:13:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [48][78/79]	Step 34496	Loss 2.4297	Prec@(1,5) (37.9%, 69.3%)
07/04 09:13:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 48/199] Final Prec@1 37.9000%
07/04 09:13:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:13:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][50/703]	Step 34546	lr 0.1	Loss 2.4960 (2.2222)	Prec@(1,5) (41.8%, 74.0%)	
07/04 09:13:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][100/703]	Step 34596	lr 0.1	Loss 2.4672 (2.1844)	Prec@(1,5) (41.9%, 74.3%)	
07/04 09:13:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][150/703]	Step 34646	lr 0.1	Loss 2.2287 (2.1490)	Prec@(1,5) (42.9%, 74.6%)	
07/04 09:13:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][200/703]	Step 34696	lr 0.1	Loss 2.0115 (2.1517)	Prec@(1,5) (42.7%, 74.5%)	
07/04 09:13:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][250/703]	Step 34746	lr 0.1	Loss 1.9587 (2.1645)	Prec@(1,5) (42.4%, 74.4%)	
07/04 09:13:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][300/703]	Step 34796	lr 0.1	Loss 2.0449 (2.1615)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:13:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][350/703]	Step 34846	lr 0.1	Loss 2.0623 (2.1666)	Prec@(1,5) (42.3%, 74.5%)	
07/04 09:13:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][400/703]	Step 34896	lr 0.1	Loss 2.2230 (2.1714)	Prec@(1,5) (42.1%, 74.4%)	
07/04 09:13:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][450/703]	Step 34946	lr 0.1	Loss 2.1704 (2.1748)	Prec@(1,5) (42.0%, 74.4%)	
07/04 09:13:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][500/703]	Step 34996	lr 0.1	Loss 2.2481 (2.1761)	Prec@(1,5) (41.9%, 74.4%)	
07/04 09:13:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][550/703]	Step 35046	lr 0.1	Loss 2.1187 (2.1779)	Prec@(1,5) (41.8%, 74.2%)	
07/04 09:13:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][600/703]	Step 35096	lr 0.1	Loss 1.9266 (2.1716)	Prec@(1,5) (42.0%, 74.3%)	
07/04 09:13:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][650/703]	Step 35146	lr 0.1	Loss 2.3101 (2.1783)	Prec@(1,5) (41.9%, 74.2%)	
07/04 09:13:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][700/703]	Step 35196	lr 0.1	Loss 1.7634 (2.1836)	Prec@(1,5) (41.9%, 74.1%)	
07/04 09:13:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [49][703/703]	Step 35199	lr 0.1	Loss 1.9267 (2.1829)	Prec@(1,5) (41.9%, 74.1%)	
07/04 09:13:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 49/199] Final Prec@1 41.8956%
07/04 09:13:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [49][50/79]	Step 35200	Loss 2.4254	Prec@(1,5) (38.7%, 68.2%)
07/04 09:13:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [49][78/79]	Step 35200	Loss 2.4247	Prec@(1,5) (38.7%, 69.1%)
07/04 09:13:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 49/199] Final Prec@1 38.7200%
07/04 09:13:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:13:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][50/703]	Step 35250	lr 0.1	Loss 2.1879 (2.1804)	Prec@(1,5) (42.0%, 74.7%)	
07/04 09:13:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][100/703]	Step 35300	lr 0.1	Loss 2.5644 (2.1693)	Prec@(1,5) (41.8%, 74.8%)	
07/04 09:13:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][150/703]	Step 35350	lr 0.1	Loss 2.0400 (2.1684)	Prec@(1,5) (42.2%, 74.9%)	
07/04 09:14:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][200/703]	Step 35400	lr 0.1	Loss 2.3296 (2.1633)	Prec@(1,5) (42.3%, 74.7%)	
07/04 09:14:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][250/703]	Step 35450	lr 0.1	Loss 2.1357 (2.1652)	Prec@(1,5) (42.4%, 74.5%)	
07/04 09:14:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][300/703]	Step 35500	lr 0.1	Loss 2.2011 (2.1545)	Prec@(1,5) (42.7%, 74.8%)	
07/04 09:14:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][350/703]	Step 35550	lr 0.1	Loss 2.0862 (2.1611)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:14:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][400/703]	Step 35600	lr 0.1	Loss 2.2977 (2.1645)	Prec@(1,5) (42.5%, 74.7%)	
07/04 09:14:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][450/703]	Step 35650	lr 0.1	Loss 2.2358 (2.1606)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:14:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][500/703]	Step 35700	lr 0.1	Loss 2.3897 (2.1622)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:14:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][550/703]	Step 35750	lr 0.1	Loss 2.1840 (2.1633)	Prec@(1,5) (42.5%, 74.7%)	
07/04 09:14:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][600/703]	Step 35800	lr 0.1	Loss 2.2471 (2.1639)	Prec@(1,5) (42.5%, 74.7%)	
07/04 09:14:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][650/703]	Step 35850	lr 0.1	Loss 1.9835 (2.1681)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:14:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][700/703]	Step 35900	lr 0.1	Loss 2.1614 (2.1673)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:14:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [50][703/703]	Step 35903	lr 0.1	Loss 2.4043 (2.1668)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:14:36PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 50/199] Final Prec@1 42.3978%
07/04 09:14:37PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [50][50/79]	Step 35904	Loss 2.6346	Prec@(1,5) (34.9%, 66.8%)
07/04 09:14:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [50][78/79]	Step 35904	Loss 2.6209	Prec@(1,5) (35.2%, 67.1%)
07/04 09:14:38PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 50/199] Final Prec@1 35.1400%
07/04 09:14:38PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:14:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][50/703]	Step 35954	lr 0.1	Loss 2.0059 (2.2830)	Prec@(1,5) (39.1%, 72.1%)	
07/04 09:14:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][100/703]	Step 36004	lr 0.1	Loss 1.9975 (2.2094)	Prec@(1,5) (40.8%, 73.7%)	
07/04 09:14:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][150/703]	Step 36054	lr 0.1	Loss 1.9642 (2.1608)	Prec@(1,5) (42.3%, 74.7%)	
07/04 09:14:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][200/703]	Step 36104	lr 0.1	Loss 2.2465 (2.1611)	Prec@(1,5) (42.4%, 74.5%)	
07/04 09:14:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][250/703]	Step 36154	lr 0.1	Loss 2.5612 (2.1601)	Prec@(1,5) (42.0%, 74.6%)	
07/04 09:14:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][300/703]	Step 36204	lr 0.1	Loss 2.1886 (2.1665)	Prec@(1,5) (42.0%, 74.4%)	
07/04 09:15:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][350/703]	Step 36254	lr 0.1	Loss 2.2519 (2.1599)	Prec@(1,5) (42.2%, 74.5%)	
07/04 09:15:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][400/703]	Step 36304	lr 0.1	Loss 2.0567 (2.1586)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:15:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][450/703]	Step 36354	lr 0.1	Loss 2.0072 (2.1617)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:15:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][500/703]	Step 36404	lr 0.1	Loss 2.2144 (2.1628)	Prec@(1,5) (42.3%, 74.5%)	
07/04 09:15:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][550/703]	Step 36454	lr 0.1	Loss 1.9169 (2.1671)	Prec@(1,5) (42.3%, 74.5%)	
07/04 09:15:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][600/703]	Step 36504	lr 0.1	Loss 2.0505 (2.1675)	Prec@(1,5) (42.3%, 74.5%)	
07/04 09:15:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][650/703]	Step 36554	lr 0.1	Loss 2.1132 (2.1724)	Prec@(1,5) (42.1%, 74.4%)	
07/04 09:15:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][700/703]	Step 36604	lr 0.1	Loss 2.4561 (2.1782)	Prec@(1,5) (42.0%, 74.3%)	
07/04 09:15:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [51][703/703]	Step 36607	lr 0.1	Loss 1.9893 (2.1782)	Prec@(1,5) (42.0%, 74.3%)	
07/04 09:15:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 51/199] Final Prec@1 41.9800%
07/04 09:15:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [51][50/79]	Step 36608	Loss 2.4463	Prec@(1,5) (37.2%, 70.0%)
07/04 09:15:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [51][78/79]	Step 36608	Loss 2.4600	Prec@(1,5) (37.0%, 69.3%)
07/04 09:15:26PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 51/199] Final Prec@1 36.9800%
07/04 09:15:26PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:15:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][50/703]	Step 36658	lr 0.1	Loss 2.0812 (2.1168)	Prec@(1,5) (43.7%, 74.7%)	
07/04 09:15:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][100/703]	Step 36708	lr 0.1	Loss 2.0035 (2.1025)	Prec@(1,5) (43.5%, 75.5%)	
07/04 09:15:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][150/703]	Step 36758	lr 0.1	Loss 2.0518 (2.1138)	Prec@(1,5) (43.4%, 75.3%)	
07/04 09:15:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][200/703]	Step 36808	lr 0.1	Loss 2.4853 (2.1221)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:15:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][250/703]	Step 36858	lr 0.1	Loss 2.1867 (2.1253)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:15:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][300/703]	Step 36908	lr 0.1	Loss 2.2935 (2.1277)	Prec@(1,5) (43.0%, 75.4%)	
07/04 09:15:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][350/703]	Step 36958	lr 0.1	Loss 2.1197 (2.1354)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:15:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][400/703]	Step 37008	lr 0.1	Loss 2.4161 (2.1364)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:15:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][450/703]	Step 37058	lr 0.1	Loss 2.2840 (2.1452)	Prec@(1,5) (42.6%, 75.0%)	
07/04 09:16:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][500/703]	Step 37108	lr 0.1	Loss 2.0246 (2.1498)	Prec@(1,5) (42.5%, 74.9%)	
07/04 09:16:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][550/703]	Step 37158	lr 0.1	Loss 2.3793 (2.1525)	Prec@(1,5) (42.5%, 74.9%)	
07/04 09:16:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][600/703]	Step 37208	lr 0.1	Loss 1.7292 (2.1530)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:16:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][650/703]	Step 37258	lr 0.1	Loss 2.4997 (2.1578)	Prec@(1,5) (42.4%, 74.7%)	
07/04 09:16:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][700/703]	Step 37308	lr 0.1	Loss 2.2367 (2.1616)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:16:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [52][703/703]	Step 37311	lr 0.1	Loss 2.1887 (2.1612)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:16:13PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 52/199] Final Prec@1 42.2867%
07/04 09:16:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [52][50/79]	Step 37312	Loss 2.3616	Prec@(1,5) (38.7%, 71.0%)
07/04 09:16:15PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [52][78/79]	Step 37312	Loss 2.3390	Prec@(1,5) (39.2%, 71.2%)
07/04 09:16:15PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 52/199] Final Prec@1 39.1600%
07/04 09:16:15PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.4000%
07/04 09:16:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][50/703]	Step 37362	lr 0.1	Loss 1.9683 (2.0593)	Prec@(1,5) (44.1%, 76.8%)	
07/04 09:16:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][100/703]	Step 37412	lr 0.1	Loss 2.1779 (2.0831)	Prec@(1,5) (43.2%, 76.5%)	
07/04 09:16:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][150/703]	Step 37462	lr 0.1	Loss 2.0382 (2.1088)	Prec@(1,5) (42.7%, 76.2%)	
07/04 09:16:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][200/703]	Step 37512	lr 0.1	Loss 2.3156 (2.1283)	Prec@(1,5) (42.5%, 75.8%)	
07/04 09:16:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][250/703]	Step 37562	lr 0.1	Loss 2.4228 (2.1448)	Prec@(1,5) (42.3%, 75.2%)	
07/04 09:16:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][300/703]	Step 37612	lr 0.1	Loss 2.0856 (2.1406)	Prec@(1,5) (42.6%, 75.1%)	
07/04 09:16:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][350/703]	Step 37662	lr 0.1	Loss 1.9960 (2.1497)	Prec@(1,5) (42.3%, 75.1%)	
07/04 09:16:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][400/703]	Step 37712	lr 0.1	Loss 2.4251 (2.1487)	Prec@(1,5) (42.4%, 75.2%)	
07/04 09:16:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][450/703]	Step 37762	lr 0.1	Loss 2.0908 (2.1499)	Prec@(1,5) (42.4%, 75.1%)	
07/04 09:16:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][500/703]	Step 37812	lr 0.1	Loss 2.3786 (2.1470)	Prec@(1,5) (42.5%, 75.1%)	
07/04 09:16:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][550/703]	Step 37862	lr 0.1	Loss 2.0968 (2.1522)	Prec@(1,5) (42.5%, 75.0%)	
07/04 09:16:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][600/703]	Step 37912	lr 0.1	Loss 2.2878 (2.1583)	Prec@(1,5) (42.4%, 74.8%)	
07/04 09:16:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][650/703]	Step 37962	lr 0.1	Loss 2.2465 (2.1559)	Prec@(1,5) (42.5%, 74.9%)	
07/04 09:17:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][700/703]	Step 38012	lr 0.1	Loss 2.1339 (2.1590)	Prec@(1,5) (42.4%, 74.8%)	
07/04 09:17:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [53][703/703]	Step 38015	lr 0.1	Loss 2.3899 (2.1590)	Prec@(1,5) (42.4%, 74.8%)	
07/04 09:17:02PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 53/199] Final Prec@1 42.3778%
07/04 09:17:03PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [53][50/79]	Step 38016	Loss 2.3361	Prec@(1,5) (39.6%, 71.9%)
07/04 09:17:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [53][78/79]	Step 38016	Loss 2.3371	Prec@(1,5) (39.6%, 71.8%)
07/04 09:17:04PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 53/199] Final Prec@1 39.5600%
07/04 09:17:04PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:17:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][50/703]	Step 38066	lr 0.1	Loss 1.9862 (2.1751)	Prec@(1,5) (41.2%, 74.7%)	
07/04 09:17:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][100/703]	Step 38116	lr 0.1	Loss 1.9065 (2.1534)	Prec@(1,5) (42.1%, 75.4%)	
07/04 09:17:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][150/703]	Step 38166	lr 0.1	Loss 2.3428 (2.1371)	Prec@(1,5) (42.8%, 75.4%)	
07/04 09:17:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][200/703]	Step 38216	lr 0.1	Loss 2.4744 (2.1464)	Prec@(1,5) (42.8%, 74.9%)	
07/04 09:17:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][250/703]	Step 38266	lr 0.1	Loss 2.3109 (2.1506)	Prec@(1,5) (42.6%, 74.8%)	
07/04 09:17:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][300/703]	Step 38316	lr 0.1	Loss 2.5431 (2.1434)	Prec@(1,5) (42.6%, 75.1%)	
07/04 09:17:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][350/703]	Step 38366	lr 0.1	Loss 2.4201 (2.1534)	Prec@(1,5) (42.3%, 75.0%)	
07/04 09:17:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][400/703]	Step 38416	lr 0.1	Loss 1.8360 (2.1525)	Prec@(1,5) (42.2%, 75.0%)	
07/04 09:17:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][450/703]	Step 38466	lr 0.1	Loss 1.9791 (2.1564)	Prec@(1,5) (42.2%, 74.9%)	
07/04 09:17:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][500/703]	Step 38516	lr 0.1	Loss 2.4352 (2.1570)	Prec@(1,5) (42.2%, 74.8%)	
07/04 09:17:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][550/703]	Step 38566	lr 0.1	Loss 2.0815 (2.1599)	Prec@(1,5) (42.2%, 74.8%)	
07/04 09:17:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][600/703]	Step 38616	lr 0.1	Loss 2.1176 (2.1581)	Prec@(1,5) (42.2%, 74.8%)	
07/04 09:17:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][650/703]	Step 38666	lr 0.1	Loss 2.2015 (2.1604)	Prec@(1,5) (42.2%, 74.8%)	
07/04 09:17:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][700/703]	Step 38716	lr 0.1	Loss 2.2028 (2.1618)	Prec@(1,5) (42.3%, 74.7%)	
07/04 09:17:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [54][703/703]	Step 38719	lr 0.1	Loss 1.9046 (2.1613)	Prec@(1,5) (42.3%, 74.7%)	
07/04 09:17:51PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 54/199] Final Prec@1 42.2667%
07/04 09:17:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [54][50/79]	Step 38720	Loss 2.5145	Prec@(1,5) (35.3%, 69.1%)
07/04 09:17:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [54][78/79]	Step 38720	Loss 2.5175	Prec@(1,5) (36.1%, 69.3%)
07/04 09:17:53PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 54/199] Final Prec@1 36.1000%
07/04 09:17:53PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:17:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][50/703]	Step 38770	lr 0.1	Loss 2.2013 (2.1883)	Prec@(1,5) (42.1%, 75.2%)	
07/04 09:17:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][100/703]	Step 38820	lr 0.1	Loss 2.1107 (2.1783)	Prec@(1,5) (42.2%, 75.1%)	
07/04 09:18:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][150/703]	Step 38870	lr 0.1	Loss 2.0812 (2.1805)	Prec@(1,5) (42.0%, 74.5%)	
07/04 09:18:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][200/703]	Step 38920	lr 0.1	Loss 2.2595 (2.1702)	Prec@(1,5) (42.2%, 74.9%)	
07/04 09:18:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][250/703]	Step 38970	lr 0.1	Loss 2.1386 (2.1666)	Prec@(1,5) (42.3%, 74.8%)	
07/04 09:18:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][300/703]	Step 39020	lr 0.1	Loss 2.2522 (2.1666)	Prec@(1,5) (42.1%, 74.9%)	
07/04 09:18:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][350/703]	Step 39070	lr 0.1	Loss 2.1632 (2.1644)	Prec@(1,5) (42.4%, 74.8%)	
07/04 09:18:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][400/703]	Step 39120	lr 0.1	Loss 2.1454 (2.1690)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:18:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][450/703]	Step 39170	lr 0.1	Loss 2.1087 (2.1674)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:18:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][500/703]	Step 39220	lr 0.1	Loss 2.0557 (2.1674)	Prec@(1,5) (42.4%, 74.6%)	
07/04 09:18:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][550/703]	Step 39270	lr 0.1	Loss 2.3688 (2.1701)	Prec@(1,5) (42.3%, 74.7%)	
07/04 09:18:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][600/703]	Step 39320	lr 0.1	Loss 2.2732 (2.1672)	Prec@(1,5) (42.4%, 74.7%)	
07/04 09:18:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][650/703]	Step 39370	lr 0.1	Loss 2.2297 (2.1699)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:18:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][700/703]	Step 39420	lr 0.1	Loss 1.9573 (2.1688)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:18:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [55][703/703]	Step 39423	lr 0.1	Loss 2.0359 (2.1697)	Prec@(1,5) (42.3%, 74.6%)	
07/04 09:18:38PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 55/199] Final Prec@1 42.2667%
07/04 09:18:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [55][50/79]	Step 39424	Loss 2.4560	Prec@(1,5) (38.0%, 68.0%)
07/04 09:18:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [55][78/79]	Step 39424	Loss 2.4484	Prec@(1,5) (38.4%, 68.6%)
07/04 09:18:40PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 55/199] Final Prec@1 38.3600%
07/04 09:18:40PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:18:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][50/703]	Step 39474	lr 0.1	Loss 2.4145 (2.1779)	Prec@(1,5) (42.7%, 74.4%)	
07/04 09:18:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][100/703]	Step 39524	lr 0.1	Loss 1.9998 (2.1353)	Prec@(1,5) (43.4%, 74.6%)	
07/04 09:18:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][150/703]	Step 39574	lr 0.1	Loss 2.6817 (2.1351)	Prec@(1,5) (43.3%, 75.0%)	
07/04 09:18:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][200/703]	Step 39624	lr 0.1	Loss 2.4066 (2.1423)	Prec@(1,5) (43.0%, 74.9%)	
07/04 09:18:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][250/703]	Step 39674	lr 0.1	Loss 2.5406 (2.1368)	Prec@(1,5) (43.1%, 75.1%)	
07/04 09:19:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][300/703]	Step 39724	lr 0.1	Loss 1.7479 (2.1342)	Prec@(1,5) (43.4%, 75.0%)	
07/04 09:19:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][350/703]	Step 39774	lr 0.1	Loss 2.2901 (2.1396)	Prec@(1,5) (43.2%, 75.0%)	
07/04 09:19:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][400/703]	Step 39824	lr 0.1	Loss 1.9141 (2.1445)	Prec@(1,5) (43.2%, 74.8%)	
07/04 09:19:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][450/703]	Step 39874	lr 0.1	Loss 2.6170 (2.1514)	Prec@(1,5) (43.0%, 74.7%)	
07/04 09:19:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][500/703]	Step 39924	lr 0.1	Loss 2.3194 (2.1589)	Prec@(1,5) (42.8%, 74.6%)	
07/04 09:19:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][550/703]	Step 39974	lr 0.1	Loss 2.4720 (2.1650)	Prec@(1,5) (42.6%, 74.5%)	
07/04 09:19:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][600/703]	Step 40024	lr 0.1	Loss 1.9848 (2.1645)	Prec@(1,5) (42.6%, 74.6%)	
07/04 09:19:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][650/703]	Step 40074	lr 0.1	Loss 2.3327 (2.1647)	Prec@(1,5) (42.6%, 74.6%)	
07/04 09:19:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][700/703]	Step 40124	lr 0.1	Loss 2.3778 (2.1663)	Prec@(1,5) (42.6%, 74.5%)	
07/04 09:19:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [56][703/703]	Step 40127	lr 0.1	Loss 2.2251 (2.1660)	Prec@(1,5) (42.6%, 74.5%)	
07/04 09:19:27PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 56/199] Final Prec@1 42.6222%
07/04 09:19:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [56][50/79]	Step 40128	Loss 2.4660	Prec@(1,5) (37.2%, 68.5%)
07/04 09:19:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [56][78/79]	Step 40128	Loss 2.4709	Prec@(1,5) (37.2%, 68.3%)
07/04 09:19:28PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 56/199] Final Prec@1 37.1600%
07/04 09:19:28PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:19:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][50/703]	Step 40178	lr 0.1	Loss 2.3449 (2.1911)	Prec@(1,5) (42.4%, 73.8%)	
07/04 09:19:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][100/703]	Step 40228	lr 0.1	Loss 2.1399 (2.1444)	Prec@(1,5) (43.3%, 75.0%)	
07/04 09:19:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][150/703]	Step 40278	lr 0.1	Loss 2.0838 (2.1463)	Prec@(1,5) (43.4%, 74.7%)	
07/04 09:19:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][200/703]	Step 40328	lr 0.1	Loss 1.9865 (2.1343)	Prec@(1,5) (43.4%, 75.3%)	
07/04 09:19:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][250/703]	Step 40378	lr 0.1	Loss 2.0917 (2.1304)	Prec@(1,5) (43.6%, 75.5%)	
07/04 09:19:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][300/703]	Step 40428	lr 0.1	Loss 2.3331 (2.1398)	Prec@(1,5) (43.4%, 75.1%)	
07/04 09:19:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][350/703]	Step 40478	lr 0.1	Loss 1.9078 (2.1427)	Prec@(1,5) (43.2%, 75.1%)	
07/04 09:19:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][400/703]	Step 40528	lr 0.1	Loss 1.9149 (2.1466)	Prec@(1,5) (43.0%, 75.0%)	
07/04 09:19:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][450/703]	Step 40578	lr 0.1	Loss 2.0716 (2.1486)	Prec@(1,5) (43.0%, 74.9%)	
07/04 09:20:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][500/703]	Step 40628	lr 0.1	Loss 1.7107 (2.1486)	Prec@(1,5) (43.0%, 74.9%)	
07/04 09:20:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][550/703]	Step 40678	lr 0.1	Loss 2.2007 (2.1522)	Prec@(1,5) (42.9%, 74.9%)	
07/04 09:20:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][600/703]	Step 40728	lr 0.1	Loss 2.1020 (2.1556)	Prec@(1,5) (42.8%, 74.7%)	
07/04 09:20:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][650/703]	Step 40778	lr 0.1	Loss 2.0713 (2.1579)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:20:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][700/703]	Step 40828	lr 0.1	Loss 2.2749 (2.1591)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:20:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [57][703/703]	Step 40831	lr 0.1	Loss 2.2920 (2.1586)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:20:13PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 57/199] Final Prec@1 42.7089%
07/04 09:20:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [57][50/79]	Step 40832	Loss 2.3524	Prec@(1,5) (38.8%, 71.0%)
07/04 09:20:15PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [57][78/79]	Step 40832	Loss 2.3719	Prec@(1,5) (39.1%, 71.1%)
07/04 09:20:15PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 57/199] Final Prec@1 39.0800%
07/04 09:20:15PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:20:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][50/703]	Step 40882	lr 0.1	Loss 2.1677 (2.1313)	Prec@(1,5) (42.7%, 75.3%)	
07/04 09:20:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][100/703]	Step 40932	lr 0.1	Loss 2.1196 (2.1222)	Prec@(1,5) (42.5%, 75.8%)	
07/04 09:20:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][150/703]	Step 40982	lr 0.1	Loss 1.9494 (2.1202)	Prec@(1,5) (43.1%, 75.9%)	
07/04 09:20:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][200/703]	Step 41032	lr 0.1	Loss 2.1757 (2.1371)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:20:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][250/703]	Step 41082	lr 0.1	Loss 2.2218 (2.1343)	Prec@(1,5) (42.8%, 75.4%)	
07/04 09:20:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][300/703]	Step 41132	lr 0.1	Loss 1.9886 (2.1345)	Prec@(1,5) (42.9%, 75.2%)	
07/04 09:20:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][350/703]	Step 41182	lr 0.1	Loss 2.5035 (2.1272)	Prec@(1,5) (43.0%, 75.4%)	
07/04 09:20:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][400/703]	Step 41232	lr 0.1	Loss 2.2213 (2.1284)	Prec@(1,5) (43.0%, 75.4%)	
07/04 09:20:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][450/703]	Step 41282	lr 0.1	Loss 1.7911 (2.1325)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:20:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][500/703]	Step 41332	lr 0.1	Loss 1.9642 (2.1401)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:20:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][550/703]	Step 41382	lr 0.1	Loss 2.1006 (2.1415)	Prec@(1,5) (42.9%, 75.1%)	
07/04 09:20:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][600/703]	Step 41432	lr 0.1	Loss 2.0683 (2.1424)	Prec@(1,5) (42.9%, 75.0%)	
07/04 09:20:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][650/703]	Step 41482	lr 0.1	Loss 1.9232 (2.1461)	Prec@(1,5) (42.8%, 74.9%)	
07/04 09:21:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][700/703]	Step 41532	lr 0.1	Loss 2.3159 (2.1473)	Prec@(1,5) (42.8%, 74.9%)	
07/04 09:21:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [58][703/703]	Step 41535	lr 0.1	Loss 2.2649 (2.1483)	Prec@(1,5) (42.8%, 74.9%)	
07/04 09:21:02PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 58/199] Final Prec@1 42.8089%
07/04 09:21:03PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [58][50/79]	Step 41536	Loss 2.4272	Prec@(1,5) (38.7%, 69.2%)
07/04 09:21:03PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [58][78/79]	Step 41536	Loss 2.4459	Prec@(1,5) (37.5%, 69.3%)
07/04 09:21:03PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 58/199] Final Prec@1 37.5200%
07/04 09:21:04PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:21:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][50/703]	Step 41586	lr 0.1	Loss 2.0460 (2.1524)	Prec@(1,5) (43.5%, 74.4%)	
07/04 09:21:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][100/703]	Step 41636	lr 0.1	Loss 1.7649 (2.1309)	Prec@(1,5) (43.5%, 74.6%)	
07/04 09:21:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][150/703]	Step 41686	lr 0.1	Loss 2.5030 (2.1379)	Prec@(1,5) (43.1%, 74.8%)	
07/04 09:21:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][200/703]	Step 41736	lr 0.1	Loss 2.0060 (2.1558)	Prec@(1,5) (43.0%, 74.5%)	
07/04 09:21:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][250/703]	Step 41786	lr 0.1	Loss 2.3809 (2.1591)	Prec@(1,5) (42.8%, 74.5%)	
07/04 09:21:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][300/703]	Step 41836	lr 0.1	Loss 2.2144 (2.1544)	Prec@(1,5) (42.9%, 74.6%)	
07/04 09:21:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][350/703]	Step 41886	lr 0.1	Loss 2.2543 (2.1557)	Prec@(1,5) (42.9%, 74.5%)	
07/04 09:21:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][400/703]	Step 41936	lr 0.1	Loss 2.0058 (2.1579)	Prec@(1,5) (42.9%, 74.5%)	
07/04 09:21:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][450/703]	Step 41986	lr 0.1	Loss 2.1284 (2.1536)	Prec@(1,5) (42.9%, 74.7%)	
07/04 09:21:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][500/703]	Step 42036	lr 0.1	Loss 2.0889 (2.1580)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:21:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][550/703]	Step 42086	lr 0.1	Loss 2.3501 (2.1567)	Prec@(1,5) (42.8%, 74.6%)	
07/04 09:21:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][600/703]	Step 42136	lr 0.1	Loss 1.5716 (2.1555)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:21:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][650/703]	Step 42186	lr 0.1	Loss 2.1460 (2.1587)	Prec@(1,5) (42.7%, 74.5%)	
07/04 09:21:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][700/703]	Step 42236	lr 0.1	Loss 1.8291 (2.1547)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:21:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [59][703/703]	Step 42239	lr 0.1	Loss 2.4116 (2.1550)	Prec@(1,5) (42.8%, 74.6%)	
07/04 09:21:50PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 59/199] Final Prec@1 42.7511%
07/04 09:21:51PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [59][50/79]	Step 42240	Loss 2.4943	Prec@(1,5) (38.9%, 68.1%)
07/04 09:21:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [59][78/79]	Step 42240	Loss 2.4954	Prec@(1,5) (38.5%, 68.1%)
07/04 09:21:52PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 59/199] Final Prec@1 38.5200%
07/04 09:21:52PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:21:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][50/703]	Step 42290	lr 0.1	Loss 2.1876 (2.1945)	Prec@(1,5) (42.0%, 74.3%)	
07/04 09:21:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][100/703]	Step 42340	lr 0.1	Loss 2.0429 (2.1865)	Prec@(1,5) (41.8%, 74.0%)	
07/04 09:22:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][150/703]	Step 42390	lr 0.1	Loss 2.3083 (2.1665)	Prec@(1,5) (42.2%, 75.0%)	
07/04 09:22:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][200/703]	Step 42440	lr 0.1	Loss 2.1050 (2.1503)	Prec@(1,5) (42.8%, 75.1%)	
07/04 09:22:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][250/703]	Step 42490	lr 0.1	Loss 2.1527 (2.1409)	Prec@(1,5) (43.0%, 75.1%)	
07/04 09:22:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][300/703]	Step 42540	lr 0.1	Loss 2.4523 (2.1512)	Prec@(1,5) (42.8%, 74.7%)	
07/04 09:22:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][350/703]	Step 42590	lr 0.1	Loss 2.0412 (2.1476)	Prec@(1,5) (43.0%, 74.9%)	
07/04 09:22:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][400/703]	Step 42640	lr 0.1	Loss 2.1115 (2.1462)	Prec@(1,5) (43.0%, 74.9%)	
07/04 09:22:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][450/703]	Step 42690	lr 0.1	Loss 2.1099 (2.1498)	Prec@(1,5) (42.9%, 74.8%)	
07/04 09:22:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][500/703]	Step 42740	lr 0.1	Loss 2.6382 (2.1531)	Prec@(1,5) (42.8%, 74.7%)	
07/04 09:22:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][550/703]	Step 42790	lr 0.1	Loss 1.9400 (2.1549)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:22:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][600/703]	Step 42840	lr 0.1	Loss 2.3984 (2.1542)	Prec@(1,5) (42.8%, 74.7%)	
07/04 09:22:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][650/703]	Step 42890	lr 0.1	Loss 2.1333 (2.1587)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:22:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][700/703]	Step 42940	lr 0.1	Loss 2.2111 (2.1581)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:22:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [60][703/703]	Step 42943	lr 0.1	Loss 2.1651 (2.1579)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:22:37PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 60/199] Final Prec@1 42.6800%
07/04 09:22:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [60][50/79]	Step 42944	Loss 2.3920	Prec@(1,5) (38.5%, 70.2%)
07/04 09:22:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [60][78/79]	Step 42944	Loss 2.3625	Prec@(1,5) (39.3%, 71.0%)
07/04 09:22:39PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 60/199] Final Prec@1 39.3200%
07/04 09:22:39PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:22:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][50/703]	Step 42994	lr 0.1	Loss 2.2755 (2.2258)	Prec@(1,5) (41.4%, 73.5%)	
07/04 09:22:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][100/703]	Step 43044	lr 0.1	Loss 2.1502 (2.1785)	Prec@(1,5) (42.1%, 74.5%)	
07/04 09:22:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][150/703]	Step 43094	lr 0.1	Loss 2.2061 (2.1649)	Prec@(1,5) (42.6%, 74.8%)	
07/04 09:22:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][200/703]	Step 43144	lr 0.1	Loss 2.5600 (2.1600)	Prec@(1,5) (42.5%, 74.9%)	
07/04 09:22:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][250/703]	Step 43194	lr 0.1	Loss 2.1432 (2.1484)	Prec@(1,5) (42.8%, 75.1%)	
07/04 09:22:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][300/703]	Step 43244	lr 0.1	Loss 2.1209 (2.1529)	Prec@(1,5) (42.8%, 74.9%)	
07/04 09:23:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][350/703]	Step 43294	lr 0.1	Loss 1.9535 (2.1466)	Prec@(1,5) (42.9%, 74.9%)	
07/04 09:23:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][400/703]	Step 43344	lr 0.1	Loss 2.3862 (2.1470)	Prec@(1,5) (42.9%, 74.9%)	
07/04 09:23:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][450/703]	Step 43394	lr 0.1	Loss 1.9404 (2.1450)	Prec@(1,5) (42.7%, 75.1%)	
07/04 09:23:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][500/703]	Step 43444	lr 0.1	Loss 2.9018 (2.1497)	Prec@(1,5) (42.7%, 75.0%)	
07/04 09:23:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][550/703]	Step 43494	lr 0.1	Loss 1.9474 (2.1491)	Prec@(1,5) (42.7%, 75.0%)	
07/04 09:23:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][600/703]	Step 43544	lr 0.1	Loss 1.9269 (2.1558)	Prec@(1,5) (42.5%, 74.9%)	
07/04 09:23:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][650/703]	Step 43594	lr 0.1	Loss 1.9136 (2.1592)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:23:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][700/703]	Step 43644	lr 0.1	Loss 2.1427 (2.1595)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:23:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [61][703/703]	Step 43647	lr 0.1	Loss 2.1106 (2.1597)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:23:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 61/199] Final Prec@1 42.4667%
07/04 09:23:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [61][50/79]	Step 43648	Loss 2.3922	Prec@(1,5) (39.7%, 69.6%)
07/04 09:23:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [61][78/79]	Step 43648	Loss 2.4056	Prec@(1,5) (38.9%, 69.6%)
07/04 09:23:27PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 61/199] Final Prec@1 38.9200%
07/04 09:23:27PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:23:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][50/703]	Step 43698	lr 0.1	Loss 2.0464 (2.1251)	Prec@(1,5) (43.4%, 74.1%)	
07/04 09:23:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][100/703]	Step 43748	lr 0.1	Loss 2.4240 (2.1586)	Prec@(1,5) (42.9%, 73.7%)	
07/04 09:23:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][150/703]	Step 43798	lr 0.1	Loss 1.9772 (2.1455)	Prec@(1,5) (42.6%, 74.7%)	
07/04 09:23:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][200/703]	Step 43848	lr 0.1	Loss 1.9085 (2.1448)	Prec@(1,5) (42.9%, 74.7%)	
07/04 09:23:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][250/703]	Step 43898	lr 0.1	Loss 1.8703 (2.1472)	Prec@(1,5) (42.8%, 74.8%)	
07/04 09:23:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][300/703]	Step 43948	lr 0.1	Loss 1.6328 (2.1446)	Prec@(1,5) (42.8%, 74.7%)	
07/04 09:23:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][350/703]	Step 43998	lr 0.1	Loss 2.2575 (2.1485)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:23:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][400/703]	Step 44048	lr 0.1	Loss 2.1706 (2.1514)	Prec@(1,5) (42.7%, 74.6%)	
07/04 09:23:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][450/703]	Step 44098	lr 0.1	Loss 2.1696 (2.1513)	Prec@(1,5) (42.7%, 74.7%)	
07/04 09:24:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][500/703]	Step 44148	lr 0.1	Loss 2.1373 (2.1564)	Prec@(1,5) (42.7%, 74.5%)	
07/04 09:24:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][550/703]	Step 44198	lr 0.1	Loss 2.2938 (2.1481)	Prec@(1,5) (42.8%, 74.8%)	
07/04 09:24:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][600/703]	Step 44248	lr 0.1	Loss 2.1551 (2.1470)	Prec@(1,5) (42.9%, 74.8%)	
07/04 09:24:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][650/703]	Step 44298	lr 0.1	Loss 1.8866 (2.1437)	Prec@(1,5) (43.0%, 74.8%)	
07/04 09:24:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][700/703]	Step 44348	lr 0.1	Loss 2.2049 (2.1478)	Prec@(1,5) (42.9%, 74.8%)	
07/04 09:24:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [62][703/703]	Step 44351	lr 0.1	Loss 2.0910 (2.1475)	Prec@(1,5) (42.9%, 74.8%)	
07/04 09:24:13PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 62/199] Final Prec@1 42.9178%
07/04 09:24:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [62][50/79]	Step 44352	Loss 2.4007	Prec@(1,5) (38.4%, 70.1%)
07/04 09:24:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [62][78/79]	Step 44352	Loss 2.3773	Prec@(1,5) (39.0%, 70.6%)
07/04 09:24:14PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 62/199] Final Prec@1 39.0400%
07/04 09:24:14PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:24:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][50/703]	Step 44402	lr 0.1	Loss 2.1189 (2.1101)	Prec@(1,5) (44.8%, 75.6%)	
07/04 09:24:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][100/703]	Step 44452	lr 0.1	Loss 1.5641 (2.1101)	Prec@(1,5) (44.3%, 75.4%)	
07/04 09:24:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][150/703]	Step 44502	lr 0.1	Loss 2.3727 (2.1051)	Prec@(1,5) (44.1%, 75.6%)	
07/04 09:24:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][200/703]	Step 44552	lr 0.1	Loss 2.5629 (2.1089)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:24:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][250/703]	Step 44602	lr 0.1	Loss 2.0401 (2.1032)	Prec@(1,5) (44.1%, 75.7%)	
07/04 09:24:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][300/703]	Step 44652	lr 0.1	Loss 2.0563 (2.1025)	Prec@(1,5) (44.1%, 75.7%)	
07/04 09:24:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][350/703]	Step 44702	lr 0.1	Loss 1.6447 (2.1096)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:24:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][400/703]	Step 44752	lr 0.1	Loss 2.3416 (2.1160)	Prec@(1,5) (43.7%, 75.5%)	
07/04 09:24:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][450/703]	Step 44802	lr 0.1	Loss 2.2450 (2.1254)	Prec@(1,5) (43.6%, 75.4%)	
07/04 09:24:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][500/703]	Step 44852	lr 0.1	Loss 2.4304 (2.1255)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:24:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][550/703]	Step 44902	lr 0.1	Loss 1.7734 (2.1281)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:24:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][600/703]	Step 44952	lr 0.1	Loss 2.3436 (2.1296)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:24:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][650/703]	Step 45002	lr 0.1	Loss 2.1134 (2.1323)	Prec@(1,5) (43.4%, 75.2%)	
07/04 09:25:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][700/703]	Step 45052	lr 0.1	Loss 1.9684 (2.1371)	Prec@(1,5) (43.3%, 75.1%)	
07/04 09:25:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [63][703/703]	Step 45055	lr 0.1	Loss 2.0810 (2.1366)	Prec@(1,5) (43.3%, 75.1%)	
07/04 09:25:01PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 63/199] Final Prec@1 43.2778%
07/04 09:25:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [63][50/79]	Step 45056	Loss 2.4512	Prec@(1,5) (37.8%, 68.3%)
07/04 09:25:03PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [63][78/79]	Step 45056	Loss 2.4560	Prec@(1,5) (37.6%, 68.5%)
07/04 09:25:03PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 63/199] Final Prec@1 37.6600%
07/04 09:25:03PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:25:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][50/703]	Step 45106	lr 0.1	Loss 2.0128 (2.0729)	Prec@(1,5) (43.5%, 76.4%)	
07/04 09:25:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][100/703]	Step 45156	lr 0.1	Loss 2.3960 (2.1014)	Prec@(1,5) (43.3%, 75.6%)	
07/04 09:25:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][150/703]	Step 45206	lr 0.1	Loss 1.9531 (2.0993)	Prec@(1,5) (43.2%, 76.2%)	
07/04 09:25:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][200/703]	Step 45256	lr 0.1	Loss 2.3603 (2.1140)	Prec@(1,5) (43.2%, 76.0%)	
07/04 09:25:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][250/703]	Step 45306	lr 0.1	Loss 1.8491 (2.1196)	Prec@(1,5) (43.2%, 75.9%)	
07/04 09:25:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][300/703]	Step 45356	lr 0.1	Loss 1.9092 (2.1236)	Prec@(1,5) (43.0%, 75.7%)	
07/04 09:25:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][350/703]	Step 45406	lr 0.1	Loss 2.4611 (2.1188)	Prec@(1,5) (43.2%, 75.9%)	
07/04 09:25:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][400/703]	Step 45456	lr 0.1	Loss 2.0477 (2.1227)	Prec@(1,5) (43.1%, 75.7%)	
07/04 09:25:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][450/703]	Step 45506	lr 0.1	Loss 2.2037 (2.1176)	Prec@(1,5) (43.2%, 75.9%)	
07/04 09:25:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][500/703]	Step 45556	lr 0.1	Loss 2.2059 (2.1131)	Prec@(1,5) (43.4%, 76.0%)	
07/04 09:25:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][550/703]	Step 45606	lr 0.1	Loss 2.2234 (2.1192)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:25:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][600/703]	Step 45656	lr 0.1	Loss 2.1353 (2.1251)	Prec@(1,5) (43.2%, 75.6%)	
07/04 09:25:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][650/703]	Step 45706	lr 0.1	Loss 1.7582 (2.1250)	Prec@(1,5) (43.3%, 75.6%)	
07/04 09:25:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][700/703]	Step 45756	lr 0.1	Loss 2.0391 (2.1283)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:25:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [64][703/703]	Step 45759	lr 0.1	Loss 2.1516 (2.1289)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:25:50PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 64/199] Final Prec@1 43.1689%
07/04 09:25:51PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [64][50/79]	Step 45760	Loss 2.3963	Prec@(1,5) (38.8%, 70.7%)
07/04 09:25:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [64][78/79]	Step 45760	Loss 2.3936	Prec@(1,5) (38.9%, 70.7%)
07/04 09:25:52PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 64/199] Final Prec@1 38.8800%
07/04 09:25:52PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:25:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][50/703]	Step 45810	lr 0.1	Loss 2.2929 (2.1761)	Prec@(1,5) (41.4%, 75.2%)	
07/04 09:25:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][100/703]	Step 45860	lr 0.1	Loss 2.0655 (2.1333)	Prec@(1,5) (42.4%, 75.3%)	
07/04 09:26:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][150/703]	Step 45910	lr 0.1	Loss 2.1068 (2.1210)	Prec@(1,5) (43.0%, 75.2%)	
07/04 09:26:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][200/703]	Step 45960	lr 0.1	Loss 2.2955 (2.1221)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:26:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][250/703]	Step 46010	lr 0.1	Loss 1.5567 (2.1275)	Prec@(1,5) (43.2%, 75.1%)	
07/04 09:26:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][300/703]	Step 46060	lr 0.1	Loss 2.4204 (2.1277)	Prec@(1,5) (43.0%, 75.2%)	
07/04 09:26:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][350/703]	Step 46110	lr 0.1	Loss 1.9645 (2.1232)	Prec@(1,5) (43.1%, 75.3%)	
07/04 09:26:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][400/703]	Step 46160	lr 0.1	Loss 2.1764 (2.1260)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:26:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][450/703]	Step 46210	lr 0.1	Loss 1.8061 (2.1223)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:26:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][500/703]	Step 46260	lr 0.1	Loss 1.7958 (2.1257)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:26:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][550/703]	Step 46310	lr 0.1	Loss 2.1102 (2.1270)	Prec@(1,5) (42.9%, 75.2%)	
07/04 09:26:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][600/703]	Step 46360	lr 0.1	Loss 2.1144 (2.1338)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:26:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][650/703]	Step 46410	lr 0.1	Loss 1.9083 (2.1413)	Prec@(1,5) (42.7%, 74.9%)	
07/04 09:26:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][700/703]	Step 46460	lr 0.1	Loss 2.2248 (2.1457)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:26:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [65][703/703]	Step 46463	lr 0.1	Loss 2.2759 (2.1461)	Prec@(1,5) (42.5%, 74.8%)	
07/04 09:26:37PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 65/199] Final Prec@1 42.5200%
07/04 09:26:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [65][50/79]	Step 46464	Loss 2.4529	Prec@(1,5) (37.6%, 68.4%)
07/04 09:26:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [65][78/79]	Step 46464	Loss 2.4646	Prec@(1,5) (37.2%, 68.3%)
07/04 09:26:38PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 65/199] Final Prec@1 37.2600%
07/04 09:26:38PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 39.5600%
07/04 09:26:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][50/703]	Step 46514	lr 0.1	Loss 1.7831 (2.1001)	Prec@(1,5) (43.7%, 76.4%)	
07/04 09:26:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][100/703]	Step 46564	lr 0.1	Loss 1.9710 (2.1306)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:26:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][150/703]	Step 46614	lr 0.1	Loss 2.0871 (2.1347)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:26:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][200/703]	Step 46664	lr 0.1	Loss 2.3604 (2.1463)	Prec@(1,5) (43.1%, 75.1%)	
07/04 09:26:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][250/703]	Step 46714	lr 0.1	Loss 2.1304 (2.1419)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:26:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][300/703]	Step 46764	lr 0.1	Loss 1.9215 (2.1356)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:27:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][350/703]	Step 46814	lr 0.1	Loss 2.2775 (2.1399)	Prec@(1,5) (43.2%, 75.4%)	
07/04 09:27:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][400/703]	Step 46864	lr 0.1	Loss 2.3185 (2.1457)	Prec@(1,5) (43.0%, 75.2%)	
07/04 09:27:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][450/703]	Step 46914	lr 0.1	Loss 2.3742 (2.1462)	Prec@(1,5) (43.1%, 75.2%)	
07/04 09:27:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][500/703]	Step 46964	lr 0.1	Loss 2.2266 (2.1456)	Prec@(1,5) (43.1%, 75.2%)	
07/04 09:27:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][550/703]	Step 47014	lr 0.1	Loss 1.7405 (2.1438)	Prec@(1,5) (43.1%, 75.2%)	
07/04 09:27:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][600/703]	Step 47064	lr 0.1	Loss 2.2220 (2.1455)	Prec@(1,5) (43.0%, 75.1%)	
07/04 09:27:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][650/703]	Step 47114	lr 0.1	Loss 2.2692 (2.1477)	Prec@(1,5) (42.9%, 75.1%)	
07/04 09:27:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][700/703]	Step 47164	lr 0.1	Loss 2.1858 (2.1473)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:27:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [66][703/703]	Step 47167	lr 0.1	Loss 2.2415 (2.1468)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:27:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 66/199] Final Prec@1 42.8422%
07/04 09:27:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [66][50/79]	Step 47168	Loss 2.2380	Prec@(1,5) (40.7%, 73.3%)
07/04 09:27:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [66][78/79]	Step 47168	Loss 2.2536	Prec@(1,5) (40.5%, 72.9%)
07/04 09:27:27PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 66/199] Final Prec@1 40.4200%
07/04 09:27:27PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:27:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][50/703]	Step 47218	lr 0.1	Loss 2.2620 (2.0979)	Prec@(1,5) (43.4%, 76.7%)	
07/04 09:27:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][100/703]	Step 47268	lr 0.1	Loss 1.5890 (2.0795)	Prec@(1,5) (43.5%, 77.3%)	
07/04 09:27:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][150/703]	Step 47318	lr 0.1	Loss 1.9760 (2.0879)	Prec@(1,5) (43.6%, 76.8%)	
07/04 09:27:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][200/703]	Step 47368	lr 0.1	Loss 1.8657 (2.0925)	Prec@(1,5) (43.6%, 76.6%)	
07/04 09:27:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][250/703]	Step 47418	lr 0.1	Loss 2.0396 (2.0970)	Prec@(1,5) (43.6%, 76.4%)	
07/04 09:27:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][300/703]	Step 47468	lr 0.1	Loss 2.3731 (2.1045)	Prec@(1,5) (43.5%, 76.2%)	
07/04 09:27:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][350/703]	Step 47518	lr 0.1	Loss 1.9326 (2.1054)	Prec@(1,5) (43.5%, 76.1%)	
07/04 09:27:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][400/703]	Step 47568	lr 0.1	Loss 2.1426 (2.1166)	Prec@(1,5) (43.2%, 75.8%)	
07/04 09:27:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][450/703]	Step 47618	lr 0.1	Loss 2.0412 (2.1233)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:28:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][500/703]	Step 47668	lr 0.1	Loss 1.8686 (2.1273)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:28:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][550/703]	Step 47718	lr 0.1	Loss 2.1890 (2.1297)	Prec@(1,5) (43.1%, 75.4%)	
07/04 09:28:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][600/703]	Step 47768	lr 0.1	Loss 2.2422 (2.1349)	Prec@(1,5) (43.1%, 75.3%)	
07/04 09:28:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][650/703]	Step 47818	lr 0.1	Loss 2.6032 (2.1366)	Prec@(1,5) (43.0%, 75.3%)	
07/04 09:28:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][700/703]	Step 47868	lr 0.1	Loss 2.7822 (2.1386)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:28:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [67][703/703]	Step 47871	lr 0.1	Loss 2.4523 (2.1392)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:28:14PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 67/199] Final Prec@1 42.9089%
07/04 09:28:15PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [67][50/79]	Step 47872	Loss 2.5179	Prec@(1,5) (36.5%, 68.2%)
07/04 09:28:15PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [67][78/79]	Step 47872	Loss 2.4910	Prec@(1,5) (37.6%, 68.0%)
07/04 09:28:15PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 67/199] Final Prec@1 37.5400%
07/04 09:28:15PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:28:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][50/703]	Step 47922	lr 0.1	Loss 2.4107 (2.1166)	Prec@(1,5) (43.3%, 74.8%)	
07/04 09:28:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][100/703]	Step 47972	lr 0.1	Loss 2.4887 (2.1088)	Prec@(1,5) (43.2%, 75.7%)	
07/04 09:28:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][150/703]	Step 48022	lr 0.1	Loss 1.9237 (2.1031)	Prec@(1,5) (43.5%, 75.6%)	
07/04 09:28:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][200/703]	Step 48072	lr 0.1	Loss 2.2971 (2.0950)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:28:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][250/703]	Step 48122	lr 0.1	Loss 2.2115 (2.0916)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:28:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][300/703]	Step 48172	lr 0.1	Loss 2.0339 (2.1032)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:28:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][350/703]	Step 48222	lr 0.1	Loss 2.3297 (2.1072)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:28:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][400/703]	Step 48272	lr 0.1	Loss 1.7995 (2.1111)	Prec@(1,5) (43.2%, 75.8%)	
07/04 09:28:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][450/703]	Step 48322	lr 0.1	Loss 2.3060 (2.1219)	Prec@(1,5) (43.0%, 75.5%)	
07/04 09:28:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][500/703]	Step 48372	lr 0.1	Loss 2.0644 (2.1297)	Prec@(1,5) (42.8%, 75.4%)	
07/04 09:28:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][550/703]	Step 48422	lr 0.1	Loss 2.5985 (2.1323)	Prec@(1,5) (42.8%, 75.4%)	
07/04 09:28:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][600/703]	Step 48472	lr 0.1	Loss 2.0920 (2.1329)	Prec@(1,5) (42.8%, 75.3%)	
07/04 09:28:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][650/703]	Step 48522	lr 0.1	Loss 1.7418 (2.1303)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:29:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][700/703]	Step 48572	lr 0.1	Loss 1.9848 (2.1308)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:29:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [68][703/703]	Step 48575	lr 0.1	Loss 2.4301 (2.1309)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:29:01PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 68/199] Final Prec@1 42.9067%
07/04 09:29:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [68][50/79]	Step 48576	Loss 2.3332	Prec@(1,5) (39.6%, 71.1%)
07/04 09:29:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [68][78/79]	Step 48576	Loss 2.3601	Prec@(1,5) (39.2%, 70.8%)
07/04 09:29:02PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 68/199] Final Prec@1 39.1600%
07/04 09:29:03PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:29:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][50/703]	Step 48626	lr 0.1	Loss 1.9702 (2.0918)	Prec@(1,5) (43.6%, 76.2%)	
07/04 09:29:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][100/703]	Step 48676	lr 0.1	Loss 2.0596 (2.0867)	Prec@(1,5) (44.0%, 76.1%)	
07/04 09:29:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][150/703]	Step 48726	lr 0.1	Loss 2.0885 (2.0852)	Prec@(1,5) (44.4%, 76.2%)	
07/04 09:29:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][200/703]	Step 48776	lr 0.1	Loss 2.1761 (2.0853)	Prec@(1,5) (44.2%, 76.1%)	
07/04 09:29:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][250/703]	Step 48826	lr 0.1	Loss 2.3609 (2.0859)	Prec@(1,5) (44.1%, 76.1%)	
07/04 09:29:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][300/703]	Step 48876	lr 0.1	Loss 2.0398 (2.1055)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:29:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][350/703]	Step 48926	lr 0.1	Loss 2.2677 (2.1119)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:29:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][400/703]	Step 48976	lr 0.1	Loss 1.8377 (2.1197)	Prec@(1,5) (43.5%, 75.5%)	
07/04 09:29:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][450/703]	Step 49026	lr 0.1	Loss 2.0604 (2.1173)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:29:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][500/703]	Step 49076	lr 0.1	Loss 2.2335 (2.1243)	Prec@(1,5) (43.3%, 75.4%)	
07/04 09:29:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][550/703]	Step 49126	lr 0.1	Loss 2.1621 (2.1231)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:29:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][600/703]	Step 49176	lr 0.1	Loss 1.9841 (2.1176)	Prec@(1,5) (43.5%, 75.5%)	
07/04 09:29:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][650/703]	Step 49226	lr 0.1	Loss 1.7669 (2.1177)	Prec@(1,5) (43.6%, 75.5%)	
07/04 09:29:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][700/703]	Step 49276	lr 0.1	Loss 1.8816 (2.1214)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:29:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [69][703/703]	Step 49279	lr 0.1	Loss 2.2799 (2.1224)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:29:49PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 69/199] Final Prec@1 43.4756%
07/04 09:29:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [69][50/79]	Step 49280	Loss 2.3779	Prec@(1,5) (39.4%, 69.5%)
07/04 09:29:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [69][78/79]	Step 49280	Loss 2.3589	Prec@(1,5) (39.8%, 70.1%)
07/04 09:29:50PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 69/199] Final Prec@1 39.7600%
07/04 09:29:50PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:29:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][50/703]	Step 49330	lr 0.1	Loss 1.7582 (2.1016)	Prec@(1,5) (43.4%, 76.5%)	
07/04 09:29:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][100/703]	Step 49380	lr 0.1	Loss 1.9529 (2.0970)	Prec@(1,5) (43.6%, 76.2%)	
07/04 09:30:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][150/703]	Step 49430	lr 0.1	Loss 2.0674 (2.0973)	Prec@(1,5) (43.7%, 76.0%)	
07/04 09:30:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][200/703]	Step 49480	lr 0.1	Loss 2.2829 (2.1009)	Prec@(1,5) (43.3%, 76.1%)	
07/04 09:30:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][250/703]	Step 49530	lr 0.1	Loss 2.1622 (2.1113)	Prec@(1,5) (43.2%, 75.9%)	
07/04 09:30:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][300/703]	Step 49580	lr 0.1	Loss 1.8168 (2.1151)	Prec@(1,5) (43.1%, 75.9%)	
07/04 09:30:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][350/703]	Step 49630	lr 0.1	Loss 1.9636 (2.1219)	Prec@(1,5) (43.0%, 75.7%)	
07/04 09:30:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][400/703]	Step 49680	lr 0.1	Loss 2.0546 (2.1199)	Prec@(1,5) (43.1%, 75.7%)	
07/04 09:30:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][450/703]	Step 49730	lr 0.1	Loss 2.3595 (2.1281)	Prec@(1,5) (42.9%, 75.6%)	
07/04 09:30:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][500/703]	Step 49780	lr 0.1	Loss 2.2393 (2.1310)	Prec@(1,5) (42.8%, 75.5%)	
07/04 09:30:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][550/703]	Step 49830	lr 0.1	Loss 2.2213 (2.1353)	Prec@(1,5) (42.8%, 75.4%)	
07/04 09:30:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][600/703]	Step 49880	lr 0.1	Loss 2.1554 (2.1371)	Prec@(1,5) (42.8%, 75.3%)	
07/04 09:30:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][650/703]	Step 49930	lr 0.1	Loss 1.6087 (2.1408)	Prec@(1,5) (42.7%, 75.2%)	
07/04 09:30:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][700/703]	Step 49980	lr 0.1	Loss 1.7525 (2.1427)	Prec@(1,5) (42.7%, 75.2%)	
07/04 09:30:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [70][703/703]	Step 49983	lr 0.1	Loss 1.9253 (2.1416)	Prec@(1,5) (42.7%, 75.2%)	
07/04 09:30:37PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 70/199] Final Prec@1 42.6933%
07/04 09:30:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [70][50/79]	Step 49984	Loss 2.4147	Prec@(1,5) (38.6%, 70.1%)
07/04 09:30:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [70][78/79]	Step 49984	Loss 2.4354	Prec@(1,5) (37.6%, 69.4%)
07/04 09:30:38PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 70/199] Final Prec@1 37.6600%
07/04 09:30:38PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:30:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][50/703]	Step 50034	lr 0.1	Loss 1.9250 (2.1070)	Prec@(1,5) (43.4%, 75.9%)	
07/04 09:30:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][100/703]	Step 50084	lr 0.1	Loss 1.9625 (2.0752)	Prec@(1,5) (44.1%, 76.5%)	
07/04 09:30:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][150/703]	Step 50134	lr 0.1	Loss 1.7745 (2.0869)	Prec@(1,5) (44.0%, 76.1%)	
07/04 09:30:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][200/703]	Step 50184	lr 0.1	Loss 1.8765 (2.0892)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:30:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][250/703]	Step 50234	lr 0.1	Loss 1.9813 (2.1028)	Prec@(1,5) (43.8%, 75.5%)	
07/04 09:30:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][300/703]	Step 50284	lr 0.1	Loss 2.2325 (2.1085)	Prec@(1,5) (43.6%, 75.4%)	
07/04 09:31:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][350/703]	Step 50334	lr 0.1	Loss 2.1016 (2.1167)	Prec@(1,5) (43.5%, 75.2%)	
07/04 09:31:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][400/703]	Step 50384	lr 0.1	Loss 2.0313 (2.1186)	Prec@(1,5) (43.5%, 75.2%)	
07/04 09:31:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][450/703]	Step 50434	lr 0.1	Loss 1.9669 (2.1257)	Prec@(1,5) (43.4%, 75.1%)	
07/04 09:31:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][500/703]	Step 50484	lr 0.1	Loss 2.5054 (2.1304)	Prec@(1,5) (43.4%, 75.0%)	
07/04 09:31:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][550/703]	Step 50534	lr 0.1	Loss 2.2276 (2.1297)	Prec@(1,5) (43.4%, 75.0%)	
07/04 09:31:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][600/703]	Step 50584	lr 0.1	Loss 2.3984 (2.1305)	Prec@(1,5) (43.4%, 75.0%)	
07/04 09:31:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][650/703]	Step 50634	lr 0.1	Loss 1.8508 (2.1308)	Prec@(1,5) (43.5%, 75.0%)	
07/04 09:31:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][700/703]	Step 50684	lr 0.1	Loss 2.1862 (2.1340)	Prec@(1,5) (43.4%, 74.9%)	
07/04 09:31:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [71][703/703]	Step 50687	lr 0.1	Loss 2.1336 (2.1342)	Prec@(1,5) (43.4%, 74.9%)	
07/04 09:31:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 71/199] Final Prec@1 43.3867%
07/04 09:31:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [71][50/79]	Step 50688	Loss 2.3253	Prec@(1,5) (39.5%, 71.4%)
07/04 09:31:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [71][78/79]	Step 50688	Loss 2.3412	Prec@(1,5) (39.5%, 71.0%)
07/04 09:31:26PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 71/199] Final Prec@1 39.6000%
07/04 09:31:26PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:31:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][50/703]	Step 50738	lr 0.1	Loss 2.2471 (2.0923)	Prec@(1,5) (44.6%, 76.2%)	
07/04 09:31:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][100/703]	Step 50788	lr 0.1	Loss 1.9190 (2.0924)	Prec@(1,5) (44.2%, 76.2%)	
07/04 09:31:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][150/703]	Step 50838	lr 0.1	Loss 2.3334 (2.0949)	Prec@(1,5) (44.2%, 76.0%)	
07/04 09:31:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][200/703]	Step 50888	lr 0.1	Loss 2.5232 (2.1042)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:31:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][250/703]	Step 50938	lr 0.1	Loss 2.2589 (2.1109)	Prec@(1,5) (43.9%, 75.8%)	
07/04 09:31:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][300/703]	Step 50988	lr 0.1	Loss 2.4246 (2.1193)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:31:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][350/703]	Step 51038	lr 0.1	Loss 2.0042 (2.1197)	Prec@(1,5) (43.7%, 75.6%)	
07/04 09:31:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][400/703]	Step 51088	lr 0.1	Loss 2.2294 (2.1232)	Prec@(1,5) (43.6%, 75.6%)	
07/04 09:31:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][450/703]	Step 51138	lr 0.1	Loss 2.3315 (2.1216)	Prec@(1,5) (43.5%, 75.5%)	
07/04 09:31:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][500/703]	Step 51188	lr 0.1	Loss 1.9445 (2.1205)	Prec@(1,5) (43.7%, 75.5%)	
07/04 09:32:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][550/703]	Step 51238	lr 0.1	Loss 1.8389 (2.1238)	Prec@(1,5) (43.6%, 75.4%)	
07/04 09:32:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][600/703]	Step 51288	lr 0.1	Loss 2.1843 (2.1266)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:32:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][650/703]	Step 51338	lr 0.1	Loss 2.2330 (2.1299)	Prec@(1,5) (43.4%, 75.3%)	
07/04 09:32:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][700/703]	Step 51388	lr 0.1	Loss 1.8662 (2.1304)	Prec@(1,5) (43.4%, 75.3%)	
07/04 09:32:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [72][703/703]	Step 51391	lr 0.1	Loss 2.1164 (2.1307)	Prec@(1,5) (43.3%, 75.3%)	
07/04 09:32:12PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 72/199] Final Prec@1 43.3333%
07/04 09:32:13PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [72][50/79]	Step 51392	Loss 2.4134	Prec@(1,5) (38.1%, 69.6%)
07/04 09:32:13PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [72][78/79]	Step 51392	Loss 2.3919	Prec@(1,5) (38.6%, 69.9%)
07/04 09:32:13PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 72/199] Final Prec@1 38.6000%
07/04 09:32:13PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 40.4200%
07/04 09:32:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][50/703]	Step 51442	lr 0.1	Loss 2.3591 (2.1336)	Prec@(1,5) (42.1%, 75.7%)	
07/04 09:32:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][100/703]	Step 51492	lr 0.1	Loss 1.7846 (2.1019)	Prec@(1,5) (43.7%, 76.1%)	
07/04 09:32:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][150/703]	Step 51542	lr 0.1	Loss 2.0474 (2.1171)	Prec@(1,5) (43.8%, 75.9%)	
07/04 09:32:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][200/703]	Step 51592	lr 0.1	Loss 2.7570 (2.1176)	Prec@(1,5) (43.7%, 76.1%)	
07/04 09:32:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][250/703]	Step 51642	lr 0.1	Loss 1.9751 (2.1183)	Prec@(1,5) (43.5%, 75.9%)	
07/04 09:32:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][300/703]	Step 51692	lr 0.1	Loss 2.4058 (2.1284)	Prec@(1,5) (43.3%, 75.8%)	
07/04 09:32:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][350/703]	Step 51742	lr 0.1	Loss 2.0069 (2.1268)	Prec@(1,5) (43.2%, 75.8%)	
07/04 09:32:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][400/703]	Step 51792	lr 0.1	Loss 1.8361 (2.1255)	Prec@(1,5) (43.3%, 75.7%)	
07/04 09:32:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][450/703]	Step 51842	lr 0.1	Loss 1.8033 (2.1258)	Prec@(1,5) (43.2%, 75.7%)	
07/04 09:32:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][500/703]	Step 51892	lr 0.1	Loss 2.0376 (2.1303)	Prec@(1,5) (43.0%, 75.6%)	
07/04 09:32:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][550/703]	Step 51942	lr 0.1	Loss 2.0988 (2.1324)	Prec@(1,5) (43.0%, 75.5%)	
07/04 09:32:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][600/703]	Step 51992	lr 0.1	Loss 2.3664 (2.1337)	Prec@(1,5) (43.0%, 75.5%)	
07/04 09:32:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][650/703]	Step 52042	lr 0.1	Loss 2.1908 (2.1343)	Prec@(1,5) (42.9%, 75.4%)	
07/04 09:33:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][700/703]	Step 52092	lr 0.1	Loss 2.4414 (2.1381)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:33:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [73][703/703]	Step 52095	lr 0.1	Loss 1.9929 (2.1379)	Prec@(1,5) (42.9%, 75.3%)	
07/04 09:33:00PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 73/199] Final Prec@1 42.8622%
07/04 09:33:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [73][50/79]	Step 52096	Loss 2.2702	Prec@(1,5) (41.3%, 72.8%)
07/04 09:33:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [73][78/79]	Step 52096	Loss 2.2654	Prec@(1,5) (41.1%, 73.1%)
07/04 09:33:02PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 73/199] Final Prec@1 41.1000%
07/04 09:33:02PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:33:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][50/703]	Step 52146	lr 0.1	Loss 1.7954 (2.0765)	Prec@(1,5) (44.1%, 76.7%)	
07/04 09:33:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][100/703]	Step 52196	lr 0.1	Loss 2.0108 (2.0919)	Prec@(1,5) (43.2%, 76.5%)	
07/04 09:33:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][150/703]	Step 52246	lr 0.1	Loss 2.2309 (2.1048)	Prec@(1,5) (43.0%, 76.0%)	
07/04 09:33:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][200/703]	Step 52296	lr 0.1	Loss 2.0964 (2.1028)	Prec@(1,5) (43.2%, 75.8%)	
07/04 09:33:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][250/703]	Step 52346	lr 0.1	Loss 2.1756 (2.1019)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:33:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][300/703]	Step 52396	lr 0.1	Loss 1.9887 (2.1093)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:33:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][350/703]	Step 52446	lr 0.1	Loss 2.2053 (2.1163)	Prec@(1,5) (43.3%, 75.6%)	
07/04 09:33:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][400/703]	Step 52496	lr 0.1	Loss 2.1977 (2.1137)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:33:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][450/703]	Step 52546	lr 0.1	Loss 1.8821 (2.1209)	Prec@(1,5) (43.3%, 75.5%)	
07/04 09:33:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][500/703]	Step 52596	lr 0.1	Loss 2.1901 (2.1238)	Prec@(1,5) (43.1%, 75.6%)	
07/04 09:33:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][550/703]	Step 52646	lr 0.1	Loss 1.9004 (2.1270)	Prec@(1,5) (43.1%, 75.5%)	
07/04 09:33:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][600/703]	Step 52696	lr 0.1	Loss 1.9798 (2.1263)	Prec@(1,5) (43.1%, 75.5%)	
07/04 09:33:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][650/703]	Step 52746	lr 0.1	Loss 1.9999 (2.1284)	Prec@(1,5) (43.1%, 75.4%)	
07/04 09:33:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][700/703]	Step 52796	lr 0.1	Loss 2.0736 (2.1310)	Prec@(1,5) (43.0%, 75.3%)	
07/04 09:33:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [74][703/703]	Step 52799	lr 0.1	Loss 2.0851 (2.1320)	Prec@(1,5) (43.0%, 75.3%)	
07/04 09:33:49PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 74/199] Final Prec@1 43.0178%
07/04 09:33:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [74][50/79]	Step 52800	Loss 2.5714	Prec@(1,5) (37.0%, 67.3%)
07/04 09:33:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [74][78/79]	Step 52800	Loss 2.5476	Prec@(1,5) (36.8%, 67.9%)
07/04 09:33:51PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 74/199] Final Prec@1 36.8200%
07/04 09:33:51PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:33:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][50/703]	Step 52850	lr 0.1	Loss 2.0884 (2.1748)	Prec@(1,5) (42.6%, 74.4%)	
07/04 09:33:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][100/703]	Step 52900	lr 0.1	Loss 2.0956 (2.1395)	Prec@(1,5) (42.6%, 75.2%)	
07/04 09:34:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][150/703]	Step 52950	lr 0.1	Loss 1.9708 (2.1274)	Prec@(1,5) (42.7%, 75.4%)	
07/04 09:34:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][200/703]	Step 53000	lr 0.1	Loss 2.3908 (2.1331)	Prec@(1,5) (42.8%, 75.2%)	
07/04 09:34:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][250/703]	Step 53050	lr 0.1	Loss 2.1583 (2.1275)	Prec@(1,5) (43.0%, 75.4%)	
07/04 09:34:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][300/703]	Step 53100	lr 0.1	Loss 2.0292 (2.1242)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:34:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][350/703]	Step 53150	lr 0.1	Loss 1.8357 (2.1221)	Prec@(1,5) (43.3%, 75.3%)	
07/04 09:34:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][400/703]	Step 53200	lr 0.1	Loss 2.2288 (2.1204)	Prec@(1,5) (43.3%, 75.4%)	
07/04 09:34:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][450/703]	Step 53250	lr 0.1	Loss 2.1870 (2.1202)	Prec@(1,5) (43.3%, 75.3%)	
07/04 09:34:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][500/703]	Step 53300	lr 0.1	Loss 1.7860 (2.1214)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:34:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][550/703]	Step 53350	lr 0.1	Loss 2.4032 (2.1213)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:34:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][600/703]	Step 53400	lr 0.1	Loss 2.0710 (2.1249)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:34:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][650/703]	Step 53450	lr 0.1	Loss 2.2189 (2.1240)	Prec@(1,5) (43.3%, 75.4%)	
07/04 09:34:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][700/703]	Step 53500	lr 0.1	Loss 2.2243 (2.1272)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:34:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [75][703/703]	Step 53503	lr 0.1	Loss 2.3640 (2.1276)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:34:37PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 75/199] Final Prec@1 43.2356%
07/04 09:34:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [75][50/79]	Step 53504	Loss 2.4537	Prec@(1,5) (38.0%, 68.7%)
07/04 09:34:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [75][78/79]	Step 53504	Loss 2.4878	Prec@(1,5) (36.3%, 68.2%)
07/04 09:34:38PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 75/199] Final Prec@1 36.3600%
07/04 09:34:38PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:34:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][50/703]	Step 53554	lr 0.1	Loss 2.0211 (2.1252)	Prec@(1,5) (42.1%, 75.6%)	
07/04 09:34:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][100/703]	Step 53604	lr 0.1	Loss 1.8894 (2.0940)	Prec@(1,5) (43.1%, 76.0%)	
07/04 09:34:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][150/703]	Step 53654	lr 0.1	Loss 2.0544 (2.1006)	Prec@(1,5) (43.1%, 76.1%)	
07/04 09:34:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][200/703]	Step 53704	lr 0.1	Loss 2.4365 (2.1119)	Prec@(1,5) (43.1%, 75.7%)	
07/04 09:34:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][250/703]	Step 53754	lr 0.1	Loss 2.4485 (2.1195)	Prec@(1,5) (43.1%, 75.5%)	
07/04 09:34:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][300/703]	Step 53804	lr 0.1	Loss 2.2923 (2.1175)	Prec@(1,5) (43.1%, 75.6%)	
07/04 09:35:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][350/703]	Step 53854	lr 0.1	Loss 2.5091 (2.1201)	Prec@(1,5) (43.1%, 75.6%)	
07/04 09:35:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][400/703]	Step 53904	lr 0.1	Loss 2.1200 (2.1183)	Prec@(1,5) (43.2%, 75.5%)	
07/04 09:35:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][450/703]	Step 53954	lr 0.1	Loss 2.3506 (2.1152)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:35:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][500/703]	Step 54004	lr 0.1	Loss 1.7633 (2.1168)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:35:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][550/703]	Step 54054	lr 0.1	Loss 1.7966 (2.1172)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:35:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][600/703]	Step 54104	lr 0.1	Loss 2.2794 (2.1189)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:35:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][650/703]	Step 54154	lr 0.1	Loss 2.2070 (2.1220)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:35:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][700/703]	Step 54204	lr 0.1	Loss 2.2435 (2.1242)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:35:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [76][703/703]	Step 54207	lr 0.1	Loss 2.4717 (2.1242)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:35:24PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 76/199] Final Prec@1 43.3578%
07/04 09:35:25PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [76][50/79]	Step 54208	Loss 2.2830	Prec@(1,5) (41.6%, 71.4%)
07/04 09:35:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [76][78/79]	Step 54208	Loss 2.3054	Prec@(1,5) (40.5%, 71.8%)
07/04 09:35:26PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 76/199] Final Prec@1 40.5000%
07/04 09:35:26PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:35:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][50/703]	Step 54258	lr 0.1	Loss 2.1892 (2.1117)	Prec@(1,5) (43.8%, 76.0%)	
07/04 09:35:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][100/703]	Step 54308	lr 0.1	Loss 2.1519 (2.1031)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:35:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][150/703]	Step 54358	lr 0.1	Loss 2.2221 (2.0925)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:35:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][200/703]	Step 54408	lr 0.1	Loss 2.0850 (2.0967)	Prec@(1,5) (43.8%, 76.0%)	
07/04 09:35:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][250/703]	Step 54458	lr 0.1	Loss 2.6101 (2.0884)	Prec@(1,5) (44.1%, 75.9%)	
07/04 09:35:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][300/703]	Step 54508	lr 0.1	Loss 2.0178 (2.0857)	Prec@(1,5) (44.2%, 76.0%)	
07/04 09:35:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][350/703]	Step 54558	lr 0.1	Loss 2.2450 (2.0987)	Prec@(1,5) (44.0%, 75.7%)	
07/04 09:35:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][400/703]	Step 54608	lr 0.1	Loss 1.8445 (2.1014)	Prec@(1,5) (43.8%, 75.8%)	
07/04 09:35:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][450/703]	Step 54658	lr 0.1	Loss 2.2350 (2.1005)	Prec@(1,5) (43.8%, 75.7%)	
07/04 09:35:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][500/703]	Step 54708	lr 0.1	Loss 2.1573 (2.1055)	Prec@(1,5) (43.8%, 75.7%)	
07/04 09:36:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][550/703]	Step 54758	lr 0.1	Loss 2.0174 (2.1079)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:36:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][600/703]	Step 54808	lr 0.1	Loss 2.2443 (2.1113)	Prec@(1,5) (43.7%, 75.5%)	
07/04 09:36:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][650/703]	Step 54858	lr 0.1	Loss 2.0689 (2.1166)	Prec@(1,5) (43.6%, 75.4%)	
07/04 09:36:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][700/703]	Step 54908	lr 0.1	Loss 2.3689 (2.1164)	Prec@(1,5) (43.6%, 75.4%)	
07/04 09:36:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [77][703/703]	Step 54911	lr 0.1	Loss 1.7848 (2.1164)	Prec@(1,5) (43.6%, 75.4%)	
07/04 09:36:11PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 77/199] Final Prec@1 43.6422%
07/04 09:36:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [77][50/79]	Step 54912	Loss 2.4115	Prec@(1,5) (38.2%, 70.6%)
07/04 09:36:13PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [77][78/79]	Step 54912	Loss 2.3729	Prec@(1,5) (39.2%, 71.2%)
07/04 09:36:13PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 77/199] Final Prec@1 39.1600%
07/04 09:36:13PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:36:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][50/703]	Step 54962	lr 0.1	Loss 1.8847 (2.1364)	Prec@(1,5) (42.0%, 74.4%)	
07/04 09:36:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][100/703]	Step 55012	lr 0.1	Loss 2.0696 (2.0748)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:36:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][150/703]	Step 55062	lr 0.1	Loss 1.8095 (2.0959)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:36:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][200/703]	Step 55112	lr 0.1	Loss 2.2594 (2.0964)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:36:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][250/703]	Step 55162	lr 0.1	Loss 2.1247 (2.0965)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:36:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][300/703]	Step 55212	lr 0.1	Loss 2.1675 (2.1098)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:36:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][350/703]	Step 55262	lr 0.1	Loss 2.1866 (2.1150)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:36:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][400/703]	Step 55312	lr 0.1	Loss 1.9979 (2.1104)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:36:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][450/703]	Step 55362	lr 0.1	Loss 2.0864 (2.1133)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:36:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][500/703]	Step 55412	lr 0.1	Loss 2.1836 (2.1137)	Prec@(1,5) (43.5%, 75.5%)	
07/04 09:36:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][550/703]	Step 55462	lr 0.1	Loss 2.1707 (2.1099)	Prec@(1,5) (43.6%, 75.6%)	
07/04 09:36:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][600/703]	Step 55512	lr 0.1	Loss 2.3303 (2.1098)	Prec@(1,5) (43.5%, 75.6%)	
07/04 09:36:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][650/703]	Step 55562	lr 0.1	Loss 2.3883 (2.1151)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:36:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][700/703]	Step 55612	lr 0.1	Loss 2.0634 (2.1190)	Prec@(1,5) (43.3%, 75.5%)	
07/04 09:36:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [78][703/703]	Step 55615	lr 0.1	Loss 2.1148 (2.1184)	Prec@(1,5) (43.3%, 75.5%)	
07/04 09:36:59PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 78/199] Final Prec@1 43.3333%
07/04 09:37:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [78][50/79]	Step 55616	Loss 2.3817	Prec@(1,5) (38.9%, 70.8%)
07/04 09:37:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [78][78/79]	Step 55616	Loss 2.3605	Prec@(1,5) (39.0%, 70.9%)
07/04 09:37:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 78/199] Final Prec@1 39.0000%
07/04 09:37:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:37:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][50/703]	Step 55666	lr 0.1	Loss 2.1055 (2.0532)	Prec@(1,5) (44.8%, 77.6%)	
07/04 09:37:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][100/703]	Step 55716	lr 0.1	Loss 1.7219 (2.0682)	Prec@(1,5) (44.5%, 76.7%)	
07/04 09:37:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][150/703]	Step 55766	lr 0.1	Loss 2.1665 (2.0917)	Prec@(1,5) (44.1%, 76.4%)	
07/04 09:37:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][200/703]	Step 55816	lr 0.1	Loss 2.2611 (2.0833)	Prec@(1,5) (44.0%, 76.6%)	
07/04 09:37:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][250/703]	Step 55866	lr 0.1	Loss 2.1510 (2.0812)	Prec@(1,5) (44.3%, 76.6%)	
07/04 09:37:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][300/703]	Step 55916	lr 0.1	Loss 1.8620 (2.0954)	Prec@(1,5) (43.9%, 76.3%)	
07/04 09:37:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][350/703]	Step 55966	lr 0.1	Loss 2.4298 (2.1022)	Prec@(1,5) (43.7%, 76.2%)	
07/04 09:37:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][400/703]	Step 56016	lr 0.1	Loss 1.9506 (2.1056)	Prec@(1,5) (43.7%, 76.0%)	
07/04 09:37:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][450/703]	Step 56066	lr 0.1	Loss 2.3319 (2.1057)	Prec@(1,5) (43.6%, 76.1%)	
07/04 09:37:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][500/703]	Step 56116	lr 0.1	Loss 2.0230 (2.1155)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:37:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][550/703]	Step 56166	lr 0.1	Loss 1.8372 (2.1166)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:37:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][600/703]	Step 56216	lr 0.1	Loss 1.8363 (2.1189)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:37:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][650/703]	Step 56266	lr 0.1	Loss 2.2553 (2.1247)	Prec@(1,5) (43.3%, 75.3%)	
07/04 09:37:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][700/703]	Step 56316	lr 0.1	Loss 2.1621 (2.1260)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:37:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [79][703/703]	Step 56319	lr 0.1	Loss 2.6085 (2.1268)	Prec@(1,5) (43.2%, 75.3%)	
07/04 09:37:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 79/199] Final Prec@1 43.1867%
07/04 09:37:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [79][50/79]	Step 56320	Loss 2.3728	Prec@(1,5) (39.4%, 70.4%)
07/04 09:37:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [79][78/79]	Step 56320	Loss 2.3352	Prec@(1,5) (39.6%, 71.2%)
07/04 09:37:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 79/199] Final Prec@1 39.5400%
07/04 09:37:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:37:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][50/703]	Step 56370	lr 0.1	Loss 1.7884 (2.0631)	Prec@(1,5) (45.1%, 75.6%)	
07/04 09:37:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][100/703]	Step 56420	lr 0.1	Loss 1.9377 (2.0458)	Prec@(1,5) (45.5%, 76.2%)	
07/04 09:37:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][150/703]	Step 56470	lr 0.1	Loss 2.0733 (2.0519)	Prec@(1,5) (45.1%, 76.3%)	
07/04 09:38:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][200/703]	Step 56520	lr 0.1	Loss 2.2202 (2.0696)	Prec@(1,5) (44.6%, 76.1%)	
07/04 09:38:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][250/703]	Step 56570	lr 0.1	Loss 1.8157 (2.0885)	Prec@(1,5) (44.1%, 75.9%)	
07/04 09:38:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][300/703]	Step 56620	lr 0.1	Loss 1.8957 (2.0950)	Prec@(1,5) (43.8%, 76.0%)	
07/04 09:38:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][350/703]	Step 56670	lr 0.1	Loss 1.9493 (2.0930)	Prec@(1,5) (43.9%, 76.0%)	
07/04 09:38:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][400/703]	Step 56720	lr 0.1	Loss 2.4526 (2.1001)	Prec@(1,5) (43.9%, 75.8%)	
07/04 09:38:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][450/703]	Step 56770	lr 0.1	Loss 2.6292 (2.1048)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:38:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][500/703]	Step 56820	lr 0.1	Loss 2.2469 (2.1076)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:38:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][550/703]	Step 56870	lr 0.1	Loss 2.1823 (2.1132)	Prec@(1,5) (43.6%, 75.6%)	
07/04 09:38:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][600/703]	Step 56920	lr 0.1	Loss 2.5560 (2.1185)	Prec@(1,5) (43.6%, 75.5%)	
07/04 09:38:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][650/703]	Step 56970	lr 0.1	Loss 2.5077 (2.1238)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:38:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][700/703]	Step 57020	lr 0.1	Loss 1.8140 (2.1226)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:38:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [80][703/703]	Step 57023	lr 0.1	Loss 2.3126 (2.1235)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:38:32PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 80/199] Final Prec@1 43.4222%
07/04 09:38:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [80][50/79]	Step 57024	Loss 2.3563	Prec@(1,5) (39.5%, 70.7%)
07/04 09:38:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [80][78/79]	Step 57024	Loss 2.3863	Prec@(1,5) (39.1%, 69.8%)
07/04 09:38:34PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 80/199] Final Prec@1 39.1200%
07/04 09:38:34PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:38:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][50/703]	Step 57074	lr 0.1	Loss 2.1614 (2.1203)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:38:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][100/703]	Step 57124	lr 0.1	Loss 2.3886 (2.1074)	Prec@(1,5) (43.5%, 76.0%)	
07/04 09:38:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][150/703]	Step 57174	lr 0.1	Loss 2.0881 (2.1157)	Prec@(1,5) (43.0%, 75.5%)	
07/04 09:38:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][200/703]	Step 57224	lr 0.1	Loss 1.7940 (2.0929)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:38:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][250/703]	Step 57274	lr 0.1	Loss 2.0401 (2.0959)	Prec@(1,5) (43.7%, 75.8%)	
07/04 09:38:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][300/703]	Step 57324	lr 0.1	Loss 2.1293 (2.0966)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:38:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][350/703]	Step 57374	lr 0.1	Loss 1.9767 (2.1024)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:38:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][400/703]	Step 57424	lr 0.1	Loss 1.9551 (2.1011)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:39:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][450/703]	Step 57474	lr 0.1	Loss 2.3604 (2.1061)	Prec@(1,5) (43.6%, 75.6%)	
07/04 09:39:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][500/703]	Step 57524	lr 0.1	Loss 1.9782 (2.1075)	Prec@(1,5) (43.6%, 75.7%)	
07/04 09:39:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][550/703]	Step 57574	lr 0.1	Loss 1.6081 (2.1077)	Prec@(1,5) (43.6%, 75.7%)	
07/04 09:39:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][600/703]	Step 57624	lr 0.1	Loss 2.1146 (2.1126)	Prec@(1,5) (43.5%, 75.6%)	
07/04 09:39:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][650/703]	Step 57674	lr 0.1	Loss 1.9273 (2.1150)	Prec@(1,5) (43.5%, 75.5%)	
07/04 09:39:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][700/703]	Step 57724	lr 0.1	Loss 1.8555 (2.1164)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:39:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [81][703/703]	Step 57727	lr 0.1	Loss 1.9538 (2.1167)	Prec@(1,5) (43.4%, 75.6%)	
07/04 09:39:19PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 81/199] Final Prec@1 43.4200%
07/04 09:39:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [81][50/79]	Step 57728	Loss 2.3588	Prec@(1,5) (39.8%, 71.3%)
07/04 09:39:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [81][78/79]	Step 57728	Loss 2.3657	Prec@(1,5) (39.9%, 71.2%)
07/04 09:39:20PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 81/199] Final Prec@1 39.9200%
07/04 09:39:21PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:39:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][50/703]	Step 57778	lr 0.1	Loss 2.0694 (2.0991)	Prec@(1,5) (44.2%, 74.8%)	
07/04 09:39:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][100/703]	Step 57828	lr 0.1	Loss 1.8280 (2.0475)	Prec@(1,5) (44.8%, 76.8%)	
07/04 09:39:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][150/703]	Step 57878	lr 0.1	Loss 1.6933 (2.0770)	Prec@(1,5) (44.5%, 76.2%)	
07/04 09:39:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][200/703]	Step 57928	lr 0.1	Loss 2.3985 (2.0807)	Prec@(1,5) (44.4%, 76.3%)	
07/04 09:39:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][250/703]	Step 57978	lr 0.1	Loss 2.2213 (2.0875)	Prec@(1,5) (44.1%, 76.2%)	
07/04 09:39:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][300/703]	Step 58028	lr 0.1	Loss 1.7700 (2.0840)	Prec@(1,5) (44.2%, 76.2%)	
07/04 09:39:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][350/703]	Step 58078	lr 0.1	Loss 2.2706 (2.0833)	Prec@(1,5) (44.1%, 76.2%)	
07/04 09:39:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][400/703]	Step 58128	lr 0.1	Loss 1.9018 (2.0872)	Prec@(1,5) (44.0%, 76.1%)	
07/04 09:39:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][450/703]	Step 58178	lr 0.1	Loss 2.1528 (2.0887)	Prec@(1,5) (43.9%, 76.1%)	
07/04 09:39:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][500/703]	Step 58228	lr 0.1	Loss 2.1146 (2.0918)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:39:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][550/703]	Step 58278	lr 0.1	Loss 2.4284 (2.1021)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:40:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][600/703]	Step 58328	lr 0.1	Loss 2.0815 (2.1056)	Prec@(1,5) (43.7%, 75.6%)	
07/04 09:40:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][650/703]	Step 58378	lr 0.1	Loss 1.9796 (2.1059)	Prec@(1,5) (43.7%, 75.6%)	
07/04 09:40:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][700/703]	Step 58428	lr 0.1	Loss 2.0171 (2.1112)	Prec@(1,5) (43.6%, 75.5%)	
07/04 09:40:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [82][703/703]	Step 58431	lr 0.1	Loss 2.1546 (2.1115)	Prec@(1,5) (43.6%, 75.5%)	
07/04 09:40:07PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 82/199] Final Prec@1 43.6422%
07/04 09:40:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [82][50/79]	Step 58432	Loss 2.5981	Prec@(1,5) (35.4%, 65.2%)
07/04 09:40:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [82][78/79]	Step 58432	Loss 2.5908	Prec@(1,5) (35.6%, 65.8%)
07/04 09:40:08PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 82/199] Final Prec@1 35.6200%
07/04 09:40:08PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:40:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][50/703]	Step 58482	lr 0.1	Loss 2.2337 (2.2126)	Prec@(1,5) (40.6%, 73.7%)	
07/04 09:40:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][100/703]	Step 58532	lr 0.1	Loss 2.0285 (2.1480)	Prec@(1,5) (42.4%, 74.9%)	
07/04 09:40:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][150/703]	Step 58582	lr 0.1	Loss 1.9593 (2.1239)	Prec@(1,5) (43.4%, 75.3%)	
07/04 09:40:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][200/703]	Step 58632	lr 0.1	Loss 2.2538 (2.1090)	Prec@(1,5) (43.6%, 75.6%)	
07/04 09:40:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][250/703]	Step 58682	lr 0.1	Loss 2.3363 (2.1089)	Prec@(1,5) (43.6%, 75.6%)	
07/04 09:40:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][300/703]	Step 58732	lr 0.1	Loss 2.4599 (2.1179)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:40:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][350/703]	Step 58782	lr 0.1	Loss 2.0604 (2.1174)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:40:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][400/703]	Step 58832	lr 0.1	Loss 2.4665 (2.1132)	Prec@(1,5) (43.5%, 75.6%)	
07/04 09:40:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][450/703]	Step 58882	lr 0.1	Loss 2.2700 (2.1214)	Prec@(1,5) (43.3%, 75.4%)	
07/04 09:40:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][500/703]	Step 58932	lr 0.1	Loss 2.3089 (2.1162)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:40:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][550/703]	Step 58982	lr 0.1	Loss 2.0417 (2.1216)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:40:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][600/703]	Step 59032	lr 0.1	Loss 2.0234 (2.1189)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:40:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][650/703]	Step 59082	lr 0.1	Loss 2.4510 (2.1234)	Prec@(1,5) (43.3%, 75.3%)	
07/04 09:40:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][700/703]	Step 59132	lr 0.1	Loss 2.2600 (2.1188)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:40:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [83][703/703]	Step 59135	lr 0.1	Loss 2.0043 (2.1195)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:40:54PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 83/199] Final Prec@1 43.4556%
07/04 09:40:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [83][50/79]	Step 59136	Loss 2.4828	Prec@(1,5) (38.0%, 69.1%)
07/04 09:40:56PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [83][78/79]	Step 59136	Loss 2.4735	Prec@(1,5) (38.3%, 69.3%)
07/04 09:40:56PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 83/199] Final Prec@1 38.3000%
07/04 09:40:56PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:41:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][50/703]	Step 59186	lr 0.1	Loss 2.1847 (2.1382)	Prec@(1,5) (43.4%, 75.0%)	
07/04 09:41:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][100/703]	Step 59236	lr 0.1	Loss 2.6288 (2.0971)	Prec@(1,5) (44.7%, 75.5%)	
07/04 09:41:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][150/703]	Step 59286	lr 0.1	Loss 1.8804 (2.1012)	Prec@(1,5) (44.6%, 75.4%)	
07/04 09:41:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][200/703]	Step 59336	lr 0.1	Loss 2.4763 (2.0947)	Prec@(1,5) (44.3%, 75.8%)	
07/04 09:41:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][250/703]	Step 59386	lr 0.1	Loss 1.7634 (2.1110)	Prec@(1,5) (43.9%, 75.5%)	
07/04 09:41:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][300/703]	Step 59436	lr 0.1	Loss 1.9311 (2.1069)	Prec@(1,5) (43.8%, 75.7%)	
07/04 09:41:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][350/703]	Step 59486	lr 0.1	Loss 2.3327 (2.1138)	Prec@(1,5) (43.7%, 75.5%)	
07/04 09:41:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][400/703]	Step 59536	lr 0.1	Loss 1.9165 (2.1206)	Prec@(1,5) (43.6%, 75.2%)	
07/04 09:41:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][450/703]	Step 59586	lr 0.1	Loss 1.9024 (2.1259)	Prec@(1,5) (43.4%, 75.1%)	
07/04 09:41:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][500/703]	Step 59636	lr 0.1	Loss 2.0331 (2.1222)	Prec@(1,5) (43.5%, 75.2%)	
07/04 09:41:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][550/703]	Step 59686	lr 0.1	Loss 1.7897 (2.1226)	Prec@(1,5) (43.5%, 75.2%)	
07/04 09:41:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][600/703]	Step 59736	lr 0.1	Loss 1.9206 (2.1221)	Prec@(1,5) (43.4%, 75.2%)	
07/04 09:41:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][650/703]	Step 59786	lr 0.1	Loss 2.3040 (2.1231)	Prec@(1,5) (43.4%, 75.2%)	
07/04 09:41:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][700/703]	Step 59836	lr 0.1	Loss 2.4086 (2.1245)	Prec@(1,5) (43.4%, 75.1%)	
07/04 09:41:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [84][703/703]	Step 59839	lr 0.1	Loss 2.1665 (2.1247)	Prec@(1,5) (43.4%, 75.2%)	
07/04 09:41:43PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 84/199] Final Prec@1 43.4378%
07/04 09:41:43PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [84][50/79]	Step 59840	Loss 2.3139	Prec@(1,5) (40.1%, 71.8%)
07/04 09:41:44PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [84][78/79]	Step 59840	Loss 2.2880	Prec@(1,5) (40.3%, 72.6%)
07/04 09:41:44PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 84/199] Final Prec@1 40.2600%
07/04 09:41:44PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:41:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][50/703]	Step 59890	lr 0.1	Loss 1.7960 (2.0666)	Prec@(1,5) (44.9%, 76.6%)	
07/04 09:41:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][100/703]	Step 59940	lr 0.1	Loss 1.8264 (2.0907)	Prec@(1,5) (44.2%, 76.1%)	
07/04 09:41:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][150/703]	Step 59990	lr 0.1	Loss 2.2365 (2.0865)	Prec@(1,5) (44.5%, 76.0%)	
07/04 09:41:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][200/703]	Step 60040	lr 0.1	Loss 1.8385 (2.0831)	Prec@(1,5) (44.5%, 76.1%)	
07/04 09:42:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][250/703]	Step 60090	lr 0.1	Loss 2.1064 (2.0899)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:42:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][300/703]	Step 60140	lr 0.1	Loss 2.2345 (2.0863)	Prec@(1,5) (44.1%, 76.2%)	
07/04 09:42:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][350/703]	Step 60190	lr 0.1	Loss 2.7922 (2.0942)	Prec@(1,5) (43.9%, 76.0%)	
07/04 09:42:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][400/703]	Step 60240	lr 0.1	Loss 2.1129 (2.0909)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:42:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][450/703]	Step 60290	lr 0.1	Loss 2.2612 (2.0973)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:42:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][500/703]	Step 60340	lr 0.1	Loss 2.6358 (2.0970)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:42:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][550/703]	Step 60390	lr 0.1	Loss 2.0651 (2.0943)	Prec@(1,5) (43.9%, 76.0%)	
07/04 09:42:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][600/703]	Step 60440	lr 0.1	Loss 2.2434 (2.0973)	Prec@(1,5) (43.8%, 76.0%)	
07/04 09:42:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][650/703]	Step 60490	lr 0.1	Loss 1.8178 (2.0990)	Prec@(1,5) (43.8%, 75.9%)	
07/04 09:42:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][700/703]	Step 60540	lr 0.1	Loss 1.9909 (2.1009)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:42:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [85][703/703]	Step 60543	lr 0.1	Loss 2.1225 (2.1007)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:42:30PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 85/199] Final Prec@1 43.8556%
07/04 09:42:31PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [85][50/79]	Step 60544	Loss 2.4485	Prec@(1,5) (37.2%, 68.9%)
07/04 09:42:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [85][78/79]	Step 60544	Loss 2.4525	Prec@(1,5) (37.2%, 69.0%)
07/04 09:42:32PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 85/199] Final Prec@1 37.2000%
07/04 09:42:32PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:42:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][50/703]	Step 60594	lr 0.1	Loss 1.8487 (2.1588)	Prec@(1,5) (44.1%, 74.9%)	
07/04 09:42:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][100/703]	Step 60644	lr 0.1	Loss 2.0421 (2.1199)	Prec@(1,5) (44.0%, 75.7%)	
07/04 09:42:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][150/703]	Step 60694	lr 0.1	Loss 1.8736 (2.1140)	Prec@(1,5) (43.8%, 75.7%)	
07/04 09:42:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][200/703]	Step 60744	lr 0.1	Loss 2.1180 (2.1102)	Prec@(1,5) (43.8%, 75.7%)	
07/04 09:42:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][250/703]	Step 60794	lr 0.1	Loss 1.9077 (2.1057)	Prec@(1,5) (43.8%, 75.8%)	
07/04 09:42:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][300/703]	Step 60844	lr 0.1	Loss 2.4462 (2.1032)	Prec@(1,5) (43.8%, 75.7%)	
07/04 09:42:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][350/703]	Step 60894	lr 0.1	Loss 2.2980 (2.1071)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:42:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][400/703]	Step 60944	lr 0.1	Loss 2.3921 (2.1065)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:43:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][450/703]	Step 60994	lr 0.1	Loss 1.8587 (2.1096)	Prec@(1,5) (43.7%, 75.5%)	
07/04 09:43:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][500/703]	Step 61044	lr 0.1	Loss 2.2304 (2.1184)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:43:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][550/703]	Step 61094	lr 0.1	Loss 2.1769 (2.1198)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:43:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][600/703]	Step 61144	lr 0.1	Loss 2.2131 (2.1211)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:43:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][650/703]	Step 61194	lr 0.1	Loss 2.4077 (2.1231)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:43:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][700/703]	Step 61244	lr 0.1	Loss 2.0905 (2.1205)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:43:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [86][703/703]	Step 61247	lr 0.1	Loss 2.3139 (2.1213)	Prec@(1,5) (43.5%, 75.4%)	
07/04 09:43:19PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 86/199] Final Prec@1 43.4933%
07/04 09:43:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [86][50/79]	Step 61248	Loss 2.4667	Prec@(1,5) (38.9%, 69.3%)
07/04 09:43:21PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [86][78/79]	Step 61248	Loss 2.4676	Prec@(1,5) (38.5%, 69.6%)
07/04 09:43:21PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 86/199] Final Prec@1 38.5000%
07/04 09:43:21PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:43:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][50/703]	Step 61298	lr 0.1	Loss 1.9477 (2.1403)	Prec@(1,5) (43.2%, 75.2%)	
07/04 09:43:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][100/703]	Step 61348	lr 0.1	Loss 2.0568 (2.1021)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:43:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][150/703]	Step 61398	lr 0.1	Loss 1.9421 (2.0765)	Prec@(1,5) (44.7%, 76.2%)	
07/04 09:43:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][200/703]	Step 61448	lr 0.1	Loss 2.5060 (2.1056)	Prec@(1,5) (44.0%, 75.8%)	
07/04 09:43:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][250/703]	Step 61498	lr 0.1	Loss 2.2037 (2.1081)	Prec@(1,5) (43.7%, 75.9%)	
07/04 09:43:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][300/703]	Step 61548	lr 0.1	Loss 2.1478 (2.1022)	Prec@(1,5) (44.0%, 76.1%)	
07/04 09:43:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][350/703]	Step 61598	lr 0.1	Loss 2.3082 (2.1072)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:43:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][400/703]	Step 61648	lr 0.1	Loss 2.0887 (2.1156)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:43:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][450/703]	Step 61698	lr 0.1	Loss 2.4152 (2.1211)	Prec@(1,5) (43.5%, 75.7%)	
07/04 09:43:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][500/703]	Step 61748	lr 0.1	Loss 2.0524 (2.1216)	Prec@(1,5) (43.5%, 75.7%)	
07/04 09:43:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][550/703]	Step 61798	lr 0.1	Loss 1.9862 (2.1199)	Prec@(1,5) (43.5%, 75.9%)	
07/04 09:44:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][600/703]	Step 61848	lr 0.1	Loss 1.7718 (2.1167)	Prec@(1,5) (43.6%, 75.9%)	
07/04 09:44:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][650/703]	Step 61898	lr 0.1	Loss 2.0839 (2.1201)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:44:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][700/703]	Step 61948	lr 0.1	Loss 1.9454 (2.1198)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:44:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [87][703/703]	Step 61951	lr 0.1	Loss 2.1447 (2.1196)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:44:07PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 87/199] Final Prec@1 43.4889%
07/04 09:44:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [87][50/79]	Step 61952	Loss 2.5159	Prec@(1,5) (35.5%, 67.9%)
07/04 09:44:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [87][78/79]	Step 61952	Loss 2.5230	Prec@(1,5) (35.7%, 67.9%)
07/04 09:44:09PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 87/199] Final Prec@1 35.7200%
07/04 09:44:09PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:44:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][50/703]	Step 62002	lr 0.1	Loss 2.1071 (2.2140)	Prec@(1,5) (40.1%, 74.2%)	
07/04 09:44:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][100/703]	Step 62052	lr 0.1	Loss 2.1215 (2.1526)	Prec@(1,5) (42.0%, 75.6%)	
07/04 09:44:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][150/703]	Step 62102	lr 0.1	Loss 2.0600 (2.1289)	Prec@(1,5) (42.8%, 75.9%)	
07/04 09:44:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][200/703]	Step 62152	lr 0.1	Loss 2.3348 (2.1189)	Prec@(1,5) (42.9%, 75.8%)	
07/04 09:44:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][250/703]	Step 62202	lr 0.1	Loss 2.0816 (2.1087)	Prec@(1,5) (43.4%, 75.9%)	
07/04 09:44:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][300/703]	Step 62252	lr 0.1	Loss 2.2296 (2.1039)	Prec@(1,5) (43.4%, 76.0%)	
07/04 09:44:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][350/703]	Step 62302	lr 0.1	Loss 2.0808 (2.1041)	Prec@(1,5) (43.4%, 76.0%)	
07/04 09:44:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][400/703]	Step 62352	lr 0.1	Loss 2.4752 (2.1124)	Prec@(1,5) (43.3%, 75.8%)	
07/04 09:44:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][450/703]	Step 62402	lr 0.1	Loss 2.0191 (2.1127)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:44:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][500/703]	Step 62452	lr 0.1	Loss 2.2941 (2.1175)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:44:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][550/703]	Step 62502	lr 0.1	Loss 1.9961 (2.1181)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:44:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][600/703]	Step 62552	lr 0.1	Loss 2.0443 (2.1142)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:44:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][650/703]	Step 62602	lr 0.1	Loss 1.7837 (2.1154)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:44:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][700/703]	Step 62652	lr 0.1	Loss 2.1986 (2.1167)	Prec@(1,5) (43.5%, 75.7%)	
07/04 09:44:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [88][703/703]	Step 62655	lr 0.1	Loss 1.9751 (2.1160)	Prec@(1,5) (43.5%, 75.7%)	
07/04 09:44:54PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 88/199] Final Prec@1 43.5400%
07/04 09:44:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [88][50/79]	Step 62656	Loss 2.4413	Prec@(1,5) (37.5%, 68.2%)
07/04 09:44:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [88][78/79]	Step 62656	Loss 2.4351	Prec@(1,5) (38.2%, 68.6%)
07/04 09:44:55PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 88/199] Final Prec@1 38.2400%
07/04 09:44:56PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:44:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][50/703]	Step 62706	lr 0.1	Loss 2.0830 (2.0899)	Prec@(1,5) (45.1%, 76.2%)	
07/04 09:45:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][100/703]	Step 62756	lr 0.1	Loss 2.0864 (2.0719)	Prec@(1,5) (45.1%, 76.7%)	
07/04 09:45:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][150/703]	Step 62806	lr 0.1	Loss 1.9436 (2.0670)	Prec@(1,5) (45.2%, 76.7%)	
07/04 09:45:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][200/703]	Step 62856	lr 0.1	Loss 1.5961 (2.0603)	Prec@(1,5) (45.1%, 76.7%)	
07/04 09:45:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][250/703]	Step 62906	lr 0.1	Loss 2.7797 (2.0677)	Prec@(1,5) (44.9%, 76.5%)	
07/04 09:45:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][300/703]	Step 62956	lr 0.1	Loss 2.2807 (2.0808)	Prec@(1,5) (44.5%, 76.3%)	
07/04 09:45:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][350/703]	Step 63006	lr 0.1	Loss 2.3277 (2.0775)	Prec@(1,5) (44.5%, 76.3%)	
07/04 09:45:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][400/703]	Step 63056	lr 0.1	Loss 1.8553 (2.0815)	Prec@(1,5) (44.3%, 76.3%)	
07/04 09:45:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][450/703]	Step 63106	lr 0.1	Loss 2.1444 (2.0876)	Prec@(1,5) (44.2%, 76.2%)	
07/04 09:45:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][500/703]	Step 63156	lr 0.1	Loss 1.9141 (2.0930)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:45:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][550/703]	Step 63206	lr 0.1	Loss 2.2489 (2.0940)	Prec@(1,5) (44.0%, 76.0%)	
07/04 09:45:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][600/703]	Step 63256	lr 0.1	Loss 2.2260 (2.0966)	Prec@(1,5) (43.9%, 76.0%)	
07/04 09:45:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][650/703]	Step 63306	lr 0.1	Loss 2.3619 (2.1034)	Prec@(1,5) (43.8%, 75.8%)	
07/04 09:45:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][700/703]	Step 63356	lr 0.1	Loss 2.2692 (2.1030)	Prec@(1,5) (43.8%, 75.8%)	
07/04 09:45:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [89][703/703]	Step 63359	lr 0.1	Loss 2.2716 (2.1035)	Prec@(1,5) (43.8%, 75.8%)	
07/04 09:45:41PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 89/199] Final Prec@1 43.8200%
07/04 09:45:42PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [89][50/79]	Step 63360	Loss 2.3796	Prec@(1,5) (39.2%, 70.7%)
07/04 09:45:42PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [89][78/79]	Step 63360	Loss 2.3803	Prec@(1,5) (39.3%, 70.8%)
07/04 09:45:42PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 89/199] Final Prec@1 39.3000%
07/04 09:45:42PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:45:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][50/703]	Step 63410	lr 0.1	Loss 1.9748 (2.1416)	Prec@(1,5) (42.7%, 75.3%)	
07/04 09:45:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][100/703]	Step 63460	lr 0.1	Loss 2.0154 (2.1091)	Prec@(1,5) (43.4%, 76.0%)	
07/04 09:45:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][150/703]	Step 63510	lr 0.1	Loss 2.2781 (2.1091)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:45:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][200/703]	Step 63560	lr 0.1	Loss 2.2721 (2.1241)	Prec@(1,5) (43.1%, 75.4%)	
07/04 09:45:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][250/703]	Step 63610	lr 0.1	Loss 2.2844 (2.1170)	Prec@(1,5) (43.2%, 75.6%)	
07/04 09:46:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][300/703]	Step 63660	lr 0.1	Loss 2.2195 (2.1234)	Prec@(1,5) (43.1%, 75.4%)	
07/04 09:46:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][350/703]	Step 63710	lr 0.1	Loss 2.2880 (2.1199)	Prec@(1,5) (43.3%, 75.5%)	
07/04 09:46:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][400/703]	Step 63760	lr 0.1	Loss 1.7524 (2.1177)	Prec@(1,5) (43.4%, 75.5%)	
07/04 09:46:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][450/703]	Step 63810	lr 0.1	Loss 2.1739 (2.1197)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:46:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][500/703]	Step 63860	lr 0.1	Loss 2.1664 (2.1196)	Prec@(1,5) (43.5%, 75.3%)	
07/04 09:46:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][550/703]	Step 63910	lr 0.1	Loss 2.3625 (2.1204)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:46:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][600/703]	Step 63960	lr 0.1	Loss 1.9662 (2.1215)	Prec@(1,5) (43.4%, 75.3%)	
07/04 09:46:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][650/703]	Step 64010	lr 0.1	Loss 2.5540 (2.1231)	Prec@(1,5) (43.3%, 75.3%)	
07/04 09:46:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][700/703]	Step 64060	lr 0.1	Loss 1.8904 (2.1228)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:46:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [90][703/703]	Step 64063	lr 0.1	Loss 1.8243 (2.1221)	Prec@(1,5) (43.4%, 75.4%)	
07/04 09:46:29PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 90/199] Final Prec@1 43.3822%
07/04 09:46:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [90][50/79]	Step 64064	Loss 2.4088	Prec@(1,5) (38.0%, 69.6%)
07/04 09:46:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [90][78/79]	Step 64064	Loss 2.4022	Prec@(1,5) (38.4%, 69.9%)
07/04 09:46:31PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 90/199] Final Prec@1 38.3800%
07/04 09:46:31PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:46:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][50/703]	Step 64114	lr 0.1	Loss 1.9855 (2.1005)	Prec@(1,5) (43.6%, 76.7%)	
07/04 09:46:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][100/703]	Step 64164	lr 0.1	Loss 1.9265 (2.0855)	Prec@(1,5) (43.9%, 76.9%)	
07/04 09:46:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][150/703]	Step 64214	lr 0.1	Loss 1.8626 (2.0738)	Prec@(1,5) (43.9%, 76.7%)	
07/04 09:46:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][200/703]	Step 64264	lr 0.1	Loss 2.0448 (2.0720)	Prec@(1,5) (44.3%, 76.4%)	
07/04 09:46:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][250/703]	Step 64314	lr 0.1	Loss 2.3305 (2.0796)	Prec@(1,5) (44.2%, 76.3%)	
07/04 09:46:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][300/703]	Step 64364	lr 0.1	Loss 1.9481 (2.0856)	Prec@(1,5) (44.2%, 76.3%)	
07/04 09:46:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][350/703]	Step 64414	lr 0.1	Loss 2.3785 (2.0834)	Prec@(1,5) (44.3%, 76.3%)	
07/04 09:46:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][400/703]	Step 64464	lr 0.1	Loss 1.9695 (2.0824)	Prec@(1,5) (44.4%, 76.2%)	
07/04 09:47:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][450/703]	Step 64514	lr 0.1	Loss 2.1418 (2.0873)	Prec@(1,5) (44.2%, 76.1%)	
07/04 09:47:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][500/703]	Step 64564	lr 0.1	Loss 2.1336 (2.0931)	Prec@(1,5) (44.1%, 75.9%)	
07/04 09:47:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][550/703]	Step 64614	lr 0.1	Loss 2.3371 (2.0928)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:47:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][600/703]	Step 64664	lr 0.1	Loss 2.1767 (2.0991)	Prec@(1,5) (44.0%, 75.8%)	
07/04 09:47:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][650/703]	Step 64714	lr 0.1	Loss 1.9861 (2.1028)	Prec@(1,5) (43.9%, 75.8%)	
07/04 09:47:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][700/703]	Step 64764	lr 0.1	Loss 2.2241 (2.1054)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:47:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [91][703/703]	Step 64767	lr 0.1	Loss 2.2886 (2.1055)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:47:16PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 91/199] Final Prec@1 43.9022%
07/04 09:47:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [91][50/79]	Step 64768	Loss 2.3423	Prec@(1,5) (39.5%, 71.2%)
07/04 09:47:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [91][78/79]	Step 64768	Loss 2.3225	Prec@(1,5) (40.0%, 71.7%)
07/04 09:47:17PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 91/199] Final Prec@1 40.0000%
07/04 09:47:17PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:47:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][50/703]	Step 64818	lr 0.1	Loss 1.8525 (2.0287)	Prec@(1,5) (45.3%, 77.3%)	
07/04 09:47:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][100/703]	Step 64868	lr 0.1	Loss 2.1766 (2.0472)	Prec@(1,5) (45.3%, 76.8%)	
07/04 09:47:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][150/703]	Step 64918	lr 0.1	Loss 1.8712 (2.0538)	Prec@(1,5) (45.3%, 76.7%)	
07/04 09:47:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][200/703]	Step 64968	lr 0.1	Loss 2.2015 (2.0623)	Prec@(1,5) (45.2%, 76.6%)	
07/04 09:47:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][250/703]	Step 65018	lr 0.1	Loss 2.0548 (2.0848)	Prec@(1,5) (44.7%, 76.3%)	
07/04 09:47:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][300/703]	Step 65068	lr 0.1	Loss 2.0275 (2.0868)	Prec@(1,5) (44.6%, 76.0%)	
07/04 09:47:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][350/703]	Step 65118	lr 0.1	Loss 1.9574 (2.0894)	Prec@(1,5) (44.4%, 75.8%)	
07/04 09:47:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][400/703]	Step 65168	lr 0.1	Loss 2.2524 (2.0963)	Prec@(1,5) (44.1%, 75.8%)	
07/04 09:47:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][450/703]	Step 65218	lr 0.1	Loss 2.0445 (2.1013)	Prec@(1,5) (44.0%, 75.8%)	
07/04 09:47:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][500/703]	Step 65268	lr 0.1	Loss 1.9841 (2.1039)	Prec@(1,5) (44.0%, 75.7%)	
07/04 09:47:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][550/703]	Step 65318	lr 0.1	Loss 2.0035 (2.1072)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:47:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][600/703]	Step 65368	lr 0.1	Loss 2.0922 (2.1089)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:48:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][650/703]	Step 65418	lr 0.1	Loss 2.1026 (2.1148)	Prec@(1,5) (43.8%, 75.5%)	
07/04 09:48:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][700/703]	Step 65468	lr 0.1	Loss 2.6532 (2.1105)	Prec@(1,5) (43.9%, 75.6%)	
07/04 09:48:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [92][703/703]	Step 65471	lr 0.1	Loss 1.8606 (2.1107)	Prec@(1,5) (43.9%, 75.6%)	
07/04 09:48:03PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 92/199] Final Prec@1 43.9067%
07/04 09:48:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [92][50/79]	Step 65472	Loss 2.3670	Prec@(1,5) (39.2%, 70.8%)
07/04 09:48:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [92][78/79]	Step 65472	Loss 2.3820	Prec@(1,5) (39.1%, 70.8%)
07/04 09:48:05PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 92/199] Final Prec@1 39.0800%
07/04 09:48:05PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:48:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][50/703]	Step 65522	lr 0.1	Loss 2.0127 (2.1670)	Prec@(1,5) (42.3%, 75.3%)	
07/04 09:48:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][100/703]	Step 65572	lr 0.1	Loss 2.1133 (2.1207)	Prec@(1,5) (42.8%, 75.8%)	
07/04 09:48:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][150/703]	Step 65622	lr 0.1	Loss 2.2648 (2.0955)	Prec@(1,5) (43.5%, 76.3%)	
07/04 09:48:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][200/703]	Step 65672	lr 0.1	Loss 1.9747 (2.0862)	Prec@(1,5) (43.7%, 76.4%)	
07/04 09:48:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][250/703]	Step 65722	lr 0.1	Loss 2.1544 (2.0875)	Prec@(1,5) (43.7%, 76.2%)	
07/04 09:48:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][300/703]	Step 65772	lr 0.1	Loss 1.8383 (2.0855)	Prec@(1,5) (43.9%, 76.2%)	
07/04 09:48:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][350/703]	Step 65822	lr 0.1	Loss 2.5365 (2.0809)	Prec@(1,5) (43.9%, 76.3%)	
07/04 09:48:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][400/703]	Step 65872	lr 0.1	Loss 1.8708 (2.0840)	Prec@(1,5) (43.9%, 76.3%)	
07/04 09:48:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][450/703]	Step 65922	lr 0.1	Loss 2.0177 (2.0948)	Prec@(1,5) (43.6%, 76.2%)	
07/04 09:48:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][500/703]	Step 65972	lr 0.1	Loss 2.0610 (2.0966)	Prec@(1,5) (43.5%, 76.1%)	
07/04 09:48:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][550/703]	Step 66022	lr 0.1	Loss 1.7951 (2.0969)	Prec@(1,5) (43.6%, 76.1%)	
07/04 09:48:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][600/703]	Step 66072	lr 0.1	Loss 2.3972 (2.1012)	Prec@(1,5) (43.6%, 76.0%)	
07/04 09:48:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][650/703]	Step 66122	lr 0.1	Loss 1.8107 (2.1082)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:48:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][700/703]	Step 66172	lr 0.1	Loss 2.0988 (2.1124)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:48:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [93][703/703]	Step 66175	lr 0.1	Loss 2.1930 (2.1124)	Prec@(1,5) (43.4%, 75.7%)	
07/04 09:48:50PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 93/199] Final Prec@1 43.4200%
07/04 09:48:51PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [93][50/79]	Step 66176	Loss 2.4147	Prec@(1,5) (38.2%, 71.2%)
07/04 09:48:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [93][78/79]	Step 66176	Loss 2.4290	Prec@(1,5) (38.1%, 70.5%)
07/04 09:48:52PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 93/199] Final Prec@1 38.0600%
07/04 09:48:52PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:48:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][50/703]	Step 66226	lr 0.1	Loss 2.1303 (2.1381)	Prec@(1,5) (42.6%, 75.9%)	
07/04 09:48:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][100/703]	Step 66276	lr 0.1	Loss 1.9543 (2.1182)	Prec@(1,5) (43.1%, 76.1%)	
07/04 09:49:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][150/703]	Step 66326	lr 0.1	Loss 1.9274 (2.1162)	Prec@(1,5) (43.3%, 76.1%)	
07/04 09:49:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][200/703]	Step 66376	lr 0.1	Loss 2.2414 (2.0955)	Prec@(1,5) (43.5%, 76.4%)	
07/04 09:49:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][250/703]	Step 66426	lr 0.1	Loss 2.4457 (2.0998)	Prec@(1,5) (43.6%, 76.0%)	
07/04 09:49:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][300/703]	Step 66476	lr 0.1	Loss 2.3510 (2.1002)	Prec@(1,5) (43.7%, 75.9%)	
07/04 09:49:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][350/703]	Step 66526	lr 0.1	Loss 2.0541 (2.1020)	Prec@(1,5) (43.7%, 75.9%)	
07/04 09:49:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][400/703]	Step 66576	lr 0.1	Loss 2.2546 (2.1049)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:49:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][450/703]	Step 66626	lr 0.1	Loss 2.7671 (2.1057)	Prec@(1,5) (43.7%, 75.8%)	
07/04 09:49:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][500/703]	Step 66676	lr 0.1	Loss 1.8696 (2.1092)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:49:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][550/703]	Step 66726	lr 0.1	Loss 1.7687 (2.1067)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:49:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][600/703]	Step 66776	lr 0.1	Loss 1.9304 (2.1104)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:49:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][650/703]	Step 66826	lr 0.1	Loss 2.1948 (2.1071)	Prec@(1,5) (43.5%, 75.8%)	
07/04 09:49:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][700/703]	Step 66876	lr 0.1	Loss 2.2316 (2.1103)	Prec@(1,5) (43.6%, 75.8%)	
07/04 09:49:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [94][703/703]	Step 66879	lr 0.1	Loss 2.1789 (2.1110)	Prec@(1,5) (43.6%, 75.7%)	
07/04 09:49:37PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 94/199] Final Prec@1 43.5822%
07/04 09:49:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [94][50/79]	Step 66880	Loss 2.3083	Prec@(1,5) (41.2%, 71.7%)
07/04 09:49:39PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [94][78/79]	Step 66880	Loss 2.3031	Prec@(1,5) (40.9%, 72.1%)
07/04 09:49:39PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 94/199] Final Prec@1 40.9400%
07/04 09:49:39PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:49:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][50/703]	Step 66930	lr 0.1	Loss 2.1103 (2.0031)	Prec@(1,5) (46.3%, 77.3%)	
07/04 09:49:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][100/703]	Step 66980	lr 0.1	Loss 2.5398 (2.0535)	Prec@(1,5) (44.6%, 76.3%)	
07/04 09:49:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][150/703]	Step 67030	lr 0.1	Loss 2.3586 (2.0691)	Prec@(1,5) (44.2%, 76.2%)	
07/04 09:49:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][200/703]	Step 67080	lr 0.1	Loss 1.9841 (2.0704)	Prec@(1,5) (44.0%, 76.4%)	
07/04 09:49:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][250/703]	Step 67130	lr 0.1	Loss 2.3958 (2.0859)	Prec@(1,5) (43.7%, 76.1%)	
07/04 09:49:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][300/703]	Step 67180	lr 0.1	Loss 2.2348 (2.0975)	Prec@(1,5) (43.7%, 75.7%)	
07/04 09:50:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][350/703]	Step 67230	lr 0.1	Loss 2.0256 (2.0913)	Prec@(1,5) (44.0%, 75.8%)	
07/04 09:50:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][400/703]	Step 67280	lr 0.1	Loss 2.0323 (2.0884)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:50:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][450/703]	Step 67330	lr 0.1	Loss 2.4616 (2.0949)	Prec@(1,5) (44.0%, 75.7%)	
07/04 09:50:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][500/703]	Step 67380	lr 0.1	Loss 1.7720 (2.0953)	Prec@(1,5) (44.1%, 75.7%)	
07/04 09:50:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][550/703]	Step 67430	lr 0.1	Loss 2.4051 (2.0961)	Prec@(1,5) (44.0%, 75.7%)	
07/04 09:50:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][600/703]	Step 67480	lr 0.1	Loss 2.0829 (2.1007)	Prec@(1,5) (43.9%, 75.6%)	
07/04 09:50:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][650/703]	Step 67530	lr 0.1	Loss 2.0484 (2.1009)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:50:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][700/703]	Step 67580	lr 0.1	Loss 1.7092 (2.1029)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:50:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [95][703/703]	Step 67583	lr 0.1	Loss 2.0298 (2.1025)	Prec@(1,5) (43.8%, 75.6%)	
07/04 09:50:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 95/199] Final Prec@1 43.7844%
07/04 09:50:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [95][50/79]	Step 67584	Loss 2.3446	Prec@(1,5) (39.2%, 71.8%)
07/04 09:50:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [95][78/79]	Step 67584	Loss 2.3425	Prec@(1,5) (39.6%, 71.8%)
07/04 09:50:27PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 95/199] Final Prec@1 39.5800%
07/04 09:50:27PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:50:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][50/703]	Step 67634	lr 0.1	Loss 2.0770 (2.1074)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:50:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][100/703]	Step 67684	lr 0.1	Loss 2.3185 (2.0947)	Prec@(1,5) (43.7%, 76.2%)	
07/04 09:50:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][150/703]	Step 67734	lr 0.1	Loss 2.3485 (2.0797)	Prec@(1,5) (44.4%, 76.5%)	
07/04 09:50:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][200/703]	Step 67784	lr 0.1	Loss 1.9895 (2.0741)	Prec@(1,5) (44.3%, 76.6%)	
07/04 09:50:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][250/703]	Step 67834	lr 0.1	Loss 2.3931 (2.0715)	Prec@(1,5) (44.3%, 76.6%)	
07/04 09:50:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][300/703]	Step 67884	lr 0.1	Loss 2.3351 (2.0776)	Prec@(1,5) (44.1%, 76.6%)	
07/04 09:50:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][350/703]	Step 67934	lr 0.1	Loss 2.2822 (2.0803)	Prec@(1,5) (44.1%, 76.5%)	
07/04 09:50:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][400/703]	Step 67984	lr 0.1	Loss 1.8142 (2.0848)	Prec@(1,5) (44.0%, 76.4%)	
07/04 09:50:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][450/703]	Step 68034	lr 0.1	Loss 1.9877 (2.0851)	Prec@(1,5) (44.0%, 76.6%)	
07/04 09:50:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][500/703]	Step 68084	lr 0.1	Loss 2.4267 (2.0908)	Prec@(1,5) (44.0%, 76.4%)	
07/04 09:51:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][550/703]	Step 68134	lr 0.1	Loss 2.5060 (2.0966)	Prec@(1,5) (44.0%, 76.3%)	
07/04 09:51:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][600/703]	Step 68184	lr 0.1	Loss 2.0669 (2.0921)	Prec@(1,5) (44.0%, 76.4%)	
07/04 09:51:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][650/703]	Step 68234	lr 0.1	Loss 1.9495 (2.0967)	Prec@(1,5) (43.8%, 76.3%)	
07/04 09:51:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][700/703]	Step 68284	lr 0.1	Loss 2.0086 (2.0983)	Prec@(1,5) (43.7%, 76.3%)	
07/04 09:51:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [96][703/703]	Step 68287	lr 0.1	Loss 2.2847 (2.0982)	Prec@(1,5) (43.7%, 76.3%)	
07/04 09:51:12PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 96/199] Final Prec@1 43.7156%
07/04 09:51:13PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [96][50/79]	Step 68288	Loss 2.3974	Prec@(1,5) (39.7%, 70.1%)
07/04 09:51:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [96][78/79]	Step 68288	Loss 2.3927	Prec@(1,5) (39.6%, 69.7%)
07/04 09:51:14PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 96/199] Final Prec@1 39.5200%
07/04 09:51:14PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:51:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][50/703]	Step 68338	lr 0.1	Loss 1.8886 (2.0434)	Prec@(1,5) (45.7%, 77.7%)	
07/04 09:51:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][100/703]	Step 68388	lr 0.1	Loss 2.1299 (2.0404)	Prec@(1,5) (45.4%, 77.4%)	
07/04 09:51:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][150/703]	Step 68438	lr 0.1	Loss 2.2072 (2.0638)	Prec@(1,5) (45.0%, 77.1%)	
07/04 09:51:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][200/703]	Step 68488	lr 0.1	Loss 2.2481 (2.0692)	Prec@(1,5) (44.8%, 77.0%)	
07/04 09:51:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][250/703]	Step 68538	lr 0.1	Loss 2.1301 (2.0679)	Prec@(1,5) (44.8%, 76.9%)	
07/04 09:51:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][300/703]	Step 68588	lr 0.1	Loss 2.2590 (2.0786)	Prec@(1,5) (44.5%, 76.6%)	
07/04 09:51:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][350/703]	Step 68638	lr 0.1	Loss 2.3254 (2.0865)	Prec@(1,5) (44.2%, 76.3%)	
07/04 09:51:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][400/703]	Step 68688	lr 0.1	Loss 2.6088 (2.0890)	Prec@(1,5) (44.0%, 76.2%)	
07/04 09:51:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][450/703]	Step 68738	lr 0.1	Loss 1.6775 (2.0873)	Prec@(1,5) (44.1%, 76.2%)	
07/04 09:51:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][500/703]	Step 68788	lr 0.1	Loss 2.4605 (2.0870)	Prec@(1,5) (44.1%, 76.2%)	
07/04 09:51:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][550/703]	Step 68838	lr 0.1	Loss 2.1822 (2.0893)	Prec@(1,5) (44.1%, 76.1%)	
07/04 09:51:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][600/703]	Step 68888	lr 0.1	Loss 1.9406 (2.0914)	Prec@(1,5) (44.0%, 76.0%)	
07/04 09:51:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][650/703]	Step 68938	lr 0.1	Loss 2.3663 (2.0906)	Prec@(1,5) (44.0%, 76.0%)	
07/04 09:51:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][700/703]	Step 68988	lr 0.1	Loss 2.2019 (2.0943)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:51:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [97][703/703]	Step 68991	lr 0.1	Loss 2.4943 (2.0949)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:52:00PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 97/199] Final Prec@1 43.9489%
07/04 09:52:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [97][50/79]	Step 68992	Loss 2.3003	Prec@(1,5) (40.8%, 71.4%)
07/04 09:52:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [97][78/79]	Step 68992	Loss 2.3320	Prec@(1,5) (40.3%, 71.0%)
07/04 09:52:01PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 97/199] Final Prec@1 40.2200%
07/04 09:52:02PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:52:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][50/703]	Step 69042	lr 0.1	Loss 2.1046 (2.0994)	Prec@(1,5) (43.2%, 75.8%)	
07/04 09:52:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][100/703]	Step 69092	lr 0.1	Loss 1.8979 (2.0869)	Prec@(1,5) (43.2%, 76.2%)	
07/04 09:52:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][150/703]	Step 69142	lr 0.1	Loss 2.1044 (2.1027)	Prec@(1,5) (43.4%, 75.8%)	
07/04 09:52:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][200/703]	Step 69192	lr 0.1	Loss 2.4037 (2.1038)	Prec@(1,5) (43.7%, 75.8%)	
07/04 09:52:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][250/703]	Step 69242	lr 0.1	Loss 1.9127 (2.0915)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:52:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][300/703]	Step 69292	lr 0.1	Loss 2.4583 (2.0853)	Prec@(1,5) (44.2%, 76.2%)	
07/04 09:52:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][350/703]	Step 69342	lr 0.1	Loss 2.3355 (2.0884)	Prec@(1,5) (44.2%, 76.2%)	
07/04 09:52:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][400/703]	Step 69392	lr 0.1	Loss 2.0209 (2.0946)	Prec@(1,5) (44.0%, 76.0%)	
07/04 09:52:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][450/703]	Step 69442	lr 0.1	Loss 2.0179 (2.1040)	Prec@(1,5) (43.8%, 75.8%)	
07/04 09:52:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][500/703]	Step 69492	lr 0.1	Loss 2.0790 (2.1043)	Prec@(1,5) (43.9%, 75.8%)	
07/04 09:52:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][550/703]	Step 69542	lr 0.1	Loss 1.8353 (2.1033)	Prec@(1,5) (43.9%, 75.9%)	
07/04 09:52:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][600/703]	Step 69592	lr 0.1	Loss 1.8174 (2.1074)	Prec@(1,5) (43.9%, 75.8%)	
07/04 09:52:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][650/703]	Step 69642	lr 0.1	Loss 2.1019 (2.1095)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:52:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][700/703]	Step 69692	lr 0.1	Loss 2.2245 (2.1083)	Prec@(1,5) (43.9%, 75.8%)	
07/04 09:52:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [98][703/703]	Step 69695	lr 0.1	Loss 2.8005 (2.1094)	Prec@(1,5) (43.9%, 75.7%)	
07/04 09:52:47PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 98/199] Final Prec@1 43.9067%
07/04 09:52:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [98][50/79]	Step 69696	Loss 2.3579	Prec@(1,5) (40.0%, 72.1%)
07/04 09:52:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [98][78/79]	Step 69696	Loss 2.3847	Prec@(1,5) (39.1%, 71.4%)
07/04 09:52:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 98/199] Final Prec@1 39.0600%
07/04 09:52:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:52:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][50/703]	Step 69746	lr 0.1	Loss 2.1649 (2.0501)	Prec@(1,5) (44.2%, 77.0%)	
07/04 09:52:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][100/703]	Step 69796	lr 0.1	Loss 1.8930 (2.0914)	Prec@(1,5) (43.8%, 76.2%)	
07/04 09:52:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][150/703]	Step 69846	lr 0.1	Loss 1.7204 (2.0716)	Prec@(1,5) (44.2%, 76.5%)	
07/04 09:53:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][200/703]	Step 69896	lr 0.1	Loss 2.3518 (2.0725)	Prec@(1,5) (44.4%, 76.4%)	
07/04 09:53:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][250/703]	Step 69946	lr 0.1	Loss 2.4675 (2.0925)	Prec@(1,5) (44.0%, 76.0%)	
07/04 09:53:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][300/703]	Step 69996	lr 0.1	Loss 2.3444 (2.0818)	Prec@(1,5) (44.2%, 76.0%)	
07/04 09:53:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][350/703]	Step 70046	lr 0.1	Loss 2.2372 (2.0832)	Prec@(1,5) (44.2%, 75.9%)	
07/04 09:53:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][400/703]	Step 70096	lr 0.1	Loss 1.9245 (2.0799)	Prec@(1,5) (44.3%, 76.1%)	
07/04 09:53:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][450/703]	Step 70146	lr 0.1	Loss 2.9826 (2.0919)	Prec@(1,5) (44.1%, 75.9%)	
07/04 09:53:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][500/703]	Step 70196	lr 0.1	Loss 2.2590 (2.0890)	Prec@(1,5) (44.1%, 75.9%)	
07/04 09:53:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][550/703]	Step 70246	lr 0.1	Loss 1.9812 (2.0891)	Prec@(1,5) (44.2%, 76.0%)	
07/04 09:53:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][600/703]	Step 70296	lr 0.1	Loss 2.2364 (2.0953)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:53:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][650/703]	Step 70346	lr 0.1	Loss 1.9150 (2.0943)	Prec@(1,5) (44.1%, 76.0%)	
07/04 09:53:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][700/703]	Step 70396	lr 0.1	Loss 2.1834 (2.0993)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:53:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [99][703/703]	Step 70399	lr 0.1	Loss 2.1240 (2.0996)	Prec@(1,5) (44.0%, 75.9%)	
07/04 09:53:34PM finetuneTeacher_trainer.py:185 [INFO] Train: [ 99/199] Final Prec@1 43.9533%
07/04 09:53:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [99][50/79]	Step 70400	Loss 2.3019	Prec@(1,5) (41.3%, 72.3%)
07/04 09:53:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [99][78/79]	Step 70400	Loss 2.3225	Prec@(1,5) (40.9%, 72.0%)
07/04 09:53:36PM finetuneTeacher_trainer.py:220 [INFO] Valid: [ 99/199] Final Prec@1 40.9400%
07/04 09:53:36PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 41.1000%
07/04 09:53:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][50/703]	Step 70450	lr 0.01	Loss 1.9806 (1.9314)	Prec@(1,5) (48.1%, 78.5%)	
07/04 09:53:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][100/703]	Step 70500	lr 0.01	Loss 1.5297 (1.8445)	Prec@(1,5) (50.5%, 80.3%)	
07/04 09:53:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][150/703]	Step 70550	lr 0.01	Loss 1.5500 (1.7776)	Prec@(1,5) (51.9%, 81.5%)	
07/04 09:53:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][200/703]	Step 70600	lr 0.01	Loss 1.6136 (1.7416)	Prec@(1,5) (52.8%, 82.1%)	
07/04 09:53:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][250/703]	Step 70650	lr 0.01	Loss 1.9699 (1.7248)	Prec@(1,5) (53.1%, 82.4%)	
07/04 09:53:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][300/703]	Step 70700	lr 0.01	Loss 1.3937 (1.7025)	Prec@(1,5) (53.6%, 82.8%)	
07/04 09:54:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][350/703]	Step 70750	lr 0.01	Loss 1.5771 (1.6817)	Prec@(1,5) (54.0%, 83.1%)	
07/04 09:54:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][400/703]	Step 70800	lr 0.01	Loss 1.4126 (1.6693)	Prec@(1,5) (54.3%, 83.2%)	
07/04 09:54:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][450/703]	Step 70850	lr 0.01	Loss 1.7842 (1.6570)	Prec@(1,5) (54.6%, 83.5%)	
07/04 09:54:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][500/703]	Step 70900	lr 0.01	Loss 1.4991 (1.6444)	Prec@(1,5) (54.8%, 83.7%)	
07/04 09:54:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][550/703]	Step 70950	lr 0.01	Loss 1.7797 (1.6361)	Prec@(1,5) (55.0%, 83.8%)	
07/04 09:54:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][600/703]	Step 71000	lr 0.01	Loss 1.8635 (1.6238)	Prec@(1,5) (55.3%, 84.0%)	
07/04 09:54:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][650/703]	Step 71050	lr 0.01	Loss 1.4888 (1.6150)	Prec@(1,5) (55.5%, 84.2%)	
07/04 09:54:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][700/703]	Step 71100	lr 0.01	Loss 1.4845 (1.6086)	Prec@(1,5) (55.6%, 84.3%)	
07/04 09:54:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [100][703/703]	Step 71103	lr 0.01	Loss 1.5307 (1.6083)	Prec@(1,5) (55.6%, 84.3%)	
07/04 09:54:22PM finetuneTeacher_trainer.py:185 [INFO] Train: [100/199] Final Prec@1 55.6222%
07/04 09:54:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [100][50/79]	Step 71104	Loss 1.7297	Prec@(1,5) (53.5%, 81.4%)
07/04 09:54:24PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [100][78/79]	Step 71104	Loss 1.7104	Prec@(1,5) (53.5%, 81.9%)
07/04 09:54:24PM finetuneTeacher_trainer.py:220 [INFO] Valid: [100/199] Final Prec@1 53.5200%
07/04 09:54:24PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 53.5200%
07/04 09:54:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][50/703]	Step 71154	lr 0.01	Loss 1.5419 (1.4546)	Prec@(1,5) (59.5%, 86.3%)	
07/04 09:54:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][100/703]	Step 71204	lr 0.01	Loss 1.1452 (1.4370)	Prec@(1,5) (60.2%, 86.6%)	
07/04 09:54:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][150/703]	Step 71254	lr 0.01	Loss 1.7692 (1.4378)	Prec@(1,5) (60.0%, 86.6%)	
07/04 09:54:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][200/703]	Step 71304	lr 0.01	Loss 1.8150 (1.4413)	Prec@(1,5) (60.0%, 86.7%)	
07/04 09:54:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][250/703]	Step 71354	lr 0.01	Loss 1.3216 (1.4404)	Prec@(1,5) (59.9%, 86.9%)	
07/04 09:54:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][300/703]	Step 71404	lr 0.01	Loss 1.5510 (1.4481)	Prec@(1,5) (59.8%, 86.7%)	
07/04 09:54:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][350/703]	Step 71454	lr 0.01	Loss 1.2406 (1.4438)	Prec@(1,5) (59.8%, 86.8%)	
07/04 09:54:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][400/703]	Step 71504	lr 0.01	Loss 1.4242 (1.4409)	Prec@(1,5) (59.8%, 86.9%)	
07/04 09:54:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][450/703]	Step 71554	lr 0.01	Loss 1.2368 (1.4384)	Prec@(1,5) (59.9%, 86.8%)	
07/04 09:54:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][500/703]	Step 71604	lr 0.01	Loss 1.5027 (1.4368)	Prec@(1,5) (59.8%, 86.9%)	
07/04 09:55:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][550/703]	Step 71654	lr 0.01	Loss 2.0370 (1.4416)	Prec@(1,5) (59.7%, 86.8%)	
07/04 09:55:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][600/703]	Step 71704	lr 0.01	Loss 1.3090 (1.4400)	Prec@(1,5) (59.7%, 86.8%)	
07/04 09:55:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][650/703]	Step 71754	lr 0.01	Loss 1.4005 (1.4408)	Prec@(1,5) (59.7%, 86.8%)	
07/04 09:55:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][700/703]	Step 71804	lr 0.01	Loss 1.3097 (1.4367)	Prec@(1,5) (59.7%, 86.8%)	
07/04 09:55:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [101][703/703]	Step 71807	lr 0.01	Loss 1.0805 (1.4358)	Prec@(1,5) (59.8%, 86.8%)	
07/04 09:55:10PM finetuneTeacher_trainer.py:185 [INFO] Train: [101/199] Final Prec@1 59.7489%
07/04 09:55:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [101][50/79]	Step 71808	Loss 1.7375	Prec@(1,5) (53.3%, 80.7%)
07/04 09:55:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [101][78/79]	Step 71808	Loss 1.7092	Prec@(1,5) (53.7%, 81.5%)
07/04 09:55:12PM finetuneTeacher_trainer.py:220 [INFO] Valid: [101/199] Final Prec@1 53.7800%
07/04 09:55:12PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 53.7800%
07/04 09:55:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][50/703]	Step 71858	lr 0.01	Loss 1.3636 (1.3931)	Prec@(1,5) (60.8%, 87.8%)	
07/04 09:55:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][100/703]	Step 71908	lr 0.01	Loss 1.2006 (1.3762)	Prec@(1,5) (61.2%, 88.2%)	
07/04 09:55:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][150/703]	Step 71958	lr 0.01	Loss 1.2144 (1.3662)	Prec@(1,5) (61.3%, 88.3%)	
07/04 09:55:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][200/703]	Step 72008	lr 0.01	Loss 1.2294 (1.3542)	Prec@(1,5) (61.7%, 88.4%)	
07/04 09:55:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][250/703]	Step 72058	lr 0.01	Loss 1.8471 (1.3649)	Prec@(1,5) (61.3%, 88.2%)	
07/04 09:55:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][300/703]	Step 72108	lr 0.01	Loss 1.5736 (1.3763)	Prec@(1,5) (61.1%, 88.0%)	
07/04 09:55:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][350/703]	Step 72158	lr 0.01	Loss 1.5179 (1.3727)	Prec@(1,5) (61.2%, 88.1%)	
07/04 09:55:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][400/703]	Step 72208	lr 0.01	Loss 1.3366 (1.3688)	Prec@(1,5) (61.2%, 88.1%)	
07/04 09:55:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][450/703]	Step 72258	lr 0.01	Loss 1.3477 (1.3692)	Prec@(1,5) (61.1%, 88.1%)	
07/04 09:55:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][500/703]	Step 72308	lr 0.01	Loss 1.2919 (1.3690)	Prec@(1,5) (61.2%, 88.1%)	
07/04 09:55:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][550/703]	Step 72358	lr 0.01	Loss 1.6809 (1.3688)	Prec@(1,5) (61.3%, 88.0%)	
07/04 09:55:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][600/703]	Step 72408	lr 0.01	Loss 0.8536 (1.3650)	Prec@(1,5) (61.4%, 88.1%)	
07/04 09:55:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][650/703]	Step 72458	lr 0.01	Loss 1.0576 (1.3640)	Prec@(1,5) (61.4%, 88.1%)	
07/04 09:55:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][700/703]	Step 72508	lr 0.01	Loss 1.0855 (1.3626)	Prec@(1,5) (61.5%, 88.1%)	
07/04 09:55:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [102][703/703]	Step 72511	lr 0.01	Loss 1.5217 (1.3627)	Prec@(1,5) (61.5%, 88.1%)	
07/04 09:55:59PM finetuneTeacher_trainer.py:185 [INFO] Train: [102/199] Final Prec@1 61.5044%
07/04 09:56:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [102][50/79]	Step 72512	Loss 1.6780	Prec@(1,5) (54.0%, 83.4%)
07/04 09:56:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [102][78/79]	Step 72512	Loss 1.6805	Prec@(1,5) (54.5%, 83.0%)
07/04 09:56:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [102/199] Final Prec@1 54.5800%
07/04 09:56:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 54.5800%
07/04 09:56:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][50/703]	Step 72562	lr 0.01	Loss 0.9471 (1.3059)	Prec@(1,5) (63.8%, 89.0%)	
07/04 09:56:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][100/703]	Step 72612	lr 0.01	Loss 1.6849 (1.3116)	Prec@(1,5) (62.7%, 88.8%)	
07/04 09:56:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][150/703]	Step 72662	lr 0.01	Loss 1.4796 (1.3344)	Prec@(1,5) (62.3%, 88.5%)	
07/04 09:56:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][200/703]	Step 72712	lr 0.01	Loss 1.3285 (1.3305)	Prec@(1,5) (62.3%, 88.5%)	
07/04 09:56:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][250/703]	Step 72762	lr 0.01	Loss 1.4047 (1.3308)	Prec@(1,5) (62.4%, 88.4%)	
07/04 09:56:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][300/703]	Step 72812	lr 0.01	Loss 1.3928 (1.3299)	Prec@(1,5) (62.5%, 88.5%)	
07/04 09:56:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][350/703]	Step 72862	lr 0.01	Loss 1.4414 (1.3342)	Prec@(1,5) (62.3%, 88.4%)	
07/04 09:56:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][400/703]	Step 72912	lr 0.01	Loss 1.0508 (1.3311)	Prec@(1,5) (62.3%, 88.5%)	
07/04 09:56:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][450/703]	Step 72962	lr 0.01	Loss 0.9406 (1.3273)	Prec@(1,5) (62.4%, 88.5%)	
07/04 09:56:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][500/703]	Step 73012	lr 0.01	Loss 1.2397 (1.3312)	Prec@(1,5) (62.3%, 88.4%)	
07/04 09:56:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][550/703]	Step 73062	lr 0.01	Loss 1.6032 (1.3303)	Prec@(1,5) (62.3%, 88.4%)	
07/04 09:56:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][600/703]	Step 73112	lr 0.01	Loss 1.2531 (1.3299)	Prec@(1,5) (62.3%, 88.4%)	
07/04 09:56:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][650/703]	Step 73162	lr 0.01	Loss 1.3063 (1.3317)	Prec@(1,5) (62.1%, 88.4%)	
07/04 09:56:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][700/703]	Step 73212	lr 0.01	Loss 1.1966 (1.3323)	Prec@(1,5) (62.1%, 88.4%)	
07/04 09:56:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [103][703/703]	Step 73215	lr 0.01	Loss 1.3964 (1.3326)	Prec@(1,5) (62.1%, 88.4%)	
07/04 09:56:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [103/199] Final Prec@1 62.1178%
07/04 09:56:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [103][50/79]	Step 73216	Loss 1.6833	Prec@(1,5) (54.6%, 82.3%)
07/04 09:56:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [103][78/79]	Step 73216	Loss 1.6654	Prec@(1,5) (55.1%, 83.2%)
07/04 09:56:47PM finetuneTeacher_trainer.py:220 [INFO] Valid: [103/199] Final Prec@1 55.1800%
07/04 09:56:47PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.1800%
07/04 09:56:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][50/703]	Step 73266	lr 0.01	Loss 1.0646 (1.3054)	Prec@(1,5) (64.2%, 88.5%)	
07/04 09:56:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][100/703]	Step 73316	lr 0.01	Loss 1.1990 (1.2885)	Prec@(1,5) (64.0%, 88.6%)	
07/04 09:56:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][150/703]	Step 73366	lr 0.01	Loss 1.3265 (1.2936)	Prec@(1,5) (63.6%, 88.9%)	
07/04 09:57:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][200/703]	Step 73416	lr 0.01	Loss 1.2651 (1.2938)	Prec@(1,5) (63.4%, 88.8%)	
07/04 09:57:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][250/703]	Step 73466	lr 0.01	Loss 1.3153 (1.2928)	Prec@(1,5) (63.4%, 88.8%)	
07/04 09:57:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][300/703]	Step 73516	lr 0.01	Loss 1.2829 (1.2955)	Prec@(1,5) (63.3%, 88.8%)	
07/04 09:57:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][350/703]	Step 73566	lr 0.01	Loss 1.2440 (1.2926)	Prec@(1,5) (63.4%, 88.9%)	
07/04 09:57:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][400/703]	Step 73616	lr 0.01	Loss 1.2053 (1.2956)	Prec@(1,5) (63.2%, 88.9%)	
07/04 09:57:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][450/703]	Step 73666	lr 0.01	Loss 1.3857 (1.2952)	Prec@(1,5) (63.1%, 88.9%)	
07/04 09:57:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][500/703]	Step 73716	lr 0.01	Loss 1.1096 (1.2958)	Prec@(1,5) (63.0%, 88.9%)	
07/04 09:57:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][550/703]	Step 73766	lr 0.01	Loss 1.4227 (1.2959)	Prec@(1,5) (63.0%, 88.9%)	
07/04 09:57:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][600/703]	Step 73816	lr 0.01	Loss 1.1660 (1.2955)	Prec@(1,5) (62.9%, 88.9%)	
07/04 09:57:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][650/703]	Step 73866	lr 0.01	Loss 1.3954 (1.2949)	Prec@(1,5) (62.9%, 89.0%)	
07/04 09:57:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][700/703]	Step 73916	lr 0.01	Loss 1.3347 (1.2954)	Prec@(1,5) (63.0%, 89.0%)	
07/04 09:57:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [104][703/703]	Step 73919	lr 0.01	Loss 1.5904 (1.2956)	Prec@(1,5) (63.0%, 89.0%)	
07/04 09:57:33PM finetuneTeacher_trainer.py:185 [INFO] Train: [104/199] Final Prec@1 62.9533%
07/04 09:57:34PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [104][50/79]	Step 73920	Loss 1.6492	Prec@(1,5) (54.5%, 83.3%)
07/04 09:57:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [104][78/79]	Step 73920	Loss 1.6441	Prec@(1,5) (55.2%, 83.5%)
07/04 09:57:35PM finetuneTeacher_trainer.py:220 [INFO] Valid: [104/199] Final Prec@1 55.2800%
07/04 09:57:35PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.2800%
07/04 09:57:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][50/703]	Step 73970	lr 0.01	Loss 1.1226 (1.2418)	Prec@(1,5) (65.3%, 88.8%)	
07/04 09:57:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][100/703]	Step 74020	lr 0.01	Loss 1.4570 (1.2314)	Prec@(1,5) (65.3%, 89.6%)	
07/04 09:57:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][150/703]	Step 74070	lr 0.01	Loss 1.1438 (1.2348)	Prec@(1,5) (65.1%, 89.8%)	
07/04 09:57:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][200/703]	Step 74120	lr 0.01	Loss 1.0509 (1.2446)	Prec@(1,5) (64.6%, 89.8%)	
07/04 09:57:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][250/703]	Step 74170	lr 0.01	Loss 1.3297 (1.2539)	Prec@(1,5) (64.4%, 89.8%)	
07/04 09:57:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][300/703]	Step 74220	lr 0.01	Loss 1.2959 (1.2511)	Prec@(1,5) (64.3%, 89.9%)	
07/04 09:57:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][350/703]	Step 74270	lr 0.01	Loss 1.1672 (1.2537)	Prec@(1,5) (64.2%, 89.8%)	
07/04 09:58:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][400/703]	Step 74320	lr 0.01	Loss 1.4664 (1.2553)	Prec@(1,5) (64.2%, 89.7%)	
07/04 09:58:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][450/703]	Step 74370	lr 0.01	Loss 1.2132 (1.2550)	Prec@(1,5) (64.2%, 89.7%)	
07/04 09:58:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][500/703]	Step 74420	lr 0.01	Loss 1.0463 (1.2519)	Prec@(1,5) (64.2%, 89.7%)	
07/04 09:58:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][550/703]	Step 74470	lr 0.01	Loss 1.0322 (1.2517)	Prec@(1,5) (64.2%, 89.7%)	
07/04 09:58:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][600/703]	Step 74520	lr 0.01	Loss 0.8351 (1.2525)	Prec@(1,5) (64.1%, 89.7%)	
07/04 09:58:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][650/703]	Step 74570	lr 0.01	Loss 1.3348 (1.2530)	Prec@(1,5) (64.1%, 89.7%)	
07/04 09:58:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][700/703]	Step 74620	lr 0.01	Loss 1.0778 (1.2534)	Prec@(1,5) (64.1%, 89.6%)	
07/04 09:58:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [105][703/703]	Step 74623	lr 0.01	Loss 1.2166 (1.2540)	Prec@(1,5) (64.1%, 89.6%)	
07/04 09:58:22PM finetuneTeacher_trainer.py:185 [INFO] Train: [105/199] Final Prec@1 64.1067%
07/04 09:58:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [105][50/79]	Step 74624	Loss 1.6250	Prec@(1,5) (56.3%, 83.6%)
07/04 09:58:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [105][78/79]	Step 74624	Loss 1.6483	Prec@(1,5) (55.6%, 83.4%)
07/04 09:58:23PM finetuneTeacher_trainer.py:220 [INFO] Valid: [105/199] Final Prec@1 55.6200%
07/04 09:58:24PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.6200%
07/04 09:58:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][50/703]	Step 74674	lr 0.01	Loss 1.0460 (1.2012)	Prec@(1,5) (65.9%, 90.5%)	
07/04 09:58:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][100/703]	Step 74724	lr 0.01	Loss 1.1439 (1.2213)	Prec@(1,5) (65.3%, 90.2%)	
07/04 09:58:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][150/703]	Step 74774	lr 0.01	Loss 1.0390 (1.2132)	Prec@(1,5) (65.5%, 90.4%)	
07/04 09:58:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][200/703]	Step 74824	lr 0.01	Loss 1.0521 (1.2135)	Prec@(1,5) (65.2%, 90.3%)	
07/04 09:58:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][250/703]	Step 74874	lr 0.01	Loss 1.0630 (1.2150)	Prec@(1,5) (65.1%, 90.3%)	
07/04 09:58:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][300/703]	Step 74924	lr 0.01	Loss 1.4992 (1.2210)	Prec@(1,5) (65.0%, 90.3%)	
07/04 09:58:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][350/703]	Step 74974	lr 0.01	Loss 1.2973 (1.2186)	Prec@(1,5) (65.0%, 90.3%)	
07/04 09:58:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][400/703]	Step 75024	lr 0.01	Loss 1.0875 (1.2196)	Prec@(1,5) (65.0%, 90.3%)	
07/04 09:58:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][450/703]	Step 75074	lr 0.01	Loss 0.9254 (1.2232)	Prec@(1,5) (64.9%, 90.2%)	
07/04 09:58:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][500/703]	Step 75124	lr 0.01	Loss 1.5502 (1.2268)	Prec@(1,5) (64.8%, 90.2%)	
07/04 09:59:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][550/703]	Step 75174	lr 0.01	Loss 0.9188 (1.2282)	Prec@(1,5) (64.7%, 90.1%)	
07/04 09:59:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][600/703]	Step 75224	lr 0.01	Loss 1.1725 (1.2323)	Prec@(1,5) (64.7%, 90.0%)	
07/04 09:59:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][650/703]	Step 75274	lr 0.01	Loss 1.2909 (1.2357)	Prec@(1,5) (64.5%, 90.0%)	
07/04 09:59:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][700/703]	Step 75324	lr 0.01	Loss 1.7381 (1.2371)	Prec@(1,5) (64.5%, 89.9%)	
07/04 09:59:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [106][703/703]	Step 75327	lr 0.01	Loss 1.0135 (1.2368)	Prec@(1,5) (64.6%, 89.9%)	
07/04 09:59:10PM finetuneTeacher_trainer.py:185 [INFO] Train: [106/199] Final Prec@1 64.5533%
07/04 09:59:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [106][50/79]	Step 75328	Loss 1.6142	Prec@(1,5) (55.6%, 83.6%)
07/04 09:59:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [106][78/79]	Step 75328	Loss 1.6108	Prec@(1,5) (55.7%, 83.7%)
07/04 09:59:11PM finetuneTeacher_trainer.py:220 [INFO] Valid: [106/199] Final Prec@1 55.7200%
07/04 09:59:11PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.7200%
07/04 09:59:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][50/703]	Step 75378	lr 0.01	Loss 1.1457 (1.1581)	Prec@(1,5) (67.3%, 90.8%)	
07/04 09:59:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][100/703]	Step 75428	lr 0.01	Loss 1.1257 (1.1729)	Prec@(1,5) (66.4%, 91.1%)	
07/04 09:59:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][150/703]	Step 75478	lr 0.01	Loss 1.0763 (1.1776)	Prec@(1,5) (66.1%, 91.0%)	
07/04 09:59:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][200/703]	Step 75528	lr 0.01	Loss 1.3008 (1.1836)	Prec@(1,5) (66.0%, 91.0%)	
07/04 09:59:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][250/703]	Step 75578	lr 0.01	Loss 0.9800 (1.1820)	Prec@(1,5) (66.1%, 90.8%)	
07/04 09:59:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][300/703]	Step 75628	lr 0.01	Loss 1.3935 (1.1833)	Prec@(1,5) (66.2%, 90.7%)	
07/04 09:59:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][350/703]	Step 75678	lr 0.01	Loss 1.2659 (1.1873)	Prec@(1,5) (66.0%, 90.7%)	
07/04 09:59:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][400/703]	Step 75728	lr 0.01	Loss 1.0427 (1.1952)	Prec@(1,5) (65.7%, 90.6%)	
07/04 09:59:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][450/703]	Step 75778	lr 0.01	Loss 1.1076 (1.2007)	Prec@(1,5) (65.6%, 90.5%)	
07/04 09:59:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][500/703]	Step 75828	lr 0.01	Loss 1.0754 (1.2045)	Prec@(1,5) (65.6%, 90.4%)	
07/04 09:59:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][550/703]	Step 75878	lr 0.01	Loss 1.0267 (1.2074)	Prec@(1,5) (65.5%, 90.4%)	
07/04 09:59:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][600/703]	Step 75928	lr 0.01	Loss 1.2137 (1.2112)	Prec@(1,5) (65.4%, 90.3%)	
07/04 09:59:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][650/703]	Step 75978	lr 0.01	Loss 1.5374 (1.2146)	Prec@(1,5) (65.3%, 90.3%)	
07/04 09:59:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][700/703]	Step 76028	lr 0.01	Loss 1.3664 (1.2185)	Prec@(1,5) (65.3%, 90.2%)	
07/04 09:59:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [107][703/703]	Step 76031	lr 0.01	Loss 1.3458 (1.2188)	Prec@(1,5) (65.2%, 90.2%)	
07/04 09:59:58PM finetuneTeacher_trainer.py:185 [INFO] Train: [107/199] Final Prec@1 65.2444%
07/04 09:59:58PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [107][50/79]	Step 76032	Loss 1.6552	Prec@(1,5) (55.7%, 83.6%)
07/04 09:59:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [107][78/79]	Step 76032	Loss 1.6525	Prec@(1,5) (55.4%, 83.6%)
07/04 09:59:59PM finetuneTeacher_trainer.py:220 [INFO] Valid: [107/199] Final Prec@1 55.4600%
07/04 09:59:59PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.7200%
07/04 10:00:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][50/703]	Step 76082	lr 0.01	Loss 0.9548 (1.1499)	Prec@(1,5) (67.1%, 90.9%)	
07/04 10:00:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][100/703]	Step 76132	lr 0.01	Loss 1.3133 (1.1814)	Prec@(1,5) (66.3%, 90.5%)	
07/04 10:00:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][150/703]	Step 76182	lr 0.01	Loss 1.4351 (1.1760)	Prec@(1,5) (66.1%, 90.7%)	
07/04 10:00:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][200/703]	Step 76232	lr 0.01	Loss 1.2809 (1.1762)	Prec@(1,5) (66.2%, 90.8%)	
07/04 10:00:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][250/703]	Step 76282	lr 0.01	Loss 0.9795 (1.1743)	Prec@(1,5) (66.3%, 90.8%)	
07/04 10:00:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][300/703]	Step 76332	lr 0.01	Loss 1.0338 (1.1727)	Prec@(1,5) (66.3%, 90.8%)	
07/04 10:00:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][350/703]	Step 76382	lr 0.01	Loss 1.3795 (1.1752)	Prec@(1,5) (66.1%, 90.8%)	
07/04 10:00:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][400/703]	Step 76432	lr 0.01	Loss 1.1512 (1.1784)	Prec@(1,5) (66.1%, 90.7%)	
07/04 10:00:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][450/703]	Step 76482	lr 0.01	Loss 1.4396 (1.1857)	Prec@(1,5) (65.8%, 90.7%)	
07/04 10:00:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][500/703]	Step 76532	lr 0.01	Loss 1.4251 (1.1924)	Prec@(1,5) (65.7%, 90.6%)	
07/04 10:00:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][550/703]	Step 76582	lr 0.01	Loss 1.4711 (1.1926)	Prec@(1,5) (65.7%, 90.7%)	
07/04 10:00:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][600/703]	Step 76632	lr 0.01	Loss 1.3463 (1.1939)	Prec@(1,5) (65.7%, 90.6%)	
07/04 10:00:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][650/703]	Step 76682	lr 0.01	Loss 1.0921 (1.1912)	Prec@(1,5) (65.7%, 90.6%)	
07/04 10:00:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][700/703]	Step 76732	lr 0.01	Loss 1.1473 (1.1914)	Prec@(1,5) (65.8%, 90.6%)	
07/04 10:00:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [108][703/703]	Step 76735	lr 0.01	Loss 1.1563 (1.1907)	Prec@(1,5) (65.8%, 90.6%)	
07/04 10:00:45PM finetuneTeacher_trainer.py:185 [INFO] Train: [108/199] Final Prec@1 65.7956%
07/04 10:00:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [108][50/79]	Step 76736	Loss 1.6489	Prec@(1,5) (55.9%, 84.1%)
07/04 10:00:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [108][78/79]	Step 76736	Loss 1.6462	Prec@(1,5) (55.7%, 84.0%)
07/04 10:00:46PM finetuneTeacher_trainer.py:220 [INFO] Valid: [108/199] Final Prec@1 55.7200%
07/04 10:00:47PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.7200%
07/04 10:00:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][50/703]	Step 76786	lr 0.01	Loss 1.1985 (1.1420)	Prec@(1,5) (66.4%, 91.7%)	
07/04 10:00:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][100/703]	Step 76836	lr 0.01	Loss 0.9378 (1.1497)	Prec@(1,5) (66.8%, 91.3%)	
07/04 10:00:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][150/703]	Step 76886	lr 0.01	Loss 1.2117 (1.1563)	Prec@(1,5) (66.7%, 91.1%)	
07/04 10:01:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][200/703]	Step 76936	lr 0.01	Loss 1.0525 (1.1514)	Prec@(1,5) (66.9%, 91.1%)	
07/04 10:01:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][250/703]	Step 76986	lr 0.01	Loss 0.8579 (1.1497)	Prec@(1,5) (66.7%, 91.2%)	
07/04 10:01:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][300/703]	Step 77036	lr 0.01	Loss 1.3092 (1.1621)	Prec@(1,5) (66.4%, 91.0%)	
07/04 10:01:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][350/703]	Step 77086	lr 0.01	Loss 1.1577 (1.1656)	Prec@(1,5) (66.3%, 91.0%)	
07/04 10:01:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][400/703]	Step 77136	lr 0.01	Loss 1.1023 (1.1715)	Prec@(1,5) (66.2%, 90.8%)	
07/04 10:01:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][450/703]	Step 77186	lr 0.01	Loss 1.2337 (1.1734)	Prec@(1,5) (66.2%, 90.8%)	
07/04 10:01:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][500/703]	Step 77236	lr 0.01	Loss 1.2363 (1.1750)	Prec@(1,5) (66.2%, 90.7%)	
07/04 10:01:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][550/703]	Step 77286	lr 0.01	Loss 1.1860 (1.1752)	Prec@(1,5) (66.2%, 90.7%)	
07/04 10:01:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][600/703]	Step 77336	lr 0.01	Loss 1.0080 (1.1751)	Prec@(1,5) (66.1%, 90.8%)	
07/04 10:01:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][650/703]	Step 77386	lr 0.01	Loss 1.1480 (1.1765)	Prec@(1,5) (66.1%, 90.8%)	
07/04 10:01:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][700/703]	Step 77436	lr 0.01	Loss 1.3591 (1.1780)	Prec@(1,5) (66.1%, 90.8%)	
07/04 10:01:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [109][703/703]	Step 77439	lr 0.01	Loss 1.3558 (1.1780)	Prec@(1,5) (66.1%, 90.8%)	
07/04 10:01:31PM finetuneTeacher_trainer.py:185 [INFO] Train: [109/199] Final Prec@1 66.0467%
07/04 10:01:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [109][50/79]	Step 77440	Loss 1.6402	Prec@(1,5) (55.1%, 83.2%)
07/04 10:01:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [109][78/79]	Step 77440	Loss 1.6329	Prec@(1,5) (55.8%, 83.6%)
07/04 10:01:33PM finetuneTeacher_trainer.py:220 [INFO] Valid: [109/199] Final Prec@1 55.8200%
07/04 10:01:33PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.8200%
07/04 10:01:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][50/703]	Step 77490	lr 0.01	Loss 0.9139 (1.1510)	Prec@(1,5) (66.6%, 91.3%)	
07/04 10:01:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][100/703]	Step 77540	lr 0.01	Loss 1.0622 (1.1489)	Prec@(1,5) (66.7%, 91.4%)	
07/04 10:01:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][150/703]	Step 77590	lr 0.01	Loss 1.6401 (1.1488)	Prec@(1,5) (66.7%, 91.6%)	
07/04 10:01:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][200/703]	Step 77640	lr 0.01	Loss 0.8971 (1.1455)	Prec@(1,5) (66.8%, 91.5%)	
07/04 10:01:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][250/703]	Step 77690	lr 0.01	Loss 1.2460 (1.1421)	Prec@(1,5) (66.8%, 91.5%)	
07/04 10:01:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][300/703]	Step 77740	lr 0.01	Loss 1.2047 (1.1470)	Prec@(1,5) (66.5%, 91.4%)	
07/04 10:01:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][350/703]	Step 77790	lr 0.01	Loss 1.0376 (1.1438)	Prec@(1,5) (66.6%, 91.5%)	
07/04 10:01:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][400/703]	Step 77840	lr 0.01	Loss 1.6433 (1.1465)	Prec@(1,5) (66.4%, 91.4%)	
07/04 10:02:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][450/703]	Step 77890	lr 0.01	Loss 1.2763 (1.1447)	Prec@(1,5) (66.4%, 91.4%)	
07/04 10:02:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][500/703]	Step 77940	lr 0.01	Loss 0.9197 (1.1511)	Prec@(1,5) (66.3%, 91.2%)	
07/04 10:02:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][550/703]	Step 77990	lr 0.01	Loss 1.2849 (1.1526)	Prec@(1,5) (66.3%, 91.2%)	
07/04 10:02:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][600/703]	Step 78040	lr 0.01	Loss 1.0585 (1.1509)	Prec@(1,5) (66.4%, 91.2%)	
07/04 10:02:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][650/703]	Step 78090	lr 0.01	Loss 0.8854 (1.1528)	Prec@(1,5) (66.3%, 91.2%)	
07/04 10:02:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][700/703]	Step 78140	lr 0.01	Loss 1.2412 (1.1571)	Prec@(1,5) (66.2%, 91.1%)	
07/04 10:02:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [110][703/703]	Step 78143	lr 0.01	Loss 1.0858 (1.1574)	Prec@(1,5) (66.2%, 91.1%)	
07/04 10:02:18PM finetuneTeacher_trainer.py:185 [INFO] Train: [110/199] Final Prec@1 66.1956%
07/04 10:02:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [110][50/79]	Step 78144	Loss 1.6592	Prec@(1,5) (55.8%, 84.2%)
07/04 10:02:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [110][78/79]	Step 78144	Loss 1.6402	Prec@(1,5) (55.7%, 84.4%)
07/04 10:02:19PM finetuneTeacher_trainer.py:220 [INFO] Valid: [110/199] Final Prec@1 55.7200%
07/04 10:02:19PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.8200%
07/04 10:02:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][50/703]	Step 78194	lr 0.01	Loss 1.3022 (1.1325)	Prec@(1,5) (67.7%, 92.0%)	
07/04 10:02:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][100/703]	Step 78244	lr 0.01	Loss 0.9256 (1.1243)	Prec@(1,5) (67.6%, 91.8%)	
07/04 10:02:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][150/703]	Step 78294	lr 0.01	Loss 1.3753 (1.1220)	Prec@(1,5) (67.5%, 91.7%)	
07/04 10:02:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][200/703]	Step 78344	lr 0.01	Loss 0.8423 (1.1203)	Prec@(1,5) (67.7%, 91.6%)	
07/04 10:02:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][250/703]	Step 78394	lr 0.01	Loss 1.0272 (1.1257)	Prec@(1,5) (67.6%, 91.5%)	
07/04 10:02:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][300/703]	Step 78444	lr 0.01	Loss 0.8230 (1.1337)	Prec@(1,5) (67.4%, 91.4%)	
07/04 10:02:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][350/703]	Step 78494	lr 0.01	Loss 0.9048 (1.1370)	Prec@(1,5) (67.3%, 91.3%)	
07/04 10:02:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][400/703]	Step 78544	lr 0.01	Loss 1.3323 (1.1403)	Prec@(1,5) (67.2%, 91.2%)	
07/04 10:02:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][450/703]	Step 78594	lr 0.01	Loss 1.7542 (1.1405)	Prec@(1,5) (67.2%, 91.3%)	
07/04 10:02:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][500/703]	Step 78644	lr 0.01	Loss 0.8919 (1.1426)	Prec@(1,5) (67.0%, 91.3%)	
07/04 10:02:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][550/703]	Step 78694	lr 0.01	Loss 1.1097 (1.1463)	Prec@(1,5) (67.1%, 91.2%)	
07/04 10:02:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][600/703]	Step 78744	lr 0.01	Loss 0.8641 (1.1488)	Prec@(1,5) (66.9%, 91.1%)	
07/04 10:03:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][650/703]	Step 78794	lr 0.01	Loss 1.3999 (1.1477)	Prec@(1,5) (67.0%, 91.1%)	
07/04 10:03:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][700/703]	Step 78844	lr 0.01	Loss 1.1921 (1.1477)	Prec@(1,5) (67.0%, 91.1%)	
07/04 10:03:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [111][703/703]	Step 78847	lr 0.01	Loss 0.9262 (1.1470)	Prec@(1,5) (67.1%, 91.1%)	
07/04 10:03:04PM finetuneTeacher_trainer.py:185 [INFO] Train: [111/199] Final Prec@1 67.0511%
07/04 10:03:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [111][50/79]	Step 78848	Loss 1.5870	Prec@(1,5) (56.7%, 84.8%)
07/04 10:03:06PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [111][78/79]	Step 78848	Loss 1.6372	Prec@(1,5) (55.7%, 83.9%)
07/04 10:03:06PM finetuneTeacher_trainer.py:220 [INFO] Valid: [111/199] Final Prec@1 55.7600%
07/04 10:03:06PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.8200%
07/04 10:03:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][50/703]	Step 78898	lr 0.01	Loss 1.0808 (1.0946)	Prec@(1,5) (67.9%, 92.2%)	
07/04 10:03:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][100/703]	Step 78948	lr 0.01	Loss 0.9753 (1.1141)	Prec@(1,5) (67.6%, 91.6%)	
07/04 10:03:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][150/703]	Step 78998	lr 0.01	Loss 1.0704 (1.1215)	Prec@(1,5) (67.7%, 91.5%)	
07/04 10:03:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][200/703]	Step 79048	lr 0.01	Loss 1.0963 (1.1162)	Prec@(1,5) (67.7%, 91.4%)	
07/04 10:03:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][250/703]	Step 79098	lr 0.01	Loss 0.9277 (1.1148)	Prec@(1,5) (67.8%, 91.5%)	
07/04 10:03:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][300/703]	Step 79148	lr 0.01	Loss 1.3276 (1.1176)	Prec@(1,5) (67.8%, 91.5%)	
07/04 10:03:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][350/703]	Step 79198	lr 0.01	Loss 0.8726 (1.1203)	Prec@(1,5) (67.7%, 91.4%)	
07/04 10:03:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][400/703]	Step 79248	lr 0.01	Loss 1.0224 (1.1166)	Prec@(1,5) (67.9%, 91.4%)	
07/04 10:03:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][450/703]	Step 79298	lr 0.01	Loss 0.8782 (1.1195)	Prec@(1,5) (67.7%, 91.4%)	
07/04 10:03:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][500/703]	Step 79348	lr 0.01	Loss 1.1615 (1.1238)	Prec@(1,5) (67.6%, 91.4%)	
07/04 10:03:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][550/703]	Step 79398	lr 0.01	Loss 1.1195 (1.1240)	Prec@(1,5) (67.6%, 91.4%)	
07/04 10:03:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][600/703]	Step 79448	lr 0.01	Loss 1.3657 (1.1226)	Prec@(1,5) (67.7%, 91.4%)	
07/04 10:03:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][650/703]	Step 79498	lr 0.01	Loss 0.9267 (1.1239)	Prec@(1,5) (67.6%, 91.4%)	
07/04 10:03:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][700/703]	Step 79548	lr 0.01	Loss 1.1607 (1.1279)	Prec@(1,5) (67.4%, 91.4%)	
07/04 10:03:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [112][703/703]	Step 79551	lr 0.01	Loss 1.3292 (1.1283)	Prec@(1,5) (67.4%, 91.4%)	
07/04 10:03:52PM finetuneTeacher_trainer.py:185 [INFO] Train: [112/199] Final Prec@1 67.3822%
07/04 10:03:53PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [112][50/79]	Step 79552	Loss 1.6122	Prec@(1,5) (55.0%, 84.0%)
07/04 10:03:53PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [112][78/79]	Step 79552	Loss 1.6360	Prec@(1,5) (55.5%, 83.4%)
07/04 10:03:53PM finetuneTeacher_trainer.py:220 [INFO] Valid: [112/199] Final Prec@1 55.5000%
07/04 10:03:54PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.8200%
07/04 10:03:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][50/703]	Step 79602	lr 0.01	Loss 0.9617 (1.0800)	Prec@(1,5) (68.3%, 92.5%)	
07/04 10:04:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][100/703]	Step 79652	lr 0.01	Loss 1.0115 (1.0777)	Prec@(1,5) (68.3%, 92.4%)	
07/04 10:04:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][150/703]	Step 79702	lr 0.01	Loss 1.3120 (1.0826)	Prec@(1,5) (68.3%, 92.3%)	
07/04 10:04:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][200/703]	Step 79752	lr 0.01	Loss 1.0949 (1.0859)	Prec@(1,5) (68.4%, 92.1%)	
07/04 10:04:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][250/703]	Step 79802	lr 0.01	Loss 1.1820 (1.0878)	Prec@(1,5) (68.2%, 92.2%)	
07/04 10:04:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][300/703]	Step 79852	lr 0.01	Loss 1.2896 (1.0915)	Prec@(1,5) (68.2%, 92.2%)	
07/04 10:04:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][350/703]	Step 79902	lr 0.01	Loss 1.3128 (1.0988)	Prec@(1,5) (68.0%, 92.0%)	
07/04 10:04:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][400/703]	Step 79952	lr 0.01	Loss 1.1917 (1.0996)	Prec@(1,5) (68.1%, 92.0%)	
07/04 10:04:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][450/703]	Step 80002	lr 0.01	Loss 0.9418 (1.1015)	Prec@(1,5) (68.1%, 91.9%)	
07/04 10:04:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][500/703]	Step 80052	lr 0.01	Loss 1.5332 (1.1020)	Prec@(1,5) (68.1%, 91.9%)	
07/04 10:04:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][550/703]	Step 80102	lr 0.01	Loss 1.1199 (1.1092)	Prec@(1,5) (67.9%, 91.8%)	
07/04 10:04:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][600/703]	Step 80152	lr 0.01	Loss 1.2047 (1.1115)	Prec@(1,5) (67.8%, 91.7%)	
07/04 10:04:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][650/703]	Step 80202	lr 0.01	Loss 1.0097 (1.1118)	Prec@(1,5) (67.8%, 91.7%)	
07/04 10:04:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][700/703]	Step 80252	lr 0.01	Loss 1.3352 (1.1132)	Prec@(1,5) (67.7%, 91.7%)	
07/04 10:04:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [113][703/703]	Step 80255	lr 0.01	Loss 1.3386 (1.1135)	Prec@(1,5) (67.7%, 91.7%)	
07/04 10:04:39PM finetuneTeacher_trainer.py:185 [INFO] Train: [113/199] Final Prec@1 67.7200%
07/04 10:04:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [113][50/79]	Step 80256	Loss 1.6238	Prec@(1,5) (56.3%, 83.9%)
07/04 10:04:41PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [113][78/79]	Step 80256	Loss 1.6359	Prec@(1,5) (55.6%, 83.6%)
07/04 10:04:41PM finetuneTeacher_trainer.py:220 [INFO] Valid: [113/199] Final Prec@1 55.6000%
07/04 10:04:41PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.8200%
07/04 10:04:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][50/703]	Step 80306	lr 0.01	Loss 0.9539 (1.0854)	Prec@(1,5) (67.8%, 92.6%)	
07/04 10:04:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][100/703]	Step 80356	lr 0.01	Loss 1.0630 (1.0965)	Prec@(1,5) (67.8%, 92.2%)	
07/04 10:04:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][150/703]	Step 80406	lr 0.01	Loss 0.8093 (1.0833)	Prec@(1,5) (68.2%, 92.4%)	
07/04 10:04:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][200/703]	Step 80456	lr 0.01	Loss 1.1246 (1.0868)	Prec@(1,5) (68.3%, 92.4%)	
07/04 10:04:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][250/703]	Step 80506	lr 0.01	Loss 1.1577 (1.0862)	Prec@(1,5) (68.1%, 92.3%)	
07/04 10:05:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][300/703]	Step 80556	lr 0.01	Loss 1.0770 (1.0874)	Prec@(1,5) (68.0%, 92.3%)	
07/04 10:05:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][350/703]	Step 80606	lr 0.01	Loss 0.9319 (1.0901)	Prec@(1,5) (68.1%, 92.2%)	
07/04 10:05:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][400/703]	Step 80656	lr 0.01	Loss 0.9848 (1.0926)	Prec@(1,5) (68.0%, 92.2%)	
07/04 10:05:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][450/703]	Step 80706	lr 0.01	Loss 1.0469 (1.0934)	Prec@(1,5) (68.1%, 92.1%)	
07/04 10:05:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][500/703]	Step 80756	lr 0.01	Loss 1.0377 (1.0999)	Prec@(1,5) (67.9%, 92.0%)	
07/04 10:05:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][550/703]	Step 80806	lr 0.01	Loss 1.4423 (1.1018)	Prec@(1,5) (67.9%, 91.9%)	
07/04 10:05:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][600/703]	Step 80856	lr 0.01	Loss 1.1181 (1.1081)	Prec@(1,5) (67.8%, 91.9%)	
07/04 10:05:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][650/703]	Step 80906	lr 0.01	Loss 1.0608 (1.1064)	Prec@(1,5) (67.9%, 91.9%)	
07/04 10:05:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][700/703]	Step 80956	lr 0.01	Loss 1.2208 (1.1087)	Prec@(1,5) (67.8%, 91.8%)	
07/04 10:05:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [114][703/703]	Step 80959	lr 0.01	Loss 1.1048 (1.1086)	Prec@(1,5) (67.8%, 91.8%)	
07/04 10:05:27PM finetuneTeacher_trainer.py:185 [INFO] Train: [114/199] Final Prec@1 67.8422%
07/04 10:05:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [114][50/79]	Step 80960	Loss 1.6654	Prec@(1,5) (55.7%, 83.6%)
07/04 10:05:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [114][78/79]	Step 80960	Loss 1.6545	Prec@(1,5) (55.6%, 83.8%)
07/04 10:05:28PM finetuneTeacher_trainer.py:220 [INFO] Valid: [114/199] Final Prec@1 55.6600%
07/04 10:05:28PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 55.8200%
07/04 10:05:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][50/703]	Step 81010	lr 0.01	Loss 0.7499 (1.0527)	Prec@(1,5) (69.0%, 93.1%)	
07/04 10:05:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][100/703]	Step 81060	lr 0.01	Loss 1.2164 (1.0650)	Prec@(1,5) (68.7%, 92.8%)	
07/04 10:05:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][150/703]	Step 81110	lr 0.01	Loss 1.1559 (1.0678)	Prec@(1,5) (68.9%, 92.4%)	
07/04 10:05:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][200/703]	Step 81160	lr 0.01	Loss 1.2355 (1.0742)	Prec@(1,5) (68.7%, 92.5%)	
07/04 10:05:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][250/703]	Step 81210	lr 0.01	Loss 1.0143 (1.0658)	Prec@(1,5) (69.1%, 92.7%)	
07/04 10:05:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][300/703]	Step 81260	lr 0.01	Loss 0.9016 (1.0659)	Prec@(1,5) (69.0%, 92.7%)	
07/04 10:05:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][350/703]	Step 81310	lr 0.01	Loss 0.7781 (1.0722)	Prec@(1,5) (68.7%, 92.5%)	
07/04 10:05:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][400/703]	Step 81360	lr 0.01	Loss 1.0623 (1.0766)	Prec@(1,5) (68.6%, 92.4%)	
07/04 10:05:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][450/703]	Step 81410	lr 0.01	Loss 1.0930 (1.0838)	Prec@(1,5) (68.4%, 92.3%)	
07/04 10:06:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][500/703]	Step 81460	lr 0.01	Loss 1.2761 (1.0886)	Prec@(1,5) (68.3%, 92.3%)	
07/04 10:06:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][550/703]	Step 81510	lr 0.01	Loss 1.2021 (1.0901)	Prec@(1,5) (68.1%, 92.2%)	
07/04 10:06:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][600/703]	Step 81560	lr 0.01	Loss 1.3535 (1.0919)	Prec@(1,5) (68.1%, 92.2%)	
07/04 10:06:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][650/703]	Step 81610	lr 0.01	Loss 0.9280 (1.0962)	Prec@(1,5) (68.0%, 92.1%)	
07/04 10:06:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][700/703]	Step 81660	lr 0.01	Loss 0.9459 (1.0986)	Prec@(1,5) (67.9%, 92.0%)	
07/04 10:06:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [115][703/703]	Step 81663	lr 0.01	Loss 1.2228 (1.0981)	Prec@(1,5) (67.9%, 92.0%)	
07/04 10:06:15PM finetuneTeacher_trainer.py:185 [INFO] Train: [115/199] Final Prec@1 67.9378%
07/04 10:06:16PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [115][50/79]	Step 81664	Loss 1.6124	Prec@(1,5) (56.8%, 84.7%)
07/04 10:06:16PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [115][78/79]	Step 81664	Loss 1.6166	Prec@(1,5) (56.6%, 84.2%)
07/04 10:06:16PM finetuneTeacher_trainer.py:220 [INFO] Valid: [115/199] Final Prec@1 56.5400%
07/04 10:06:17PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:06:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][50/703]	Step 81714	lr 0.01	Loss 1.2037 (1.0774)	Prec@(1,5) (68.2%, 92.2%)	
07/04 10:06:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][100/703]	Step 81764	lr 0.01	Loss 1.0109 (1.0743)	Prec@(1,5) (68.7%, 92.3%)	
07/04 10:06:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][150/703]	Step 81814	lr 0.01	Loss 1.0364 (1.0697)	Prec@(1,5) (68.8%, 92.2%)	
07/04 10:06:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][200/703]	Step 81864	lr 0.01	Loss 1.4486 (1.0721)	Prec@(1,5) (68.7%, 92.2%)	
07/04 10:06:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][250/703]	Step 81914	lr 0.01	Loss 1.0929 (1.0704)	Prec@(1,5) (68.8%, 92.3%)	
07/04 10:06:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][300/703]	Step 81964	lr 0.01	Loss 1.3367 (1.0787)	Prec@(1,5) (68.6%, 92.1%)	
07/04 10:06:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][350/703]	Step 82014	lr 0.01	Loss 0.9404 (1.0810)	Prec@(1,5) (68.5%, 92.0%)	
07/04 10:06:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][400/703]	Step 82064	lr 0.01	Loss 0.9548 (1.0811)	Prec@(1,5) (68.4%, 92.1%)	
07/04 10:06:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][450/703]	Step 82114	lr 0.01	Loss 1.0784 (1.0838)	Prec@(1,5) (68.4%, 92.1%)	
07/04 10:06:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][500/703]	Step 82164	lr 0.01	Loss 1.2048 (1.0850)	Prec@(1,5) (68.3%, 92.2%)	
07/04 10:06:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][550/703]	Step 82214	lr 0.01	Loss 0.8341 (1.0903)	Prec@(1,5) (68.2%, 92.1%)	
07/04 10:06:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][600/703]	Step 82264	lr 0.01	Loss 0.9579 (1.0909)	Prec@(1,5) (68.2%, 92.1%)	
07/04 10:07:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][650/703]	Step 82314	lr 0.01	Loss 1.0641 (1.0924)	Prec@(1,5) (68.2%, 92.0%)	
07/04 10:07:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][700/703]	Step 82364	lr 0.01	Loss 0.8990 (1.0912)	Prec@(1,5) (68.2%, 92.0%)	
07/04 10:07:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [116][703/703]	Step 82367	lr 0.01	Loss 0.9421 (1.0904)	Prec@(1,5) (68.3%, 92.0%)	
07/04 10:07:03PM finetuneTeacher_trainer.py:185 [INFO] Train: [116/199] Final Prec@1 68.2556%
07/04 10:07:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [116][50/79]	Step 82368	Loss 1.6510	Prec@(1,5) (55.4%, 83.1%)
07/04 10:07:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [116][78/79]	Step 82368	Loss 1.6676	Prec@(1,5) (55.2%, 83.2%)
07/04 10:07:05PM finetuneTeacher_trainer.py:220 [INFO] Valid: [116/199] Final Prec@1 55.1800%
07/04 10:07:05PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:07:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][50/703]	Step 82418	lr 0.01	Loss 0.8303 (1.0558)	Prec@(1,5) (69.6%, 92.4%)	
07/04 10:07:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][100/703]	Step 82468	lr 0.01	Loss 1.1142 (1.0488)	Prec@(1,5) (69.5%, 92.4%)	
07/04 10:07:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][150/703]	Step 82518	lr 0.01	Loss 0.7532 (1.0451)	Prec@(1,5) (69.4%, 92.6%)	
07/04 10:07:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][200/703]	Step 82568	lr 0.01	Loss 1.1618 (1.0484)	Prec@(1,5) (69.3%, 92.6%)	
07/04 10:07:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][250/703]	Step 82618	lr 0.01	Loss 1.2033 (1.0461)	Prec@(1,5) (69.4%, 92.7%)	
07/04 10:07:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][300/703]	Step 82668	lr 0.01	Loss 1.1051 (1.0516)	Prec@(1,5) (69.3%, 92.6%)	
07/04 10:07:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][350/703]	Step 82718	lr 0.01	Loss 1.0454 (1.0569)	Prec@(1,5) (69.2%, 92.6%)	
07/04 10:07:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][400/703]	Step 82768	lr 0.01	Loss 1.0627 (1.0619)	Prec@(1,5) (69.0%, 92.5%)	
07/04 10:07:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][450/703]	Step 82818	lr 0.01	Loss 1.0482 (1.0653)	Prec@(1,5) (68.9%, 92.5%)	
07/04 10:07:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][500/703]	Step 82868	lr 0.01	Loss 1.0626 (1.0674)	Prec@(1,5) (68.8%, 92.4%)	
07/04 10:07:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][550/703]	Step 82918	lr 0.01	Loss 1.3025 (1.0705)	Prec@(1,5) (68.7%, 92.4%)	
07/04 10:07:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][600/703]	Step 82968	lr 0.01	Loss 1.2370 (1.0724)	Prec@(1,5) (68.7%, 92.4%)	
07/04 10:07:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][650/703]	Step 83018	lr 0.01	Loss 0.8831 (1.0733)	Prec@(1,5) (68.6%, 92.3%)	
07/04 10:07:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][700/703]	Step 83068	lr 0.01	Loss 1.1501 (1.0797)	Prec@(1,5) (68.4%, 92.2%)	
07/04 10:07:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [117][703/703]	Step 83071	lr 0.01	Loss 1.2362 (1.0796)	Prec@(1,5) (68.4%, 92.2%)	
07/04 10:07:51PM finetuneTeacher_trainer.py:185 [INFO] Train: [117/199] Final Prec@1 68.4400%
07/04 10:07:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [117][50/79]	Step 83072	Loss 1.6672	Prec@(1,5) (54.9%, 84.8%)
07/04 10:07:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [117][78/79]	Step 83072	Loss 1.6663	Prec@(1,5) (54.5%, 84.4%)
07/04 10:07:53PM finetuneTeacher_trainer.py:220 [INFO] Valid: [117/199] Final Prec@1 54.5000%
07/04 10:07:53PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:07:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][50/703]	Step 83122	lr 0.01	Loss 0.8589 (1.0583)	Prec@(1,5) (69.5%, 93.0%)	
07/04 10:08:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][100/703]	Step 83172	lr 0.01	Loss 0.9390 (1.0374)	Prec@(1,5) (69.8%, 92.9%)	
07/04 10:08:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][150/703]	Step 83222	lr 0.01	Loss 1.1041 (1.0418)	Prec@(1,5) (69.5%, 92.7%)	
07/04 10:08:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][200/703]	Step 83272	lr 0.01	Loss 0.9489 (1.0350)	Prec@(1,5) (69.5%, 92.9%)	
07/04 10:08:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][250/703]	Step 83322	lr 0.01	Loss 1.0881 (1.0426)	Prec@(1,5) (69.2%, 92.7%)	
07/04 10:08:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][300/703]	Step 83372	lr 0.01	Loss 0.9557 (1.0494)	Prec@(1,5) (69.1%, 92.6%)	
07/04 10:08:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][350/703]	Step 83422	lr 0.01	Loss 1.0481 (1.0553)	Prec@(1,5) (68.9%, 92.5%)	
07/04 10:08:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][400/703]	Step 83472	lr 0.01	Loss 1.1459 (1.0558)	Prec@(1,5) (68.9%, 92.5%)	
07/04 10:08:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][450/703]	Step 83522	lr 0.01	Loss 1.1322 (1.0635)	Prec@(1,5) (68.7%, 92.4%)	
07/04 10:08:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][500/703]	Step 83572	lr 0.01	Loss 0.8685 (1.0647)	Prec@(1,5) (68.7%, 92.3%)	
07/04 10:08:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][550/703]	Step 83622	lr 0.01	Loss 1.2029 (1.0677)	Prec@(1,5) (68.6%, 92.3%)	
07/04 10:08:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][600/703]	Step 83672	lr 0.01	Loss 1.1314 (1.0678)	Prec@(1,5) (68.6%, 92.3%)	
07/04 10:08:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][650/703]	Step 83722	lr 0.01	Loss 1.1870 (1.0701)	Prec@(1,5) (68.5%, 92.3%)	
07/04 10:08:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][700/703]	Step 83772	lr 0.01	Loss 1.2424 (1.0701)	Prec@(1,5) (68.5%, 92.3%)	
07/04 10:08:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [118][703/703]	Step 83775	lr 0.01	Loss 0.8987 (1.0697)	Prec@(1,5) (68.5%, 92.3%)	
07/04 10:08:39PM finetuneTeacher_trainer.py:185 [INFO] Train: [118/199] Final Prec@1 68.4889%
07/04 10:08:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [118][50/79]	Step 83776	Loss 1.6987	Prec@(1,5) (54.8%, 82.5%)
07/04 10:08:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [118][78/79]	Step 83776	Loss 1.7028	Prec@(1,5) (54.5%, 82.8%)
07/04 10:08:40PM finetuneTeacher_trainer.py:220 [INFO] Valid: [118/199] Final Prec@1 54.4800%
07/04 10:08:40PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:08:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][50/703]	Step 83826	lr 0.01	Loss 0.9667 (1.0799)	Prec@(1,5) (68.8%, 92.5%)	
07/04 10:08:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][100/703]	Step 83876	lr 0.01	Loss 1.2124 (1.0571)	Prec@(1,5) (69.3%, 92.6%)	
07/04 10:08:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][150/703]	Step 83926	lr 0.01	Loss 0.9580 (1.0380)	Prec@(1,5) (69.7%, 92.9%)	
07/04 10:08:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][200/703]	Step 83976	lr 0.01	Loss 1.0599 (1.0417)	Prec@(1,5) (69.6%, 92.9%)	
07/04 10:08:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][250/703]	Step 84026	lr 0.01	Loss 1.1082 (1.0365)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:08:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][300/703]	Step 84076	lr 0.01	Loss 0.7018 (1.0371)	Prec@(1,5) (69.7%, 93.0%)	
07/04 10:09:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][350/703]	Step 84126	lr 0.01	Loss 0.8517 (1.0408)	Prec@(1,5) (69.5%, 92.9%)	
07/04 10:09:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][400/703]	Step 84176	lr 0.01	Loss 1.0401 (1.0435)	Prec@(1,5) (69.4%, 93.0%)	
07/04 10:09:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][450/703]	Step 84226	lr 0.01	Loss 0.7883 (1.0473)	Prec@(1,5) (69.3%, 92.9%)	
07/04 10:09:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][500/703]	Step 84276	lr 0.01	Loss 1.1445 (1.0501)	Prec@(1,5) (69.1%, 92.9%)	
07/04 10:09:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][550/703]	Step 84326	lr 0.01	Loss 1.1025 (1.0550)	Prec@(1,5) (69.0%, 92.8%)	
07/04 10:09:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][600/703]	Step 84376	lr 0.01	Loss 1.2145 (1.0605)	Prec@(1,5) (68.9%, 92.7%)	
07/04 10:09:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][650/703]	Step 84426	lr 0.01	Loss 1.1122 (1.0612)	Prec@(1,5) (68.9%, 92.7%)	
07/04 10:09:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][700/703]	Step 84476	lr 0.01	Loss 1.1947 (1.0650)	Prec@(1,5) (68.8%, 92.6%)	
07/04 10:09:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [119][703/703]	Step 84479	lr 0.01	Loss 0.8827 (1.0646)	Prec@(1,5) (68.8%, 92.7%)	
07/04 10:09:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [119/199] Final Prec@1 68.8067%
07/04 10:09:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [119][50/79]	Step 84480	Loss 1.6474	Prec@(1,5) (55.9%, 83.2%)
07/04 10:09:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [119][78/79]	Step 84480	Loss 1.6617	Prec@(1,5) (55.3%, 83.2%)
07/04 10:09:27PM finetuneTeacher_trainer.py:220 [INFO] Valid: [119/199] Final Prec@1 55.3200%
07/04 10:09:27PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:09:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][50/703]	Step 84530	lr 0.01	Loss 1.4099 (1.0205)	Prec@(1,5) (69.5%, 92.9%)	
07/04 10:09:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][100/703]	Step 84580	lr 0.01	Loss 0.8962 (1.0211)	Prec@(1,5) (69.9%, 92.7%)	
07/04 10:09:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][150/703]	Step 84630	lr 0.01	Loss 1.2477 (1.0224)	Prec@(1,5) (69.8%, 92.9%)	
07/04 10:09:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][200/703]	Step 84680	lr 0.01	Loss 0.9757 (1.0203)	Prec@(1,5) (70.0%, 93.0%)	
07/04 10:09:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][250/703]	Step 84730	lr 0.01	Loss 1.1526 (1.0203)	Prec@(1,5) (70.0%, 93.0%)	
07/04 10:09:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][300/703]	Step 84780	lr 0.01	Loss 1.2365 (1.0229)	Prec@(1,5) (69.9%, 93.0%)	
07/04 10:09:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][350/703]	Step 84830	lr 0.01	Loss 0.9011 (1.0286)	Prec@(1,5) (69.9%, 92.8%)	
07/04 10:09:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][400/703]	Step 84880	lr 0.01	Loss 0.9445 (1.0341)	Prec@(1,5) (69.8%, 92.8%)	
07/04 10:09:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][450/703]	Step 84930	lr 0.01	Loss 0.8619 (1.0350)	Prec@(1,5) (69.8%, 92.8%)	
07/04 10:09:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][500/703]	Step 84980	lr 0.01	Loss 0.9765 (1.0349)	Prec@(1,5) (69.9%, 92.8%)	
07/04 10:10:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][550/703]	Step 85030	lr 0.01	Loss 0.9038 (1.0391)	Prec@(1,5) (69.7%, 92.7%)	
07/04 10:10:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][600/703]	Step 85080	lr 0.01	Loss 1.1808 (1.0421)	Prec@(1,5) (69.5%, 92.7%)	
07/04 10:10:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][650/703]	Step 85130	lr 0.01	Loss 1.0954 (1.0482)	Prec@(1,5) (69.3%, 92.7%)	
07/04 10:10:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][700/703]	Step 85180	lr 0.01	Loss 1.2536 (1.0537)	Prec@(1,5) (69.2%, 92.6%)	
07/04 10:10:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [120][703/703]	Step 85183	lr 0.01	Loss 1.0391 (1.0543)	Prec@(1,5) (69.1%, 92.6%)	
07/04 10:10:11PM finetuneTeacher_trainer.py:185 [INFO] Train: [120/199] Final Prec@1 69.1422%
07/04 10:10:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [120][50/79]	Step 85184	Loss 1.6744	Prec@(1,5) (55.0%, 83.6%)
07/04 10:10:13PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [120][78/79]	Step 85184	Loss 1.7013	Prec@(1,5) (54.4%, 83.1%)
07/04 10:10:13PM finetuneTeacher_trainer.py:220 [INFO] Valid: [120/199] Final Prec@1 54.3800%
07/04 10:10:13PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:10:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][50/703]	Step 85234	lr 0.01	Loss 1.0553 (1.0893)	Prec@(1,5) (68.9%, 91.7%)	
07/04 10:10:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][100/703]	Step 85284	lr 0.01	Loss 1.0530 (1.0501)	Prec@(1,5) (69.3%, 92.6%)	
07/04 10:10:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][150/703]	Step 85334	lr 0.01	Loss 1.2087 (1.0345)	Prec@(1,5) (69.6%, 92.7%)	
07/04 10:10:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][200/703]	Step 85384	lr 0.01	Loss 1.1813 (1.0319)	Prec@(1,5) (69.7%, 92.7%)	
07/04 10:10:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][250/703]	Step 85434	lr 0.01	Loss 0.9829 (1.0316)	Prec@(1,5) (69.8%, 92.8%)	
07/04 10:10:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][300/703]	Step 85484	lr 0.01	Loss 0.9441 (1.0347)	Prec@(1,5) (69.9%, 92.7%)	
07/04 10:10:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][350/703]	Step 85534	lr 0.01	Loss 0.7162 (1.0375)	Prec@(1,5) (69.9%, 92.7%)	
07/04 10:10:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][400/703]	Step 85584	lr 0.01	Loss 1.1008 (1.0406)	Prec@(1,5) (69.7%, 92.7%)	
07/04 10:10:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][450/703]	Step 85634	lr 0.01	Loss 1.1112 (1.0457)	Prec@(1,5) (69.6%, 92.6%)	
07/04 10:10:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][500/703]	Step 85684	lr 0.01	Loss 1.4622 (1.0480)	Prec@(1,5) (69.5%, 92.6%)	
07/04 10:10:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][550/703]	Step 85734	lr 0.01	Loss 1.2799 (1.0493)	Prec@(1,5) (69.5%, 92.6%)	
07/04 10:10:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][600/703]	Step 85784	lr 0.01	Loss 1.1846 (1.0526)	Prec@(1,5) (69.4%, 92.5%)	
07/04 10:10:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][650/703]	Step 85834	lr 0.01	Loss 0.9906 (1.0522)	Prec@(1,5) (69.3%, 92.6%)	
07/04 10:10:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][700/703]	Step 85884	lr 0.01	Loss 0.8195 (1.0550)	Prec@(1,5) (69.2%, 92.5%)	
07/04 10:10:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [121][703/703]	Step 85887	lr 0.01	Loss 1.0691 (1.0554)	Prec@(1,5) (69.2%, 92.5%)	
07/04 10:10:58PM finetuneTeacher_trainer.py:185 [INFO] Train: [121/199] Final Prec@1 69.2089%
07/04 10:10:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [121][50/79]	Step 85888	Loss 1.6396	Prec@(1,5) (56.7%, 83.5%)
07/04 10:10:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [121][78/79]	Step 85888	Loss 1.6624	Prec@(1,5) (55.8%, 83.5%)
07/04 10:10:59PM finetuneTeacher_trainer.py:220 [INFO] Valid: [121/199] Final Prec@1 55.9000%
07/04 10:10:59PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5400%
07/04 10:11:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][50/703]	Step 85938	lr 0.01	Loss 1.4061 (1.0031)	Prec@(1,5) (70.4%, 93.3%)	
07/04 10:11:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][100/703]	Step 85988	lr 0.01	Loss 1.0166 (0.9930)	Prec@(1,5) (70.9%, 93.4%)	
07/04 10:11:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][150/703]	Step 86038	lr 0.01	Loss 1.0714 (1.0108)	Prec@(1,5) (70.2%, 93.2%)	
07/04 10:11:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][200/703]	Step 86088	lr 0.01	Loss 0.8846 (1.0066)	Prec@(1,5) (70.3%, 93.1%)	
07/04 10:11:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][250/703]	Step 86138	lr 0.01	Loss 1.2754 (1.0126)	Prec@(1,5) (70.3%, 93.0%)	
07/04 10:11:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][300/703]	Step 86188	lr 0.01	Loss 1.1801 (1.0153)	Prec@(1,5) (70.2%, 93.0%)	
07/04 10:11:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][350/703]	Step 86238	lr 0.01	Loss 1.0762 (1.0238)	Prec@(1,5) (70.0%, 92.9%)	
07/04 10:11:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][400/703]	Step 86288	lr 0.01	Loss 0.9704 (1.0265)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:11:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][450/703]	Step 86338	lr 0.01	Loss 0.9881 (1.0245)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:11:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][500/703]	Step 86388	lr 0.01	Loss 0.9384 (1.0262)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:11:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][550/703]	Step 86438	lr 0.01	Loss 1.1787 (1.0330)	Prec@(1,5) (69.6%, 92.9%)	
07/04 10:11:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][600/703]	Step 86488	lr 0.01	Loss 1.2342 (1.0376)	Prec@(1,5) (69.5%, 92.8%)	
07/04 10:11:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][650/703]	Step 86538	lr 0.01	Loss 1.6055 (1.0390)	Prec@(1,5) (69.5%, 92.8%)	
07/04 10:11:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][700/703]	Step 86588	lr 0.01	Loss 0.7560 (1.0407)	Prec@(1,5) (69.4%, 92.7%)	
07/04 10:11:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [122][703/703]	Step 86591	lr 0.01	Loss 1.0589 (1.0412)	Prec@(1,5) (69.4%, 92.7%)	
07/04 10:11:44PM finetuneTeacher_trainer.py:185 [INFO] Train: [122/199] Final Prec@1 69.4289%
07/04 10:11:45PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [122][50/79]	Step 86592	Loss 1.6838	Prec@(1,5) (55.6%, 83.3%)
07/04 10:11:45PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [122][78/79]	Step 86592	Loss 1.6237	Prec@(1,5) (56.6%, 84.2%)
07/04 10:11:45PM finetuneTeacher_trainer.py:220 [INFO] Valid: [122/199] Final Prec@1 56.5800%
07/04 10:11:45PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:11:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][50/703]	Step 86642	lr 0.01	Loss 1.0036 (1.0113)	Prec@(1,5) (70.7%, 93.8%)	
07/04 10:11:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][100/703]	Step 86692	lr 0.01	Loss 1.2263 (0.9991)	Prec@(1,5) (70.6%, 93.7%)	
07/04 10:11:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][150/703]	Step 86742	lr 0.01	Loss 0.6956 (1.0029)	Prec@(1,5) (70.5%, 93.5%)	
07/04 10:11:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][200/703]	Step 86792	lr 0.01	Loss 1.1188 (0.9995)	Prec@(1,5) (70.5%, 93.5%)	
07/04 10:12:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][250/703]	Step 86842	lr 0.01	Loss 1.1828 (1.0064)	Prec@(1,5) (70.3%, 93.4%)	
07/04 10:12:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][300/703]	Step 86892	lr 0.01	Loss 1.0146 (1.0095)	Prec@(1,5) (70.1%, 93.3%)	
07/04 10:12:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][350/703]	Step 86942	lr 0.01	Loss 0.9755 (1.0139)	Prec@(1,5) (69.9%, 93.2%)	
07/04 10:12:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][400/703]	Step 86992	lr 0.01	Loss 1.2801 (1.0185)	Prec@(1,5) (69.9%, 93.2%)	
07/04 10:12:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][450/703]	Step 87042	lr 0.01	Loss 1.0344 (1.0200)	Prec@(1,5) (69.8%, 93.2%)	
07/04 10:12:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][500/703]	Step 87092	lr 0.01	Loss 1.1459 (1.0253)	Prec@(1,5) (69.7%, 93.1%)	
07/04 10:12:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][550/703]	Step 87142	lr 0.01	Loss 1.1604 (1.0283)	Prec@(1,5) (69.7%, 93.0%)	
07/04 10:12:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][600/703]	Step 87192	lr 0.01	Loss 1.0629 (1.0335)	Prec@(1,5) (69.6%, 93.0%)	
07/04 10:12:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][650/703]	Step 87242	lr 0.01	Loss 1.0109 (1.0354)	Prec@(1,5) (69.5%, 92.9%)	
07/04 10:12:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][700/703]	Step 87292	lr 0.01	Loss 1.0430 (1.0402)	Prec@(1,5) (69.4%, 92.9%)	
07/04 10:12:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [123][703/703]	Step 87295	lr 0.01	Loss 0.9197 (1.0403)	Prec@(1,5) (69.3%, 92.9%)	
07/04 10:12:32PM finetuneTeacher_trainer.py:185 [INFO] Train: [123/199] Final Prec@1 69.3333%
07/04 10:12:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [123][50/79]	Step 87296	Loss 1.6756	Prec@(1,5) (55.9%, 83.1%)
07/04 10:12:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [123][78/79]	Step 87296	Loss 1.6683	Prec@(1,5) (56.2%, 83.2%)
07/04 10:12:33PM finetuneTeacher_trainer.py:220 [INFO] Valid: [123/199] Final Prec@1 56.1800%
07/04 10:12:33PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:12:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][50/703]	Step 87346	lr 0.01	Loss 1.1301 (1.0327)	Prec@(1,5) (69.4%, 93.5%)	
07/04 10:12:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][100/703]	Step 87396	lr 0.01	Loss 0.9260 (1.0340)	Prec@(1,5) (69.7%, 93.0%)	
07/04 10:12:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][150/703]	Step 87446	lr 0.01	Loss 1.0581 (1.0282)	Prec@(1,5) (69.6%, 93.1%)	
07/04 10:12:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][200/703]	Step 87496	lr 0.01	Loss 0.8245 (1.0264)	Prec@(1,5) (69.6%, 93.2%)	
07/04 10:12:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][250/703]	Step 87546	lr 0.01	Loss 1.0578 (1.0261)	Prec@(1,5) (69.6%, 93.1%)	
07/04 10:12:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][300/703]	Step 87596	lr 0.01	Loss 0.8712 (1.0210)	Prec@(1,5) (69.8%, 93.1%)	
07/04 10:12:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][350/703]	Step 87646	lr 0.01	Loss 0.9702 (1.0181)	Prec@(1,5) (69.7%, 93.1%)	
07/04 10:13:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][400/703]	Step 87696	lr 0.01	Loss 1.2461 (1.0166)	Prec@(1,5) (69.8%, 93.1%)	
07/04 10:13:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][450/703]	Step 87746	lr 0.01	Loss 0.8130 (1.0168)	Prec@(1,5) (69.9%, 93.1%)	
07/04 10:13:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][500/703]	Step 87796	lr 0.01	Loss 0.7613 (1.0202)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:13:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][550/703]	Step 87846	lr 0.01	Loss 0.7930 (1.0210)	Prec@(1,5) (69.6%, 93.0%)	
07/04 10:13:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][600/703]	Step 87896	lr 0.01	Loss 1.0908 (1.0250)	Prec@(1,5) (69.5%, 93.0%)	
07/04 10:13:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][650/703]	Step 87946	lr 0.01	Loss 1.0668 (1.0269)	Prec@(1,5) (69.5%, 93.0%)	
07/04 10:13:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][700/703]	Step 87996	lr 0.01	Loss 0.9665 (1.0269)	Prec@(1,5) (69.5%, 93.0%)	
07/04 10:13:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [124][703/703]	Step 87999	lr 0.01	Loss 0.8347 (1.0265)	Prec@(1,5) (69.5%, 93.0%)	
07/04 10:13:18PM finetuneTeacher_trainer.py:185 [INFO] Train: [124/199] Final Prec@1 69.5089%
07/04 10:13:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [124][50/79]	Step 88000	Loss 1.6635	Prec@(1,5) (54.7%, 83.8%)
07/04 10:13:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [124][78/79]	Step 88000	Loss 1.7059	Prec@(1,5) (54.8%, 83.1%)
07/04 10:13:20PM finetuneTeacher_trainer.py:220 [INFO] Valid: [124/199] Final Prec@1 54.7400%
07/04 10:13:20PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:13:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][50/703]	Step 88050	lr 0.01	Loss 0.8576 (0.9911)	Prec@(1,5) (70.5%, 93.1%)	
07/04 10:13:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][100/703]	Step 88100	lr 0.01	Loss 0.8720 (0.9783)	Prec@(1,5) (70.8%, 93.5%)	
07/04 10:13:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][150/703]	Step 88150	lr 0.01	Loss 1.1688 (0.9848)	Prec@(1,5) (70.8%, 93.5%)	
07/04 10:13:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][200/703]	Step 88200	lr 0.01	Loss 0.9768 (0.9879)	Prec@(1,5) (70.6%, 93.4%)	
07/04 10:13:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][250/703]	Step 88250	lr 0.01	Loss 0.8093 (0.9987)	Prec@(1,5) (70.3%, 93.2%)	
07/04 10:13:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][300/703]	Step 88300	lr 0.01	Loss 0.8400 (1.0014)	Prec@(1,5) (70.3%, 93.3%)	
07/04 10:13:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][350/703]	Step 88350	lr 0.01	Loss 0.9487 (1.0081)	Prec@(1,5) (70.1%, 93.2%)	
07/04 10:13:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][400/703]	Step 88400	lr 0.01	Loss 1.3423 (1.0081)	Prec@(1,5) (70.1%, 93.2%)	
07/04 10:13:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][450/703]	Step 88450	lr 0.01	Loss 1.1542 (1.0106)	Prec@(1,5) (70.1%, 93.1%)	
07/04 10:13:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][500/703]	Step 88500	lr 0.01	Loss 1.1449 (1.0158)	Prec@(1,5) (70.0%, 93.1%)	
07/04 10:13:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][550/703]	Step 88550	lr 0.01	Loss 1.0880 (1.0159)	Prec@(1,5) (70.0%, 93.2%)	
07/04 10:13:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][600/703]	Step 88600	lr 0.01	Loss 1.1585 (1.0148)	Prec@(1,5) (70.0%, 93.2%)	
07/04 10:14:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][650/703]	Step 88650	lr 0.01	Loss 1.5366 (1.0209)	Prec@(1,5) (69.8%, 93.2%)	
07/04 10:14:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][700/703]	Step 88700	lr 0.01	Loss 1.3781 (1.0254)	Prec@(1,5) (69.7%, 93.1%)	
07/04 10:14:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [125][703/703]	Step 88703	lr 0.01	Loss 0.8883 (1.0261)	Prec@(1,5) (69.7%, 93.1%)	
07/04 10:14:06PM finetuneTeacher_trainer.py:185 [INFO] Train: [125/199] Final Prec@1 69.6578%
07/04 10:14:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [125][50/79]	Step 88704	Loss 1.6927	Prec@(1,5) (54.2%, 83.8%)
07/04 10:14:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [125][78/79]	Step 88704	Loss 1.6841	Prec@(1,5) (54.8%, 83.7%)
07/04 10:14:07PM finetuneTeacher_trainer.py:220 [INFO] Valid: [125/199] Final Prec@1 54.7800%
07/04 10:14:07PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:14:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][50/703]	Step 88754	lr 0.01	Loss 1.2287 (0.9752)	Prec@(1,5) (72.2%, 93.3%)	
07/04 10:14:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][100/703]	Step 88804	lr 0.01	Loss 0.9492 (0.9813)	Prec@(1,5) (71.4%, 93.5%)	
07/04 10:14:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][150/703]	Step 88854	lr 0.01	Loss 0.8502 (0.9883)	Prec@(1,5) (71.2%, 93.2%)	
07/04 10:14:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][200/703]	Step 88904	lr 0.01	Loss 1.2441 (1.0012)	Prec@(1,5) (70.6%, 93.2%)	
07/04 10:14:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][250/703]	Step 88954	lr 0.01	Loss 0.8689 (1.0027)	Prec@(1,5) (70.4%, 93.2%)	
07/04 10:14:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][300/703]	Step 89004	lr 0.01	Loss 1.0517 (1.0029)	Prec@(1,5) (70.4%, 93.2%)	
07/04 10:14:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][350/703]	Step 89054	lr 0.01	Loss 0.7819 (1.0074)	Prec@(1,5) (70.4%, 93.1%)	
07/04 10:14:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][400/703]	Step 89104	lr 0.01	Loss 1.1322 (1.0137)	Prec@(1,5) (70.2%, 93.2%)	
07/04 10:14:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][450/703]	Step 89154	lr 0.01	Loss 1.1768 (1.0134)	Prec@(1,5) (70.1%, 93.2%)	
07/04 10:14:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][500/703]	Step 89204	lr 0.01	Loss 0.8762 (1.0138)	Prec@(1,5) (70.1%, 93.2%)	
07/04 10:14:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][550/703]	Step 89254	lr 0.01	Loss 1.1458 (1.0181)	Prec@(1,5) (70.0%, 93.1%)	
07/04 10:14:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][600/703]	Step 89304	lr 0.01	Loss 1.2967 (1.0210)	Prec@(1,5) (70.0%, 93.1%)	
07/04 10:14:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][650/703]	Step 89354	lr 0.01	Loss 0.8811 (1.0239)	Prec@(1,5) (69.9%, 93.1%)	
07/04 10:14:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][700/703]	Step 89404	lr 0.01	Loss 1.0391 (1.0251)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:14:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [126][703/703]	Step 89407	lr 0.01	Loss 1.2099 (1.0255)	Prec@(1,5) (69.8%, 93.0%)	
07/04 10:14:53PM finetuneTeacher_trainer.py:185 [INFO] Train: [126/199] Final Prec@1 69.7911%
07/04 10:14:54PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [126][50/79]	Step 89408	Loss 1.6472	Prec@(1,5) (56.6%, 83.8%)
07/04 10:14:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [126][78/79]	Step 89408	Loss 1.6845	Prec@(1,5) (55.9%, 83.1%)
07/04 10:14:55PM finetuneTeacher_trainer.py:220 [INFO] Valid: [126/199] Final Prec@1 55.9800%
07/04 10:14:55PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:14:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][50/703]	Step 89458	lr 0.01	Loss 0.8432 (0.9719)	Prec@(1,5) (71.3%, 94.3%)	
07/04 10:15:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][100/703]	Step 89508	lr 0.01	Loss 1.2811 (0.9815)	Prec@(1,5) (70.9%, 93.8%)	
07/04 10:15:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][150/703]	Step 89558	lr 0.01	Loss 1.1928 (0.9853)	Prec@(1,5) (70.8%, 93.7%)	
07/04 10:15:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][200/703]	Step 89608	lr 0.01	Loss 1.0125 (0.9875)	Prec@(1,5) (70.5%, 93.5%)	
07/04 10:15:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][250/703]	Step 89658	lr 0.01	Loss 0.9800 (0.9898)	Prec@(1,5) (70.6%, 93.3%)	
07/04 10:15:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][300/703]	Step 89708	lr 0.01	Loss 0.9046 (0.9910)	Prec@(1,5) (70.5%, 93.4%)	
07/04 10:15:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][350/703]	Step 89758	lr 0.01	Loss 1.0613 (0.9993)	Prec@(1,5) (70.4%, 93.2%)	
07/04 10:15:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][400/703]	Step 89808	lr 0.01	Loss 1.0509 (1.0028)	Prec@(1,5) (70.3%, 93.1%)	
07/04 10:15:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][450/703]	Step 89858	lr 0.01	Loss 0.9724 (1.0051)	Prec@(1,5) (70.3%, 93.1%)	
07/04 10:15:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][500/703]	Step 89908	lr 0.01	Loss 1.2244 (1.0066)	Prec@(1,5) (70.2%, 93.1%)	
07/04 10:15:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][550/703]	Step 89958	lr 0.01	Loss 1.2435 (1.0115)	Prec@(1,5) (70.2%, 93.0%)	
07/04 10:15:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][600/703]	Step 90008	lr 0.01	Loss 1.0335 (1.0120)	Prec@(1,5) (70.2%, 93.1%)	
07/04 10:15:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][650/703]	Step 90058	lr 0.01	Loss 0.9966 (1.0157)	Prec@(1,5) (70.0%, 93.1%)	
07/04 10:15:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][700/703]	Step 90108	lr 0.01	Loss 0.7922 (1.0200)	Prec@(1,5) (69.9%, 93.0%)	
07/04 10:15:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [127][703/703]	Step 90111	lr 0.01	Loss 1.0877 (1.0204)	Prec@(1,5) (69.9%, 93.0%)	
07/04 10:15:39PM finetuneTeacher_trainer.py:185 [INFO] Train: [127/199] Final Prec@1 69.9244%
07/04 10:15:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [127][50/79]	Step 90112	Loss 1.7185	Prec@(1,5) (54.9%, 82.7%)
07/04 10:15:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [127][78/79]	Step 90112	Loss 1.7321	Prec@(1,5) (54.7%, 82.7%)
07/04 10:15:40PM finetuneTeacher_trainer.py:220 [INFO] Valid: [127/199] Final Prec@1 54.7000%
07/04 10:15:41PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:15:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][50/703]	Step 90162	lr 0.01	Loss 1.2988 (0.9444)	Prec@(1,5) (73.4%, 93.6%)	
07/04 10:15:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][100/703]	Step 90212	lr 0.01	Loss 0.9732 (0.9497)	Prec@(1,5) (72.4%, 94.0%)	
07/04 10:15:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][150/703]	Step 90262	lr 0.01	Loss 0.8261 (0.9571)	Prec@(1,5) (72.1%, 93.9%)	
07/04 10:15:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][200/703]	Step 90312	lr 0.01	Loss 0.8060 (0.9737)	Prec@(1,5) (71.7%, 93.7%)	
07/04 10:15:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][250/703]	Step 90362	lr 0.01	Loss 0.8171 (0.9769)	Prec@(1,5) (71.5%, 93.7%)	
07/04 10:16:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][300/703]	Step 90412	lr 0.01	Loss 1.1320 (0.9914)	Prec@(1,5) (71.1%, 93.5%)	
07/04 10:16:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][350/703]	Step 90462	lr 0.01	Loss 1.0940 (0.9925)	Prec@(1,5) (71.0%, 93.6%)	
07/04 10:16:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][400/703]	Step 90512	lr 0.01	Loss 1.0421 (1.0024)	Prec@(1,5) (70.7%, 93.4%)	
07/04 10:16:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][450/703]	Step 90562	lr 0.01	Loss 1.1828 (1.0045)	Prec@(1,5) (70.6%, 93.4%)	
07/04 10:16:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][500/703]	Step 90612	lr 0.01	Loss 0.9963 (1.0054)	Prec@(1,5) (70.5%, 93.3%)	
07/04 10:16:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][550/703]	Step 90662	lr 0.01	Loss 0.8760 (1.0075)	Prec@(1,5) (70.4%, 93.3%)	
07/04 10:16:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][600/703]	Step 90712	lr 0.01	Loss 0.8344 (1.0111)	Prec@(1,5) (70.3%, 93.2%)	
07/04 10:16:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][650/703]	Step 90762	lr 0.01	Loss 1.1825 (1.0166)	Prec@(1,5) (70.2%, 93.1%)	
07/04 10:16:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][700/703]	Step 90812	lr 0.01	Loss 1.0493 (1.0201)	Prec@(1,5) (70.1%, 93.1%)	
07/04 10:16:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [128][703/703]	Step 90815	lr 0.01	Loss 1.1138 (1.0209)	Prec@(1,5) (70.1%, 93.1%)	
07/04 10:16:26PM finetuneTeacher_trainer.py:185 [INFO] Train: [128/199] Final Prec@1 70.0600%
07/04 10:16:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [128][50/79]	Step 90816	Loss 1.7013	Prec@(1,5) (55.0%, 83.6%)
07/04 10:16:28PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [128][78/79]	Step 90816	Loss 1.6999	Prec@(1,5) (55.0%, 83.4%)
07/04 10:16:28PM finetuneTeacher_trainer.py:220 [INFO] Valid: [128/199] Final Prec@1 54.9800%
07/04 10:16:28PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:16:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][50/703]	Step 90866	lr 0.01	Loss 0.9153 (0.9928)	Prec@(1,5) (70.4%, 93.2%)	
07/04 10:16:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][100/703]	Step 90916	lr 0.01	Loss 0.9588 (0.9882)	Prec@(1,5) (70.7%, 93.5%)	
07/04 10:16:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][150/703]	Step 90966	lr 0.01	Loss 1.0692 (0.9959)	Prec@(1,5) (70.7%, 93.4%)	
07/04 10:16:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][200/703]	Step 91016	lr 0.01	Loss 0.7396 (0.9996)	Prec@(1,5) (70.5%, 93.4%)	
07/04 10:16:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][250/703]	Step 91066	lr 0.01	Loss 1.1199 (0.9941)	Prec@(1,5) (70.7%, 93.5%)	
07/04 10:16:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][300/703]	Step 91116	lr 0.01	Loss 0.7100 (0.9961)	Prec@(1,5) (70.4%, 93.5%)	
07/04 10:16:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][350/703]	Step 91166	lr 0.01	Loss 0.9202 (0.9937)	Prec@(1,5) (70.6%, 93.4%)	
07/04 10:16:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][400/703]	Step 91216	lr 0.01	Loss 1.1141 (0.9927)	Prec@(1,5) (70.6%, 93.4%)	
07/04 10:16:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][450/703]	Step 91266	lr 0.01	Loss 0.9502 (0.9977)	Prec@(1,5) (70.5%, 93.3%)	
07/04 10:17:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][500/703]	Step 91316	lr 0.01	Loss 0.7408 (0.9975)	Prec@(1,5) (70.6%, 93.3%)	
07/04 10:17:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][550/703]	Step 91366	lr 0.01	Loss 0.9246 (1.0013)	Prec@(1,5) (70.4%, 93.3%)	
07/04 10:17:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][600/703]	Step 91416	lr 0.01	Loss 1.0245 (1.0066)	Prec@(1,5) (70.3%, 93.2%)	
07/04 10:17:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][650/703]	Step 91466	lr 0.01	Loss 0.8933 (1.0103)	Prec@(1,5) (70.2%, 93.2%)	
07/04 10:17:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][700/703]	Step 91516	lr 0.01	Loss 0.6925 (1.0089)	Prec@(1,5) (70.2%, 93.2%)	
07/04 10:17:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [129][703/703]	Step 91519	lr 0.01	Loss 0.9037 (1.0086)	Prec@(1,5) (70.2%, 93.2%)	
07/04 10:17:13PM finetuneTeacher_trainer.py:185 [INFO] Train: [129/199] Final Prec@1 70.2289%
07/04 10:17:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [129][50/79]	Step 91520	Loss 1.7380	Prec@(1,5) (53.7%, 83.1%)
07/04 10:17:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [129][78/79]	Step 91520	Loss 1.7090	Prec@(1,5) (54.3%, 83.3%)
07/04 10:17:14PM finetuneTeacher_trainer.py:220 [INFO] Valid: [129/199] Final Prec@1 54.3000%
07/04 10:17:14PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:17:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][50/703]	Step 91570	lr 0.01	Loss 1.2327 (0.9851)	Prec@(1,5) (71.0%, 93.8%)	
07/04 10:17:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][100/703]	Step 91620	lr 0.01	Loss 0.8079 (0.9801)	Prec@(1,5) (71.3%, 93.7%)	
07/04 10:17:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][150/703]	Step 91670	lr 0.01	Loss 1.1248 (0.9706)	Prec@(1,5) (71.3%, 93.8%)	
07/04 10:17:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][200/703]	Step 91720	lr 0.01	Loss 0.9296 (0.9742)	Prec@(1,5) (71.1%, 93.9%)	
07/04 10:17:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][250/703]	Step 91770	lr 0.01	Loss 1.0889 (0.9737)	Prec@(1,5) (71.3%, 93.9%)	
07/04 10:17:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][300/703]	Step 91820	lr 0.01	Loss 0.9629 (0.9742)	Prec@(1,5) (71.2%, 93.8%)	
07/04 10:17:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][350/703]	Step 91870	lr 0.01	Loss 1.1117 (0.9757)	Prec@(1,5) (71.2%, 93.8%)	
07/04 10:17:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][400/703]	Step 91920	lr 0.01	Loss 1.1316 (0.9778)	Prec@(1,5) (71.1%, 93.7%)	
07/04 10:17:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][450/703]	Step 91970	lr 0.01	Loss 1.2516 (0.9832)	Prec@(1,5) (70.9%, 93.6%)	
07/04 10:17:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][500/703]	Step 92020	lr 0.01	Loss 1.2453 (0.9848)	Prec@(1,5) (70.9%, 93.6%)	
07/04 10:17:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][550/703]	Step 92070	lr 0.01	Loss 0.9378 (0.9881)	Prec@(1,5) (70.8%, 93.6%)	
07/04 10:17:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][600/703]	Step 92120	lr 0.01	Loss 0.8916 (0.9951)	Prec@(1,5) (70.6%, 93.5%)	
07/04 10:17:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][650/703]	Step 92170	lr 0.01	Loss 1.0392 (0.9984)	Prec@(1,5) (70.5%, 93.5%)	
07/04 10:18:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][700/703]	Step 92220	lr 0.01	Loss 0.8135 (0.9995)	Prec@(1,5) (70.4%, 93.5%)	
07/04 10:18:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [130][703/703]	Step 92223	lr 0.01	Loss 1.0146 (0.9997)	Prec@(1,5) (70.4%, 93.5%)	
07/04 10:18:00PM finetuneTeacher_trainer.py:185 [INFO] Train: [130/199] Final Prec@1 70.4089%
07/04 10:18:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [130][50/79]	Step 92224	Loss 1.7109	Prec@(1,5) (55.5%, 83.3%)
07/04 10:18:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [130][78/79]	Step 92224	Loss 1.6973	Prec@(1,5) (56.0%, 83.4%)
07/04 10:18:02PM finetuneTeacher_trainer.py:220 [INFO] Valid: [130/199] Final Prec@1 55.9600%
07/04 10:18:02PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:18:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][50/703]	Step 92274	lr 0.01	Loss 0.9250 (0.9611)	Prec@(1,5) (71.3%, 93.9%)	
07/04 10:18:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][100/703]	Step 92324	lr 0.01	Loss 1.1421 (0.9673)	Prec@(1,5) (71.2%, 94.2%)	
07/04 10:18:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][150/703]	Step 92374	lr 0.01	Loss 0.8202 (0.9713)	Prec@(1,5) (71.1%, 94.1%)	
07/04 10:18:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][200/703]	Step 92424	lr 0.01	Loss 1.1169 (0.9654)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:18:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][250/703]	Step 92474	lr 0.01	Loss 1.2089 (0.9760)	Prec@(1,5) (71.2%, 93.8%)	
07/04 10:18:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][300/703]	Step 92524	lr 0.01	Loss 0.9592 (0.9831)	Prec@(1,5) (70.9%, 93.7%)	
07/04 10:18:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][350/703]	Step 92574	lr 0.01	Loss 0.8626 (0.9817)	Prec@(1,5) (71.1%, 93.6%)	
07/04 10:18:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][400/703]	Step 92624	lr 0.01	Loss 1.3625 (0.9873)	Prec@(1,5) (70.9%, 93.6%)	
07/04 10:18:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][450/703]	Step 92674	lr 0.01	Loss 0.8573 (0.9891)	Prec@(1,5) (70.7%, 93.5%)	
07/04 10:18:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][500/703]	Step 92724	lr 0.01	Loss 0.8193 (0.9882)	Prec@(1,5) (70.8%, 93.5%)	
07/04 10:18:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][550/703]	Step 92774	lr 0.01	Loss 1.4118 (0.9897)	Prec@(1,5) (70.6%, 93.6%)	
07/04 10:18:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][600/703]	Step 92824	lr 0.01	Loss 0.7366 (0.9897)	Prec@(1,5) (70.7%, 93.6%)	
07/04 10:18:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][650/703]	Step 92874	lr 0.01	Loss 1.0144 (0.9950)	Prec@(1,5) (70.5%, 93.5%)	
07/04 10:18:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][700/703]	Step 92924	lr 0.01	Loss 0.8305 (0.9973)	Prec@(1,5) (70.4%, 93.4%)	
07/04 10:18:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [131][703/703]	Step 92927	lr 0.01	Loss 0.8778 (0.9978)	Prec@(1,5) (70.4%, 93.4%)	
07/04 10:18:48PM finetuneTeacher_trainer.py:185 [INFO] Train: [131/199] Final Prec@1 70.4267%
07/04 10:18:49PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [131][50/79]	Step 92928	Loss 1.7224	Prec@(1,5) (54.6%, 82.7%)
07/04 10:18:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [131][78/79]	Step 92928	Loss 1.7158	Prec@(1,5) (54.8%, 82.7%)
07/04 10:18:50PM finetuneTeacher_trainer.py:220 [INFO] Valid: [131/199] Final Prec@1 54.8200%
07/04 10:18:50PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:18:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][50/703]	Step 92978	lr 0.01	Loss 0.7394 (0.9488)	Prec@(1,5) (72.5%, 94.3%)	
07/04 10:18:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][100/703]	Step 93028	lr 0.01	Loss 0.7531 (0.9284)	Prec@(1,5) (73.0%, 94.4%)	
07/04 10:19:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][150/703]	Step 93078	lr 0.01	Loss 1.0211 (0.9403)	Prec@(1,5) (72.6%, 94.3%)	
07/04 10:19:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][200/703]	Step 93128	lr 0.01	Loss 1.1498 (0.9473)	Prec@(1,5) (72.2%, 94.1%)	
07/04 10:19:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][250/703]	Step 93178	lr 0.01	Loss 1.2089 (0.9613)	Prec@(1,5) (71.8%, 93.8%)	
07/04 10:19:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][300/703]	Step 93228	lr 0.01	Loss 0.9481 (0.9675)	Prec@(1,5) (71.5%, 93.8%)	
07/04 10:19:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][350/703]	Step 93278	lr 0.01	Loss 0.8661 (0.9693)	Prec@(1,5) (71.5%, 93.8%)	
07/04 10:19:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][400/703]	Step 93328	lr 0.01	Loss 0.9263 (0.9724)	Prec@(1,5) (71.4%, 93.7%)	
07/04 10:19:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][450/703]	Step 93378	lr 0.01	Loss 0.8053 (0.9732)	Prec@(1,5) (71.3%, 93.7%)	
07/04 10:19:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][500/703]	Step 93428	lr 0.01	Loss 0.8193 (0.9751)	Prec@(1,5) (71.3%, 93.7%)	
07/04 10:19:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][550/703]	Step 93478	lr 0.01	Loss 1.1754 (0.9809)	Prec@(1,5) (71.1%, 93.6%)	
07/04 10:19:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][600/703]	Step 93528	lr 0.01	Loss 1.0645 (0.9845)	Prec@(1,5) (71.0%, 93.6%)	
07/04 10:19:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][650/703]	Step 93578	lr 0.01	Loss 0.6194 (0.9901)	Prec@(1,5) (70.8%, 93.5%)	
07/04 10:19:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][700/703]	Step 93628	lr 0.01	Loss 1.1409 (0.9961)	Prec@(1,5) (70.7%, 93.5%)	
07/04 10:19:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [132][703/703]	Step 93631	lr 0.01	Loss 1.0719 (0.9965)	Prec@(1,5) (70.6%, 93.5%)	
07/04 10:19:36PM finetuneTeacher_trainer.py:185 [INFO] Train: [132/199] Final Prec@1 70.6156%
07/04 10:19:37PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [132][50/79]	Step 93632	Loss 1.7885	Prec@(1,5) (54.2%, 81.7%)
07/04 10:19:37PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [132][78/79]	Step 93632	Loss 1.7413	Prec@(1,5) (55.1%, 82.5%)
07/04 10:19:37PM finetuneTeacher_trainer.py:220 [INFO] Valid: [132/199] Final Prec@1 55.0600%
07/04 10:19:38PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:19:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][50/703]	Step 93682	lr 0.01	Loss 0.8428 (0.9925)	Prec@(1,5) (71.0%, 93.6%)	
07/04 10:19:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][100/703]	Step 93732	lr 0.01	Loss 1.1337 (0.9562)	Prec@(1,5) (72.0%, 94.0%)	
07/04 10:19:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][150/703]	Step 93782	lr 0.01	Loss 0.7812 (0.9649)	Prec@(1,5) (71.6%, 93.9%)	
07/04 10:19:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][200/703]	Step 93832	lr 0.01	Loss 0.8286 (0.9654)	Prec@(1,5) (71.5%, 93.9%)	
07/04 10:19:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][250/703]	Step 93882	lr 0.01	Loss 0.9663 (0.9704)	Prec@(1,5) (71.5%, 93.9%)	
07/04 10:19:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][300/703]	Step 93932	lr 0.01	Loss 0.7083 (0.9723)	Prec@(1,5) (71.5%, 93.9%)	
07/04 10:20:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][350/703]	Step 93982	lr 0.01	Loss 0.9270 (0.9770)	Prec@(1,5) (71.3%, 93.8%)	
07/04 10:20:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][400/703]	Step 94032	lr 0.01	Loss 0.9403 (0.9754)	Prec@(1,5) (71.3%, 93.8%)	
07/04 10:20:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][450/703]	Step 94082	lr 0.01	Loss 0.8761 (0.9770)	Prec@(1,5) (71.2%, 93.7%)	
07/04 10:20:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][500/703]	Step 94132	lr 0.01	Loss 1.3224 (0.9776)	Prec@(1,5) (71.3%, 93.7%)	
07/04 10:20:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][550/703]	Step 94182	lr 0.01	Loss 0.9466 (0.9783)	Prec@(1,5) (71.2%, 93.6%)	
07/04 10:20:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][600/703]	Step 94232	lr 0.01	Loss 1.2887 (0.9837)	Prec@(1,5) (71.1%, 93.6%)	
07/04 10:20:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][650/703]	Step 94282	lr 0.01	Loss 0.8177 (0.9876)	Prec@(1,5) (70.9%, 93.6%)	
07/04 10:20:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][700/703]	Step 94332	lr 0.01	Loss 1.0868 (0.9883)	Prec@(1,5) (70.9%, 93.5%)	
07/04 10:20:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [133][703/703]	Step 94335	lr 0.01	Loss 1.2454 (0.9890)	Prec@(1,5) (70.9%, 93.5%)	
07/04 10:20:25PM finetuneTeacher_trainer.py:185 [INFO] Train: [133/199] Final Prec@1 70.8622%
07/04 10:20:25PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [133][50/79]	Step 94336	Loss 1.6559	Prec@(1,5) (55.6%, 84.2%)
07/04 10:20:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [133][78/79]	Step 94336	Loss 1.7062	Prec@(1,5) (55.0%, 83.2%)
07/04 10:20:26PM finetuneTeacher_trainer.py:220 [INFO] Valid: [133/199] Final Prec@1 55.0800%
07/04 10:20:26PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:20:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][50/703]	Step 94386	lr 0.01	Loss 0.8965 (0.9348)	Prec@(1,5) (71.2%, 94.8%)	
07/04 10:20:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][100/703]	Step 94436	lr 0.01	Loss 0.9954 (0.9433)	Prec@(1,5) (71.9%, 94.4%)	
07/04 10:20:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][150/703]	Step 94486	lr 0.01	Loss 0.8786 (0.9386)	Prec@(1,5) (71.9%, 94.5%)	
07/04 10:20:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][200/703]	Step 94536	lr 0.01	Loss 0.5886 (0.9386)	Prec@(1,5) (71.9%, 94.5%)	
07/04 10:20:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][250/703]	Step 94586	lr 0.01	Loss 0.8269 (0.9465)	Prec@(1,5) (71.9%, 94.2%)	
07/04 10:20:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][300/703]	Step 94636	lr 0.01	Loss 1.0500 (0.9531)	Prec@(1,5) (71.7%, 94.1%)	
07/04 10:20:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][350/703]	Step 94686	lr 0.01	Loss 0.8559 (0.9571)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:20:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][400/703]	Step 94736	lr 0.01	Loss 0.8861 (0.9593)	Prec@(1,5) (71.4%, 94.0%)	
07/04 10:20:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][450/703]	Step 94786	lr 0.01	Loss 0.8320 (0.9674)	Prec@(1,5) (71.2%, 93.9%)	
07/04 10:20:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][500/703]	Step 94836	lr 0.01	Loss 0.9975 (0.9723)	Prec@(1,5) (71.0%, 93.8%)	
07/04 10:21:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][550/703]	Step 94886	lr 0.01	Loss 0.8512 (0.9753)	Prec@(1,5) (71.0%, 93.7%)	
07/04 10:21:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][600/703]	Step 94936	lr 0.01	Loss 0.9283 (0.9768)	Prec@(1,5) (71.0%, 93.7%)	
07/04 10:21:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][650/703]	Step 94986	lr 0.01	Loss 1.2562 (0.9778)	Prec@(1,5) (70.9%, 93.7%)	
07/04 10:21:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][700/703]	Step 95036	lr 0.01	Loss 1.1907 (0.9822)	Prec@(1,5) (70.8%, 93.7%)	
07/04 10:21:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [134][703/703]	Step 95039	lr 0.01	Loss 0.9248 (0.9824)	Prec@(1,5) (70.8%, 93.7%)	
07/04 10:21:11PM finetuneTeacher_trainer.py:185 [INFO] Train: [134/199] Final Prec@1 70.8311%
07/04 10:21:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [134][50/79]	Step 95040	Loss 1.7106	Prec@(1,5) (55.2%, 82.8%)
07/04 10:21:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [134][78/79]	Step 95040	Loss 1.7213	Prec@(1,5) (55.0%, 82.9%)
07/04 10:21:12PM finetuneTeacher_trainer.py:220 [INFO] Valid: [134/199] Final Prec@1 54.9200%
07/04 10:21:13PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:21:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][50/703]	Step 95090	lr 0.01	Loss 0.8324 (0.9352)	Prec@(1,5) (72.0%, 94.5%)	
07/04 10:21:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][100/703]	Step 95140	lr 0.01	Loss 0.8739 (0.9226)	Prec@(1,5) (72.6%, 94.8%)	
07/04 10:21:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][150/703]	Step 95190	lr 0.01	Loss 0.9548 (0.9337)	Prec@(1,5) (72.6%, 94.6%)	
07/04 10:21:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][200/703]	Step 95240	lr 0.01	Loss 0.8715 (0.9426)	Prec@(1,5) (72.4%, 94.4%)	
07/04 10:21:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][250/703]	Step 95290	lr 0.01	Loss 0.8428 (0.9402)	Prec@(1,5) (72.4%, 94.3%)	
07/04 10:21:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][300/703]	Step 95340	lr 0.01	Loss 0.9186 (0.9489)	Prec@(1,5) (72.2%, 94.3%)	
07/04 10:21:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][350/703]	Step 95390	lr 0.01	Loss 0.9650 (0.9464)	Prec@(1,5) (72.4%, 94.3%)	
07/04 10:21:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][400/703]	Step 95440	lr 0.01	Loss 0.6516 (0.9526)	Prec@(1,5) (72.1%, 94.1%)	
07/04 10:21:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][450/703]	Step 95490	lr 0.01	Loss 0.8359 (0.9533)	Prec@(1,5) (72.1%, 94.1%)	
07/04 10:21:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][500/703]	Step 95540	lr 0.01	Loss 1.0010 (0.9576)	Prec@(1,5) (71.9%, 94.0%)	
07/04 10:21:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][550/703]	Step 95590	lr 0.01	Loss 1.1423 (0.9591)	Prec@(1,5) (71.8%, 94.0%)	
07/04 10:21:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][600/703]	Step 95640	lr 0.01	Loss 1.0647 (0.9654)	Prec@(1,5) (71.6%, 94.0%)	
07/04 10:21:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][650/703]	Step 95690	lr 0.01	Loss 1.0972 (0.9678)	Prec@(1,5) (71.5%, 93.9%)	
07/04 10:21:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][700/703]	Step 95740	lr 0.01	Loss 1.0627 (0.9719)	Prec@(1,5) (71.3%, 93.8%)	
07/04 10:21:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [135][703/703]	Step 95743	lr 0.01	Loss 0.9917 (0.9721)	Prec@(1,5) (71.3%, 93.8%)	
07/04 10:21:59PM finetuneTeacher_trainer.py:185 [INFO] Train: [135/199] Final Prec@1 71.3267%
07/04 10:22:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [135][50/79]	Step 95744	Loss 1.8167	Prec@(1,5) (54.0%, 81.7%)
07/04 10:22:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [135][78/79]	Step 95744	Loss 1.7934	Prec@(1,5) (54.0%, 82.3%)
07/04 10:22:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [135/199] Final Prec@1 54.1200%
07/04 10:22:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:22:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][50/703]	Step 95794	lr 0.01	Loss 0.7878 (0.9606)	Prec@(1,5) (71.6%, 93.5%)	
07/04 10:22:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][100/703]	Step 95844	lr 0.01	Loss 0.8086 (0.9416)	Prec@(1,5) (71.7%, 94.1%)	
07/04 10:22:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][150/703]	Step 95894	lr 0.01	Loss 0.6394 (0.9564)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:22:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][200/703]	Step 95944	lr 0.01	Loss 0.9012 (0.9607)	Prec@(1,5) (71.6%, 94.0%)	
07/04 10:22:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][250/703]	Step 95994	lr 0.01	Loss 1.0663 (0.9544)	Prec@(1,5) (71.8%, 94.0%)	
07/04 10:22:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][300/703]	Step 96044	lr 0.01	Loss 1.0247 (0.9458)	Prec@(1,5) (72.0%, 94.0%)	
07/04 10:22:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][350/703]	Step 96094	lr 0.01	Loss 1.0008 (0.9565)	Prec@(1,5) (71.6%, 93.9%)	
07/04 10:22:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][400/703]	Step 96144	lr 0.01	Loss 1.0300 (0.9616)	Prec@(1,5) (71.5%, 93.9%)	
07/04 10:22:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][450/703]	Step 96194	lr 0.01	Loss 1.2054 (0.9667)	Prec@(1,5) (71.3%, 93.8%)	
07/04 10:22:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][500/703]	Step 96244	lr 0.01	Loss 1.1244 (0.9710)	Prec@(1,5) (71.2%, 93.8%)	
07/04 10:22:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][550/703]	Step 96294	lr 0.01	Loss 1.3396 (0.9801)	Prec@(1,5) (70.9%, 93.7%)	
07/04 10:22:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][600/703]	Step 96344	lr 0.01	Loss 1.1068 (0.9813)	Prec@(1,5) (70.9%, 93.7%)	
07/04 10:22:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][650/703]	Step 96394	lr 0.01	Loss 1.1336 (0.9837)	Prec@(1,5) (70.8%, 93.6%)	
07/04 10:22:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][700/703]	Step 96444	lr 0.01	Loss 1.0674 (0.9854)	Prec@(1,5) (70.7%, 93.6%)	
07/04 10:22:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [136][703/703]	Step 96447	lr 0.01	Loss 0.9724 (0.9852)	Prec@(1,5) (70.8%, 93.6%)	
07/04 10:22:45PM finetuneTeacher_trainer.py:185 [INFO] Train: [136/199] Final Prec@1 70.7467%
07/04 10:22:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [136][50/79]	Step 96448	Loss 1.7757	Prec@(1,5) (53.3%, 82.3%)
07/04 10:22:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [136][78/79]	Step 96448	Loss 1.7261	Prec@(1,5) (54.5%, 82.7%)
07/04 10:22:47PM finetuneTeacher_trainer.py:220 [INFO] Valid: [136/199] Final Prec@1 54.5800%
07/04 10:22:47PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:22:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][50/703]	Step 96498	lr 0.01	Loss 1.0270 (0.9432)	Prec@(1,5) (72.2%, 94.3%)	
07/04 10:22:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][100/703]	Step 96548	lr 0.01	Loss 1.4205 (0.9420)	Prec@(1,5) (72.4%, 94.6%)	
07/04 10:22:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][150/703]	Step 96598	lr 0.01	Loss 1.0251 (0.9396)	Prec@(1,5) (72.5%, 94.6%)	
07/04 10:23:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][200/703]	Step 96648	lr 0.01	Loss 1.0358 (0.9386)	Prec@(1,5) (72.1%, 94.4%)	
07/04 10:23:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][250/703]	Step 96698	lr 0.01	Loss 1.0520 (0.9470)	Prec@(1,5) (71.9%, 94.3%)	
07/04 10:23:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][300/703]	Step 96748	lr 0.01	Loss 1.1509 (0.9495)	Prec@(1,5) (71.8%, 94.2%)	
07/04 10:23:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][350/703]	Step 96798	lr 0.01	Loss 1.1605 (0.9467)	Prec@(1,5) (71.8%, 94.1%)	
07/04 10:23:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][400/703]	Step 96848	lr 0.01	Loss 1.0165 (0.9499)	Prec@(1,5) (71.6%, 94.1%)	
07/04 10:23:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][450/703]	Step 96898	lr 0.01	Loss 0.8885 (0.9567)	Prec@(1,5) (71.4%, 94.1%)	
07/04 10:23:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][500/703]	Step 96948	lr 0.01	Loss 1.2456 (0.9596)	Prec@(1,5) (71.4%, 93.9%)	
07/04 10:23:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][550/703]	Step 96998	lr 0.01	Loss 1.1837 (0.9625)	Prec@(1,5) (71.3%, 94.0%)	
07/04 10:23:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][600/703]	Step 97048	lr 0.01	Loss 0.7734 (0.9643)	Prec@(1,5) (71.2%, 93.9%)	
07/04 10:23:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][650/703]	Step 97098	lr 0.01	Loss 1.1695 (0.9666)	Prec@(1,5) (71.1%, 94.0%)	
07/04 10:23:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][700/703]	Step 97148	lr 0.01	Loss 0.9705 (0.9668)	Prec@(1,5) (71.1%, 94.0%)	
07/04 10:23:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [137][703/703]	Step 97151	lr 0.01	Loss 1.1694 (0.9678)	Prec@(1,5) (71.1%, 93.9%)	
07/04 10:23:31PM finetuneTeacher_trainer.py:185 [INFO] Train: [137/199] Final Prec@1 71.0667%
07/04 10:23:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [137][50/79]	Step 97152	Loss 1.7757	Prec@(1,5) (54.7%, 82.7%)
07/04 10:23:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [137][78/79]	Step 97152	Loss 1.7705	Prec@(1,5) (54.4%, 82.7%)
07/04 10:23:33PM finetuneTeacher_trainer.py:220 [INFO] Valid: [137/199] Final Prec@1 54.3800%
07/04 10:23:33PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:23:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][50/703]	Step 97202	lr 0.01	Loss 0.6369 (1.0172)	Prec@(1,5) (70.5%, 93.0%)	
07/04 10:23:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][100/703]	Step 97252	lr 0.01	Loss 1.2004 (0.9732)	Prec@(1,5) (71.7%, 93.7%)	
07/04 10:23:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][150/703]	Step 97302	lr 0.01	Loss 1.1319 (0.9527)	Prec@(1,5) (72.0%, 93.9%)	
07/04 10:23:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][200/703]	Step 97352	lr 0.01	Loss 0.5264 (0.9485)	Prec@(1,5) (72.0%, 94.0%)	
07/04 10:23:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][250/703]	Step 97402	lr 0.01	Loss 0.8336 (0.9414)	Prec@(1,5) (72.2%, 94.2%)	
07/04 10:23:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][300/703]	Step 97452	lr 0.01	Loss 0.7559 (0.9450)	Prec@(1,5) (72.0%, 94.1%)	
07/04 10:23:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][350/703]	Step 97502	lr 0.01	Loss 0.9457 (0.9459)	Prec@(1,5) (72.0%, 94.1%)	
07/04 10:24:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][400/703]	Step 97552	lr 0.01	Loss 0.9288 (0.9484)	Prec@(1,5) (71.8%, 94.1%)	
07/04 10:24:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][450/703]	Step 97602	lr 0.01	Loss 1.1360 (0.9513)	Prec@(1,5) (71.7%, 94.1%)	
07/04 10:24:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][500/703]	Step 97652	lr 0.01	Loss 1.0642 (0.9563)	Prec@(1,5) (71.7%, 94.0%)	
07/04 10:24:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][550/703]	Step 97702	lr 0.01	Loss 0.6226 (0.9576)	Prec@(1,5) (71.6%, 94.0%)	
07/04 10:24:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][600/703]	Step 97752	lr 0.01	Loss 0.8663 (0.9596)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:24:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][650/703]	Step 97802	lr 0.01	Loss 1.4449 (0.9656)	Prec@(1,5) (71.3%, 93.9%)	
07/04 10:24:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][700/703]	Step 97852	lr 0.01	Loss 0.7094 (0.9697)	Prec@(1,5) (71.2%, 93.8%)	
07/04 10:24:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [138][703/703]	Step 97855	lr 0.01	Loss 1.0904 (0.9706)	Prec@(1,5) (71.1%, 93.8%)	
07/04 10:24:19PM finetuneTeacher_trainer.py:185 [INFO] Train: [138/199] Final Prec@1 71.1200%
07/04 10:24:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [138][50/79]	Step 97856	Loss 1.7347	Prec@(1,5) (55.5%, 83.0%)
07/04 10:24:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [138][78/79]	Step 97856	Loss 1.7504	Prec@(1,5) (55.3%, 82.8%)
07/04 10:24:20PM finetuneTeacher_trainer.py:220 [INFO] Valid: [138/199] Final Prec@1 55.3000%
07/04 10:24:21PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:24:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][50/703]	Step 97906	lr 0.01	Loss 1.1162 (0.9621)	Prec@(1,5) (70.9%, 94.0%)	
07/04 10:24:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][100/703]	Step 97956	lr 0.01	Loss 1.1085 (0.9542)	Prec@(1,5) (72.0%, 94.0%)	
07/04 10:24:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][150/703]	Step 98006	lr 0.01	Loss 0.8702 (0.9570)	Prec@(1,5) (71.7%, 94.0%)	
07/04 10:24:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][200/703]	Step 98056	lr 0.01	Loss 0.6719 (0.9408)	Prec@(1,5) (72.2%, 94.2%)	
07/04 10:24:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][250/703]	Step 98106	lr 0.01	Loss 0.9340 (0.9391)	Prec@(1,5) (72.2%, 94.2%)	
07/04 10:24:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][300/703]	Step 98156	lr 0.01	Loss 1.0229 (0.9391)	Prec@(1,5) (72.2%, 94.2%)	
07/04 10:24:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][350/703]	Step 98206	lr 0.01	Loss 1.0261 (0.9343)	Prec@(1,5) (72.3%, 94.3%)	
07/04 10:24:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][400/703]	Step 98256	lr 0.01	Loss 0.7810 (0.9408)	Prec@(1,5) (72.3%, 94.2%)	
07/04 10:24:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][450/703]	Step 98306	lr 0.01	Loss 1.0200 (0.9450)	Prec@(1,5) (72.1%, 94.3%)	
07/04 10:24:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][500/703]	Step 98356	lr 0.01	Loss 0.9471 (0.9503)	Prec@(1,5) (71.9%, 94.1%)	
07/04 10:24:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][550/703]	Step 98406	lr 0.01	Loss 0.8924 (0.9487)	Prec@(1,5) (71.9%, 94.2%)	
07/04 10:24:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][600/703]	Step 98456	lr 0.01	Loss 1.0147 (0.9529)	Prec@(1,5) (71.7%, 94.1%)	
07/04 10:25:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][650/703]	Step 98506	lr 0.01	Loss 0.9571 (0.9604)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:25:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][700/703]	Step 98556	lr 0.01	Loss 1.0399 (0.9621)	Prec@(1,5) (71.4%, 93.9%)	
07/04 10:25:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [139][703/703]	Step 98559	lr 0.01	Loss 1.0371 (0.9622)	Prec@(1,5) (71.4%, 93.9%)	
07/04 10:25:06PM finetuneTeacher_trainer.py:185 [INFO] Train: [139/199] Final Prec@1 71.4044%
07/04 10:25:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [139][50/79]	Step 98560	Loss 1.6854	Prec@(1,5) (55.5%, 83.1%)
07/04 10:25:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [139][78/79]	Step 98560	Loss 1.7182	Prec@(1,5) (54.7%, 82.7%)
07/04 10:25:07PM finetuneTeacher_trainer.py:220 [INFO] Valid: [139/199] Final Prec@1 54.7200%
07/04 10:25:07PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:25:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][50/703]	Step 98610	lr 0.01	Loss 0.9343 (0.9663)	Prec@(1,5) (71.1%, 93.9%)	
07/04 10:25:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][100/703]	Step 98660	lr 0.01	Loss 0.7430 (0.9479)	Prec@(1,5) (72.1%, 93.9%)	
07/04 10:25:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][150/703]	Step 98710	lr 0.01	Loss 1.0094 (0.9417)	Prec@(1,5) (72.6%, 94.0%)	
07/04 10:25:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][200/703]	Step 98760	lr 0.01	Loss 0.9190 (0.9420)	Prec@(1,5) (72.4%, 94.0%)	
07/04 10:25:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][250/703]	Step 98810	lr 0.01	Loss 1.0586 (0.9455)	Prec@(1,5) (72.1%, 94.1%)	
07/04 10:25:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][300/703]	Step 98860	lr 0.01	Loss 0.8205 (0.9421)	Prec@(1,5) (72.2%, 94.2%)	
07/04 10:25:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][350/703]	Step 98910	lr 0.01	Loss 0.9307 (0.9490)	Prec@(1,5) (72.0%, 94.2%)	
07/04 10:25:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][400/703]	Step 98960	lr 0.01	Loss 0.9044 (0.9497)	Prec@(1,5) (72.0%, 94.2%)	
07/04 10:25:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][450/703]	Step 99010	lr 0.01	Loss 1.4527 (0.9534)	Prec@(1,5) (71.8%, 94.1%)	
07/04 10:25:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][500/703]	Step 99060	lr 0.01	Loss 0.8090 (0.9531)	Prec@(1,5) (71.8%, 94.1%)	
07/04 10:25:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][550/703]	Step 99110	lr 0.01	Loss 0.7004 (0.9568)	Prec@(1,5) (71.6%, 94.1%)	
07/04 10:25:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][600/703]	Step 99160	lr 0.01	Loss 0.6715 (0.9606)	Prec@(1,5) (71.5%, 94.1%)	
07/04 10:25:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][650/703]	Step 99210	lr 0.01	Loss 0.8923 (0.9621)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:25:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][700/703]	Step 99260	lr 0.01	Loss 0.8748 (0.9613)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:25:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [140][703/703]	Step 99263	lr 0.01	Loss 0.9517 (0.9612)	Prec@(1,5) (71.5%, 94.0%)	
07/04 10:25:53PM finetuneTeacher_trainer.py:185 [INFO] Train: [140/199] Final Prec@1 71.5133%
07/04 10:25:54PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [140][50/79]	Step 99264	Loss 1.7016	Prec@(1,5) (55.3%, 83.4%)
07/04 10:25:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [140][78/79]	Step 99264	Loss 1.7184	Prec@(1,5) (54.9%, 83.1%)
07/04 10:25:55PM finetuneTeacher_trainer.py:220 [INFO] Valid: [140/199] Final Prec@1 54.8400%
07/04 10:25:55PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:25:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][50/703]	Step 99314	lr 0.01	Loss 0.6860 (0.8957)	Prec@(1,5) (74.0%, 94.4%)	
07/04 10:26:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][100/703]	Step 99364	lr 0.01	Loss 0.8472 (0.8912)	Prec@(1,5) (74.2%, 94.5%)	
07/04 10:26:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][150/703]	Step 99414	lr 0.01	Loss 0.6634 (0.8831)	Prec@(1,5) (74.2%, 94.9%)	
07/04 10:26:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][200/703]	Step 99464	lr 0.01	Loss 1.1478 (0.9020)	Prec@(1,5) (73.5%, 94.7%)	
07/04 10:26:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][250/703]	Step 99514	lr 0.01	Loss 0.8076 (0.9088)	Prec@(1,5) (73.3%, 94.7%)	
07/04 10:26:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][300/703]	Step 99564	lr 0.01	Loss 0.9034 (0.9138)	Prec@(1,5) (73.2%, 94.6%)	
07/04 10:26:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][350/703]	Step 99614	lr 0.01	Loss 0.8561 (0.9104)	Prec@(1,5) (73.3%, 94.6%)	
07/04 10:26:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][400/703]	Step 99664	lr 0.01	Loss 1.0683 (0.9104)	Prec@(1,5) (73.3%, 94.6%)	
07/04 10:26:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][450/703]	Step 99714	lr 0.01	Loss 1.0125 (0.9170)	Prec@(1,5) (73.1%, 94.5%)	
07/04 10:26:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][500/703]	Step 99764	lr 0.01	Loss 0.9568 (0.9210)	Prec@(1,5) (72.9%, 94.5%)	
07/04 10:26:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][550/703]	Step 99814	lr 0.01	Loss 0.9374 (0.9239)	Prec@(1,5) (72.8%, 94.4%)	
07/04 10:26:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][600/703]	Step 99864	lr 0.01	Loss 1.0294 (0.9309)	Prec@(1,5) (72.6%, 94.4%)	
07/04 10:26:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][650/703]	Step 99914	lr 0.01	Loss 0.9920 (0.9366)	Prec@(1,5) (72.3%, 94.3%)	
07/04 10:26:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][700/703]	Step 99964	lr 0.01	Loss 0.9203 (0.9418)	Prec@(1,5) (72.1%, 94.3%)	
07/04 10:26:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [141][703/703]	Step 99967	lr 0.01	Loss 0.8233 (0.9417)	Prec@(1,5) (72.1%, 94.3%)	
07/04 10:26:41PM finetuneTeacher_trainer.py:185 [INFO] Train: [141/199] Final Prec@1 72.0778%
07/04 10:26:42PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [141][50/79]	Step 99968	Loss 1.6960	Prec@(1,5) (55.1%, 83.5%)
07/04 10:26:42PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [141][78/79]	Step 99968	Loss 1.7072	Prec@(1,5) (55.2%, 83.4%)
07/04 10:26:42PM finetuneTeacher_trainer.py:220 [INFO] Valid: [141/199] Final Prec@1 55.1600%
07/04 10:26:43PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:26:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][50/703]	Step 100018	lr 0.01	Loss 1.1604 (0.9381)	Prec@(1,5) (72.0%, 94.0%)	
07/04 10:26:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][100/703]	Step 100068	lr 0.01	Loss 0.6365 (0.9168)	Prec@(1,5) (73.0%, 94.3%)	
07/04 10:26:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][150/703]	Step 100118	lr 0.01	Loss 0.7944 (0.9240)	Prec@(1,5) (72.7%, 94.4%)	
07/04 10:26:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][200/703]	Step 100168	lr 0.01	Loss 1.0838 (0.9213)	Prec@(1,5) (72.9%, 94.4%)	
07/04 10:27:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][250/703]	Step 100218	lr 0.01	Loss 0.9945 (0.9324)	Prec@(1,5) (72.5%, 94.2%)	
07/04 10:27:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][300/703]	Step 100268	lr 0.01	Loss 0.9267 (0.9333)	Prec@(1,5) (72.4%, 94.2%)	
07/04 10:27:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][350/703]	Step 100318	lr 0.01	Loss 0.9814 (0.9282)	Prec@(1,5) (72.6%, 94.3%)	
07/04 10:27:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][400/703]	Step 100368	lr 0.01	Loss 0.7105 (0.9294)	Prec@(1,5) (72.5%, 94.3%)	
07/04 10:27:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][450/703]	Step 100418	lr 0.01	Loss 0.7591 (0.9317)	Prec@(1,5) (72.4%, 94.2%)	
07/04 10:27:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][500/703]	Step 100468	lr 0.01	Loss 0.8279 (0.9334)	Prec@(1,5) (72.3%, 94.2%)	
07/04 10:27:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][550/703]	Step 100518	lr 0.01	Loss 1.0636 (0.9333)	Prec@(1,5) (72.3%, 94.2%)	
07/04 10:27:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][600/703]	Step 100568	lr 0.01	Loss 0.7942 (0.9317)	Prec@(1,5) (72.3%, 94.2%)	
07/04 10:27:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][650/703]	Step 100618	lr 0.01	Loss 1.0897 (0.9371)	Prec@(1,5) (72.1%, 94.2%)	
07/04 10:27:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][700/703]	Step 100668	lr 0.01	Loss 0.9869 (0.9378)	Prec@(1,5) (72.1%, 94.2%)	
07/04 10:27:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [142][703/703]	Step 100671	lr 0.01	Loss 1.0315 (0.9388)	Prec@(1,5) (72.1%, 94.1%)	
07/04 10:27:29PM finetuneTeacher_trainer.py:185 [INFO] Train: [142/199] Final Prec@1 72.0911%
07/04 10:27:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [142][50/79]	Step 100672	Loss 1.7714	Prec@(1,5) (54.3%, 82.1%)
07/04 10:27:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [142][78/79]	Step 100672	Loss 1.7752	Prec@(1,5) (54.4%, 82.0%)
07/04 10:27:30PM finetuneTeacher_trainer.py:220 [INFO] Valid: [142/199] Final Prec@1 54.3400%
07/04 10:27:30PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:27:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][50/703]	Step 100722	lr 0.01	Loss 0.9448 (0.8976)	Prec@(1,5) (73.6%, 94.7%)	
07/04 10:27:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][100/703]	Step 100772	lr 0.01	Loss 0.9002 (0.8890)	Prec@(1,5) (73.5%, 94.9%)	
07/04 10:27:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][150/703]	Step 100822	lr 0.01	Loss 0.8065 (0.8916)	Prec@(1,5) (73.4%, 94.9%)	
07/04 10:27:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][200/703]	Step 100872	lr 0.01	Loss 0.8567 (0.8953)	Prec@(1,5) (73.4%, 94.7%)	
07/04 10:27:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][250/703]	Step 100922	lr 0.01	Loss 0.9040 (0.8951)	Prec@(1,5) (73.6%, 94.7%)	
07/04 10:27:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][300/703]	Step 100972	lr 0.01	Loss 1.1736 (0.9032)	Prec@(1,5) (73.3%, 94.6%)	
07/04 10:27:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][350/703]	Step 101022	lr 0.01	Loss 0.9054 (0.9054)	Prec@(1,5) (73.3%, 94.7%)	
07/04 10:27:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][400/703]	Step 101072	lr 0.01	Loss 0.9144 (0.9076)	Prec@(1,5) (73.1%, 94.6%)	
07/04 10:28:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][450/703]	Step 101122	lr 0.01	Loss 0.9734 (0.9141)	Prec@(1,5) (73.0%, 94.5%)	
07/04 10:28:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][500/703]	Step 101172	lr 0.01	Loss 0.9299 (0.9197)	Prec@(1,5) (72.8%, 94.4%)	
07/04 10:28:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][550/703]	Step 101222	lr 0.01	Loss 0.7289 (0.9212)	Prec@(1,5) (72.8%, 94.4%)	
07/04 10:28:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][600/703]	Step 101272	lr 0.01	Loss 0.9741 (0.9211)	Prec@(1,5) (72.8%, 94.4%)	
07/04 10:28:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][650/703]	Step 101322	lr 0.01	Loss 1.0292 (0.9257)	Prec@(1,5) (72.6%, 94.3%)	
07/04 10:28:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][700/703]	Step 101372	lr 0.01	Loss 0.8957 (0.9289)	Prec@(1,5) (72.5%, 94.3%)	
07/04 10:28:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [143][703/703]	Step 101375	lr 0.01	Loss 0.9582 (0.9297)	Prec@(1,5) (72.5%, 94.3%)	
07/04 10:28:15PM finetuneTeacher_trainer.py:185 [INFO] Train: [143/199] Final Prec@1 72.5044%
07/04 10:28:16PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [143][50/79]	Step 101376	Loss 1.8035	Prec@(1,5) (54.3%, 82.4%)
07/04 10:28:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [143][78/79]	Step 101376	Loss 1.7895	Prec@(1,5) (54.0%, 82.4%)
07/04 10:28:17PM finetuneTeacher_trainer.py:220 [INFO] Valid: [143/199] Final Prec@1 54.0000%
07/04 10:28:17PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:28:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][50/703]	Step 101426	lr 0.01	Loss 0.8256 (0.9000)	Prec@(1,5) (74.2%, 94.7%)	
07/04 10:28:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][100/703]	Step 101476	lr 0.01	Loss 0.7937 (0.9092)	Prec@(1,5) (73.4%, 95.0%)	
07/04 10:28:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][150/703]	Step 101526	lr 0.01	Loss 0.9220 (0.9095)	Prec@(1,5) (73.3%, 94.9%)	
07/04 10:28:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][200/703]	Step 101576	lr 0.01	Loss 1.0983 (0.9160)	Prec@(1,5) (73.2%, 94.8%)	
07/04 10:28:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][250/703]	Step 101626	lr 0.01	Loss 1.0007 (0.9130)	Prec@(1,5) (73.2%, 94.7%)	
07/04 10:28:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][300/703]	Step 101676	lr 0.01	Loss 0.7087 (0.9123)	Prec@(1,5) (73.1%, 94.6%)	
07/04 10:28:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][350/703]	Step 101726	lr 0.01	Loss 0.7977 (0.9121)	Prec@(1,5) (73.0%, 94.6%)	
07/04 10:28:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][400/703]	Step 101776	lr 0.01	Loss 1.3779 (0.9160)	Prec@(1,5) (72.8%, 94.6%)	
07/04 10:28:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][450/703]	Step 101826	lr 0.01	Loss 0.8210 (0.9178)	Prec@(1,5) (72.8%, 94.5%)	
07/04 10:28:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][500/703]	Step 101876	lr 0.01	Loss 1.0057 (0.9202)	Prec@(1,5) (72.7%, 94.5%)	
07/04 10:28:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][550/703]	Step 101926	lr 0.01	Loss 0.9490 (0.9241)	Prec@(1,5) (72.6%, 94.4%)	
07/04 10:28:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][600/703]	Step 101976	lr 0.01	Loss 1.2115 (0.9274)	Prec@(1,5) (72.5%, 94.4%)	
07/04 10:29:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][650/703]	Step 102026	lr 0.01	Loss 0.8920 (0.9274)	Prec@(1,5) (72.5%, 94.4%)	
07/04 10:29:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][700/703]	Step 102076	lr 0.01	Loss 1.0437 (0.9309)	Prec@(1,5) (72.4%, 94.3%)	
07/04 10:29:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [144][703/703]	Step 102079	lr 0.01	Loss 0.8678 (0.9307)	Prec@(1,5) (72.4%, 94.3%)	
07/04 10:29:03PM finetuneTeacher_trainer.py:185 [INFO] Train: [144/199] Final Prec@1 72.3978%
07/04 10:29:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [144][50/79]	Step 102080	Loss 1.7594	Prec@(1,5) (54.4%, 82.8%)
07/04 10:29:04PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [144][78/79]	Step 102080	Loss 1.7472	Prec@(1,5) (54.9%, 82.9%)
07/04 10:29:05PM finetuneTeacher_trainer.py:220 [INFO] Valid: [144/199] Final Prec@1 54.9800%
07/04 10:29:05PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:29:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][50/703]	Step 102130	lr 0.01	Loss 0.8378 (0.8582)	Prec@(1,5) (74.9%, 94.7%)	
07/04 10:29:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][100/703]	Step 102180	lr 0.01	Loss 0.6959 (0.8484)	Prec@(1,5) (74.7%, 95.0%)	
07/04 10:29:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][150/703]	Step 102230	lr 0.01	Loss 0.7750 (0.8537)	Prec@(1,5) (74.4%, 95.1%)	
07/04 10:29:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][200/703]	Step 102280	lr 0.01	Loss 0.9676 (0.8587)	Prec@(1,5) (74.4%, 95.0%)	
07/04 10:29:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][250/703]	Step 102330	lr 0.01	Loss 0.9911 (0.8691)	Prec@(1,5) (74.1%, 94.9%)	
07/04 10:29:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][300/703]	Step 102380	lr 0.01	Loss 1.0827 (0.8765)	Prec@(1,5) (73.9%, 94.9%)	
07/04 10:29:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][350/703]	Step 102430	lr 0.01	Loss 0.8339 (0.8860)	Prec@(1,5) (73.7%, 94.7%)	
07/04 10:29:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][400/703]	Step 102480	lr 0.01	Loss 0.6982 (0.8900)	Prec@(1,5) (73.6%, 94.7%)	
07/04 10:29:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][450/703]	Step 102530	lr 0.01	Loss 0.8801 (0.8901)	Prec@(1,5) (73.4%, 94.7%)	
07/04 10:29:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][500/703]	Step 102580	lr 0.01	Loss 1.3286 (0.8953)	Prec@(1,5) (73.3%, 94.6%)	
07/04 10:29:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][550/703]	Step 102630	lr 0.01	Loss 1.0992 (0.9013)	Prec@(1,5) (73.2%, 94.6%)	
07/04 10:29:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][600/703]	Step 102680	lr 0.01	Loss 0.9580 (0.9064)	Prec@(1,5) (73.0%, 94.5%)	
07/04 10:29:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][650/703]	Step 102730	lr 0.01	Loss 0.6989 (0.9118)	Prec@(1,5) (72.8%, 94.4%)	
07/04 10:29:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][700/703]	Step 102780	lr 0.01	Loss 1.0128 (0.9185)	Prec@(1,5) (72.7%, 94.4%)	
07/04 10:29:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [145][703/703]	Step 102783	lr 0.01	Loss 0.9148 (0.9190)	Prec@(1,5) (72.6%, 94.4%)	
07/04 10:29:51PM finetuneTeacher_trainer.py:185 [INFO] Train: [145/199] Final Prec@1 72.6111%
07/04 10:29:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [145][50/79]	Step 102784	Loss 1.7598	Prec@(1,5) (54.7%, 82.6%)
07/04 10:29:53PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [145][78/79]	Step 102784	Loss 1.7755	Prec@(1,5) (54.5%, 82.1%)
07/04 10:29:53PM finetuneTeacher_trainer.py:220 [INFO] Valid: [145/199] Final Prec@1 54.5600%
07/04 10:29:53PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:29:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][50/703]	Step 102834	lr 0.01	Loss 1.1242 (0.9107)	Prec@(1,5) (73.4%, 94.6%)	
07/04 10:30:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][100/703]	Step 102884	lr 0.01	Loss 1.0141 (0.9007)	Prec@(1,5) (73.5%, 94.6%)	
07/04 10:30:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][150/703]	Step 102934	lr 0.01	Loss 0.7716 (0.8889)	Prec@(1,5) (73.6%, 94.6%)	
07/04 10:30:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][200/703]	Step 102984	lr 0.01	Loss 0.7754 (0.8855)	Prec@(1,5) (73.5%, 94.8%)	
07/04 10:30:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][250/703]	Step 103034	lr 0.01	Loss 0.8058 (0.8856)	Prec@(1,5) (73.5%, 94.8%)	
07/04 10:30:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][300/703]	Step 103084	lr 0.01	Loss 0.7106 (0.8800)	Prec@(1,5) (73.6%, 94.9%)	
07/04 10:30:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][350/703]	Step 103134	lr 0.01	Loss 0.7958 (0.8834)	Prec@(1,5) (73.4%, 94.9%)	
07/04 10:30:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][400/703]	Step 103184	lr 0.01	Loss 0.9050 (0.8896)	Prec@(1,5) (73.3%, 94.9%)	
07/04 10:30:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][450/703]	Step 103234	lr 0.01	Loss 0.7663 (0.8921)	Prec@(1,5) (73.2%, 94.9%)	
07/04 10:30:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][500/703]	Step 103284	lr 0.01	Loss 1.2862 (0.8976)	Prec@(1,5) (73.0%, 94.8%)	
07/04 10:30:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][550/703]	Step 103334	lr 0.01	Loss 1.1161 (0.9039)	Prec@(1,5) (72.8%, 94.8%)	
07/04 10:30:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][600/703]	Step 103384	lr 0.01	Loss 0.7933 (0.9075)	Prec@(1,5) (72.8%, 94.7%)	
07/04 10:30:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][650/703]	Step 103434	lr 0.01	Loss 0.8786 (0.9150)	Prec@(1,5) (72.6%, 94.6%)	
07/04 10:30:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][700/703]	Step 103484	lr 0.01	Loss 1.3992 (0.9186)	Prec@(1,5) (72.5%, 94.6%)	
07/04 10:30:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [146][703/703]	Step 103487	lr 0.01	Loss 0.8801 (0.9185)	Prec@(1,5) (72.5%, 94.6%)	
07/04 10:30:39PM finetuneTeacher_trainer.py:185 [INFO] Train: [146/199] Final Prec@1 72.4778%
07/04 10:30:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [146][50/79]	Step 103488	Loss 1.7840	Prec@(1,5) (53.4%, 83.1%)
07/04 10:30:40PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [146][78/79]	Step 103488	Loss 1.7730	Prec@(1,5) (53.9%, 82.6%)
07/04 10:30:40PM finetuneTeacher_trainer.py:220 [INFO] Valid: [146/199] Final Prec@1 53.9400%
07/04 10:30:40PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:30:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][50/703]	Step 103538	lr 0.01	Loss 1.0178 (0.8739)	Prec@(1,5) (74.3%, 95.4%)	
07/04 10:30:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][100/703]	Step 103588	lr 0.01	Loss 1.1237 (0.8553)	Prec@(1,5) (74.6%, 95.3%)	
07/04 10:30:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][150/703]	Step 103638	lr 0.01	Loss 0.7539 (0.8568)	Prec@(1,5) (74.5%, 95.2%)	
07/04 10:30:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][200/703]	Step 103688	lr 0.01	Loss 0.8968 (0.8617)	Prec@(1,5) (74.1%, 95.1%)	
07/04 10:30:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][250/703]	Step 103738	lr 0.01	Loss 0.7676 (0.8651)	Prec@(1,5) (74.1%, 95.1%)	
07/04 10:31:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][300/703]	Step 103788	lr 0.01	Loss 1.0080 (0.8768)	Prec@(1,5) (73.9%, 95.0%)	
07/04 10:31:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][350/703]	Step 103838	lr 0.01	Loss 0.9792 (0.8810)	Prec@(1,5) (73.8%, 94.9%)	
07/04 10:31:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][400/703]	Step 103888	lr 0.01	Loss 0.8084 (0.8869)	Prec@(1,5) (73.6%, 94.9%)	
07/04 10:31:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][450/703]	Step 103938	lr 0.01	Loss 0.9311 (0.8947)	Prec@(1,5) (73.4%, 94.8%)	
07/04 10:31:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][500/703]	Step 103988	lr 0.01	Loss 0.7321 (0.8998)	Prec@(1,5) (73.4%, 94.8%)	
07/04 10:31:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][550/703]	Step 104038	lr 0.01	Loss 1.0852 (0.9035)	Prec@(1,5) (73.2%, 94.7%)	
07/04 10:31:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][600/703]	Step 104088	lr 0.01	Loss 0.8958 (0.9096)	Prec@(1,5) (73.0%, 94.7%)	
07/04 10:31:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][650/703]	Step 104138	lr 0.01	Loss 0.9666 (0.9156)	Prec@(1,5) (72.8%, 94.6%)	
07/04 10:31:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][700/703]	Step 104188	lr 0.01	Loss 0.9967 (0.9185)	Prec@(1,5) (72.7%, 94.5%)	
07/04 10:31:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [147][703/703]	Step 104191	lr 0.01	Loss 0.9391 (0.9183)	Prec@(1,5) (72.7%, 94.5%)	
07/04 10:31:26PM finetuneTeacher_trainer.py:185 [INFO] Train: [147/199] Final Prec@1 72.6556%
07/04 10:31:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [147][50/79]	Step 104192	Loss 1.7563	Prec@(1,5) (54.3%, 82.3%)
07/04 10:31:27PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [147][78/79]	Step 104192	Loss 1.7793	Prec@(1,5) (54.5%, 82.0%)
07/04 10:31:27PM finetuneTeacher_trainer.py:220 [INFO] Valid: [147/199] Final Prec@1 54.5200%
07/04 10:31:27PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:31:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][50/703]	Step 104242	lr 0.01	Loss 1.0009 (0.9176)	Prec@(1,5) (71.9%, 95.0%)	
07/04 10:31:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][100/703]	Step 104292	lr 0.01	Loss 0.9553 (0.9234)	Prec@(1,5) (72.1%, 94.8%)	
07/04 10:31:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][150/703]	Step 104342	lr 0.01	Loss 1.1587 (0.8999)	Prec@(1,5) (73.1%, 94.9%)	
07/04 10:31:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][200/703]	Step 104392	lr 0.01	Loss 0.9734 (0.8956)	Prec@(1,5) (73.1%, 94.9%)	
07/04 10:31:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][250/703]	Step 104442	lr 0.01	Loss 0.6602 (0.8948)	Prec@(1,5) (73.2%, 95.0%)	
07/04 10:31:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][300/703]	Step 104492	lr 0.01	Loss 0.8106 (0.8974)	Prec@(1,5) (73.1%, 94.9%)	
07/04 10:31:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][350/703]	Step 104542	lr 0.01	Loss 0.9422 (0.8996)	Prec@(1,5) (73.2%, 94.9%)	
07/04 10:31:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][400/703]	Step 104592	lr 0.01	Loss 0.8463 (0.8990)	Prec@(1,5) (73.3%, 94.8%)	
07/04 10:31:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][450/703]	Step 104642	lr 0.01	Loss 0.8512 (0.9054)	Prec@(1,5) (73.2%, 94.7%)	
07/04 10:32:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][500/703]	Step 104692	lr 0.01	Loss 1.1263 (0.9055)	Prec@(1,5) (73.1%, 94.7%)	
07/04 10:32:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][550/703]	Step 104742	lr 0.01	Loss 0.9981 (0.9055)	Prec@(1,5) (73.1%, 94.7%)	
07/04 10:32:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][600/703]	Step 104792	lr 0.01	Loss 1.0902 (0.9102)	Prec@(1,5) (72.9%, 94.7%)	
07/04 10:32:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][650/703]	Step 104842	lr 0.01	Loss 1.0701 (0.9144)	Prec@(1,5) (72.7%, 94.7%)	
07/04 10:32:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][700/703]	Step 104892	lr 0.01	Loss 0.7129 (0.9165)	Prec@(1,5) (72.7%, 94.6%)	
07/04 10:32:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [148][703/703]	Step 104895	lr 0.01	Loss 0.7729 (0.9160)	Prec@(1,5) (72.7%, 94.6%)	
07/04 10:32:13PM finetuneTeacher_trainer.py:185 [INFO] Train: [148/199] Final Prec@1 72.6756%
07/04 10:32:14PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [148][50/79]	Step 104896	Loss 1.7789	Prec@(1,5) (53.9%, 82.7%)
07/04 10:32:15PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [148][78/79]	Step 104896	Loss 1.7887	Prec@(1,5) (53.8%, 82.3%)
07/04 10:32:15PM finetuneTeacher_trainer.py:220 [INFO] Valid: [148/199] Final Prec@1 53.8000%
07/04 10:32:15PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:32:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][50/703]	Step 104946	lr 0.01	Loss 0.7692 (0.9315)	Prec@(1,5) (73.2%, 94.3%)	
07/04 10:32:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][100/703]	Step 104996	lr 0.01	Loss 0.8257 (0.8906)	Prec@(1,5) (73.9%, 94.6%)	
07/04 10:32:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][150/703]	Step 105046	lr 0.01	Loss 0.4953 (0.8811)	Prec@(1,5) (74.0%, 94.8%)	
07/04 10:32:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][200/703]	Step 105096	lr 0.01	Loss 1.0622 (0.8770)	Prec@(1,5) (73.9%, 94.9%)	
07/04 10:32:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][250/703]	Step 105146	lr 0.01	Loss 0.9951 (0.8816)	Prec@(1,5) (73.7%, 94.9%)	
07/04 10:32:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][300/703]	Step 105196	lr 0.01	Loss 0.7234 (0.8848)	Prec@(1,5) (73.5%, 94.8%)	
07/04 10:32:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][350/703]	Step 105246	lr 0.01	Loss 0.8416 (0.8831)	Prec@(1,5) (73.5%, 94.8%)	
07/04 10:32:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][400/703]	Step 105296	lr 0.01	Loss 0.8779 (0.8894)	Prec@(1,5) (73.3%, 94.8%)	
07/04 10:32:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][450/703]	Step 105346	lr 0.01	Loss 0.8439 (0.8990)	Prec@(1,5) (73.1%, 94.7%)	
07/04 10:32:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][500/703]	Step 105396	lr 0.01	Loss 1.0789 (0.9029)	Prec@(1,5) (73.0%, 94.6%)	
07/04 10:32:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][550/703]	Step 105446	lr 0.01	Loss 0.7265 (0.9039)	Prec@(1,5) (73.0%, 94.6%)	
07/04 10:32:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][600/703]	Step 105496	lr 0.01	Loss 1.0428 (0.9078)	Prec@(1,5) (72.9%, 94.6%)	
07/04 10:32:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][650/703]	Step 105546	lr 0.01	Loss 1.0019 (0.9086)	Prec@(1,5) (72.8%, 94.6%)	
07/04 10:33:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][700/703]	Step 105596	lr 0.01	Loss 0.8911 (0.9106)	Prec@(1,5) (72.8%, 94.5%)	
07/04 10:33:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [149][703/703]	Step 105599	lr 0.01	Loss 1.0215 (0.9104)	Prec@(1,5) (72.8%, 94.5%)	
07/04 10:33:00PM finetuneTeacher_trainer.py:185 [INFO] Train: [149/199] Final Prec@1 72.7867%
07/04 10:33:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [149][50/79]	Step 105600	Loss 1.7922	Prec@(1,5) (53.3%, 82.1%)
07/04 10:33:01PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [149][78/79]	Step 105600	Loss 1.8183	Prec@(1,5) (53.0%, 81.4%)
07/04 10:33:01PM finetuneTeacher_trainer.py:220 [INFO] Valid: [149/199] Final Prec@1 53.0600%
07/04 10:33:01PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 56.5800%
07/04 10:33:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][50/703]	Step 105650	lr 0.001	Loss 0.8362 (0.8274)	Prec@(1,5) (75.3%, 95.4%)	
07/04 10:33:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][100/703]	Step 105700	lr 0.001	Loss 0.6117 (0.7992)	Prec@(1,5) (76.5%, 95.7%)	
07/04 10:33:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][150/703]	Step 105750	lr 0.001	Loss 0.7419 (0.7782)	Prec@(1,5) (77.1%, 95.9%)	
07/04 10:33:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][200/703]	Step 105800	lr 0.001	Loss 0.7290 (0.7528)	Prec@(1,5) (78.1%, 96.1%)	
07/04 10:33:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][250/703]	Step 105850	lr 0.001	Loss 0.7845 (0.7379)	Prec@(1,5) (78.4%, 96.3%)	
07/04 10:33:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][300/703]	Step 105900	lr 0.001	Loss 0.7059 (0.7322)	Prec@(1,5) (78.7%, 96.3%)	
07/04 10:33:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][350/703]	Step 105950	lr 0.001	Loss 0.7049 (0.7263)	Prec@(1,5) (78.8%, 96.4%)	
07/04 10:33:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][400/703]	Step 106000	lr 0.001	Loss 0.6427 (0.7201)	Prec@(1,5) (78.9%, 96.5%)	
07/04 10:33:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][450/703]	Step 106050	lr 0.001	Loss 0.6393 (0.7181)	Prec@(1,5) (79.0%, 96.5%)	
07/04 10:33:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][500/703]	Step 106100	lr 0.001	Loss 0.5099 (0.7136)	Prec@(1,5) (79.0%, 96.6%)	
07/04 10:33:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][550/703]	Step 106150	lr 0.001	Loss 0.6713 (0.7087)	Prec@(1,5) (79.2%, 96.6%)	
07/04 10:33:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][600/703]	Step 106200	lr 0.001	Loss 0.7373 (0.7067)	Prec@(1,5) (79.2%, 96.6%)	
07/04 10:33:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][650/703]	Step 106250	lr 0.001	Loss 0.5474 (0.7004)	Prec@(1,5) (79.5%, 96.7%)	
07/04 10:33:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][700/703]	Step 106300	lr 0.001	Loss 0.4196 (0.6963)	Prec@(1,5) (79.6%, 96.7%)	
07/04 10:33:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [150][703/703]	Step 106303	lr 0.001	Loss 0.5725 (0.6964)	Prec@(1,5) (79.6%, 96.7%)	
07/04 10:33:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [150/199] Final Prec@1 79.6178%
07/04 10:33:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [150][50/79]	Step 106304	Loss 1.6125	Prec@(1,5) (57.7%, 84.9%)
07/04 10:33:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [150][78/79]	Step 106304	Loss 1.5916	Prec@(1,5) (57.8%, 85.0%)
07/04 10:33:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [150/199] Final Prec@1 57.7600%
07/04 10:33:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 57.7600%
07/04 10:33:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][50/703]	Step 106354	lr 0.001	Loss 0.6312 (0.6327)	Prec@(1,5) (81.7%, 97.6%)	
07/04 10:33:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][100/703]	Step 106404	lr 0.001	Loss 0.5125 (0.6255)	Prec@(1,5) (81.8%, 97.5%)	
07/04 10:33:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][150/703]	Step 106454	lr 0.001	Loss 0.5505 (0.6260)	Prec@(1,5) (82.1%, 97.4%)	
07/04 10:34:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][200/703]	Step 106504	lr 0.001	Loss 0.6169 (0.6331)	Prec@(1,5) (81.9%, 97.2%)	
07/04 10:34:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][250/703]	Step 106554	lr 0.001	Loss 0.6007 (0.6390)	Prec@(1,5) (81.6%, 97.3%)	
07/04 10:34:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][300/703]	Step 106604	lr 0.001	Loss 0.6962 (0.6368)	Prec@(1,5) (81.7%, 97.2%)	
07/04 10:34:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][350/703]	Step 106654	lr 0.001	Loss 0.4980 (0.6372)	Prec@(1,5) (81.6%, 97.2%)	
07/04 10:34:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][400/703]	Step 106704	lr 0.001	Loss 0.7737 (0.6385)	Prec@(1,5) (81.6%, 97.2%)	
07/04 10:34:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][450/703]	Step 106754	lr 0.001	Loss 0.6448 (0.6328)	Prec@(1,5) (81.8%, 97.3%)	
07/04 10:34:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][500/703]	Step 106804	lr 0.001	Loss 0.6175 (0.6310)	Prec@(1,5) (81.8%, 97.3%)	
07/04 10:34:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][550/703]	Step 106854	lr 0.001	Loss 0.6136 (0.6287)	Prec@(1,5) (81.8%, 97.3%)	
07/04 10:34:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][600/703]	Step 106904	lr 0.001	Loss 0.6460 (0.6285)	Prec@(1,5) (81.7%, 97.3%)	
07/04 10:34:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][650/703]	Step 106954	lr 0.001	Loss 0.3986 (0.6268)	Prec@(1,5) (81.8%, 97.4%)	
07/04 10:34:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][700/703]	Step 107004	lr 0.001	Loss 0.7253 (0.6255)	Prec@(1,5) (81.9%, 97.4%)	
07/04 10:34:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [151][703/703]	Step 107007	lr 0.001	Loss 0.6990 (0.6258)	Prec@(1,5) (81.9%, 97.4%)	
07/04 10:34:34PM finetuneTeacher_trainer.py:185 [INFO] Train: [151/199] Final Prec@1 81.8444%
07/04 10:34:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [151][50/79]	Step 107008	Loss 1.5695	Prec@(1,5) (58.7%, 84.5%)
07/04 10:34:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [151][78/79]	Step 107008	Loss 1.5629	Prec@(1,5) (58.7%, 84.9%)
07/04 10:34:36PM finetuneTeacher_trainer.py:220 [INFO] Valid: [151/199] Final Prec@1 58.6400%
07/04 10:34:36PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 58.6400%
07/04 10:34:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][50/703]	Step 107058	lr 0.001	Loss 0.5271 (0.6013)	Prec@(1,5) (82.9%, 97.8%)	
07/04 10:34:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][100/703]	Step 107108	lr 0.001	Loss 0.5890 (0.6074)	Prec@(1,5) (82.5%, 97.6%)	
07/04 10:34:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][150/703]	Step 107158	lr 0.001	Loss 0.4595 (0.6081)	Prec@(1,5) (82.7%, 97.6%)	
07/04 10:34:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][200/703]	Step 107208	lr 0.001	Loss 0.5027 (0.6029)	Prec@(1,5) (82.8%, 97.5%)	
07/04 10:34:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][250/703]	Step 107258	lr 0.001	Loss 0.5898 (0.6027)	Prec@(1,5) (82.9%, 97.6%)	
07/04 10:34:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][300/703]	Step 107308	lr 0.001	Loss 0.6347 (0.6021)	Prec@(1,5) (82.9%, 97.6%)	
07/04 10:34:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][350/703]	Step 107358	lr 0.001	Loss 0.7213 (0.6022)	Prec@(1,5) (82.8%, 97.6%)	
07/04 10:35:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][400/703]	Step 107408	lr 0.001	Loss 0.7301 (0.6036)	Prec@(1,5) (82.8%, 97.6%)	
07/04 10:35:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][450/703]	Step 107458	lr 0.001	Loss 0.5991 (0.6036)	Prec@(1,5) (82.7%, 97.5%)	
07/04 10:35:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][500/703]	Step 107508	lr 0.001	Loss 0.5892 (0.6035)	Prec@(1,5) (82.8%, 97.5%)	
07/04 10:35:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][550/703]	Step 107558	lr 0.001	Loss 0.6457 (0.6013)	Prec@(1,5) (82.8%, 97.6%)	
07/04 10:35:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][600/703]	Step 107608	lr 0.001	Loss 0.5151 (0.6028)	Prec@(1,5) (82.7%, 97.5%)	
07/04 10:35:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][650/703]	Step 107658	lr 0.001	Loss 0.5098 (0.6024)	Prec@(1,5) (82.8%, 97.6%)	
07/04 10:35:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][700/703]	Step 107708	lr 0.001	Loss 0.5388 (0.6026)	Prec@(1,5) (82.8%, 97.5%)	
07/04 10:35:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [152][703/703]	Step 107711	lr 0.001	Loss 0.6709 (0.6027)	Prec@(1,5) (82.8%, 97.5%)	
07/04 10:35:22PM finetuneTeacher_trainer.py:185 [INFO] Train: [152/199] Final Prec@1 82.7511%
07/04 10:35:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [152][50/79]	Step 107712	Loss 1.5139	Prec@(1,5) (59.9%, 86.2%)
07/04 10:35:24PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [152][78/79]	Step 107712	Loss 1.5213	Prec@(1,5) (60.1%, 85.9%)
07/04 10:35:24PM finetuneTeacher_trainer.py:220 [INFO] Valid: [152/199] Final Prec@1 60.1400%
07/04 10:35:24PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:35:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][50/703]	Step 107762	lr 0.001	Loss 0.4543 (0.5762)	Prec@(1,5) (82.9%, 98.1%)	
07/04 10:35:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][100/703]	Step 107812	lr 0.001	Loss 0.5655 (0.5787)	Prec@(1,5) (83.1%, 97.8%)	
07/04 10:35:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][150/703]	Step 107862	lr 0.001	Loss 0.6214 (0.5740)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:35:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][200/703]	Step 107912	lr 0.001	Loss 0.6150 (0.5750)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:35:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][250/703]	Step 107962	lr 0.001	Loss 0.5111 (0.5755)	Prec@(1,5) (83.5%, 97.6%)	
07/04 10:35:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][300/703]	Step 108012	lr 0.001	Loss 0.4413 (0.5759)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:35:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][350/703]	Step 108062	lr 0.001	Loss 0.4568 (0.5754)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:35:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][400/703]	Step 108112	lr 0.001	Loss 0.5417 (0.5756)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:35:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][450/703]	Step 108162	lr 0.001	Loss 0.3919 (0.5729)	Prec@(1,5) (83.6%, 97.7%)	
07/04 10:35:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][500/703]	Step 108212	lr 0.001	Loss 0.6126 (0.5724)	Prec@(1,5) (83.6%, 97.7%)	
07/04 10:36:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][550/703]	Step 108262	lr 0.001	Loss 0.4950 (0.5720)	Prec@(1,5) (83.7%, 97.8%)	
07/04 10:36:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][600/703]	Step 108312	lr 0.001	Loss 0.5190 (0.5767)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:36:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][650/703]	Step 108362	lr 0.001	Loss 0.5181 (0.5771)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:36:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][700/703]	Step 108412	lr 0.001	Loss 0.7384 (0.5764)	Prec@(1,5) (83.5%, 97.7%)	
07/04 10:36:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [153][703/703]	Step 108415	lr 0.001	Loss 0.5918 (0.5771)	Prec@(1,5) (83.4%, 97.7%)	
07/04 10:36:10PM finetuneTeacher_trainer.py:185 [INFO] Train: [153/199] Final Prec@1 83.4178%
07/04 10:36:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [153][50/79]	Step 108416	Loss 1.5945	Prec@(1,5) (58.6%, 85.8%)
07/04 10:36:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [153][78/79]	Step 108416	Loss 1.5652	Prec@(1,5) (59.2%, 85.9%)
07/04 10:36:12PM finetuneTeacher_trainer.py:220 [INFO] Valid: [153/199] Final Prec@1 59.1800%
07/04 10:36:12PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:36:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][50/703]	Step 108466	lr 0.001	Loss 0.6218 (0.5646)	Prec@(1,5) (83.8%, 97.7%)	
07/04 10:36:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][100/703]	Step 108516	lr 0.001	Loss 0.7924 (0.5700)	Prec@(1,5) (83.6%, 97.8%)	
07/04 10:36:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][150/703]	Step 108566	lr 0.001	Loss 0.4244 (0.5651)	Prec@(1,5) (83.8%, 98.0%)	
07/04 10:36:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][200/703]	Step 108616	lr 0.001	Loss 0.7678 (0.5631)	Prec@(1,5) (83.9%, 98.1%)	
07/04 10:36:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][250/703]	Step 108666	lr 0.001	Loss 0.6647 (0.5631)	Prec@(1,5) (84.0%, 98.0%)	
07/04 10:36:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][300/703]	Step 108716	lr 0.001	Loss 0.5282 (0.5605)	Prec@(1,5) (84.0%, 98.1%)	
07/04 10:36:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][350/703]	Step 108766	lr 0.001	Loss 0.5759 (0.5591)	Prec@(1,5) (84.1%, 98.1%)	
07/04 10:36:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][400/703]	Step 108816	lr 0.001	Loss 0.5286 (0.5609)	Prec@(1,5) (84.0%, 98.1%)	
07/04 10:36:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][450/703]	Step 108866	lr 0.001	Loss 0.7034 (0.5615)	Prec@(1,5) (84.0%, 98.1%)	
07/04 10:36:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][500/703]	Step 108916	lr 0.001	Loss 0.5734 (0.5634)	Prec@(1,5) (84.0%, 98.0%)	
07/04 10:36:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][550/703]	Step 108966	lr 0.001	Loss 0.4634 (0.5614)	Prec@(1,5) (84.1%, 98.1%)	
07/04 10:36:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][600/703]	Step 109016	lr 0.001	Loss 0.6503 (0.5613)	Prec@(1,5) (84.1%, 98.1%)	
07/04 10:36:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][650/703]	Step 109066	lr 0.001	Loss 0.5186 (0.5614)	Prec@(1,5) (84.1%, 98.0%)	
07/04 10:36:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][700/703]	Step 109116	lr 0.001	Loss 0.5997 (0.5616)	Prec@(1,5) (84.0%, 98.0%)	
07/04 10:36:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [154][703/703]	Step 109119	lr 0.001	Loss 0.6305 (0.5616)	Prec@(1,5) (84.1%, 98.0%)	
07/04 10:36:58PM finetuneTeacher_trainer.py:185 [INFO] Train: [154/199] Final Prec@1 84.0511%
07/04 10:36:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [154][50/79]	Step 109120	Loss 1.5784	Prec@(1,5) (59.1%, 84.8%)
07/04 10:36:59PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [154][78/79]	Step 109120	Loss 1.5463	Prec@(1,5) (59.5%, 85.6%)
07/04 10:37:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [154/199] Final Prec@1 59.5200%
07/04 10:37:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:37:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][50/703]	Step 109170	lr 0.001	Loss 0.6854 (0.5869)	Prec@(1,5) (83.3%, 97.5%)	
07/04 10:37:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][100/703]	Step 109220	lr 0.001	Loss 0.4774 (0.5770)	Prec@(1,5) (83.5%, 97.5%)	
07/04 10:37:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][150/703]	Step 109270	lr 0.001	Loss 0.5672 (0.5660)	Prec@(1,5) (84.0%, 97.6%)	
07/04 10:37:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][200/703]	Step 109320	lr 0.001	Loss 0.5725 (0.5677)	Prec@(1,5) (84.0%, 97.6%)	
07/04 10:37:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][250/703]	Step 109370	lr 0.001	Loss 0.6684 (0.5662)	Prec@(1,5) (84.0%, 97.6%)	
07/04 10:37:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][300/703]	Step 109420	lr 0.001	Loss 0.5405 (0.5568)	Prec@(1,5) (84.3%, 97.7%)	
07/04 10:37:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][350/703]	Step 109470	lr 0.001	Loss 0.3865 (0.5573)	Prec@(1,5) (84.3%, 97.7%)	
07/04 10:37:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][400/703]	Step 109520	lr 0.001	Loss 0.4948 (0.5607)	Prec@(1,5) (84.3%, 97.7%)	
07/04 10:37:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][450/703]	Step 109570	lr 0.001	Loss 0.3207 (0.5601)	Prec@(1,5) (84.2%, 97.7%)	
07/04 10:37:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][500/703]	Step 109620	lr 0.001	Loss 0.5619 (0.5602)	Prec@(1,5) (84.3%, 97.7%)	
07/04 10:37:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][550/703]	Step 109670	lr 0.001	Loss 0.5409 (0.5570)	Prec@(1,5) (84.3%, 97.8%)	
07/04 10:37:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][600/703]	Step 109720	lr 0.001	Loss 0.5395 (0.5580)	Prec@(1,5) (84.4%, 97.8%)	
07/04 10:37:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][650/703]	Step 109770	lr 0.001	Loss 0.6244 (0.5592)	Prec@(1,5) (84.3%, 97.8%)	
07/04 10:37:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][700/703]	Step 109820	lr 0.001	Loss 0.5734 (0.5576)	Prec@(1,5) (84.3%, 97.8%)	
07/04 10:37:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [155][703/703]	Step 109823	lr 0.001	Loss 0.6545 (0.5574)	Prec@(1,5) (84.3%, 97.8%)	
07/04 10:37:45PM finetuneTeacher_trainer.py:185 [INFO] Train: [155/199] Final Prec@1 84.3222%
07/04 10:37:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [155][50/79]	Step 109824	Loss 1.5392	Prec@(1,5) (60.2%, 85.9%)
07/04 10:37:46PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [155][78/79]	Step 109824	Loss 1.5512	Prec@(1,5) (59.6%, 85.5%)
07/04 10:37:46PM finetuneTeacher_trainer.py:220 [INFO] Valid: [155/199] Final Prec@1 59.6400%
07/04 10:37:46PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:37:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][50/703]	Step 109874	lr 0.001	Loss 0.5051 (0.5287)	Prec@(1,5) (85.3%, 98.2%)	
07/04 10:37:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][100/703]	Step 109924	lr 0.001	Loss 0.5490 (0.5388)	Prec@(1,5) (84.8%, 98.0%)	
07/04 10:37:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][150/703]	Step 109974	lr 0.001	Loss 0.4904 (0.5317)	Prec@(1,5) (85.2%, 98.0%)	
07/04 10:38:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][200/703]	Step 110024	lr 0.001	Loss 0.6522 (0.5302)	Prec@(1,5) (85.3%, 98.0%)	
07/04 10:38:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][250/703]	Step 110074	lr 0.001	Loss 0.5371 (0.5329)	Prec@(1,5) (85.0%, 98.1%)	
07/04 10:38:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][300/703]	Step 110124	lr 0.001	Loss 0.5655 (0.5345)	Prec@(1,5) (84.9%, 98.0%)	
07/04 10:38:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][350/703]	Step 110174	lr 0.001	Loss 0.6066 (0.5338)	Prec@(1,5) (84.8%, 98.1%)	
07/04 10:38:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][400/703]	Step 110224	lr 0.001	Loss 0.4705 (0.5388)	Prec@(1,5) (84.7%, 98.0%)	
07/04 10:38:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][450/703]	Step 110274	lr 0.001	Loss 0.6265 (0.5391)	Prec@(1,5) (84.7%, 98.0%)	
07/04 10:38:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][500/703]	Step 110324	lr 0.001	Loss 0.4263 (0.5415)	Prec@(1,5) (84.7%, 98.0%)	
07/04 10:38:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][550/703]	Step 110374	lr 0.001	Loss 0.5420 (0.5426)	Prec@(1,5) (84.6%, 98.0%)	
07/04 10:38:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][600/703]	Step 110424	lr 0.001	Loss 0.3924 (0.5431)	Prec@(1,5) (84.6%, 97.9%)	
07/04 10:38:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][650/703]	Step 110474	lr 0.001	Loss 0.3943 (0.5424)	Prec@(1,5) (84.7%, 97.9%)	
07/04 10:38:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][700/703]	Step 110524	lr 0.001	Loss 0.3979 (0.5406)	Prec@(1,5) (84.8%, 97.9%)	
07/04 10:38:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [156][703/703]	Step 110527	lr 0.001	Loss 0.6529 (0.5410)	Prec@(1,5) (84.8%, 97.9%)	
07/04 10:38:32PM finetuneTeacher_trainer.py:185 [INFO] Train: [156/199] Final Prec@1 84.7600%
07/04 10:38:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [156][50/79]	Step 110528	Loss 1.5464	Prec@(1,5) (60.2%, 85.0%)
07/04 10:38:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [156][78/79]	Step 110528	Loss 1.5484	Prec@(1,5) (59.9%, 85.3%)
07/04 10:38:33PM finetuneTeacher_trainer.py:220 [INFO] Valid: [156/199] Final Prec@1 59.8800%
07/04 10:38:33PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:38:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][50/703]	Step 110578	lr 0.001	Loss 0.5310 (0.5131)	Prec@(1,5) (86.2%, 98.1%)	
07/04 10:38:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][100/703]	Step 110628	lr 0.001	Loss 0.5655 (0.5164)	Prec@(1,5) (85.6%, 98.3%)	
07/04 10:38:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][150/703]	Step 110678	lr 0.001	Loss 0.4220 (0.5113)	Prec@(1,5) (85.6%, 98.2%)	
07/04 10:38:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][200/703]	Step 110728	lr 0.001	Loss 0.4124 (0.5175)	Prec@(1,5) (85.3%, 98.2%)	
07/04 10:38:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][250/703]	Step 110778	lr 0.001	Loss 0.6238 (0.5242)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:38:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][300/703]	Step 110828	lr 0.001	Loss 0.3568 (0.5256)	Prec@(1,5) (84.8%, 98.2%)	
07/04 10:38:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][350/703]	Step 110878	lr 0.001	Loss 0.4069 (0.5263)	Prec@(1,5) (84.8%, 98.2%)	
07/04 10:38:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][400/703]	Step 110928	lr 0.001	Loss 0.4618 (0.5272)	Prec@(1,5) (84.7%, 98.2%)	
07/04 10:39:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][450/703]	Step 110978	lr 0.001	Loss 0.7228 (0.5283)	Prec@(1,5) (84.7%, 98.2%)	
07/04 10:39:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][500/703]	Step 111028	lr 0.001	Loss 0.5205 (0.5301)	Prec@(1,5) (84.6%, 98.2%)	
07/04 10:39:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][550/703]	Step 111078	lr 0.001	Loss 0.6221 (0.5290)	Prec@(1,5) (84.6%, 98.2%)	
07/04 10:39:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][600/703]	Step 111128	lr 0.001	Loss 0.7003 (0.5305)	Prec@(1,5) (84.6%, 98.1%)	
07/04 10:39:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][650/703]	Step 111178	lr 0.001	Loss 0.4839 (0.5303)	Prec@(1,5) (84.7%, 98.1%)	
07/04 10:39:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][700/703]	Step 111228	lr 0.001	Loss 0.8049 (0.5285)	Prec@(1,5) (84.8%, 98.1%)	
07/04 10:39:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [157][703/703]	Step 111231	lr 0.001	Loss 0.5268 (0.5284)	Prec@(1,5) (84.8%, 98.1%)	
07/04 10:39:19PM finetuneTeacher_trainer.py:185 [INFO] Train: [157/199] Final Prec@1 84.7756%
07/04 10:39:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [157][50/79]	Step 111232	Loss 1.5521	Prec@(1,5) (59.6%, 84.7%)
07/04 10:39:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [157][78/79]	Step 111232	Loss 1.5361	Prec@(1,5) (60.1%, 85.0%)
07/04 10:39:20PM finetuneTeacher_trainer.py:220 [INFO] Valid: [157/199] Final Prec@1 60.0200%
07/04 10:39:21PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:39:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][50/703]	Step 111282	lr 0.001	Loss 0.4679 (0.5340)	Prec@(1,5) (85.4%, 97.9%)	
07/04 10:39:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][100/703]	Step 111332	lr 0.001	Loss 0.2622 (0.5225)	Prec@(1,5) (85.5%, 98.2%)	
07/04 10:39:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][150/703]	Step 111382	lr 0.001	Loss 0.4076 (0.5202)	Prec@(1,5) (85.4%, 98.1%)	
07/04 10:39:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][200/703]	Step 111432	lr 0.001	Loss 0.6452 (0.5165)	Prec@(1,5) (85.4%, 98.2%)	
07/04 10:39:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][250/703]	Step 111482	lr 0.001	Loss 0.7764 (0.5175)	Prec@(1,5) (85.3%, 98.2%)	
07/04 10:39:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][300/703]	Step 111532	lr 0.001	Loss 0.4609 (0.5181)	Prec@(1,5) (85.2%, 98.2%)	
07/04 10:39:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][350/703]	Step 111582	lr 0.001	Loss 0.5740 (0.5202)	Prec@(1,5) (85.1%, 98.2%)	
07/04 10:39:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][400/703]	Step 111632	lr 0.001	Loss 0.6188 (0.5206)	Prec@(1,5) (85.1%, 98.2%)	
07/04 10:39:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][450/703]	Step 111682	lr 0.001	Loss 0.6100 (0.5217)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:39:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][500/703]	Step 111732	lr 0.001	Loss 0.5028 (0.5247)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:39:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][550/703]	Step 111782	lr 0.001	Loss 0.3151 (0.5246)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:40:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][600/703]	Step 111832	lr 0.001	Loss 0.3149 (0.5228)	Prec@(1,5) (85.1%, 98.2%)	
07/04 10:40:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][650/703]	Step 111882	lr 0.001	Loss 0.5628 (0.5231)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:40:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][700/703]	Step 111932	lr 0.001	Loss 0.5438 (0.5243)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:40:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [158][703/703]	Step 111935	lr 0.001	Loss 0.5059 (0.5237)	Prec@(1,5) (85.0%, 98.2%)	
07/04 10:40:06PM finetuneTeacher_trainer.py:185 [INFO] Train: [158/199] Final Prec@1 84.9800%
07/04 10:40:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [158][50/79]	Step 111936	Loss 1.5390	Prec@(1,5) (59.6%, 86.5%)
07/04 10:40:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [158][78/79]	Step 111936	Loss 1.5305	Prec@(1,5) (59.6%, 86.7%)
07/04 10:40:08PM finetuneTeacher_trainer.py:220 [INFO] Valid: [158/199] Final Prec@1 59.5600%
07/04 10:40:08PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:40:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][50/703]	Step 111986	lr 0.001	Loss 0.4725 (0.5173)	Prec@(1,5) (85.7%, 98.2%)	
07/04 10:40:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][100/703]	Step 112036	lr 0.001	Loss 0.4329 (0.5145)	Prec@(1,5) (85.5%, 98.2%)	
07/04 10:40:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][150/703]	Step 112086	lr 0.001	Loss 0.4304 (0.5081)	Prec@(1,5) (85.6%, 98.3%)	
07/04 10:40:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][200/703]	Step 112136	lr 0.001	Loss 0.4953 (0.5145)	Prec@(1,5) (85.4%, 98.3%)	
07/04 10:40:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][250/703]	Step 112186	lr 0.001	Loss 0.5101 (0.5117)	Prec@(1,5) (85.6%, 98.3%)	
07/04 10:40:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][300/703]	Step 112236	lr 0.001	Loss 0.5358 (0.5081)	Prec@(1,5) (85.6%, 98.4%)	
07/04 10:40:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][350/703]	Step 112286	lr 0.001	Loss 0.4668 (0.5126)	Prec@(1,5) (85.5%, 98.3%)	
07/04 10:40:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][400/703]	Step 112336	lr 0.001	Loss 0.4755 (0.5124)	Prec@(1,5) (85.5%, 98.3%)	
07/04 10:40:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][450/703]	Step 112386	lr 0.001	Loss 0.5251 (0.5151)	Prec@(1,5) (85.4%, 98.2%)	
07/04 10:40:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][500/703]	Step 112436	lr 0.001	Loss 0.3000 (0.5152)	Prec@(1,5) (85.4%, 98.2%)	
07/04 10:40:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][550/703]	Step 112486	lr 0.001	Loss 0.4212 (0.5157)	Prec@(1,5) (85.3%, 98.2%)	
07/04 10:40:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][600/703]	Step 112536	lr 0.001	Loss 0.5081 (0.5164)	Prec@(1,5) (85.2%, 98.2%)	
07/04 10:40:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][650/703]	Step 112586	lr 0.001	Loss 0.4366 (0.5177)	Prec@(1,5) (85.2%, 98.2%)	
07/04 10:40:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][700/703]	Step 112636	lr 0.001	Loss 0.5536 (0.5184)	Prec@(1,5) (85.2%, 98.2%)	
07/04 10:40:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [159][703/703]	Step 112639	lr 0.001	Loss 0.5316 (0.5183)	Prec@(1,5) (85.2%, 98.2%)	
07/04 10:40:54PM finetuneTeacher_trainer.py:185 [INFO] Train: [159/199] Final Prec@1 85.1822%
07/04 10:40:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [159][50/79]	Step 112640	Loss 1.5598	Prec@(1,5) (60.2%, 85.3%)
07/04 10:40:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [159][78/79]	Step 112640	Loss 1.5500	Prec@(1,5) (59.5%, 85.5%)
07/04 10:40:55PM finetuneTeacher_trainer.py:220 [INFO] Valid: [159/199] Final Prec@1 59.5200%
07/04 10:40:55PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:40:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][50/703]	Step 112690	lr 0.001	Loss 0.4069 (0.4786)	Prec@(1,5) (86.9%, 98.2%)	
07/04 10:41:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][100/703]	Step 112740	lr 0.001	Loss 0.4255 (0.4907)	Prec@(1,5) (86.5%, 98.2%)	
07/04 10:41:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][150/703]	Step 112790	lr 0.001	Loss 0.4348 (0.4895)	Prec@(1,5) (86.3%, 98.3%)	
07/04 10:41:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][200/703]	Step 112840	lr 0.001	Loss 0.5558 (0.4954)	Prec@(1,5) (86.3%, 98.3%)	
07/04 10:41:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][250/703]	Step 112890	lr 0.001	Loss 0.5924 (0.4968)	Prec@(1,5) (86.1%, 98.3%)	
07/04 10:41:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][300/703]	Step 112940	lr 0.001	Loss 0.5605 (0.4963)	Prec@(1,5) (86.1%, 98.3%)	
07/04 10:41:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][350/703]	Step 112990	lr 0.001	Loss 0.4131 (0.5004)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:41:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][400/703]	Step 113040	lr 0.001	Loss 0.5657 (0.4997)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:41:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][450/703]	Step 113090	lr 0.001	Loss 0.6538 (0.5031)	Prec@(1,5) (85.8%, 98.3%)	
07/04 10:41:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][500/703]	Step 113140	lr 0.001	Loss 0.4410 (0.5015)	Prec@(1,5) (85.9%, 98.3%)	
07/04 10:41:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][550/703]	Step 113190	lr 0.001	Loss 0.5875 (0.5017)	Prec@(1,5) (85.9%, 98.3%)	
07/04 10:41:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][600/703]	Step 113240	lr 0.001	Loss 0.4358 (0.5014)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:41:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][650/703]	Step 113290	lr 0.001	Loss 0.3390 (0.5020)	Prec@(1,5) (85.9%, 98.3%)	
07/04 10:41:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][700/703]	Step 113340	lr 0.001	Loss 0.4754 (0.5040)	Prec@(1,5) (85.8%, 98.2%)	
07/04 10:41:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [160][703/703]	Step 113343	lr 0.001	Loss 0.4323 (0.5039)	Prec@(1,5) (85.8%, 98.2%)	
07/04 10:41:41PM finetuneTeacher_trainer.py:185 [INFO] Train: [160/199] Final Prec@1 85.8444%
07/04 10:41:42PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [160][50/79]	Step 113344	Loss 1.5737	Prec@(1,5) (58.7%, 85.8%)
07/04 10:41:42PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [160][78/79]	Step 113344	Loss 1.5523	Prec@(1,5) (59.8%, 86.1%)
07/04 10:41:42PM finetuneTeacher_trainer.py:220 [INFO] Valid: [160/199] Final Prec@1 59.8000%
07/04 10:41:42PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:41:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][50/703]	Step 113394	lr 0.001	Loss 0.6447 (0.4894)	Prec@(1,5) (86.1%, 98.2%)	
07/04 10:41:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][100/703]	Step 113444	lr 0.001	Loss 0.5446 (0.4800)	Prec@(1,5) (86.4%, 98.2%)	
07/04 10:41:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][150/703]	Step 113494	lr 0.001	Loss 0.3238 (0.4791)	Prec@(1,5) (86.4%, 98.3%)	
07/04 10:41:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][200/703]	Step 113544	lr 0.001	Loss 0.6661 (0.4844)	Prec@(1,5) (86.1%, 98.4%)	
07/04 10:42:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][250/703]	Step 113594	lr 0.001	Loss 0.5024 (0.4873)	Prec@(1,5) (86.1%, 98.3%)	
07/04 10:42:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][300/703]	Step 113644	lr 0.001	Loss 0.2564 (0.4917)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][350/703]	Step 113694	lr 0.001	Loss 0.5182 (0.4945)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][400/703]	Step 113744	lr 0.001	Loss 0.4363 (0.4951)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][450/703]	Step 113794	lr 0.001	Loss 0.3769 (0.4933)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][500/703]	Step 113844	lr 0.001	Loss 0.4815 (0.4934)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][550/703]	Step 113894	lr 0.001	Loss 0.3575 (0.4926)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][600/703]	Step 113944	lr 0.001	Loss 0.6681 (0.4932)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][650/703]	Step 113994	lr 0.001	Loss 0.4351 (0.4941)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][700/703]	Step 114044	lr 0.001	Loss 0.5047 (0.4941)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [161][703/703]	Step 114047	lr 0.001	Loss 0.5118 (0.4939)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:42:30PM finetuneTeacher_trainer.py:185 [INFO] Train: [161/199] Final Prec@1 85.9556%
07/04 10:42:31PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [161][50/79]	Step 114048	Loss 1.5224	Prec@(1,5) (60.6%, 85.7%)
07/04 10:42:31PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [161][78/79]	Step 114048	Loss 1.5355	Prec@(1,5) (59.8%, 85.8%)
07/04 10:42:31PM finetuneTeacher_trainer.py:220 [INFO] Valid: [161/199] Final Prec@1 59.8000%
07/04 10:42:31PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.1400%
07/04 10:42:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][50/703]	Step 114098	lr 0.001	Loss 0.2780 (0.4988)	Prec@(1,5) (85.8%, 98.5%)	
07/04 10:42:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][100/703]	Step 114148	lr 0.001	Loss 0.7403 (0.4995)	Prec@(1,5) (86.2%, 98.3%)	
07/04 10:42:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][150/703]	Step 114198	lr 0.001	Loss 0.4732 (0.4969)	Prec@(1,5) (86.2%, 98.2%)	
07/04 10:42:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][200/703]	Step 114248	lr 0.001	Loss 0.3395 (0.4946)	Prec@(1,5) (86.4%, 98.3%)	
07/04 10:42:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][250/703]	Step 114298	lr 0.001	Loss 0.4012 (0.4957)	Prec@(1,5) (86.3%, 98.3%)	
07/04 10:42:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][300/703]	Step 114348	lr 0.001	Loss 0.5077 (0.4891)	Prec@(1,5) (86.5%, 98.3%)	
07/04 10:42:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][350/703]	Step 114398	lr 0.001	Loss 0.3949 (0.4898)	Prec@(1,5) (86.5%, 98.3%)	
07/04 10:42:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][400/703]	Step 114448	lr 0.001	Loss 0.5984 (0.4904)	Prec@(1,5) (86.5%, 98.3%)	
07/04 10:43:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][450/703]	Step 114498	lr 0.001	Loss 0.4452 (0.4908)	Prec@(1,5) (86.5%, 98.3%)	
07/04 10:43:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][500/703]	Step 114548	lr 0.001	Loss 0.3908 (0.4909)	Prec@(1,5) (86.5%, 98.3%)	
07/04 10:43:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][550/703]	Step 114598	lr 0.001	Loss 0.4897 (0.4914)	Prec@(1,5) (86.4%, 98.3%)	
07/04 10:43:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][600/703]	Step 114648	lr 0.001	Loss 0.4986 (0.4915)	Prec@(1,5) (86.4%, 98.3%)	
07/04 10:43:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][650/703]	Step 114698	lr 0.001	Loss 0.3866 (0.4898)	Prec@(1,5) (86.5%, 98.3%)	
07/04 10:43:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][700/703]	Step 114748	lr 0.001	Loss 0.4323 (0.4887)	Prec@(1,5) (86.4%, 98.4%)	
07/04 10:43:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [162][703/703]	Step 114751	lr 0.001	Loss 0.4530 (0.4886)	Prec@(1,5) (86.4%, 98.4%)	
07/04 10:43:17PM finetuneTeacher_trainer.py:185 [INFO] Train: [162/199] Final Prec@1 86.4267%
07/04 10:43:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [162][50/79]	Step 114752	Loss 1.5168	Prec@(1,5) (61.2%, 86.4%)
07/04 10:43:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [162][78/79]	Step 114752	Loss 1.5197	Prec@(1,5) (60.8%, 86.3%)
07/04 10:43:18PM finetuneTeacher_trainer.py:220 [INFO] Valid: [162/199] Final Prec@1 60.8400%
07/04 10:43:19PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:43:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][50/703]	Step 114802	lr 0.001	Loss 0.5422 (0.4694)	Prec@(1,5) (86.9%, 98.6%)	
07/04 10:43:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][100/703]	Step 114852	lr 0.001	Loss 0.3203 (0.4834)	Prec@(1,5) (86.6%, 98.5%)	
07/04 10:43:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][150/703]	Step 114902	lr 0.001	Loss 0.3873 (0.4792)	Prec@(1,5) (86.9%, 98.4%)	
07/04 10:43:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][200/703]	Step 114952	lr 0.001	Loss 0.5273 (0.4839)	Prec@(1,5) (86.7%, 98.4%)	
07/04 10:43:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][250/703]	Step 115002	lr 0.001	Loss 0.3158 (0.4830)	Prec@(1,5) (86.5%, 98.5%)	
07/04 10:43:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][300/703]	Step 115052	lr 0.001	Loss 0.3295 (0.4865)	Prec@(1,5) (86.3%, 98.4%)	
07/04 10:43:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][350/703]	Step 115102	lr 0.001	Loss 0.6131 (0.4892)	Prec@(1,5) (86.2%, 98.4%)	
07/04 10:43:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][400/703]	Step 115152	lr 0.001	Loss 0.6165 (0.4877)	Prec@(1,5) (86.3%, 98.3%)	
07/04 10:43:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][450/703]	Step 115202	lr 0.001	Loss 0.3420 (0.4854)	Prec@(1,5) (86.2%, 98.4%)	
07/04 10:43:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][500/703]	Step 115252	lr 0.001	Loss 0.3751 (0.4845)	Prec@(1,5) (86.3%, 98.4%)	
07/04 10:43:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][550/703]	Step 115302	lr 0.001	Loss 0.5348 (0.4861)	Prec@(1,5) (86.2%, 98.3%)	
07/04 10:43:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][600/703]	Step 115352	lr 0.001	Loss 0.5476 (0.4868)	Prec@(1,5) (86.3%, 98.3%)	
07/04 10:44:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][650/703]	Step 115402	lr 0.001	Loss 0.3912 (0.4867)	Prec@(1,5) (86.2%, 98.3%)	
07/04 10:44:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][700/703]	Step 115452	lr 0.001	Loss 0.4924 (0.4877)	Prec@(1,5) (86.2%, 98.4%)	
07/04 10:44:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [163][703/703]	Step 115455	lr 0.001	Loss 0.4027 (0.4877)	Prec@(1,5) (86.2%, 98.4%)	
07/04 10:44:05PM finetuneTeacher_trainer.py:185 [INFO] Train: [163/199] Final Prec@1 86.1689%
07/04 10:44:06PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [163][50/79]	Step 115456	Loss 1.5391	Prec@(1,5) (59.6%, 85.7%)
07/04 10:44:06PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [163][78/79]	Step 115456	Loss 1.5663	Prec@(1,5) (59.2%, 85.1%)
07/04 10:44:06PM finetuneTeacher_trainer.py:220 [INFO] Valid: [163/199] Final Prec@1 59.2200%
07/04 10:44:06PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:44:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][50/703]	Step 115506	lr 0.001	Loss 0.3634 (0.4840)	Prec@(1,5) (86.2%, 98.4%)	
07/04 10:44:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][100/703]	Step 115556	lr 0.001	Loss 0.4858 (0.4984)	Prec@(1,5) (86.0%, 98.3%)	
07/04 10:44:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][150/703]	Step 115606	lr 0.001	Loss 0.6569 (0.4869)	Prec@(1,5) (86.3%, 98.5%)	
07/04 10:44:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][200/703]	Step 115656	lr 0.001	Loss 0.3280 (0.4820)	Prec@(1,5) (86.4%, 98.5%)	
07/04 10:44:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][250/703]	Step 115706	lr 0.001	Loss 0.4907 (0.4793)	Prec@(1,5) (86.4%, 98.5%)	
07/04 10:44:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][300/703]	Step 115756	lr 0.001	Loss 0.4016 (0.4820)	Prec@(1,5) (86.2%, 98.4%)	
07/04 10:44:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][350/703]	Step 115806	lr 0.001	Loss 0.5535 (0.4791)	Prec@(1,5) (86.5%, 98.4%)	
07/04 10:44:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][400/703]	Step 115856	lr 0.001	Loss 0.2898 (0.4769)	Prec@(1,5) (86.6%, 98.5%)	
07/04 10:44:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][450/703]	Step 115906	lr 0.001	Loss 0.6298 (0.4804)	Prec@(1,5) (86.4%, 98.5%)	
07/04 10:44:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][500/703]	Step 115956	lr 0.001	Loss 0.4025 (0.4795)	Prec@(1,5) (86.4%, 98.5%)	
07/04 10:44:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][550/703]	Step 116006	lr 0.001	Loss 0.4412 (0.4798)	Prec@(1,5) (86.4%, 98.5%)	
07/04 10:44:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][600/703]	Step 116056	lr 0.001	Loss 0.6758 (0.4799)	Prec@(1,5) (86.3%, 98.5%)	
07/04 10:44:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][650/703]	Step 116106	lr 0.001	Loss 0.3827 (0.4802)	Prec@(1,5) (86.4%, 98.5%)	
07/04 10:44:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][700/703]	Step 116156	lr 0.001	Loss 0.5310 (0.4809)	Prec@(1,5) (86.3%, 98.4%)	
07/04 10:44:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [164][703/703]	Step 116159	lr 0.001	Loss 0.5637 (0.4808)	Prec@(1,5) (86.3%, 98.4%)	
07/04 10:44:51PM finetuneTeacher_trainer.py:185 [INFO] Train: [164/199] Final Prec@1 86.3422%
07/04 10:44:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [164][50/79]	Step 116160	Loss 1.5869	Prec@(1,5) (59.6%, 85.0%)
07/04 10:44:52PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [164][78/79]	Step 116160	Loss 1.5646	Prec@(1,5) (59.9%, 85.4%)
07/04 10:44:53PM finetuneTeacher_trainer.py:220 [INFO] Valid: [164/199] Final Prec@1 59.9200%
07/04 10:44:53PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:44:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][50/703]	Step 116210	lr 0.001	Loss 0.4041 (0.4664)	Prec@(1,5) (87.3%, 98.9%)	
07/04 10:45:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][100/703]	Step 116260	lr 0.001	Loss 0.5347 (0.4657)	Prec@(1,5) (87.0%, 98.7%)	
07/04 10:45:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][150/703]	Step 116310	lr 0.001	Loss 0.5359 (0.4735)	Prec@(1,5) (86.7%, 98.5%)	
07/04 10:45:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][200/703]	Step 116360	lr 0.001	Loss 0.5823 (0.4691)	Prec@(1,5) (86.9%, 98.5%)	
07/04 10:45:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][250/703]	Step 116410	lr 0.001	Loss 0.5893 (0.4738)	Prec@(1,5) (86.6%, 98.5%)	
07/04 10:45:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][300/703]	Step 116460	lr 0.001	Loss 0.3983 (0.4752)	Prec@(1,5) (86.6%, 98.4%)	
07/04 10:45:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][350/703]	Step 116510	lr 0.001	Loss 0.4721 (0.4752)	Prec@(1,5) (86.6%, 98.4%)	
07/04 10:45:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][400/703]	Step 116560	lr 0.001	Loss 0.5730 (0.4764)	Prec@(1,5) (86.6%, 98.4%)	
07/04 10:45:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][450/703]	Step 116610	lr 0.001	Loss 0.5279 (0.4753)	Prec@(1,5) (86.6%, 98.4%)	
07/04 10:45:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][500/703]	Step 116660	lr 0.001	Loss 0.6722 (0.4759)	Prec@(1,5) (86.6%, 98.4%)	
07/04 10:45:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][550/703]	Step 116710	lr 0.001	Loss 0.5958 (0.4762)	Prec@(1,5) (86.6%, 98.4%)	
07/04 10:45:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][600/703]	Step 116760	lr 0.001	Loss 0.3802 (0.4798)	Prec@(1,5) (86.5%, 98.4%)	
07/04 10:45:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][650/703]	Step 116810	lr 0.001	Loss 0.5871 (0.4813)	Prec@(1,5) (86.4%, 98.4%)	
07/04 10:45:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][700/703]	Step 116860	lr 0.001	Loss 0.4590 (0.4818)	Prec@(1,5) (86.4%, 98.4%)	
07/04 10:45:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [165][703/703]	Step 116863	lr 0.001	Loss 0.6016 (0.4821)	Prec@(1,5) (86.4%, 98.4%)	
07/04 10:45:37PM finetuneTeacher_trainer.py:185 [INFO] Train: [165/199] Final Prec@1 86.3911%
07/04 10:45:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [165][50/79]	Step 116864	Loss 1.5575	Prec@(1,5) (60.1%, 86.2%)
07/04 10:45:38PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [165][78/79]	Step 116864	Loss 1.5669	Prec@(1,5) (59.8%, 86.1%)
07/04 10:45:39PM finetuneTeacher_trainer.py:220 [INFO] Valid: [165/199] Final Prec@1 59.7800%
07/04 10:45:39PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:45:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][50/703]	Step 116914	lr 0.001	Loss 0.4417 (0.4706)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:45:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][100/703]	Step 116964	lr 0.001	Loss 0.4197 (0.4556)	Prec@(1,5) (87.6%, 98.7%)	
07/04 10:45:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][150/703]	Step 117014	lr 0.001	Loss 0.6150 (0.4575)	Prec@(1,5) (87.6%, 98.7%)	
07/04 10:45:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][200/703]	Step 117064	lr 0.001	Loss 0.2985 (0.4554)	Prec@(1,5) (87.6%, 98.6%)	
07/04 10:45:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][250/703]	Step 117114	lr 0.001	Loss 0.4192 (0.4580)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:45:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][300/703]	Step 117164	lr 0.001	Loss 0.4383 (0.4600)	Prec@(1,5) (87.3%, 98.6%)	
07/04 10:46:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][350/703]	Step 117214	lr 0.001	Loss 0.4870 (0.4620)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:46:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][400/703]	Step 117264	lr 0.001	Loss 0.3993 (0.4672)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:46:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][450/703]	Step 117314	lr 0.001	Loss 0.5712 (0.4690)	Prec@(1,5) (86.9%, 98.5%)	
07/04 10:46:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][500/703]	Step 117364	lr 0.001	Loss 0.4313 (0.4682)	Prec@(1,5) (86.9%, 98.5%)	
07/04 10:46:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][550/703]	Step 117414	lr 0.001	Loss 0.4316 (0.4722)	Prec@(1,5) (86.8%, 98.5%)	
07/04 10:46:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][600/703]	Step 117464	lr 0.001	Loss 0.4218 (0.4733)	Prec@(1,5) (86.7%, 98.5%)	
07/04 10:46:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][650/703]	Step 117514	lr 0.001	Loss 0.4840 (0.4738)	Prec@(1,5) (86.7%, 98.5%)	
07/04 10:46:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][700/703]	Step 117564	lr 0.001	Loss 0.4617 (0.4746)	Prec@(1,5) (86.7%, 98.5%)	
07/04 10:46:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [166][703/703]	Step 117567	lr 0.001	Loss 0.4170 (0.4747)	Prec@(1,5) (86.7%, 98.5%)	
07/04 10:46:24PM finetuneTeacher_trainer.py:185 [INFO] Train: [166/199] Final Prec@1 86.6556%
07/04 10:46:25PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [166][50/79]	Step 117568	Loss 1.5915	Prec@(1,5) (59.4%, 84.8%)
07/04 10:46:26PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [166][78/79]	Step 117568	Loss 1.5676	Prec@(1,5) (59.7%, 85.5%)
07/04 10:46:26PM finetuneTeacher_trainer.py:220 [INFO] Valid: [166/199] Final Prec@1 59.7200%
07/04 10:46:26PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:46:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][50/703]	Step 117618	lr 0.001	Loss 0.6738 (0.4670)	Prec@(1,5) (87.2%, 98.4%)	
07/04 10:46:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][100/703]	Step 117668	lr 0.001	Loss 0.6424 (0.4686)	Prec@(1,5) (86.8%, 98.5%)	
07/04 10:46:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][150/703]	Step 117718	lr 0.001	Loss 0.5227 (0.4629)	Prec@(1,5) (87.0%, 98.6%)	
07/04 10:46:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][200/703]	Step 117768	lr 0.001	Loss 0.4986 (0.4575)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:46:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][250/703]	Step 117818	lr 0.001	Loss 0.4181 (0.4625)	Prec@(1,5) (87.2%, 98.5%)	
07/04 10:46:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][300/703]	Step 117868	lr 0.001	Loss 0.5518 (0.4637)	Prec@(1,5) (87.1%, 98.5%)	
07/04 10:46:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][350/703]	Step 117918	lr 0.001	Loss 0.4725 (0.4616)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:46:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][400/703]	Step 117968	lr 0.001	Loss 0.4712 (0.4620)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:46:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][450/703]	Step 118018	lr 0.001	Loss 0.4696 (0.4622)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:46:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][500/703]	Step 118068	lr 0.001	Loss 0.3622 (0.4606)	Prec@(1,5) (87.3%, 98.6%)	
07/04 10:47:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][550/703]	Step 118118	lr 0.001	Loss 0.6822 (0.4613)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:47:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][600/703]	Step 118168	lr 0.001	Loss 0.4763 (0.4610)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:47:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][650/703]	Step 118218	lr 0.001	Loss 0.4973 (0.4619)	Prec@(1,5) (87.1%, 98.5%)	
07/04 10:47:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][700/703]	Step 118268	lr 0.001	Loss 0.4636 (0.4628)	Prec@(1,5) (87.1%, 98.5%)	
07/04 10:47:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [167][703/703]	Step 118271	lr 0.001	Loss 0.5229 (0.4631)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:11PM finetuneTeacher_trainer.py:185 [INFO] Train: [167/199] Final Prec@1 87.0311%
07/04 10:47:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [167][50/79]	Step 118272	Loss 1.5859	Prec@(1,5) (59.5%, 85.2%)
07/04 10:47:13PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [167][78/79]	Step 118272	Loss 1.5249	Prec@(1,5) (60.7%, 86.3%)
07/04 10:47:13PM finetuneTeacher_trainer.py:220 [INFO] Valid: [167/199] Final Prec@1 60.7000%
07/04 10:47:13PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:47:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][50/703]	Step 118322	lr 0.001	Loss 0.4485 (0.4555)	Prec@(1,5) (87.8%, 98.3%)	
07/04 10:47:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][100/703]	Step 118372	lr 0.001	Loss 0.3582 (0.4534)	Prec@(1,5) (87.7%, 98.5%)	
07/04 10:47:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][150/703]	Step 118422	lr 0.001	Loss 0.5427 (0.4538)	Prec@(1,5) (87.6%, 98.5%)	
07/04 10:47:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][200/703]	Step 118472	lr 0.001	Loss 0.6755 (0.4586)	Prec@(1,5) (87.3%, 98.4%)	
07/04 10:47:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][250/703]	Step 118522	lr 0.001	Loss 0.5552 (0.4623)	Prec@(1,5) (87.1%, 98.5%)	
07/04 10:47:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][300/703]	Step 118572	lr 0.001	Loss 0.4281 (0.4644)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][350/703]	Step 118622	lr 0.001	Loss 0.2356 (0.4649)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][400/703]	Step 118672	lr 0.001	Loss 0.5461 (0.4633)	Prec@(1,5) (87.1%, 98.5%)	
07/04 10:47:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][450/703]	Step 118722	lr 0.001	Loss 0.4656 (0.4615)	Prec@(1,5) (87.1%, 98.6%)	
07/04 10:47:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][500/703]	Step 118772	lr 0.001	Loss 0.4757 (0.4612)	Prec@(1,5) (87.1%, 98.6%)	
07/04 10:47:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][550/703]	Step 118822	lr 0.001	Loss 0.4837 (0.4608)	Prec@(1,5) (87.1%, 98.5%)	
07/04 10:47:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][600/703]	Step 118872	lr 0.001	Loss 0.4712 (0.4614)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][650/703]	Step 118922	lr 0.001	Loss 0.4298 (0.4621)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][700/703]	Step 118972	lr 0.001	Loss 0.6150 (0.4621)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [168][703/703]	Step 118975	lr 0.001	Loss 0.3241 (0.4618)	Prec@(1,5) (87.0%, 98.5%)	
07/04 10:47:59PM finetuneTeacher_trainer.py:185 [INFO] Train: [168/199] Final Prec@1 87.0178%
07/04 10:48:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [168][50/79]	Step 118976	Loss 1.6038	Prec@(1,5) (58.8%, 84.6%)
07/04 10:48:00PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [168][78/79]	Step 118976	Loss 1.5618	Prec@(1,5) (59.6%, 84.9%)
07/04 10:48:00PM finetuneTeacher_trainer.py:220 [INFO] Valid: [168/199] Final Prec@1 59.6200%
07/04 10:48:00PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:48:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][50/703]	Step 119026	lr 0.001	Loss 0.5019 (0.4451)	Prec@(1,5) (87.5%, 98.8%)	
07/04 10:48:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][100/703]	Step 119076	lr 0.001	Loss 0.4231 (0.4530)	Prec@(1,5) (87.6%, 98.6%)	
07/04 10:48:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][150/703]	Step 119126	lr 0.001	Loss 0.6277 (0.4515)	Prec@(1,5) (87.5%, 98.7%)	
07/04 10:48:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][200/703]	Step 119176	lr 0.001	Loss 0.4809 (0.4552)	Prec@(1,5) (87.4%, 98.5%)	
07/04 10:48:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][250/703]	Step 119226	lr 0.001	Loss 0.4452 (0.4554)	Prec@(1,5) (87.4%, 98.5%)	
07/04 10:48:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][300/703]	Step 119276	lr 0.001	Loss 0.3013 (0.4532)	Prec@(1,5) (87.4%, 98.5%)	
07/04 10:48:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][350/703]	Step 119326	lr 0.001	Loss 0.5136 (0.4532)	Prec@(1,5) (87.4%, 98.5%)	
07/04 10:48:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][400/703]	Step 119376	lr 0.001	Loss 0.3921 (0.4565)	Prec@(1,5) (87.3%, 98.5%)	
07/04 10:48:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][450/703]	Step 119426	lr 0.001	Loss 0.3195 (0.4578)	Prec@(1,5) (87.2%, 98.5%)	
07/04 10:48:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][500/703]	Step 119476	lr 0.001	Loss 0.3483 (0.4577)	Prec@(1,5) (87.3%, 98.5%)	
07/04 10:48:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][550/703]	Step 119526	lr 0.001	Loss 0.5768 (0.4608)	Prec@(1,5) (87.1%, 98.4%)	
07/04 10:48:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][600/703]	Step 119576	lr 0.001	Loss 0.5368 (0.4601)	Prec@(1,5) (87.2%, 98.4%)	
07/04 10:48:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][650/703]	Step 119626	lr 0.001	Loss 0.4378 (0.4609)	Prec@(1,5) (87.2%, 98.4%)	
07/04 10:48:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][700/703]	Step 119676	lr 0.001	Loss 0.5033 (0.4603)	Prec@(1,5) (87.1%, 98.4%)	
07/04 10:48:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [169][703/703]	Step 119679	lr 0.001	Loss 0.4006 (0.4599)	Prec@(1,5) (87.1%, 98.4%)	
07/04 10:48:46PM finetuneTeacher_trainer.py:185 [INFO] Train: [169/199] Final Prec@1 87.1400%
07/04 10:48:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [169][50/79]	Step 119680	Loss 1.5655	Prec@(1,5) (59.8%, 86.0%)
07/04 10:48:47PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [169][78/79]	Step 119680	Loss 1.5810	Prec@(1,5) (59.7%, 85.5%)
07/04 10:48:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [169/199] Final Prec@1 59.7200%
07/04 10:48:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:48:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][50/703]	Step 119730	lr 0.001	Loss 0.5106 (0.4569)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:48:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][100/703]	Step 119780	lr 0.001	Loss 0.4384 (0.4490)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:48:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][150/703]	Step 119830	lr 0.001	Loss 0.4778 (0.4565)	Prec@(1,5) (86.9%, 98.5%)	
07/04 10:49:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][200/703]	Step 119880	lr 0.001	Loss 0.3824 (0.4566)	Prec@(1,5) (87.1%, 98.6%)	
07/04 10:49:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][250/703]	Step 119930	lr 0.001	Loss 0.5564 (0.4513)	Prec@(1,5) (87.3%, 98.6%)	
07/04 10:49:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][300/703]	Step 119980	lr 0.001	Loss 0.3853 (0.4493)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:49:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][350/703]	Step 120030	lr 0.001	Loss 0.3778 (0.4495)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:49:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][400/703]	Step 120080	lr 0.001	Loss 0.4384 (0.4481)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:49:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][450/703]	Step 120130	lr 0.001	Loss 0.3418 (0.4496)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:49:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][500/703]	Step 120180	lr 0.001	Loss 0.4435 (0.4493)	Prec@(1,5) (87.3%, 98.6%)	
07/04 10:49:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][550/703]	Step 120230	lr 0.001	Loss 0.5284 (0.4492)	Prec@(1,5) (87.3%, 98.6%)	
07/04 10:49:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][600/703]	Step 120280	lr 0.001	Loss 0.3161 (0.4507)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:49:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][650/703]	Step 120330	lr 0.001	Loss 0.3370 (0.4505)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:49:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][700/703]	Step 120380	lr 0.001	Loss 0.4705 (0.4507)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:49:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [170][703/703]	Step 120383	lr 0.001	Loss 0.5858 (0.4508)	Prec@(1,5) (87.2%, 98.6%)	
07/04 10:49:33PM finetuneTeacher_trainer.py:185 [INFO] Train: [170/199] Final Prec@1 87.1822%
07/04 10:49:34PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [170][50/79]	Step 120384	Loss 1.5677	Prec@(1,5) (60.2%, 85.3%)
07/04 10:49:35PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [170][78/79]	Step 120384	Loss 1.5756	Prec@(1,5) (60.0%, 85.1%)
07/04 10:49:35PM finetuneTeacher_trainer.py:220 [INFO] Valid: [170/199] Final Prec@1 59.9800%
07/04 10:49:35PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:49:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][50/703]	Step 120434	lr 0.001	Loss 0.4175 (0.4287)	Prec@(1,5) (87.9%, 98.7%)	
07/04 10:49:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][100/703]	Step 120484	lr 0.001	Loss 0.3583 (0.4378)	Prec@(1,5) (87.5%, 98.6%)	
07/04 10:49:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][150/703]	Step 120534	lr 0.001	Loss 0.4647 (0.4358)	Prec@(1,5) (87.7%, 98.7%)	
07/04 10:49:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][200/703]	Step 120584	lr 0.001	Loss 0.3426 (0.4386)	Prec@(1,5) (87.7%, 98.7%)	
07/04 10:49:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][250/703]	Step 120634	lr 0.001	Loss 0.5049 (0.4404)	Prec@(1,5) (87.6%, 98.6%)	
07/04 10:49:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][300/703]	Step 120684	lr 0.001	Loss 0.5249 (0.4406)	Prec@(1,5) (87.6%, 98.6%)	
07/04 10:49:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][350/703]	Step 120734	lr 0.001	Loss 0.4606 (0.4420)	Prec@(1,5) (87.4%, 98.7%)	
07/04 10:50:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][400/703]	Step 120784	lr 0.001	Loss 0.6415 (0.4462)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][450/703]	Step 120834	lr 0.001	Loss 0.3456 (0.4492)	Prec@(1,5) (87.3%, 98.6%)	
07/04 10:50:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][500/703]	Step 120884	lr 0.001	Loss 0.4759 (0.4486)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][550/703]	Step 120934	lr 0.001	Loss 0.4938 (0.4490)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][600/703]	Step 120984	lr 0.001	Loss 0.4582 (0.4480)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][650/703]	Step 121034	lr 0.001	Loss 0.3580 (0.4472)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][700/703]	Step 121084	lr 0.001	Loss 0.4637 (0.4478)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [171][703/703]	Step 121087	lr 0.001	Loss 0.3658 (0.4474)	Prec@(1,5) (87.4%, 98.6%)	
07/04 10:50:21PM finetuneTeacher_trainer.py:185 [INFO] Train: [171/199] Final Prec@1 87.3956%
07/04 10:50:22PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [171][50/79]	Step 121088	Loss 1.5383	Prec@(1,5) (60.0%, 85.4%)
07/04 10:50:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [171][78/79]	Step 121088	Loss 1.5664	Prec@(1,5) (59.7%, 85.3%)
07/04 10:50:23PM finetuneTeacher_trainer.py:220 [INFO] Valid: [171/199] Final Prec@1 59.7600%
07/04 10:50:23PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:50:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][50/703]	Step 121138	lr 0.001	Loss 0.4212 (0.4282)	Prec@(1,5) (88.1%, 98.8%)	
07/04 10:50:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][100/703]	Step 121188	lr 0.001	Loss 0.4195 (0.4335)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:50:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][150/703]	Step 121238	lr 0.001	Loss 0.5802 (0.4361)	Prec@(1,5) (87.8%, 98.7%)	
07/04 10:50:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][200/703]	Step 121288	lr 0.001	Loss 0.4525 (0.4393)	Prec@(1,5) (87.8%, 98.6%)	
07/04 10:50:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][250/703]	Step 121338	lr 0.001	Loss 0.4954 (0.4457)	Prec@(1,5) (87.6%, 98.5%)	
07/04 10:50:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][300/703]	Step 121388	lr 0.001	Loss 0.3718 (0.4404)	Prec@(1,5) (87.7%, 98.5%)	
07/04 10:50:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][350/703]	Step 121438	lr 0.001	Loss 0.5213 (0.4416)	Prec@(1,5) (87.7%, 98.5%)	
07/04 10:50:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][400/703]	Step 121488	lr 0.001	Loss 0.4711 (0.4395)	Prec@(1,5) (87.8%, 98.6%)	
07/04 10:50:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][450/703]	Step 121538	lr 0.001	Loss 0.4946 (0.4403)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:50:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][500/703]	Step 121588	lr 0.001	Loss 0.2477 (0.4402)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:50:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][550/703]	Step 121638	lr 0.001	Loss 0.2861 (0.4405)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:51:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][600/703]	Step 121688	lr 0.001	Loss 0.3283 (0.4398)	Prec@(1,5) (87.7%, 98.7%)	
07/04 10:51:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][650/703]	Step 121738	lr 0.001	Loss 0.5811 (0.4406)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:51:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][700/703]	Step 121788	lr 0.001	Loss 0.4074 (0.4436)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:51:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [172][703/703]	Step 121791	lr 0.001	Loss 0.4149 (0.4433)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:51:07PM finetuneTeacher_trainer.py:185 [INFO] Train: [172/199] Final Prec@1 87.6844%
07/04 10:51:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [172][50/79]	Step 121792	Loss 1.5736	Prec@(1,5) (59.8%, 85.2%)
07/04 10:51:08PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [172][78/79]	Step 121792	Loss 1.5501	Prec@(1,5) (60.7%, 85.3%)
07/04 10:51:08PM finetuneTeacher_trainer.py:220 [INFO] Valid: [172/199] Final Prec@1 60.6800%
07/04 10:51:09PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:51:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][50/703]	Step 121842	lr 0.001	Loss 0.2839 (0.4227)	Prec@(1,5) (87.8%, 98.8%)	
07/04 10:51:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][100/703]	Step 121892	lr 0.001	Loss 0.4483 (0.4136)	Prec@(1,5) (88.1%, 98.9%)	
07/04 10:51:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][150/703]	Step 121942	lr 0.001	Loss 0.4052 (0.4166)	Prec@(1,5) (88.0%, 98.9%)	
07/04 10:51:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][200/703]	Step 121992	lr 0.001	Loss 0.3961 (0.4181)	Prec@(1,5) (87.9%, 98.9%)	
07/04 10:51:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][250/703]	Step 122042	lr 0.001	Loss 0.3984 (0.4199)	Prec@(1,5) (88.0%, 98.8%)	
07/04 10:51:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][300/703]	Step 122092	lr 0.001	Loss 0.6552 (0.4181)	Prec@(1,5) (88.1%, 98.8%)	
07/04 10:51:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][350/703]	Step 122142	lr 0.001	Loss 0.4681 (0.4205)	Prec@(1,5) (88.1%, 98.8%)	
07/04 10:51:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][400/703]	Step 122192	lr 0.001	Loss 0.5150 (0.4219)	Prec@(1,5) (88.1%, 98.8%)	
07/04 10:51:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][450/703]	Step 122242	lr 0.001	Loss 0.3984 (0.4222)	Prec@(1,5) (88.1%, 98.8%)	
07/04 10:51:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][500/703]	Step 122292	lr 0.001	Loss 0.4264 (0.4256)	Prec@(1,5) (88.1%, 98.7%)	
07/04 10:51:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][550/703]	Step 122342	lr 0.001	Loss 0.3657 (0.4289)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:51:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][600/703]	Step 122392	lr 0.001	Loss 0.5778 (0.4308)	Prec@(1,5) (87.9%, 98.7%)	
07/04 10:51:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][650/703]	Step 122442	lr 0.001	Loss 0.4924 (0.4304)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:51:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][700/703]	Step 122492	lr 0.001	Loss 0.4360 (0.4322)	Prec@(1,5) (87.8%, 98.7%)	
07/04 10:51:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [173][703/703]	Step 122495	lr 0.001	Loss 0.4008 (0.4324)	Prec@(1,5) (87.9%, 98.7%)	
07/04 10:51:54PM finetuneTeacher_trainer.py:185 [INFO] Train: [173/199] Final Prec@1 87.8489%
07/04 10:51:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [173][50/79]	Step 122496	Loss 1.5364	Prec@(1,5) (60.3%, 85.7%)
07/04 10:51:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [173][78/79]	Step 122496	Loss 1.5565	Prec@(1,5) (60.3%, 85.5%)
07/04 10:51:55PM finetuneTeacher_trainer.py:220 [INFO] Valid: [173/199] Final Prec@1 60.2400%
07/04 10:51:56PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:51:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][50/703]	Step 122546	lr 0.001	Loss 0.4873 (0.4332)	Prec@(1,5) (87.8%, 98.3%)	
07/04 10:52:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][100/703]	Step 122596	lr 0.001	Loss 0.4260 (0.4240)	Prec@(1,5) (88.2%, 98.6%)	
07/04 10:52:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][150/703]	Step 122646	lr 0.001	Loss 0.4835 (0.4276)	Prec@(1,5) (88.2%, 98.5%)	
07/04 10:52:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][200/703]	Step 122696	lr 0.001	Loss 0.4363 (0.4301)	Prec@(1,5) (88.2%, 98.5%)	
07/04 10:52:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][250/703]	Step 122746	lr 0.001	Loss 0.4230 (0.4329)	Prec@(1,5) (88.0%, 98.5%)	
07/04 10:52:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][300/703]	Step 122796	lr 0.001	Loss 0.4711 (0.4331)	Prec@(1,5) (88.0%, 98.5%)	
07/04 10:52:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][350/703]	Step 122846	lr 0.001	Loss 0.4410 (0.4344)	Prec@(1,5) (87.9%, 98.5%)	
07/04 10:52:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][400/703]	Step 122896	lr 0.001	Loss 0.3945 (0.4342)	Prec@(1,5) (87.9%, 98.5%)	
07/04 10:52:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][450/703]	Step 122946	lr 0.001	Loss 0.4695 (0.4325)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:52:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][500/703]	Step 122996	lr 0.001	Loss 0.3921 (0.4326)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:52:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][550/703]	Step 123046	lr 0.001	Loss 0.3905 (0.4336)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:52:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][600/703]	Step 123096	lr 0.001	Loss 0.3273 (0.4344)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:52:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][650/703]	Step 123146	lr 0.001	Loss 0.4744 (0.4351)	Prec@(1,5) (87.8%, 98.6%)	
07/04 10:52:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][700/703]	Step 123196	lr 0.001	Loss 0.5017 (0.4347)	Prec@(1,5) (87.8%, 98.6%)	
07/04 10:52:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [174][703/703]	Step 123199	lr 0.001	Loss 0.4481 (0.4344)	Prec@(1,5) (87.8%, 98.6%)	
07/04 10:52:40PM finetuneTeacher_trainer.py:185 [INFO] Train: [174/199] Final Prec@1 87.8333%
07/04 10:52:41PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [174][50/79]	Step 123200	Loss 1.5340	Prec@(1,5) (60.9%, 85.7%)
07/04 10:52:41PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [174][78/79]	Step 123200	Loss 1.5546	Prec@(1,5) (60.4%, 85.4%)
07/04 10:52:42PM finetuneTeacher_trainer.py:220 [INFO] Valid: [174/199] Final Prec@1 60.4400%
07/04 10:52:42PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:52:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][50/703]	Step 123250	lr 0.001	Loss 0.4824 (0.4118)	Prec@(1,5) (88.5%, 98.7%)	
07/04 10:52:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][100/703]	Step 123300	lr 0.001	Loss 0.4240 (0.4263)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:52:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][150/703]	Step 123350	lr 0.001	Loss 0.5069 (0.4285)	Prec@(1,5) (88.1%, 98.6%)	
07/04 10:52:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][200/703]	Step 123400	lr 0.001	Loss 0.6091 (0.4333)	Prec@(1,5) (87.7%, 98.6%)	
07/04 10:52:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][250/703]	Step 123450	lr 0.001	Loss 0.4189 (0.4327)	Prec@(1,5) (87.8%, 98.6%)	
07/04 10:53:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][300/703]	Step 123500	lr 0.001	Loss 0.4002 (0.4313)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:53:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][350/703]	Step 123550	lr 0.001	Loss 0.3836 (0.4309)	Prec@(1,5) (88.0%, 98.6%)	
07/04 10:53:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][400/703]	Step 123600	lr 0.001	Loss 0.4318 (0.4296)	Prec@(1,5) (88.0%, 98.6%)	
07/04 10:53:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][450/703]	Step 123650	lr 0.001	Loss 0.4167 (0.4284)	Prec@(1,5) (88.0%, 98.6%)	
07/04 10:53:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][500/703]	Step 123700	lr 0.001	Loss 0.3150 (0.4286)	Prec@(1,5) (88.0%, 98.6%)	
07/04 10:53:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][550/703]	Step 123750	lr 0.001	Loss 0.3384 (0.4293)	Prec@(1,5) (87.9%, 98.7%)	
07/04 10:53:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][600/703]	Step 123800	lr 0.001	Loss 0.3895 (0.4301)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:53:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][650/703]	Step 123850	lr 0.001	Loss 0.4813 (0.4302)	Prec@(1,5) (87.9%, 98.7%)	
07/04 10:53:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][700/703]	Step 123900	lr 0.001	Loss 0.5405 (0.4313)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:53:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [175][703/703]	Step 123903	lr 0.001	Loss 0.3365 (0.4314)	Prec@(1,5) (87.9%, 98.6%)	
07/04 10:53:28PM finetuneTeacher_trainer.py:185 [INFO] Train: [175/199] Final Prec@1 87.8756%
07/04 10:53:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [175][50/79]	Step 123904	Loss 1.5059	Prec@(1,5) (61.3%, 86.6%)
07/04 10:53:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [175][78/79]	Step 123904	Loss 1.5347	Prec@(1,5) (60.7%, 86.4%)
07/04 10:53:30PM finetuneTeacher_trainer.py:220 [INFO] Valid: [175/199] Final Prec@1 60.6400%
07/04 10:53:30PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:53:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][50/703]	Step 123954	lr 0.001	Loss 0.4258 (0.4130)	Prec@(1,5) (88.9%, 98.9%)	
07/04 10:53:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][100/703]	Step 124004	lr 0.001	Loss 0.3930 (0.4295)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:53:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][150/703]	Step 124054	lr 0.001	Loss 0.4191 (0.4286)	Prec@(1,5) (88.3%, 98.7%)	
07/04 10:53:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][200/703]	Step 124104	lr 0.001	Loss 0.3205 (0.4275)	Prec@(1,5) (88.2%, 98.6%)	
07/04 10:53:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][250/703]	Step 124154	lr 0.001	Loss 0.4194 (0.4270)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:53:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][300/703]	Step 124204	lr 0.001	Loss 0.3249 (0.4276)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:53:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][350/703]	Step 124254	lr 0.001	Loss 0.3592 (0.4281)	Prec@(1,5) (88.1%, 98.7%)	
07/04 10:53:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][400/703]	Step 124304	lr 0.001	Loss 0.2714 (0.4277)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:54:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][450/703]	Step 124354	lr 0.001	Loss 0.3363 (0.4251)	Prec@(1,5) (88.1%, 98.7%)	
07/04 10:54:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][500/703]	Step 124404	lr 0.001	Loss 0.4490 (0.4284)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:54:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][550/703]	Step 124454	lr 0.001	Loss 0.4037 (0.4274)	Prec@(1,5) (88.1%, 98.7%)	
07/04 10:54:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][600/703]	Step 124504	lr 0.001	Loss 0.6028 (0.4269)	Prec@(1,5) (88.1%, 98.7%)	
07/04 10:54:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][650/703]	Step 124554	lr 0.001	Loss 0.2203 (0.4275)	Prec@(1,5) (88.1%, 98.7%)	
07/04 10:54:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][700/703]	Step 124604	lr 0.001	Loss 0.5215 (0.4285)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:54:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [176][703/703]	Step 124607	lr 0.001	Loss 0.4017 (0.4284)	Prec@(1,5) (88.0%, 98.7%)	
07/04 10:54:16PM finetuneTeacher_trainer.py:185 [INFO] Train: [176/199] Final Prec@1 88.0244%
07/04 10:54:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [176][50/79]	Step 124608	Loss 1.6022	Prec@(1,5) (59.5%, 85.1%)
07/04 10:54:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [176][78/79]	Step 124608	Loss 1.5724	Prec@(1,5) (60.0%, 85.4%)
07/04 10:54:18PM finetuneTeacher_trainer.py:220 [INFO] Valid: [176/199] Final Prec@1 59.9800%
07/04 10:54:18PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:54:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][50/703]	Step 124658	lr 0.001	Loss 0.5727 (0.4226)	Prec@(1,5) (88.7%, 98.5%)	
07/04 10:54:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][100/703]	Step 124708	lr 0.001	Loss 0.4539 (0.4093)	Prec@(1,5) (89.2%, 98.7%)	
07/04 10:54:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][150/703]	Step 124758	lr 0.001	Loss 0.4078 (0.4132)	Prec@(1,5) (88.8%, 98.7%)	
07/04 10:54:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][200/703]	Step 124808	lr 0.001	Loss 0.4010 (0.4136)	Prec@(1,5) (88.7%, 98.7%)	
07/04 10:54:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][250/703]	Step 124858	lr 0.001	Loss 0.5410 (0.4153)	Prec@(1,5) (88.7%, 98.7%)	
07/04 10:54:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][300/703]	Step 124908	lr 0.001	Loss 0.5469 (0.4144)	Prec@(1,5) (88.7%, 98.7%)	
07/04 10:54:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][350/703]	Step 124958	lr 0.001	Loss 0.5520 (0.4144)	Prec@(1,5) (88.6%, 98.7%)	
07/04 10:54:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][400/703]	Step 125008	lr 0.001	Loss 0.3393 (0.4135)	Prec@(1,5) (88.6%, 98.7%)	
07/04 10:54:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][450/703]	Step 125058	lr 0.001	Loss 0.3428 (0.4161)	Prec@(1,5) (88.5%, 98.7%)	
07/04 10:54:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][500/703]	Step 125108	lr 0.001	Loss 0.3523 (0.4166)	Prec@(1,5) (88.5%, 98.7%)	
07/04 10:54:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][550/703]	Step 125158	lr 0.001	Loss 0.3794 (0.4178)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:54:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][600/703]	Step 125208	lr 0.001	Loss 0.4309 (0.4165)	Prec@(1,5) (88.5%, 98.7%)	
07/04 10:54:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][650/703]	Step 125258	lr 0.001	Loss 0.5293 (0.4191)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:55:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][700/703]	Step 125308	lr 0.001	Loss 0.5324 (0.4188)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:55:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [177][703/703]	Step 125311	lr 0.001	Loss 0.3388 (0.4188)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:55:01PM finetuneTeacher_trainer.py:185 [INFO] Train: [177/199] Final Prec@1 88.3933%
07/04 10:55:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [177][50/79]	Step 125312	Loss 1.6058	Prec@(1,5) (58.9%, 85.7%)
07/04 10:55:02PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [177][78/79]	Step 125312	Loss 1.5887	Prec@(1,5) (59.3%, 85.7%)
07/04 10:55:02PM finetuneTeacher_trainer.py:220 [INFO] Valid: [177/199] Final Prec@1 59.2400%
07/04 10:55:02PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:55:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][50/703]	Step 125362	lr 0.001	Loss 0.3428 (0.4250)	Prec@(1,5) (88.6%, 98.4%)	
07/04 10:55:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][100/703]	Step 125412	lr 0.001	Loss 0.3564 (0.4175)	Prec@(1,5) (88.5%, 98.4%)	
07/04 10:55:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][150/703]	Step 125462	lr 0.001	Loss 0.3643 (0.4067)	Prec@(1,5) (88.8%, 98.6%)	
07/04 10:55:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][200/703]	Step 125512	lr 0.001	Loss 0.2933 (0.4142)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:55:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][250/703]	Step 125562	lr 0.001	Loss 0.5527 (0.4171)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:55:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][300/703]	Step 125612	lr 0.001	Loss 0.4249 (0.4162)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:55:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][350/703]	Step 125662	lr 0.001	Loss 0.2341 (0.4170)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:55:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][400/703]	Step 125712	lr 0.001	Loss 0.3805 (0.4175)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:55:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][450/703]	Step 125762	lr 0.001	Loss 0.4052 (0.4165)	Prec@(1,5) (88.5%, 98.6%)	
07/04 10:55:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][500/703]	Step 125812	lr 0.001	Loss 0.4890 (0.4175)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:55:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][550/703]	Step 125862	lr 0.001	Loss 0.3969 (0.4184)	Prec@(1,5) (88.3%, 98.7%)	
07/04 10:55:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][600/703]	Step 125912	lr 0.001	Loss 0.2277 (0.4201)	Prec@(1,5) (88.3%, 98.6%)	
07/04 10:55:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][650/703]	Step 125962	lr 0.001	Loss 0.5605 (0.4208)	Prec@(1,5) (88.2%, 98.6%)	
07/04 10:55:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][700/703]	Step 126012	lr 0.001	Loss 0.3494 (0.4210)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:55:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [178][703/703]	Step 126015	lr 0.001	Loss 0.5446 (0.4213)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:55:47PM finetuneTeacher_trainer.py:185 [INFO] Train: [178/199] Final Prec@1 88.1800%
07/04 10:55:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [178][50/79]	Step 126016	Loss 1.5603	Prec@(1,5) (60.5%, 85.1%)
07/04 10:55:48PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [178][78/79]	Step 126016	Loss 1.5899	Prec@(1,5) (60.2%, 84.9%)
07/04 10:55:48PM finetuneTeacher_trainer.py:220 [INFO] Valid: [178/199] Final Prec@1 60.1400%
07/04 10:55:48PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:55:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][50/703]	Step 126066	lr 0.001	Loss 0.4212 (0.3999)	Prec@(1,5) (89.3%, 98.9%)	
07/04 10:55:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][100/703]	Step 126116	lr 0.001	Loss 0.6149 (0.4143)	Prec@(1,5) (88.8%, 98.7%)	
07/04 10:56:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][150/703]	Step 126166	lr 0.001	Loss 0.4266 (0.4134)	Prec@(1,5) (88.8%, 98.7%)	
07/04 10:56:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][200/703]	Step 126216	lr 0.001	Loss 0.4171 (0.4085)	Prec@(1,5) (89.0%, 98.7%)	
07/04 10:56:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][250/703]	Step 126266	lr 0.001	Loss 0.3804 (0.4085)	Prec@(1,5) (88.9%, 98.7%)	
07/04 10:56:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][300/703]	Step 126316	lr 0.001	Loss 0.4559 (0.4121)	Prec@(1,5) (88.7%, 98.8%)	
07/04 10:56:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][350/703]	Step 126366	lr 0.001	Loss 0.2594 (0.4093)	Prec@(1,5) (88.8%, 98.8%)	
07/04 10:56:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][400/703]	Step 126416	lr 0.001	Loss 0.4602 (0.4097)	Prec@(1,5) (88.8%, 98.8%)	
07/04 10:56:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][450/703]	Step 126466	lr 0.001	Loss 0.5871 (0.4133)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:56:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][500/703]	Step 126516	lr 0.001	Loss 0.6741 (0.4162)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:56:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][550/703]	Step 126566	lr 0.001	Loss 0.5054 (0.4175)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:56:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][600/703]	Step 126616	lr 0.001	Loss 0.3854 (0.4165)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:56:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][650/703]	Step 126666	lr 0.001	Loss 0.3781 (0.4169)	Prec@(1,5) (88.4%, 98.8%)	
07/04 10:56:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][700/703]	Step 126716	lr 0.001	Loss 0.3224 (0.4175)	Prec@(1,5) (88.4%, 98.8%)	
07/04 10:56:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [179][703/703]	Step 126719	lr 0.001	Loss 0.4693 (0.4176)	Prec@(1,5) (88.4%, 98.8%)	
07/04 10:56:35PM finetuneTeacher_trainer.py:185 [INFO] Train: [179/199] Final Prec@1 88.3889%
07/04 10:56:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [179][50/79]	Step 126720	Loss 1.6100	Prec@(1,5) (58.9%, 85.4%)
07/04 10:56:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [179][78/79]	Step 126720	Loss 1.5774	Prec@(1,5) (59.3%, 85.6%)
07/04 10:56:36PM finetuneTeacher_trainer.py:220 [INFO] Valid: [179/199] Final Prec@1 59.3600%
07/04 10:56:37PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:56:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][50/703]	Step 126770	lr 0.001	Loss 0.4191 (0.4055)	Prec@(1,5) (88.7%, 98.7%)	
07/04 10:56:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][100/703]	Step 126820	lr 0.001	Loss 0.3561 (0.4094)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:56:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][150/703]	Step 126870	lr 0.001	Loss 0.6408 (0.4110)	Prec@(1,5) (88.6%, 98.7%)	
07/04 10:56:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][200/703]	Step 126920	lr 0.001	Loss 0.5333 (0.4164)	Prec@(1,5) (88.5%, 98.6%)	
07/04 10:56:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][250/703]	Step 126970	lr 0.001	Loss 0.4495 (0.4114)	Prec@(1,5) (88.6%, 98.7%)	
07/04 10:56:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][300/703]	Step 127020	lr 0.001	Loss 0.5067 (0.4165)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:57:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][350/703]	Step 127070	lr 0.001	Loss 0.3744 (0.4190)	Prec@(1,5) (88.3%, 98.6%)	
07/04 10:57:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][400/703]	Step 127120	lr 0.001	Loss 0.2941 (0.4185)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:57:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][450/703]	Step 127170	lr 0.001	Loss 0.3513 (0.4193)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:57:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][500/703]	Step 127220	lr 0.001	Loss 0.4114 (0.4189)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:57:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][550/703]	Step 127270	lr 0.001	Loss 0.5014 (0.4200)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:57:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][600/703]	Step 127320	lr 0.001	Loss 0.4228 (0.4185)	Prec@(1,5) (88.3%, 98.7%)	
07/04 10:57:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][650/703]	Step 127370	lr 0.001	Loss 0.5129 (0.4186)	Prec@(1,5) (88.3%, 98.7%)	
07/04 10:57:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][700/703]	Step 127420	lr 0.001	Loss 0.4067 (0.4198)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:57:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [180][703/703]	Step 127423	lr 0.001	Loss 0.4368 (0.4200)	Prec@(1,5) (88.2%, 98.7%)	
07/04 10:57:22PM finetuneTeacher_trainer.py:185 [INFO] Train: [180/199] Final Prec@1 88.1800%
07/04 10:57:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [180][50/79]	Step 127424	Loss 1.5589	Prec@(1,5) (60.4%, 85.5%)
07/04 10:57:23PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [180][78/79]	Step 127424	Loss 1.5907	Prec@(1,5) (59.8%, 85.1%)
07/04 10:57:23PM finetuneTeacher_trainer.py:220 [INFO] Valid: [180/199] Final Prec@1 59.8200%
07/04 10:57:23PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:57:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][50/703]	Step 127474	lr 0.001	Loss 0.3648 (0.4192)	Prec@(1,5) (88.5%, 98.7%)	
07/04 10:57:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][100/703]	Step 127524	lr 0.001	Loss 0.3319 (0.4073)	Prec@(1,5) (88.7%, 98.8%)	
07/04 10:57:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][150/703]	Step 127574	lr 0.001	Loss 0.5953 (0.4047)	Prec@(1,5) (88.7%, 98.8%)	
07/04 10:57:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][200/703]	Step 127624	lr 0.001	Loss 0.3344 (0.4057)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:57:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][250/703]	Step 127674	lr 0.001	Loss 0.3202 (0.4070)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:57:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][300/703]	Step 127724	lr 0.001	Loss 0.4167 (0.4091)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:57:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][350/703]	Step 127774	lr 0.001	Loss 0.2801 (0.4070)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:57:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][400/703]	Step 127824	lr 0.001	Loss 0.4935 (0.4079)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:57:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][450/703]	Step 127874	lr 0.001	Loss 0.3028 (0.4074)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:57:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][500/703]	Step 127924	lr 0.001	Loss 0.4495 (0.4080)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:57:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][550/703]	Step 127974	lr 0.001	Loss 0.5403 (0.4080)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][600/703]	Step 128024	lr 0.001	Loss 0.5330 (0.4093)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][650/703]	Step 128074	lr 0.001	Loss 0.4168 (0.4108)	Prec@(1,5) (88.4%, 98.8%)	
07/04 10:58:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][700/703]	Step 128124	lr 0.001	Loss 0.4771 (0.4102)	Prec@(1,5) (88.4%, 98.8%)	
07/04 10:58:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [181][703/703]	Step 128127	lr 0.001	Loss 0.3149 (0.4098)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:09PM finetuneTeacher_trainer.py:185 [INFO] Train: [181/199] Final Prec@1 88.4578%
07/04 10:58:09PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [181][50/79]	Step 128128	Loss 1.5836	Prec@(1,5) (59.9%, 85.2%)
07/04 10:58:10PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [181][78/79]	Step 128128	Loss 1.6175	Prec@(1,5) (59.5%, 85.1%)
07/04 10:58:10PM finetuneTeacher_trainer.py:220 [INFO] Valid: [181/199] Final Prec@1 59.5000%
07/04 10:58:10PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:58:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][50/703]	Step 128178	lr 0.001	Loss 0.3923 (0.4171)	Prec@(1,5) (88.2%, 98.5%)	
07/04 10:58:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][100/703]	Step 128228	lr 0.001	Loss 0.3921 (0.4126)	Prec@(1,5) (88.4%, 98.6%)	
07/04 10:58:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][150/703]	Step 128278	lr 0.001	Loss 0.3858 (0.4062)	Prec@(1,5) (88.5%, 98.7%)	
07/04 10:58:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][200/703]	Step 128328	lr 0.001	Loss 0.4436 (0.4086)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:58:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][250/703]	Step 128378	lr 0.001	Loss 0.6943 (0.4124)	Prec@(1,5) (88.3%, 98.7%)	
07/04 10:58:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][300/703]	Step 128428	lr 0.001	Loss 0.4747 (0.4103)	Prec@(1,5) (88.4%, 98.7%)	
07/04 10:58:33PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][350/703]	Step 128478	lr 0.001	Loss 0.4394 (0.4094)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][400/703]	Step 128528	lr 0.001	Loss 0.4178 (0.4079)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][450/703]	Step 128578	lr 0.001	Loss 0.2800 (0.4069)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][500/703]	Step 128628	lr 0.001	Loss 0.3613 (0.4055)	Prec@(1,5) (88.5%, 98.9%)	
07/04 10:58:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][550/703]	Step 128678	lr 0.001	Loss 0.2613 (0.4060)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:58:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][600/703]	Step 128728	lr 0.001	Loss 0.4225 (0.4043)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:58:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][650/703]	Step 128778	lr 0.001	Loss 0.3411 (0.4049)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:58:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][700/703]	Step 128828	lr 0.001	Loss 0.4139 (0.4053)	Prec@(1,5) (88.6%, 98.9%)	
07/04 10:58:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [182][703/703]	Step 128831	lr 0.001	Loss 0.4454 (0.4056)	Prec@(1,5) (88.6%, 98.9%)	
07/04 10:58:56PM finetuneTeacher_trainer.py:185 [INFO] Train: [182/199] Final Prec@1 88.5644%
07/04 10:58:57PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [182][50/79]	Step 128832	Loss 1.5713	Prec@(1,5) (59.7%, 85.3%)
07/04 10:58:57PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [182][78/79]	Step 128832	Loss 1.5734	Prec@(1,5) (59.7%, 85.7%)
07/04 10:58:57PM finetuneTeacher_trainer.py:220 [INFO] Valid: [182/199] Final Prec@1 59.6200%
07/04 10:58:58PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:59:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][50/703]	Step 128882	lr 0.001	Loss 0.3359 (0.3884)	Prec@(1,5) (89.2%, 99.0%)	
07/04 10:59:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][100/703]	Step 128932	lr 0.001	Loss 0.2587 (0.4012)	Prec@(1,5) (89.0%, 98.8%)	
07/04 10:59:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][150/703]	Step 128982	lr 0.001	Loss 0.3110 (0.3920)	Prec@(1,5) (89.2%, 98.9%)	
07/04 10:59:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][200/703]	Step 129032	lr 0.001	Loss 0.2966 (0.4038)	Prec@(1,5) (88.5%, 98.9%)	
07/04 10:59:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][250/703]	Step 129082	lr 0.001	Loss 0.3006 (0.4076)	Prec@(1,5) (88.4%, 98.8%)	
07/04 10:59:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][300/703]	Step 129132	lr 0.001	Loss 0.2953 (0.4062)	Prec@(1,5) (88.5%, 98.8%)	
07/04 10:59:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][350/703]	Step 129182	lr 0.001	Loss 0.3020 (0.4047)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][400/703]	Step 129232	lr 0.001	Loss 0.3376 (0.4037)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][450/703]	Step 129282	lr 0.001	Loss 0.4515 (0.4049)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][500/703]	Step 129332	lr 0.001	Loss 0.4253 (0.4040)	Prec@(1,5) (88.7%, 98.8%)	
07/04 10:59:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][550/703]	Step 129382	lr 0.001	Loss 0.3681 (0.4048)	Prec@(1,5) (88.7%, 98.8%)	
07/04 10:59:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][600/703]	Step 129432	lr 0.001	Loss 0.5208 (0.4050)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][650/703]	Step 129482	lr 0.001	Loss 0.3314 (0.4044)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][700/703]	Step 129532	lr 0.001	Loss 0.3146 (0.4052)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [183][703/703]	Step 129535	lr 0.001	Loss 0.2893 (0.4048)	Prec@(1,5) (88.6%, 98.8%)	
07/04 10:59:43PM finetuneTeacher_trainer.py:185 [INFO] Train: [183/199] Final Prec@1 88.5622%
07/04 10:59:44PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [183][50/79]	Step 129536	Loss 1.5833	Prec@(1,5) (59.2%, 85.8%)
07/04 10:59:45PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [183][78/79]	Step 129536	Loss 1.5727	Prec@(1,5) (59.7%, 85.6%)
07/04 10:59:45PM finetuneTeacher_trainer.py:220 [INFO] Valid: [183/199] Final Prec@1 59.6600%
07/04 10:59:45PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 10:59:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][50/703]	Step 129586	lr 0.001	Loss 0.4496 (0.3773)	Prec@(1,5) (89.4%, 98.8%)	
07/04 10:59:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][100/703]	Step 129636	lr 0.001	Loss 0.3516 (0.3806)	Prec@(1,5) (89.2%, 99.0%)	
07/04 10:59:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][150/703]	Step 129686	lr 0.001	Loss 0.3750 (0.3899)	Prec@(1,5) (89.0%, 99.0%)	
07/04 10:59:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][200/703]	Step 129736	lr 0.001	Loss 0.2741 (0.3903)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:00:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][250/703]	Step 129786	lr 0.001	Loss 0.4568 (0.3925)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:00:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][300/703]	Step 129836	lr 0.001	Loss 0.4826 (0.3943)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:00:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][350/703]	Step 129886	lr 0.001	Loss 0.3080 (0.3931)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:00:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][400/703]	Step 129936	lr 0.001	Loss 0.3517 (0.3958)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:00:14PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][450/703]	Step 129986	lr 0.001	Loss 0.3745 (0.3971)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:00:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][500/703]	Step 130036	lr 0.001	Loss 0.3938 (0.3969)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:00:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][550/703]	Step 130086	lr 0.001	Loss 0.4548 (0.3972)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:00:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][600/703]	Step 130136	lr 0.001	Loss 0.3769 (0.3967)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:00:27PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][650/703]	Step 130186	lr 0.001	Loss 0.6230 (0.3979)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:00:30PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][700/703]	Step 130236	lr 0.001	Loss 0.3781 (0.4004)	Prec@(1,5) (88.8%, 98.8%)	
07/04 11:00:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [184][703/703]	Step 130239	lr 0.001	Loss 0.4508 (0.4004)	Prec@(1,5) (88.8%, 98.8%)	
07/04 11:00:31PM finetuneTeacher_trainer.py:185 [INFO] Train: [184/199] Final Prec@1 88.8133%
07/04 11:00:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [184][50/79]	Step 130240	Loss 1.6042	Prec@(1,5) (59.4%, 84.7%)
07/04 11:00:32PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [184][78/79]	Step 130240	Loss 1.5755	Prec@(1,5) (59.9%, 85.7%)
07/04 11:00:32PM finetuneTeacher_trainer.py:220 [INFO] Valid: [184/199] Final Prec@1 59.8600%
07/04 11:00:32PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 11:00:36PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][50/703]	Step 130290	lr 0.001	Loss 0.3896 (0.3913)	Prec@(1,5) (89.2%, 98.8%)	
07/04 11:00:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][100/703]	Step 130340	lr 0.001	Loss 0.4595 (0.3957)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:00:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][150/703]	Step 130390	lr 0.001	Loss 0.3924 (0.3952)	Prec@(1,5) (88.9%, 99.0%)	
07/04 11:00:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][200/703]	Step 130440	lr 0.001	Loss 0.3022 (0.3924)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:00:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][250/703]	Step 130490	lr 0.001	Loss 0.5045 (0.3956)	Prec@(1,5) (88.7%, 99.0%)	
07/04 11:00:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][300/703]	Step 130540	lr 0.001	Loss 0.5464 (0.3988)	Prec@(1,5) (88.6%, 98.9%)	
07/04 11:00:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][350/703]	Step 130590	lr 0.001	Loss 0.2857 (0.4002)	Prec@(1,5) (88.6%, 98.9%)	
07/04 11:00:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][400/703]	Step 130640	lr 0.001	Loss 0.4728 (0.3975)	Prec@(1,5) (88.7%, 98.9%)	
07/04 11:01:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][450/703]	Step 130690	lr 0.001	Loss 0.4459 (0.3991)	Prec@(1,5) (88.6%, 98.9%)	
07/04 11:01:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][500/703]	Step 130740	lr 0.001	Loss 0.3466 (0.3992)	Prec@(1,5) (88.5%, 98.9%)	
07/04 11:01:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][550/703]	Step 130790	lr 0.001	Loss 0.3208 (0.4002)	Prec@(1,5) (88.5%, 98.8%)	
07/04 11:01:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][600/703]	Step 130840	lr 0.001	Loss 0.5358 (0.4006)	Prec@(1,5) (88.5%, 98.9%)	
07/04 11:01:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][650/703]	Step 130890	lr 0.001	Loss 0.3103 (0.4007)	Prec@(1,5) (88.5%, 98.8%)	
07/04 11:01:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][700/703]	Step 130940	lr 0.001	Loss 0.2829 (0.4020)	Prec@(1,5) (88.4%, 98.8%)	
07/04 11:01:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [185][703/703]	Step 130943	lr 0.001	Loss 0.3197 (0.4020)	Prec@(1,5) (88.4%, 98.8%)	
07/04 11:01:18PM finetuneTeacher_trainer.py:185 [INFO] Train: [185/199] Final Prec@1 88.4333%
07/04 11:01:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [185][50/79]	Step 130944	Loss 1.5859	Prec@(1,5) (60.5%, 85.6%)
07/04 11:01:20PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [185][78/79]	Step 130944	Loss 1.5914	Prec@(1,5) (60.2%, 85.2%)
07/04 11:01:20PM finetuneTeacher_trainer.py:220 [INFO] Valid: [185/199] Final Prec@1 60.1800%
07/04 11:01:20PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.8400%
07/04 11:01:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][50/703]	Step 130994	lr 0.001	Loss 0.3070 (0.3812)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:01:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][100/703]	Step 131044	lr 0.001	Loss 0.2248 (0.3852)	Prec@(1,5) (88.8%, 99.0%)	
07/04 11:01:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][150/703]	Step 131094	lr 0.001	Loss 0.4414 (0.3918)	Prec@(1,5) (88.3%, 99.0%)	
07/04 11:01:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][200/703]	Step 131144	lr 0.001	Loss 0.4895 (0.3906)	Prec@(1,5) (88.5%, 99.0%)	
07/04 11:01:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][250/703]	Step 131194	lr 0.001	Loss 0.4018 (0.3934)	Prec@(1,5) (88.4%, 99.0%)	
07/04 11:01:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][300/703]	Step 131244	lr 0.001	Loss 0.3710 (0.3943)	Prec@(1,5) (88.5%, 99.0%)	
07/04 11:01:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][350/703]	Step 131294	lr 0.001	Loss 0.4429 (0.3948)	Prec@(1,5) (88.5%, 99.0%)	
07/04 11:01:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][400/703]	Step 131344	lr 0.001	Loss 0.5587 (0.3934)	Prec@(1,5) (88.7%, 99.0%)	
07/04 11:01:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][450/703]	Step 131394	lr 0.001	Loss 0.4250 (0.3938)	Prec@(1,5) (88.7%, 98.9%)	
07/04 11:01:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][500/703]	Step 131444	lr 0.001	Loss 0.2688 (0.3937)	Prec@(1,5) (88.7%, 98.9%)	
07/04 11:01:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][550/703]	Step 131494	lr 0.001	Loss 0.2438 (0.3937)	Prec@(1,5) (88.8%, 99.0%)	
07/04 11:01:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][600/703]	Step 131544	lr 0.001	Loss 0.4994 (0.3944)	Prec@(1,5) (88.8%, 98.9%)	
07/04 11:02:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][650/703]	Step 131594	lr 0.001	Loss 0.4618 (0.3942)	Prec@(1,5) (88.8%, 98.9%)	
07/04 11:02:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][700/703]	Step 131644	lr 0.001	Loss 0.4220 (0.3941)	Prec@(1,5) (88.8%, 98.9%)	
07/04 11:02:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [186][703/703]	Step 131647	lr 0.001	Loss 0.4774 (0.3943)	Prec@(1,5) (88.8%, 98.9%)	
07/04 11:02:06PM finetuneTeacher_trainer.py:185 [INFO] Train: [186/199] Final Prec@1 88.7733%
07/04 11:02:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [186][50/79]	Step 131648	Loss 1.5890	Prec@(1,5) (60.6%, 85.7%)
07/04 11:02:07PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [186][78/79]	Step 131648	Loss 1.5884	Prec@(1,5) (60.9%, 85.4%)
07/04 11:02:08PM finetuneTeacher_trainer.py:220 [INFO] Valid: [186/199] Final Prec@1 60.9400%
07/04 11:02:08PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:02:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][50/703]	Step 131698	lr 0.001	Loss 0.3912 (0.3777)	Prec@(1,5) (89.5%, 99.1%)	
07/04 11:02:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][100/703]	Step 131748	lr 0.001	Loss 0.3448 (0.3821)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:02:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][150/703]	Step 131798	lr 0.001	Loss 0.2863 (0.3835)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:02:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][200/703]	Step 131848	lr 0.001	Loss 0.3632 (0.3866)	Prec@(1,5) (89.2%, 99.0%)	
07/04 11:02:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][250/703]	Step 131898	lr 0.001	Loss 0.3496 (0.3874)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:02:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][300/703]	Step 131948	lr 0.001	Loss 0.3457 (0.3860)	Prec@(1,5) (89.1%, 99.0%)	
07/04 11:02:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][350/703]	Step 131998	lr 0.001	Loss 0.4599 (0.3931)	Prec@(1,5) (88.9%, 98.9%)	
07/04 11:02:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][400/703]	Step 132048	lr 0.001	Loss 0.5725 (0.3907)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:02:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][450/703]	Step 132098	lr 0.001	Loss 0.4778 (0.3921)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:02:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][500/703]	Step 132148	lr 0.001	Loss 0.5286 (0.3913)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:02:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][550/703]	Step 132198	lr 0.001	Loss 0.4995 (0.3921)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:02:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][600/703]	Step 132248	lr 0.001	Loss 0.4341 (0.3920)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:02:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][650/703]	Step 132298	lr 0.001	Loss 0.6021 (0.3934)	Prec@(1,5) (89.0%, 98.9%)	
07/04 11:02:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][700/703]	Step 132348	lr 0.001	Loss 0.2702 (0.3937)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:02:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [187][703/703]	Step 132351	lr 0.001	Loss 0.3541 (0.3934)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:02:54PM finetuneTeacher_trainer.py:185 [INFO] Train: [187/199] Final Prec@1 89.0533%
07/04 11:02:55PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [187][50/79]	Step 132352	Loss 1.5746	Prec@(1,5) (60.6%, 85.6%)
07/04 11:02:56PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [187][78/79]	Step 132352	Loss 1.6071	Prec@(1,5) (59.8%, 85.2%)
07/04 11:02:56PM finetuneTeacher_trainer.py:220 [INFO] Valid: [187/199] Final Prec@1 59.7800%
07/04 11:02:56PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:03:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][50/703]	Step 132402	lr 0.001	Loss 0.3442 (0.3667)	Prec@(1,5) (90.5%, 99.0%)	
07/04 11:03:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][100/703]	Step 132452	lr 0.001	Loss 0.3334 (0.3753)	Prec@(1,5) (89.8%, 98.9%)	
07/04 11:03:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][150/703]	Step 132502	lr 0.001	Loss 0.3424 (0.3797)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:03:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][200/703]	Step 132552	lr 0.001	Loss 0.2022 (0.3753)	Prec@(1,5) (89.6%, 98.9%)	
07/04 11:03:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][250/703]	Step 132602	lr 0.001	Loss 0.3791 (0.3763)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:03:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][300/703]	Step 132652	lr 0.001	Loss 0.4188 (0.3769)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:03:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][350/703]	Step 132702	lr 0.001	Loss 0.2472 (0.3781)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:03:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][400/703]	Step 132752	lr 0.001	Loss 0.3162 (0.3802)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:03:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][450/703]	Step 132802	lr 0.001	Loss 0.2737 (0.3800)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:03:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][500/703]	Step 132852	lr 0.001	Loss 0.3802 (0.3787)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:03:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][550/703]	Step 132902	lr 0.001	Loss 0.2725 (0.3823)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:03:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][600/703]	Step 132952	lr 0.001	Loss 0.4766 (0.3829)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:03:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][650/703]	Step 133002	lr 0.001	Loss 0.3708 (0.3837)	Prec@(1,5) (89.2%, 99.0%)	
07/04 11:03:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][700/703]	Step 133052	lr 0.001	Loss 0.3312 (0.3838)	Prec@(1,5) (89.2%, 99.0%)	
07/04 11:03:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [188][703/703]	Step 133055	lr 0.001	Loss 0.4065 (0.3838)	Prec@(1,5) (89.2%, 99.0%)	
07/04 11:03:42PM finetuneTeacher_trainer.py:185 [INFO] Train: [188/199] Final Prec@1 89.1778%
07/04 11:03:43PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [188][50/79]	Step 133056	Loss 1.6230	Prec@(1,5) (59.3%, 84.9%)
07/04 11:03:43PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [188][78/79]	Step 133056	Loss 1.6188	Prec@(1,5) (59.4%, 85.1%)
07/04 11:03:43PM finetuneTeacher_trainer.py:220 [INFO] Valid: [188/199] Final Prec@1 59.4600%
07/04 11:03:43PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:03:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][50/703]	Step 133106	lr 0.001	Loss 0.2171 (0.3894)	Prec@(1,5) (89.5%, 98.8%)	
07/04 11:03:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][100/703]	Step 133156	lr 0.001	Loss 0.3792 (0.3890)	Prec@(1,5) (89.4%, 98.8%)	
07/04 11:03:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][150/703]	Step 133206	lr 0.001	Loss 0.4744 (0.3830)	Prec@(1,5) (89.6%, 98.8%)	
07/04 11:03:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][200/703]	Step 133256	lr 0.001	Loss 0.3006 (0.3837)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:04:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][250/703]	Step 133306	lr 0.001	Loss 0.3479 (0.3839)	Prec@(1,5) (89.4%, 98.8%)	
07/04 11:04:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][300/703]	Step 133356	lr 0.001	Loss 0.4784 (0.3840)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:04:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][350/703]	Step 133406	lr 0.001	Loss 0.3875 (0.3863)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:04:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][400/703]	Step 133456	lr 0.001	Loss 0.2146 (0.3850)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:04:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][450/703]	Step 133506	lr 0.001	Loss 0.2298 (0.3837)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:04:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][500/703]	Step 133556	lr 0.001	Loss 0.5961 (0.3848)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:04:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][550/703]	Step 133606	lr 0.001	Loss 0.3048 (0.3862)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:04:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][600/703]	Step 133656	lr 0.001	Loss 0.4446 (0.3857)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:04:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][650/703]	Step 133706	lr 0.001	Loss 0.4404 (0.3850)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:04:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][700/703]	Step 133756	lr 0.001	Loss 0.2959 (0.3863)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:04:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [189][703/703]	Step 133759	lr 0.001	Loss 0.2747 (0.3861)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:04:29PM finetuneTeacher_trainer.py:185 [INFO] Train: [189/199] Final Prec@1 89.1756%
07/04 11:04:29PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [189][50/79]	Step 133760	Loss 1.5791	Prec@(1,5) (60.3%, 85.5%)
07/04 11:04:30PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [189][78/79]	Step 133760	Loss 1.6004	Prec@(1,5) (59.8%, 85.3%)
07/04 11:04:30PM finetuneTeacher_trainer.py:220 [INFO] Valid: [189/199] Final Prec@1 59.8600%
07/04 11:04:30PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:04:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][50/703]	Step 133810	lr 0.001	Loss 0.4726 (0.3674)	Prec@(1,5) (89.6%, 98.9%)	
07/04 11:04:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][100/703]	Step 133860	lr 0.001	Loss 0.3989 (0.3692)	Prec@(1,5) (89.6%, 99.0%)	
07/04 11:04:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][150/703]	Step 133910	lr 0.001	Loss 0.3743 (0.3721)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:04:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][200/703]	Step 133960	lr 0.001	Loss 0.3104 (0.3701)	Prec@(1,5) (89.8%, 99.0%)	
07/04 11:04:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][250/703]	Step 134010	lr 0.001	Loss 0.5014 (0.3753)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:04:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][300/703]	Step 134060	lr 0.001	Loss 0.4248 (0.3756)	Prec@(1,5) (89.6%, 99.0%)	
07/04 11:04:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][350/703]	Step 134110	lr 0.001	Loss 0.3584 (0.3772)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:04:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][400/703]	Step 134160	lr 0.001	Loss 0.3677 (0.3784)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:05:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][450/703]	Step 134210	lr 0.001	Loss 0.3262 (0.3785)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:05:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][500/703]	Step 134260	lr 0.001	Loss 0.6153 (0.3807)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:05:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][550/703]	Step 134310	lr 0.001	Loss 0.4226 (0.3820)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:05:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][600/703]	Step 134360	lr 0.001	Loss 0.3600 (0.3839)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:05:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][650/703]	Step 134410	lr 0.001	Loss 0.4013 (0.3853)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:05:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][700/703]	Step 134460	lr 0.001	Loss 0.3440 (0.3868)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:05:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [190][703/703]	Step 134463	lr 0.001	Loss 0.4723 (0.3866)	Prec@(1,5) (89.1%, 98.9%)	
07/04 11:05:16PM finetuneTeacher_trainer.py:185 [INFO] Train: [190/199] Final Prec@1 89.1111%
07/04 11:05:17PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [190][50/79]	Step 134464	Loss 1.5866	Prec@(1,5) (60.5%, 85.5%)
07/04 11:05:18PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [190][78/79]	Step 134464	Loss 1.5759	Prec@(1,5) (60.5%, 85.8%)
07/04 11:05:18PM finetuneTeacher_trainer.py:220 [INFO] Valid: [190/199] Final Prec@1 60.5400%
07/04 11:05:18PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:05:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][50/703]	Step 134514	lr 0.001	Loss 0.4775 (0.3841)	Prec@(1,5) (89.7%, 98.9%)	
07/04 11:05:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][100/703]	Step 134564	lr 0.001	Loss 0.4053 (0.3787)	Prec@(1,5) (89.8%, 98.8%)	
07/04 11:05:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][150/703]	Step 134614	lr 0.001	Loss 0.3721 (0.3793)	Prec@(1,5) (89.7%, 98.9%)	
07/04 11:05:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][200/703]	Step 134664	lr 0.001	Loss 0.2038 (0.3786)	Prec@(1,5) (89.8%, 98.9%)	
07/04 11:05:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][250/703]	Step 134714	lr 0.001	Loss 0.4057 (0.3727)	Prec@(1,5) (89.9%, 98.9%)	
07/04 11:05:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][300/703]	Step 134764	lr 0.001	Loss 0.4060 (0.3760)	Prec@(1,5) (89.8%, 98.9%)	
07/04 11:05:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][350/703]	Step 134814	lr 0.001	Loss 0.2308 (0.3738)	Prec@(1,5) (89.8%, 99.0%)	
07/04 11:05:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][400/703]	Step 134864	lr 0.001	Loss 0.2707 (0.3772)	Prec@(1,5) (89.7%, 98.9%)	
07/04 11:05:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][450/703]	Step 134914	lr 0.001	Loss 0.5251 (0.3768)	Prec@(1,5) (89.6%, 98.9%)	
07/04 11:05:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][500/703]	Step 134964	lr 0.001	Loss 0.2554 (0.3766)	Prec@(1,5) (89.6%, 99.0%)	
07/04 11:05:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][550/703]	Step 135014	lr 0.001	Loss 0.3716 (0.3778)	Prec@(1,5) (89.5%, 99.0%)	
07/04 11:05:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][600/703]	Step 135064	lr 0.001	Loss 0.6177 (0.3792)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:06:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][650/703]	Step 135114	lr 0.001	Loss 0.4173 (0.3793)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:06:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][700/703]	Step 135164	lr 0.001	Loss 0.3863 (0.3789)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:06:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [191][703/703]	Step 135167	lr 0.001	Loss 0.3329 (0.3788)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:06:04PM finetuneTeacher_trainer.py:185 [INFO] Train: [191/199] Final Prec@1 89.4156%
07/04 11:06:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [191][50/79]	Step 135168	Loss 1.6155	Prec@(1,5) (59.6%, 85.0%)
07/04 11:06:05PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [191][78/79]	Step 135168	Loss 1.6085	Prec@(1,5) (60.2%, 84.9%)
07/04 11:06:05PM finetuneTeacher_trainer.py:220 [INFO] Valid: [191/199] Final Prec@1 60.2600%
07/04 11:06:05PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:06:09PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][50/703]	Step 135218	lr 0.001	Loss 0.2667 (0.3833)	Prec@(1,5) (89.2%, 98.8%)	
07/04 11:06:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][100/703]	Step 135268	lr 0.001	Loss 0.3261 (0.3846)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:06:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][150/703]	Step 135318	lr 0.001	Loss 0.3877 (0.3770)	Prec@(1,5) (89.6%, 98.9%)	
07/04 11:06:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][200/703]	Step 135368	lr 0.001	Loss 0.5473 (0.3808)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:06:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][250/703]	Step 135418	lr 0.001	Loss 0.2996 (0.3826)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:06:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][300/703]	Step 135468	lr 0.001	Loss 0.4408 (0.3813)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:06:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][350/703]	Step 135518	lr 0.001	Loss 0.1492 (0.3787)	Prec@(1,5) (89.3%, 99.1%)	
07/04 11:06:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][400/703]	Step 135568	lr 0.001	Loss 0.2640 (0.3779)	Prec@(1,5) (89.4%, 99.1%)	
07/04 11:06:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][450/703]	Step 135618	lr 0.001	Loss 0.3064 (0.3747)	Prec@(1,5) (89.5%, 99.1%)	
07/04 11:06:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][500/703]	Step 135668	lr 0.001	Loss 0.5557 (0.3768)	Prec@(1,5) (89.4%, 99.0%)	
07/04 11:06:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][550/703]	Step 135718	lr 0.001	Loss 0.2251 (0.3758)	Prec@(1,5) (89.5%, 99.0%)	
07/04 11:06:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][600/703]	Step 135768	lr 0.001	Loss 0.5538 (0.3750)	Prec@(1,5) (89.5%, 99.0%)	
07/04 11:06:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][650/703]	Step 135818	lr 0.001	Loss 0.3942 (0.3761)	Prec@(1,5) (89.5%, 99.0%)	
07/04 11:06:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][700/703]	Step 135868	lr 0.001	Loss 0.5407 (0.3794)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:06:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [192][703/703]	Step 135871	lr 0.001	Loss 0.4265 (0.3797)	Prec@(1,5) (89.3%, 99.0%)	
07/04 11:06:49PM finetuneTeacher_trainer.py:185 [INFO] Train: [192/199] Final Prec@1 89.3222%
07/04 11:06:50PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [192][50/79]	Step 135872	Loss 1.5627	Prec@(1,5) (60.7%, 85.0%)
07/04 11:06:51PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [192][78/79]	Step 135872	Loss 1.5781	Prec@(1,5) (60.6%, 84.8%)
07/04 11:06:51PM finetuneTeacher_trainer.py:220 [INFO] Valid: [192/199] Final Prec@1 60.5800%
07/04 11:06:51PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:06:55PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][50/703]	Step 135922	lr 0.001	Loss 0.3129 (0.3466)	Prec@(1,5) (91.0%, 98.9%)	
07/04 11:06:58PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][100/703]	Step 135972	lr 0.001	Loss 0.4045 (0.3609)	Prec@(1,5) (90.1%, 99.0%)	
07/04 11:07:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][150/703]	Step 136022	lr 0.001	Loss 0.3484 (0.3610)	Prec@(1,5) (90.2%, 99.1%)	
07/04 11:07:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][200/703]	Step 136072	lr 0.001	Loss 0.3686 (0.3609)	Prec@(1,5) (90.2%, 99.1%)	
07/04 11:07:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][250/703]	Step 136122	lr 0.001	Loss 0.4428 (0.3646)	Prec@(1,5) (90.1%, 99.0%)	
07/04 11:07:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][300/703]	Step 136172	lr 0.001	Loss 0.2141 (0.3667)	Prec@(1,5) (90.1%, 99.0%)	
07/04 11:07:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][350/703]	Step 136222	lr 0.001	Loss 0.2773 (0.3675)	Prec@(1,5) (90.1%, 99.0%)	
07/04 11:07:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][400/703]	Step 136272	lr 0.001	Loss 0.2601 (0.3664)	Prec@(1,5) (90.1%, 99.0%)	
07/04 11:07:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][450/703]	Step 136322	lr 0.001	Loss 0.2910 (0.3694)	Prec@(1,5) (90.0%, 99.0%)	
07/04 11:07:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][500/703]	Step 136372	lr 0.001	Loss 0.1921 (0.3716)	Prec@(1,5) (89.9%, 98.9%)	
07/04 11:07:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][550/703]	Step 136422	lr 0.001	Loss 0.3147 (0.3709)	Prec@(1,5) (90.0%, 98.9%)	
07/04 11:07:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][600/703]	Step 136472	lr 0.001	Loss 0.2785 (0.3688)	Prec@(1,5) (90.0%, 98.9%)	
07/04 11:07:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][650/703]	Step 136522	lr 0.001	Loss 0.3244 (0.3706)	Prec@(1,5) (89.9%, 98.9%)	
07/04 11:07:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][700/703]	Step 136572	lr 0.001	Loss 0.4439 (0.3724)	Prec@(1,5) (89.9%, 98.9%)	
07/04 11:07:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [193][703/703]	Step 136575	lr 0.001	Loss 0.2447 (0.3721)	Prec@(1,5) (89.9%, 98.9%)	
07/04 11:07:35PM finetuneTeacher_trainer.py:185 [INFO] Train: [193/199] Final Prec@1 89.8711%
07/04 11:07:36PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [193][50/79]	Step 136576	Loss 1.6178	Prec@(1,5) (60.4%, 85.2%)
07/04 11:07:37PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [193][78/79]	Step 136576	Loss 1.6030	Prec@(1,5) (59.8%, 85.4%)
07/04 11:07:37PM finetuneTeacher_trainer.py:220 [INFO] Valid: [193/199] Final Prec@1 59.7800%
07/04 11:07:37PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:07:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][50/703]	Step 136626	lr 0.001	Loss 0.3360 (0.3742)	Prec@(1,5) (89.6%, 98.7%)	
07/04 11:07:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][100/703]	Step 136676	lr 0.001	Loss 0.2870 (0.3746)	Prec@(1,5) (89.6%, 98.9%)	
07/04 11:07:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][150/703]	Step 136726	lr 0.001	Loss 0.4826 (0.3761)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:07:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][200/703]	Step 136776	lr 0.001	Loss 0.2623 (0.3720)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:07:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][250/703]	Step 136826	lr 0.001	Loss 0.3164 (0.3737)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:07:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][300/703]	Step 136876	lr 0.001	Loss 0.2218 (0.3741)	Prec@(1,5) (89.5%, 98.9%)	
07/04 11:08:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][350/703]	Step 136926	lr 0.001	Loss 0.2241 (0.3758)	Prec@(1,5) (89.4%, 98.9%)	
07/04 11:08:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][400/703]	Step 136976	lr 0.001	Loss 0.3252 (0.3807)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:08:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][450/703]	Step 137026	lr 0.001	Loss 0.4860 (0.3829)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:08:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][500/703]	Step 137076	lr 0.001	Loss 0.3817 (0.3821)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:08:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][550/703]	Step 137126	lr 0.001	Loss 0.4709 (0.3812)	Prec@(1,5) (89.3%, 98.9%)	
07/04 11:08:17PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][600/703]	Step 137176	lr 0.001	Loss 0.3111 (0.3813)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:08:20PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][650/703]	Step 137226	lr 0.001	Loss 0.4054 (0.3823)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:08:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][700/703]	Step 137276	lr 0.001	Loss 0.4406 (0.3830)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:08:23PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [194][703/703]	Step 137279	lr 0.001	Loss 0.4143 (0.3834)	Prec@(1,5) (89.2%, 98.9%)	
07/04 11:08:23PM finetuneTeacher_trainer.py:185 [INFO] Train: [194/199] Final Prec@1 89.1622%
07/04 11:08:24PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [194][50/79]	Step 137280	Loss 1.6413	Prec@(1,5) (58.9%, 84.9%)
07/04 11:08:25PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [194][78/79]	Step 137280	Loss 1.5947	Prec@(1,5) (59.7%, 85.5%)
07/04 11:08:25PM finetuneTeacher_trainer.py:220 [INFO] Valid: [194/199] Final Prec@1 59.7600%
07/04 11:08:25PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:08:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][50/703]	Step 137330	lr 0.001	Loss 0.2080 (0.3461)	Prec@(1,5) (90.6%, 99.0%)	
07/04 11:08:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][100/703]	Step 137380	lr 0.001	Loss 0.4124 (0.3473)	Prec@(1,5) (90.6%, 99.1%)	
07/04 11:08:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][150/703]	Step 137430	lr 0.001	Loss 0.3230 (0.3478)	Prec@(1,5) (90.6%, 99.1%)	
07/04 11:08:39PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][200/703]	Step 137480	lr 0.001	Loss 0.3244 (0.3519)	Prec@(1,5) (90.6%, 99.1%)	
07/04 11:08:42PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][250/703]	Step 137530	lr 0.001	Loss 0.3896 (0.3545)	Prec@(1,5) (90.4%, 99.2%)	
07/04 11:08:45PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][300/703]	Step 137580	lr 0.001	Loss 0.4047 (0.3558)	Prec@(1,5) (90.2%, 99.1%)	
07/04 11:08:48PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][350/703]	Step 137630	lr 0.001	Loss 0.2889 (0.3643)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:08:51PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][400/703]	Step 137680	lr 0.001	Loss 0.2221 (0.3637)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:08:54PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][450/703]	Step 137730	lr 0.001	Loss 0.5230 (0.3674)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:08:57PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][500/703]	Step 137780	lr 0.001	Loss 0.4758 (0.3679)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:01PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][550/703]	Step 137830	lr 0.001	Loss 0.3286 (0.3679)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:04PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][600/703]	Step 137880	lr 0.001	Loss 0.3574 (0.3679)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:07PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][650/703]	Step 137930	lr 0.001	Loss 0.3450 (0.3670)	Prec@(1,5) (89.7%, 99.1%)	
07/04 11:09:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][700/703]	Step 137980	lr 0.001	Loss 0.3716 (0.3684)	Prec@(1,5) (89.6%, 99.1%)	
07/04 11:09:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [195][703/703]	Step 137983	lr 0.001	Loss 0.6020 (0.3688)	Prec@(1,5) (89.6%, 99.0%)	
07/04 11:09:10PM finetuneTeacher_trainer.py:185 [INFO] Train: [195/199] Final Prec@1 89.6378%
07/04 11:09:11PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [195][50/79]	Step 137984	Loss 1.5908	Prec@(1,5) (60.2%, 85.5%)
07/04 11:09:12PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [195][78/79]	Step 137984	Loss 1.5881	Prec@(1,5) (59.8%, 85.6%)
07/04 11:09:12PM finetuneTeacher_trainer.py:220 [INFO] Valid: [195/199] Final Prec@1 59.8200%
07/04 11:09:12PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:09:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][50/703]	Step 138034	lr 0.001	Loss 0.2955 (0.3453)	Prec@(1,5) (90.3%, 99.3%)	
07/04 11:09:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][100/703]	Step 138084	lr 0.001	Loss 0.5047 (0.3468)	Prec@(1,5) (90.4%, 99.2%)	
07/04 11:09:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][150/703]	Step 138134	lr 0.001	Loss 0.4123 (0.3565)	Prec@(1,5) (90.2%, 99.2%)	
07/04 11:09:25PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][200/703]	Step 138184	lr 0.001	Loss 0.3740 (0.3569)	Prec@(1,5) (90.1%, 99.2%)	
07/04 11:09:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][250/703]	Step 138234	lr 0.001	Loss 0.4261 (0.3596)	Prec@(1,5) (89.9%, 99.2%)	
07/04 11:09:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][300/703]	Step 138284	lr 0.001	Loss 0.4554 (0.3641)	Prec@(1,5) (89.8%, 99.1%)	
07/04 11:09:35PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][350/703]	Step 138334	lr 0.001	Loss 0.3788 (0.3634)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:09:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][400/703]	Step 138384	lr 0.001	Loss 0.3193 (0.3623)	Prec@(1,5) (90.0%, 99.1%)	
07/04 11:09:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][450/703]	Step 138434	lr 0.001	Loss 0.3159 (0.3624)	Prec@(1,5) (90.0%, 99.1%)	
07/04 11:09:44PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][500/703]	Step 138484	lr 0.001	Loss 0.3110 (0.3656)	Prec@(1,5) (89.8%, 99.1%)	
07/04 11:09:47PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][550/703]	Step 138534	lr 0.001	Loss 0.4466 (0.3689)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][600/703]	Step 138584	lr 0.001	Loss 0.2755 (0.3688)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][650/703]	Step 138634	lr 0.001	Loss 0.3915 (0.3704)	Prec@(1,5) (89.6%, 99.0%)	
07/04 11:09:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][700/703]	Step 138684	lr 0.001	Loss 0.4102 (0.3700)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [196][703/703]	Step 138687	lr 0.001	Loss 0.4267 (0.3702)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:09:57PM finetuneTeacher_trainer.py:185 [INFO] Train: [196/199] Final Prec@1 89.6556%
07/04 11:09:57PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [196][50/79]	Step 138688	Loss 1.6192	Prec@(1,5) (60.5%, 85.2%)
07/04 11:09:58PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [196][78/79]	Step 138688	Loss 1.6108	Prec@(1,5) (60.4%, 85.1%)
07/04 11:09:58PM finetuneTeacher_trainer.py:220 [INFO] Valid: [196/199] Final Prec@1 60.4200%
07/04 11:09:58PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:10:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][50/703]	Step 138738	lr 0.001	Loss 0.4959 (0.3749)	Prec@(1,5) (89.2%, 99.0%)	
07/04 11:10:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][100/703]	Step 138788	lr 0.001	Loss 0.3476 (0.3683)	Prec@(1,5) (89.6%, 99.2%)	
07/04 11:10:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][150/703]	Step 138838	lr 0.001	Loss 0.1421 (0.3621)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:10:12PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][200/703]	Step 138888	lr 0.001	Loss 0.3516 (0.3616)	Prec@(1,5) (90.1%, 99.1%)	
07/04 11:10:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][250/703]	Step 138938	lr 0.001	Loss 0.2801 (0.3610)	Prec@(1,5) (90.0%, 99.1%)	
07/04 11:10:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][300/703]	Step 138988	lr 0.001	Loss 0.2972 (0.3604)	Prec@(1,5) (90.1%, 99.1%)	
07/04 11:10:21PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][350/703]	Step 139038	lr 0.001	Loss 0.4915 (0.3633)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:10:24PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][400/703]	Step 139088	lr 0.001	Loss 0.2863 (0.3626)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:10:28PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][450/703]	Step 139138	lr 0.001	Loss 0.3851 (0.3679)	Prec@(1,5) (89.8%, 99.0%)	
07/04 11:10:31PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][500/703]	Step 139188	lr 0.001	Loss 0.1833 (0.3685)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:10:34PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][550/703]	Step 139238	lr 0.001	Loss 0.3816 (0.3700)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:10:37PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][600/703]	Step 139288	lr 0.001	Loss 0.3177 (0.3700)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:10:40PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][650/703]	Step 139338	lr 0.001	Loss 0.3853 (0.3701)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:10:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][700/703]	Step 139388	lr 0.001	Loss 0.2848 (0.3702)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:10:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [197][703/703]	Step 139391	lr 0.001	Loss 0.2971 (0.3705)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:10:44PM finetuneTeacher_trainer.py:185 [INFO] Train: [197/199] Final Prec@1 89.6956%
07/04 11:10:44PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [197][50/79]	Step 139392	Loss 1.5774	Prec@(1,5) (60.7%, 85.7%)
07/04 11:10:45PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [197][78/79]	Step 139392	Loss 1.5876	Prec@(1,5) (60.6%, 85.5%)
07/04 11:10:45PM finetuneTeacher_trainer.py:220 [INFO] Valid: [197/199] Final Prec@1 60.6000%
07/04 11:10:45PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:10:50PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][50/703]	Step 139442	lr 0.001	Loss 0.3631 (0.3410)	Prec@(1,5) (90.7%, 99.1%)	
07/04 11:10:53PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][100/703]	Step 139492	lr 0.001	Loss 0.4270 (0.3594)	Prec@(1,5) (90.1%, 98.9%)	
07/04 11:10:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][150/703]	Step 139542	lr 0.001	Loss 0.3322 (0.3576)	Prec@(1,5) (90.0%, 98.9%)	
07/04 11:11:00PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][200/703]	Step 139592	lr 0.001	Loss 0.2762 (0.3608)	Prec@(1,5) (89.9%, 99.0%)	
07/04 11:11:03PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][250/703]	Step 139642	lr 0.001	Loss 0.4350 (0.3593)	Prec@(1,5) (89.9%, 99.0%)	
07/04 11:11:06PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][300/703]	Step 139692	lr 0.001	Loss 0.4347 (0.3611)	Prec@(1,5) (89.8%, 99.0%)	
07/04 11:11:10PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][350/703]	Step 139742	lr 0.001	Loss 0.3597 (0.3607)	Prec@(1,5) (89.8%, 99.0%)	
07/04 11:11:13PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][400/703]	Step 139792	lr 0.001	Loss 0.2566 (0.3635)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:16PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][450/703]	Step 139842	lr 0.001	Loss 0.2984 (0.3621)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:19PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][500/703]	Step 139892	lr 0.001	Loss 0.2596 (0.3631)	Prec@(1,5) (89.8%, 99.0%)	
07/04 11:11:22PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][550/703]	Step 139942	lr 0.001	Loss 0.3469 (0.3649)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:26PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][600/703]	Step 139992	lr 0.001	Loss 0.5659 (0.3655)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:29PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][650/703]	Step 140042	lr 0.001	Loss 0.2531 (0.3659)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][700/703]	Step 140092	lr 0.001	Loss 0.3535 (0.3656)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:32PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [198][703/703]	Step 140095	lr 0.001	Loss 0.4560 (0.3655)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:11:32PM finetuneTeacher_trainer.py:185 [INFO] Train: [198/199] Final Prec@1 89.6956%
07/04 11:11:33PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [198][50/79]	Step 140096	Loss 1.6151	Prec@(1,5) (59.3%, 84.6%)
07/04 11:11:34PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [198][78/79]	Step 140096	Loss 1.5982	Prec@(1,5) (59.7%, 85.0%)
07/04 11:11:34PM finetuneTeacher_trainer.py:220 [INFO] Valid: [198/199] Final Prec@1 59.7200%
07/04 11:11:34PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:11:38PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][50/703]	Step 140146	lr 0.001	Loss 0.2788 (0.3382)	Prec@(1,5) (90.2%, 99.2%)	
07/04 11:11:41PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][100/703]	Step 140196	lr 0.001	Loss 0.4618 (0.3493)	Prec@(1,5) (90.2%, 99.2%)	
07/04 11:11:43PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][150/703]	Step 140246	lr 0.001	Loss 0.3450 (0.3556)	Prec@(1,5) (90.1%, 99.1%)	
07/04 11:11:46PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][200/703]	Step 140296	lr 0.001	Loss 0.3427 (0.3576)	Prec@(1,5) (90.0%, 99.1%)	
07/04 11:11:49PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][250/703]	Step 140346	lr 0.001	Loss 0.5298 (0.3576)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:11:52PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][300/703]	Step 140396	lr 0.001	Loss 0.3494 (0.3594)	Prec@(1,5) (89.9%, 99.1%)	
07/04 11:11:56PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][350/703]	Step 140446	lr 0.001	Loss 0.3127 (0.3595)	Prec@(1,5) (89.8%, 99.1%)	
07/04 11:11:59PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][400/703]	Step 140496	lr 0.001	Loss 0.3476 (0.3601)	Prec@(1,5) (89.8%, 99.1%)	
07/04 11:12:02PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][450/703]	Step 140546	lr 0.001	Loss 0.3497 (0.3638)	Prec@(1,5) (89.7%, 99.1%)	
07/04 11:12:05PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][500/703]	Step 140596	lr 0.001	Loss 0.2323 (0.3641)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:12:08PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][550/703]	Step 140646	lr 0.001	Loss 0.2698 (0.3634)	Prec@(1,5) (89.7%, 99.1%)	
07/04 11:12:11PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][600/703]	Step 140696	lr 0.001	Loss 0.2642 (0.3624)	Prec@(1,5) (89.8%, 99.1%)	
07/04 11:12:15PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][650/703]	Step 140746	lr 0.001	Loss 0.2643 (0.3655)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:12:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][700/703]	Step 140796	lr 0.001	Loss 0.5007 (0.3652)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:12:18PM finetuneTeacher_trainer.py:175 [INFO] Train: Epoch: [199][703/703]	Step 140799	lr 0.001	Loss 0.4180 (0.3654)	Prec@(1,5) (89.7%, 99.0%)	
07/04 11:12:18PM finetuneTeacher_trainer.py:185 [INFO] Train: [199/199] Final Prec@1 89.7044%
07/04 11:12:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [199][50/79]	Step 140800	Loss 1.6047	Prec@(1,5) (59.5%, 85.7%)
07/04 11:12:19PM finetuneTeacher_trainer.py:213 [INFO] Valid: Epoch: [199][78/79]	Step 140800	Loss 1.6084	Prec@(1,5) (59.7%, 85.5%)
07/04 11:12:20PM finetuneTeacher_trainer.py:220 [INFO] Valid: [199/199] Final Prec@1 59.6400%
07/04 11:12:20PM finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 60.9400%
07/04 11:12:20PM finetuneTeacher_main.py:56 [INFO] Final best Prec@1 = 60.9400%
