06/26 03:14:40PM parser.py:28 [INFO] 
06/26 03:14:40PM parser.py:29 [INFO] Parameters:
06/26 03:14:40PM parser.py:31 [INFO] BATCH_SIZE=64
06/26 03:14:40PM parser.py:31 [INFO] CUTOUT_LENGTH=0
06/26 03:14:40PM parser.py:31 [INFO] DATA_PATH=../data/
06/26 03:14:40PM parser.py:31 [INFO] DATASET=cifar10
06/26 03:14:40PM parser.py:31 [INFO] EPOCHS=25
06/26 03:14:40PM parser.py:31 [INFO] EXP_NAME=E25-20240626-151440
06/26 03:14:40PM parser.py:31 [INFO] GPUS=[0]
06/26 03:14:40PM parser.py:31 [INFO] LOCAL_RANK=0
06/26 03:14:40PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
06/26 03:14:40PM parser.py:31 [INFO] MODEL_NAME=densenet121
06/26 03:14:40PM parser.py:31 [INFO] NAME=FINETUNE
06/26 03:14:40PM parser.py:31 [INFO] PATH=results/teacher/cifar10/densenet121/FINETUNE/E25-20240626-151440
06/26 03:14:40PM parser.py:31 [INFO] PLOT_PATH=results/teacher/cifar10/densenet121/FINETUNE/E25-20240626-151440/plots
06/26 03:14:40PM parser.py:31 [INFO] PRINT_FREQ=50
06/26 03:14:40PM parser.py:31 [INFO] RESUME_PATH=None
06/26 03:14:40PM parser.py:31 [INFO] SAVE=E25
06/26 03:14:40PM parser.py:31 [INFO] SEED=0
06/26 03:14:40PM parser.py:31 [INFO] TRAIN_PORTION=1.0
06/26 03:14:40PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
06/26 03:14:40PM parser.py:31 [INFO] W_LR=0.025
06/26 03:14:40PM parser.py:31 [INFO] W_LR_MIN=0.001
06/26 03:14:40PM parser.py:31 [INFO] W_MOMENTUM=0.9
06/26 03:14:40PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
06/26 03:14:40PM parser.py:31 [INFO] WORKERS=4
06/26 03:14:40PM parser.py:32 [INFO] 
06/26 03:14:44PM finetuneTeacher_trainer.py:109 [INFO] --> No loaded checkpoint!
06/26 03:14:49PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][50/781]	Step 50	lr 0.025	Loss 1.4316 (1.8914)	Prec@(1,5) (36.2%, 81.1%)	
06/26 03:14:52PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][100/781]	Step 100	lr 0.025	Loss 1.7850 (1.8355)	Prec@(1,5) (43.0%, 86.5%)	
06/26 03:14:55PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][150/781]	Step 150	lr 0.025	Loss 2.1752 (1.9630)	Prec@(1,5) (43.3%, 87.4%)	
06/26 03:14:58PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][200/781]	Step 200	lr 0.025	Loss 1.8639 (1.9224)	Prec@(1,5) (43.6%, 87.8%)	
06/26 03:15:01PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][250/781]	Step 250	lr 0.025	Loss 1.2093 (1.9693)	Prec@(1,5) (44.1%, 88.5%)	
06/26 03:15:04PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][300/781]	Step 300	lr 0.025	Loss 1.2652 (1.9291)	Prec@(1,5) (45.5%, 89.3%)	
06/26 03:15:07PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][350/781]	Step 350	lr 0.025	Loss 2.3099 (1.8923)	Prec@(1,5) (46.5%, 89.9%)	
06/26 03:15:10PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][400/781]	Step 400	lr 0.025	Loss 3.6401 (1.8754)	Prec@(1,5) (47.7%, 90.4%)	
06/26 03:15:13PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][450/781]	Step 450	lr 0.025	Loss 1.4336 (1.8847)	Prec@(1,5) (48.2%, 90.7%)	
06/26 03:15:16PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][500/781]	Step 500	lr 0.025	Loss 1.7295 (1.8505)	Prec@(1,5) (49.0%, 91.0%)	
06/26 03:15:19PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][550/781]	Step 550	lr 0.025	Loss 1.5535 (1.8056)	Prec@(1,5) (50.0%, 91.3%)	
06/26 03:15:22PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][600/781]	Step 600	lr 0.025	Loss 1.6609 (1.7668)	Prec@(1,5) (50.7%, 91.7%)	
06/26 03:15:25PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][650/781]	Step 650	lr 0.025	Loss 1.0864 (1.7338)	Prec@(1,5) (51.3%, 91.8%)	
06/26 03:15:28PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][700/781]	Step 700	lr 0.025	Loss 1.1640 (1.6932)	Prec@(1,5) (52.0%, 92.1%)	
06/26 03:15:31PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][750/781]	Step 750	lr 0.025	Loss 0.9413 (1.6498)	Prec@(1,5) (53.0%, 92.4%)	
06/26 03:15:33PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][781/781]	Step 781	lr 0.025	Loss 1.6022 (1.6246)	Prec@(1,5) (53.5%, 92.5%)	
06/26 03:15:36PM finetuneTeacher_trainer.py:181 [INFO] Train: [  0/24] Final Prec@1 53.4880%
06/26 03:15:36PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][50/391]	Step 782	Loss 1.1051	Prec@(1,5) (65.5%, 96.6%)
06/26 03:15:37PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][100/391]	Step 782	Loss 1.1383	Prec@(1,5) (65.0%, 96.4%)
06/26 03:15:38PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][150/391]	Step 782	Loss 1.1619	Prec@(1,5) (64.6%, 96.2%)
06/26 03:15:38PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][200/391]	Step 782	Loss 1.1559	Prec@(1,5) (65.0%, 96.3%)
06/26 03:15:39PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][250/391]	Step 782	Loss 1.1632	Prec@(1,5) (64.6%, 96.3%)
06/26 03:15:40PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][300/391]	Step 782	Loss 1.1644	Prec@(1,5) (64.6%, 96.4%)
06/26 03:15:41PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][350/391]	Step 782	Loss 1.1609	Prec@(1,5) (64.7%, 96.4%)
06/26 03:15:41PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][390/391]	Step 782	Loss 1.1558	Prec@(1,5) (64.9%, 96.4%)
06/26 03:15:42PM finetuneTeacher_trainer.py:216 [INFO] Valid: [  0/24] Final Prec@1 64.8800%
06/26 03:15:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.8800%
06/26 03:15:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][50/781]	Step 832	lr 0.02491	Loss 0.8993 (0.9982)	Prec@(1,5) (66.1%, 96.6%)	
06/26 03:15:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][100/781]	Step 882	lr 0.02491	Loss 0.7446 (0.9841)	Prec@(1,5) (67.0%, 96.9%)	
06/26 03:15:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][150/781]	Step 932	lr 0.02491	Loss 0.8690 (0.9872)	Prec@(1,5) (66.6%, 96.9%)	
06/26 03:15:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][200/781]	Step 982	lr 0.02491	Loss 1.0573 (1.0048)	Prec@(1,5) (66.4%, 96.9%)	
06/26 03:15:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][250/781]	Step 1032	lr 0.02491	Loss 1.2959 (1.0002)	Prec@(1,5) (66.6%, 97.0%)	
06/26 03:16:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][300/781]	Step 1082	lr 0.02491	Loss 1.1794 (0.9824)	Prec@(1,5) (67.1%, 97.1%)	
06/26 03:16:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][350/781]	Step 1132	lr 0.02491	Loss 0.9851 (0.9882)	Prec@(1,5) (67.0%, 97.0%)	
06/26 03:16:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][400/781]	Step 1182	lr 0.02491	Loss 0.5983 (0.9818)	Prec@(1,5) (67.3%, 97.0%)	
06/26 03:16:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][450/781]	Step 1232	lr 0.02491	Loss 0.9214 (0.9749)	Prec@(1,5) (67.5%, 97.1%)	
06/26 03:16:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][500/781]	Step 1282	lr 0.02491	Loss 0.8023 (0.9679)	Prec@(1,5) (67.8%, 97.1%)	
06/26 03:16:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][550/781]	Step 1332	lr 0.02491	Loss 0.8442 (0.9518)	Prec@(1,5) (68.3%, 97.2%)	
06/26 03:16:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][600/781]	Step 1382	lr 0.02491	Loss 0.6556 (0.9397)	Prec@(1,5) (68.6%, 97.2%)	
06/26 03:16:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][650/781]	Step 1432	lr 0.02491	Loss 0.7801 (0.9325)	Prec@(1,5) (68.8%, 97.3%)	
06/26 03:16:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][700/781]	Step 1482	lr 0.02491	Loss 0.9625 (0.9252)	Prec@(1,5) (69.0%, 97.3%)	
06/26 03:16:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][750/781]	Step 1532	lr 0.02491	Loss 0.6089 (0.9196)	Prec@(1,5) (69.2%, 97.4%)	
06/26 03:16:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][781/781]	Step 1563	lr 0.02491	Loss 0.8698 (0.9155)	Prec@(1,5) (69.3%, 97.4%)	
06/26 03:16:30午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  1/24] Final Prec@1 69.3060%
06/26 03:16:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][50/391]	Step 1564	Loss 0.8669	Prec@(1,5) (70.9%, 98.2%)
06/26 03:16:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][100/391]	Step 1564	Loss 0.8317	Prec@(1,5) (72.3%, 98.0%)
06/26 03:16:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][150/391]	Step 1564	Loss 0.8325	Prec@(1,5) (72.1%, 98.1%)
06/26 03:16:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][200/391]	Step 1564	Loss 0.8344	Prec@(1,5) (72.3%, 98.0%)
06/26 03:16:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][250/391]	Step 1564	Loss 0.8285	Prec@(1,5) (72.4%, 97.9%)
06/26 03:16:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][300/391]	Step 1564	Loss 0.8308	Prec@(1,5) (72.1%, 97.9%)
06/26 03:16:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][350/391]	Step 1564	Loss 0.8323	Prec@(1,5) (72.0%, 97.9%)
06/26 03:16:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][390/391]	Step 1564	Loss 0.8297	Prec@(1,5) (72.1%, 97.9%)
06/26 03:16:35午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  1/24] Final Prec@1 72.0920%
06/26 03:16:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 72.0920%
06/26 03:16:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][50/781]	Step 1614	lr 0.02462	Loss 0.7587 (0.7975)	Prec@(1,5) (73.8%, 97.7%)	
06/26 03:16:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][100/781]	Step 1664	lr 0.02462	Loss 0.8003 (0.7990)	Prec@(1,5) (73.6%, 98.0%)	
06/26 03:16:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][150/781]	Step 1714	lr 0.02462	Loss 0.5965 (0.7783)	Prec@(1,5) (73.9%, 98.1%)	
06/26 03:16:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][200/781]	Step 1764	lr 0.02462	Loss 0.6867 (0.7774)	Prec@(1,5) (73.7%, 98.1%)	
06/26 03:16:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][250/781]	Step 1814	lr 0.02462	Loss 0.7961 (0.7676)	Prec@(1,5) (73.9%, 98.1%)	
06/26 03:16:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][300/781]	Step 1864	lr 0.02462	Loss 0.8242 (0.7601)	Prec@(1,5) (74.2%, 98.2%)	
06/26 03:16:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][350/781]	Step 1914	lr 0.02462	Loss 0.8141 (0.7581)	Prec@(1,5) (74.3%, 98.2%)	
06/26 03:17:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][400/781]	Step 1964	lr 0.02462	Loss 0.7387 (0.7527)	Prec@(1,5) (74.5%, 98.2%)	
06/26 03:17:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][450/781]	Step 2014	lr 0.02462	Loss 0.5017 (0.7449)	Prec@(1,5) (74.7%, 98.3%)	
06/26 03:17:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][500/781]	Step 2064	lr 0.02462	Loss 0.5029 (0.7433)	Prec@(1,5) (74.7%, 98.3%)	
06/26 03:17:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][550/781]	Step 2114	lr 0.02462	Loss 0.6912 (0.7390)	Prec@(1,5) (74.8%, 98.3%)	
06/26 03:17:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][600/781]	Step 2164	lr 0.02462	Loss 0.5954 (0.7366)	Prec@(1,5) (74.9%, 98.3%)	
06/26 03:17:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][650/781]	Step 2214	lr 0.02462	Loss 0.6279 (0.7354)	Prec@(1,5) (75.0%, 98.3%)	
06/26 03:17:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][700/781]	Step 2264	lr 0.02462	Loss 0.6077 (0.7383)	Prec@(1,5) (75.0%, 98.3%)	
06/26 03:17:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][750/781]	Step 2314	lr 0.02462	Loss 0.8236 (0.7361)	Prec@(1,5) (75.0%, 98.3%)	
06/26 03:17:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][781/781]	Step 2345	lr 0.02462	Loss 0.4850 (0.7351)	Prec@(1,5) (75.0%, 98.3%)	
06/26 03:17:24午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  2/24] Final Prec@1 75.0400%
06/26 03:17:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][50/391]	Step 2346	Loss 0.8317	Prec@(1,5) (72.5%, 97.7%)
06/26 03:17:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][100/391]	Step 2346	Loss 0.8201	Prec@(1,5) (72.7%, 97.8%)
06/26 03:17:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][150/391]	Step 2346	Loss 0.8207	Prec@(1,5) (72.8%, 97.8%)
06/26 03:17:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][200/391]	Step 2346	Loss 0.8189	Prec@(1,5) (73.1%, 97.8%)
06/26 03:17:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][250/391]	Step 2346	Loss 0.8287	Prec@(1,5) (72.9%, 97.8%)
06/26 03:17:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][300/391]	Step 2346	Loss 0.8345	Prec@(1,5) (72.6%, 97.7%)
06/26 03:17:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][350/391]	Step 2346	Loss 0.8356	Prec@(1,5) (72.8%, 97.8%)
06/26 03:17:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][390/391]	Step 2346	Loss 0.8313	Prec@(1,5) (72.8%, 97.8%)
06/26 03:17:30午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  2/24] Final Prec@1 72.7960%
06/26 03:17:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 72.7960%
06/26 03:17:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][50/781]	Step 2396	lr 0.02416	Loss 0.6252 (0.6905)	Prec@(1,5) (76.5%, 98.5%)	
06/26 03:17:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][100/781]	Step 2446	lr 0.02416	Loss 0.7630 (0.6831)	Prec@(1,5) (76.9%, 98.5%)	
06/26 03:17:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][150/781]	Step 2496	lr 0.02416	Loss 0.7291 (0.6655)	Prec@(1,5) (77.2%, 98.7%)	
06/26 03:17:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][200/781]	Step 2546	lr 0.02416	Loss 0.6546 (0.6675)	Prec@(1,5) (77.2%, 98.7%)	
06/26 03:17:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][250/781]	Step 2596	lr 0.02416	Loss 0.5739 (0.6526)	Prec@(1,5) (77.7%, 98.8%)	
06/26 03:17:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][300/781]	Step 2646	lr 0.02416	Loss 0.5730 (0.6556)	Prec@(1,5) (77.6%, 98.7%)	
06/26 03:17:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][350/781]	Step 2696	lr 0.02416	Loss 0.6517 (0.6517)	Prec@(1,5) (77.6%, 98.7%)	
06/26 03:17:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][400/781]	Step 2746	lr 0.02416	Loss 0.4974 (0.6462)	Prec@(1,5) (77.8%, 98.7%)	
06/26 03:17:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][450/781]	Step 2796	lr 0.02416	Loss 0.4649 (0.6487)	Prec@(1,5) (77.7%, 98.8%)	
06/26 03:18:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][500/781]	Step 2846	lr 0.02416	Loss 0.6115 (0.6452)	Prec@(1,5) (77.8%, 98.8%)	
06/26 03:18:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][550/781]	Step 2896	lr 0.02416	Loss 0.8531 (0.6454)	Prec@(1,5) (77.9%, 98.8%)	
06/26 03:18:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][600/781]	Step 2946	lr 0.02416	Loss 0.4299 (0.6436)	Prec@(1,5) (77.9%, 98.8%)	
06/26 03:18:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][650/781]	Step 2996	lr 0.02416	Loss 0.6727 (0.6416)	Prec@(1,5) (78.0%, 98.8%)	
06/26 03:18:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][700/781]	Step 3046	lr 0.02416	Loss 0.5791 (0.6419)	Prec@(1,5) (78.1%, 98.8%)	
06/26 03:18:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][750/781]	Step 3096	lr 0.02416	Loss 0.7478 (0.6392)	Prec@(1,5) (78.1%, 98.8%)	
06/26 03:18:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][781/781]	Step 3127	lr 0.02416	Loss 0.7990 (0.6384)	Prec@(1,5) (78.1%, 98.8%)	
06/26 03:18:18午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  3/24] Final Prec@1 78.1160%
06/26 03:18:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][50/391]	Step 3128	Loss 0.6691	Prec@(1,5) (78.1%, 98.5%)
06/26 03:18:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][100/391]	Step 3128	Loss 0.6767	Prec@(1,5) (77.6%, 98.5%)
06/26 03:18:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][150/391]	Step 3128	Loss 0.6685	Prec@(1,5) (77.5%, 98.5%)
06/26 03:18:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][200/391]	Step 3128	Loss 0.6790	Prec@(1,5) (76.9%, 98.5%)
06/26 03:18:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][250/391]	Step 3128	Loss 0.6773	Prec@(1,5) (76.8%, 98.6%)
06/26 03:18:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][300/391]	Step 3128	Loss 0.6729	Prec@(1,5) (77.0%, 98.6%)
06/26 03:18:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][350/391]	Step 3128	Loss 0.6718	Prec@(1,5) (77.0%, 98.6%)
06/26 03:18:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][390/391]	Step 3128	Loss 0.6694	Prec@(1,5) (77.1%, 98.6%)
06/26 03:18:23午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  3/24] Final Prec@1 77.0960%
06/26 03:18:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 77.0960%
06/26 03:18:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][50/781]	Step 3178	lr 0.02352	Loss 0.8625 (0.5952)	Prec@(1,5) (79.5%, 99.1%)	
06/26 03:18:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][100/781]	Step 3228	lr 0.02352	Loss 0.4848 (0.5912)	Prec@(1,5) (79.9%, 99.0%)	
06/26 03:18:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][150/781]	Step 3278	lr 0.02352	Loss 0.5954 (0.5964)	Prec@(1,5) (79.6%, 98.9%)	
06/26 03:18:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][200/781]	Step 3328	lr 0.02352	Loss 0.5234 (0.5975)	Prec@(1,5) (79.4%, 99.0%)	
06/26 03:18:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][250/781]	Step 3378	lr 0.02352	Loss 0.4618 (0.5985)	Prec@(1,5) (79.4%, 99.0%)	
06/26 03:18:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][300/781]	Step 3428	lr 0.02352	Loss 0.4013 (0.5930)	Prec@(1,5) (79.6%, 99.0%)	
06/26 03:18:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][350/781]	Step 3478	lr 0.02352	Loss 0.4753 (0.5948)	Prec@(1,5) (79.6%, 98.9%)	
06/26 03:18:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][400/781]	Step 3528	lr 0.02352	Loss 0.7059 (0.5895)	Prec@(1,5) (79.8%, 99.0%)	
06/26 03:18:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][450/781]	Step 3578	lr 0.02352	Loss 0.6218 (0.5878)	Prec@(1,5) (79.9%, 98.9%)	
06/26 03:18:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][500/781]	Step 3628	lr 0.02352	Loss 0.7153 (0.5860)	Prec@(1,5) (79.9%, 98.9%)	
06/26 03:18:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][550/781]	Step 3678	lr 0.02352	Loss 0.5723 (0.5893)	Prec@(1,5) (79.7%, 98.9%)	
06/26 03:19:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][600/781]	Step 3728	lr 0.02352	Loss 0.6356 (0.5895)	Prec@(1,5) (79.8%, 98.9%)	
06/26 03:19:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][650/781]	Step 3778	lr 0.02352	Loss 0.4782 (0.5888)	Prec@(1,5) (79.8%, 99.0%)	
06/26 03:19:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][700/781]	Step 3828	lr 0.02352	Loss 0.5217 (0.5899)	Prec@(1,5) (79.7%, 99.0%)	
06/26 03:19:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][750/781]	Step 3878	lr 0.02352	Loss 0.4408 (0.5890)	Prec@(1,5) (79.8%, 99.0%)	
06/26 03:19:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][781/781]	Step 3909	lr 0.02352	Loss 0.7591 (0.5875)	Prec@(1,5) (79.8%, 99.0%)	
06/26 03:19:12午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  4/24] Final Prec@1 79.8200%
06/26 03:19:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][50/391]	Step 3910	Loss 0.5592	Prec@(1,5) (80.4%, 98.8%)
06/26 03:19:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][100/391]	Step 3910	Loss 0.5645	Prec@(1,5) (80.2%, 99.0%)
06/26 03:19:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][150/391]	Step 3910	Loss 0.5661	Prec@(1,5) (80.1%, 99.0%)
06/26 03:19:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][200/391]	Step 3910	Loss 0.5640	Prec@(1,5) (80.3%, 99.1%)
06/26 03:19:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][250/391]	Step 3910	Loss 0.5618	Prec@(1,5) (80.5%, 99.1%)
06/26 03:19:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][300/391]	Step 3910	Loss 0.5656	Prec@(1,5) (80.3%, 99.0%)
06/26 03:19:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][350/391]	Step 3910	Loss 0.5642	Prec@(1,5) (80.3%, 99.0%)
06/26 03:19:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][390/391]	Step 3910	Loss 0.5636	Prec@(1,5) (80.3%, 99.0%)
06/26 03:19:17午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  4/24] Final Prec@1 80.2720%
06/26 03:19:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 80.2720%
06/26 03:19:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][50/781]	Step 3960	lr 0.02271	Loss 0.6043 (0.5468)	Prec@(1,5) (81.0%, 99.1%)	
06/26 03:19:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][100/781]	Step 4010	lr 0.02271	Loss 0.4292 (0.5485)	Prec@(1,5) (81.0%, 99.2%)	
06/26 03:19:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][150/781]	Step 4060	lr 0.02271	Loss 0.4124 (0.5538)	Prec@(1,5) (80.7%, 99.1%)	
06/26 03:19:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][200/781]	Step 4110	lr 0.02271	Loss 0.4616 (0.5538)	Prec@(1,5) (80.9%, 99.1%)	
06/26 03:19:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][250/781]	Step 4160	lr 0.02271	Loss 0.5707 (0.5457)	Prec@(1,5) (81.0%, 99.1%)	
06/26 03:19:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][300/781]	Step 4210	lr 0.02271	Loss 0.5517 (0.5517)	Prec@(1,5) (81.0%, 99.1%)	
06/26 03:19:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][350/781]	Step 4260	lr 0.02271	Loss 0.4123 (0.5507)	Prec@(1,5) (81.0%, 99.0%)	
06/26 03:19:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][400/781]	Step 4310	lr 0.02271	Loss 0.7055 (0.5500)	Prec@(1,5) (81.0%, 99.1%)	
06/26 03:19:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][450/781]	Step 4360	lr 0.02271	Loss 0.5233 (0.5530)	Prec@(1,5) (80.9%, 99.0%)	
06/26 03:19:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][500/781]	Step 4410	lr 0.02271	Loss 0.2524 (0.5512)	Prec@(1,5) (80.9%, 99.0%)	
06/26 03:19:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][550/781]	Step 4460	lr 0.02271	Loss 0.4849 (0.5501)	Prec@(1,5) (80.9%, 99.0%)	
06/26 03:19:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][600/781]	Step 4510	lr 0.02271	Loss 0.4994 (0.5467)	Prec@(1,5) (81.0%, 99.1%)	
06/26 03:19:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][650/781]	Step 4560	lr 0.02271	Loss 0.4499 (0.5436)	Prec@(1,5) (81.1%, 99.1%)	
06/26 03:20:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][700/781]	Step 4610	lr 0.02271	Loss 0.4283 (0.5429)	Prec@(1,5) (81.1%, 99.1%)	
06/26 03:20:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][750/781]	Step 4660	lr 0.02271	Loss 0.3629 (0.5431)	Prec@(1,5) (81.1%, 99.1%)	
06/26 03:20:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][781/781]	Step 4691	lr 0.02271	Loss 0.5666 (0.5438)	Prec@(1,5) (81.1%, 99.1%)	
06/26 03:20:06午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  5/24] Final Prec@1 81.0780%
06/26 03:20:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][50/391]	Step 4692	Loss 0.5012	Prec@(1,5) (83.3%, 99.3%)
06/26 03:20:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][100/391]	Step 4692	Loss 0.5087	Prec@(1,5) (83.5%, 99.4%)
06/26 03:20:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][150/391]	Step 4692	Loss 0.5225	Prec@(1,5) (83.1%, 99.3%)
06/26 03:20:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][200/391]	Step 4692	Loss 0.5253	Prec@(1,5) (82.9%, 99.4%)
06/26 03:20:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][250/391]	Step 4692	Loss 0.5238	Prec@(1,5) (82.9%, 99.4%)
06/26 03:20:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][300/391]	Step 4692	Loss 0.5138	Prec@(1,5) (83.0%, 99.4%)
06/26 03:20:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][350/391]	Step 4692	Loss 0.5117	Prec@(1,5) (83.0%, 99.4%)
06/26 03:20:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][390/391]	Step 4692	Loss 0.5120	Prec@(1,5) (83.0%, 99.3%)
06/26 03:20:12午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  5/24] Final Prec@1 82.9800%
06/26 03:20:12午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 82.9800%
06/26 03:20:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][50/781]	Step 4742	lr 0.02175	Loss 0.3738 (0.5121)	Prec@(1,5) (82.1%, 99.4%)	
06/26 03:20:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][100/781]	Step 4792	lr 0.02175	Loss 0.5236 (0.5134)	Prec@(1,5) (82.3%, 99.3%)	
06/26 03:20:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][150/781]	Step 4842	lr 0.02175	Loss 0.5062 (0.5149)	Prec@(1,5) (81.9%, 99.3%)	
06/26 03:20:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][200/781]	Step 4892	lr 0.02175	Loss 0.4305 (0.5148)	Prec@(1,5) (82.1%, 99.2%)	
06/26 03:20:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][250/781]	Step 4942	lr 0.02175	Loss 0.6358 (0.5099)	Prec@(1,5) (82.2%, 99.2%)	
06/26 03:20:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][300/781]	Step 4992	lr 0.02175	Loss 0.3643 (0.5092)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][350/781]	Step 5042	lr 0.02175	Loss 0.4430 (0.5090)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][400/781]	Step 5092	lr 0.02175	Loss 0.4579 (0.5083)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][450/781]	Step 5142	lr 0.02175	Loss 0.4369 (0.5094)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][500/781]	Step 5192	lr 0.02175	Loss 0.7605 (0.5086)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][550/781]	Step 5242	lr 0.02175	Loss 0.3667 (0.5074)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][600/781]	Step 5292	lr 0.02175	Loss 0.9387 (0.5084)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][650/781]	Step 5342	lr 0.02175	Loss 0.5964 (0.5100)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:20:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][700/781]	Step 5392	lr 0.02175	Loss 0.3669 (0.5098)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:21:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][750/781]	Step 5442	lr 0.02175	Loss 0.6164 (0.5099)	Prec@(1,5) (82.2%, 99.2%)	
06/26 03:21:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][781/781]	Step 5473	lr 0.02175	Loss 0.3641 (0.5104)	Prec@(1,5) (82.3%, 99.2%)	
06/26 03:21:02午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  6/24] Final Prec@1 82.2640%
06/26 03:21:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][50/391]	Step 5474	Loss 0.4579	Prec@(1,5) (84.1%, 99.5%)
06/26 03:21:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][100/391]	Step 5474	Loss 0.4649	Prec@(1,5) (83.6%, 99.5%)
06/26 03:21:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][150/391]	Step 5474	Loss 0.4626	Prec@(1,5) (83.6%, 99.5%)
06/26 03:21:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][200/391]	Step 5474	Loss 0.4630	Prec@(1,5) (83.6%, 99.5%)
06/26 03:21:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][250/391]	Step 5474	Loss 0.4732	Prec@(1,5) (83.3%, 99.4%)
06/26 03:21:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][300/391]	Step 5474	Loss 0.4665	Prec@(1,5) (83.5%, 99.4%)
06/26 03:21:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][350/391]	Step 5474	Loss 0.4668	Prec@(1,5) (83.6%, 99.4%)
06/26 03:21:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][390/391]	Step 5474	Loss 0.4655	Prec@(1,5) (83.6%, 99.4%)
06/26 03:21:08午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  6/24] Final Prec@1 83.6280%
06/26 03:21:08午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 83.6280%
06/26 03:21:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][50/781]	Step 5524	lr 0.02065	Loss 0.5706 (0.4973)	Prec@(1,5) (82.6%, 99.4%)	
06/26 03:21:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][100/781]	Step 5574	lr 0.02065	Loss 0.3713 (0.4844)	Prec@(1,5) (83.1%, 99.4%)	
06/26 03:21:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][150/781]	Step 5624	lr 0.02065	Loss 0.4831 (0.4883)	Prec@(1,5) (82.8%, 99.3%)	
06/26 03:21:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][200/781]	Step 5674	lr 0.02065	Loss 0.5154 (0.4867)	Prec@(1,5) (83.0%, 99.3%)	
06/26 03:21:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][250/781]	Step 5724	lr 0.02065	Loss 0.5257 (0.4852)	Prec@(1,5) (83.1%, 99.3%)	
06/26 03:21:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][300/781]	Step 5774	lr 0.02065	Loss 0.3982 (0.4854)	Prec@(1,5) (83.1%, 99.3%)	
06/26 03:21:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][350/781]	Step 5824	lr 0.02065	Loss 0.7057 (0.4842)	Prec@(1,5) (83.1%, 99.3%)	
06/26 03:21:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][400/781]	Step 5874	lr 0.02065	Loss 0.4509 (0.4853)	Prec@(1,5) (83.1%, 99.3%)	
06/26 03:21:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][450/781]	Step 5924	lr 0.02065	Loss 0.4325 (0.4811)	Prec@(1,5) (83.2%, 99.3%)	
06/26 03:21:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][500/781]	Step 5974	lr 0.02065	Loss 0.3592 (0.4811)	Prec@(1,5) (83.3%, 99.3%)	
06/26 03:21:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][550/781]	Step 6024	lr 0.02065	Loss 0.3698 (0.4820)	Prec@(1,5) (83.2%, 99.2%)	
06/26 03:21:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][600/781]	Step 6074	lr 0.02065	Loss 0.4407 (0.4820)	Prec@(1,5) (83.2%, 99.3%)	
06/26 03:21:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][650/781]	Step 6124	lr 0.02065	Loss 0.4285 (0.4813)	Prec@(1,5) (83.2%, 99.3%)	
06/26 03:21:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][700/781]	Step 6174	lr 0.02065	Loss 0.5542 (0.4836)	Prec@(1,5) (83.2%, 99.2%)	
06/26 03:21:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][750/781]	Step 6224	lr 0.02065	Loss 0.4822 (0.4834)	Prec@(1,5) (83.2%, 99.2%)	
06/26 03:21:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][781/781]	Step 6255	lr 0.02065	Loss 0.3885 (0.4841)	Prec@(1,5) (83.2%, 99.2%)	
06/26 03:21:56午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  7/24] Final Prec@1 83.1760%
06/26 03:21:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][50/391]	Step 6256	Loss 0.4261	Prec@(1,5) (85.4%, 99.6%)
06/26 03:21:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][100/391]	Step 6256	Loss 0.4186	Prec@(1,5) (85.7%, 99.6%)
06/26 03:21:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][150/391]	Step 6256	Loss 0.4230	Prec@(1,5) (85.4%, 99.6%)
06/26 03:21:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][200/391]	Step 6256	Loss 0.4253	Prec@(1,5) (85.4%, 99.6%)
06/26 03:22:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][250/391]	Step 6256	Loss 0.4270	Prec@(1,5) (85.3%, 99.5%)
06/26 03:22:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][300/391]	Step 6256	Loss 0.4259	Prec@(1,5) (85.4%, 99.6%)
06/26 03:22:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][350/391]	Step 6256	Loss 0.4296	Prec@(1,5) (85.2%, 99.5%)
06/26 03:22:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][390/391]	Step 6256	Loss 0.4316	Prec@(1,5) (85.1%, 99.6%)
06/26 03:22:02午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  7/24] Final Prec@1 85.0640%
06/26 03:22:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 85.0640%
06/26 03:22:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][50/781]	Step 6306	lr 0.01943	Loss 0.4492 (0.4583)	Prec@(1,5) (84.1%, 99.5%)	
06/26 03:22:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][100/781]	Step 6356	lr 0.01943	Loss 0.4184 (0.4462)	Prec@(1,5) (84.5%, 99.5%)	
06/26 03:22:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][150/781]	Step 6406	lr 0.01943	Loss 0.5813 (0.4343)	Prec@(1,5) (84.9%, 99.5%)	
06/26 03:22:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][200/781]	Step 6456	lr 0.01943	Loss 0.6674 (0.4354)	Prec@(1,5) (84.9%, 99.5%)	
06/26 03:22:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][250/781]	Step 6506	lr 0.01943	Loss 0.3277 (0.4462)	Prec@(1,5) (84.4%, 99.4%)	
06/26 03:22:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][300/781]	Step 6556	lr 0.01943	Loss 0.4683 (0.4527)	Prec@(1,5) (84.3%, 99.4%)	
06/26 03:22:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][350/781]	Step 6606	lr 0.01943	Loss 0.5373 (0.4541)	Prec@(1,5) (84.2%, 99.4%)	
06/26 03:22:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][400/781]	Step 6656	lr 0.01943	Loss 0.4695 (0.4547)	Prec@(1,5) (84.3%, 99.4%)	
06/26 03:22:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][450/781]	Step 6706	lr 0.01943	Loss 0.4769 (0.4565)	Prec@(1,5) (84.2%, 99.4%)	
06/26 03:22:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][500/781]	Step 6756	lr 0.01943	Loss 0.3958 (0.4543)	Prec@(1,5) (84.4%, 99.4%)	
06/26 03:22:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][550/781]	Step 6806	lr 0.01943	Loss 0.6028 (0.4548)	Prec@(1,5) (84.3%, 99.4%)	
06/26 03:22:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][600/781]	Step 6856	lr 0.01943	Loss 0.6649 (0.4540)	Prec@(1,5) (84.3%, 99.4%)	
06/26 03:22:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][650/781]	Step 6906	lr 0.01943	Loss 0.2952 (0.4533)	Prec@(1,5) (84.3%, 99.4%)	
06/26 03:22:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][700/781]	Step 6956	lr 0.01943	Loss 0.4515 (0.4514)	Prec@(1,5) (84.4%, 99.4%)	
06/26 03:22:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][750/781]	Step 7006	lr 0.01943	Loss 0.5111 (0.4513)	Prec@(1,5) (84.4%, 99.4%)	
06/26 03:22:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][781/781]	Step 7037	lr 0.01943	Loss 0.4305 (0.4518)	Prec@(1,5) (84.4%, 99.4%)	
06/26 03:22:47午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  8/24] Final Prec@1 84.3800%
06/26 03:22:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][50/391]	Step 7038	Loss 0.3904	Prec@(1,5) (86.3%, 99.5%)
06/26 03:22:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][100/391]	Step 7038	Loss 0.4052	Prec@(1,5) (85.6%, 99.5%)
06/26 03:22:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][150/391]	Step 7038	Loss 0.4081	Prec@(1,5) (85.7%, 99.5%)
06/26 03:22:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][200/391]	Step 7038	Loss 0.4100	Prec@(1,5) (85.6%, 99.5%)
06/26 03:22:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][250/391]	Step 7038	Loss 0.4174	Prec@(1,5) (85.4%, 99.5%)
06/26 03:22:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][300/391]	Step 7038	Loss 0.4140	Prec@(1,5) (85.5%, 99.5%)
06/26 03:22:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][350/391]	Step 7038	Loss 0.4134	Prec@(1,5) (85.5%, 99.5%)
06/26 03:22:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][390/391]	Step 7038	Loss 0.4151	Prec@(1,5) (85.5%, 99.5%)
06/26 03:22:52午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  8/24] Final Prec@1 85.4840%
06/26 03:22:53午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 85.4840%
06/26 03:22:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][50/781]	Step 7088	lr 0.01811	Loss 0.2799 (0.4180)	Prec@(1,5) (85.4%, 99.6%)	
06/26 03:23:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][100/781]	Step 7138	lr 0.01811	Loss 0.3183 (0.4157)	Prec@(1,5) (85.2%, 99.6%)	
06/26 03:23:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][150/781]	Step 7188	lr 0.01811	Loss 0.3576 (0.4086)	Prec@(1,5) (85.6%, 99.5%)	
06/26 03:23:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][200/781]	Step 7238	lr 0.01811	Loss 0.3300 (0.4150)	Prec@(1,5) (85.7%, 99.5%)	
06/26 03:23:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][250/781]	Step 7288	lr 0.01811	Loss 0.4321 (0.4171)	Prec@(1,5) (85.7%, 99.4%)	
06/26 03:23:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][300/781]	Step 7338	lr 0.01811	Loss 0.3788 (0.4212)	Prec@(1,5) (85.4%, 99.4%)	
06/26 03:23:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][350/781]	Step 7388	lr 0.01811	Loss 0.4089 (0.4232)	Prec@(1,5) (85.3%, 99.5%)	
06/26 03:23:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][400/781]	Step 7438	lr 0.01811	Loss 0.6017 (0.4247)	Prec@(1,5) (85.2%, 99.5%)	
06/26 03:23:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][450/781]	Step 7488	lr 0.01811	Loss 0.6294 (0.4244)	Prec@(1,5) (85.2%, 99.5%)	
06/26 03:23:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][500/781]	Step 7538	lr 0.01811	Loss 0.6551 (0.4245)	Prec@(1,5) (85.3%, 99.5%)	
06/26 03:23:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][550/781]	Step 7588	lr 0.01811	Loss 0.5488 (0.4297)	Prec@(1,5) (85.1%, 99.4%)	
06/26 03:23:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][600/781]	Step 7638	lr 0.01811	Loss 0.4330 (0.4278)	Prec@(1,5) (85.1%, 99.4%)	
06/26 03:23:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][650/781]	Step 7688	lr 0.01811	Loss 0.1531 (0.4274)	Prec@(1,5) (85.1%, 99.5%)	
06/26 03:23:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][700/781]	Step 7738	lr 0.01811	Loss 0.5191 (0.4248)	Prec@(1,5) (85.2%, 99.4%)	
06/26 03:23:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][750/781]	Step 7788	lr 0.01811	Loss 0.5670 (0.4256)	Prec@(1,5) (85.2%, 99.4%)	
06/26 03:23:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][781/781]	Step 7819	lr 0.01811	Loss 0.4269 (0.4249)	Prec@(1,5) (85.2%, 99.5%)	
06/26 03:23:41午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  9/24] Final Prec@1 85.1880%
06/26 03:23:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][50/391]	Step 7820	Loss 0.3780	Prec@(1,5) (86.7%, 99.5%)
06/26 03:23:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][100/391]	Step 7820	Loss 0.3832	Prec@(1,5) (86.7%, 99.5%)
06/26 03:23:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][150/391]	Step 7820	Loss 0.3853	Prec@(1,5) (86.6%, 99.5%)
06/26 03:23:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][200/391]	Step 7820	Loss 0.3787	Prec@(1,5) (86.9%, 99.5%)
06/26 03:23:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][250/391]	Step 7820	Loss 0.3745	Prec@(1,5) (87.0%, 99.6%)
06/26 03:23:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][300/391]	Step 7820	Loss 0.3703	Prec@(1,5) (87.1%, 99.6%)
06/26 03:23:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][350/391]	Step 7820	Loss 0.3709	Prec@(1,5) (87.1%, 99.6%)
06/26 03:23:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][390/391]	Step 7820	Loss 0.3690	Prec@(1,5) (87.2%, 99.6%)
06/26 03:23:47午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  9/24] Final Prec@1 87.2400%
06/26 03:23:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.2400%
06/26 03:23:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][50/781]	Step 7870	lr 0.01671	Loss 0.3099 (0.3805)	Prec@(1,5) (86.6%, 99.6%)	
06/26 03:23:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][100/781]	Step 7920	lr 0.01671	Loss 0.5159 (0.3800)	Prec@(1,5) (86.8%, 99.7%)	
06/26 03:23:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][150/781]	Step 7970	lr 0.01671	Loss 0.4224 (0.3869)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][200/781]	Step 8020	lr 0.01671	Loss 0.3160 (0.3841)	Prec@(1,5) (86.4%, 99.7%)	
06/26 03:24:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][250/781]	Step 8070	lr 0.01671	Loss 0.2567 (0.3848)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][300/781]	Step 8120	lr 0.01671	Loss 0.3671 (0.3878)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][350/781]	Step 8170	lr 0.01671	Loss 0.5557 (0.3898)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][400/781]	Step 8220	lr 0.01671	Loss 0.4577 (0.3852)	Prec@(1,5) (86.5%, 99.6%)	
06/26 03:24:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][450/781]	Step 8270	lr 0.01671	Loss 0.4857 (0.3873)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][500/781]	Step 8320	lr 0.01671	Loss 0.6438 (0.3886)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][550/781]	Step 8370	lr 0.01671	Loss 0.5642 (0.3915)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][600/781]	Step 8420	lr 0.01671	Loss 0.6349 (0.3934)	Prec@(1,5) (86.4%, 99.6%)	
06/26 03:24:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][650/781]	Step 8470	lr 0.01671	Loss 0.2520 (0.3952)	Prec@(1,5) (86.3%, 99.6%)	
06/26 03:24:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][700/781]	Step 8520	lr 0.01671	Loss 0.3841 (0.3960)	Prec@(1,5) (86.3%, 99.6%)	
06/26 03:24:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][750/781]	Step 8570	lr 0.01671	Loss 0.3728 (0.3946)	Prec@(1,5) (86.3%, 99.6%)	
06/26 03:24:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][781/781]	Step 8601	lr 0.01671	Loss 0.4567 (0.3959)	Prec@(1,5) (86.3%, 99.6%)	
06/26 03:24:36午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 10/24] Final Prec@1 86.3060%
06/26 03:24:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][50/391]	Step 8602	Loss 0.3556	Prec@(1,5) (87.1%, 99.7%)
06/26 03:24:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][100/391]	Step 8602	Loss 0.3675	Prec@(1,5) (86.6%, 99.5%)
06/26 03:24:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][150/391]	Step 8602	Loss 0.3635	Prec@(1,5) (86.9%, 99.6%)
06/26 03:24:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][200/391]	Step 8602	Loss 0.3620	Prec@(1,5) (87.0%, 99.6%)
06/26 03:24:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][250/391]	Step 8602	Loss 0.3645	Prec@(1,5) (87.1%, 99.6%)
06/26 03:24:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][300/391]	Step 8602	Loss 0.3635	Prec@(1,5) (87.2%, 99.6%)
06/26 03:24:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][350/391]	Step 8602	Loss 0.3647	Prec@(1,5) (87.1%, 99.7%)
06/26 03:24:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][390/391]	Step 8602	Loss 0.3652	Prec@(1,5) (87.1%, 99.7%)
06/26 03:24:42午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 10/24] Final Prec@1 87.0960%
06/26 03:24:42午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.2400%
06/26 03:24:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][50/781]	Step 8652	lr 0.01525	Loss 0.4405 (0.3593)	Prec@(1,5) (87.2%, 99.6%)	
06/26 03:24:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][100/781]	Step 8702	lr 0.01525	Loss 0.3064 (0.3635)	Prec@(1,5) (87.1%, 99.6%)	
06/26 03:24:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][150/781]	Step 8752	lr 0.01525	Loss 0.4562 (0.3694)	Prec@(1,5) (87.3%, 99.6%)	
06/26 03:24:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][200/781]	Step 8802	lr 0.01525	Loss 0.3735 (0.3773)	Prec@(1,5) (86.9%, 99.6%)	
06/26 03:24:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][250/781]	Step 8852	lr 0.01525	Loss 0.3897 (0.3770)	Prec@(1,5) (87.0%, 99.6%)	
06/26 03:25:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][300/781]	Step 8902	lr 0.01525	Loss 0.4148 (0.3748)	Prec@(1,5) (87.1%, 99.6%)	
06/26 03:25:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][350/781]	Step 8952	lr 0.01525	Loss 0.2869 (0.3732)	Prec@(1,5) (87.1%, 99.6%)	
06/26 03:25:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][400/781]	Step 9002	lr 0.01525	Loss 0.2554 (0.3686)	Prec@(1,5) (87.2%, 99.7%)	
06/26 03:25:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][450/781]	Step 9052	lr 0.01525	Loss 0.3839 (0.3717)	Prec@(1,5) (87.1%, 99.7%)	
06/26 03:25:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][500/781]	Step 9102	lr 0.01525	Loss 0.5606 (0.3704)	Prec@(1,5) (87.1%, 99.6%)	
06/26 03:25:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][550/781]	Step 9152	lr 0.01525	Loss 0.3519 (0.3722)	Prec@(1,5) (87.0%, 99.6%)	
06/26 03:25:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][600/781]	Step 9202	lr 0.01525	Loss 0.2738 (0.3712)	Prec@(1,5) (87.0%, 99.6%)	
06/26 03:25:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][650/781]	Step 9252	lr 0.01525	Loss 0.4586 (0.3715)	Prec@(1,5) (87.0%, 99.6%)	
06/26 03:25:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][700/781]	Step 9302	lr 0.01525	Loss 0.3953 (0.3753)	Prec@(1,5) (86.9%, 99.6%)	
06/26 03:25:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][750/781]	Step 9352	lr 0.01525	Loss 0.3716 (0.3755)	Prec@(1,5) (86.9%, 99.6%)	
06/26 03:25:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][781/781]	Step 9383	lr 0.01525	Loss 0.4265 (0.3756)	Prec@(1,5) (86.9%, 99.6%)	
06/26 03:25:28午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 11/24] Final Prec@1 86.8640%
06/26 03:25:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][50/391]	Step 9384	Loss 0.3708	Prec@(1,5) (86.7%, 99.7%)
06/26 03:25:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][100/391]	Step 9384	Loss 0.3811	Prec@(1,5) (86.2%, 99.6%)
06/26 03:25:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][150/391]	Step 9384	Loss 0.3729	Prec@(1,5) (86.6%, 99.6%)
06/26 03:25:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][200/391]	Step 9384	Loss 0.3735	Prec@(1,5) (86.7%, 99.6%)
06/26 03:25:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][250/391]	Step 9384	Loss 0.3705	Prec@(1,5) (86.8%, 99.6%)
06/26 03:25:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][300/391]	Step 9384	Loss 0.3694	Prec@(1,5) (86.8%, 99.6%)
06/26 03:25:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][350/391]	Step 9384	Loss 0.3670	Prec@(1,5) (87.0%, 99.6%)
06/26 03:25:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][390/391]	Step 9384	Loss 0.3654	Prec@(1,5) (87.1%, 99.6%)
06/26 03:25:33午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 11/24] Final Prec@1 87.0720%
06/26 03:25:33午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.2400%
06/26 03:25:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][50/781]	Step 9434	lr 0.01375	Loss 0.2530 (0.3419)	Prec@(1,5) (88.1%, 99.7%)	
06/26 03:25:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][100/781]	Step 9484	lr 0.01375	Loss 0.3749 (0.3428)	Prec@(1,5) (88.1%, 99.7%)	
06/26 03:25:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][150/781]	Step 9534	lr 0.01375	Loss 0.3152 (0.3450)	Prec@(1,5) (87.9%, 99.7%)	
06/26 03:25:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][200/781]	Step 9584	lr 0.01375	Loss 0.3340 (0.3507)	Prec@(1,5) (87.7%, 99.7%)	
06/26 03:25:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][250/781]	Step 9634	lr 0.01375	Loss 0.2230 (0.3453)	Prec@(1,5) (87.9%, 99.7%)	
06/26 03:25:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][300/781]	Step 9684	lr 0.01375	Loss 0.3415 (0.3450)	Prec@(1,5) (88.0%, 99.7%)	
06/26 03:25:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][350/781]	Step 9734	lr 0.01375	Loss 0.2922 (0.3431)	Prec@(1,5) (88.1%, 99.7%)	
06/26 03:25:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][400/781]	Step 9784	lr 0.01375	Loss 0.3258 (0.3447)	Prec@(1,5) (88.1%, 99.7%)	
06/26 03:26:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][450/781]	Step 9834	lr 0.01375	Loss 0.1868 (0.3470)	Prec@(1,5) (88.0%, 99.6%)	
06/26 03:26:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][500/781]	Step 9884	lr 0.01375	Loss 0.2233 (0.3482)	Prec@(1,5) (87.9%, 99.6%)	
06/26 03:26:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][550/781]	Step 9934	lr 0.01375	Loss 0.8278 (0.3507)	Prec@(1,5) (87.8%, 99.7%)	
06/26 03:26:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][600/781]	Step 9984	lr 0.01375	Loss 0.4663 (0.3512)	Prec@(1,5) (87.8%, 99.6%)	
06/26 03:26:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][650/781]	Step 10034	lr 0.01375	Loss 0.3145 (0.3542)	Prec@(1,5) (87.7%, 99.6%)	
06/26 03:26:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][700/781]	Step 10084	lr 0.01375	Loss 0.1940 (0.3551)	Prec@(1,5) (87.6%, 99.6%)	
06/26 03:26:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][750/781]	Step 10134	lr 0.01375	Loss 0.2209 (0.3553)	Prec@(1,5) (87.6%, 99.6%)	
06/26 03:26:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][781/781]	Step 10165	lr 0.01375	Loss 0.3346 (0.3544)	Prec@(1,5) (87.6%, 99.6%)	
06/26 03:26:22午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 12/24] Final Prec@1 87.6400%
06/26 03:26:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][50/391]	Step 10166	Loss 0.3152	Prec@(1,5) (89.3%, 99.7%)
06/26 03:26:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][100/391]	Step 10166	Loss 0.3023	Prec@(1,5) (89.8%, 99.7%)
06/26 03:26:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][150/391]	Step 10166	Loss 0.3004	Prec@(1,5) (89.7%, 99.7%)
06/26 03:26:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][200/391]	Step 10166	Loss 0.3038	Prec@(1,5) (89.5%, 99.7%)
06/26 03:26:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][250/391]	Step 10166	Loss 0.3029	Prec@(1,5) (89.6%, 99.7%)
06/26 03:26:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][300/391]	Step 10166	Loss 0.3070	Prec@(1,5) (89.3%, 99.7%)
06/26 03:26:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][350/391]	Step 10166	Loss 0.3042	Prec@(1,5) (89.4%, 99.7%)
06/26 03:26:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][390/391]	Step 10166	Loss 0.3034	Prec@(1,5) (89.4%, 99.7%)
06/26 03:26:27午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 12/24] Final Prec@1 89.4520%
06/26 03:26:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.4520%
06/26 03:26:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][50/781]	Step 10216	lr 0.01225	Loss 0.4943 (0.3283)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:26:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][100/781]	Step 10266	lr 0.01225	Loss 0.3524 (0.3154)	Prec@(1,5) (89.0%, 99.7%)	
06/26 03:26:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][150/781]	Step 10316	lr 0.01225	Loss 0.4077 (0.3206)	Prec@(1,5) (89.0%, 99.7%)	
06/26 03:26:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][200/781]	Step 10366	lr 0.01225	Loss 0.4163 (0.3264)	Prec@(1,5) (88.7%, 99.7%)	
06/26 03:26:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][250/781]	Step 10416	lr 0.01225	Loss 0.2056 (0.3230)	Prec@(1,5) (88.8%, 99.7%)	
06/26 03:26:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][300/781]	Step 10466	lr 0.01225	Loss 0.4472 (0.3235)	Prec@(1,5) (88.8%, 99.7%)	
06/26 03:26:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][350/781]	Step 10516	lr 0.01225	Loss 0.3486 (0.3242)	Prec@(1,5) (88.8%, 99.7%)	
06/26 03:26:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][400/781]	Step 10566	lr 0.01225	Loss 0.3234 (0.3247)	Prec@(1,5) (88.8%, 99.7%)	
06/26 03:26:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][450/781]	Step 10616	lr 0.01225	Loss 0.2931 (0.3266)	Prec@(1,5) (88.6%, 99.7%)	
06/26 03:27:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][500/781]	Step 10666	lr 0.01225	Loss 0.4637 (0.3274)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:27:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][550/781]	Step 10716	lr 0.01225	Loss 0.4123 (0.3272)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:27:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][600/781]	Step 10766	lr 0.01225	Loss 0.3481 (0.3264)	Prec@(1,5) (88.6%, 99.7%)	
06/26 03:27:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][650/781]	Step 10816	lr 0.01225	Loss 0.3607 (0.3256)	Prec@(1,5) (88.7%, 99.7%)	
06/26 03:27:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][700/781]	Step 10866	lr 0.01225	Loss 0.3203 (0.3266)	Prec@(1,5) (88.7%, 99.7%)	
06/26 03:27:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][750/781]	Step 10916	lr 0.01225	Loss 0.4256 (0.3279)	Prec@(1,5) (88.7%, 99.7%)	
06/26 03:27:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][781/781]	Step 10947	lr 0.01225	Loss 0.4122 (0.3278)	Prec@(1,5) (88.7%, 99.7%)	
06/26 03:27:17午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 13/24] Final Prec@1 88.6580%
06/26 03:27:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][50/391]	Step 10948	Loss 0.2748	Prec@(1,5) (89.8%, 99.7%)
06/26 03:27:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][100/391]	Step 10948	Loss 0.2857	Prec@(1,5) (90.0%, 99.7%)
06/26 03:27:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][150/391]	Step 10948	Loss 0.2933	Prec@(1,5) (89.7%, 99.7%)
06/26 03:27:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][200/391]	Step 10948	Loss 0.2910	Prec@(1,5) (89.8%, 99.7%)
06/26 03:27:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][250/391]	Step 10948	Loss 0.2868	Prec@(1,5) (89.9%, 99.7%)
06/26 03:27:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][300/391]	Step 10948	Loss 0.2891	Prec@(1,5) (89.9%, 99.7%)
06/26 03:27:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][350/391]	Step 10948	Loss 0.2914	Prec@(1,5) (89.8%, 99.7%)
06/26 03:27:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][390/391]	Step 10948	Loss 0.2905	Prec@(1,5) (89.9%, 99.7%)
06/26 03:27:23午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 13/24] Final Prec@1 89.8960%
06/26 03:27:23午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.8960%
06/26 03:27:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][50/781]	Step 10998	lr 0.01075	Loss 0.2539 (0.2840)	Prec@(1,5) (90.5%, 99.7%)	
06/26 03:27:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][100/781]	Step 11048	lr 0.01075	Loss 0.3261 (0.2912)	Prec@(1,5) (90.1%, 99.7%)	
06/26 03:27:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][150/781]	Step 11098	lr 0.01075	Loss 0.4206 (0.2925)	Prec@(1,5) (89.9%, 99.8%)	
06/26 03:27:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][200/781]	Step 11148	lr 0.01075	Loss 0.2679 (0.2936)	Prec@(1,5) (89.9%, 99.8%)	
06/26 03:27:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][250/781]	Step 11198	lr 0.01075	Loss 0.1722 (0.2936)	Prec@(1,5) (89.9%, 99.8%)	
06/26 03:27:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][300/781]	Step 11248	lr 0.01075	Loss 0.2483 (0.2970)	Prec@(1,5) (89.7%, 99.8%)	
06/26 03:27:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][350/781]	Step 11298	lr 0.01075	Loss 0.3653 (0.2951)	Prec@(1,5) (89.9%, 99.8%)	
06/26 03:27:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][400/781]	Step 11348	lr 0.01075	Loss 0.2489 (0.2970)	Prec@(1,5) (89.8%, 99.8%)	
06/26 03:27:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][450/781]	Step 11398	lr 0.01075	Loss 0.3026 (0.2962)	Prec@(1,5) (89.8%, 99.8%)	
06/26 03:27:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][500/781]	Step 11448	lr 0.01075	Loss 0.2070 (0.2992)	Prec@(1,5) (89.7%, 99.8%)	
06/26 03:27:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][550/781]	Step 11498	lr 0.01075	Loss 0.3176 (0.2992)	Prec@(1,5) (89.6%, 99.8%)	
06/26 03:28:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][600/781]	Step 11548	lr 0.01075	Loss 0.3285 (0.3009)	Prec@(1,5) (89.6%, 99.8%)	
06/26 03:28:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][650/781]	Step 11598	lr 0.01075	Loss 0.3231 (0.2994)	Prec@(1,5) (89.6%, 99.8%)	
06/26 03:28:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][700/781]	Step 11648	lr 0.01075	Loss 0.2576 (0.3013)	Prec@(1,5) (89.5%, 99.8%)	
06/26 03:28:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][750/781]	Step 11698	lr 0.01075	Loss 0.2542 (0.3010)	Prec@(1,5) (89.5%, 99.8%)	
06/26 03:28:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][781/781]	Step 11729	lr 0.01075	Loss 0.3638 (0.3029)	Prec@(1,5) (89.4%, 99.8%)	
06/26 03:28:12午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 14/24] Final Prec@1 89.3740%
06/26 03:28:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][50/391]	Step 11730	Loss 0.2933	Prec@(1,5) (89.7%, 99.7%)
06/26 03:28:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][100/391]	Step 11730	Loss 0.3002	Prec@(1,5) (89.5%, 99.7%)
06/26 03:28:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][150/391]	Step 11730	Loss 0.2960	Prec@(1,5) (89.6%, 99.8%)
06/26 03:28:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][200/391]	Step 11730	Loss 0.3044	Prec@(1,5) (89.2%, 99.8%)
06/26 03:28:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][250/391]	Step 11730	Loss 0.3039	Prec@(1,5) (89.3%, 99.8%)
06/26 03:28:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][300/391]	Step 11730	Loss 0.3017	Prec@(1,5) (89.4%, 99.8%)
06/26 03:28:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][350/391]	Step 11730	Loss 0.3034	Prec@(1,5) (89.3%, 99.8%)
06/26 03:28:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][390/391]	Step 11730	Loss 0.3016	Prec@(1,5) (89.4%, 99.8%)
06/26 03:28:18午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 14/24] Final Prec@1 89.4080%
06/26 03:28:18午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.8960%
06/26 03:28:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][50/781]	Step 11780	lr 0.00929	Loss 0.6610 (0.2970)	Prec@(1,5) (89.0%, 99.7%)	
06/26 03:28:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][100/781]	Step 11830	lr 0.00929	Loss 0.2336 (0.2894)	Prec@(1,5) (89.7%, 99.8%)	
06/26 03:28:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][150/781]	Step 11880	lr 0.00929	Loss 0.1753 (0.2793)	Prec@(1,5) (90.3%, 99.9%)	
06/26 03:28:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][200/781]	Step 11930	lr 0.00929	Loss 0.3600 (0.2753)	Prec@(1,5) (90.3%, 99.9%)	
06/26 03:28:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][250/781]	Step 11980	lr 0.00929	Loss 0.2513 (0.2749)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:28:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][300/781]	Step 12030	lr 0.00929	Loss 0.1462 (0.2769)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:28:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][350/781]	Step 12080	lr 0.00929	Loss 0.3246 (0.2748)	Prec@(1,5) (90.3%, 99.8%)	
06/26 03:28:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][400/781]	Step 12130	lr 0.00929	Loss 0.1378 (0.2719)	Prec@(1,5) (90.4%, 99.8%)	
06/26 03:28:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][450/781]	Step 12180	lr 0.00929	Loss 0.1732 (0.2711)	Prec@(1,5) (90.4%, 99.8%)	
06/26 03:28:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][500/781]	Step 12230	lr 0.00929	Loss 0.3570 (0.2728)	Prec@(1,5) (90.4%, 99.8%)	
06/26 03:28:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][550/781]	Step 12280	lr 0.00929	Loss 0.2784 (0.2749)	Prec@(1,5) (90.3%, 99.8%)	
06/26 03:28:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][600/781]	Step 12330	lr 0.00929	Loss 0.2736 (0.2781)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:28:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][650/781]	Step 12380	lr 0.00929	Loss 0.3156 (0.2780)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:29:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][700/781]	Step 12430	lr 0.00929	Loss 0.2753 (0.2775)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:29:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][750/781]	Step 12480	lr 0.00929	Loss 0.4168 (0.2781)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:29:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][781/781]	Step 12511	lr 0.00929	Loss 0.3191 (0.2789)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:29:06午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 15/24] Final Prec@1 90.1900%
06/26 03:29:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][50/391]	Step 12512	Loss 0.2272	Prec@(1,5) (91.7%, 99.9%)
06/26 03:29:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][100/391]	Step 12512	Loss 0.2295	Prec@(1,5) (91.9%, 99.9%)
06/26 03:29:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][150/391]	Step 12512	Loss 0.2304	Prec@(1,5) (91.8%, 99.9%)
06/26 03:29:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][200/391]	Step 12512	Loss 0.2354	Prec@(1,5) (91.7%, 99.9%)
06/26 03:29:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][250/391]	Step 12512	Loss 0.2362	Prec@(1,5) (91.6%, 99.9%)
06/26 03:29:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][300/391]	Step 12512	Loss 0.2338	Prec@(1,5) (91.7%, 99.9%)
06/26 03:29:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][350/391]	Step 12512	Loss 0.2344	Prec@(1,5) (91.7%, 99.9%)
06/26 03:29:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][390/391]	Step 12512	Loss 0.2345	Prec@(1,5) (91.7%, 99.9%)
06/26 03:29:11午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 15/24] Final Prec@1 91.7040%
06/26 03:29:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 91.7040%
06/26 03:29:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][50/781]	Step 12562	lr 0.00789	Loss 0.1549 (0.2360)	Prec@(1,5) (92.0%, 99.8%)	
06/26 03:29:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][100/781]	Step 12612	lr 0.00789	Loss 0.3807 (0.2370)	Prec@(1,5) (91.7%, 99.9%)	
06/26 03:29:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][150/781]	Step 12662	lr 0.00789	Loss 0.2334 (0.2404)	Prec@(1,5) (91.6%, 99.9%)	
06/26 03:29:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][200/781]	Step 12712	lr 0.00789	Loss 0.2271 (0.2451)	Prec@(1,5) (91.4%, 99.8%)	
06/26 03:29:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][250/781]	Step 12762	lr 0.00789	Loss 0.1562 (0.2489)	Prec@(1,5) (91.3%, 99.8%)	
06/26 03:29:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][300/781]	Step 12812	lr 0.00789	Loss 0.2047 (0.2459)	Prec@(1,5) (91.4%, 99.8%)	
06/26 03:29:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][350/781]	Step 12862	lr 0.00789	Loss 0.2690 (0.2450)	Prec@(1,5) (91.4%, 99.9%)	
06/26 03:29:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][400/781]	Step 12912	lr 0.00789	Loss 0.2397 (0.2446)	Prec@(1,5) (91.4%, 99.9%)	
06/26 03:29:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][450/781]	Step 12962	lr 0.00789	Loss 0.3241 (0.2496)	Prec@(1,5) (91.3%, 99.9%)	
06/26 03:29:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][500/781]	Step 13012	lr 0.00789	Loss 0.1629 (0.2509)	Prec@(1,5) (91.2%, 99.9%)	
06/26 03:29:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][550/781]	Step 13062	lr 0.00789	Loss 0.3109 (0.2518)	Prec@(1,5) (91.2%, 99.9%)	
06/26 03:29:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][600/781]	Step 13112	lr 0.00789	Loss 0.1667 (0.2518)	Prec@(1,5) (91.1%, 99.9%)	
06/26 03:29:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][650/781]	Step 13162	lr 0.00789	Loss 0.2553 (0.2532)	Prec@(1,5) (91.1%, 99.9%)	
06/26 03:29:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][700/781]	Step 13212	lr 0.00789	Loss 0.3126 (0.2528)	Prec@(1,5) (91.1%, 99.9%)	
06/26 03:29:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][750/781]	Step 13262	lr 0.00789	Loss 0.1609 (0.2526)	Prec@(1,5) (91.1%, 99.9%)	
06/26 03:30:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][781/781]	Step 13293	lr 0.00789	Loss 0.2703 (0.2525)	Prec@(1,5) (91.1%, 99.9%)	
06/26 03:30:00午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 16/24] Final Prec@1 91.1020%
06/26 03:30:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][50/391]	Step 13294	Loss 0.1924	Prec@(1,5) (93.2%, 99.9%)
06/26 03:30:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][100/391]	Step 13294	Loss 0.1896	Prec@(1,5) (93.4%, 99.9%)
06/26 03:30:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][150/391]	Step 13294	Loss 0.1966	Prec@(1,5) (93.2%, 99.9%)
06/26 03:30:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][200/391]	Step 13294	Loss 0.1951	Prec@(1,5) (93.3%, 99.9%)
06/26 03:30:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][250/391]	Step 13294	Loss 0.1947	Prec@(1,5) (93.3%, 99.9%)
06/26 03:30:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][300/391]	Step 13294	Loss 0.1952	Prec@(1,5) (93.2%, 99.9%)
06/26 03:30:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][350/391]	Step 13294	Loss 0.1953	Prec@(1,5) (93.2%, 99.9%)
06/26 03:30:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][390/391]	Step 13294	Loss 0.1950	Prec@(1,5) (93.2%, 99.9%)
06/26 03:30:06午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 16/24] Final Prec@1 93.1680%
06/26 03:30:06午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.1680%
06/26 03:30:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][50/781]	Step 13344	lr 0.00657	Loss 0.1318 (0.2049)	Prec@(1,5) (92.5%, 99.9%)	
06/26 03:30:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][100/781]	Step 13394	lr 0.00657	Loss 0.1177 (0.2070)	Prec@(1,5) (92.6%, 99.9%)	
06/26 03:30:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][150/781]	Step 13444	lr 0.00657	Loss 0.1335 (0.2082)	Prec@(1,5) (92.5%, 99.9%)	
06/26 03:30:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][200/781]	Step 13494	lr 0.00657	Loss 0.2222 (0.2061)	Prec@(1,5) (92.6%, 99.9%)	
06/26 03:30:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][250/781]	Step 13544	lr 0.00657	Loss 0.2855 (0.2097)	Prec@(1,5) (92.5%, 99.9%)	
06/26 03:30:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][300/781]	Step 13594	lr 0.00657	Loss 0.1285 (0.2132)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:30:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][350/781]	Step 13644	lr 0.00657	Loss 0.2256 (0.2150)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:30:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][400/781]	Step 13694	lr 0.00657	Loss 0.2439 (0.2179)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:30:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][450/781]	Step 13744	lr 0.00657	Loss 0.3628 (0.2184)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:30:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][500/781]	Step 13794	lr 0.00657	Loss 0.1384 (0.2201)	Prec@(1,5) (92.3%, 99.9%)	
06/26 03:30:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][550/781]	Step 13844	lr 0.00657	Loss 0.3077 (0.2193)	Prec@(1,5) (92.3%, 99.9%)	
06/26 03:30:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][600/781]	Step 13894	lr 0.00657	Loss 0.3106 (0.2183)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:30:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][650/781]	Step 13944	lr 0.00657	Loss 0.1783 (0.2164)	Prec@(1,5) (92.5%, 99.9%)	
06/26 03:30:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][700/781]	Step 13994	lr 0.00657	Loss 0.2328 (0.2166)	Prec@(1,5) (92.5%, 99.9%)	
06/26 03:30:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][750/781]	Step 14044	lr 0.00657	Loss 0.3693 (0.2184)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:30:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][781/781]	Step 14075	lr 0.00657	Loss 0.2152 (0.2181)	Prec@(1,5) (92.5%, 99.9%)	
06/26 03:30:55午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 17/24] Final Prec@1 92.4660%
06/26 03:30:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][50/391]	Step 14076	Loss 0.1804	Prec@(1,5) (93.5%, 99.9%)
06/26 03:30:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][100/391]	Step 14076	Loss 0.1765	Prec@(1,5) (93.6%, 100.0%)
06/26 03:30:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][150/391]	Step 14076	Loss 0.1800	Prec@(1,5) (93.5%, 99.9%)
06/26 03:30:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][200/391]	Step 14076	Loss 0.1770	Prec@(1,5) (93.7%, 99.9%)
06/26 03:30:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][250/391]	Step 14076	Loss 0.1783	Prec@(1,5) (93.7%, 99.9%)
06/26 03:30:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][300/391]	Step 14076	Loss 0.1800	Prec@(1,5) (93.6%, 99.9%)
06/26 03:31:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][350/391]	Step 14076	Loss 0.1793	Prec@(1,5) (93.6%, 99.9%)
06/26 03:31:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][390/391]	Step 14076	Loss 0.1775	Prec@(1,5) (93.7%, 99.9%)
06/26 03:31:00午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 17/24] Final Prec@1 93.7400%
06/26 03:31:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.7400%
06/26 03:31:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][50/781]	Step 14126	lr 0.00535	Loss 0.0924 (0.1793)	Prec@(1,5) (93.8%, 99.9%)	
06/26 03:31:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][100/781]	Step 14176	lr 0.00535	Loss 0.0856 (0.1826)	Prec@(1,5) (93.7%, 99.9%)	
06/26 03:31:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][150/781]	Step 14226	lr 0.00535	Loss 0.2139 (0.1855)	Prec@(1,5) (93.4%, 99.9%)	
06/26 03:31:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][200/781]	Step 14276	lr 0.00535	Loss 0.2691 (0.1855)	Prec@(1,5) (93.3%, 99.9%)	
06/26 03:31:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][250/781]	Step 14326	lr 0.00535	Loss 0.1317 (0.1873)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:31:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][300/781]	Step 14376	lr 0.00535	Loss 0.1503 (0.1899)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:31:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][350/781]	Step 14426	lr 0.00535	Loss 0.0733 (0.1914)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:31:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][400/781]	Step 14476	lr 0.00535	Loss 0.3478 (0.1936)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:31:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][450/781]	Step 14526	lr 0.00535	Loss 0.2731 (0.1919)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:31:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][500/781]	Step 14576	lr 0.00535	Loss 0.2070 (0.1918)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:31:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][550/781]	Step 14626	lr 0.00535	Loss 0.1711 (0.1926)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:31:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][600/781]	Step 14676	lr 0.00535	Loss 0.3895 (0.1948)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:31:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][650/781]	Step 14726	lr 0.00535	Loss 0.1737 (0.1947)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:31:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][700/781]	Step 14776	lr 0.00535	Loss 0.1867 (0.1956)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:31:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][750/781]	Step 14826	lr 0.00535	Loss 0.2927 (0.1959)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:31:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][781/781]	Step 14857	lr 0.00535	Loss 0.1178 (0.1962)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:31:50午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 18/24] Final Prec@1 92.9720%
06/26 03:31:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][50/391]	Step 14858	Loss 0.1582	Prec@(1,5) (94.6%, 100.0%)
06/26 03:31:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][100/391]	Step 14858	Loss 0.1462	Prec@(1,5) (95.0%, 100.0%)
06/26 03:31:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][150/391]	Step 14858	Loss 0.1450	Prec@(1,5) (95.1%, 100.0%)
06/26 03:31:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][200/391]	Step 14858	Loss 0.1499	Prec@(1,5) (94.9%, 100.0%)
06/26 03:31:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][250/391]	Step 14858	Loss 0.1480	Prec@(1,5) (95.0%, 100.0%)
06/26 03:31:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][300/391]	Step 14858	Loss 0.1497	Prec@(1,5) (94.9%, 100.0%)
06/26 03:31:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][350/391]	Step 14858	Loss 0.1497	Prec@(1,5) (94.9%, 100.0%)
06/26 03:31:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][390/391]	Step 14858	Loss 0.1492	Prec@(1,5) (94.9%, 100.0%)
06/26 03:31:55午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 18/24] Final Prec@1 94.9440%
06/26 03:31:55午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 94.9440%
06/26 03:31:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][50/781]	Step 14908	lr 0.00425	Loss 0.0909 (0.1840)	Prec@(1,5) (93.5%, 100.0%)	
06/26 03:32:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][100/781]	Step 14958	lr 0.00425	Loss 0.3351 (0.1831)	Prec@(1,5) (93.5%, 100.0%)	
06/26 03:32:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][150/781]	Step 15008	lr 0.00425	Loss 0.1531 (0.1821)	Prec@(1,5) (93.6%, 99.9%)	
06/26 03:32:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][200/781]	Step 15058	lr 0.00425	Loss 0.1512 (0.1797)	Prec@(1,5) (93.7%, 99.9%)	
06/26 03:32:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][250/781]	Step 15108	lr 0.00425	Loss 0.1069 (0.1741)	Prec@(1,5) (93.8%, 99.9%)	
06/26 03:32:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][300/781]	Step 15158	lr 0.00425	Loss 0.3464 (0.1740)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:32:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][350/781]	Step 15208	lr 0.00425	Loss 0.1566 (0.1719)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][400/781]	Step 15258	lr 0.00425	Loss 0.0734 (0.1722)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][450/781]	Step 15308	lr 0.00425	Loss 0.0922 (0.1727)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][500/781]	Step 15358	lr 0.00425	Loss 0.1603 (0.1724)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][550/781]	Step 15408	lr 0.00425	Loss 0.2344 (0.1728)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][600/781]	Step 15458	lr 0.00425	Loss 0.1079 (0.1717)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][650/781]	Step 15508	lr 0.00425	Loss 0.2080 (0.1727)	Prec@(1,5) (94.0%, 99.9%)	
06/26 03:32:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][700/781]	Step 15558	lr 0.00425	Loss 0.1207 (0.1741)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:32:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][750/781]	Step 15608	lr 0.00425	Loss 0.1966 (0.1746)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:32:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][781/781]	Step 15639	lr 0.00425	Loss 0.0968 (0.1742)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:32:44午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 19/24] Final Prec@1 93.9080%
06/26 03:32:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][50/391]	Step 15640	Loss 0.1260	Prec@(1,5) (95.3%, 99.9%)
06/26 03:32:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][100/391]	Step 15640	Loss 0.1301	Prec@(1,5) (95.5%, 99.9%)
06/26 03:32:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][150/391]	Step 15640	Loss 0.1282	Prec@(1,5) (95.7%, 99.9%)
06/26 03:32:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][200/391]	Step 15640	Loss 0.1276	Prec@(1,5) (95.7%, 100.0%)
06/26 03:32:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][250/391]	Step 15640	Loss 0.1268	Prec@(1,5) (95.8%, 100.0%)
06/26 03:32:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][300/391]	Step 15640	Loss 0.1275	Prec@(1,5) (95.7%, 100.0%)
06/26 03:32:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][350/391]	Step 15640	Loss 0.1277	Prec@(1,5) (95.7%, 100.0%)
06/26 03:32:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][390/391]	Step 15640	Loss 0.1270	Prec@(1,5) (95.7%, 100.0%)
06/26 03:32:50午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 19/24] Final Prec@1 95.7080%
06/26 03:32:50午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 95.7080%
06/26 03:32:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][50/781]	Step 15690	lr 0.00329	Loss 0.1855 (0.1638)	Prec@(1,5) (94.4%, 100.0%)	
06/26 03:32:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][100/781]	Step 15740	lr 0.00329	Loss 0.1484 (0.1565)	Prec@(1,5) (94.8%, 100.0%)	
06/26 03:33:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][150/781]	Step 15790	lr 0.00329	Loss 0.0765 (0.1559)	Prec@(1,5) (94.6%, 100.0%)	
06/26 03:33:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][200/781]	Step 15840	lr 0.00329	Loss 0.1758 (0.1528)	Prec@(1,5) (94.8%, 100.0%)	
06/26 03:33:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][250/781]	Step 15890	lr 0.00329	Loss 0.0818 (0.1523)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][300/781]	Step 15940	lr 0.00329	Loss 0.2471 (0.1504)	Prec@(1,5) (94.8%, 100.0%)	
06/26 03:33:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][350/781]	Step 15990	lr 0.00329	Loss 0.1012 (0.1494)	Prec@(1,5) (94.8%, 100.0%)	
06/26 03:33:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][400/781]	Step 16040	lr 0.00329	Loss 0.0559 (0.1498)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][450/781]	Step 16090	lr 0.00329	Loss 0.1347 (0.1499)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][500/781]	Step 16140	lr 0.00329	Loss 0.1106 (0.1491)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][550/781]	Step 16190	lr 0.00329	Loss 0.1536 (0.1489)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][600/781]	Step 16240	lr 0.00329	Loss 0.2091 (0.1487)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][650/781]	Step 16290	lr 0.00329	Loss 0.1182 (0.1486)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][700/781]	Step 16340	lr 0.00329	Loss 0.0792 (0.1485)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][750/781]	Step 16390	lr 0.00329	Loss 0.2024 (0.1495)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][781/781]	Step 16421	lr 0.00329	Loss 0.0826 (0.1489)	Prec@(1,5) (94.7%, 100.0%)	
06/26 03:33:38午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 20/24] Final Prec@1 94.7240%
06/26 03:33:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][50/391]	Step 16422	Loss 0.1124	Prec@(1,5) (96.1%, 100.0%)
06/26 03:33:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][100/391]	Step 16422	Loss 0.1128	Prec@(1,5) (96.1%, 100.0%)
06/26 03:33:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][150/391]	Step 16422	Loss 0.1110	Prec@(1,5) (96.2%, 100.0%)
06/26 03:33:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][200/391]	Step 16422	Loss 0.1101	Prec@(1,5) (96.2%, 100.0%)
06/26 03:33:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][250/391]	Step 16422	Loss 0.1089	Prec@(1,5) (96.3%, 100.0%)
06/26 03:33:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][300/391]	Step 16422	Loss 0.1085	Prec@(1,5) (96.3%, 100.0%)
06/26 03:33:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][350/391]	Step 16422	Loss 0.1112	Prec@(1,5) (96.2%, 100.0%)
06/26 03:33:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][390/391]	Step 16422	Loss 0.1105	Prec@(1,5) (96.3%, 100.0%)
06/26 03:33:43午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 20/24] Final Prec@1 96.2520%
06/26 03:33:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.2520%
06/26 03:33:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][50/781]	Step 16472	lr 0.00248	Loss 0.1093 (0.1303)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:33:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][100/781]	Step 16522	lr 0.00248	Loss 0.0376 (0.1328)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:33:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][150/781]	Step 16572	lr 0.00248	Loss 0.1475 (0.1272)	Prec@(1,5) (95.5%, 100.0%)	
06/26 03:33:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][200/781]	Step 16622	lr 0.00248	Loss 0.1379 (0.1270)	Prec@(1,5) (95.6%, 100.0%)	
06/26 03:33:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][250/781]	Step 16672	lr 0.00248	Loss 0.1050 (0.1271)	Prec@(1,5) (95.6%, 100.0%)	
06/26 03:34:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][300/781]	Step 16722	lr 0.00248	Loss 0.0638 (0.1277)	Prec@(1,5) (95.5%, 100.0%)	
06/26 03:34:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][350/781]	Step 16772	lr 0.00248	Loss 0.1465 (0.1283)	Prec@(1,5) (95.5%, 100.0%)	
06/26 03:34:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][400/781]	Step 16822	lr 0.00248	Loss 0.2494 (0.1275)	Prec@(1,5) (95.5%, 100.0%)	
06/26 03:34:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][450/781]	Step 16872	lr 0.00248	Loss 0.1494 (0.1285)	Prec@(1,5) (95.4%, 100.0%)	
06/26 03:34:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][500/781]	Step 16922	lr 0.00248	Loss 0.2265 (0.1296)	Prec@(1,5) (95.4%, 100.0%)	
06/26 03:34:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][550/781]	Step 16972	lr 0.00248	Loss 0.0943 (0.1293)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:34:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][600/781]	Step 17022	lr 0.00248	Loss 0.1154 (0.1294)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:34:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][650/781]	Step 17072	lr 0.00248	Loss 0.1824 (0.1298)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:34:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][700/781]	Step 17122	lr 0.00248	Loss 0.1053 (0.1311)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:34:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][750/781]	Step 17172	lr 0.00248	Loss 0.1185 (0.1321)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:34:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][781/781]	Step 17203	lr 0.00248	Loss 0.0480 (0.1318)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:34:30午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 21/24] Final Prec@1 95.2560%
06/26 03:34:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][50/391]	Step 17204	Loss 0.0867	Prec@(1,5) (97.1%, 100.0%)
06/26 03:34:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][100/391]	Step 17204	Loss 0.0890	Prec@(1,5) (97.1%, 100.0%)
06/26 03:34:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][150/391]	Step 17204	Loss 0.0875	Prec@(1,5) (97.2%, 100.0%)
06/26 03:34:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][200/391]	Step 17204	Loss 0.0887	Prec@(1,5) (97.2%, 100.0%)
06/26 03:34:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][250/391]	Step 17204	Loss 0.0898	Prec@(1,5) (97.1%, 100.0%)
06/26 03:34:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][300/391]	Step 17204	Loss 0.0896	Prec@(1,5) (97.1%, 100.0%)
06/26 03:34:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][350/391]	Step 17204	Loss 0.0900	Prec@(1,5) (97.0%, 100.0%)
06/26 03:34:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][390/391]	Step 17204	Loss 0.0904	Prec@(1,5) (97.0%, 100.0%)
06/26 03:34:36午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 21/24] Final Prec@1 97.0280%
06/26 03:34:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.0280%
06/26 03:34:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][50/781]	Step 17254	lr 0.00184	Loss 0.0848 (0.1056)	Prec@(1,5) (96.4%, 100.0%)	
06/26 03:34:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][100/781]	Step 17304	lr 0.00184	Loss 0.0768 (0.1114)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:34:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][150/781]	Step 17354	lr 0.00184	Loss 0.1424 (0.1124)	Prec@(1,5) (96.0%, 100.0%)	
06/26 03:34:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][200/781]	Step 17404	lr 0.00184	Loss 0.0832 (0.1100)	Prec@(1,5) (96.1%, 100.0%)	
06/26 03:34:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][250/781]	Step 17454	lr 0.00184	Loss 0.1358 (0.1089)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:34:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][300/781]	Step 17504	lr 0.00184	Loss 0.1197 (0.1106)	Prec@(1,5) (96.1%, 100.0%)	
06/26 03:34:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][350/781]	Step 17554	lr 0.00184	Loss 0.0784 (0.1084)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:35:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][400/781]	Step 17604	lr 0.00184	Loss 0.0671 (0.1087)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:35:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][450/781]	Step 17654	lr 0.00184	Loss 0.0312 (0.1076)	Prec@(1,5) (96.3%, 100.0%)	
06/26 03:35:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][500/781]	Step 17704	lr 0.00184	Loss 0.1834 (0.1074)	Prec@(1,5) (96.3%, 100.0%)	
06/26 03:35:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][550/781]	Step 17754	lr 0.00184	Loss 0.0994 (0.1085)	Prec@(1,5) (96.3%, 100.0%)	
06/26 03:35:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][600/781]	Step 17804	lr 0.00184	Loss 0.0559 (0.1079)	Prec@(1,5) (96.3%, 100.0%)	
06/26 03:35:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][650/781]	Step 17854	lr 0.00184	Loss 0.0957 (0.1078)	Prec@(1,5) (96.3%, 100.0%)	
06/26 03:35:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][700/781]	Step 17904	lr 0.00184	Loss 0.1166 (0.1087)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:35:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][750/781]	Step 17954	lr 0.00184	Loss 0.1198 (0.1094)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:35:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][781/781]	Step 17985	lr 0.00184	Loss 0.0821 (0.1096)	Prec@(1,5) (96.2%, 100.0%)	
06/26 03:35:24午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 22/24] Final Prec@1 96.2140%
06/26 03:35:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][50/391]	Step 17986	Loss 0.0748	Prec@(1,5) (97.7%, 100.0%)
06/26 03:35:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][100/391]	Step 17986	Loss 0.0742	Prec@(1,5) (97.7%, 100.0%)
06/26 03:35:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][150/391]	Step 17986	Loss 0.0736	Prec@(1,5) (97.7%, 100.0%)
06/26 03:35:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][200/391]	Step 17986	Loss 0.0730	Prec@(1,5) (97.7%, 100.0%)
06/26 03:35:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][250/391]	Step 17986	Loss 0.0734	Prec@(1,5) (97.6%, 100.0%)
06/26 03:35:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][300/391]	Step 17986	Loss 0.0748	Prec@(1,5) (97.6%, 100.0%)
06/26 03:35:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][350/391]	Step 17986	Loss 0.0763	Prec@(1,5) (97.5%, 100.0%)
06/26 03:35:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][390/391]	Step 17986	Loss 0.0769	Prec@(1,5) (97.5%, 100.0%)
06/26 03:35:29午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 22/24] Final Prec@1 97.5000%
06/26 03:35:30午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.5000%
06/26 03:35:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][50/781]	Step 18036	lr 0.00138	Loss 0.1821 (0.0985)	Prec@(1,5) (96.3%, 100.0%)	
06/26 03:35:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][100/781]	Step 18086	lr 0.00138	Loss 0.1904 (0.0973)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:35:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][150/781]	Step 18136	lr 0.00138	Loss 0.0485 (0.0956)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:35:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][200/781]	Step 18186	lr 0.00138	Loss 0.1701 (0.0986)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:35:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][250/781]	Step 18236	lr 0.00138	Loss 0.1201 (0.0986)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:35:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][300/781]	Step 18286	lr 0.00138	Loss 0.0487 (0.0994)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:35:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][350/781]	Step 18336	lr 0.00138	Loss 0.0489 (0.0984)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:35:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][400/781]	Step 18386	lr 0.00138	Loss 0.0464 (0.0975)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:35:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][450/781]	Step 18436	lr 0.00138	Loss 0.1554 (0.0976)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:36:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][500/781]	Step 18486	lr 0.00138	Loss 0.0722 (0.0972)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:36:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][550/781]	Step 18536	lr 0.00138	Loss 0.0486 (0.0973)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:36:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][600/781]	Step 18586	lr 0.00138	Loss 0.1160 (0.0975)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:36:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][650/781]	Step 18636	lr 0.00138	Loss 0.1457 (0.0977)	Prec@(1,5) (96.7%, 100.0%)	
06/26 03:36:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][700/781]	Step 18686	lr 0.00138	Loss 0.0365 (0.0982)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:36:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][750/781]	Step 18736	lr 0.00138	Loss 0.1104 (0.0985)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:36:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][781/781]	Step 18767	lr 0.00138	Loss 0.0716 (0.0988)	Prec@(1,5) (96.6%, 100.0%)	
06/26 03:36:18午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 23/24] Final Prec@1 96.5920%
06/26 03:36:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][50/391]	Step 18768	Loss 0.0654	Prec@(1,5) (97.6%, 100.0%)
06/26 03:36:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][100/391]	Step 18768	Loss 0.0723	Prec@(1,5) (97.5%, 100.0%)
06/26 03:36:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][150/391]	Step 18768	Loss 0.0699	Prec@(1,5) (97.5%, 100.0%)
06/26 03:36:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][200/391]	Step 18768	Loss 0.0684	Prec@(1,5) (97.6%, 100.0%)
06/26 03:36:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][250/391]	Step 18768	Loss 0.0691	Prec@(1,5) (97.6%, 100.0%)
06/26 03:36:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][300/391]	Step 18768	Loss 0.0682	Prec@(1,5) (97.7%, 100.0%)
06/26 03:36:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][350/391]	Step 18768	Loss 0.0686	Prec@(1,5) (97.6%, 100.0%)
06/26 03:36:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][390/391]	Step 18768	Loss 0.0681	Prec@(1,5) (97.7%, 100.0%)
06/26 03:36:23午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 23/24] Final Prec@1 97.6720%
06/26 03:36:23午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.6720%
06/26 03:36:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][50/781]	Step 18818	lr 0.00109	Loss 0.0841 (0.0804)	Prec@(1,5) (97.1%, 100.0%)	
06/26 03:36:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][100/781]	Step 18868	lr 0.00109	Loss 0.0989 (0.0880)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:36:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][150/781]	Step 18918	lr 0.00109	Loss 0.1411 (0.0875)	Prec@(1,5) (97.0%, 100.0%)	
06/26 03:36:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][200/781]	Step 18968	lr 0.00109	Loss 0.0534 (0.0871)	Prec@(1,5) (97.0%, 100.0%)	
06/26 03:36:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][250/781]	Step 19018	lr 0.00109	Loss 0.0687 (0.0883)	Prec@(1,5) (97.0%, 100.0%)	
06/26 03:36:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][300/781]	Step 19068	lr 0.00109	Loss 0.0670 (0.0888)	Prec@(1,5) (97.0%, 100.0%)	
06/26 03:36:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][350/781]	Step 19118	lr 0.00109	Loss 0.0448 (0.0892)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:36:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][400/781]	Step 19168	lr 0.00109	Loss 0.1018 (0.0885)	Prec@(1,5) (97.0%, 100.0%)	
06/26 03:36:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][450/781]	Step 19218	lr 0.00109	Loss 0.1692 (0.0886)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:36:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][500/781]	Step 19268	lr 0.00109	Loss 0.0552 (0.0900)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:36:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][550/781]	Step 19318	lr 0.00109	Loss 0.1219 (0.0903)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:36:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][600/781]	Step 19368	lr 0.00109	Loss 0.0630 (0.0904)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:37:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][650/781]	Step 19418	lr 0.00109	Loss 0.1848 (0.0895)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:37:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][700/781]	Step 19468	lr 0.00109	Loss 0.0698 (0.0887)	Prec@(1,5) (97.0%, 100.0%)	
06/26 03:37:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][750/781]	Step 19518	lr 0.00109	Loss 0.1554 (0.0892)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:37:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][781/781]	Step 19549	lr 0.00109	Loss 0.0508 (0.0891)	Prec@(1,5) (96.9%, 100.0%)	
06/26 03:37:10午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 24/24] Final Prec@1 96.9400%
06/26 03:37:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][50/391]	Step 19550	Loss 0.0633	Prec@(1,5) (98.0%, 100.0%)
06/26 03:37:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][100/391]	Step 19550	Loss 0.0616	Prec@(1,5) (98.1%, 100.0%)
06/26 03:37:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][150/391]	Step 19550	Loss 0.0596	Prec@(1,5) (98.1%, 100.0%)
06/26 03:37:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][200/391]	Step 19550	Loss 0.0594	Prec@(1,5) (98.1%, 100.0%)
06/26 03:37:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][250/391]	Step 19550	Loss 0.0592	Prec@(1,5) (98.1%, 100.0%)
06/26 03:37:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][300/391]	Step 19550	Loss 0.0611	Prec@(1,5) (98.0%, 100.0%)
06/26 03:37:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][350/391]	Step 19550	Loss 0.0611	Prec@(1,5) (98.0%, 100.0%)
06/26 03:37:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][390/391]	Step 19550	Loss 0.0614	Prec@(1,5) (98.0%, 100.0%)
06/26 03:37:15午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 24/24] Final Prec@1 97.9960%
06/26 03:37:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.9960%
06/26 03:37:16午後 finetuneTeacher_main.py:56 [INFO] Final best Prec@1 = 97.9960%
