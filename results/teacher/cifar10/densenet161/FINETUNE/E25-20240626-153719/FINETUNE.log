06/26 03:37:19PM parser.py:28 [INFO] 
06/26 03:37:19PM parser.py:29 [INFO] Parameters:
06/26 03:37:19PM parser.py:31 [INFO] BATCH_SIZE=64
06/26 03:37:19PM parser.py:31 [INFO] CUTOUT_LENGTH=0
06/26 03:37:19PM parser.py:31 [INFO] DATA_PATH=../data/
06/26 03:37:19PM parser.py:31 [INFO] DATASET=cifar10
06/26 03:37:19PM parser.py:31 [INFO] EPOCHS=25
06/26 03:37:19PM parser.py:31 [INFO] EXP_NAME=E25-20240626-153719
06/26 03:37:19PM parser.py:31 [INFO] GPUS=[0]
06/26 03:37:19PM parser.py:31 [INFO] LOCAL_RANK=0
06/26 03:37:19PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
06/26 03:37:19PM parser.py:31 [INFO] MODEL_NAME=densenet161
06/26 03:37:19PM parser.py:31 [INFO] NAME=FINETUNE
06/26 03:37:19PM parser.py:31 [INFO] PATH=results/teacher/cifar10/densenet161/FINETUNE/E25-20240626-153719
06/26 03:37:19PM parser.py:31 [INFO] PLOT_PATH=results/teacher/cifar10/densenet161/FINETUNE/E25-20240626-153719/plots
06/26 03:37:19PM parser.py:31 [INFO] PRINT_FREQ=50
06/26 03:37:19PM parser.py:31 [INFO] RESUME_PATH=None
06/26 03:37:19PM parser.py:31 [INFO] SAVE=E25
06/26 03:37:19PM parser.py:31 [INFO] SEED=0
06/26 03:37:19PM parser.py:31 [INFO] TRAIN_PORTION=1.0
06/26 03:37:19PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
06/26 03:37:19PM parser.py:31 [INFO] W_LR=0.025
06/26 03:37:19PM parser.py:31 [INFO] W_LR_MIN=0.001
06/26 03:37:19PM parser.py:31 [INFO] W_MOMENTUM=0.9
06/26 03:37:19PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
06/26 03:37:19PM parser.py:31 [INFO] WORKERS=4
06/26 03:37:19PM parser.py:32 [INFO] 
06/26 03:37:25PM finetuneTeacher_trainer.py:109 [INFO] --> No loaded checkpoint!
06/26 03:37:31PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][50/781]	Step 50	lr 0.025	Loss 1.8126 (1.9206)	Prec@(1,5) (35.3%, 81.3%)	
06/26 03:37:35PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][100/781]	Step 100	lr 0.025	Loss 1.7386 (1.7568)	Prec@(1,5) (43.3%, 87.1%)	
06/26 03:37:38PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][150/781]	Step 150	lr 0.025	Loss 2.6417 (1.7261)	Prec@(1,5) (46.4%, 88.8%)	
06/26 03:37:42PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][200/781]	Step 200	lr 0.025	Loss 1.5775 (1.7329)	Prec@(1,5) (47.6%, 89.5%)	
06/26 03:37:45PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][250/781]	Step 250	lr 0.025	Loss 1.3215 (1.7635)	Prec@(1,5) (48.9%, 90.3%)	
06/26 03:37:49PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][300/781]	Step 300	lr 0.025	Loss 1.5221 (1.7393)	Prec@(1,5) (49.7%, 90.7%)	
06/26 03:37:52PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][350/781]	Step 350	lr 0.025	Loss 1.9535 (1.7265)	Prec@(1,5) (50.5%, 91.2%)	
06/26 03:37:55PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][400/781]	Step 400	lr 0.025	Loss 1.2206 (1.6787)	Prec@(1,5) (51.8%, 91.7%)	
06/26 03:37:59PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][450/781]	Step 450	lr 0.025	Loss 1.1148 (1.6331)	Prec@(1,5) (52.7%, 92.2%)	
06/26 03:38:02PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][500/781]	Step 500	lr 0.025	Loss 1.1347 (1.5945)	Prec@(1,5) (53.8%, 92.5%)	
06/26 03:38:06PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][550/781]	Step 550	lr 0.025	Loss 0.9771 (1.5756)	Prec@(1,5) (54.7%, 92.9%)	
06/26 03:38:09PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][600/781]	Step 600	lr 0.025	Loss 1.1511 (1.5436)	Prec@(1,5) (55.5%, 93.2%)	
06/26 03:38:13PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][650/781]	Step 650	lr 0.025	Loss 0.7244 (1.5104)	Prec@(1,5) (56.3%, 93.4%)	
06/26 03:38:16PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][700/781]	Step 700	lr 0.025	Loss 0.9901 (1.4753)	Prec@(1,5) (57.2%, 93.7%)	
06/26 03:38:20PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][750/781]	Step 750	lr 0.025	Loss 1.0408 (1.4412)	Prec@(1,5) (57.9%, 93.9%)	
06/26 03:38:22PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][781/781]	Step 781	lr 0.025	Loss 0.6599 (1.4223)	Prec@(1,5) (58.3%, 94.1%)	
06/26 03:38:25PM finetuneTeacher_trainer.py:181 [INFO] Train: [  0/24] Final Prec@1 58.3320%
06/26 03:38:26PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][50/391]	Step 782	Loss 0.9096	Prec@(1,5) (70.0%, 97.7%)
06/26 03:38:27PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][100/391]	Step 782	Loss 0.8910	Prec@(1,5) (70.0%, 97.7%)
06/26 03:38:28PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][150/391]	Step 782	Loss 0.9209	Prec@(1,5) (70.1%, 97.9%)
06/26 03:38:29PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][200/391]	Step 782	Loss 0.9346	Prec@(1,5) (70.0%, 97.8%)
06/26 03:38:30PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][250/391]	Step 782	Loss 0.9379	Prec@(1,5) (69.7%, 97.8%)
06/26 03:38:31PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][300/391]	Step 782	Loss 0.9407	Prec@(1,5) (69.6%, 97.8%)
06/26 03:38:32PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][350/391]	Step 782	Loss 0.9364	Prec@(1,5) (69.8%, 97.8%)
06/26 03:38:33PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][390/391]	Step 782	Loss 0.9347	Prec@(1,5) (69.7%, 97.8%)
06/26 03:38:34PM finetuneTeacher_trainer.py:216 [INFO] Valid: [  0/24] Final Prec@1 69.7440%
06/26 03:38:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 69.7440%
06/26 03:38:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][50/781]	Step 832	lr 0.02491	Loss 0.8767 (0.9401)	Prec@(1,5) (68.8%, 96.8%)	
06/26 03:38:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][100/781]	Step 882	lr 0.02491	Loss 0.7114 (0.9379)	Prec@(1,5) (68.3%, 97.0%)	
06/26 03:38:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][150/781]	Step 932	lr 0.02491	Loss 0.9567 (0.9145)	Prec@(1,5) (69.2%, 97.2%)	
06/26 03:38:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][200/781]	Step 982	lr 0.02491	Loss 0.8096 (0.8976)	Prec@(1,5) (69.9%, 97.3%)	
06/26 03:38:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][250/781]	Step 1032	lr 0.02491	Loss 0.8855 (0.9056)	Prec@(1,5) (70.2%, 97.2%)	
06/26 03:39:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][300/781]	Step 1082	lr 0.02491	Loss 0.8159 (0.9043)	Prec@(1,5) (70.1%, 97.3%)	
06/26 03:39:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][350/781]	Step 1132	lr 0.02491	Loss 0.8183 (0.9019)	Prec@(1,5) (70.1%, 97.4%)	
06/26 03:39:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][400/781]	Step 1182	lr 0.02491	Loss 0.5542 (0.8984)	Prec@(1,5) (70.2%, 97.4%)	
06/26 03:39:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][450/781]	Step 1232	lr 0.02491	Loss 0.8889 (0.9076)	Prec@(1,5) (70.3%, 97.4%)	
06/26 03:39:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][500/781]	Step 1282	lr 0.02491	Loss 0.6804 (0.9037)	Prec@(1,5) (70.4%, 97.5%)	
06/26 03:39:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][550/781]	Step 1332	lr 0.02491	Loss 0.6184 (0.8995)	Prec@(1,5) (70.5%, 97.5%)	
06/26 03:39:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][600/781]	Step 1382	lr 0.02491	Loss 0.7796 (0.8902)	Prec@(1,5) (70.7%, 97.6%)	
06/26 03:39:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][650/781]	Step 1432	lr 0.02491	Loss 0.5912 (0.8822)	Prec@(1,5) (71.0%, 97.6%)	
06/26 03:39:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][700/781]	Step 1482	lr 0.02491	Loss 1.1371 (0.8745)	Prec@(1,5) (71.3%, 97.6%)	
06/26 03:39:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][750/781]	Step 1532	lr 0.02491	Loss 1.1125 (0.8683)	Prec@(1,5) (71.4%, 97.6%)	
06/26 03:39:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][781/781]	Step 1563	lr 0.02491	Loss 0.7809 (0.8650)	Prec@(1,5) (71.5%, 97.7%)	
06/26 03:39:40午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  1/24] Final Prec@1 71.4560%
06/26 03:39:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][50/391]	Step 1564	Loss 0.7752	Prec@(1,5) (74.2%, 98.7%)
06/26 03:39:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][100/391]	Step 1564	Loss 0.8063	Prec@(1,5) (73.5%, 98.5%)
06/26 03:39:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][150/391]	Step 1564	Loss 0.8044	Prec@(1,5) (73.7%, 98.5%)
06/26 03:39:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][200/391]	Step 1564	Loss 0.8032	Prec@(1,5) (73.9%, 98.4%)
06/26 03:39:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][250/391]	Step 1564	Loss 0.8081	Prec@(1,5) (73.7%, 98.4%)
06/26 03:39:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][300/391]	Step 1564	Loss 0.8079	Prec@(1,5) (73.7%, 98.4%)
06/26 03:39:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][350/391]	Step 1564	Loss 0.8051	Prec@(1,5) (73.9%, 98.4%)
06/26 03:39:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][390/391]	Step 1564	Loss 0.8040	Prec@(1,5) (74.0%, 98.4%)
06/26 03:39:48午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  1/24] Final Prec@1 73.9680%
06/26 03:39:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 73.9680%
06/26 03:39:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][50/781]	Step 1614	lr 0.02462	Loss 0.6568 (0.7048)	Prec@(1,5) (76.0%, 98.2%)	
06/26 03:39:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][100/781]	Step 1664	lr 0.02462	Loss 0.5946 (0.6772)	Prec@(1,5) (77.1%, 98.4%)	
06/26 03:40:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][150/781]	Step 1714	lr 0.02462	Loss 0.6092 (0.6687)	Prec@(1,5) (77.2%, 98.6%)	
06/26 03:40:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][200/781]	Step 1764	lr 0.02462	Loss 0.9474 (0.6679)	Prec@(1,5) (77.2%, 98.6%)	
06/26 03:40:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][250/781]	Step 1814	lr 0.02462	Loss 0.9570 (0.6719)	Prec@(1,5) (77.1%, 98.6%)	
06/26 03:40:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][300/781]	Step 1864	lr 0.02462	Loss 0.5838 (0.6861)	Prec@(1,5) (77.2%, 98.6%)	
06/26 03:40:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][350/781]	Step 1914	lr 0.02462	Loss 0.7475 (0.6837)	Prec@(1,5) (77.3%, 98.6%)	
06/26 03:40:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][400/781]	Step 1964	lr 0.02462	Loss 0.6419 (0.6826)	Prec@(1,5) (77.2%, 98.6%)	
06/26 03:40:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][450/781]	Step 2014	lr 0.02462	Loss 0.4629 (0.6873)	Prec@(1,5) (77.2%, 98.6%)	
06/26 03:40:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][500/781]	Step 2064	lr 0.02462	Loss 0.7052 (0.6841)	Prec@(1,5) (77.3%, 98.6%)	
06/26 03:40:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][550/781]	Step 2114	lr 0.02462	Loss 0.9886 (0.6865)	Prec@(1,5) (77.2%, 98.7%)	
06/26 03:40:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][600/781]	Step 2164	lr 0.02462	Loss 0.5560 (0.6839)	Prec@(1,5) (77.2%, 98.6%)	
06/26 03:40:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][650/781]	Step 2214	lr 0.02462	Loss 0.8309 (0.6804)	Prec@(1,5) (77.3%, 98.6%)	
06/26 03:40:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][700/781]	Step 2264	lr 0.02462	Loss 0.7364 (0.6743)	Prec@(1,5) (77.4%, 98.6%)	
06/26 03:40:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][750/781]	Step 2314	lr 0.02462	Loss 0.4457 (0.6685)	Prec@(1,5) (77.6%, 98.7%)	
06/26 03:40:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][781/781]	Step 2345	lr 0.02462	Loss 0.6223 (0.6638)	Prec@(1,5) (77.8%, 98.7%)	
06/26 03:40:53午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  2/24] Final Prec@1 77.7600%
06/26 03:40:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][50/391]	Step 2346	Loss 0.6319	Prec@(1,5) (78.2%, 99.2%)
06/26 03:40:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][100/391]	Step 2346	Loss 0.6337	Prec@(1,5) (78.7%, 99.1%)
06/26 03:40:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][150/391]	Step 2346	Loss 0.6373	Prec@(1,5) (78.9%, 99.1%)
06/26 03:40:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][200/391]	Step 2346	Loss 0.6396	Prec@(1,5) (78.9%, 99.0%)
06/26 03:40:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][250/391]	Step 2346	Loss 0.6343	Prec@(1,5) (78.9%, 99.1%)
06/26 03:40:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][300/391]	Step 2346	Loss 0.6427	Prec@(1,5) (78.7%, 99.0%)
06/26 03:41:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][350/391]	Step 2346	Loss 0.6441	Prec@(1,5) (78.7%, 99.0%)
06/26 03:41:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][390/391]	Step 2346	Loss 0.6402	Prec@(1,5) (78.8%, 99.0%)
06/26 03:41:01午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  2/24] Final Prec@1 78.7960%
06/26 03:41:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 78.7960%
06/26 03:41:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][50/781]	Step 2396	lr 0.02416	Loss 0.6601 (0.6129)	Prec@(1,5) (79.2%, 99.2%)	
06/26 03:41:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][100/781]	Step 2446	lr 0.02416	Loss 0.5270 (0.5949)	Prec@(1,5) (79.8%, 98.9%)	
06/26 03:41:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][150/781]	Step 2496	lr 0.02416	Loss 0.4745 (0.5848)	Prec@(1,5) (79.8%, 99.0%)	
06/26 03:41:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][200/781]	Step 2546	lr 0.02416	Loss 0.4457 (0.6145)	Prec@(1,5) (79.5%, 98.9%)	
06/26 03:41:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][250/781]	Step 2596	lr 0.02416	Loss 0.6288 (0.6089)	Prec@(1,5) (79.5%, 98.9%)	
06/26 03:41:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][300/781]	Step 2646	lr 0.02416	Loss 0.5808 (0.6071)	Prec@(1,5) (79.7%, 98.9%)	
06/26 03:41:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][350/781]	Step 2696	lr 0.02416	Loss 0.6000 (0.6123)	Prec@(1,5) (79.6%, 98.9%)	
06/26 03:41:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][400/781]	Step 2746	lr 0.02416	Loss 0.4648 (0.6075)	Prec@(1,5) (79.7%, 98.9%)	
06/26 03:41:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][450/781]	Step 2796	lr 0.02416	Loss 0.7543 (0.6048)	Prec@(1,5) (79.7%, 98.9%)	
06/26 03:41:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][500/781]	Step 2846	lr 0.02416	Loss 0.4990 (0.6026)	Prec@(1,5) (79.7%, 98.9%)	
06/26 03:41:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][550/781]	Step 2896	lr 0.02416	Loss 0.6779 (0.6016)	Prec@(1,5) (79.7%, 98.9%)	
06/26 03:41:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][600/781]	Step 2946	lr 0.02416	Loss 0.4442 (0.5979)	Prec@(1,5) (79.9%, 98.9%)	
06/26 03:41:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][650/781]	Step 2996	lr 0.02416	Loss 0.5367 (0.6011)	Prec@(1,5) (79.9%, 98.9%)	
06/26 03:41:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][700/781]	Step 3046	lr 0.02416	Loss 0.5440 (0.5978)	Prec@(1,5) (79.9%, 99.0%)	
06/26 03:42:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][750/781]	Step 3096	lr 0.02416	Loss 0.7548 (0.5984)	Prec@(1,5) (80.0%, 99.0%)	
06/26 03:42:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][781/781]	Step 3127	lr 0.02416	Loss 0.5803 (0.6066)	Prec@(1,5) (79.9%, 99.0%)	
06/26 03:42:05午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  3/24] Final Prec@1 79.9420%
06/26 03:42:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][50/391]	Step 3128	Loss 0.5299	Prec@(1,5) (81.8%, 99.2%)
06/26 03:42:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][100/391]	Step 3128	Loss 0.5351	Prec@(1,5) (81.9%, 99.1%)
06/26 03:42:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][150/391]	Step 3128	Loss 0.5290	Prec@(1,5) (82.1%, 99.2%)
06/26 03:42:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][200/391]	Step 3128	Loss 0.5350	Prec@(1,5) (81.9%, 99.1%)
06/26 03:42:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][250/391]	Step 3128	Loss 0.5388	Prec@(1,5) (82.2%, 99.1%)
06/26 03:42:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][300/391]	Step 3128	Loss 0.5313	Prec@(1,5) (82.3%, 99.1%)
06/26 03:42:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][350/391]	Step 3128	Loss 0.5339	Prec@(1,5) (82.3%, 99.1%)
06/26 03:42:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][390/391]	Step 3128	Loss 0.5332	Prec@(1,5) (82.3%, 99.1%)
06/26 03:42:14午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  3/24] Final Prec@1 82.3320%
06/26 03:42:15午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 82.3320%
06/26 03:42:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][50/781]	Step 3178	lr 0.02352	Loss 0.6360 (0.5670)	Prec@(1,5) (80.3%, 99.2%)	
06/26 03:42:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][100/781]	Step 3228	lr 0.02352	Loss 0.5841 (0.5546)	Prec@(1,5) (81.1%, 99.2%)	
06/26 03:42:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][150/781]	Step 3278	lr 0.02352	Loss 0.4910 (0.5750)	Prec@(1,5) (81.5%, 99.1%)	
06/26 03:42:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][200/781]	Step 3328	lr 0.02352	Loss 0.7479 (0.5757)	Prec@(1,5) (81.4%, 99.1%)	
06/26 03:42:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][250/781]	Step 3378	lr 0.02352	Loss 0.5919 (0.5700)	Prec@(1,5) (81.3%, 99.1%)	
06/26 03:42:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][300/781]	Step 3428	lr 0.02352	Loss 0.4079 (0.5647)	Prec@(1,5) (81.2%, 99.1%)	
06/26 03:42:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][350/781]	Step 3478	lr 0.02352	Loss 0.4203 (0.5639)	Prec@(1,5) (81.1%, 99.1%)	
06/26 03:42:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][400/781]	Step 3528	lr 0.02352	Loss 0.4032 (0.5569)	Prec@(1,5) (81.3%, 99.1%)	
06/26 03:42:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][450/781]	Step 3578	lr 0.02352	Loss 0.4970 (0.5640)	Prec@(1,5) (81.1%, 99.1%)	
06/26 03:42:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][500/781]	Step 3628	lr 0.02352	Loss 0.5090 (0.5587)	Prec@(1,5) (81.2%, 99.1%)	
06/26 03:43:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][550/781]	Step 3678	lr 0.02352	Loss 0.4900 (0.5555)	Prec@(1,5) (81.3%, 99.1%)	
06/26 03:43:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][600/781]	Step 3728	lr 0.02352	Loss 1.0879 (0.5540)	Prec@(1,5) (81.4%, 99.1%)	
06/26 03:43:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][650/781]	Step 3778	lr 0.02352	Loss 0.6222 (0.5550)	Prec@(1,5) (81.3%, 99.1%)	
06/26 03:43:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][700/781]	Step 3828	lr 0.02352	Loss 0.4006 (0.5506)	Prec@(1,5) (81.4%, 99.1%)	
06/26 03:43:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][750/781]	Step 3878	lr 0.02352	Loss 0.4275 (0.5537)	Prec@(1,5) (81.4%, 99.2%)	
06/26 03:43:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][781/781]	Step 3909	lr 0.02352	Loss 0.3436 (0.5521)	Prec@(1,5) (81.4%, 99.2%)	
06/26 03:43:18午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  4/24] Final Prec@1 81.3700%
06/26 03:43:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][50/391]	Step 3910	Loss 0.5245	Prec@(1,5) (81.7%, 99.2%)
06/26 03:43:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][100/391]	Step 3910	Loss 0.5099	Prec@(1,5) (82.3%, 99.2%)
06/26 03:43:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][150/391]	Step 3910	Loss 0.5143	Prec@(1,5) (82.2%, 99.1%)
06/26 03:43:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][200/391]	Step 3910	Loss 0.5116	Prec@(1,5) (82.4%, 99.1%)
06/26 03:43:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][250/391]	Step 3910	Loss 0.5099	Prec@(1,5) (82.4%, 99.1%)
06/26 03:43:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][300/391]	Step 3910	Loss 0.5102	Prec@(1,5) (82.4%, 99.1%)
06/26 03:43:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][350/391]	Step 3910	Loss 0.5065	Prec@(1,5) (82.5%, 99.2%)
06/26 03:43:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][390/391]	Step 3910	Loss 0.5072	Prec@(1,5) (82.5%, 99.1%)
06/26 03:43:26午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  4/24] Final Prec@1 82.5080%
06/26 03:43:27午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 82.5080%
06/26 03:43:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][50/781]	Step 3960	lr 0.02271	Loss 0.7114 (0.4575)	Prec@(1,5) (84.9%, 99.3%)	
06/26 03:43:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][100/781]	Step 4010	lr 0.02271	Loss 0.9364 (0.4908)	Prec@(1,5) (83.4%, 99.3%)	
06/26 03:43:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][150/781]	Step 4060	lr 0.02271	Loss 0.6010 (0.4943)	Prec@(1,5) (83.0%, 99.3%)	
06/26 03:43:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][200/781]	Step 4110	lr 0.02271	Loss 0.4523 (0.4913)	Prec@(1,5) (83.1%, 99.2%)	
06/26 03:43:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][250/781]	Step 4160	lr 0.02271	Loss 0.6472 (0.4936)	Prec@(1,5) (82.9%, 99.2%)	
06/26 03:43:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][300/781]	Step 4210	lr 0.02271	Loss 0.5839 (0.5062)	Prec@(1,5) (82.6%, 99.2%)	
06/26 03:43:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][350/781]	Step 4260	lr 0.02271	Loss 0.3892 (0.5105)	Prec@(1,5) (82.5%, 99.2%)	
06/26 03:44:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][400/781]	Step 4310	lr 0.02271	Loss 0.3103 (0.5123)	Prec@(1,5) (82.4%, 99.2%)	
06/26 03:44:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][450/781]	Step 4360	lr 0.02271	Loss 0.4516 (0.5064)	Prec@(1,5) (82.6%, 99.2%)	
06/26 03:44:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][500/781]	Step 4410	lr 0.02271	Loss 0.5341 (0.5041)	Prec@(1,5) (82.7%, 99.2%)	
06/26 03:44:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][550/781]	Step 4460	lr 0.02271	Loss 0.6289 (0.5023)	Prec@(1,5) (82.8%, 99.2%)	
06/26 03:44:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][600/781]	Step 4510	lr 0.02271	Loss 0.6083 (0.5046)	Prec@(1,5) (82.9%, 99.2%)	
06/26 03:44:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][650/781]	Step 4560	lr 0.02271	Loss 0.4441 (0.5060)	Prec@(1,5) (82.8%, 99.2%)	
06/26 03:44:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][700/781]	Step 4610	lr 0.02271	Loss 0.5889 (0.5041)	Prec@(1,5) (82.8%, 99.3%)	
06/26 03:44:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][750/781]	Step 4660	lr 0.02271	Loss 0.4655 (0.5036)	Prec@(1,5) (82.8%, 99.3%)	
06/26 03:44:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][781/781]	Step 4691	lr 0.02271	Loss 0.4480 (0.5023)	Prec@(1,5) (82.8%, 99.3%)	
06/26 03:44:31午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  5/24] Final Prec@1 82.8140%
06/26 03:44:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][50/391]	Step 4692	Loss 0.4564	Prec@(1,5) (84.0%, 99.6%)
06/26 03:44:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][100/391]	Step 4692	Loss 0.4513	Prec@(1,5) (84.2%, 99.4%)
06/26 03:44:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][150/391]	Step 4692	Loss 0.4478	Prec@(1,5) (84.1%, 99.4%)
06/26 03:44:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][200/391]	Step 4692	Loss 0.4448	Prec@(1,5) (84.5%, 99.4%)
06/26 03:44:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][250/391]	Step 4692	Loss 0.4424	Prec@(1,5) (84.6%, 99.5%)
06/26 03:44:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][300/391]	Step 4692	Loss 0.4396	Prec@(1,5) (84.7%, 99.4%)
06/26 03:44:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][350/391]	Step 4692	Loss 0.4434	Prec@(1,5) (84.6%, 99.4%)
06/26 03:44:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][390/391]	Step 4692	Loss 0.4432	Prec@(1,5) (84.5%, 99.5%)
06/26 03:44:39午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  5/24] Final Prec@1 84.5400%
06/26 03:44:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 84.5400%
06/26 03:44:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][50/781]	Step 4742	lr 0.02175	Loss 0.5853 (0.4958)	Prec@(1,5) (83.8%, 99.3%)	
06/26 03:44:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][100/781]	Step 4792	lr 0.02175	Loss 0.4487 (0.4775)	Prec@(1,5) (83.8%, 99.4%)	
06/26 03:44:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][150/781]	Step 4842	lr 0.02175	Loss 0.4886 (0.4650)	Prec@(1,5) (83.9%, 99.4%)	
06/26 03:44:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][200/781]	Step 4892	lr 0.02175	Loss 0.4793 (0.4615)	Prec@(1,5) (84.1%, 99.4%)	
06/26 03:45:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][250/781]	Step 4942	lr 0.02175	Loss 0.4581 (0.4580)	Prec@(1,5) (84.2%, 99.4%)	
06/26 03:45:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][300/781]	Step 4992	lr 0.02175	Loss 0.3883 (0.4575)	Prec@(1,5) (84.1%, 99.4%)	
06/26 03:45:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][350/781]	Step 5042	lr 0.02175	Loss 0.4054 (0.4598)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][400/781]	Step 5092	lr 0.02175	Loss 0.4341 (0.4602)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][450/781]	Step 5142	lr 0.02175	Loss 0.5910 (0.4611)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][500/781]	Step 5192	lr 0.02175	Loss 0.5844 (0.4613)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][550/781]	Step 5242	lr 0.02175	Loss 0.4924 (0.4621)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][600/781]	Step 5292	lr 0.02175	Loss 0.3502 (0.4615)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][650/781]	Step 5342	lr 0.02175	Loss 0.3919 (0.4614)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][700/781]	Step 5392	lr 0.02175	Loss 0.5588 (0.4641)	Prec@(1,5) (84.0%, 99.4%)	
06/26 03:45:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][750/781]	Step 5442	lr 0.02175	Loss 0.6442 (0.4648)	Prec@(1,5) (83.9%, 99.3%)	
06/26 03:45:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][781/781]	Step 5473	lr 0.02175	Loss 0.2964 (0.4641)	Prec@(1,5) (83.9%, 99.3%)	
06/26 03:45:43午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  6/24] Final Prec@1 83.9340%
06/26 03:45:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][50/391]	Step 5474	Loss 0.4274	Prec@(1,5) (85.6%, 99.7%)
06/26 03:45:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][100/391]	Step 5474	Loss 0.4215	Prec@(1,5) (85.5%, 99.6%)
06/26 03:45:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][150/391]	Step 5474	Loss 0.4178	Prec@(1,5) (85.6%, 99.6%)
06/26 03:45:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][200/391]	Step 5474	Loss 0.4247	Prec@(1,5) (85.3%, 99.5%)
06/26 03:45:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][250/391]	Step 5474	Loss 0.4239	Prec@(1,5) (85.4%, 99.5%)
06/26 03:45:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][300/391]	Step 5474	Loss 0.4282	Prec@(1,5) (85.2%, 99.5%)
06/26 03:45:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][350/391]	Step 5474	Loss 0.4287	Prec@(1,5) (85.2%, 99.5%)
06/26 03:45:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][390/391]	Step 5474	Loss 0.4260	Prec@(1,5) (85.2%, 99.5%)
06/26 03:45:51午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  6/24] Final Prec@1 85.2120%
06/26 03:45:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 85.2120%
06/26 03:45:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][50/781]	Step 5524	lr 0.02065	Loss 0.3675 (0.4186)	Prec@(1,5) (85.3%, 99.3%)	
06/26 03:46:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][100/781]	Step 5574	lr 0.02065	Loss 0.2833 (0.4261)	Prec@(1,5) (85.3%, 99.3%)	
06/26 03:46:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][150/781]	Step 5624	lr 0.02065	Loss 0.4743 (0.4201)	Prec@(1,5) (85.5%, 99.4%)	
06/26 03:46:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][200/781]	Step 5674	lr 0.02065	Loss 0.3447 (0.4176)	Prec@(1,5) (85.7%, 99.4%)	
06/26 03:46:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][250/781]	Step 5724	lr 0.02065	Loss 0.6145 (0.4206)	Prec@(1,5) (85.5%, 99.4%)	
06/26 03:46:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][300/781]	Step 5774	lr 0.02065	Loss 0.2757 (0.4211)	Prec@(1,5) (85.5%, 99.4%)	
06/26 03:46:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][350/781]	Step 5824	lr 0.02065	Loss 0.4075 (0.4320)	Prec@(1,5) (85.2%, 99.4%)	
06/26 03:46:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][400/781]	Step 5874	lr 0.02065	Loss 0.5833 (0.4347)	Prec@(1,5) (85.1%, 99.4%)	
06/26 03:46:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][450/781]	Step 5924	lr 0.02065	Loss 0.4151 (0.4344)	Prec@(1,5) (85.1%, 99.4%)	
06/26 03:46:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][500/781]	Step 5974	lr 0.02065	Loss 0.3343 (0.4337)	Prec@(1,5) (85.1%, 99.4%)	
06/26 03:46:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][550/781]	Step 6024	lr 0.02065	Loss 0.5259 (0.4336)	Prec@(1,5) (85.1%, 99.4%)	
06/26 03:46:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][600/781]	Step 6074	lr 0.02065	Loss 0.3935 (0.4392)	Prec@(1,5) (85.0%, 99.4%)	
06/26 03:46:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][650/781]	Step 6124	lr 0.02065	Loss 0.2787 (0.4401)	Prec@(1,5) (85.0%, 99.4%)	
06/26 03:46:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][700/781]	Step 6174	lr 0.02065	Loss 0.5506 (0.4414)	Prec@(1,5) (85.0%, 99.4%)	
06/26 03:46:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][750/781]	Step 6224	lr 0.02065	Loss 0.6817 (0.4410)	Prec@(1,5) (84.9%, 99.4%)	
06/26 03:46:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][781/781]	Step 6255	lr 0.02065	Loss 0.6614 (0.4412)	Prec@(1,5) (84.9%, 99.4%)	
06/26 03:46:55午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  7/24] Final Prec@1 84.8600%
06/26 03:46:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][50/391]	Step 6256	Loss 0.3877	Prec@(1,5) (86.7%, 99.6%)
06/26 03:46:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][100/391]	Step 6256	Loss 0.3921	Prec@(1,5) (86.2%, 99.7%)
06/26 03:46:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][150/391]	Step 6256	Loss 0.3816	Prec@(1,5) (86.7%, 99.7%)
06/26 03:46:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][200/391]	Step 6256	Loss 0.3871	Prec@(1,5) (86.5%, 99.7%)
06/26 03:47:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][250/391]	Step 6256	Loss 0.3875	Prec@(1,5) (86.5%, 99.7%)
06/26 03:47:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][300/391]	Step 6256	Loss 0.3867	Prec@(1,5) (86.5%, 99.7%)
06/26 03:47:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][350/391]	Step 6256	Loss 0.3841	Prec@(1,5) (86.6%, 99.7%)
06/26 03:47:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][390/391]	Step 6256	Loss 0.3813	Prec@(1,5) (86.6%, 99.7%)
06/26 03:47:03午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  7/24] Final Prec@1 86.6400%
06/26 03:47:04午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 86.6400%
06/26 03:47:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][50/781]	Step 6306	lr 0.01943	Loss 0.5189 (0.4147)	Prec@(1,5) (85.2%, 99.7%)	
06/26 03:47:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][100/781]	Step 6356	lr 0.01943	Loss 0.3939 (0.4140)	Prec@(1,5) (85.2%, 99.5%)	
06/26 03:47:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][150/781]	Step 6406	lr 0.01943	Loss 0.3630 (0.4137)	Prec@(1,5) (85.4%, 99.5%)	
06/26 03:47:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][200/781]	Step 6456	lr 0.01943	Loss 0.3115 (0.4117)	Prec@(1,5) (85.7%, 99.5%)	
06/26 03:47:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][250/781]	Step 6506	lr 0.01943	Loss 0.2705 (0.4089)	Prec@(1,5) (85.7%, 99.6%)	
06/26 03:47:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][300/781]	Step 6556	lr 0.01943	Loss 0.2424 (0.4031)	Prec@(1,5) (85.9%, 99.6%)	
06/26 03:47:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][350/781]	Step 6606	lr 0.01943	Loss 0.3511 (0.4053)	Prec@(1,5) (85.9%, 99.6%)	
06/26 03:47:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][400/781]	Step 6656	lr 0.01943	Loss 0.4575 (0.4080)	Prec@(1,5) (85.9%, 99.5%)	
06/26 03:47:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][450/781]	Step 6706	lr 0.01943	Loss 0.3688 (0.4083)	Prec@(1,5) (85.8%, 99.5%)	
06/26 03:47:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][500/781]	Step 6756	lr 0.01943	Loss 0.6853 (0.4105)	Prec@(1,5) (85.7%, 99.5%)	
06/26 03:47:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][550/781]	Step 6806	lr 0.01943	Loss 0.2687 (0.4100)	Prec@(1,5) (85.7%, 99.5%)	
06/26 03:47:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][600/781]	Step 6856	lr 0.01943	Loss 0.3165 (0.4078)	Prec@(1,5) (85.8%, 99.6%)	
06/26 03:47:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][650/781]	Step 6906	lr 0.01943	Loss 0.3388 (0.4084)	Prec@(1,5) (85.8%, 99.5%)	
06/26 03:48:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][700/781]	Step 6956	lr 0.01943	Loss 0.3222 (0.4074)	Prec@(1,5) (85.8%, 99.5%)	
06/26 03:48:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][750/781]	Step 7006	lr 0.01943	Loss 0.3007 (0.4089)	Prec@(1,5) (85.7%, 99.5%)	
06/26 03:48:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][781/781]	Step 7037	lr 0.01943	Loss 0.4196 (0.4071)	Prec@(1,5) (85.8%, 99.5%)	
06/26 03:48:08午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  8/24] Final Prec@1 85.8180%
06/26 03:48:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][50/391]	Step 7038	Loss 0.3352	Prec@(1,5) (88.4%, 99.5%)
06/26 03:48:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][100/391]	Step 7038	Loss 0.3420	Prec@(1,5) (88.4%, 99.6%)
06/26 03:48:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][150/391]	Step 7038	Loss 0.3392	Prec@(1,5) (88.4%, 99.7%)
06/26 03:48:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][200/391]	Step 7038	Loss 0.3347	Prec@(1,5) (88.6%, 99.7%)
06/26 03:48:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][250/391]	Step 7038	Loss 0.3366	Prec@(1,5) (88.5%, 99.7%)
06/26 03:48:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][300/391]	Step 7038	Loss 0.3338	Prec@(1,5) (88.7%, 99.7%)
06/26 03:48:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][350/391]	Step 7038	Loss 0.3306	Prec@(1,5) (88.8%, 99.7%)
06/26 03:48:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][390/391]	Step 7038	Loss 0.3297	Prec@(1,5) (88.8%, 99.7%)
06/26 03:48:17午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  8/24] Final Prec@1 88.7760%
06/26 03:48:17午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 88.7760%
06/26 03:48:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][50/781]	Step 7088	lr 0.01811	Loss 0.2785 (0.3307)	Prec@(1,5) (88.9%, 99.7%)	
06/26 03:48:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][100/781]	Step 7138	lr 0.01811	Loss 0.3386 (0.3440)	Prec@(1,5) (88.6%, 99.6%)	
06/26 03:48:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][150/781]	Step 7188	lr 0.01811	Loss 0.3366 (0.3456)	Prec@(1,5) (88.4%, 99.6%)	
06/26 03:48:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][200/781]	Step 7238	lr 0.01811	Loss 0.6032 (0.3520)	Prec@(1,5) (88.2%, 99.6%)	
06/26 03:48:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][250/781]	Step 7288	lr 0.01811	Loss 0.2679 (0.3559)	Prec@(1,5) (87.9%, 99.7%)	
06/26 03:48:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][300/781]	Step 7338	lr 0.01811	Loss 0.2258 (0.3548)	Prec@(1,5) (88.0%, 99.7%)	
06/26 03:48:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][350/781]	Step 7388	lr 0.01811	Loss 0.4667 (0.3583)	Prec@(1,5) (87.8%, 99.7%)	
06/26 03:48:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][400/781]	Step 7438	lr 0.01811	Loss 0.6374 (0.3615)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:48:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][450/781]	Step 7488	lr 0.01811	Loss 0.2110 (0.3616)	Prec@(1,5) (87.6%, 99.6%)	
06/26 03:48:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][500/781]	Step 7538	lr 0.01811	Loss 0.5163 (0.3653)	Prec@(1,5) (87.4%, 99.6%)	
06/26 03:49:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][550/781]	Step 7588	lr 0.01811	Loss 0.2916 (0.3681)	Prec@(1,5) (87.3%, 99.6%)	
06/26 03:49:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][600/781]	Step 7638	lr 0.01811	Loss 0.4031 (0.3700)	Prec@(1,5) (87.2%, 99.6%)	
06/26 03:49:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][650/781]	Step 7688	lr 0.01811	Loss 0.2436 (0.3718)	Prec@(1,5) (87.2%, 99.6%)	
06/26 03:49:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][700/781]	Step 7738	lr 0.01811	Loss 0.4948 (0.3742)	Prec@(1,5) (87.1%, 99.6%)	
06/26 03:49:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][750/781]	Step 7788	lr 0.01811	Loss 0.3591 (0.3755)	Prec@(1,5) (87.0%, 99.6%)	
06/26 03:49:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][781/781]	Step 7819	lr 0.01811	Loss 0.2747 (0.3759)	Prec@(1,5) (87.0%, 99.6%)	
06/26 03:49:20午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  9/24] Final Prec@1 86.9880%
06/26 03:49:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][50/391]	Step 7820	Loss 0.3733	Prec@(1,5) (86.9%, 99.6%)
06/26 03:49:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][100/391]	Step 7820	Loss 0.3707	Prec@(1,5) (87.0%, 99.6%)
06/26 03:49:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][150/391]	Step 7820	Loss 0.3685	Prec@(1,5) (87.0%, 99.6%)
06/26 03:49:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][200/391]	Step 7820	Loss 0.3666	Prec@(1,5) (87.0%, 99.6%)
06/26 03:49:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][250/391]	Step 7820	Loss 0.3656	Prec@(1,5) (87.1%, 99.6%)
06/26 03:49:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][300/391]	Step 7820	Loss 0.3634	Prec@(1,5) (87.2%, 99.6%)
06/26 03:49:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][350/391]	Step 7820	Loss 0.3602	Prec@(1,5) (87.3%, 99.7%)
06/26 03:49:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][390/391]	Step 7820	Loss 0.3597	Prec@(1,5) (87.3%, 99.7%)
06/26 03:49:28午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  9/24] Final Prec@1 87.2800%
06/26 03:49:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 88.7760%
06/26 03:49:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][50/781]	Step 7870	lr 0.01671	Loss 0.1887 (0.3235)	Prec@(1,5) (88.1%, 99.7%)	
06/26 03:49:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][100/781]	Step 7920	lr 0.01671	Loss 0.4443 (0.3282)	Prec@(1,5) (88.0%, 99.7%)	
06/26 03:49:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][150/781]	Step 7970	lr 0.01671	Loss 0.5862 (0.3408)	Prec@(1,5) (87.7%, 99.7%)	
06/26 03:49:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][200/781]	Step 8020	lr 0.01671	Loss 0.2753 (0.3368)	Prec@(1,5) (88.1%, 99.8%)	
06/26 03:49:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][250/781]	Step 8070	lr 0.01671	Loss 0.3700 (0.3446)	Prec@(1,5) (87.8%, 99.7%)	
06/26 03:49:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][300/781]	Step 8120	lr 0.01671	Loss 0.3862 (0.3456)	Prec@(1,5) (87.7%, 99.7%)	
06/26 03:49:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][350/781]	Step 8170	lr 0.01671	Loss 0.3931 (0.3462)	Prec@(1,5) (87.7%, 99.7%)	
06/26 03:50:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][400/781]	Step 8220	lr 0.01671	Loss 0.3050 (0.3506)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:50:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][450/781]	Step 8270	lr 0.01671	Loss 0.3816 (0.3531)	Prec@(1,5) (87.5%, 99.7%)	
06/26 03:50:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][500/781]	Step 8320	lr 0.01671	Loss 0.4955 (0.3524)	Prec@(1,5) (87.5%, 99.7%)	
06/26 03:50:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][550/781]	Step 8370	lr 0.01671	Loss 0.2968 (0.3508)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:50:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][600/781]	Step 8420	lr 0.01671	Loss 0.4832 (0.3512)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:50:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][650/781]	Step 8470	lr 0.01671	Loss 0.3854 (0.3499)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:50:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][700/781]	Step 8520	lr 0.01671	Loss 0.2347 (0.3482)	Prec@(1,5) (87.7%, 99.7%)	
06/26 03:50:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][750/781]	Step 8570	lr 0.01671	Loss 0.3381 (0.3498)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:50:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][781/781]	Step 8601	lr 0.01671	Loss 0.3178 (0.3509)	Prec@(1,5) (87.6%, 99.7%)	
06/26 03:50:30午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 10/24] Final Prec@1 87.6060%
06/26 03:50:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][50/391]	Step 8602	Loss 0.2988	Prec@(1,5) (89.1%, 99.7%)
06/26 03:50:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][100/391]	Step 8602	Loss 0.2974	Prec@(1,5) (89.2%, 99.8%)
06/26 03:50:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][150/391]	Step 8602	Loss 0.3054	Prec@(1,5) (89.1%, 99.8%)
06/26 03:50:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][200/391]	Step 8602	Loss 0.3071	Prec@(1,5) (89.0%, 99.8%)
06/26 03:50:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][250/391]	Step 8602	Loss 0.3113	Prec@(1,5) (88.9%, 99.8%)
06/26 03:50:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][300/391]	Step 8602	Loss 0.3096	Prec@(1,5) (89.0%, 99.8%)
06/26 03:50:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][350/391]	Step 8602	Loss 0.3099	Prec@(1,5) (89.0%, 99.8%)
06/26 03:50:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][390/391]	Step 8602	Loss 0.3078	Prec@(1,5) (89.0%, 99.8%)
06/26 03:50:38午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 10/24] Final Prec@1 89.0160%
06/26 03:50:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.0160%
06/26 03:50:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][50/781]	Step 8652	lr 0.01525	Loss 0.3333 (0.3384)	Prec@(1,5) (88.5%, 99.6%)	
06/26 03:50:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][100/781]	Step 8702	lr 0.01525	Loss 0.2984 (0.3345)	Prec@(1,5) (88.3%, 99.7%)	
06/26 03:50:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][150/781]	Step 8752	lr 0.01525	Loss 0.3362 (0.3218)	Prec@(1,5) (88.7%, 99.8%)	
06/26 03:50:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][200/781]	Step 8802	lr 0.01525	Loss 0.4569 (0.3239)	Prec@(1,5) (88.6%, 99.7%)	
06/26 03:51:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][250/781]	Step 8852	lr 0.01525	Loss 0.2729 (0.3264)	Prec@(1,5) (88.6%, 99.7%)	
06/26 03:51:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][300/781]	Step 8902	lr 0.01525	Loss 0.4585 (0.3252)	Prec@(1,5) (88.6%, 99.7%)	
06/26 03:51:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][350/781]	Step 8952	lr 0.01525	Loss 0.2366 (0.3243)	Prec@(1,5) (88.6%, 99.7%)	
06/26 03:51:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][400/781]	Step 9002	lr 0.01525	Loss 0.3158 (0.3263)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:51:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][450/781]	Step 9052	lr 0.01525	Loss 0.2703 (0.3272)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:51:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][500/781]	Step 9102	lr 0.01525	Loss 0.2704 (0.3269)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:51:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][550/781]	Step 9152	lr 0.01525	Loss 0.2746 (0.3286)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:51:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][600/781]	Step 9202	lr 0.01525	Loss 0.2862 (0.3308)	Prec@(1,5) (88.5%, 99.7%)	
06/26 03:51:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][650/781]	Step 9252	lr 0.01525	Loss 0.2074 (0.3320)	Prec@(1,5) (88.4%, 99.7%)	
06/26 03:51:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][700/781]	Step 9302	lr 0.01525	Loss 0.2440 (0.3312)	Prec@(1,5) (88.4%, 99.7%)	
06/26 03:51:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][750/781]	Step 9352	lr 0.01525	Loss 0.3992 (0.3314)	Prec@(1,5) (88.4%, 99.7%)	
06/26 03:51:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][781/781]	Step 9383	lr 0.01525	Loss 0.3370 (0.3315)	Prec@(1,5) (88.4%, 99.7%)	
06/26 03:51:40午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 11/24] Final Prec@1 88.4160%
06/26 03:51:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][50/391]	Step 9384	Loss 0.2852	Prec@(1,5) (90.3%, 99.9%)
06/26 03:51:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][100/391]	Step 9384	Loss 0.2716	Prec@(1,5) (90.8%, 99.9%)
06/26 03:51:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][150/391]	Step 9384	Loss 0.2784	Prec@(1,5) (90.4%, 99.8%)
06/26 03:51:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][200/391]	Step 9384	Loss 0.2793	Prec@(1,5) (90.4%, 99.8%)
06/26 03:51:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][250/391]	Step 9384	Loss 0.2810	Prec@(1,5) (90.3%, 99.8%)
06/26 03:51:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][300/391]	Step 9384	Loss 0.2809	Prec@(1,5) (90.4%, 99.8%)
06/26 03:51:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][350/391]	Step 9384	Loss 0.2829	Prec@(1,5) (90.3%, 99.8%)
06/26 03:51:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][390/391]	Step 9384	Loss 0.2838	Prec@(1,5) (90.2%, 99.8%)
06/26 03:51:48午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 11/24] Final Prec@1 90.2000%
06/26 03:51:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 90.2000%
06/26 03:51:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][50/781]	Step 9434	lr 0.01375	Loss 0.3622 (0.2908)	Prec@(1,5) (90.0%, 99.7%)	
06/26 03:51:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][100/781]	Step 9484	lr 0.01375	Loss 0.3293 (0.2959)	Prec@(1,5) (89.8%, 99.7%)	
06/26 03:52:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][150/781]	Step 9534	lr 0.01375	Loss 0.2075 (0.3062)	Prec@(1,5) (89.4%, 99.7%)	
06/26 03:52:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][200/781]	Step 9584	lr 0.01375	Loss 0.2785 (0.3029)	Prec@(1,5) (89.5%, 99.7%)	
06/26 03:52:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][250/781]	Step 9634	lr 0.01375	Loss 0.2901 (0.3053)	Prec@(1,5) (89.3%, 99.7%)	
06/26 03:52:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][300/781]	Step 9684	lr 0.01375	Loss 0.2223 (0.3013)	Prec@(1,5) (89.5%, 99.7%)	
06/26 03:52:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][350/781]	Step 9734	lr 0.01375	Loss 0.2676 (0.3007)	Prec@(1,5) (89.4%, 99.7%)	
06/26 03:52:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][400/781]	Step 9784	lr 0.01375	Loss 0.2656 (0.3014)	Prec@(1,5) (89.3%, 99.8%)	
06/26 03:52:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][450/781]	Step 9834	lr 0.01375	Loss 0.2426 (0.3046)	Prec@(1,5) (89.3%, 99.8%)	
06/26 03:52:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][500/781]	Step 9884	lr 0.01375	Loss 0.4551 (0.3059)	Prec@(1,5) (89.3%, 99.8%)	
06/26 03:52:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][550/781]	Step 9934	lr 0.01375	Loss 0.1817 (0.3080)	Prec@(1,5) (89.2%, 99.8%)	
06/26 03:52:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][600/781]	Step 9984	lr 0.01375	Loss 0.2293 (0.3100)	Prec@(1,5) (89.1%, 99.8%)	
06/26 03:52:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][650/781]	Step 10034	lr 0.01375	Loss 0.2812 (0.3102)	Prec@(1,5) (89.1%, 99.8%)	
06/26 03:52:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][700/781]	Step 10084	lr 0.01375	Loss 0.3382 (0.3090)	Prec@(1,5) (89.1%, 99.8%)	
06/26 03:52:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][750/781]	Step 10134	lr 0.01375	Loss 0.4975 (0.3086)	Prec@(1,5) (89.1%, 99.8%)	
06/26 03:52:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][781/781]	Step 10165	lr 0.01375	Loss 0.3320 (0.3091)	Prec@(1,5) (89.1%, 99.7%)	
06/26 03:52:54午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 12/24] Final Prec@1 89.1240%
06/26 03:52:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][50/391]	Step 10166	Loss 0.2891	Prec@(1,5) (89.5%, 99.9%)
06/26 03:52:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][100/391]	Step 10166	Loss 0.2846	Prec@(1,5) (90.0%, 99.8%)
06/26 03:52:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][150/391]	Step 10166	Loss 0.2880	Prec@(1,5) (89.8%, 99.8%)
06/26 03:52:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][200/391]	Step 10166	Loss 0.2888	Prec@(1,5) (89.9%, 99.8%)
06/26 03:52:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][250/391]	Step 10166	Loss 0.2888	Prec@(1,5) (89.8%, 99.8%)
06/26 03:53:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][300/391]	Step 10166	Loss 0.2885	Prec@(1,5) (89.8%, 99.8%)
06/26 03:53:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][350/391]	Step 10166	Loss 0.2877	Prec@(1,5) (89.9%, 99.8%)
06/26 03:53:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][390/391]	Step 10166	Loss 0.2894	Prec@(1,5) (89.9%, 99.8%)
06/26 03:53:02午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 12/24] Final Prec@1 89.8480%
06/26 03:53:02午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 90.2000%
06/26 03:53:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][50/781]	Step 10216	lr 0.01225	Loss 0.1858 (0.2779)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:53:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][100/781]	Step 10266	lr 0.01225	Loss 0.3169 (0.2737)	Prec@(1,5) (90.5%, 99.8%)	
06/26 03:53:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][150/781]	Step 10316	lr 0.01225	Loss 0.3288 (0.2694)	Prec@(1,5) (90.5%, 99.9%)	
06/26 03:53:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][200/781]	Step 10366	lr 0.01225	Loss 0.2929 (0.2702)	Prec@(1,5) (90.4%, 99.9%)	
06/26 03:53:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][250/781]	Step 10416	lr 0.01225	Loss 0.2792 (0.2756)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:53:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][300/781]	Step 10466	lr 0.01225	Loss 0.1930 (0.2779)	Prec@(1,5) (90.1%, 99.8%)	
06/26 03:53:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][350/781]	Step 10516	lr 0.01225	Loss 0.3899 (0.2771)	Prec@(1,5) (90.1%, 99.8%)	
06/26 03:53:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][400/781]	Step 10566	lr 0.01225	Loss 0.2357 (0.2782)	Prec@(1,5) (90.1%, 99.8%)	
06/26 03:53:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][450/781]	Step 10616	lr 0.01225	Loss 0.3450 (0.2781)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:53:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][500/781]	Step 10666	lr 0.01225	Loss 0.2202 (0.2788)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:53:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][550/781]	Step 10716	lr 0.01225	Loss 0.2024 (0.2761)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:53:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][600/781]	Step 10766	lr 0.01225	Loss 0.2058 (0.2749)	Prec@(1,5) (90.3%, 99.8%)	
06/26 03:53:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][650/781]	Step 10816	lr 0.01225	Loss 0.2670 (0.2758)	Prec@(1,5) (90.2%, 99.9%)	
06/26 03:54:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][700/781]	Step 10866	lr 0.01225	Loss 0.4675 (0.2793)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:54:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][750/781]	Step 10916	lr 0.01225	Loss 0.4332 (0.2795)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:54:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][781/781]	Step 10947	lr 0.01225	Loss 0.3979 (0.2787)	Prec@(1,5) (90.2%, 99.8%)	
06/26 03:54:07午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 13/24] Final Prec@1 90.1960%
06/26 03:54:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][50/391]	Step 10948	Loss 0.2390	Prec@(1,5) (91.1%, 99.8%)
06/26 03:54:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][100/391]	Step 10948	Loss 0.2354	Prec@(1,5) (91.6%, 99.9%)
06/26 03:54:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][150/391]	Step 10948	Loss 0.2442	Prec@(1,5) (91.5%, 99.8%)
06/26 03:54:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][200/391]	Step 10948	Loss 0.2453	Prec@(1,5) (91.6%, 99.8%)
06/26 03:54:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][250/391]	Step 10948	Loss 0.2440	Prec@(1,5) (91.5%, 99.8%)
06/26 03:54:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][300/391]	Step 10948	Loss 0.2401	Prec@(1,5) (91.6%, 99.8%)
06/26 03:54:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][350/391]	Step 10948	Loss 0.2401	Prec@(1,5) (91.7%, 99.9%)
06/26 03:54:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][390/391]	Step 10948	Loss 0.2398	Prec@(1,5) (91.7%, 99.9%)
06/26 03:54:15午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 13/24] Final Prec@1 91.6800%
06/26 03:54:15午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 91.6800%
06/26 03:54:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][50/781]	Step 10998	lr 0.01075	Loss 0.2885 (0.2508)	Prec@(1,5) (90.9%, 99.8%)	
06/26 03:54:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][100/781]	Step 11048	lr 0.01075	Loss 0.1776 (0.2420)	Prec@(1,5) (91.5%, 99.8%)	
06/26 03:54:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][150/781]	Step 11098	lr 0.01075	Loss 0.2805 (0.2406)	Prec@(1,5) (91.6%, 99.8%)	
06/26 03:54:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][200/781]	Step 11148	lr 0.01075	Loss 0.2142 (0.2441)	Prec@(1,5) (91.5%, 99.8%)	
06/26 03:54:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][250/781]	Step 11198	lr 0.01075	Loss 0.2625 (0.2480)	Prec@(1,5) (91.2%, 99.8%)	
06/26 03:54:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][300/781]	Step 11248	lr 0.01075	Loss 0.3069 (0.2506)	Prec@(1,5) (91.0%, 99.8%)	
06/26 03:54:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][350/781]	Step 11298	lr 0.01075	Loss 0.3401 (0.2522)	Prec@(1,5) (91.0%, 99.8%)	
06/26 03:54:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][400/781]	Step 11348	lr 0.01075	Loss 0.1933 (0.2541)	Prec@(1,5) (91.0%, 99.8%)	
06/26 03:54:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][450/781]	Step 11398	lr 0.01075	Loss 0.2524 (0.2553)	Prec@(1,5) (90.9%, 99.8%)	
06/26 03:54:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][500/781]	Step 11448	lr 0.01075	Loss 0.2132 (0.2562)	Prec@(1,5) (90.9%, 99.8%)	
06/26 03:55:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][550/781]	Step 11498	lr 0.01075	Loss 0.1928 (0.2557)	Prec@(1,5) (90.9%, 99.8%)	
06/26 03:55:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][600/781]	Step 11548	lr 0.01075	Loss 0.3195 (0.2569)	Prec@(1,5) (90.8%, 99.8%)	
06/26 03:55:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][650/781]	Step 11598	lr 0.01075	Loss 0.2363 (0.2573)	Prec@(1,5) (90.8%, 99.8%)	
06/26 03:55:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][700/781]	Step 11648	lr 0.01075	Loss 0.3755 (0.2579)	Prec@(1,5) (90.8%, 99.8%)	
06/26 03:55:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][750/781]	Step 11698	lr 0.01075	Loss 0.1217 (0.2568)	Prec@(1,5) (90.8%, 99.8%)	
06/26 03:55:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][781/781]	Step 11729	lr 0.01075	Loss 0.1302 (0.2561)	Prec@(1,5) (90.8%, 99.8%)	
06/26 03:55:17午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 14/24] Final Prec@1 90.8460%
06/26 03:55:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][50/391]	Step 11730	Loss 0.1828	Prec@(1,5) (93.9%, 100.0%)
06/26 03:55:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][100/391]	Step 11730	Loss 0.1826	Prec@(1,5) (93.9%, 100.0%)
06/26 03:55:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][150/391]	Step 11730	Loss 0.1931	Prec@(1,5) (93.4%, 99.9%)
06/26 03:55:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][200/391]	Step 11730	Loss 0.1893	Prec@(1,5) (93.5%, 99.9%)
06/26 03:55:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][250/391]	Step 11730	Loss 0.1886	Prec@(1,5) (93.5%, 99.9%)
06/26 03:55:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][300/391]	Step 11730	Loss 0.1893	Prec@(1,5) (93.4%, 99.9%)
06/26 03:55:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][350/391]	Step 11730	Loss 0.1905	Prec@(1,5) (93.4%, 99.9%)
06/26 03:55:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][390/391]	Step 11730	Loss 0.1889	Prec@(1,5) (93.4%, 99.9%)
06/26 03:55:26午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 14/24] Final Prec@1 93.4480%
06/26 03:55:27午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.4480%
06/26 03:55:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][50/781]	Step 11780	lr 0.00929	Loss 0.1360 (0.2050)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:55:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][100/781]	Step 11830	lr 0.00929	Loss 0.1074 (0.1969)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:55:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][150/781]	Step 11880	lr 0.00929	Loss 0.2795 (0.1997)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:55:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][200/781]	Step 11930	lr 0.00929	Loss 0.1729 (0.2067)	Prec@(1,5) (92.8%, 99.9%)	
06/26 03:55:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][250/781]	Step 11980	lr 0.00929	Loss 0.1755 (0.2119)	Prec@(1,5) (92.6%, 99.9%)	
06/26 03:55:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][300/781]	Step 12030	lr 0.00929	Loss 0.2556 (0.2141)	Prec@(1,5) (92.4%, 99.9%)	
06/26 03:55:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][350/781]	Step 12080	lr 0.00929	Loss 0.2014 (0.2168)	Prec@(1,5) (92.3%, 99.9%)	
06/26 03:56:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][400/781]	Step 12130	lr 0.00929	Loss 0.1894 (0.2179)	Prec@(1,5) (92.3%, 99.9%)	
06/26 03:56:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][450/781]	Step 12180	lr 0.00929	Loss 0.2582 (0.2199)	Prec@(1,5) (92.2%, 99.9%)	
06/26 03:56:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][500/781]	Step 12230	lr 0.00929	Loss 0.2197 (0.2222)	Prec@(1,5) (92.1%, 99.9%)	
06/26 03:56:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][550/781]	Step 12280	lr 0.00929	Loss 0.1444 (0.2226)	Prec@(1,5) (92.1%, 99.9%)	
06/26 03:56:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][600/781]	Step 12330	lr 0.00929	Loss 0.1511 (0.2227)	Prec@(1,5) (92.1%, 99.9%)	
06/26 03:56:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][650/781]	Step 12380	lr 0.00929	Loss 0.4107 (0.2259)	Prec@(1,5) (92.0%, 99.9%)	
06/26 03:56:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][700/781]	Step 12430	lr 0.00929	Loss 0.2322 (0.2269)	Prec@(1,5) (92.0%, 99.9%)	
06/26 03:56:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][750/781]	Step 12480	lr 0.00929	Loss 0.2373 (0.2285)	Prec@(1,5) (91.9%, 99.9%)	
06/26 03:56:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][781/781]	Step 12511	lr 0.00929	Loss 0.2426 (0.2281)	Prec@(1,5) (91.9%, 99.9%)	
06/26 03:56:31午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 15/24] Final Prec@1 91.9440%
06/26 03:56:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][50/391]	Step 12512	Loss 0.1835	Prec@(1,5) (93.1%, 100.0%)
06/26 03:56:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][100/391]	Step 12512	Loss 0.1808	Prec@(1,5) (93.3%, 100.0%)
06/26 03:56:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][150/391]	Step 12512	Loss 0.1816	Prec@(1,5) (93.5%, 100.0%)
06/26 03:56:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][200/391]	Step 12512	Loss 0.1791	Prec@(1,5) (93.6%, 100.0%)
06/26 03:56:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][250/391]	Step 12512	Loss 0.1797	Prec@(1,5) (93.6%, 99.9%)
06/26 03:56:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][300/391]	Step 12512	Loss 0.1811	Prec@(1,5) (93.6%, 99.9%)
06/26 03:56:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][350/391]	Step 12512	Loss 0.1839	Prec@(1,5) (93.5%, 99.9%)
06/26 03:56:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][390/391]	Step 12512	Loss 0.1836	Prec@(1,5) (93.5%, 99.9%)
06/26 03:56:40午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 15/24] Final Prec@1 93.5360%
06/26 03:56:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.5360%
06/26 03:56:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][50/781]	Step 12562	lr 0.00789	Loss 0.0697 (0.2017)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:56:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][100/781]	Step 12612	lr 0.00789	Loss 0.2998 (0.1911)	Prec@(1,5) (93.4%, 99.9%)	
06/26 03:56:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][150/781]	Step 12662	lr 0.00789	Loss 0.2178 (0.1882)	Prec@(1,5) (93.6%, 99.9%)	
06/26 03:56:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][200/781]	Step 12712	lr 0.00789	Loss 0.3832 (0.1911)	Prec@(1,5) (93.4%, 99.9%)	
06/26 03:56:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][250/781]	Step 12762	lr 0.00789	Loss 0.1365 (0.1908)	Prec@(1,5) (93.3%, 99.9%)	
06/26 03:57:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][300/781]	Step 12812	lr 0.00789	Loss 0.3013 (0.1908)	Prec@(1,5) (93.3%, 99.9%)	
06/26 03:57:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][350/781]	Step 12862	lr 0.00789	Loss 0.2833 (0.1928)	Prec@(1,5) (93.2%, 99.9%)	
06/26 03:57:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][400/781]	Step 12912	lr 0.00789	Loss 0.1724 (0.1947)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:57:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][450/781]	Step 12962	lr 0.00789	Loss 0.0810 (0.1948)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:57:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][500/781]	Step 13012	lr 0.00789	Loss 0.2224 (0.1961)	Prec@(1,5) (93.1%, 99.9%)	
06/26 03:57:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][550/781]	Step 13062	lr 0.00789	Loss 0.3531 (0.1983)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:57:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][600/781]	Step 13112	lr 0.00789	Loss 0.1313 (0.1987)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:57:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][650/781]	Step 13162	lr 0.00789	Loss 0.1786 (0.1988)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:57:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][700/781]	Step 13212	lr 0.00789	Loss 0.1641 (0.1978)	Prec@(1,5) (93.0%, 99.9%)	
06/26 03:57:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][750/781]	Step 13262	lr 0.00789	Loss 0.1326 (0.1998)	Prec@(1,5) (92.9%, 99.9%)	
06/26 03:57:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][781/781]	Step 13293	lr 0.00789	Loss 0.1336 (0.2002)	Prec@(1,5) (92.9%, 99.9%)	
06/26 03:57:42午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 16/24] Final Prec@1 92.9280%
06/26 03:57:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][50/391]	Step 13294	Loss 0.1560	Prec@(1,5) (94.5%, 100.0%)
06/26 03:57:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][100/391]	Step 13294	Loss 0.1540	Prec@(1,5) (95.0%, 100.0%)
06/26 03:57:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][150/391]	Step 13294	Loss 0.1507	Prec@(1,5) (94.9%, 100.0%)
06/26 03:57:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][200/391]	Step 13294	Loss 0.1517	Prec@(1,5) (94.9%, 100.0%)
06/26 03:57:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][250/391]	Step 13294	Loss 0.1542	Prec@(1,5) (94.8%, 100.0%)
06/26 03:57:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][300/391]	Step 13294	Loss 0.1548	Prec@(1,5) (94.7%, 100.0%)
06/26 03:57:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][350/391]	Step 13294	Loss 0.1541	Prec@(1,5) (94.8%, 100.0%)
06/26 03:57:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][390/391]	Step 13294	Loss 0.1542	Prec@(1,5) (94.8%, 100.0%)
06/26 03:57:50午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 16/24] Final Prec@1 94.7920%
06/26 03:57:51午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 94.7920%
06/26 03:57:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][50/781]	Step 13344	lr 0.00657	Loss 0.2385 (0.1729)	Prec@(1,5) (94.4%, 99.9%)	
06/26 03:58:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][100/781]	Step 13394	lr 0.00657	Loss 0.1312 (0.1704)	Prec@(1,5) (94.2%, 99.9%)	
06/26 03:58:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][150/781]	Step 13444	lr 0.00657	Loss 0.1786 (0.1726)	Prec@(1,5) (94.0%, 100.0%)	
06/26 03:58:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][200/781]	Step 13494	lr 0.00657	Loss 0.2345 (0.1715)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:58:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][250/781]	Step 13544	lr 0.00657	Loss 0.1698 (0.1732)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:58:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][300/781]	Step 13594	lr 0.00657	Loss 0.1482 (0.1741)	Prec@(1,5) (93.8%, 100.0%)	
06/26 03:58:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][350/781]	Step 13644	lr 0.00657	Loss 0.1541 (0.1738)	Prec@(1,5) (93.8%, 100.0%)	
06/26 03:58:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][400/781]	Step 13694	lr 0.00657	Loss 0.1509 (0.1730)	Prec@(1,5) (93.8%, 100.0%)	
06/26 03:58:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][450/781]	Step 13744	lr 0.00657	Loss 0.1773 (0.1717)	Prec@(1,5) (93.9%, 100.0%)	
06/26 03:58:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][500/781]	Step 13794	lr 0.00657	Loss 0.1018 (0.1710)	Prec@(1,5) (93.9%, 100.0%)	
06/26 03:58:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][550/781]	Step 13844	lr 0.00657	Loss 0.2268 (0.1715)	Prec@(1,5) (93.9%, 100.0%)	
06/26 03:58:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][600/781]	Step 13894	lr 0.00657	Loss 0.2081 (0.1716)	Prec@(1,5) (93.9%, 100.0%)	
06/26 03:58:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][650/781]	Step 13944	lr 0.00657	Loss 0.1460 (0.1715)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:58:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][700/781]	Step 13994	lr 0.00657	Loss 0.0819 (0.1725)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:58:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][750/781]	Step 14044	lr 0.00657	Loss 0.2129 (0.1718)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:58:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][781/781]	Step 14075	lr 0.00657	Loss 0.1477 (0.1716)	Prec@(1,5) (93.9%, 99.9%)	
06/26 03:58:57午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 17/24] Final Prec@1 93.8760%
06/26 03:58:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][50/391]	Step 14076	Loss 0.1059	Prec@(1,5) (96.4%, 100.0%)
06/26 03:58:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][100/391]	Step 14076	Loss 0.1164	Prec@(1,5) (96.0%, 100.0%)
06/26 03:59:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][150/391]	Step 14076	Loss 0.1223	Prec@(1,5) (95.8%, 99.9%)
06/26 03:59:01午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][200/391]	Step 14076	Loss 0.1201	Prec@(1,5) (95.9%, 100.0%)
06/26 03:59:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][250/391]	Step 14076	Loss 0.1201	Prec@(1,5) (95.8%, 100.0%)
06/26 03:59:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][300/391]	Step 14076	Loss 0.1204	Prec@(1,5) (95.8%, 100.0%)
06/26 03:59:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][350/391]	Step 14076	Loss 0.1202	Prec@(1,5) (95.8%, 100.0%)
06/26 03:59:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][390/391]	Step 14076	Loss 0.1202	Prec@(1,5) (95.8%, 100.0%)
06/26 03:59:05午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 17/24] Final Prec@1 95.8520%
06/26 03:59:06午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 95.8520%
06/26 03:59:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][50/781]	Step 14126	lr 0.00535	Loss 0.1693 (0.1353)	Prec@(1,5) (95.5%, 100.0%)	
06/26 03:59:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][100/781]	Step 14176	lr 0.00535	Loss 0.1133 (0.1389)	Prec@(1,5) (95.3%, 100.0%)	
06/26 03:59:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][150/781]	Step 14226	lr 0.00535	Loss 0.2130 (0.1417)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:59:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][200/781]	Step 14276	lr 0.00535	Loss 0.1425 (0.1426)	Prec@(1,5) (95.2%, 99.9%)	
06/26 03:59:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][250/781]	Step 14326	lr 0.00535	Loss 0.0560 (0.1423)	Prec@(1,5) (95.1%, 100.0%)	
06/26 03:59:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][300/781]	Step 14376	lr 0.00535	Loss 0.1712 (0.1404)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:59:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][350/781]	Step 14426	lr 0.00535	Loss 0.1274 (0.1407)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:59:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][400/781]	Step 14476	lr 0.00535	Loss 0.1927 (0.1397)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:59:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][450/781]	Step 14526	lr 0.00535	Loss 0.1225 (0.1393)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:59:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][500/781]	Step 14576	lr 0.00535	Loss 0.1694 (0.1397)	Prec@(1,5) (95.2%, 100.0%)	
06/26 03:59:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][550/781]	Step 14626	lr 0.00535	Loss 0.1380 (0.1415)	Prec@(1,5) (95.1%, 100.0%)	
06/26 03:59:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][600/781]	Step 14676	lr 0.00535	Loss 0.1483 (0.1436)	Prec@(1,5) (95.1%, 100.0%)	
06/26 03:59:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][650/781]	Step 14726	lr 0.00535	Loss 0.1838 (0.1449)	Prec@(1,5) (95.0%, 100.0%)	
06/26 04:00:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][700/781]	Step 14776	lr 0.00535	Loss 0.1323 (0.1458)	Prec@(1,5) (95.0%, 100.0%)	
06/26 04:00:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][750/781]	Step 14826	lr 0.00535	Loss 0.2586 (0.1474)	Prec@(1,5) (94.9%, 100.0%)	
06/26 04:00:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][781/781]	Step 14857	lr 0.00535	Loss 0.1019 (0.1476)	Prec@(1,5) (94.9%, 100.0%)	
06/26 04:00:07午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 18/24] Final Prec@1 94.8700%
06/26 04:00:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][50/391]	Step 14858	Loss 0.1210	Prec@(1,5) (95.4%, 100.0%)
06/26 04:00:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][100/391]	Step 14858	Loss 0.1182	Prec@(1,5) (95.5%, 100.0%)
06/26 04:00:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][150/391]	Step 14858	Loss 0.1148	Prec@(1,5) (95.7%, 100.0%)
06/26 04:00:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][200/391]	Step 14858	Loss 0.1137	Prec@(1,5) (95.9%, 100.0%)
06/26 04:00:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][250/391]	Step 14858	Loss 0.1119	Prec@(1,5) (95.9%, 100.0%)
06/26 04:00:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][300/391]	Step 14858	Loss 0.1112	Prec@(1,5) (96.0%, 100.0%)
06/26 04:00:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][350/391]	Step 14858	Loss 0.1086	Prec@(1,5) (96.1%, 100.0%)
06/26 04:00:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][390/391]	Step 14858	Loss 0.1076	Prec@(1,5) (96.1%, 100.0%)
06/26 04:00:15午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 18/24] Final Prec@1 96.1280%
06/26 04:00:16午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.1280%
06/26 04:00:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][50/781]	Step 14908	lr 0.00425	Loss 0.0848 (0.1236)	Prec@(1,5) (96.1%, 100.0%)	
06/26 04:00:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][100/781]	Step 14958	lr 0.00425	Loss 0.0488 (0.1181)	Prec@(1,5) (95.8%, 100.0%)	
06/26 04:00:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][150/781]	Step 15008	lr 0.00425	Loss 0.0606 (0.1153)	Prec@(1,5) (96.0%, 100.0%)	
06/26 04:00:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][200/781]	Step 15058	lr 0.00425	Loss 0.1731 (0.1130)	Prec@(1,5) (96.1%, 100.0%)	
06/26 04:00:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][250/781]	Step 15108	lr 0.00425	Loss 0.0893 (0.1148)	Prec@(1,5) (96.0%, 100.0%)	
06/26 04:00:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][300/781]	Step 15158	lr 0.00425	Loss 0.1493 (0.1162)	Prec@(1,5) (96.0%, 100.0%)	
06/26 04:00:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][350/781]	Step 15208	lr 0.00425	Loss 0.1461 (0.1175)	Prec@(1,5) (96.0%, 100.0%)	
06/26 04:00:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][400/781]	Step 15258	lr 0.00425	Loss 0.0839 (0.1184)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:00:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][450/781]	Step 15308	lr 0.00425	Loss 0.0361 (0.1172)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:00:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][500/781]	Step 15358	lr 0.00425	Loss 0.1617 (0.1157)	Prec@(1,5) (96.0%, 100.0%)	
06/26 04:01:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][550/781]	Step 15408	lr 0.00425	Loss 0.0680 (0.1168)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:01:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][600/781]	Step 15458	lr 0.00425	Loss 0.1241 (0.1172)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:01:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][650/781]	Step 15508	lr 0.00425	Loss 0.1157 (0.1182)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:01:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][700/781]	Step 15558	lr 0.00425	Loss 0.1406 (0.1179)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:01:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][750/781]	Step 15608	lr 0.00425	Loss 0.1649 (0.1183)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:01:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][781/781]	Step 15639	lr 0.00425	Loss 0.0266 (0.1188)	Prec@(1,5) (95.9%, 100.0%)	
06/26 04:01:20午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 19/24] Final Prec@1 95.8660%
06/26 04:01:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][50/391]	Step 15640	Loss 0.0871	Prec@(1,5) (97.0%, 100.0%)
06/26 04:01:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][100/391]	Step 15640	Loss 0.0898	Prec@(1,5) (96.9%, 100.0%)
06/26 04:01:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][150/391]	Step 15640	Loss 0.0896	Prec@(1,5) (96.8%, 100.0%)
06/26 04:01:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][200/391]	Step 15640	Loss 0.0897	Prec@(1,5) (96.8%, 100.0%)
06/26 04:01:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][250/391]	Step 15640	Loss 0.0914	Prec@(1,5) (96.8%, 100.0%)
06/26 04:01:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][300/391]	Step 15640	Loss 0.0929	Prec@(1,5) (96.7%, 100.0%)
06/26 04:01:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][350/391]	Step 15640	Loss 0.0923	Prec@(1,5) (96.8%, 100.0%)
06/26 04:01:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][390/391]	Step 15640	Loss 0.0916	Prec@(1,5) (96.8%, 100.0%)
06/26 04:01:28午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 19/24] Final Prec@1 96.8040%
06/26 04:01:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.8040%
06/26 04:01:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][50/781]	Step 15690	lr 0.00329	Loss 0.1887 (0.1069)	Prec@(1,5) (96.1%, 99.9%)	
06/26 04:01:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][100/781]	Step 15740	lr 0.00329	Loss 0.1580 (0.1060)	Prec@(1,5) (96.3%, 100.0%)	
06/26 04:01:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][150/781]	Step 15790	lr 0.00329	Loss 0.0534 (0.1007)	Prec@(1,5) (96.5%, 100.0%)	
06/26 04:01:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][200/781]	Step 15840	lr 0.00329	Loss 0.0542 (0.1007)	Prec@(1,5) (96.4%, 100.0%)	
06/26 04:01:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][250/781]	Step 15890	lr 0.00329	Loss 0.0815 (0.0995)	Prec@(1,5) (96.5%, 100.0%)	
06/26 04:01:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][300/781]	Step 15940	lr 0.00329	Loss 0.0933 (0.0983)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][350/781]	Step 15990	lr 0.00329	Loss 0.0518 (0.0966)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][400/781]	Step 16040	lr 0.00329	Loss 0.0707 (0.0958)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][450/781]	Step 16090	lr 0.00329	Loss 0.0595 (0.0960)	Prec@(1,5) (96.7%, 100.0%)	
06/26 04:02:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][500/781]	Step 16140	lr 0.00329	Loss 0.1265 (0.0954)	Prec@(1,5) (96.7%, 100.0%)	
06/26 04:02:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][550/781]	Step 16190	lr 0.00329	Loss 0.0844 (0.0958)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][600/781]	Step 16240	lr 0.00329	Loss 0.0418 (0.0958)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][650/781]	Step 16290	lr 0.00329	Loss 0.0652 (0.0962)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][700/781]	Step 16340	lr 0.00329	Loss 0.1519 (0.0969)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][750/781]	Step 16390	lr 0.00329	Loss 0.0543 (0.0971)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][781/781]	Step 16421	lr 0.00329	Loss 0.1039 (0.0971)	Prec@(1,5) (96.6%, 100.0%)	
06/26 04:02:36午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 20/24] Final Prec@1 96.5620%
06/26 04:02:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][50/391]	Step 16422	Loss 0.0660	Prec@(1,5) (97.8%, 100.0%)
06/26 04:02:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][100/391]	Step 16422	Loss 0.0686	Prec@(1,5) (97.7%, 100.0%)
06/26 04:02:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][150/391]	Step 16422	Loss 0.0683	Prec@(1,5) (97.8%, 100.0%)
06/26 04:02:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][200/391]	Step 16422	Loss 0.0662	Prec@(1,5) (97.8%, 100.0%)
06/26 04:02:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][250/391]	Step 16422	Loss 0.0688	Prec@(1,5) (97.7%, 100.0%)
06/26 04:02:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][300/391]	Step 16422	Loss 0.0672	Prec@(1,5) (97.8%, 100.0%)
06/26 04:02:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][350/391]	Step 16422	Loss 0.0663	Prec@(1,5) (97.8%, 100.0%)
06/26 04:02:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][390/391]	Step 16422	Loss 0.0646	Prec@(1,5) (97.9%, 100.0%)
06/26 04:02:45午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 20/24] Final Prec@1 97.8760%
06/26 04:02:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.8760%
06/26 04:02:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][50/781]	Step 16472	lr 0.00248	Loss 0.1225 (0.0880)	Prec@(1,5) (97.0%, 100.0%)	
06/26 04:02:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][100/781]	Step 16522	lr 0.00248	Loss 0.0529 (0.0820)	Prec@(1,5) (97.3%, 100.0%)	
06/26 04:02:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][150/781]	Step 16572	lr 0.00248	Loss 0.0545 (0.0844)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][200/781]	Step 16622	lr 0.00248	Loss 0.0916 (0.0830)	Prec@(1,5) (97.1%, 100.0%)	
06/26 04:03:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][250/781]	Step 16672	lr 0.00248	Loss 0.0662 (0.0858)	Prec@(1,5) (97.0%, 100.0%)	
06/26 04:03:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][300/781]	Step 16722	lr 0.00248	Loss 0.0475 (0.0839)	Prec@(1,5) (97.1%, 100.0%)	
06/26 04:03:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][350/781]	Step 16772	lr 0.00248	Loss 0.0592 (0.0819)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][400/781]	Step 16822	lr 0.00248	Loss 0.0700 (0.0817)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][450/781]	Step 16872	lr 0.00248	Loss 0.1198 (0.0818)	Prec@(1,5) (97.1%, 100.0%)	
06/26 04:03:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][500/781]	Step 16922	lr 0.00248	Loss 0.1068 (0.0817)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][550/781]	Step 16972	lr 0.00248	Loss 0.0202 (0.0819)	Prec@(1,5) (97.1%, 100.0%)	
06/26 04:03:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][600/781]	Step 17022	lr 0.00248	Loss 0.0712 (0.0819)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][650/781]	Step 17072	lr 0.00248	Loss 0.0757 (0.0809)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][700/781]	Step 17122	lr 0.00248	Loss 0.0466 (0.0806)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][750/781]	Step 17172	lr 0.00248	Loss 0.0310 (0.0799)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][781/781]	Step 17203	lr 0.00248	Loss 0.1281 (0.0804)	Prec@(1,5) (97.2%, 100.0%)	
06/26 04:03:51午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 21/24] Final Prec@1 97.2280%
06/26 04:03:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][50/391]	Step 17204	Loss 0.0478	Prec@(1,5) (98.5%, 100.0%)
06/26 04:03:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][100/391]	Step 17204	Loss 0.0497	Prec@(1,5) (98.4%, 100.0%)
06/26 04:03:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][150/391]	Step 17204	Loss 0.0518	Prec@(1,5) (98.4%, 100.0%)
06/26 04:03:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][200/391]	Step 17204	Loss 0.0508	Prec@(1,5) (98.4%, 100.0%)
06/26 04:03:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][250/391]	Step 17204	Loss 0.0524	Prec@(1,5) (98.3%, 100.0%)
06/26 04:03:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][300/391]	Step 17204	Loss 0.0522	Prec@(1,5) (98.3%, 100.0%)
06/26 04:03:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][350/391]	Step 17204	Loss 0.0519	Prec@(1,5) (98.3%, 100.0%)
06/26 04:03:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][390/391]	Step 17204	Loss 0.0524	Prec@(1,5) (98.3%, 100.0%)
06/26 04:03:59午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 21/24] Final Prec@1 98.3080%
06/26 04:04:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 98.3080%
06/26 04:04:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][50/781]	Step 17254	lr 0.00184	Loss 0.0561 (0.0737)	Prec@(1,5) (97.4%, 100.0%)	
06/26 04:04:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][100/781]	Step 17304	lr 0.00184	Loss 0.0602 (0.0708)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:04:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][150/781]	Step 17354	lr 0.00184	Loss 0.0288 (0.0698)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:04:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][200/781]	Step 17404	lr 0.00184	Loss 0.0388 (0.0683)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][250/781]	Step 17454	lr 0.00184	Loss 0.0672 (0.0691)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][300/781]	Step 17504	lr 0.00184	Loss 0.0531 (0.0687)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][350/781]	Step 17554	lr 0.00184	Loss 0.1311 (0.0696)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][400/781]	Step 17604	lr 0.00184	Loss 0.0707 (0.0693)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][450/781]	Step 17654	lr 0.00184	Loss 0.1285 (0.0689)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][500/781]	Step 17704	lr 0.00184	Loss 0.0669 (0.0683)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][550/781]	Step 17754	lr 0.00184	Loss 0.0582 (0.0679)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][600/781]	Step 17804	lr 0.00184	Loss 0.0844 (0.0676)	Prec@(1,5) (97.8%, 100.0%)	
06/26 04:04:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][650/781]	Step 17854	lr 0.00184	Loss 0.1401 (0.0685)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:04:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][700/781]	Step 17904	lr 0.00184	Loss 0.0456 (0.0679)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:05:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][750/781]	Step 17954	lr 0.00184	Loss 0.0787 (0.0676)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:05:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][781/781]	Step 17985	lr 0.00184	Loss 0.0386 (0.0679)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:05:05午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 22/24] Final Prec@1 97.7280%
06/26 04:05:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][50/391]	Step 17986	Loss 0.0409	Prec@(1,5) (98.7%, 100.0%)
06/26 04:05:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][100/391]	Step 17986	Loss 0.0435	Prec@(1,5) (98.6%, 100.0%)
06/26 04:05:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][150/391]	Step 17986	Loss 0.0405	Prec@(1,5) (98.8%, 100.0%)
06/26 04:05:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][200/391]	Step 17986	Loss 0.0383	Prec@(1,5) (98.9%, 100.0%)
06/26 04:05:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][250/391]	Step 17986	Loss 0.0408	Prec@(1,5) (98.8%, 100.0%)
06/26 04:05:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][300/391]	Step 17986	Loss 0.0401	Prec@(1,5) (98.8%, 100.0%)
06/26 04:05:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][350/391]	Step 17986	Loss 0.0410	Prec@(1,5) (98.8%, 100.0%)
06/26 04:05:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][390/391]	Step 17986	Loss 0.0417	Prec@(1,5) (98.7%, 100.0%)
06/26 04:05:13午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 22/24] Final Prec@1 98.7440%
06/26 04:05:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 98.7440%
06/26 04:05:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][50/781]	Step 18036	lr 0.00138	Loss 0.0116 (0.0595)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:05:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][100/781]	Step 18086	lr 0.00138	Loss 0.0234 (0.0570)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:05:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][150/781]	Step 18136	lr 0.00138	Loss 0.0756 (0.0580)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:05:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][200/781]	Step 18186	lr 0.00138	Loss 0.0548 (0.0560)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:05:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][250/781]	Step 18236	lr 0.00138	Loss 0.0988 (0.0565)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:05:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][300/781]	Step 18286	lr 0.00138	Loss 0.0948 (0.0579)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:05:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][350/781]	Step 18336	lr 0.00138	Loss 0.0411 (0.0581)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:05:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][400/781]	Step 18386	lr 0.00138	Loss 0.0097 (0.0579)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:05:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][450/781]	Step 18436	lr 0.00138	Loss 0.0736 (0.0570)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:05:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][500/781]	Step 18486	lr 0.00138	Loss 0.1057 (0.0566)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:06:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][550/781]	Step 18536	lr 0.00138	Loss 0.0239 (0.0569)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:06:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][600/781]	Step 18586	lr 0.00138	Loss 0.1079 (0.0573)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:06:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][650/781]	Step 18636	lr 0.00138	Loss 0.0252 (0.0573)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:06:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][700/781]	Step 18686	lr 0.00138	Loss 0.0188 (0.0577)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:06:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][750/781]	Step 18736	lr 0.00138	Loss 0.1534 (0.0580)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:06:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][781/781]	Step 18767	lr 0.00138	Loss 0.0515 (0.0581)	Prec@(1,5) (98.1%, 100.0%)	
06/26 04:06:19午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 23/24] Final Prec@1 98.0980%
06/26 04:06:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][50/391]	Step 18768	Loss 0.0330	Prec@(1,5) (99.2%, 100.0%)
06/26 04:06:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][100/391]	Step 18768	Loss 0.0350	Prec@(1,5) (99.1%, 100.0%)
06/26 04:06:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][150/391]	Step 18768	Loss 0.0347	Prec@(1,5) (99.1%, 100.0%)
06/26 04:06:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][200/391]	Step 18768	Loss 0.0351	Prec@(1,5) (99.1%, 100.0%)
06/26 04:06:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][250/391]	Step 18768	Loss 0.0348	Prec@(1,5) (99.0%, 100.0%)
06/26 04:06:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][300/391]	Step 18768	Loss 0.0339	Prec@(1,5) (99.1%, 100.0%)
06/26 04:06:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][350/391]	Step 18768	Loss 0.0340	Prec@(1,5) (99.1%, 100.0%)
06/26 04:06:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][390/391]	Step 18768	Loss 0.0336	Prec@(1,5) (99.1%, 100.0%)
06/26 04:06:28午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 23/24] Final Prec@1 99.0800%
06/26 04:06:29午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 99.0800%
06/26 04:06:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][50/781]	Step 18818	lr 0.00109	Loss 0.0332 (0.0456)	Prec@(1,5) (98.4%, 100.0%)	
06/26 04:06:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][100/781]	Step 18868	lr 0.00109	Loss 0.0115 (0.0468)	Prec@(1,5) (98.4%, 100.0%)	
06/26 04:06:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][150/781]	Step 18918	lr 0.00109	Loss 0.0487 (0.0510)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:06:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][200/781]	Step 18968	lr 0.00109	Loss 0.0598 (0.0516)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:06:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][250/781]	Step 19018	lr 0.00109	Loss 0.0162 (0.0513)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:06:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][300/781]	Step 19068	lr 0.00109	Loss 0.0318 (0.0516)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:06:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][350/781]	Step 19118	lr 0.00109	Loss 0.0779 (0.0513)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][400/781]	Step 19168	lr 0.00109	Loss 0.1099 (0.0515)	Prec@(1,5) (98.2%, 100.0%)	
06/26 04:07:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][450/781]	Step 19218	lr 0.00109	Loss 0.0070 (0.0512)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][500/781]	Step 19268	lr 0.00109	Loss 0.0304 (0.0502)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][550/781]	Step 19318	lr 0.00109	Loss 0.0179 (0.0502)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][600/781]	Step 19368	lr 0.00109	Loss 0.0115 (0.0504)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][650/781]	Step 19418	lr 0.00109	Loss 0.0671 (0.0501)	Prec@(1,5) (98.4%, 100.0%)	
06/26 04:07:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][700/781]	Step 19468	lr 0.00109	Loss 0.0185 (0.0508)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][750/781]	Step 19518	lr 0.00109	Loss 0.0693 (0.0506)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][781/781]	Step 19549	lr 0.00109	Loss 0.0384 (0.0506)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:07:35午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 24/24] Final Prec@1 98.3220%
06/26 04:07:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][50/391]	Step 19550	Loss 0.0324	Prec@(1,5) (99.0%, 100.0%)
06/26 04:07:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][100/391]	Step 19550	Loss 0.0309	Prec@(1,5) (99.1%, 100.0%)
06/26 04:07:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][150/391]	Step 19550	Loss 0.0318	Prec@(1,5) (99.0%, 100.0%)
06/26 04:07:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][200/391]	Step 19550	Loss 0.0306	Prec@(1,5) (99.1%, 100.0%)
06/26 04:07:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][250/391]	Step 19550	Loss 0.0293	Prec@(1,5) (99.1%, 100.0%)
06/26 04:07:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][300/391]	Step 19550	Loss 0.0300	Prec@(1,5) (99.1%, 100.0%)
06/26 04:07:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][350/391]	Step 19550	Loss 0.0304	Prec@(1,5) (99.1%, 100.0%)
06/26 04:07:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][390/391]	Step 19550	Loss 0.0296	Prec@(1,5) (99.2%, 100.0%)
06/26 04:07:43午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 24/24] Final Prec@1 99.1560%
06/26 04:07:44午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 99.1560%
06/26 04:07:44午後 finetuneTeacher_main.py:56 [INFO] Final best Prec@1 = 99.1560%
