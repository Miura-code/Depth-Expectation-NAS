06/26 03:54:25PM parser.py:28 [INFO] 
06/26 03:54:25PM parser.py:29 [INFO] Parameters:
06/26 03:54:25PM parser.py:31 [INFO] BATCH_SIZE=64
06/26 03:54:25PM parser.py:31 [INFO] CUTOUT_LENGTH=0
06/26 03:54:25PM parser.py:31 [INFO] DATA_PATH=../data/
06/26 03:54:25PM parser.py:31 [INFO] DATASET=cifar10
06/26 03:54:25PM parser.py:31 [INFO] EPOCHS=25
06/26 03:54:25PM parser.py:31 [INFO] EXP_NAME=E25-20240626-155425
06/26 03:54:25PM parser.py:31 [INFO] GPUS=[0]
06/26 03:54:25PM parser.py:31 [INFO] LOCAL_RANK=0
06/26 03:54:25PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
06/26 03:54:25PM parser.py:31 [INFO] MODEL_NAME=tf_efficientnetv2_m
06/26 03:54:25PM parser.py:31 [INFO] NAME=FINETUNE
06/26 03:54:25PM parser.py:31 [INFO] PATH=results/teacher/cifar10/tf_efficientnetv2_m/FINETUNE/E25-20240626-155425
06/26 03:54:25PM parser.py:31 [INFO] PLOT_PATH=results/teacher/cifar10/tf_efficientnetv2_m/FINETUNE/E25-20240626-155425/plots
06/26 03:54:25PM parser.py:31 [INFO] PRINT_FREQ=50
06/26 03:54:25PM parser.py:31 [INFO] RESUME_PATH=None
06/26 03:54:25PM parser.py:31 [INFO] SAVE=E25
06/26 03:54:25PM parser.py:31 [INFO] SEED=0
06/26 03:54:25PM parser.py:31 [INFO] TRAIN_PORTION=1.0
06/26 03:54:25PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
06/26 03:54:25PM parser.py:31 [INFO] W_LR=0.025
06/26 03:54:25PM parser.py:31 [INFO] W_LR_MIN=0.001
06/26 03:54:25PM parser.py:31 [INFO] W_MOMENTUM=0.9
06/26 03:54:25PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
06/26 03:54:25PM parser.py:31 [INFO] WORKERS=4
06/26 03:54:25PM parser.py:32 [INFO] 
06/26 03:54:32PM finetuneTeacher_trainer.py:109 [INFO] --> No loaded checkpoint!
06/26 03:54:38PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][50/781]	Step 50	lr 0.025	Loss 1.9332 (2.8320)	Prec@(1,5) (19.0%, 63.1%)	
06/26 03:54:43PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][100/781]	Step 100	lr 0.025	Loss 1.7334 (2.2673)	Prec@(1,5) (28.9%, 74.6%)	
06/26 03:54:48PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][150/781]	Step 150	lr 0.025	Loss 1.3139 (1.9834)	Prec@(1,5) (36.0%, 80.7%)	
06/26 03:54:52PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][200/781]	Step 200	lr 0.025	Loss 1.1481 (1.8056)	Prec@(1,5) (40.8%, 84.2%)	
06/26 03:54:57PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][250/781]	Step 250	lr 0.025	Loss 0.9436 (1.6728)	Prec@(1,5) (45.0%, 86.4%)	
06/26 03:55:01PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][300/781]	Step 300	lr 0.025	Loss 1.2578 (1.5730)	Prec@(1,5) (48.2%, 88.1%)	
06/26 03:55:05PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][350/781]	Step 350	lr 0.025	Loss 0.9385 (1.4900)	Prec@(1,5) (50.8%, 89.3%)	
06/26 03:55:10PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][400/781]	Step 400	lr 0.025	Loss 1.1187 (1.4166)	Prec@(1,5) (53.1%, 90.3%)	
06/26 03:55:14PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][450/781]	Step 450	lr 0.025	Loss 1.1268 (1.3575)	Prec@(1,5) (55.1%, 91.1%)	
06/26 03:55:19PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][500/781]	Step 500	lr 0.025	Loss 0.9855 (1.3079)	Prec@(1,5) (56.8%, 91.7%)	
06/26 03:55:23PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][550/781]	Step 550	lr 0.025	Loss 0.7478 (1.2680)	Prec@(1,5) (58.1%, 92.2%)	
06/26 03:55:28PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][600/781]	Step 600	lr 0.025	Loss 0.7330 (1.2309)	Prec@(1,5) (59.3%, 92.7%)	
06/26 03:55:32PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][650/781]	Step 650	lr 0.025	Loss 0.8776 (1.1981)	Prec@(1,5) (60.4%, 93.1%)	
06/26 03:55:37PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][700/781]	Step 700	lr 0.025	Loss 0.7352 (1.1690)	Prec@(1,5) (61.2%, 93.5%)	
06/26 03:55:41PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][750/781]	Step 750	lr 0.025	Loss 0.8097 (1.1398)	Prec@(1,5) (62.2%, 93.8%)	
06/26 03:55:44PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][781/781]	Step 781	lr 0.025	Loss 0.6750 (1.1259)	Prec@(1,5) (62.6%, 94.0%)	
06/26 03:55:45PM finetuneTeacher_trainer.py:181 [INFO] Train: [  0/24] Final Prec@1 62.5880%
06/26 03:55:47PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][50/391]	Step 782	Loss 0.6485	Prec@(1,5) (77.3%, 98.9%)
06/26 03:55:48PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][100/391]	Step 782	Loss 0.6380	Prec@(1,5) (77.4%, 99.0%)
06/26 03:55:49PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][150/391]	Step 782	Loss 0.6336	Prec@(1,5) (77.4%, 98.9%)
06/26 03:55:50PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][200/391]	Step 782	Loss 0.6281	Prec@(1,5) (77.7%, 98.9%)
06/26 03:55:51PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][250/391]	Step 782	Loss 0.6301	Prec@(1,5) (77.8%, 98.8%)
06/26 03:55:52PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][300/391]	Step 782	Loss 0.6289	Prec@(1,5) (77.8%, 98.8%)
06/26 03:55:54PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][350/391]	Step 782	Loss 0.6290	Prec@(1,5) (77.7%, 98.8%)
06/26 03:55:54PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][390/391]	Step 782	Loss 0.6277	Prec@(1,5) (77.8%, 98.8%)
06/26 03:55:55PM finetuneTeacher_trainer.py:216 [INFO] Valid: [  0/24] Final Prec@1 77.8160%
06/26 03:55:56午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 77.8160%
06/26 03:56:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][50/781]	Step 832	lr 0.02491	Loss 0.4410 (0.6860)	Prec@(1,5) (76.6%, 98.6%)	
06/26 03:56:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][100/781]	Step 882	lr 0.02491	Loss 0.8460 (0.6807)	Prec@(1,5) (76.7%, 98.6%)	
06/26 03:56:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][150/781]	Step 932	lr 0.02491	Loss 0.5559 (0.6716)	Prec@(1,5) (76.8%, 98.7%)	
06/26 03:56:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][200/781]	Step 982	lr 0.02491	Loss 0.5317 (0.6624)	Prec@(1,5) (77.3%, 98.7%)	
06/26 03:56:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][250/781]	Step 1032	lr 0.02491	Loss 0.6339 (0.6592)	Prec@(1,5) (77.5%, 98.7%)	
06/26 03:56:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][300/781]	Step 1082	lr 0.02491	Loss 0.5484 (0.6588)	Prec@(1,5) (77.7%, 98.7%)	
06/26 03:56:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][350/781]	Step 1132	lr 0.02491	Loss 0.4137 (0.6489)	Prec@(1,5) (78.1%, 98.7%)	
06/26 03:56:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][400/781]	Step 1182	lr 0.02491	Loss 0.5612 (0.6469)	Prec@(1,5) (78.2%, 98.7%)	
06/26 03:56:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][450/781]	Step 1232	lr 0.02491	Loss 0.5279 (0.6413)	Prec@(1,5) (78.3%, 98.7%)	
06/26 03:56:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][500/781]	Step 1282	lr 0.02491	Loss 0.5147 (0.6356)	Prec@(1,5) (78.5%, 98.7%)	
06/26 03:56:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][550/781]	Step 1332	lr 0.02491	Loss 0.6699 (0.6345)	Prec@(1,5) (78.5%, 98.7%)	
06/26 03:56:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][600/781]	Step 1382	lr 0.02491	Loss 0.7201 (0.6304)	Prec@(1,5) (78.7%, 98.7%)	
06/26 03:56:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][650/781]	Step 1432	lr 0.02491	Loss 0.2905 (0.6291)	Prec@(1,5) (78.8%, 98.8%)	
06/26 03:57:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][700/781]	Step 1482	lr 0.02491	Loss 0.6985 (0.6254)	Prec@(1,5) (78.9%, 98.8%)	
06/26 03:57:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][750/781]	Step 1532	lr 0.02491	Loss 0.7993 (0.6240)	Prec@(1,5) (78.9%, 98.7%)	
06/26 03:57:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][781/781]	Step 1563	lr 0.02491	Loss 0.7289 (0.6249)	Prec@(1,5) (78.9%, 98.7%)	
06/26 03:57:10午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  1/24] Final Prec@1 78.9240%
06/26 03:57:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][50/391]	Step 1564	Loss 0.4755	Prec@(1,5) (83.9%, 99.4%)
06/26 03:57:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][100/391]	Step 1564	Loss 0.4927	Prec@(1,5) (83.2%, 99.3%)
06/26 03:57:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][150/391]	Step 1564	Loss 0.4975	Prec@(1,5) (83.0%, 99.3%)
06/26 03:57:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][200/391]	Step 1564	Loss 0.5040	Prec@(1,5) (82.8%, 99.3%)
06/26 03:57:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][250/391]	Step 1564	Loss 0.4962	Prec@(1,5) (83.2%, 99.3%)
06/26 03:57:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][300/391]	Step 1564	Loss 0.4975	Prec@(1,5) (83.1%, 99.3%)
06/26 03:57:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][350/391]	Step 1564	Loss 0.4941	Prec@(1,5) (83.2%, 99.3%)
06/26 03:57:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][390/391]	Step 1564	Loss 0.4947	Prec@(1,5) (83.2%, 99.3%)
06/26 03:57:19午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  1/24] Final Prec@1 83.1760%
06/26 03:57:20午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 83.1760%
06/26 03:57:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][50/781]	Step 1614	lr 0.02462	Loss 0.6188 (0.5446)	Prec@(1,5) (81.3%, 99.1%)	
06/26 03:57:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][100/781]	Step 1664	lr 0.02462	Loss 0.5706 (0.5624)	Prec@(1,5) (81.1%, 98.9%)	
06/26 03:57:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][150/781]	Step 1714	lr 0.02462	Loss 0.6216 (0.5520)	Prec@(1,5) (81.6%, 99.1%)	
06/26 03:57:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][200/781]	Step 1764	lr 0.02462	Loss 0.4142 (0.5487)	Prec@(1,5) (81.8%, 99.1%)	
06/26 03:57:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][250/781]	Step 1814	lr 0.02462	Loss 0.4913 (0.5512)	Prec@(1,5) (81.8%, 99.1%)	
06/26 03:57:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][300/781]	Step 1864	lr 0.02462	Loss 0.3558 (0.5556)	Prec@(1,5) (81.7%, 99.1%)	
06/26 03:57:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][350/781]	Step 1914	lr 0.02462	Loss 0.5501 (0.5521)	Prec@(1,5) (82.0%, 99.1%)	
06/26 03:58:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][400/781]	Step 1964	lr 0.02462	Loss 0.5183 (0.5501)	Prec@(1,5) (82.0%, 99.2%)	
06/26 03:58:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][450/781]	Step 2014	lr 0.02462	Loss 0.4300 (0.5478)	Prec@(1,5) (82.0%, 99.2%)	
06/26 03:58:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][500/781]	Step 2064	lr 0.02462	Loss 0.4479 (0.5490)	Prec@(1,5) (81.9%, 99.2%)	
06/26 03:58:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][550/781]	Step 2114	lr 0.02462	Loss 0.4646 (0.5438)	Prec@(1,5) (82.1%, 99.2%)	
06/26 03:58:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][600/781]	Step 2164	lr 0.02462	Loss 0.4205 (0.5455)	Prec@(1,5) (82.0%, 99.2%)	
06/26 03:58:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][650/781]	Step 2214	lr 0.02462	Loss 0.7876 (0.5428)	Prec@(1,5) (82.0%, 99.2%)	
06/26 03:58:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][700/781]	Step 2264	lr 0.02462	Loss 0.3236 (0.5416)	Prec@(1,5) (82.0%, 99.2%)	
06/26 03:58:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][750/781]	Step 2314	lr 0.02462	Loss 0.6226 (0.5401)	Prec@(1,5) (82.1%, 99.2%)	
06/26 03:58:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][781/781]	Step 2345	lr 0.02462	Loss 0.4706 (0.5398)	Prec@(1,5) (82.1%, 99.2%)	
06/26 03:58:30午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  2/24] Final Prec@1 82.0820%
06/26 03:58:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][50/391]	Step 2346	Loss 0.5707	Prec@(1,5) (83.5%, 97.5%)
06/26 03:58:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][100/391]	Step 2346	Loss 0.5734	Prec@(1,5) (83.0%, 97.7%)
06/26 03:58:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][150/391]	Step 2346	Loss 0.5773	Prec@(1,5) (82.6%, 97.8%)
06/26 03:58:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][200/391]	Step 2346	Loss 0.5782	Prec@(1,5) (82.5%, 97.8%)
06/26 03:58:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][250/391]	Step 2346	Loss 0.5727	Prec@(1,5) (82.5%, 97.9%)
06/26 03:58:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][300/391]	Step 2346	Loss 0.5795	Prec@(1,5) (82.5%, 97.9%)
06/26 03:58:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][350/391]	Step 2346	Loss 0.5800	Prec@(1,5) (82.5%, 97.8%)
06/26 03:58:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][390/391]	Step 2346	Loss 0.5850	Prec@(1,5) (82.6%, 97.7%)
06/26 03:58:39午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  2/24] Final Prec@1 82.6360%
06/26 03:58:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 83.1760%
06/26 03:58:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][50/781]	Step 2396	lr 0.02416	Loss 0.5949 (0.5155)	Prec@(1,5) (81.6%, 99.3%)	
06/26 03:58:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][100/781]	Step 2446	lr 0.02416	Loss 0.4841 (0.5041)	Prec@(1,5) (82.3%, 99.4%)	
06/26 03:58:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][150/781]	Step 2496	lr 0.02416	Loss 0.4145 (0.4987)	Prec@(1,5) (82.7%, 99.4%)	
06/26 03:58:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][200/781]	Step 2546	lr 0.02416	Loss 0.3649 (0.4904)	Prec@(1,5) (83.0%, 99.4%)	
06/26 03:59:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][250/781]	Step 2596	lr 0.02416	Loss 0.5967 (0.4958)	Prec@(1,5) (82.8%, 99.4%)	
06/26 03:59:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][300/781]	Step 2646	lr 0.02416	Loss 0.3623 (0.4929)	Prec@(1,5) (82.8%, 99.4%)	
06/26 03:59:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][350/781]	Step 2696	lr 0.02416	Loss 0.5433 (0.4902)	Prec@(1,5) (82.8%, 99.4%)	
06/26 03:59:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][400/781]	Step 2746	lr 0.02416	Loss 0.6038 (0.4872)	Prec@(1,5) (83.1%, 99.3%)	
06/26 03:59:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][450/781]	Step 2796	lr 0.02416	Loss 0.5547 (0.4852)	Prec@(1,5) (83.2%, 99.4%)	
06/26 03:59:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][500/781]	Step 2846	lr 0.02416	Loss 0.7293 (0.4854)	Prec@(1,5) (83.3%, 99.3%)	
06/26 03:59:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][550/781]	Step 2896	lr 0.02416	Loss 0.4273 (0.4848)	Prec@(1,5) (83.4%, 99.3%)	
06/26 03:59:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][600/781]	Step 2946	lr 0.02416	Loss 0.3398 (0.4814)	Prec@(1,5) (83.4%, 99.3%)	
06/26 03:59:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][650/781]	Step 2996	lr 0.02416	Loss 0.3019 (0.4818)	Prec@(1,5) (83.5%, 99.3%)	
06/26 03:59:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][700/781]	Step 3046	lr 0.02416	Loss 0.4575 (0.4822)	Prec@(1,5) (83.5%, 99.3%)	
06/26 03:59:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][750/781]	Step 3096	lr 0.02416	Loss 0.5875 (0.4820)	Prec@(1,5) (83.5%, 99.3%)	
06/26 03:59:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][781/781]	Step 3127	lr 0.02416	Loss 0.5033 (0.4802)	Prec@(1,5) (83.6%, 99.3%)	
06/26 03:59:50午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  3/24] Final Prec@1 83.5960%
06/26 03:59:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][50/391]	Step 3128	Loss 0.5063	Prec@(1,5) (86.4%, 98.7%)
06/26 03:59:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][100/391]	Step 3128	Loss 0.4832	Prec@(1,5) (86.8%, 98.7%)
06/26 03:59:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][150/391]	Step 3128	Loss 0.4864	Prec@(1,5) (86.8%, 98.7%)
06/26 03:59:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][200/391]	Step 3128	Loss 0.4786	Prec@(1,5) (86.9%, 98.8%)
06/26 03:59:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][250/391]	Step 3128	Loss 0.4854	Prec@(1,5) (87.0%, 98.7%)
06/26 03:59:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][300/391]	Step 3128	Loss 0.4856	Prec@(1,5) (87.0%, 98.7%)
06/26 03:59:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][350/391]	Step 3128	Loss 0.4784	Prec@(1,5) (86.9%, 98.8%)
06/26 03:59:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][390/391]	Step 3128	Loss 0.4784	Prec@(1,5) (87.0%, 98.8%)
06/26 03:59:59午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  3/24] Final Prec@1 87.0000%
06/26 04:00:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.0000%
06/26 04:00:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][50/781]	Step 3178	lr 0.02352	Loss 0.5480 (0.4122)	Prec@(1,5) (86.0%, 99.4%)	
06/26 04:00:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][100/781]	Step 3228	lr 0.02352	Loss 0.3460 (0.4050)	Prec@(1,5) (86.2%, 99.5%)	
06/26 04:00:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][150/781]	Step 3278	lr 0.02352	Loss 0.2267 (0.3979)	Prec@(1,5) (86.3%, 99.6%)	
06/26 04:00:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][200/781]	Step 3328	lr 0.02352	Loss 0.4422 (0.4040)	Prec@(1,5) (86.1%, 99.5%)	
06/26 04:00:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][250/781]	Step 3378	lr 0.02352	Loss 0.2111 (0.4056)	Prec@(1,5) (86.2%, 99.5%)	
06/26 04:00:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][300/781]	Step 3428	lr 0.02352	Loss 0.4173 (0.4100)	Prec@(1,5) (86.1%, 99.5%)	
06/26 04:00:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][350/781]	Step 3478	lr 0.02352	Loss 0.5356 (0.4154)	Prec@(1,5) (86.0%, 99.5%)	
06/26 04:00:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][400/781]	Step 3528	lr 0.02352	Loss 0.3611 (0.4188)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:00:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][450/781]	Step 3578	lr 0.02352	Loss 0.5591 (0.4203)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:00:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][500/781]	Step 3628	lr 0.02352	Loss 0.2785 (0.4230)	Prec@(1,5) (85.6%, 99.5%)	
06/26 04:00:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][550/781]	Step 3678	lr 0.02352	Loss 0.6291 (0.4222)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:00:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][600/781]	Step 3728	lr 0.02352	Loss 0.4998 (0.4209)	Prec@(1,5) (85.8%, 99.5%)	
06/26 04:01:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][650/781]	Step 3778	lr 0.02352	Loss 0.4070 (0.4206)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:01:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][700/781]	Step 3828	lr 0.02352	Loss 0.4432 (0.4228)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:01:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][750/781]	Step 3878	lr 0.02352	Loss 0.3396 (0.4227)	Prec@(1,5) (85.7%, 99.4%)	
06/26 04:01:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][781/781]	Step 3909	lr 0.02352	Loss 0.3933 (0.4236)	Prec@(1,5) (85.7%, 99.4%)	
06/26 04:01:14午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  4/24] Final Prec@1 85.6900%
06/26 04:01:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][50/391]	Step 3910	Loss 0.4078	Prec@(1,5) (87.6%, 98.9%)
06/26 04:01:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][100/391]	Step 3910	Loss 0.4117	Prec@(1,5) (87.3%, 99.1%)
06/26 04:01:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][150/391]	Step 3910	Loss 0.4015	Prec@(1,5) (87.6%, 99.1%)
06/26 04:01:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][200/391]	Step 3910	Loss 0.3982	Prec@(1,5) (87.4%, 99.2%)
06/26 04:01:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][250/391]	Step 3910	Loss 0.4007	Prec@(1,5) (87.4%, 99.2%)
06/26 04:01:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][300/391]	Step 3910	Loss 0.4042	Prec@(1,5) (87.2%, 99.2%)
06/26 04:01:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][350/391]	Step 3910	Loss 0.4013	Prec@(1,5) (87.3%, 99.2%)
06/26 04:01:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][390/391]	Step 3910	Loss 0.4018	Prec@(1,5) (87.2%, 99.2%)
06/26 04:01:23午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  4/24] Final Prec@1 87.2200%
06/26 04:01:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.2200%
06/26 04:01:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][50/781]	Step 3960	lr 0.02271	Loss 0.4311 (0.3974)	Prec@(1,5) (86.1%, 99.6%)	
06/26 04:01:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][100/781]	Step 4010	lr 0.02271	Loss 0.3429 (0.4012)	Prec@(1,5) (86.1%, 99.5%)	
06/26 04:01:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][150/781]	Step 4060	lr 0.02271	Loss 0.3667 (0.3943)	Prec@(1,5) (86.3%, 99.6%)	
06/26 04:01:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][200/781]	Step 4110	lr 0.02271	Loss 0.2122 (0.3880)	Prec@(1,5) (86.6%, 99.6%)	
06/26 04:01:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][250/781]	Step 4160	lr 0.02271	Loss 0.1655 (0.3933)	Prec@(1,5) (86.6%, 99.6%)	
06/26 04:01:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][300/781]	Step 4210	lr 0.02271	Loss 0.6851 (0.3904)	Prec@(1,5) (86.7%, 99.5%)	
06/26 04:01:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][350/781]	Step 4260	lr 0.02271	Loss 0.4871 (0.3899)	Prec@(1,5) (86.7%, 99.5%)	
06/26 04:02:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][400/781]	Step 4310	lr 0.02271	Loss 0.4501 (0.3879)	Prec@(1,5) (86.8%, 99.5%)	
06/26 04:02:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][450/781]	Step 4360	lr 0.02271	Loss 0.3013 (0.3884)	Prec@(1,5) (86.8%, 99.5%)	
06/26 04:02:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][500/781]	Step 4410	lr 0.02271	Loss 0.3594 (0.3857)	Prec@(1,5) (86.9%, 99.5%)	
06/26 04:02:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][550/781]	Step 4460	lr 0.02271	Loss 0.3671 (0.3844)	Prec@(1,5) (87.0%, 99.5%)	
06/26 04:02:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][600/781]	Step 4510	lr 0.02271	Loss 0.4120 (0.3834)	Prec@(1,5) (87.0%, 99.5%)	
06/26 04:02:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][650/781]	Step 4560	lr 0.02271	Loss 0.2051 (0.3807)	Prec@(1,5) (87.1%, 99.6%)	
06/26 04:02:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][700/781]	Step 4610	lr 0.02271	Loss 0.3773 (0.3803)	Prec@(1,5) (87.1%, 99.6%)	
06/26 04:02:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][750/781]	Step 4660	lr 0.02271	Loss 0.4001 (0.3805)	Prec@(1,5) (87.1%, 99.6%)	
06/26 04:02:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][781/781]	Step 4691	lr 0.02271	Loss 0.5268 (0.3813)	Prec@(1,5) (87.1%, 99.6%)	
06/26 04:02:38午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  5/24] Final Prec@1 87.1040%
06/26 04:02:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][50/391]	Step 4692	Loss 0.3598	Prec@(1,5) (87.9%, 99.0%)
06/26 04:02:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][100/391]	Step 4692	Loss 0.3685	Prec@(1,5) (87.5%, 98.8%)
06/26 04:02:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][150/391]	Step 4692	Loss 0.3714	Prec@(1,5) (87.5%, 98.9%)
06/26 04:02:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][200/391]	Step 4692	Loss 0.3635	Prec@(1,5) (87.8%, 98.9%)
06/26 04:02:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][250/391]	Step 4692	Loss 0.3664	Prec@(1,5) (87.6%, 98.9%)
06/26 04:02:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][300/391]	Step 4692	Loss 0.3627	Prec@(1,5) (87.7%, 99.0%)
06/26 04:02:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][350/391]	Step 4692	Loss 0.3620	Prec@(1,5) (87.8%, 99.0%)
06/26 04:02:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][390/391]	Step 4692	Loss 0.3614	Prec@(1,5) (87.8%, 99.0%)
06/26 04:02:48午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  5/24] Final Prec@1 87.7520%
06/26 04:02:50午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.7520%
06/26 04:02:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][50/781]	Step 4742	lr 0.02175	Loss 0.2908 (0.3630)	Prec@(1,5) (87.8%, 99.5%)	
06/26 04:03:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][100/781]	Step 4792	lr 0.02175	Loss 0.2249 (0.3665)	Prec@(1,5) (87.6%, 99.4%)	
06/26 04:03:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][150/781]	Step 4842	lr 0.02175	Loss 0.2490 (0.3660)	Prec@(1,5) (87.4%, 99.5%)	
06/26 04:03:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][200/781]	Step 4892	lr 0.02175	Loss 0.4483 (0.3625)	Prec@(1,5) (87.7%, 99.5%)	
06/26 04:03:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][250/781]	Step 4942	lr 0.02175	Loss 0.3168 (0.3648)	Prec@(1,5) (87.6%, 99.5%)	
06/26 04:03:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][300/781]	Step 4992	lr 0.02175	Loss 0.3819 (0.3672)	Prec@(1,5) (87.5%, 99.4%)	
06/26 04:03:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][350/781]	Step 5042	lr 0.02175	Loss 0.4275 (0.3716)	Prec@(1,5) (87.3%, 99.4%)	
06/26 04:03:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][400/781]	Step 5092	lr 0.02175	Loss 0.3666 (0.3683)	Prec@(1,5) (87.4%, 99.4%)	
06/26 04:03:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][450/781]	Step 5142	lr 0.02175	Loss 0.2462 (0.3669)	Prec@(1,5) (87.4%, 99.5%)	
06/26 04:03:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][500/781]	Step 5192	lr 0.02175	Loss 0.6356 (0.3665)	Prec@(1,5) (87.4%, 99.5%)	
06/26 04:03:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][550/781]	Step 5242	lr 0.02175	Loss 0.2783 (0.3659)	Prec@(1,5) (87.5%, 99.5%)	
06/26 04:03:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][600/781]	Step 5292	lr 0.02175	Loss 0.5591 (0.3654)	Prec@(1,5) (87.5%, 99.5%)	
06/26 04:03:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][650/781]	Step 5342	lr 0.02175	Loss 0.3290 (0.3623)	Prec@(1,5) (87.7%, 99.5%)	
06/26 04:03:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][700/781]	Step 5392	lr 0.02175	Loss 0.4192 (0.3612)	Prec@(1,5) (87.6%, 99.5%)	
06/26 04:04:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][750/781]	Step 5442	lr 0.02175	Loss 0.4668 (0.3611)	Prec@(1,5) (87.6%, 99.5%)	
06/26 04:04:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][781/781]	Step 5473	lr 0.02175	Loss 0.4645 (0.3596)	Prec@(1,5) (87.6%, 99.5%)	
06/26 04:04:03午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  6/24] Final Prec@1 87.6380%
06/26 04:04:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][50/391]	Step 5474	Loss 0.2999	Prec@(1,5) (90.2%, 99.7%)
06/26 04:04:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][100/391]	Step 5474	Loss 0.3051	Prec@(1,5) (90.2%, 99.7%)
06/26 04:04:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][150/391]	Step 5474	Loss 0.3052	Prec@(1,5) (90.1%, 99.7%)
06/26 04:04:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][200/391]	Step 5474	Loss 0.3023	Prec@(1,5) (90.1%, 99.7%)
06/26 04:04:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][250/391]	Step 5474	Loss 0.3022	Prec@(1,5) (90.0%, 99.7%)
06/26 04:04:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][300/391]	Step 5474	Loss 0.2981	Prec@(1,5) (90.0%, 99.7%)
06/26 04:04:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][350/391]	Step 5474	Loss 0.2995	Prec@(1,5) (90.0%, 99.7%)
06/26 04:04:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][390/391]	Step 5474	Loss 0.3022	Prec@(1,5) (89.8%, 99.7%)
06/26 04:04:12午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  6/24] Final Prec@1 89.8520%
06/26 04:04:13午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.8520%
06/26 04:04:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][50/781]	Step 5524	lr 0.02065	Loss 0.2560 (0.3111)	Prec@(1,5) (89.9%, 99.8%)	
06/26 04:04:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][100/781]	Step 5574	lr 0.02065	Loss 0.3861 (0.3055)	Prec@(1,5) (89.8%, 99.8%)	
06/26 04:04:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][150/781]	Step 5624	lr 0.02065	Loss 0.4117 (0.3118)	Prec@(1,5) (89.4%, 99.7%)	
06/26 04:04:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][200/781]	Step 5674	lr 0.02065	Loss 0.3126 (0.3115)	Prec@(1,5) (89.4%, 99.7%)	
06/26 04:04:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][250/781]	Step 5724	lr 0.02065	Loss 0.2946 (0.3079)	Prec@(1,5) (89.6%, 99.7%)	
06/26 04:04:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][300/781]	Step 5774	lr 0.02065	Loss 0.3352 (0.3037)	Prec@(1,5) (89.7%, 99.8%)	
06/26 04:04:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][350/781]	Step 5824	lr 0.02065	Loss 0.4415 (0.3037)	Prec@(1,5) (89.6%, 99.8%)	
06/26 04:04:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][400/781]	Step 5874	lr 0.02065	Loss 0.3159 (0.3075)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:04:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][450/781]	Step 5924	lr 0.02065	Loss 0.0828 (0.3059)	Prec@(1,5) (89.6%, 99.7%)	
06/26 04:05:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][500/781]	Step 5974	lr 0.02065	Loss 0.2894 (0.3088)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:05:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][550/781]	Step 6024	lr 0.02065	Loss 0.2598 (0.3091)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:05:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][600/781]	Step 6074	lr 0.02065	Loss 0.2675 (0.3105)	Prec@(1,5) (89.4%, 99.7%)	
06/26 04:05:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][650/781]	Step 6124	lr 0.02065	Loss 0.4527 (0.3141)	Prec@(1,5) (89.3%, 99.7%)	
06/26 04:05:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][700/781]	Step 6174	lr 0.02065	Loss 0.3454 (0.3138)	Prec@(1,5) (89.3%, 99.7%)	
06/26 04:05:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][750/781]	Step 6224	lr 0.02065	Loss 0.4074 (0.3152)	Prec@(1,5) (89.2%, 99.7%)	
06/26 04:05:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][781/781]	Step 6255	lr 0.02065	Loss 0.4143 (0.3164)	Prec@(1,5) (89.2%, 99.7%)	
06/26 04:05:26午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  7/24] Final Prec@1 89.2000%
06/26 04:05:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][50/391]	Step 6256	Loss 0.3153	Prec@(1,5) (89.5%, 99.2%)
06/26 04:05:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][100/391]	Step 6256	Loss 0.3214	Prec@(1,5) (89.5%, 99.2%)
06/26 04:05:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][150/391]	Step 6256	Loss 0.3147	Prec@(1,5) (89.7%, 99.2%)
06/26 04:05:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][200/391]	Step 6256	Loss 0.3142	Prec@(1,5) (89.8%, 99.2%)
06/26 04:05:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][250/391]	Step 6256	Loss 0.3177	Prec@(1,5) (89.7%, 99.2%)
06/26 04:05:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][300/391]	Step 6256	Loss 0.3177	Prec@(1,5) (89.6%, 99.3%)
06/26 04:05:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][350/391]	Step 6256	Loss 0.3176	Prec@(1,5) (89.7%, 99.3%)
06/26 04:05:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][390/391]	Step 6256	Loss 0.3149	Prec@(1,5) (89.7%, 99.3%)
06/26 04:05:35午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  7/24] Final Prec@1 89.7000%
06/26 04:05:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.8520%
06/26 04:05:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][50/781]	Step 6306	lr 0.01943	Loss 0.3285 (0.2787)	Prec@(1,5) (90.5%, 99.7%)	
06/26 04:05:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][100/781]	Step 6356	lr 0.01943	Loss 0.2570 (0.2694)	Prec@(1,5) (90.9%, 99.7%)	
06/26 04:05:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][150/781]	Step 6406	lr 0.01943	Loss 0.2459 (0.2865)	Prec@(1,5) (90.3%, 99.8%)	
06/26 04:05:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][200/781]	Step 6456	lr 0.01943	Loss 0.2789 (0.2860)	Prec@(1,5) (90.2%, 99.8%)	
06/26 04:06:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][250/781]	Step 6506	lr 0.01943	Loss 0.4041 (0.2898)	Prec@(1,5) (90.0%, 99.8%)	
06/26 04:06:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][300/781]	Step 6556	lr 0.01943	Loss 0.2889 (0.2981)	Prec@(1,5) (89.7%, 99.8%)	
06/26 04:06:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][350/781]	Step 6606	lr 0.01943	Loss 0.3974 (0.3019)	Prec@(1,5) (89.6%, 99.7%)	
06/26 04:06:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][400/781]	Step 6656	lr 0.01943	Loss 0.3025 (0.3028)	Prec@(1,5) (89.6%, 99.7%)	
06/26 04:06:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][450/781]	Step 6706	lr 0.01943	Loss 0.5016 (0.3083)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][500/781]	Step 6756	lr 0.01943	Loss 0.1678 (0.3059)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][550/781]	Step 6806	lr 0.01943	Loss 0.2378 (0.3082)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][600/781]	Step 6856	lr 0.01943	Loss 0.1939 (0.3070)	Prec@(1,5) (89.6%, 99.7%)	
06/26 04:06:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][650/781]	Step 6906	lr 0.01943	Loss 0.2055 (0.3089)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][700/781]	Step 6956	lr 0.01943	Loss 0.1552 (0.3106)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][750/781]	Step 7006	lr 0.01943	Loss 0.2368 (0.3114)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][781/781]	Step 7037	lr 0.01943	Loss 0.3167 (0.3108)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:06:51午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  8/24] Final Prec@1 89.5000%
06/26 04:06:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][50/391]	Step 7038	Loss 4.2594	Prec@(1,5) (89.0%, 97.9%)
06/26 04:06:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][100/391]	Step 7038	Loss 4.8109	Prec@(1,5) (88.5%, 97.8%)
06/26 04:06:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][150/391]	Step 7038	Loss 4.7301	Prec@(1,5) (88.2%, 97.8%)
06/26 04:06:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][200/391]	Step 7038	Loss 4.4447	Prec@(1,5) (88.3%, 97.9%)
06/26 04:06:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][250/391]	Step 7038	Loss 4.3214	Prec@(1,5) (88.6%, 97.9%)
06/26 04:06:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][300/391]	Step 7038	Loss 4.3772	Prec@(1,5) (88.7%, 97.9%)
06/26 04:06:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][350/391]	Step 7038	Loss 4.2786	Prec@(1,5) (88.6%, 97.9%)
06/26 04:06:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][390/391]	Step 7038	Loss 4.2656	Prec@(1,5) (88.7%, 97.9%)
06/26 04:07:00午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  8/24] Final Prec@1 88.7280%
06/26 04:07:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 89.8520%
06/26 04:07:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][50/781]	Step 7088	lr 0.01811	Loss 0.2461 (0.2589)	Prec@(1,5) (91.0%, 99.8%)	
06/26 04:07:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][100/781]	Step 7138	lr 0.01811	Loss 0.1439 (0.2736)	Prec@(1,5) (90.7%, 99.8%)	
06/26 04:07:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][150/781]	Step 7188	lr 0.01811	Loss 0.3906 (0.2810)	Prec@(1,5) (90.3%, 99.8%)	
06/26 04:07:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][200/781]	Step 7238	lr 0.01811	Loss 0.2353 (0.2775)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:07:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][250/781]	Step 7288	lr 0.01811	Loss 0.2856 (0.2806)	Prec@(1,5) (90.4%, 99.7%)	
06/26 04:07:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][300/781]	Step 7338	lr 0.01811	Loss 0.2772 (0.2819)	Prec@(1,5) (90.3%, 99.8%)	
06/26 04:07:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][350/781]	Step 7388	lr 0.01811	Loss 0.2205 (0.2858)	Prec@(1,5) (90.3%, 99.7%)	
06/26 04:07:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][400/781]	Step 7438	lr 0.01811	Loss 0.3610 (0.2852)	Prec@(1,5) (90.3%, 99.7%)	
06/26 04:07:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][450/781]	Step 7488	lr 0.01811	Loss 0.2878 (0.2838)	Prec@(1,5) (90.3%, 99.7%)	
06/26 04:07:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][500/781]	Step 7538	lr 0.01811	Loss 0.3705 (0.2843)	Prec@(1,5) (90.4%, 99.7%)	
06/26 04:07:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][550/781]	Step 7588	lr 0.01811	Loss 0.3276 (0.2834)	Prec@(1,5) (90.4%, 99.7%)	
06/26 04:07:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][600/781]	Step 7638	lr 0.01811	Loss 0.2366 (0.2854)	Prec@(1,5) (90.3%, 99.7%)	
06/26 04:08:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][650/781]	Step 7688	lr 0.01811	Loss 0.3034 (0.2875)	Prec@(1,5) (90.2%, 99.7%)	
06/26 04:08:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][700/781]	Step 7738	lr 0.01811	Loss 0.2863 (0.2889)	Prec@(1,5) (90.1%, 99.7%)	
06/26 04:08:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][750/781]	Step 7788	lr 0.01811	Loss 0.4707 (0.2898)	Prec@(1,5) (90.1%, 99.7%)	
06/26 04:08:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][781/781]	Step 7819	lr 0.01811	Loss 0.2194 (0.2885)	Prec@(1,5) (90.2%, 99.7%)	
06/26 04:08:13午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  9/24] Final Prec@1 90.1640%
06/26 04:08:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][50/391]	Step 7820	Loss 1.1858	Prec@(1,5) (91.4%, 99.2%)
06/26 04:08:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][100/391]	Step 7820	Loss 1.1743	Prec@(1,5) (91.1%, 99.1%)
06/26 04:08:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][150/391]	Step 7820	Loss 1.3123	Prec@(1,5) (91.0%, 99.0%)
06/26 04:08:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][200/391]	Step 7820	Loss 1.3318	Prec@(1,5) (91.0%, 99.1%)
06/26 04:08:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][250/391]	Step 7820	Loss 1.2417	Prec@(1,5) (91.0%, 99.2%)
06/26 04:08:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][300/391]	Step 7820	Loss 1.2282	Prec@(1,5) (90.9%, 99.2%)
06/26 04:08:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][350/391]	Step 7820	Loss 1.2367	Prec@(1,5) (90.8%, 99.2%)
06/26 04:08:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][390/391]	Step 7820	Loss 1.2501	Prec@(1,5) (90.9%, 99.2%)
06/26 04:08:23午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  9/24] Final Prec@1 90.9200%
06/26 04:08:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 90.9200%
06/26 04:08:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][50/781]	Step 7870	lr 0.01671	Loss 0.2811 (0.2821)	Prec@(1,5) (91.2%, 99.8%)	
06/26 04:08:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][100/781]	Step 7920	lr 0.01671	Loss 0.3642 (0.2873)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:08:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][150/781]	Step 7970	lr 0.01671	Loss 0.2485 (0.2770)	Prec@(1,5) (90.9%, 99.8%)	
06/26 04:08:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][200/781]	Step 8020	lr 0.01671	Loss 0.1524 (0.2762)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:08:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][250/781]	Step 8070	lr 0.01671	Loss 0.2997 (0.2755)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:08:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][300/781]	Step 8120	lr 0.01671	Loss 0.1619 (0.2759)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:08:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][350/781]	Step 8170	lr 0.01671	Loss 0.2357 (0.2719)	Prec@(1,5) (91.0%, 99.8%)	
06/26 04:09:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][400/781]	Step 8220	lr 0.01671	Loss 0.3126 (0.2711)	Prec@(1,5) (91.0%, 99.8%)	
06/26 04:09:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][450/781]	Step 8270	lr 0.01671	Loss 0.2976 (0.2730)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:09:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][500/781]	Step 8320	lr 0.01671	Loss 0.1504 (0.2723)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:09:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][550/781]	Step 8370	lr 0.01671	Loss 0.1617 (0.2712)	Prec@(1,5) (90.9%, 99.8%)	
06/26 04:09:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][600/781]	Step 8420	lr 0.01671	Loss 0.2012 (0.2701)	Prec@(1,5) (90.9%, 99.8%)	
06/26 04:09:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][650/781]	Step 8470	lr 0.01671	Loss 0.3193 (0.2710)	Prec@(1,5) (90.9%, 99.8%)	
06/26 04:09:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][700/781]	Step 8520	lr 0.01671	Loss 0.2306 (0.2713)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:09:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][750/781]	Step 8570	lr 0.01671	Loss 0.2392 (0.2699)	Prec@(1,5) (90.9%, 99.8%)	
06/26 04:09:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][781/781]	Step 8601	lr 0.01671	Loss 0.2244 (0.2699)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:09:39午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 10/24] Final Prec@1 90.8380%
06/26 04:09:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][50/391]	Step 8602	Loss 0.2213	Prec@(1,5) (92.4%, 99.8%)
06/26 04:09:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][100/391]	Step 8602	Loss 0.2182	Prec@(1,5) (92.4%, 99.8%)
06/26 04:09:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][150/391]	Step 8602	Loss 0.2188	Prec@(1,5) (92.5%, 99.8%)
06/26 04:09:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][200/391]	Step 8602	Loss 0.2192	Prec@(1,5) (92.4%, 99.8%)
06/26 04:09:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][250/391]	Step 8602	Loss 0.2242	Prec@(1,5) (92.4%, 99.9%)
06/26 04:09:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][300/391]	Step 8602	Loss 0.2289	Prec@(1,5) (92.3%, 99.8%)
06/26 04:09:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][350/391]	Step 8602	Loss 0.2307	Prec@(1,5) (92.2%, 99.8%)
06/26 04:09:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][390/391]	Step 8602	Loss 0.2416	Prec@(1,5) (92.2%, 99.8%)
06/26 04:09:48午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 10/24] Final Prec@1 92.1880%
06/26 04:09:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 92.1880%
06/26 04:09:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][50/781]	Step 8652	lr 0.01525	Loss 0.1397 (0.2337)	Prec@(1,5) (91.5%, 100.0%)	
06/26 04:09:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][100/781]	Step 8702	lr 0.01525	Loss 0.2452 (0.2217)	Prec@(1,5) (92.2%, 99.9%)	
06/26 04:10:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][150/781]	Step 8752	lr 0.01525	Loss 0.1330 (0.2246)	Prec@(1,5) (92.1%, 99.9%)	
06/26 04:10:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][200/781]	Step 8802	lr 0.01525	Loss 0.3174 (0.2246)	Prec@(1,5) (92.0%, 99.9%)	
06/26 04:10:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][250/781]	Step 8852	lr 0.01525	Loss 0.1857 (0.2285)	Prec@(1,5) (91.8%, 99.9%)	
06/26 04:10:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][300/781]	Step 8902	lr 0.01525	Loss 0.2574 (0.2351)	Prec@(1,5) (91.7%, 99.9%)	
06/26 04:10:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][350/781]	Step 8952	lr 0.01525	Loss 0.4882 (0.2370)	Prec@(1,5) (91.7%, 99.9%)	
06/26 04:10:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][400/781]	Step 9002	lr 0.01525	Loss 0.1817 (0.2347)	Prec@(1,5) (91.7%, 99.9%)	
06/26 04:10:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][450/781]	Step 9052	lr 0.01525	Loss 0.2727 (0.2386)	Prec@(1,5) (91.6%, 99.9%)	
06/26 04:10:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][500/781]	Step 9102	lr 0.01525	Loss 0.2272 (0.2407)	Prec@(1,5) (91.6%, 99.9%)	
06/26 04:10:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][550/781]	Step 9152	lr 0.01525	Loss 0.2341 (0.2401)	Prec@(1,5) (91.7%, 99.9%)	
06/26 04:10:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][600/781]	Step 9202	lr 0.01525	Loss 0.3269 (0.2398)	Prec@(1,5) (91.7%, 99.9%)	
06/26 04:10:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][650/781]	Step 9252	lr 0.01525	Loss 0.1511 (0.2384)	Prec@(1,5) (91.8%, 99.8%)	
06/26 04:10:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][700/781]	Step 9302	lr 0.01525	Loss 0.2022 (0.2376)	Prec@(1,5) (91.8%, 99.8%)	
06/26 04:10:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][750/781]	Step 9352	lr 0.01525	Loss 0.2159 (0.2393)	Prec@(1,5) (91.8%, 99.8%)	
06/26 04:11:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][781/781]	Step 9383	lr 0.01525	Loss 0.2230 (0.2396)	Prec@(1,5) (91.8%, 99.8%)	
06/26 04:11:02午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 11/24] Final Prec@1 91.7900%
06/26 04:11:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][50/391]	Step 9384	Loss 0.2008	Prec@(1,5) (93.2%, 100.0%)
06/26 04:11:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][100/391]	Step 9384	Loss 0.1970	Prec@(1,5) (93.3%, 100.0%)
06/26 04:11:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][150/391]	Step 9384	Loss 0.1941	Prec@(1,5) (93.4%, 99.9%)
06/26 04:11:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][200/391]	Step 9384	Loss 0.1927	Prec@(1,5) (93.4%, 100.0%)
06/26 04:11:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][250/391]	Step 9384	Loss 0.1907	Prec@(1,5) (93.6%, 99.9%)
06/26 04:11:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][300/391]	Step 9384	Loss 0.1932	Prec@(1,5) (93.5%, 99.9%)
06/26 04:11:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][350/391]	Step 9384	Loss 0.1939	Prec@(1,5) (93.4%, 99.9%)
06/26 04:11:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][390/391]	Step 9384	Loss 0.1942	Prec@(1,5) (93.4%, 99.9%)
06/26 04:11:11午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 11/24] Final Prec@1 93.3520%
06/26 04:11:12午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.3520%
06/26 04:11:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][50/781]	Step 9434	lr 0.01375	Loss 0.1390 (0.2014)	Prec@(1,5) (93.3%, 99.9%)	
06/26 04:11:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][100/781]	Step 9484	lr 0.01375	Loss 0.3031 (0.2145)	Prec@(1,5) (92.5%, 99.9%)	
06/26 04:11:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][150/781]	Step 9534	lr 0.01375	Loss 0.4114 (0.2151)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:11:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][200/781]	Step 9584	lr 0.01375	Loss 0.3271 (0.2148)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:11:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][250/781]	Step 9634	lr 0.01375	Loss 0.1583 (0.2118)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:11:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][300/781]	Step 9684	lr 0.01375	Loss 0.3085 (0.2117)	Prec@(1,5) (92.8%, 99.9%)	
06/26 04:11:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][350/781]	Step 9734	lr 0.01375	Loss 0.2641 (0.2111)	Prec@(1,5) (92.8%, 99.9%)	
06/26 04:11:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][400/781]	Step 9784	lr 0.01375	Loss 0.1808 (0.2123)	Prec@(1,5) (92.8%, 99.9%)	
06/26 04:11:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][450/781]	Step 9834	lr 0.01375	Loss 0.1458 (0.2150)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:11:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][500/781]	Step 9884	lr 0.01375	Loss 0.3288 (0.2163)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:12:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][550/781]	Step 9934	lr 0.01375	Loss 0.2643 (0.2176)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:12:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][600/781]	Step 9984	lr 0.01375	Loss 0.3242 (0.2184)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:12:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][650/781]	Step 10034	lr 0.01375	Loss 0.2868 (0.2190)	Prec@(1,5) (92.5%, 99.9%)	
06/26 04:12:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][700/781]	Step 10084	lr 0.01375	Loss 0.3675 (0.2207)	Prec@(1,5) (92.4%, 99.9%)	
06/26 04:12:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][750/781]	Step 10134	lr 0.01375	Loss 0.3207 (0.2214)	Prec@(1,5) (92.4%, 99.9%)	
06/26 04:12:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][781/781]	Step 10165	lr 0.01375	Loss 0.1968 (0.2214)	Prec@(1,5) (92.4%, 99.9%)	
06/26 04:12:25午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 12/24] Final Prec@1 92.3580%
06/26 04:12:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][50/391]	Step 10166	Loss 28.4909	Prec@(1,5) (92.0%, 98.7%)
06/26 04:12:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][100/391]	Step 10166	Loss 26.5871	Prec@(1,5) (91.7%, 98.7%)
06/26 04:12:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][150/391]	Step 10166	Loss 25.3180	Prec@(1,5) (91.6%, 98.8%)
06/26 04:12:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][200/391]	Step 10166	Loss 25.0047	Prec@(1,5) (91.8%, 98.9%)
06/26 04:12:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][250/391]	Step 10166	Loss 26.2896	Prec@(1,5) (91.7%, 98.8%)
06/26 04:12:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][300/391]	Step 10166	Loss 27.0022	Prec@(1,5) (91.7%, 98.8%)
06/26 04:12:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][350/391]	Step 10166	Loss 27.5928	Prec@(1,5) (91.7%, 98.7%)
06/26 04:12:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][390/391]	Step 10166	Loss 26.5090	Prec@(1,5) (91.8%, 98.8%)
06/26 04:12:34午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 12/24] Final Prec@1 91.7480%
06/26 04:12:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.3520%
06/26 04:12:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][50/781]	Step 10216	lr 0.01225	Loss 0.2716 (0.2032)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:12:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][100/781]	Step 10266	lr 0.01225	Loss 0.2261 (0.2001)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:12:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][150/781]	Step 10316	lr 0.01225	Loss 0.3431 (0.1963)	Prec@(1,5) (93.2%, 99.9%)	
06/26 04:12:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][200/781]	Step 10366	lr 0.01225	Loss 0.1522 (0.1968)	Prec@(1,5) (93.2%, 99.9%)	
06/26 04:13:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][250/781]	Step 10416	lr 0.01225	Loss 0.0681 (0.1933)	Prec@(1,5) (93.2%, 99.9%)	
06/26 04:13:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][300/781]	Step 10466	lr 0.01225	Loss 0.1800 (0.2011)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][350/781]	Step 10516	lr 0.01225	Loss 0.2544 (0.2004)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:13:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][400/781]	Step 10566	lr 0.01225	Loss 0.2124 (0.1985)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:13:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][450/781]	Step 10616	lr 0.01225	Loss 0.3661 (0.2023)	Prec@(1,5) (93.0%, 99.8%)	
06/26 04:13:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][500/781]	Step 10666	lr 0.01225	Loss 0.0595 (0.2025)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][550/781]	Step 10716	lr 0.01225	Loss 0.2463 (0.2023)	Prec@(1,5) (93.1%, 99.8%)	
06/26 04:13:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][600/781]	Step 10766	lr 0.01225	Loss 0.1250 (0.2034)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][650/781]	Step 10816	lr 0.01225	Loss 0.1219 (0.2032)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][700/781]	Step 10866	lr 0.01225	Loss 0.1977 (0.2045)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][750/781]	Step 10916	lr 0.01225	Loss 0.2282 (0.2033)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][781/781]	Step 10947	lr 0.01225	Loss 0.2877 (0.2044)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:13:49午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 13/24] Final Prec@1 92.9540%
06/26 04:13:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][50/391]	Step 10948	Loss 0.1706	Prec@(1,5) (94.7%, 99.9%)
06/26 04:13:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][100/391]	Step 10948	Loss 0.1707	Prec@(1,5) (94.6%, 99.9%)
06/26 04:13:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][150/391]	Step 10948	Loss 0.1671	Prec@(1,5) (94.5%, 99.9%)
06/26 04:13:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][200/391]	Step 10948	Loss 0.1631	Prec@(1,5) (94.7%, 99.9%)
06/26 04:13:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][250/391]	Step 10948	Loss 0.1759	Prec@(1,5) (94.7%, 99.9%)
06/26 04:13:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][300/391]	Step 10948	Loss 0.1724	Prec@(1,5) (94.6%, 99.9%)
06/26 04:13:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][350/391]	Step 10948	Loss 0.1695	Prec@(1,5) (94.6%, 99.9%)
06/26 04:13:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][390/391]	Step 10948	Loss 0.1688	Prec@(1,5) (94.7%, 99.9%)
06/26 04:13:58午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 13/24] Final Prec@1 94.6560%
06/26 04:13:59午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 94.6560%
06/26 04:14:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][50/781]	Step 10998	lr 0.01075	Loss 0.2070 (0.1762)	Prec@(1,5) (94.1%, 99.9%)	
06/26 04:14:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][100/781]	Step 11048	lr 0.01075	Loss 0.0816 (0.1830)	Prec@(1,5) (93.8%, 99.9%)	
06/26 04:14:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][150/781]	Step 11098	lr 0.01075	Loss 0.3031 (0.1835)	Prec@(1,5) (93.9%, 99.9%)	
06/26 04:14:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][200/781]	Step 11148	lr 0.01075	Loss 0.2598 (0.1821)	Prec@(1,5) (93.9%, 99.9%)	
06/26 04:14:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][250/781]	Step 11198	lr 0.01075	Loss 0.1227 (0.1818)	Prec@(1,5) (93.9%, 99.9%)	
06/26 04:14:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][300/781]	Step 11248	lr 0.01075	Loss 0.2265 (0.1851)	Prec@(1,5) (93.7%, 99.9%)	
06/26 04:14:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][350/781]	Step 11298	lr 0.01075	Loss 0.2345 (0.1839)	Prec@(1,5) (93.7%, 99.9%)	
06/26 04:14:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][400/781]	Step 11348	lr 0.01075	Loss 0.2201 (0.1850)	Prec@(1,5) (93.6%, 99.9%)	
06/26 04:14:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][450/781]	Step 11398	lr 0.01075	Loss 0.1002 (0.1844)	Prec@(1,5) (93.6%, 99.9%)	
06/26 04:14:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][500/781]	Step 11448	lr 0.01075	Loss 0.0941 (0.1841)	Prec@(1,5) (93.7%, 99.9%)	
06/26 04:14:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][550/781]	Step 11498	lr 0.01075	Loss 0.1260 (0.1841)	Prec@(1,5) (93.7%, 99.9%)	
06/26 04:14:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][600/781]	Step 11548	lr 0.01075	Loss 0.0716 (0.1850)	Prec@(1,5) (93.7%, 99.9%)	
06/26 04:14:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][650/781]	Step 11598	lr 0.01075	Loss 0.1775 (0.1847)	Prec@(1,5) (93.7%, 99.9%)	
06/26 04:15:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][700/781]	Step 11648	lr 0.01075	Loss 0.2117 (0.1848)	Prec@(1,5) (93.6%, 99.9%)	
06/26 04:15:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][750/781]	Step 11698	lr 0.01075	Loss 0.1785 (0.1874)	Prec@(1,5) (93.5%, 99.9%)	
06/26 04:15:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][781/781]	Step 11729	lr 0.01075	Loss 0.3637 (0.1882)	Prec@(1,5) (93.5%, 99.9%)	
06/26 04:15:06午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 14/24] Final Prec@1 93.5300%
06/26 04:15:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][50/391]	Step 11730	Loss 0.4161	Prec@(1,5) (94.1%, 99.9%)
06/26 04:15:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][100/391]	Step 11730	Loss 1.4714	Prec@(1,5) (94.0%, 100.0%)
06/26 04:15:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][150/391]	Step 11730	Loss 1.0379	Prec@(1,5) (94.1%, 99.9%)
06/26 04:15:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][200/391]	Step 11730	Loss 0.8180	Prec@(1,5) (94.2%, 99.9%)
06/26 04:15:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][250/391]	Step 11730	Loss 0.6939	Prec@(1,5) (94.3%, 99.9%)
06/26 04:15:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][300/391]	Step 11730	Loss 0.6185	Prec@(1,5) (94.3%, 99.9%)
06/26 04:15:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][350/391]	Step 11730	Loss 0.5542	Prec@(1,5) (94.3%, 99.9%)
06/26 04:15:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][390/391]	Step 11730	Loss 0.5130	Prec@(1,5) (94.4%, 99.9%)
06/26 04:15:15午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 14/24] Final Prec@1 94.3480%
06/26 04:15:15午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 94.6560%
06/26 04:15:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][50/781]	Step 11780	lr 0.00929	Loss 0.3269 (0.1935)	Prec@(1,5) (93.4%, 99.9%)	
06/26 04:15:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][100/781]	Step 11830	lr 0.00929	Loss 0.2073 (0.1821)	Prec@(1,5) (93.9%, 100.0%)	
06/26 04:15:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][150/781]	Step 11880	lr 0.00929	Loss 0.1660 (0.1710)	Prec@(1,5) (94.2%, 100.0%)	
06/26 04:15:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][200/781]	Step 11930	lr 0.00929	Loss 0.1687 (0.1660)	Prec@(1,5) (94.4%, 99.9%)	
06/26 04:15:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][250/781]	Step 11980	lr 0.00929	Loss 0.2648 (0.1629)	Prec@(1,5) (94.6%, 99.9%)	
06/26 04:15:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][300/781]	Step 12030	lr 0.00929	Loss 0.1119 (0.1616)	Prec@(1,5) (94.6%, 99.9%)	
06/26 04:15:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][350/781]	Step 12080	lr 0.00929	Loss 0.1544 (0.1621)	Prec@(1,5) (94.5%, 99.9%)	
06/26 04:15:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][400/781]	Step 12130	lr 0.00929	Loss 0.1502 (0.1637)	Prec@(1,5) (94.5%, 99.9%)	
06/26 04:15:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][450/781]	Step 12180	lr 0.00929	Loss 0.0916 (0.1660)	Prec@(1,5) (94.4%, 99.9%)	
06/26 04:16:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][500/781]	Step 12230	lr 0.00929	Loss 0.1478 (0.1675)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][550/781]	Step 12280	lr 0.00929	Loss 0.2510 (0.1677)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][600/781]	Step 12330	lr 0.00929	Loss 0.0880 (0.1677)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][650/781]	Step 12380	lr 0.00929	Loss 0.1483 (0.1683)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][700/781]	Step 12430	lr 0.00929	Loss 0.2258 (0.1684)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][750/781]	Step 12480	lr 0.00929	Loss 0.1274 (0.1677)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][781/781]	Step 12511	lr 0.00929	Loss 0.1304 (0.1676)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:16:28午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 15/24] Final Prec@1 94.2980%
06/26 04:16:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][50/391]	Step 12512	Loss 0.1164	Prec@(1,5) (96.1%, 100.0%)
06/26 04:16:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][100/391]	Step 12512	Loss 0.1186	Prec@(1,5) (96.2%, 99.9%)
06/26 04:16:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][150/391]	Step 12512	Loss 0.1291	Prec@(1,5) (95.9%, 99.9%)
06/26 04:16:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][200/391]	Step 12512	Loss 0.1263	Prec@(1,5) (95.9%, 99.9%)
06/26 04:16:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][250/391]	Step 12512	Loss 0.1275	Prec@(1,5) (95.9%, 99.9%)
06/26 04:16:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][300/391]	Step 12512	Loss 0.1280	Prec@(1,5) (95.7%, 100.0%)
06/26 04:16:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][350/391]	Step 12512	Loss 0.1304	Prec@(1,5) (95.7%, 100.0%)
06/26 04:16:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][390/391]	Step 12512	Loss 0.1361	Prec@(1,5) (95.7%, 100.0%)
06/26 04:16:37午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 15/24] Final Prec@1 95.7320%
06/26 04:16:39午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 95.7320%
06/26 04:16:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][50/781]	Step 12562	lr 0.00789	Loss 0.1670 (0.1508)	Prec@(1,5) (94.9%, 99.9%)	
06/26 04:16:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][100/781]	Step 12612	lr 0.00789	Loss 0.1622 (0.1411)	Prec@(1,5) (95.4%, 99.9%)	
06/26 04:16:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][150/781]	Step 12662	lr 0.00789	Loss 0.1944 (0.1380)	Prec@(1,5) (95.4%, 99.9%)	
06/26 04:16:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][200/781]	Step 12712	lr 0.00789	Loss 0.0648 (0.1395)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:17:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][250/781]	Step 12762	lr 0.00789	Loss 0.2955 (0.1400)	Prec@(1,5) (95.3%, 99.9%)	
06/26 04:17:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][300/781]	Step 12812	lr 0.00789	Loss 0.1388 (0.1402)	Prec@(1,5) (95.3%, 99.9%)	
06/26 04:17:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][350/781]	Step 12862	lr 0.00789	Loss 0.1018 (0.1405)	Prec@(1,5) (95.3%, 99.9%)	
06/26 04:17:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][400/781]	Step 12912	lr 0.00789	Loss 0.1430 (0.1405)	Prec@(1,5) (95.2%, 99.9%)	
06/26 04:17:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][450/781]	Step 12962	lr 0.00789	Loss 0.0950 (0.1426)	Prec@(1,5) (95.2%, 99.9%)	
06/26 04:17:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][500/781]	Step 13012	lr 0.00789	Loss 0.3176 (0.1436)	Prec@(1,5) (95.1%, 99.9%)	
06/26 04:17:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][550/781]	Step 13062	lr 0.00789	Loss 0.1356 (0.1463)	Prec@(1,5) (95.0%, 99.9%)	
06/26 04:17:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][600/781]	Step 13112	lr 0.00789	Loss 0.1296 (0.1453)	Prec@(1,5) (95.1%, 99.9%)	
06/26 04:17:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][650/781]	Step 13162	lr 0.00789	Loss 0.2883 (0.1460)	Prec@(1,5) (95.1%, 99.9%)	
06/26 04:17:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][700/781]	Step 13212	lr 0.00789	Loss 0.1449 (0.1479)	Prec@(1,5) (95.0%, 99.9%)	
06/26 04:17:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][750/781]	Step 13262	lr 0.00789	Loss 0.1515 (0.1492)	Prec@(1,5) (95.0%, 99.9%)	
06/26 04:17:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][781/781]	Step 13293	lr 0.00789	Loss 0.1223 (0.1489)	Prec@(1,5) (95.0%, 99.9%)	
06/26 04:17:51午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 16/24] Final Prec@1 94.9740%
06/26 04:17:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][50/391]	Step 13294	Loss 0.8443	Prec@(1,5) (96.1%, 99.9%)
06/26 04:17:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][100/391]	Step 13294	Loss 0.4831	Prec@(1,5) (95.9%, 100.0%)
06/26 04:17:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][150/391]	Step 13294	Loss 0.4703	Prec@(1,5) (96.1%, 100.0%)
06/26 04:17:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][200/391]	Step 13294	Loss 0.3816	Prec@(1,5) (96.2%, 100.0%)
06/26 04:17:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][250/391]	Step 13294	Loss 0.3582	Prec@(1,5) (96.2%, 100.0%)
06/26 04:17:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][300/391]	Step 13294	Loss 0.4629	Prec@(1,5) (96.2%, 100.0%)
06/26 04:17:59午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][350/391]	Step 13294	Loss 0.4116	Prec@(1,5) (96.2%, 100.0%)
06/26 04:18:00午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][390/391]	Step 13294	Loss 0.3811	Prec@(1,5) (96.1%, 100.0%)
06/26 04:18:00午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 16/24] Final Prec@1 96.1480%
06/26 04:18:01午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.1480%
06/26 04:18:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][50/781]	Step 13344	lr 0.00657	Loss 0.1186 (0.1222)	Prec@(1,5) (95.8%, 99.8%)	
06/26 04:18:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][100/781]	Step 13394	lr 0.00657	Loss 0.1958 (0.1225)	Prec@(1,5) (95.8%, 99.9%)	
06/26 04:18:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][150/781]	Step 13444	lr 0.00657	Loss 0.1331 (0.1262)	Prec@(1,5) (95.6%, 99.9%)	
06/26 04:18:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][200/781]	Step 13494	lr 0.00657	Loss 0.1278 (0.1267)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:18:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][250/781]	Step 13544	lr 0.00657	Loss 0.0592 (0.1275)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:18:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][300/781]	Step 13594	lr 0.00657	Loss 0.1821 (0.1265)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:18:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][350/781]	Step 13644	lr 0.00657	Loss 0.1396 (0.1257)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:18:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][400/781]	Step 13694	lr 0.00657	Loss 0.1757 (0.1275)	Prec@(1,5) (95.6%, 99.9%)	
06/26 04:18:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][450/781]	Step 13744	lr 0.00657	Loss 0.2202 (0.1255)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:18:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][500/781]	Step 13794	lr 0.00657	Loss 0.1247 (0.1263)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:18:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][550/781]	Step 13844	lr 0.00657	Loss 0.1760 (0.1252)	Prec@(1,5) (95.8%, 99.9%)	
06/26 04:18:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][600/781]	Step 13894	lr 0.00657	Loss 0.0878 (0.1258)	Prec@(1,5) (95.8%, 99.9%)	
06/26 04:19:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][650/781]	Step 13944	lr 0.00657	Loss 0.0985 (0.1255)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:19:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][700/781]	Step 13994	lr 0.00657	Loss 0.0931 (0.1259)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:19:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][750/781]	Step 14044	lr 0.00657	Loss 0.1244 (0.1264)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:19:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][781/781]	Step 14075	lr 0.00657	Loss 0.1283 (0.1261)	Prec@(1,5) (95.7%, 99.9%)	
06/26 04:19:15午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 17/24] Final Prec@1 95.7060%
06/26 04:19:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][50/391]	Step 14076	Loss 0.1108	Prec@(1,5) (95.9%, 100.0%)
06/26 04:19:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][100/391]	Step 14076	Loss 0.1069	Prec@(1,5) (96.0%, 100.0%)
06/26 04:19:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][150/391]	Step 14076	Loss 0.1067	Prec@(1,5) (96.1%, 100.0%)
06/26 04:19:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][200/391]	Step 14076	Loss 0.1175	Prec@(1,5) (96.1%, 100.0%)
06/26 04:19:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][250/391]	Step 14076	Loss 0.1129	Prec@(1,5) (96.2%, 100.0%)
06/26 04:19:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][300/391]	Step 14076	Loss 0.1139	Prec@(1,5) (96.3%, 100.0%)
06/26 04:19:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][350/391]	Step 14076	Loss 0.1125	Prec@(1,5) (96.3%, 100.0%)
06/26 04:19:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][390/391]	Step 14076	Loss 0.1135	Prec@(1,5) (96.3%, 100.0%)
06/26 04:19:24午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 17/24] Final Prec@1 96.3000%
06/26 04:19:25午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.3000%
06/26 04:19:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][50/781]	Step 14126	lr 0.00535	Loss 0.1221 (0.1106)	Prec@(1,5) (96.5%, 99.8%)	
06/26 04:19:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][100/781]	Step 14176	lr 0.00535	Loss 0.0899 (0.1127)	Prec@(1,5) (96.1%, 99.8%)	
06/26 04:19:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][150/781]	Step 14226	lr 0.00535	Loss 0.0245 (0.1101)	Prec@(1,5) (96.2%, 99.9%)	
06/26 04:19:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][200/781]	Step 14276	lr 0.00535	Loss 0.1364 (0.1068)	Prec@(1,5) (96.3%, 99.9%)	
06/26 04:19:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][250/781]	Step 14326	lr 0.00535	Loss 0.1148 (0.1037)	Prec@(1,5) (96.3%, 99.9%)	
06/26 04:19:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][300/781]	Step 14376	lr 0.00535	Loss 0.0677 (0.1022)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:19:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][350/781]	Step 14426	lr 0.00535	Loss 0.0473 (0.1036)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:20:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][400/781]	Step 14476	lr 0.00535	Loss 0.2755 (0.1033)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:20:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][450/781]	Step 14526	lr 0.00535	Loss 0.0084 (0.1027)	Prec@(1,5) (96.5%, 99.9%)	
06/26 04:20:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][500/781]	Step 14576	lr 0.00535	Loss 0.0628 (0.1039)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:20:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][550/781]	Step 14626	lr 0.00535	Loss 0.1353 (0.1042)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:20:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][600/781]	Step 14676	lr 0.00535	Loss 0.1611 (0.1047)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:20:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][650/781]	Step 14726	lr 0.00535	Loss 0.0669 (0.1054)	Prec@(1,5) (96.3%, 99.9%)	
06/26 04:20:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][700/781]	Step 14776	lr 0.00535	Loss 0.1851 (0.1049)	Prec@(1,5) (96.3%, 99.9%)	
06/26 04:20:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][750/781]	Step 14826	lr 0.00535	Loss 0.0286 (0.1045)	Prec@(1,5) (96.4%, 99.9%)	
06/26 04:20:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][781/781]	Step 14857	lr 0.00535	Loss 0.1067 (0.1049)	Prec@(1,5) (96.3%, 100.0%)	
06/26 04:20:39午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 18/24] Final Prec@1 96.3440%
06/26 04:20:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][50/391]	Step 14858	Loss 0.0719	Prec@(1,5) (97.7%, 100.0%)
06/26 04:20:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][100/391]	Step 14858	Loss 0.0745	Prec@(1,5) (97.4%, 100.0%)
06/26 04:20:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][150/391]	Step 14858	Loss 0.0776	Prec@(1,5) (97.4%, 100.0%)
06/26 04:20:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][200/391]	Step 14858	Loss 0.0792	Prec@(1,5) (97.3%, 100.0%)
06/26 04:20:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][250/391]	Step 14858	Loss 0.0803	Prec@(1,5) (97.3%, 100.0%)
06/26 04:20:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][300/391]	Step 14858	Loss 0.0782	Prec@(1,5) (97.3%, 100.0%)
06/26 04:20:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][350/391]	Step 14858	Loss 0.0782	Prec@(1,5) (97.4%, 100.0%)
06/26 04:20:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][390/391]	Step 14858	Loss 0.0787	Prec@(1,5) (97.4%, 100.0%)
06/26 04:20:47午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 18/24] Final Prec@1 97.3880%
06/26 04:20:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.3880%
06/26 04:20:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][50/781]	Step 14908	lr 0.00425	Loss 0.0485 (0.0987)	Prec@(1,5) (97.0%, 100.0%)	
06/26 04:20:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][100/781]	Step 14958	lr 0.00425	Loss 0.0606 (0.0925)	Prec@(1,5) (97.0%, 100.0%)	
06/26 04:21:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][150/781]	Step 15008	lr 0.00425	Loss 0.1534 (0.0926)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:21:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][200/781]	Step 15058	lr 0.00425	Loss 0.0480 (0.0925)	Prec@(1,5) (97.0%, 100.0%)	
06/26 04:21:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][250/781]	Step 15108	lr 0.00425	Loss 0.1893 (0.0920)	Prec@(1,5) (97.0%, 100.0%)	
06/26 04:21:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][300/781]	Step 15158	lr 0.00425	Loss 0.0506 (0.0916)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:21:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][350/781]	Step 15208	lr 0.00425	Loss 0.0546 (0.0911)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:21:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][400/781]	Step 15258	lr 0.00425	Loss 0.1532 (0.0933)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:21:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][450/781]	Step 15308	lr 0.00425	Loss 0.1011 (0.0931)	Prec@(1,5) (96.8%, 100.0%)	
06/26 04:21:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][500/781]	Step 15358	lr 0.00425	Loss 0.0238 (0.0933)	Prec@(1,5) (96.8%, 100.0%)	
06/26 04:21:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][550/781]	Step 15408	lr 0.00425	Loss 0.0273 (0.0935)	Prec@(1,5) (96.8%, 100.0%)	
06/26 04:21:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][600/781]	Step 15458	lr 0.00425	Loss 0.0984 (0.0928)	Prec@(1,5) (96.8%, 100.0%)	
06/26 04:21:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][650/781]	Step 15508	lr 0.00425	Loss 0.1029 (0.0931)	Prec@(1,5) (96.8%, 100.0%)	
06/26 04:21:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][700/781]	Step 15558	lr 0.00425	Loss 0.0628 (0.0925)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:21:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][750/781]	Step 15608	lr 0.00425	Loss 0.2380 (0.0924)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:22:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][781/781]	Step 15639	lr 0.00425	Loss 0.0840 (0.0924)	Prec@(1,5) (96.9%, 100.0%)	
06/26 04:22:01午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 19/24] Final Prec@1 96.8580%
06/26 04:22:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][50/391]	Step 15640	Loss 0.0842	Prec@(1,5) (97.3%, 100.0%)
06/26 04:22:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][100/391]	Step 15640	Loss 0.1111	Prec@(1,5) (96.9%, 100.0%)
06/26 04:22:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][150/391]	Step 15640	Loss 0.1069	Prec@(1,5) (97.1%, 100.0%)
06/26 04:22:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][200/391]	Step 15640	Loss 0.1113	Prec@(1,5) (97.1%, 100.0%)
06/26 04:22:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][250/391]	Step 15640	Loss 0.1105	Prec@(1,5) (97.1%, 100.0%)
06/26 04:22:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][300/391]	Step 15640	Loss 0.1087	Prec@(1,5) (97.1%, 100.0%)
06/26 04:22:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][350/391]	Step 15640	Loss 0.1109	Prec@(1,5) (97.1%, 100.0%)
06/26 04:22:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][390/391]	Step 15640	Loss 0.1107	Prec@(1,5) (97.2%, 100.0%)
06/26 04:22:10午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 19/24] Final Prec@1 97.1520%
06/26 04:22:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 97.3880%
06/26 04:22:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][50/781]	Step 15690	lr 0.00329	Loss 0.0445 (0.0666)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:22:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][100/781]	Step 15740	lr 0.00329	Loss 0.0122 (0.0710)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:22:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][150/781]	Step 15790	lr 0.00329	Loss 0.1325 (0.0701)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:22:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][200/781]	Step 15840	lr 0.00329	Loss 0.0932 (0.0703)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:22:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][250/781]	Step 15890	lr 0.00329	Loss 0.0712 (0.0686)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:22:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][300/781]	Step 15940	lr 0.00329	Loss 0.0381 (0.0678)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:22:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][350/781]	Step 15990	lr 0.00329	Loss 0.0971 (0.0668)	Prec@(1,5) (97.8%, 100.0%)	
06/26 04:22:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][400/781]	Step 16040	lr 0.00329	Loss 0.1207 (0.0672)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:22:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][450/781]	Step 16090	lr 0.00329	Loss 0.1857 (0.0690)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:22:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][500/781]	Step 16140	lr 0.00329	Loss 0.1902 (0.0694)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:23:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][550/781]	Step 16190	lr 0.00329	Loss 0.1474 (0.0703)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:23:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][600/781]	Step 16240	lr 0.00329	Loss 0.2010 (0.0707)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:23:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][650/781]	Step 16290	lr 0.00329	Loss 0.0515 (0.0710)	Prec@(1,5) (97.5%, 100.0%)	
06/26 04:23:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][700/781]	Step 16340	lr 0.00329	Loss 0.0254 (0.0701)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:23:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][750/781]	Step 16390	lr 0.00329	Loss 0.0688 (0.0704)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:23:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][781/781]	Step 16421	lr 0.00329	Loss 0.0153 (0.0704)	Prec@(1,5) (97.6%, 100.0%)	
06/26 04:23:24午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 20/24] Final Prec@1 97.5580%
06/26 04:23:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][50/391]	Step 16422	Loss 0.0477	Prec@(1,5) (98.3%, 100.0%)
06/26 04:23:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][100/391]	Step 16422	Loss 0.0484	Prec@(1,5) (98.3%, 100.0%)
06/26 04:23:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][150/391]	Step 16422	Loss 0.0468	Prec@(1,5) (98.4%, 100.0%)
06/26 04:23:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][200/391]	Step 16422	Loss 0.0479	Prec@(1,5) (98.3%, 100.0%)
06/26 04:23:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][250/391]	Step 16422	Loss 0.0482	Prec@(1,5) (98.3%, 100.0%)
06/26 04:23:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][300/391]	Step 16422	Loss 0.0469	Prec@(1,5) (98.4%, 100.0%)
06/26 04:23:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][350/391]	Step 16422	Loss 0.0464	Prec@(1,5) (98.4%, 100.0%)
06/26 04:23:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][390/391]	Step 16422	Loss 0.0469	Prec@(1,5) (98.4%, 100.0%)
06/26 04:23:33午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 20/24] Final Prec@1 98.3880%
06/26 04:23:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 98.3880%
06/26 04:23:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][50/781]	Step 16472	lr 0.00248	Loss 0.0355 (0.0621)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:23:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][100/781]	Step 16522	lr 0.00248	Loss 0.0826 (0.0686)	Prec@(1,5) (97.7%, 100.0%)	
06/26 04:23:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][150/781]	Step 16572	lr 0.00248	Loss 0.0508 (0.0635)	Prec@(1,5) (97.9%, 100.0%)	
06/26 04:23:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][200/781]	Step 16622	lr 0.00248	Loss 0.1430 (0.0627)	Prec@(1,5) (97.9%, 100.0%)	
06/26 04:23:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][250/781]	Step 16672	lr 0.00248	Loss 0.1440 (0.0629)	Prec@(1,5) (97.9%, 100.0%)	
06/26 04:24:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][300/781]	Step 16722	lr 0.00248	Loss 0.0265 (0.0610)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][350/781]	Step 16772	lr 0.00248	Loss 0.0921 (0.0607)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][400/781]	Step 16822	lr 0.00248	Loss 0.0183 (0.0596)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][450/781]	Step 16872	lr 0.00248	Loss 0.0827 (0.0587)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][500/781]	Step 16922	lr 0.00248	Loss 0.0343 (0.0587)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][550/781]	Step 16972	lr 0.00248	Loss 0.1315 (0.0599)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][600/781]	Step 17022	lr 0.00248	Loss 0.0239 (0.0600)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][650/781]	Step 17072	lr 0.00248	Loss 0.0800 (0.0602)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][700/781]	Step 17122	lr 0.00248	Loss 0.0163 (0.0602)	Prec@(1,5) (98.0%, 100.0%)	
06/26 04:24:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][750/781]	Step 17172	lr 0.00248	Loss 0.2411 (0.0606)	Prec@(1,5) (97.9%, 100.0%)	
06/26 04:24:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][781/781]	Step 17203	lr 0.00248	Loss 0.0666 (0.0607)	Prec@(1,5) (97.9%, 100.0%)	
06/26 04:24:48午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 21/24] Final Prec@1 97.9400%
06/26 04:24:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][50/391]	Step 17204	Loss 0.0379	Prec@(1,5) (98.6%, 100.0%)
06/26 04:24:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][100/391]	Step 17204	Loss 0.0377	Prec@(1,5) (98.7%, 100.0%)
06/26 04:24:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][150/391]	Step 17204	Loss 0.0400	Prec@(1,5) (98.7%, 100.0%)
06/26 04:24:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][200/391]	Step 17204	Loss 0.0411	Prec@(1,5) (98.6%, 100.0%)
06/26 04:24:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][250/391]	Step 17204	Loss 0.0406	Prec@(1,5) (98.7%, 100.0%)
06/26 04:24:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][300/391]	Step 17204	Loss 0.0392	Prec@(1,5) (98.7%, 100.0%)
06/26 04:24:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][350/391]	Step 17204	Loss 0.0390	Prec@(1,5) (98.7%, 100.0%)
06/26 04:24:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][390/391]	Step 17204	Loss 0.0391	Prec@(1,5) (98.7%, 100.0%)
06/26 04:24:58午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 21/24] Final Prec@1 98.7240%
06/26 04:24:59午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 98.7240%
06/26 04:25:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][50/781]	Step 17254	lr 0.00184	Loss 0.0174 (0.0491)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][100/781]	Step 17304	lr 0.00184	Loss 0.0580 (0.0501)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][150/781]	Step 17354	lr 0.00184	Loss 0.0829 (0.0498)	Prec@(1,5) (98.4%, 100.0%)	
06/26 04:25:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][200/781]	Step 17404	lr 0.00184	Loss 0.0939 (0.0509)	Prec@(1,5) (98.4%, 100.0%)	
06/26 04:25:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][250/781]	Step 17454	lr 0.00184	Loss 0.0470 (0.0510)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][300/781]	Step 17504	lr 0.00184	Loss 0.0775 (0.0506)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][350/781]	Step 17554	lr 0.00184	Loss 0.1046 (0.0511)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][400/781]	Step 17604	lr 0.00184	Loss 0.0136 (0.0511)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][450/781]	Step 17654	lr 0.00184	Loss 0.0510 (0.0506)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][500/781]	Step 17704	lr 0.00184	Loss 0.1127 (0.0500)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][550/781]	Step 17754	lr 0.00184	Loss 0.0084 (0.0500)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:25:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][600/781]	Step 17804	lr 0.00184	Loss 0.0389 (0.0503)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:26:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][650/781]	Step 17854	lr 0.00184	Loss 0.0129 (0.0498)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:26:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][700/781]	Step 17904	lr 0.00184	Loss 0.0103 (0.0494)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:26:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][750/781]	Step 17954	lr 0.00184	Loss 0.1230 (0.0492)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:26:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][781/781]	Step 17985	lr 0.00184	Loss 0.1140 (0.0492)	Prec@(1,5) (98.3%, 100.0%)	
06/26 04:26:12午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 22/24] Final Prec@1 98.3340%
06/26 04:26:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][50/391]	Step 17986	Loss 0.0327	Prec@(1,5) (99.0%, 100.0%)
06/26 04:26:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][100/391]	Step 17986	Loss 0.0343	Prec@(1,5) (98.9%, 100.0%)
06/26 04:26:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][150/391]	Step 17986	Loss 0.0346	Prec@(1,5) (98.8%, 100.0%)
06/26 04:26:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][200/391]	Step 17986	Loss 0.0342	Prec@(1,5) (98.9%, 100.0%)
06/26 04:26:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][250/391]	Step 17986	Loss 0.0342	Prec@(1,5) (98.9%, 100.0%)
06/26 04:26:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][300/391]	Step 17986	Loss 0.0334	Prec@(1,5) (98.9%, 100.0%)
06/26 04:26:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][350/391]	Step 17986	Loss 0.0336	Prec@(1,5) (98.9%, 100.0%)
06/26 04:26:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][390/391]	Step 17986	Loss 0.0339	Prec@(1,5) (98.9%, 100.0%)
06/26 04:26:21午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 22/24] Final Prec@1 98.9400%
06/26 04:26:23午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 98.9400%
06/26 04:26:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][50/781]	Step 18036	lr 0.00138	Loss 0.0471 (0.0401)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:26:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][100/781]	Step 18086	lr 0.00138	Loss 0.0275 (0.0372)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:26:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][150/781]	Step 18136	lr 0.00138	Loss 0.0453 (0.0376)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:26:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][200/781]	Step 18186	lr 0.00138	Loss 0.0149 (0.0384)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:26:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][250/781]	Step 18236	lr 0.00138	Loss 0.0209 (0.0391)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:26:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][300/781]	Step 18286	lr 0.00138	Loss 0.0048 (0.0403)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:26:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][350/781]	Step 18336	lr 0.00138	Loss 0.0162 (0.0389)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:27:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][400/781]	Step 18386	lr 0.00138	Loss 0.0909 (0.0391)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:27:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][450/781]	Step 18436	lr 0.00138	Loss 0.0032 (0.0388)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:27:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][500/781]	Step 18486	lr 0.00138	Loss 0.1035 (0.0398)	Prec@(1,5) (98.6%, 100.0%)	
06/26 04:27:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][550/781]	Step 18536	lr 0.00138	Loss 0.0075 (0.0399)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:27:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][600/781]	Step 18586	lr 0.00138	Loss 0.0031 (0.0398)	Prec@(1,5) (98.6%, 100.0%)	
06/26 04:27:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][650/781]	Step 18636	lr 0.00138	Loss 0.0307 (0.0395)	Prec@(1,5) (98.6%, 100.0%)	
06/26 04:27:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][700/781]	Step 18686	lr 0.00138	Loss 0.0457 (0.0398)	Prec@(1,5) (98.6%, 100.0%)	
06/26 04:27:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][750/781]	Step 18736	lr 0.00138	Loss 0.0071 (0.0397)	Prec@(1,5) (98.6%, 100.0%)	
06/26 04:27:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][781/781]	Step 18767	lr 0.00138	Loss 0.0154 (0.0393)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:27:37午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 23/24] Final Prec@1 98.6640%
06/26 04:27:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][50/391]	Step 18768	Loss 0.0238	Prec@(1,5) (99.1%, 100.0%)
06/26 04:27:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][100/391]	Step 18768	Loss 0.0270	Prec@(1,5) (99.0%, 100.0%)
06/26 04:27:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][150/391]	Step 18768	Loss 0.0293	Prec@(1,5) (99.0%, 100.0%)
06/26 04:27:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][200/391]	Step 18768	Loss 0.0290	Prec@(1,5) (99.0%, 100.0%)
06/26 04:27:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][250/391]	Step 18768	Loss 0.0273	Prec@(1,5) (99.1%, 100.0%)
06/26 04:27:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][300/391]	Step 18768	Loss 0.0274	Prec@(1,5) (99.1%, 100.0%)
06/26 04:27:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][350/391]	Step 18768	Loss 0.0272	Prec@(1,5) (99.1%, 100.0%)
06/26 04:27:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][390/391]	Step 18768	Loss 0.0275	Prec@(1,5) (99.1%, 100.0%)
06/26 04:27:46午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 23/24] Final Prec@1 99.1400%
06/26 04:27:47午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 99.1400%
06/26 04:27:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][50/781]	Step 18818	lr 0.00109	Loss 0.0042 (0.0388)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:27:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][100/781]	Step 18868	lr 0.00109	Loss 0.0011 (0.0367)	Prec@(1,5) (98.8%, 100.0%)	
06/26 04:28:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][150/781]	Step 18918	lr 0.00109	Loss 0.0104 (0.0380)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][200/781]	Step 18968	lr 0.00109	Loss 0.0591 (0.0366)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][250/781]	Step 19018	lr 0.00109	Loss 0.0202 (0.0379)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][300/781]	Step 19068	lr 0.00109	Loss 0.0291 (0.0375)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][350/781]	Step 19118	lr 0.00109	Loss 0.0624 (0.0377)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][400/781]	Step 19168	lr 0.00109	Loss 0.0288 (0.0379)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][450/781]	Step 19218	lr 0.00109	Loss 0.0240 (0.0377)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][500/781]	Step 19268	lr 0.00109	Loss 0.0128 (0.0376)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][550/781]	Step 19318	lr 0.00109	Loss 0.0318 (0.0375)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][600/781]	Step 19368	lr 0.00109	Loss 0.0609 (0.0368)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][650/781]	Step 19418	lr 0.00109	Loss 0.0637 (0.0374)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][700/781]	Step 19468	lr 0.00109	Loss 0.0921 (0.0375)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:28:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][750/781]	Step 19518	lr 0.00109	Loss 0.0251 (0.0376)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:29:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][781/781]	Step 19549	lr 0.00109	Loss 0.0237 (0.0377)	Prec@(1,5) (98.7%, 100.0%)	
06/26 04:29:00午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 24/24] Final Prec@1 98.6940%
06/26 04:29:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][50/391]	Step 19550	Loss 0.0293	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][100/391]	Step 19550	Loss 0.0260	Prec@(1,5) (99.3%, 100.0%)
06/26 04:29:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][150/391]	Step 19550	Loss 0.0261	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][200/391]	Step 19550	Loss 0.0249	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][250/391]	Step 19550	Loss 0.0256	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][300/391]	Step 19550	Loss 0.0261	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][350/391]	Step 19550	Loss 0.0263	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][390/391]	Step 19550	Loss 0.0262	Prec@(1,5) (99.2%, 100.0%)
06/26 04:29:10午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 24/24] Final Prec@1 99.1920%
06/26 04:29:11午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 99.1920%
06/26 04:29:11午後 finetuneTeacher_main.py:56 [INFO] Final best Prec@1 = 99.1920%
