06/26 04:21:57PM parser.py:28 [INFO] 
06/26 04:21:57PM parser.py:29 [INFO] Parameters:
06/26 04:21:57PM parser.py:31 [INFO] BATCH_SIZE=64
06/26 04:21:57PM parser.py:31 [INFO] CUTOUT_LENGTH=0
06/26 04:21:57PM parser.py:31 [INFO] DATA_PATH=../data/
06/26 04:21:57PM parser.py:31 [INFO] DATASET=cifar10
06/26 04:21:57PM parser.py:31 [INFO] EPOCHS=25
06/26 04:21:57PM parser.py:31 [INFO] EXP_NAME=E25-20240626-162157
06/26 04:21:57PM parser.py:31 [INFO] GPUS=[0]
06/26 04:21:57PM parser.py:31 [INFO] LOCAL_RANK=0
06/26 04:21:57PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
06/26 04:21:57PM parser.py:31 [INFO] MODEL_NAME=resnet152
06/26 04:21:57PM parser.py:31 [INFO] NAME=FINETUNE
06/26 04:21:57PM parser.py:31 [INFO] PATH=results/teacher/cifar10/resnet152/FINETUNE/E25-20240626-162157
06/26 04:21:57PM parser.py:31 [INFO] PLOT_PATH=results/teacher/cifar10/resnet152/FINETUNE/E25-20240626-162157/plots
06/26 04:21:57PM parser.py:31 [INFO] PRINT_FREQ=50
06/26 04:21:57PM parser.py:31 [INFO] RESUME_PATH=None
06/26 04:21:57PM parser.py:31 [INFO] SAVE=E25
06/26 04:21:57PM parser.py:31 [INFO] SEED=0
06/26 04:21:57PM parser.py:31 [INFO] TRAIN_PORTION=1.0
06/26 04:21:57PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
06/26 04:21:57PM parser.py:31 [INFO] W_LR=0.025
06/26 04:21:57PM parser.py:31 [INFO] W_LR_MIN=0.001
06/26 04:21:57PM parser.py:31 [INFO] W_MOMENTUM=0.9
06/26 04:21:57PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
06/26 04:21:57PM parser.py:31 [INFO] WORKERS=4
06/26 04:21:57PM parser.py:32 [INFO] 
06/26 04:22:03PM finetuneTeacher_trainer.py:109 [INFO] --> No loaded checkpoint!
06/26 04:22:08PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][50/781]	Step 50	lr 0.025	Loss 1.4939 (1.9110)	Prec@(1,5) (31.8%, 79.3%)	
06/26 04:22:11PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][100/781]	Step 100	lr 0.025	Loss 1.6743 (1.7754)	Prec@(1,5) (38.7%, 84.8%)	
06/26 04:22:14PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][150/781]	Step 150	lr 0.025	Loss 1.7356 (1.6929)	Prec@(1,5) (42.1%, 87.2%)	
06/26 04:22:18PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][200/781]	Step 200	lr 0.025	Loss 1.5001 (1.6611)	Prec@(1,5) (44.5%, 88.6%)	
06/26 04:22:21PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][250/781]	Step 250	lr 0.025	Loss 1.7428 (1.6187)	Prec@(1,5) (46.4%, 89.4%)	
06/26 04:22:25PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][300/781]	Step 300	lr 0.025	Loss 1.6023 (1.5734)	Prec@(1,5) (48.0%, 90.2%)	
06/26 04:22:28PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][350/781]	Step 350	lr 0.025	Loss 1.3357 (1.5379)	Prec@(1,5) (49.0%, 90.9%)	
06/26 04:22:31PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][400/781]	Step 400	lr 0.025	Loss 1.2241 (1.5072)	Prec@(1,5) (50.0%, 91.4%)	
06/26 04:22:34PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][450/781]	Step 450	lr 0.025	Loss 1.3276 (1.4672)	Prec@(1,5) (51.3%, 91.9%)	
06/26 04:22:38PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][500/781]	Step 500	lr 0.025	Loss 1.0652 (1.4410)	Prec@(1,5) (52.3%, 92.3%)	
06/26 04:22:41PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][550/781]	Step 550	lr 0.025	Loss 1.3113 (1.4112)	Prec@(1,5) (53.4%, 92.6%)	
06/26 04:22:44PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][600/781]	Step 600	lr 0.025	Loss 0.9636 (1.3789)	Prec@(1,5) (54.4%, 93.0%)	
06/26 04:22:47PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][650/781]	Step 650	lr 0.025	Loss 0.8166 (1.3500)	Prec@(1,5) (55.4%, 93.3%)	
06/26 04:22:50PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][700/781]	Step 700	lr 0.025	Loss 1.0588 (1.3302)	Prec@(1,5) (56.2%, 93.5%)	
06/26 04:22:53PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][750/781]	Step 750	lr 0.025	Loss 1.1962 (1.3116)	Prec@(1,5) (56.7%, 93.7%)	
06/26 04:22:54PM finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [0][781/781]	Step 781	lr 0.025	Loss 1.0290 (1.3030)	Prec@(1,5) (57.0%, 93.8%)	
06/26 04:22:56PM finetuneTeacher_trainer.py:181 [INFO] Train: [  0/24] Final Prec@1 56.9980%
06/26 04:22:57PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][50/391]	Step 782	Loss 1.0436	Prec@(1,5) (65.5%, 97.1%)
06/26 04:22:58PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][100/391]	Step 782	Loss 1.0696	Prec@(1,5) (64.3%, 97.0%)
06/26 04:22:59PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][150/391]	Step 782	Loss 1.0643	Prec@(1,5) (64.5%, 96.9%)
06/26 04:23:00PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][200/391]	Step 782	Loss 1.0502	Prec@(1,5) (64.9%, 97.0%)
06/26 04:23:00PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][250/391]	Step 782	Loss 1.0469	Prec@(1,5) (65.0%, 97.1%)
06/26 04:23:01PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][300/391]	Step 782	Loss 1.0492	Prec@(1,5) (64.9%, 97.0%)
06/26 04:23:02PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][350/391]	Step 782	Loss 1.0548	Prec@(1,5) (64.8%, 96.9%)
06/26 04:23:03PM finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [0][390/391]	Step 782	Loss 1.0537	Prec@(1,5) (64.8%, 96.8%)
06/26 04:23:04PM finetuneTeacher_trainer.py:216 [INFO] Valid: [  0/24] Final Prec@1 64.7760%
06/26 04:23:05午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 64.7760%
06/26 04:23:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][50/781]	Step 832	lr 0.02491	Loss 1.1013 (1.0729)	Prec@(1,5) (64.9%, 96.3%)	
06/26 04:23:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][100/781]	Step 882	lr 0.02491	Loss 0.9144 (1.0564)	Prec@(1,5) (65.2%, 96.3%)	
06/26 04:23:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][150/781]	Step 932	lr 0.02491	Loss 1.1417 (1.0468)	Prec@(1,5) (65.2%, 96.5%)	
06/26 04:23:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][200/781]	Step 982	lr 0.02491	Loss 0.9216 (1.0299)	Prec@(1,5) (65.6%, 96.6%)	
06/26 04:23:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][250/781]	Step 1032	lr 0.02491	Loss 1.0211 (1.0158)	Prec@(1,5) (66.2%, 96.6%)	
06/26 04:23:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][300/781]	Step 1082	lr 0.02491	Loss 0.7169 (1.0009)	Prec@(1,5) (66.4%, 96.7%)	
06/26 04:23:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][350/781]	Step 1132	lr 0.02491	Loss 1.1498 (0.9862)	Prec@(1,5) (67.0%, 96.9%)	
06/26 04:23:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][400/781]	Step 1182	lr 0.02491	Loss 0.5451 (0.9791)	Prec@(1,5) (67.3%, 96.9%)	
06/26 04:23:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][450/781]	Step 1232	lr 0.02491	Loss 1.0786 (0.9739)	Prec@(1,5) (67.4%, 96.9%)	
06/26 04:23:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][500/781]	Step 1282	lr 0.02491	Loss 0.9040 (0.9759)	Prec@(1,5) (67.2%, 96.9%)	
06/26 04:23:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][550/781]	Step 1332	lr 0.02491	Loss 1.0031 (0.9659)	Prec@(1,5) (67.5%, 97.0%)	
06/26 04:23:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][600/781]	Step 1382	lr 0.02491	Loss 0.7397 (0.9596)	Prec@(1,5) (67.8%, 97.0%)	
06/26 04:23:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][650/781]	Step 1432	lr 0.02491	Loss 0.7870 (0.9499)	Prec@(1,5) (68.1%, 97.0%)	
06/26 04:23:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][700/781]	Step 1482	lr 0.02491	Loss 1.0190 (0.9410)	Prec@(1,5) (68.4%, 97.1%)	
06/26 04:23:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][750/781]	Step 1532	lr 0.02491	Loss 1.0319 (0.9359)	Prec@(1,5) (68.5%, 97.1%)	
06/26 04:24:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [1][781/781]	Step 1563	lr 0.02491	Loss 0.8986 (0.9308)	Prec@(1,5) (68.7%, 97.2%)	
06/26 04:24:01午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  1/24] Final Prec@1 68.6480%
06/26 04:24:02午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][50/391]	Step 1564	Loss 0.8157	Prec@(1,5) (72.2%, 97.8%)
06/26 04:24:03午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][100/391]	Step 1564	Loss 0.8297	Prec@(1,5) (71.8%, 97.7%)
06/26 04:24:04午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][150/391]	Step 1564	Loss 0.8658	Prec@(1,5) (71.2%, 97.7%)
06/26 04:24:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][200/391]	Step 1564	Loss 0.8999	Prec@(1,5) (71.2%, 97.6%)
06/26 04:24:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][250/391]	Step 1564	Loss 0.8937	Prec@(1,5) (71.3%, 97.6%)
06/26 04:24:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][300/391]	Step 1564	Loss 0.8882	Prec@(1,5) (71.6%, 97.7%)
06/26 04:24:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][350/391]	Step 1564	Loss 0.8793	Prec@(1,5) (71.6%, 97.7%)
06/26 04:24:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [1][390/391]	Step 1564	Loss 0.8812	Prec@(1,5) (71.7%, 97.7%)
06/26 04:24:08午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  1/24] Final Prec@1 71.6800%
06/26 04:24:10午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 71.6800%
06/26 04:24:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][50/781]	Step 1614	lr 0.02462	Loss 0.5739 (0.7882)	Prec@(1,5) (73.5%, 97.9%)	
06/26 04:24:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][100/781]	Step 1664	lr 0.02462	Loss 0.8982 (0.7897)	Prec@(1,5) (73.2%, 98.0%)	
06/26 04:24:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][150/781]	Step 1714	lr 0.02462	Loss 0.5614 (0.7871)	Prec@(1,5) (73.2%, 97.9%)	
06/26 04:24:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][200/781]	Step 1764	lr 0.02462	Loss 0.8593 (0.7853)	Prec@(1,5) (73.0%, 98.0%)	
06/26 04:24:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][250/781]	Step 1814	lr 0.02462	Loss 0.7747 (0.7844)	Prec@(1,5) (73.0%, 98.0%)	
06/26 04:24:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][300/781]	Step 1864	lr 0.02462	Loss 0.7752 (0.7809)	Prec@(1,5) (73.2%, 98.0%)	
06/26 04:24:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][350/781]	Step 1914	lr 0.02462	Loss 0.9115 (0.7828)	Prec@(1,5) (73.2%, 97.9%)	
06/26 04:24:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][400/781]	Step 1964	lr 0.02462	Loss 0.6939 (0.7830)	Prec@(1,5) (73.1%, 97.9%)	
06/26 04:24:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][450/781]	Step 2014	lr 0.02462	Loss 0.7623 (0.7849)	Prec@(1,5) (73.2%, 97.9%)	
06/26 04:24:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][500/781]	Step 2064	lr 0.02462	Loss 0.7589 (0.7832)	Prec@(1,5) (73.3%, 97.9%)	
06/26 04:24:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][550/781]	Step 2114	lr 0.02462	Loss 0.5358 (0.7799)	Prec@(1,5) (73.5%, 98.0%)	
06/26 04:24:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][600/781]	Step 2164	lr 0.02462	Loss 0.7389 (0.7790)	Prec@(1,5) (73.5%, 98.0%)	
06/26 04:24:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][650/781]	Step 2214	lr 0.02462	Loss 0.7314 (0.7781)	Prec@(1,5) (73.5%, 98.0%)	
06/26 04:24:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][700/781]	Step 2264	lr 0.02462	Loss 0.8678 (0.7740)	Prec@(1,5) (73.6%, 98.0%)	
06/26 04:25:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][750/781]	Step 2314	lr 0.02462	Loss 0.8342 (0.7713)	Prec@(1,5) (73.7%, 98.0%)	
06/26 04:25:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [2][781/781]	Step 2345	lr 0.02462	Loss 0.7255 (0.7697)	Prec@(1,5) (73.8%, 98.0%)	
06/26 04:25:04午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  2/24] Final Prec@1 73.7820%
06/26 04:25:05午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][50/391]	Step 2346	Loss 1.2370	Prec@(1,5) (70.9%, 97.7%)
06/26 04:25:06午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][100/391]	Step 2346	Loss 1.1878	Prec@(1,5) (71.6%, 97.7%)
06/26 04:25:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][150/391]	Step 2346	Loss 1.1574	Prec@(1,5) (71.7%, 98.0%)
06/26 04:25:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][200/391]	Step 2346	Loss 1.1718	Prec@(1,5) (71.7%, 97.9%)
06/26 04:25:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][250/391]	Step 2346	Loss 1.1694	Prec@(1,5) (71.8%, 97.9%)
06/26 04:25:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][300/391]	Step 2346	Loss 1.1969	Prec@(1,5) (71.7%, 98.0%)
06/26 04:25:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][350/391]	Step 2346	Loss 1.2016	Prec@(1,5) (71.8%, 98.0%)
06/26 04:25:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [2][390/391]	Step 2346	Loss 1.2023	Prec@(1,5) (71.7%, 98.0%)
06/26 04:25:11午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  2/24] Final Prec@1 71.6560%
06/26 04:25:12午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 71.6800%
06/26 04:25:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][50/781]	Step 2396	lr 0.02416	Loss 0.6408 (0.7020)	Prec@(1,5) (75.2%, 98.7%)	
06/26 04:25:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][100/781]	Step 2446	lr 0.02416	Loss 0.5055 (0.6944)	Prec@(1,5) (76.0%, 98.6%)	
06/26 04:25:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][150/781]	Step 2496	lr 0.02416	Loss 0.6719 (0.7108)	Prec@(1,5) (75.6%, 98.5%)	
06/26 04:25:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][200/781]	Step 2546	lr 0.02416	Loss 0.7455 (0.7158)	Prec@(1,5) (75.5%, 98.4%)	
06/26 04:25:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][250/781]	Step 2596	lr 0.02416	Loss 0.5941 (0.7075)	Prec@(1,5) (75.7%, 98.5%)	
06/26 04:25:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][300/781]	Step 2646	lr 0.02416	Loss 0.5813 (0.7033)	Prec@(1,5) (75.9%, 98.5%)	
06/26 04:25:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][350/781]	Step 2696	lr 0.02416	Loss 0.6097 (0.7049)	Prec@(1,5) (75.8%, 98.5%)	
06/26 04:25:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][400/781]	Step 2746	lr 0.02416	Loss 0.9085 (0.6983)	Prec@(1,5) (76.0%, 98.5%)	
06/26 04:25:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][450/781]	Step 2796	lr 0.02416	Loss 0.6662 (0.6920)	Prec@(1,5) (76.2%, 98.5%)	
06/26 04:25:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][500/781]	Step 2846	lr 0.02416	Loss 0.7129 (0.6937)	Prec@(1,5) (76.1%, 98.5%)	
06/26 04:25:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][550/781]	Step 2896	lr 0.02416	Loss 0.5697 (0.6904)	Prec@(1,5) (76.2%, 98.6%)	
06/26 04:25:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][600/781]	Step 2946	lr 0.02416	Loss 0.5048 (0.6921)	Prec@(1,5) (76.2%, 98.6%)	
06/26 04:25:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][650/781]	Step 2996	lr 0.02416	Loss 0.7017 (0.6936)	Prec@(1,5) (76.2%, 98.6%)	
06/26 04:26:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][700/781]	Step 3046	lr 0.02416	Loss 0.7609 (0.6953)	Prec@(1,5) (76.1%, 98.5%)	
06/26 04:26:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][750/781]	Step 3096	lr 0.02416	Loss 0.5189 (0.6947)	Prec@(1,5) (76.0%, 98.5%)	
06/26 04:26:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [3][781/781]	Step 3127	lr 0.02416	Loss 0.8255 (0.6936)	Prec@(1,5) (76.1%, 98.5%)	
06/26 04:26:06午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  3/24] Final Prec@1 76.0700%
06/26 04:26:07午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][50/391]	Step 3128	Loss 0.7885	Prec@(1,5) (73.2%, 98.3%)
06/26 04:26:08午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][100/391]	Step 3128	Loss 0.7964	Prec@(1,5) (73.1%, 98.4%)
06/26 04:26:09午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][150/391]	Step 3128	Loss 0.7860	Prec@(1,5) (73.2%, 98.5%)
06/26 04:26:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][200/391]	Step 3128	Loss 0.7928	Prec@(1,5) (73.0%, 98.5%)
06/26 04:26:10午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][250/391]	Step 3128	Loss 0.7909	Prec@(1,5) (73.1%, 98.5%)
06/26 04:26:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][300/391]	Step 3128	Loss 0.7884	Prec@(1,5) (73.2%, 98.5%)
06/26 04:26:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][350/391]	Step 3128	Loss 0.7955	Prec@(1,5) (73.1%, 98.5%)
06/26 04:26:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [3][390/391]	Step 3128	Loss 0.7951	Prec@(1,5) (73.2%, 98.4%)
06/26 04:26:13午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  3/24] Final Prec@1 73.1760%
06/26 04:26:14午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 73.1760%
06/26 04:26:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][50/781]	Step 3178	lr 0.02352	Loss 0.8409 (0.6440)	Prec@(1,5) (77.5%, 98.9%)	
06/26 04:26:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][100/781]	Step 3228	lr 0.02352	Loss 0.5812 (0.6497)	Prec@(1,5) (77.4%, 98.8%)	
06/26 04:26:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][150/781]	Step 3278	lr 0.02352	Loss 0.7535 (0.6564)	Prec@(1,5) (77.3%, 98.7%)	
06/26 04:26:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][200/781]	Step 3328	lr 0.02352	Loss 0.5696 (0.6438)	Prec@(1,5) (77.8%, 98.7%)	
06/26 04:26:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][250/781]	Step 3378	lr 0.02352	Loss 0.6755 (0.6506)	Prec@(1,5) (77.4%, 98.7%)	
06/26 04:26:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][300/781]	Step 3428	lr 0.02352	Loss 0.4964 (0.6436)	Prec@(1,5) (77.7%, 98.7%)	
06/26 04:26:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][350/781]	Step 3478	lr 0.02352	Loss 0.6456 (0.6407)	Prec@(1,5) (77.8%, 98.7%)	
06/26 04:26:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][400/781]	Step 3528	lr 0.02352	Loss 0.5515 (0.6401)	Prec@(1,5) (77.9%, 98.7%)	
06/26 04:26:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][450/781]	Step 3578	lr 0.02352	Loss 0.7792 (0.6368)	Prec@(1,5) (78.0%, 98.7%)	
06/26 04:26:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][500/781]	Step 3628	lr 0.02352	Loss 0.9226 (0.6400)	Prec@(1,5) (77.9%, 98.7%)	
06/26 04:26:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][550/781]	Step 3678	lr 0.02352	Loss 0.6032 (0.6404)	Prec@(1,5) (77.9%, 98.7%)	
06/26 04:26:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][600/781]	Step 3728	lr 0.02352	Loss 0.5299 (0.6419)	Prec@(1,5) (77.9%, 98.7%)	
06/26 04:27:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][650/781]	Step 3778	lr 0.02352	Loss 0.6109 (0.6402)	Prec@(1,5) (77.9%, 98.7%)	
06/26 04:27:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][700/781]	Step 3828	lr 0.02352	Loss 0.4131 (0.6435)	Prec@(1,5) (77.7%, 98.7%)	
06/26 04:27:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][750/781]	Step 3878	lr 0.02352	Loss 0.9638 (0.6443)	Prec@(1,5) (77.8%, 98.7%)	
06/26 04:27:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [4][781/781]	Step 3909	lr 0.02352	Loss 0.3715 (0.6429)	Prec@(1,5) (77.8%, 98.7%)	
06/26 04:27:10午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  4/24] Final Prec@1 77.8460%
06/26 04:27:11午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][50/391]	Step 3910	Loss 0.7832	Prec@(1,5) (76.0%, 98.8%)
06/26 04:27:12午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][100/391]	Step 3910	Loss 0.7895	Prec@(1,5) (75.8%, 98.6%)
06/26 04:27:13午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][150/391]	Step 3910	Loss 0.8020	Prec@(1,5) (75.6%, 98.5%)
06/26 04:27:14午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][200/391]	Step 3910	Loss 0.8086	Prec@(1,5) (75.9%, 98.4%)
06/26 04:27:15午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][250/391]	Step 3910	Loss 0.7932	Prec@(1,5) (76.0%, 98.4%)
06/26 04:27:16午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][300/391]	Step 3910	Loss 0.7903	Prec@(1,5) (76.2%, 98.5%)
06/26 04:27:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][350/391]	Step 3910	Loss 0.7837	Prec@(1,5) (76.2%, 98.5%)
06/26 04:27:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [4][390/391]	Step 3910	Loss 0.7828	Prec@(1,5) (76.2%, 98.5%)
06/26 04:27:17午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  4/24] Final Prec@1 76.2040%
06/26 04:27:19午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 76.2040%
06/26 04:27:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][50/781]	Step 3960	lr 0.02271	Loss 0.5856 (0.6260)	Prec@(1,5) (78.3%, 99.0%)	
06/26 04:27:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][100/781]	Step 4010	lr 0.02271	Loss 0.6795 (0.6342)	Prec@(1,5) (78.2%, 98.9%)	
06/26 04:27:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][150/781]	Step 4060	lr 0.02271	Loss 0.5400 (0.6253)	Prec@(1,5) (78.4%, 98.9%)	
06/26 04:27:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][200/781]	Step 4110	lr 0.02271	Loss 0.6962 (0.6223)	Prec@(1,5) (78.5%, 98.9%)	
06/26 04:27:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][250/781]	Step 4160	lr 0.02271	Loss 0.4786 (0.6161)	Prec@(1,5) (78.8%, 98.9%)	
06/26 04:27:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][300/781]	Step 4210	lr 0.02271	Loss 0.5785 (0.6147)	Prec@(1,5) (78.8%, 98.9%)	
06/26 04:27:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][350/781]	Step 4260	lr 0.02271	Loss 0.5882 (0.6173)	Prec@(1,5) (78.7%, 98.9%)	
06/26 04:27:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][400/781]	Step 4310	lr 0.02271	Loss 0.8562 (0.6150)	Prec@(1,5) (78.8%, 98.9%)	
06/26 04:27:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][450/781]	Step 4360	lr 0.02271	Loss 0.5279 (0.6147)	Prec@(1,5) (78.7%, 98.9%)	
06/26 04:27:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][500/781]	Step 4410	lr 0.02271	Loss 0.7038 (0.6160)	Prec@(1,5) (78.7%, 98.8%)	
06/26 04:27:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][550/781]	Step 4460	lr 0.02271	Loss 0.6717 (0.6170)	Prec@(1,5) (78.7%, 98.8%)	
06/26 04:28:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][600/781]	Step 4510	lr 0.02271	Loss 0.5141 (0.6176)	Prec@(1,5) (78.7%, 98.8%)	
06/26 04:28:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][650/781]	Step 4560	lr 0.02271	Loss 0.6010 (0.6150)	Prec@(1,5) (78.8%, 98.9%)	
06/26 04:28:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][700/781]	Step 4610	lr 0.02271	Loss 0.7908 (0.6125)	Prec@(1,5) (78.8%, 98.9%)	
06/26 04:28:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][750/781]	Step 4660	lr 0.02271	Loss 0.5059 (0.6102)	Prec@(1,5) (78.9%, 98.9%)	
06/26 04:28:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [5][781/781]	Step 4691	lr 0.02271	Loss 0.7485 (0.6100)	Prec@(1,5) (78.9%, 98.9%)	
06/26 04:28:16午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  5/24] Final Prec@1 78.9540%
06/26 04:28:17午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][50/391]	Step 4692	Loss 0.5990	Prec@(1,5) (80.2%, 98.8%)
06/26 04:28:18午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][100/391]	Step 4692	Loss 0.5982	Prec@(1,5) (79.8%, 99.0%)
06/26 04:28:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][150/391]	Step 4692	Loss 0.5992	Prec@(1,5) (79.6%, 99.0%)
06/26 04:28:19午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][200/391]	Step 4692	Loss 0.6083	Prec@(1,5) (79.2%, 99.0%)
06/26 04:28:20午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][250/391]	Step 4692	Loss 0.6066	Prec@(1,5) (79.4%, 98.9%)
06/26 04:28:21午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][300/391]	Step 4692	Loss 0.6075	Prec@(1,5) (79.2%, 98.9%)
06/26 04:28:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][350/391]	Step 4692	Loss 0.6082	Prec@(1,5) (79.2%, 99.0%)
06/26 04:28:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [5][390/391]	Step 4692	Loss 0.6095	Prec@(1,5) (79.2%, 99.0%)
06/26 04:28:23午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  5/24] Final Prec@1 79.1280%
06/26 04:28:24午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 79.1280%
06/26 04:28:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][50/781]	Step 4742	lr 0.02175	Loss 0.9244 (0.5669)	Prec@(1,5) (80.9%, 99.0%)	
06/26 04:28:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][100/781]	Step 4792	lr 0.02175	Loss 0.4120 (0.5702)	Prec@(1,5) (80.2%, 99.0%)	
06/26 04:28:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][150/781]	Step 4842	lr 0.02175	Loss 0.5987 (0.5677)	Prec@(1,5) (80.5%, 99.1%)	
06/26 04:28:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][200/781]	Step 4892	lr 0.02175	Loss 0.2924 (0.5673)	Prec@(1,5) (80.5%, 99.0%)	
06/26 04:28:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][250/781]	Step 4942	lr 0.02175	Loss 0.3664 (0.5611)	Prec@(1,5) (80.6%, 99.1%)	
06/26 04:28:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][300/781]	Step 4992	lr 0.02175	Loss 0.6318 (0.5694)	Prec@(1,5) (80.4%, 99.1%)	
06/26 04:28:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][350/781]	Step 5042	lr 0.02175	Loss 0.6005 (0.5708)	Prec@(1,5) (80.3%, 99.1%)	
06/26 04:28:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][400/781]	Step 5092	lr 0.02175	Loss 0.6661 (0.5736)	Prec@(1,5) (80.2%, 99.1%)	
06/26 04:28:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][450/781]	Step 5142	lr 0.02175	Loss 0.5124 (0.5755)	Prec@(1,5) (80.2%, 99.0%)	
06/26 04:29:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][500/781]	Step 5192	lr 0.02175	Loss 0.4840 (0.5747)	Prec@(1,5) (80.2%, 99.0%)	
06/26 04:29:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][550/781]	Step 5242	lr 0.02175	Loss 0.4023 (0.5749)	Prec@(1,5) (80.2%, 99.0%)	
06/26 04:29:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][600/781]	Step 5292	lr 0.02175	Loss 0.6083 (0.5759)	Prec@(1,5) (80.2%, 99.0%)	
06/26 04:29:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][650/781]	Step 5342	lr 0.02175	Loss 0.6662 (0.5766)	Prec@(1,5) (80.2%, 99.0%)	
06/26 04:29:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][700/781]	Step 5392	lr 0.02175	Loss 0.6398 (0.5773)	Prec@(1,5) (80.1%, 99.0%)	
06/26 04:29:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][750/781]	Step 5442	lr 0.02175	Loss 0.5994 (0.5819)	Prec@(1,5) (80.0%, 99.0%)	
06/26 04:29:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [6][781/781]	Step 5473	lr 0.02175	Loss 0.7087 (0.5849)	Prec@(1,5) (79.9%, 98.9%)	
06/26 04:29:21午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  6/24] Final Prec@1 79.9200%
06/26 04:29:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][50/391]	Step 5474	Loss 0.6219	Prec@(1,5) (79.0%, 98.8%)
06/26 04:29:22午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][100/391]	Step 5474	Loss 0.6018	Prec@(1,5) (80.0%, 98.9%)
06/26 04:29:23午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][150/391]	Step 5474	Loss 0.6040	Prec@(1,5) (80.1%, 98.7%)
06/26 04:29:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][200/391]	Step 5474	Loss 0.6258	Prec@(1,5) (79.8%, 98.6%)
06/26 04:29:24午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][250/391]	Step 5474	Loss 0.6213	Prec@(1,5) (79.8%, 98.7%)
06/26 04:29:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][300/391]	Step 5474	Loss 0.6200	Prec@(1,5) (79.9%, 98.8%)
06/26 04:29:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][350/391]	Step 5474	Loss 0.6286	Prec@(1,5) (79.6%, 98.8%)
06/26 04:29:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [6][390/391]	Step 5474	Loss 0.6299	Prec@(1,5) (79.5%, 98.7%)
06/26 04:29:26午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  6/24] Final Prec@1 79.5240%
06/26 04:29:28午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 79.5240%
06/26 04:29:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][50/781]	Step 5524	lr 0.02065	Loss 0.4528 (0.5999)	Prec@(1,5) (79.1%, 98.7%)	
06/26 04:29:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][100/781]	Step 5574	lr 0.02065	Loss 0.6182 (0.5920)	Prec@(1,5) (79.6%, 98.8%)	
06/26 04:29:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][150/781]	Step 5624	lr 0.02065	Loss 0.5338 (0.5944)	Prec@(1,5) (79.7%, 98.8%)	
06/26 04:29:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][200/781]	Step 5674	lr 0.02065	Loss 0.6029 (0.5922)	Prec@(1,5) (79.7%, 98.9%)	
06/26 04:29:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][250/781]	Step 5724	lr 0.02065	Loss 0.4166 (0.5876)	Prec@(1,5) (79.7%, 98.9%)	
06/26 04:29:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][300/781]	Step 5774	lr 0.02065	Loss 0.7298 (0.5814)	Prec@(1,5) (79.9%, 98.9%)	
06/26 04:29:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][350/781]	Step 5824	lr 0.02065	Loss 0.4860 (0.5774)	Prec@(1,5) (80.1%, 98.9%)	
06/26 04:29:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][400/781]	Step 5874	lr 0.02065	Loss 0.5436 (0.5745)	Prec@(1,5) (80.2%, 98.9%)	
06/26 04:30:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][450/781]	Step 5924	lr 0.02065	Loss 0.6804 (0.5689)	Prec@(1,5) (80.3%, 98.9%)	
06/26 04:30:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][500/781]	Step 5974	lr 0.02065	Loss 0.6264 (0.5690)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][550/781]	Step 6024	lr 0.02065	Loss 0.5516 (0.5678)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][600/781]	Step 6074	lr 0.02065	Loss 0.5365 (0.5671)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][650/781]	Step 6124	lr 0.02065	Loss 0.4854 (0.5654)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][700/781]	Step 6174	lr 0.02065	Loss 0.6747 (0.5656)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][750/781]	Step 6224	lr 0.02065	Loss 0.7419 (0.5675)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [7][781/781]	Step 6255	lr 0.02065	Loss 0.7096 (0.5674)	Prec@(1,5) (80.3%, 99.0%)	
06/26 04:30:24午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  7/24] Final Prec@1 80.3040%
06/26 04:30:25午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][50/391]	Step 6256	Loss 0.6078	Prec@(1,5) (79.9%, 99.0%)
06/26 04:30:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][100/391]	Step 6256	Loss 0.6113	Prec@(1,5) (80.0%, 99.0%)
06/26 04:30:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][150/391]	Step 6256	Loss 0.6044	Prec@(1,5) (80.1%, 99.0%)
06/26 04:30:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][200/391]	Step 6256	Loss 0.6086	Prec@(1,5) (80.0%, 99.0%)
06/26 04:30:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][250/391]	Step 6256	Loss 0.6111	Prec@(1,5) (79.7%, 98.9%)
06/26 04:30:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][300/391]	Step 6256	Loss 0.6104	Prec@(1,5) (79.7%, 99.0%)
06/26 04:30:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][350/391]	Step 6256	Loss 0.6078	Prec@(1,5) (79.7%, 99.0%)
06/26 04:30:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [7][390/391]	Step 6256	Loss 0.6068	Prec@(1,5) (79.6%, 99.0%)
06/26 04:30:30午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  7/24] Final Prec@1 79.6520%
06/26 04:30:31午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 79.6520%
06/26 04:30:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][50/781]	Step 6306	lr 0.01943	Loss 0.5578 (0.5576)	Prec@(1,5) (79.5%, 99.4%)	
06/26 04:30:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][100/781]	Step 6356	lr 0.01943	Loss 0.5437 (0.5236)	Prec@(1,5) (81.3%, 99.4%)	
06/26 04:30:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][150/781]	Step 6406	lr 0.01943	Loss 0.4339 (0.5204)	Prec@(1,5) (81.6%, 99.3%)	
06/26 04:30:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][200/781]	Step 6456	lr 0.01943	Loss 0.5289 (0.5217)	Prec@(1,5) (81.8%, 99.2%)	
06/26 04:30:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][250/781]	Step 6506	lr 0.01943	Loss 0.7052 (0.5284)	Prec@(1,5) (81.7%, 99.1%)	
06/26 04:30:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][300/781]	Step 6556	lr 0.01943	Loss 0.4063 (0.5234)	Prec@(1,5) (81.9%, 99.1%)	
06/26 04:30:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][350/781]	Step 6606	lr 0.01943	Loss 0.4507 (0.5235)	Prec@(1,5) (81.9%, 99.1%)	
06/26 04:30:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][400/781]	Step 6656	lr 0.01943	Loss 0.7038 (0.5251)	Prec@(1,5) (81.9%, 99.1%)	
06/26 04:31:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][450/781]	Step 6706	lr 0.01943	Loss 0.7165 (0.5252)	Prec@(1,5) (81.9%, 99.1%)	
06/26 04:31:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][500/781]	Step 6756	lr 0.01943	Loss 0.4564 (0.5222)	Prec@(1,5) (82.0%, 99.1%)	
06/26 04:31:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][550/781]	Step 6806	lr 0.01943	Loss 0.3420 (0.5226)	Prec@(1,5) (82.0%, 99.1%)	
06/26 04:31:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][600/781]	Step 6856	lr 0.01943	Loss 0.4886 (0.5236)	Prec@(1,5) (81.9%, 99.2%)	
06/26 04:31:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][650/781]	Step 6906	lr 0.01943	Loss 0.5039 (0.5234)	Prec@(1,5) (82.0%, 99.2%)	
06/26 04:31:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][700/781]	Step 6956	lr 0.01943	Loss 0.7611 (0.5232)	Prec@(1,5) (82.0%, 99.2%)	
06/26 04:31:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][750/781]	Step 7006	lr 0.01943	Loss 0.6802 (0.5227)	Prec@(1,5) (82.0%, 99.1%)	
06/26 04:31:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [8][781/781]	Step 7037	lr 0.01943	Loss 0.6289 (0.5234)	Prec@(1,5) (82.0%, 99.1%)	
06/26 04:31:25午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  8/24] Final Prec@1 81.9820%
06/26 04:31:26午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][50/391]	Step 7038	Loss 0.6036	Prec@(1,5) (79.5%, 99.3%)
06/26 04:31:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][100/391]	Step 7038	Loss 0.5748	Prec@(1,5) (80.6%, 99.3%)
06/26 04:31:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][150/391]	Step 7038	Loss 0.5717	Prec@(1,5) (80.8%, 99.3%)
06/26 04:31:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][200/391]	Step 7038	Loss 0.5799	Prec@(1,5) (80.5%, 99.3%)
06/26 04:31:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][250/391]	Step 7038	Loss 0.5770	Prec@(1,5) (80.5%, 99.3%)
06/26 04:31:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][300/391]	Step 7038	Loss 0.5763	Prec@(1,5) (80.6%, 99.3%)
06/26 04:31:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][350/391]	Step 7038	Loss 0.5727	Prec@(1,5) (80.7%, 99.3%)
06/26 04:31:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [8][390/391]	Step 7038	Loss 0.5749	Prec@(1,5) (80.6%, 99.2%)
06/26 04:31:31午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  8/24] Final Prec@1 80.6040%
06/26 04:31:32午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 80.6040%
06/26 04:31:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][50/781]	Step 7088	lr 0.01811	Loss 0.4570 (0.4660)	Prec@(1,5) (83.7%, 99.3%)	
06/26 04:31:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][100/781]	Step 7138	lr 0.01811	Loss 0.6217 (0.4863)	Prec@(1,5) (83.0%, 99.4%)	
06/26 04:31:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][150/781]	Step 7188	lr 0.01811	Loss 0.4163 (0.4833)	Prec@(1,5) (83.0%, 99.4%)	
06/26 04:31:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][200/781]	Step 7238	lr 0.01811	Loss 0.3929 (0.4873)	Prec@(1,5) (83.0%, 99.4%)	
06/26 04:31:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][250/781]	Step 7288	lr 0.01811	Loss 0.4524 (0.4859)	Prec@(1,5) (83.1%, 99.3%)	
06/26 04:31:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][300/781]	Step 7338	lr 0.01811	Loss 0.5219 (0.4901)	Prec@(1,5) (83.0%, 99.3%)	
06/26 04:31:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][350/781]	Step 7388	lr 0.01811	Loss 0.5679 (0.4907)	Prec@(1,5) (83.0%, 99.3%)	
06/26 04:32:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][400/781]	Step 7438	lr 0.01811	Loss 0.4735 (0.4904)	Prec@(1,5) (83.0%, 99.3%)	
06/26 04:32:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][450/781]	Step 7488	lr 0.01811	Loss 0.5226 (0.4942)	Prec@(1,5) (82.8%, 99.3%)	
06/26 04:32:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][500/781]	Step 7538	lr 0.01811	Loss 0.5701 (0.4993)	Prec@(1,5) (82.7%, 99.3%)	
06/26 04:32:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][550/781]	Step 7588	lr 0.01811	Loss 0.6769 (0.4995)	Prec@(1,5) (82.6%, 99.3%)	
06/26 04:32:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][600/781]	Step 7638	lr 0.01811	Loss 0.4966 (0.4995)	Prec@(1,5) (82.6%, 99.3%)	
06/26 04:32:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][650/781]	Step 7688	lr 0.01811	Loss 0.5324 (0.5001)	Prec@(1,5) (82.6%, 99.3%)	
06/26 04:32:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][700/781]	Step 7738	lr 0.01811	Loss 0.6500 (0.4993)	Prec@(1,5) (82.7%, 99.3%)	
06/26 04:32:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][750/781]	Step 7788	lr 0.01811	Loss 0.6862 (0.4997)	Prec@(1,5) (82.7%, 99.3%)	
06/26 04:32:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [9][781/781]	Step 7819	lr 0.01811	Loss 0.6594 (0.5007)	Prec@(1,5) (82.7%, 99.3%)	
06/26 04:32:27午後 finetuneTeacher_trainer.py:181 [INFO] Train: [  9/24] Final Prec@1 82.6660%
06/26 04:32:27午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][50/391]	Step 7820	Loss 0.4894	Prec@(1,5) (82.6%, 99.5%)
06/26 04:32:28午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][100/391]	Step 7820	Loss 0.4738	Prec@(1,5) (83.1%, 99.4%)
06/26 04:32:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][150/391]	Step 7820	Loss 0.4819	Prec@(1,5) (83.2%, 99.3%)
06/26 04:32:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][200/391]	Step 7820	Loss 0.4802	Prec@(1,5) (83.3%, 99.3%)
06/26 04:32:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][250/391]	Step 7820	Loss 0.4790	Prec@(1,5) (83.5%, 99.3%)
06/26 04:32:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][300/391]	Step 7820	Loss 0.4814	Prec@(1,5) (83.3%, 99.3%)
06/26 04:32:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][350/391]	Step 7820	Loss 0.4804	Prec@(1,5) (83.4%, 99.2%)
06/26 04:32:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [9][390/391]	Step 7820	Loss 0.4816	Prec@(1,5) (83.4%, 99.2%)
06/26 04:32:32午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [  9/24] Final Prec@1 83.3400%
06/26 04:32:33午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 83.3400%
06/26 04:32:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][50/781]	Step 7870	lr 0.01671	Loss 0.4326 (0.4723)	Prec@(1,5) (83.6%, 99.5%)	
06/26 04:32:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][100/781]	Step 7920	lr 0.01671	Loss 0.3354 (0.4745)	Prec@(1,5) (83.5%, 99.4%)	
06/26 04:32:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][150/781]	Step 7970	lr 0.01671	Loss 0.3663 (0.4683)	Prec@(1,5) (83.5%, 99.4%)	
06/26 04:32:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][200/781]	Step 8020	lr 0.01671	Loss 0.4090 (0.4676)	Prec@(1,5) (83.5%, 99.4%)	
06/26 04:32:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][250/781]	Step 8070	lr 0.01671	Loss 0.4346 (0.4661)	Prec@(1,5) (83.7%, 99.4%)	
06/26 04:32:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][300/781]	Step 8120	lr 0.01671	Loss 0.4839 (0.4611)	Prec@(1,5) (83.9%, 99.5%)	
06/26 04:32:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][350/781]	Step 8170	lr 0.01671	Loss 0.3401 (0.4637)	Prec@(1,5) (83.9%, 99.5%)	
06/26 04:33:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][400/781]	Step 8220	lr 0.01671	Loss 0.3863 (0.4628)	Prec@(1,5) (83.9%, 99.4%)	
06/26 04:33:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][450/781]	Step 8270	lr 0.01671	Loss 0.4593 (0.4658)	Prec@(1,5) (83.8%, 99.4%)	
06/26 04:33:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][500/781]	Step 8320	lr 0.01671	Loss 0.8315 (0.4636)	Prec@(1,5) (84.0%, 99.4%)	
06/26 04:33:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][550/781]	Step 8370	lr 0.01671	Loss 0.3476 (0.4651)	Prec@(1,5) (83.9%, 99.4%)	
06/26 04:33:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][600/781]	Step 8420	lr 0.01671	Loss 0.4253 (0.4650)	Prec@(1,5) (84.0%, 99.4%)	
06/26 04:33:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][650/781]	Step 8470	lr 0.01671	Loss 0.6021 (0.4664)	Prec@(1,5) (83.9%, 99.4%)	
06/26 04:33:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][700/781]	Step 8520	lr 0.01671	Loss 0.4027 (0.4678)	Prec@(1,5) (83.9%, 99.3%)	
06/26 04:33:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][750/781]	Step 8570	lr 0.01671	Loss 0.4372 (0.4683)	Prec@(1,5) (83.9%, 99.3%)	
06/26 04:33:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [10][781/781]	Step 8601	lr 0.01671	Loss 0.3872 (0.4694)	Prec@(1,5) (83.8%, 99.3%)	
06/26 04:33:28午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 10/24] Final Prec@1 83.8140%
06/26 04:33:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][50/391]	Step 8602	Loss 0.4529	Prec@(1,5) (84.2%, 99.5%)
06/26 04:33:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][100/391]	Step 8602	Loss 0.4428	Prec@(1,5) (84.4%, 99.5%)
06/26 04:33:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][150/391]	Step 8602	Loss 0.4389	Prec@(1,5) (84.5%, 99.5%)
06/26 04:33:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][200/391]	Step 8602	Loss 0.4406	Prec@(1,5) (84.7%, 99.5%)
06/26 04:33:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][250/391]	Step 8602	Loss 0.4381	Prec@(1,5) (84.8%, 99.5%)
06/26 04:33:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][300/391]	Step 8602	Loss 0.4359	Prec@(1,5) (84.8%, 99.5%)
06/26 04:33:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][350/391]	Step 8602	Loss 0.4349	Prec@(1,5) (84.9%, 99.5%)
06/26 04:33:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [10][390/391]	Step 8602	Loss 0.4363	Prec@(1,5) (84.9%, 99.5%)
06/26 04:33:33午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 10/24] Final Prec@1 84.8880%
06/26 04:33:34午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 84.8880%
06/26 04:33:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][50/781]	Step 8652	lr 0.01525	Loss 0.3183 (0.4014)	Prec@(1,5) (85.9%, 99.7%)	
06/26 04:33:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][100/781]	Step 8702	lr 0.01525	Loss 0.4362 (0.4014)	Prec@(1,5) (86.3%, 99.6%)	
06/26 04:33:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][150/781]	Step 8752	lr 0.01525	Loss 0.4826 (0.4170)	Prec@(1,5) (85.9%, 99.5%)	
06/26 04:33:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][200/781]	Step 8802	lr 0.01525	Loss 0.3573 (0.4235)	Prec@(1,5) (85.5%, 99.5%)	
06/26 04:33:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][250/781]	Step 8852	lr 0.01525	Loss 0.5051 (0.4275)	Prec@(1,5) (85.3%, 99.4%)	
06/26 04:33:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][300/781]	Step 8902	lr 0.01525	Loss 0.4578 (0.4319)	Prec@(1,5) (85.1%, 99.4%)	
06/26 04:33:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][350/781]	Step 8952	lr 0.01525	Loss 0.5026 (0.4320)	Prec@(1,5) (85.0%, 99.4%)	
06/26 04:34:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][400/781]	Step 9002	lr 0.01525	Loss 0.4411 (0.4330)	Prec@(1,5) (85.0%, 99.4%)	
06/26 04:34:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][450/781]	Step 9052	lr 0.01525	Loss 0.3308 (0.4357)	Prec@(1,5) (84.9%, 99.4%)	
06/26 04:34:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][500/781]	Step 9102	lr 0.01525	Loss 0.4836 (0.4358)	Prec@(1,5) (84.9%, 99.4%)	
06/26 04:34:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][550/781]	Step 9152	lr 0.01525	Loss 0.5327 (0.4384)	Prec@(1,5) (84.8%, 99.4%)	
06/26 04:34:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][600/781]	Step 9202	lr 0.01525	Loss 0.3203 (0.4386)	Prec@(1,5) (84.8%, 99.4%)	
06/26 04:34:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][650/781]	Step 9252	lr 0.01525	Loss 0.6566 (0.4418)	Prec@(1,5) (84.7%, 99.4%)	
06/26 04:34:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][700/781]	Step 9302	lr 0.01525	Loss 0.3655 (0.4431)	Prec@(1,5) (84.7%, 99.4%)	
06/26 04:34:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][750/781]	Step 9352	lr 0.01525	Loss 0.2977 (0.4425)	Prec@(1,5) (84.7%, 99.4%)	
06/26 04:34:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [11][781/781]	Step 9383	lr 0.01525	Loss 0.4336 (0.4428)	Prec@(1,5) (84.7%, 99.4%)	
06/26 04:34:29午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 11/24] Final Prec@1 84.6840%
06/26 04:34:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][50/391]	Step 9384	Loss 0.4150	Prec@(1,5) (86.0%, 99.4%)
06/26 04:34:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][100/391]	Step 9384	Loss 0.4070	Prec@(1,5) (86.3%, 99.5%)
06/26 04:34:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][150/391]	Step 9384	Loss 0.4120	Prec@(1,5) (85.9%, 99.6%)
06/26 04:34:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][200/391]	Step 9384	Loss 0.4137	Prec@(1,5) (85.8%, 99.6%)
06/26 04:34:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][250/391]	Step 9384	Loss 0.4165	Prec@(1,5) (85.7%, 99.6%)
06/26 04:34:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][300/391]	Step 9384	Loss 0.4181	Prec@(1,5) (85.7%, 99.6%)
06/26 04:34:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][350/391]	Step 9384	Loss 0.4181	Prec@(1,5) (85.7%, 99.5%)
06/26 04:34:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [11][390/391]	Step 9384	Loss 0.4164	Prec@(1,5) (85.8%, 99.5%)
06/26 04:34:34午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 11/24] Final Prec@1 85.7800%
06/26 04:34:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 85.7800%
06/26 04:34:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][50/781]	Step 9434	lr 0.01375	Loss 0.2344 (0.4035)	Prec@(1,5) (86.1%, 99.5%)	
06/26 04:34:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][100/781]	Step 9484	lr 0.01375	Loss 0.5058 (0.4172)	Prec@(1,5) (85.4%, 99.5%)	
06/26 04:34:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][150/781]	Step 9534	lr 0.01375	Loss 0.3976 (0.4178)	Prec@(1,5) (85.5%, 99.5%)	
06/26 04:34:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][200/781]	Step 9584	lr 0.01375	Loss 0.5033 (0.4095)	Prec@(1,5) (85.8%, 99.5%)	
06/26 04:34:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][250/781]	Step 9634	lr 0.01375	Loss 0.4975 (0.4147)	Prec@(1,5) (85.6%, 99.5%)	
06/26 04:34:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][300/781]	Step 9684	lr 0.01375	Loss 0.5344 (0.4154)	Prec@(1,5) (85.5%, 99.5%)	
06/26 04:35:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][350/781]	Step 9734	lr 0.01375	Loss 0.3502 (0.4144)	Prec@(1,5) (85.5%, 99.5%)	
06/26 04:35:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][400/781]	Step 9784	lr 0.01375	Loss 0.3872 (0.4121)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:35:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][450/781]	Step 9834	lr 0.01375	Loss 0.5297 (0.4120)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:35:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][500/781]	Step 9884	lr 0.01375	Loss 0.3473 (0.4127)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:35:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][550/781]	Step 9934	lr 0.01375	Loss 0.2677 (0.4126)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:35:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][600/781]	Step 9984	lr 0.01375	Loss 0.4466 (0.4140)	Prec@(1,5) (85.6%, 99.5%)	
06/26 04:35:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][650/781]	Step 10034	lr 0.01375	Loss 0.5907 (0.4138)	Prec@(1,5) (85.7%, 99.5%)	
06/26 04:35:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][700/781]	Step 10084	lr 0.01375	Loss 0.3775 (0.4133)	Prec@(1,5) (85.6%, 99.5%)	
06/26 04:35:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][750/781]	Step 10134	lr 0.01375	Loss 0.4682 (0.4155)	Prec@(1,5) (85.6%, 99.5%)	
06/26 04:35:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [12][781/781]	Step 10165	lr 0.01375	Loss 0.4938 (0.4159)	Prec@(1,5) (85.5%, 99.5%)	
06/26 04:35:30午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 12/24] Final Prec@1 85.5360%
06/26 04:35:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][50/391]	Step 10166	Loss 0.3733	Prec@(1,5) (87.2%, 99.4%)
06/26 04:35:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][100/391]	Step 10166	Loss 0.3808	Prec@(1,5) (86.7%, 99.5%)
06/26 04:35:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][150/391]	Step 10166	Loss 0.3753	Prec@(1,5) (86.9%, 99.6%)
06/26 04:35:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][200/391]	Step 10166	Loss 0.3686	Prec@(1,5) (87.2%, 99.6%)
06/26 04:35:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][250/391]	Step 10166	Loss 0.3732	Prec@(1,5) (87.0%, 99.5%)
06/26 04:35:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][300/391]	Step 10166	Loss 0.3712	Prec@(1,5) (86.9%, 99.6%)
06/26 04:35:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][350/391]	Step 10166	Loss 0.3718	Prec@(1,5) (87.0%, 99.6%)
06/26 04:35:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [12][390/391]	Step 10166	Loss 0.3692	Prec@(1,5) (87.2%, 99.6%)
06/26 04:35:36午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 12/24] Final Prec@1 87.1880%
06/26 04:35:37午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.1880%
06/26 04:35:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][50/781]	Step 10216	lr 0.01225	Loss 0.3557 (0.3845)	Prec@(1,5) (86.4%, 99.6%)	
06/26 04:35:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][100/781]	Step 10266	lr 0.01225	Loss 0.4193 (0.4060)	Prec@(1,5) (85.9%, 99.4%)	
06/26 04:35:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][150/781]	Step 10316	lr 0.01225	Loss 0.5614 (0.3969)	Prec@(1,5) (86.3%, 99.5%)	
06/26 04:35:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][200/781]	Step 10366	lr 0.01225	Loss 0.5099 (0.3980)	Prec@(1,5) (86.3%, 99.5%)	
06/26 04:35:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][250/781]	Step 10416	lr 0.01225	Loss 0.2422 (0.3932)	Prec@(1,5) (86.5%, 99.5%)	
06/26 04:35:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][300/781]	Step 10466	lr 0.01225	Loss 0.3537 (0.3954)	Prec@(1,5) (86.5%, 99.5%)	
06/26 04:36:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][350/781]	Step 10516	lr 0.01225	Loss 0.5093 (0.3927)	Prec@(1,5) (86.6%, 99.5%)	
06/26 04:36:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][400/781]	Step 10566	lr 0.01225	Loss 0.3290 (0.3918)	Prec@(1,5) (86.6%, 99.5%)	
06/26 04:36:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][450/781]	Step 10616	lr 0.01225	Loss 0.2690 (0.3896)	Prec@(1,5) (86.6%, 99.5%)	
06/26 04:36:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][500/781]	Step 10666	lr 0.01225	Loss 0.4364 (0.3902)	Prec@(1,5) (86.5%, 99.5%)	
06/26 04:36:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][550/781]	Step 10716	lr 0.01225	Loss 0.4698 (0.3897)	Prec@(1,5) (86.5%, 99.5%)	
06/26 04:36:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][600/781]	Step 10766	lr 0.01225	Loss 0.3410 (0.3883)	Prec@(1,5) (86.5%, 99.5%)	
06/26 04:36:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][650/781]	Step 10816	lr 0.01225	Loss 0.2036 (0.3871)	Prec@(1,5) (86.5%, 99.5%)	
06/26 04:36:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][700/781]	Step 10866	lr 0.01225	Loss 0.3045 (0.3861)	Prec@(1,5) (86.6%, 99.6%)	
06/26 04:36:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][750/781]	Step 10916	lr 0.01225	Loss 0.6262 (0.3859)	Prec@(1,5) (86.6%, 99.6%)	
06/26 04:36:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [13][781/781]	Step 10947	lr 0.01225	Loss 0.3165 (0.3852)	Prec@(1,5) (86.6%, 99.6%)	
06/26 04:36:31午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 13/24] Final Prec@1 86.6440%
06/26 04:36:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][50/391]	Step 10948	Loss 0.3626	Prec@(1,5) (87.4%, 99.7%)
06/26 04:36:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][100/391]	Step 10948	Loss 0.3603	Prec@(1,5) (87.5%, 99.8%)
06/26 04:36:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][150/391]	Step 10948	Loss 0.3621	Prec@(1,5) (87.5%, 99.7%)
06/26 04:36:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][200/391]	Step 10948	Loss 0.3689	Prec@(1,5) (87.1%, 99.7%)
06/26 04:36:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][250/391]	Step 10948	Loss 0.3641	Prec@(1,5) (87.3%, 99.7%)
06/26 04:36:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][300/391]	Step 10948	Loss 0.3657	Prec@(1,5) (87.4%, 99.7%)
06/26 04:36:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][350/391]	Step 10948	Loss 0.3669	Prec@(1,5) (87.2%, 99.7%)
06/26 04:36:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [13][390/391]	Step 10948	Loss 0.3700	Prec@(1,5) (87.0%, 99.7%)
06/26 04:36:37午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 13/24] Final Prec@1 87.0120%
06/26 04:36:37午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 87.1880%
06/26 04:36:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][50/781]	Step 10998	lr 0.01075	Loss 0.3633 (0.3578)	Prec@(1,5) (87.7%, 99.5%)	
06/26 04:36:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][100/781]	Step 11048	lr 0.01075	Loss 0.3920 (0.3521)	Prec@(1,5) (88.1%, 99.5%)	
06/26 04:36:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][150/781]	Step 11098	lr 0.01075	Loss 0.4529 (0.3577)	Prec@(1,5) (87.9%, 99.6%)	
06/26 04:36:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][200/781]	Step 11148	lr 0.01075	Loss 0.3981 (0.3603)	Prec@(1,5) (87.7%, 99.6%)	
06/26 04:36:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][250/781]	Step 11198	lr 0.01075	Loss 0.3748 (0.3577)	Prec@(1,5) (87.7%, 99.6%)	
06/26 04:36:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][300/781]	Step 11248	lr 0.01075	Loss 0.3908 (0.3583)	Prec@(1,5) (87.6%, 99.6%)	
06/26 04:36:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][350/781]	Step 11298	lr 0.01075	Loss 0.4576 (0.3577)	Prec@(1,5) (87.6%, 99.6%)	
06/26 04:37:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][400/781]	Step 11348	lr 0.01075	Loss 0.3716 (0.3584)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][450/781]	Step 11398	lr 0.01075	Loss 0.3947 (0.3578)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][500/781]	Step 11448	lr 0.01075	Loss 0.3647 (0.3576)	Prec@(1,5) (87.6%, 99.6%)	
06/26 04:37:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][550/781]	Step 11498	lr 0.01075	Loss 0.4042 (0.3598)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][600/781]	Step 11548	lr 0.01075	Loss 0.2722 (0.3596)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][650/781]	Step 11598	lr 0.01075	Loss 0.3107 (0.3592)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][700/781]	Step 11648	lr 0.01075	Loss 0.3540 (0.3601)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][750/781]	Step 11698	lr 0.01075	Loss 0.2646 (0.3602)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [14][781/781]	Step 11729	lr 0.01075	Loss 0.3859 (0.3602)	Prec@(1,5) (87.5%, 99.6%)	
06/26 04:37:28午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 14/24] Final Prec@1 87.4680%
06/26 04:37:29午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][50/391]	Step 11730	Loss 0.3135	Prec@(1,5) (89.1%, 99.8%)
06/26 04:37:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][100/391]	Step 11730	Loss 0.3167	Prec@(1,5) (88.9%, 99.8%)
06/26 04:37:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][150/391]	Step 11730	Loss 0.3205	Prec@(1,5) (88.7%, 99.7%)
06/26 04:37:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][200/391]	Step 11730	Loss 0.3203	Prec@(1,5) (88.8%, 99.7%)
06/26 04:37:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][250/391]	Step 11730	Loss 0.3184	Prec@(1,5) (88.9%, 99.7%)
06/26 04:37:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][300/391]	Step 11730	Loss 0.3145	Prec@(1,5) (88.9%, 99.7%)
06/26 04:37:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][350/391]	Step 11730	Loss 0.3140	Prec@(1,5) (89.0%, 99.7%)
06/26 04:37:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [14][390/391]	Step 11730	Loss 0.3153	Prec@(1,5) (88.9%, 99.7%)
06/26 04:37:34午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 14/24] Final Prec@1 88.8680%
06/26 04:37:35午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 88.8680%
06/26 04:37:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][50/781]	Step 11780	lr 0.00929	Loss 0.2050 (0.3144)	Prec@(1,5) (88.7%, 99.6%)	
06/26 04:37:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][100/781]	Step 11830	lr 0.00929	Loss 0.2570 (0.2998)	Prec@(1,5) (89.3%, 99.7%)	
06/26 04:37:46午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][150/781]	Step 11880	lr 0.00929	Loss 0.2364 (0.3084)	Prec@(1,5) (88.9%, 99.7%)	
06/26 04:37:49午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][200/781]	Step 11930	lr 0.00929	Loss 0.2350 (0.3185)	Prec@(1,5) (88.6%, 99.7%)	
06/26 04:37:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][250/781]	Step 11980	lr 0.00929	Loss 0.2360 (0.3194)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:37:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][300/781]	Step 12030	lr 0.00929	Loss 0.2797 (0.3205)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:38:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][350/781]	Step 12080	lr 0.00929	Loss 0.4489 (0.3213)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:38:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][400/781]	Step 12130	lr 0.00929	Loss 0.4246 (0.3250)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:38:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][450/781]	Step 12180	lr 0.00929	Loss 0.2319 (0.3274)	Prec@(1,5) (88.6%, 99.7%)	
06/26 04:38:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][500/781]	Step 12230	lr 0.00929	Loss 0.2865 (0.3260)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:38:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][550/781]	Step 12280	lr 0.00929	Loss 0.3265 (0.3254)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:38:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][600/781]	Step 12330	lr 0.00929	Loss 0.2245 (0.3243)	Prec@(1,5) (88.8%, 99.7%)	
06/26 04:38:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][650/781]	Step 12380	lr 0.00929	Loss 0.3262 (0.3265)	Prec@(1,5) (88.7%, 99.7%)	
06/26 04:38:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][700/781]	Step 12430	lr 0.00929	Loss 0.1790 (0.3278)	Prec@(1,5) (88.6%, 99.7%)	
06/26 04:38:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][750/781]	Step 12480	lr 0.00929	Loss 0.3805 (0.3289)	Prec@(1,5) (88.6%, 99.7%)	
06/26 04:38:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [15][781/781]	Step 12511	lr 0.00929	Loss 0.3934 (0.3294)	Prec@(1,5) (88.5%, 99.7%)	
06/26 04:38:29午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 15/24] Final Prec@1 88.5460%
06/26 04:38:30午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][50/391]	Step 12512	Loss 0.2649	Prec@(1,5) (91.1%, 99.7%)
06/26 04:38:31午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][100/391]	Step 12512	Loss 0.2693	Prec@(1,5) (90.6%, 99.8%)
06/26 04:38:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][150/391]	Step 12512	Loss 0.2709	Prec@(1,5) (90.6%, 99.8%)
06/26 04:38:32午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][200/391]	Step 12512	Loss 0.2753	Prec@(1,5) (90.4%, 99.8%)
06/26 04:38:33午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][250/391]	Step 12512	Loss 0.2757	Prec@(1,5) (90.5%, 99.8%)
06/26 04:38:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][300/391]	Step 12512	Loss 0.2782	Prec@(1,5) (90.3%, 99.8%)
06/26 04:38:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][350/391]	Step 12512	Loss 0.2783	Prec@(1,5) (90.4%, 99.8%)
06/26 04:38:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [15][390/391]	Step 12512	Loss 0.2800	Prec@(1,5) (90.2%, 99.8%)
06/26 04:38:35午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 15/24] Final Prec@1 90.2440%
06/26 04:38:36午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 90.2440%
06/26 04:38:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][50/781]	Step 12562	lr 0.00789	Loss 0.3879 (0.3145)	Prec@(1,5) (89.3%, 99.7%)	
06/26 04:38:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][100/781]	Step 12612	lr 0.00789	Loss 0.2393 (0.3052)	Prec@(1,5) (89.4%, 99.8%)	
06/26 04:38:48午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][150/781]	Step 12662	lr 0.00789	Loss 0.3948 (0.3027)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:38:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][200/781]	Step 12712	lr 0.00789	Loss 0.2925 (0.3019)	Prec@(1,5) (89.6%, 99.8%)	
06/26 04:38:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][250/781]	Step 12762	lr 0.00789	Loss 0.4407 (0.3037)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:38:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][300/781]	Step 12812	lr 0.00789	Loss 0.2788 (0.3051)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:39:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][350/781]	Step 12862	lr 0.00789	Loss 0.3749 (0.3049)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:39:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][400/781]	Step 12912	lr 0.00789	Loss 0.3573 (0.3062)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:39:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][450/781]	Step 12962	lr 0.00789	Loss 0.4050 (0.3064)	Prec@(1,5) (89.4%, 99.7%)	
06/26 04:39:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][500/781]	Step 13012	lr 0.00789	Loss 0.3850 (0.3055)	Prec@(1,5) (89.4%, 99.7%)	
06/26 04:39:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][550/781]	Step 13062	lr 0.00789	Loss 0.5399 (0.3042)	Prec@(1,5) (89.4%, 99.7%)	
06/26 04:39:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][600/781]	Step 13112	lr 0.00789	Loss 0.2835 (0.3020)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:39:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][650/781]	Step 13162	lr 0.00789	Loss 0.2782 (0.3024)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:39:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][700/781]	Step 13212	lr 0.00789	Loss 0.3844 (0.3020)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:39:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][750/781]	Step 13262	lr 0.00789	Loss 0.2976 (0.3017)	Prec@(1,5) (89.5%, 99.7%)	
06/26 04:39:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [16][781/781]	Step 13293	lr 0.00789	Loss 0.3050 (0.3005)	Prec@(1,5) (89.5%, 99.8%)	
06/26 04:39:33午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 16/24] Final Prec@1 89.5120%
06/26 04:39:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][50/391]	Step 13294	Loss 0.2663	Prec@(1,5) (90.4%, 99.9%)
06/26 04:39:34午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][100/391]	Step 13294	Loss 0.2630	Prec@(1,5) (90.5%, 99.9%)
06/26 04:39:35午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][150/391]	Step 13294	Loss 0.2575	Prec@(1,5) (90.6%, 99.9%)
06/26 04:39:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][200/391]	Step 13294	Loss 0.2677	Prec@(1,5) (90.3%, 99.9%)
06/26 04:39:36午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][250/391]	Step 13294	Loss 0.2676	Prec@(1,5) (90.4%, 99.9%)
06/26 04:39:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][300/391]	Step 13294	Loss 0.2672	Prec@(1,5) (90.5%, 99.9%)
06/26 04:39:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][350/391]	Step 13294	Loss 0.2703	Prec@(1,5) (90.4%, 99.9%)
06/26 04:39:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [16][390/391]	Step 13294	Loss 0.2705	Prec@(1,5) (90.4%, 99.9%)
06/26 04:39:38午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 16/24] Final Prec@1 90.3600%
06/26 04:39:40午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 90.3600%
06/26 04:39:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][50/781]	Step 13344	lr 0.00657	Loss 0.2656 (0.2664)	Prec@(1,5) (90.8%, 99.8%)	
06/26 04:39:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][100/781]	Step 13394	lr 0.00657	Loss 0.2708 (0.2742)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:39:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][150/781]	Step 13444	lr 0.00657	Loss 0.1816 (0.2704)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:39:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][200/781]	Step 13494	lr 0.00657	Loss 0.1390 (0.2658)	Prec@(1,5) (90.7%, 99.8%)	
06/26 04:39:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][250/781]	Step 13544	lr 0.00657	Loss 0.2443 (0.2682)	Prec@(1,5) (90.4%, 99.8%)	
06/26 04:40:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][300/781]	Step 13594	lr 0.00657	Loss 0.2187 (0.2687)	Prec@(1,5) (90.6%, 99.8%)	
06/26 04:40:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][350/781]	Step 13644	lr 0.00657	Loss 0.3319 (0.2670)	Prec@(1,5) (90.6%, 99.8%)	
06/26 04:40:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][400/781]	Step 13694	lr 0.00657	Loss 0.2102 (0.2691)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:40:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][450/781]	Step 13744	lr 0.00657	Loss 0.1587 (0.2709)	Prec@(1,5) (90.4%, 99.8%)	
06/26 04:40:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][500/781]	Step 13794	lr 0.00657	Loss 0.1197 (0.2700)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:40:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][550/781]	Step 13844	lr 0.00657	Loss 0.3116 (0.2700)	Prec@(1,5) (90.5%, 99.8%)	
06/26 04:40:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][600/781]	Step 13894	lr 0.00657	Loss 0.2399 (0.2735)	Prec@(1,5) (90.4%, 99.8%)	
06/26 04:40:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][650/781]	Step 13944	lr 0.00657	Loss 0.2576 (0.2725)	Prec@(1,5) (90.4%, 99.8%)	
06/26 04:40:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][700/781]	Step 13994	lr 0.00657	Loss 0.2743 (0.2737)	Prec@(1,5) (90.4%, 99.8%)	
06/26 04:40:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][750/781]	Step 14044	lr 0.00657	Loss 0.3449 (0.2740)	Prec@(1,5) (90.4%, 99.8%)	
06/26 04:40:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [17][781/781]	Step 14075	lr 0.00657	Loss 0.3137 (0.2741)	Prec@(1,5) (90.3%, 99.8%)	
06/26 04:40:36午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 17/24] Final Prec@1 90.3400%
06/26 04:40:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][50/391]	Step 14076	Loss 0.2575	Prec@(1,5) (90.6%, 99.8%)
06/26 04:40:37午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][100/391]	Step 14076	Loss 0.2505	Prec@(1,5) (90.9%, 99.9%)
06/26 04:40:38午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][150/391]	Step 14076	Loss 0.2509	Prec@(1,5) (91.0%, 99.9%)
06/26 04:40:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][200/391]	Step 14076	Loss 0.2427	Prec@(1,5) (91.4%, 99.8%)
06/26 04:40:39午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][250/391]	Step 14076	Loss 0.2391	Prec@(1,5) (91.6%, 99.9%)
06/26 04:40:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][300/391]	Step 14076	Loss 0.2405	Prec@(1,5) (91.5%, 99.9%)
06/26 04:40:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][350/391]	Step 14076	Loss 0.2363	Prec@(1,5) (91.7%, 99.9%)
06/26 04:40:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [17][390/391]	Step 14076	Loss 0.2363	Prec@(1,5) (91.7%, 99.9%)
06/26 04:40:41午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 17/24] Final Prec@1 91.7200%
06/26 04:40:43午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 91.7200%
06/26 04:40:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][50/781]	Step 14126	lr 0.00535	Loss 0.2086 (0.2343)	Prec@(1,5) (91.8%, 99.9%)	
06/26 04:40:51午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][100/781]	Step 14176	lr 0.00535	Loss 0.1876 (0.2387)	Prec@(1,5) (91.5%, 99.9%)	
06/26 04:40:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][150/781]	Step 14226	lr 0.00535	Loss 0.2568 (0.2430)	Prec@(1,5) (91.4%, 99.9%)	
06/26 04:40:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][200/781]	Step 14276	lr 0.00535	Loss 0.1884 (0.2429)	Prec@(1,5) (91.5%, 99.9%)	
06/26 04:41:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][250/781]	Step 14326	lr 0.00535	Loss 0.1928 (0.2427)	Prec@(1,5) (91.5%, 99.9%)	
06/26 04:41:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][300/781]	Step 14376	lr 0.00535	Loss 0.2108 (0.2410)	Prec@(1,5) (91.6%, 99.8%)	
06/26 04:41:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][350/781]	Step 14426	lr 0.00535	Loss 0.3104 (0.2406)	Prec@(1,5) (91.6%, 99.8%)	
06/26 04:41:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][400/781]	Step 14476	lr 0.00535	Loss 0.3203 (0.2420)	Prec@(1,5) (91.6%, 99.8%)	
06/26 04:41:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][450/781]	Step 14526	lr 0.00535	Loss 0.3642 (0.2421)	Prec@(1,5) (91.6%, 99.9%)	
06/26 04:41:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][500/781]	Step 14576	lr 0.00535	Loss 0.1396 (0.2419)	Prec@(1,5) (91.6%, 99.9%)	
06/26 04:41:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][550/781]	Step 14626	lr 0.00535	Loss 0.3116 (0.2410)	Prec@(1,5) (91.6%, 99.9%)	
06/26 04:41:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][600/781]	Step 14676	lr 0.00535	Loss 0.3560 (0.2395)	Prec@(1,5) (91.7%, 99.9%)	
06/26 04:41:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][650/781]	Step 14726	lr 0.00535	Loss 0.2820 (0.2399)	Prec@(1,5) (91.7%, 99.8%)	
06/26 04:41:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][700/781]	Step 14776	lr 0.00535	Loss 0.1836 (0.2396)	Prec@(1,5) (91.6%, 99.8%)	
06/26 04:41:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][750/781]	Step 14826	lr 0.00535	Loss 0.1932 (0.2400)	Prec@(1,5) (91.6%, 99.8%)	
06/26 04:41:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [18][781/781]	Step 14857	lr 0.00535	Loss 0.1883 (0.2400)	Prec@(1,5) (91.7%, 99.8%)	
06/26 04:41:39午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 18/24] Final Prec@1 91.6620%
06/26 04:41:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][50/391]	Step 14858	Loss 0.1977	Prec@(1,5) (93.7%, 99.8%)
06/26 04:41:40午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][100/391]	Step 14858	Loss 0.1985	Prec@(1,5) (93.2%, 99.9%)
06/26 04:41:41午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][150/391]	Step 14858	Loss 0.2062	Prec@(1,5) (93.0%, 99.8%)
06/26 04:41:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][200/391]	Step 14858	Loss 0.2048	Prec@(1,5) (93.0%, 99.9%)
06/26 04:41:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][250/391]	Step 14858	Loss 0.2061	Prec@(1,5) (92.9%, 99.9%)
06/26 04:41:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][300/391]	Step 14858	Loss 0.2038	Prec@(1,5) (92.9%, 99.9%)
06/26 04:41:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][350/391]	Step 14858	Loss 0.2019	Prec@(1,5) (93.0%, 99.9%)
06/26 04:41:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [18][390/391]	Step 14858	Loss 0.1999	Prec@(1,5) (93.1%, 99.9%)
06/26 04:41:45午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 18/24] Final Prec@1 93.0480%
06/26 04:41:46午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.0480%
06/26 04:41:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][50/781]	Step 14908	lr 0.00425	Loss 0.2068 (0.2103)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:41:54午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][100/781]	Step 14958	lr 0.00425	Loss 0.2343 (0.2113)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:41:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][150/781]	Step 15008	lr 0.00425	Loss 0.1590 (0.2148)	Prec@(1,5) (92.5%, 99.9%)	
06/26 04:42:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][200/781]	Step 15058	lr 0.00425	Loss 0.2333 (0.2190)	Prec@(1,5) (92.4%, 99.9%)	
06/26 04:42:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][250/781]	Step 15108	lr 0.00425	Loss 0.2202 (0.2153)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][300/781]	Step 15158	lr 0.00425	Loss 0.4205 (0.2148)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][350/781]	Step 15208	lr 0.00425	Loss 0.1272 (0.2131)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:42:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][400/781]	Step 15258	lr 0.00425	Loss 0.2429 (0.2137)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:42:18午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][450/781]	Step 15308	lr 0.00425	Loss 0.2765 (0.2154)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][500/781]	Step 15358	lr 0.00425	Loss 0.3387 (0.2142)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:42:25午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][550/781]	Step 15408	lr 0.00425	Loss 0.1614 (0.2135)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:42:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][600/781]	Step 15458	lr 0.00425	Loss 0.3826 (0.2141)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:42:32午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][650/781]	Step 15508	lr 0.00425	Loss 0.2235 (0.2141)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:35午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][700/781]	Step 15558	lr 0.00425	Loss 0.1596 (0.2152)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][750/781]	Step 15608	lr 0.00425	Loss 0.1378 (0.2156)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [19][781/781]	Step 15639	lr 0.00425	Loss 0.2167 (0.2158)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:41午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 19/24] Final Prec@1 92.5860%
06/26 04:42:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][50/391]	Step 15640	Loss 0.1891	Prec@(1,5) (93.2%, 99.9%)
06/26 04:42:42午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][100/391]	Step 15640	Loss 0.1772	Prec@(1,5) (93.7%, 99.9%)
06/26 04:42:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][150/391]	Step 15640	Loss 0.1842	Prec@(1,5) (93.4%, 99.9%)
06/26 04:42:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][200/391]	Step 15640	Loss 0.1838	Prec@(1,5) (93.5%, 99.9%)
06/26 04:42:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][250/391]	Step 15640	Loss 0.1845	Prec@(1,5) (93.5%, 99.9%)
06/26 04:42:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][300/391]	Step 15640	Loss 0.1813	Prec@(1,5) (93.6%, 99.9%)
06/26 04:42:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][350/391]	Step 15640	Loss 0.1798	Prec@(1,5) (93.7%, 99.9%)
06/26 04:42:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [19][390/391]	Step 15640	Loss 0.1785	Prec@(1,5) (93.8%, 99.9%)
06/26 04:42:46午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 19/24] Final Prec@1 93.7800%
06/26 04:42:48午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 93.7800%
06/26 04:42:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][50/781]	Step 15690	lr 0.00329	Loss 0.0798 (0.2050)	Prec@(1,5) (92.6%, 99.9%)	
06/26 04:42:55午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][100/781]	Step 15740	lr 0.00329	Loss 0.2418 (0.2088)	Prec@(1,5) (92.4%, 99.9%)	
06/26 04:42:59午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][150/781]	Step 15790	lr 0.00329	Loss 0.1579 (0.2041)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:43:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][200/781]	Step 15840	lr 0.00329	Loss 0.2163 (0.2041)	Prec@(1,5) (92.7%, 99.9%)	
06/26 04:43:06午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][250/781]	Step 15890	lr 0.00329	Loss 0.2253 (0.2023)	Prec@(1,5) (92.8%, 99.9%)	
06/26 04:43:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][300/781]	Step 15940	lr 0.00329	Loss 0.0686 (0.1984)	Prec@(1,5) (92.9%, 99.9%)	
06/26 04:43:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][350/781]	Step 15990	lr 0.00329	Loss 0.0956 (0.1945)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][400/781]	Step 16040	lr 0.00329	Loss 0.1603 (0.1947)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][450/781]	Step 16090	lr 0.00329	Loss 0.0940 (0.1962)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:43:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][500/781]	Step 16140	lr 0.00329	Loss 0.3200 (0.1962)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:43:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][550/781]	Step 16190	lr 0.00329	Loss 0.1773 (0.1956)	Prec@(1,5) (93.0%, 99.9%)	
06/26 04:43:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][600/781]	Step 16240	lr 0.00329	Loss 0.2418 (0.1947)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][650/781]	Step 16290	lr 0.00329	Loss 0.0926 (0.1956)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][700/781]	Step 16340	lr 0.00329	Loss 0.1947 (0.1959)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][750/781]	Step 16390	lr 0.00329	Loss 0.1656 (0.1947)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:42午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [20][781/781]	Step 16421	lr 0.00329	Loss 0.1144 (0.1945)	Prec@(1,5) (93.1%, 99.9%)	
06/26 04:43:42午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 20/24] Final Prec@1 93.0920%
06/26 04:43:43午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][50/391]	Step 16422	Loss 0.1717	Prec@(1,5) (94.4%, 99.9%)
06/26 04:43:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][100/391]	Step 16422	Loss 0.1547	Prec@(1,5) (94.7%, 99.9%)
06/26 04:43:44午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][150/391]	Step 16422	Loss 0.1567	Prec@(1,5) (94.6%, 99.9%)
06/26 04:43:45午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][200/391]	Step 16422	Loss 0.1577	Prec@(1,5) (94.5%, 99.9%)
06/26 04:43:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][250/391]	Step 16422	Loss 0.1577	Prec@(1,5) (94.5%, 99.9%)
06/26 04:43:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][300/391]	Step 16422	Loss 0.1571	Prec@(1,5) (94.6%, 99.9%)
06/26 04:43:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][350/391]	Step 16422	Loss 0.1580	Prec@(1,5) (94.5%, 99.9%)
06/26 04:43:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [20][390/391]	Step 16422	Loss 0.1574	Prec@(1,5) (94.5%, 99.9%)
06/26 04:43:48午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 20/24] Final Prec@1 94.5360%
06/26 04:43:49午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 94.5360%
06/26 04:43:53午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][50/781]	Step 16472	lr 0.00248	Loss 0.3122 (0.1613)	Prec@(1,5) (94.7%, 99.9%)	
06/26 04:43:57午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][100/781]	Step 16522	lr 0.00248	Loss 0.1848 (0.1619)	Prec@(1,5) (94.5%, 99.9%)	
06/26 04:44:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][150/781]	Step 16572	lr 0.00248	Loss 0.1689 (0.1661)	Prec@(1,5) (94.4%, 99.9%)	
06/26 04:44:04午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][200/781]	Step 16622	lr 0.00248	Loss 0.2297 (0.1660)	Prec@(1,5) (94.4%, 99.9%)	
06/26 04:44:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][250/781]	Step 16672	lr 0.00248	Loss 0.1959 (0.1674)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:44:11午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][300/781]	Step 16722	lr 0.00248	Loss 0.1200 (0.1678)	Prec@(1,5) (94.2%, 99.9%)	
06/26 04:44:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][350/781]	Step 16772	lr 0.00248	Loss 0.1112 (0.1673)	Prec@(1,5) (94.3%, 99.9%)	
06/26 04:44:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][400/781]	Step 16822	lr 0.00248	Loss 0.1439 (0.1684)	Prec@(1,5) (94.2%, 99.9%)	
06/26 04:44:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][450/781]	Step 16872	lr 0.00248	Loss 0.2240 (0.1685)	Prec@(1,5) (94.2%, 99.9%)	
06/26 04:44:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][500/781]	Step 16922	lr 0.00248	Loss 0.0688 (0.1683)	Prec@(1,5) (94.2%, 99.9%)	
06/26 04:44:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][550/781]	Step 16972	lr 0.00248	Loss 0.1533 (0.1686)	Prec@(1,5) (94.2%, 99.9%)	
06/26 04:44:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][600/781]	Step 17022	lr 0.00248	Loss 0.1719 (0.1692)	Prec@(1,5) (94.1%, 99.9%)	
06/26 04:44:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][650/781]	Step 17072	lr 0.00248	Loss 0.1374 (0.1694)	Prec@(1,5) (94.1%, 99.9%)	
06/26 04:44:39午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][700/781]	Step 17122	lr 0.00248	Loss 0.0954 (0.1696)	Prec@(1,5) (94.1%, 99.9%)	
06/26 04:44:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][750/781]	Step 17172	lr 0.00248	Loss 0.2803 (0.1693)	Prec@(1,5) (94.1%, 99.9%)	
06/26 04:44:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [21][781/781]	Step 17203	lr 0.00248	Loss 0.2032 (0.1687)	Prec@(1,5) (94.2%, 99.9%)	
06/26 04:44:45午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 21/24] Final Prec@1 94.1840%
06/26 04:44:46午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][50/391]	Step 17204	Loss 0.1374	Prec@(1,5) (95.1%, 100.0%)
06/26 04:44:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][100/391]	Step 17204	Loss 0.1351	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:47午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][150/391]	Step 17204	Loss 0.1374	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][200/391]	Step 17204	Loss 0.1363	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][250/391]	Step 17204	Loss 0.1369	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][300/391]	Step 17204	Loss 0.1381	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][350/391]	Step 17204	Loss 0.1384	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [21][390/391]	Step 17204	Loss 0.1383	Prec@(1,5) (95.2%, 100.0%)
06/26 04:44:51午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 21/24] Final Prec@1 95.1640%
06/26 04:44:52午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 95.1640%
06/26 04:44:56午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][50/781]	Step 17254	lr 0.00184	Loss 0.1172 (0.1532)	Prec@(1,5) (94.8%, 100.0%)	
06/26 04:45:00午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][100/781]	Step 17304	lr 0.00184	Loss 0.1938 (0.1559)	Prec@(1,5) (94.6%, 100.0%)	
06/26 04:45:03午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][150/781]	Step 17354	lr 0.00184	Loss 0.0905 (0.1525)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:07午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][200/781]	Step 17404	lr 0.00184	Loss 0.0565 (0.1534)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:10午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][250/781]	Step 17454	lr 0.00184	Loss 0.1652 (0.1525)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:14午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][300/781]	Step 17504	lr 0.00184	Loss 0.1416 (0.1527)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:17午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][350/781]	Step 17554	lr 0.00184	Loss 0.1161 (0.1538)	Prec@(1,5) (94.7%, 99.9%)	
06/26 04:45:21午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][400/781]	Step 17604	lr 0.00184	Loss 0.0741 (0.1517)	Prec@(1,5) (94.8%, 100.0%)	
06/26 04:45:24午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][450/781]	Step 17654	lr 0.00184	Loss 0.0779 (0.1515)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:28午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][500/781]	Step 17704	lr 0.00184	Loss 0.1611 (0.1519)	Prec@(1,5) (94.8%, 100.0%)	
06/26 04:45:31午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][550/781]	Step 17754	lr 0.00184	Loss 0.1660 (0.1514)	Prec@(1,5) (94.8%, 100.0%)	
06/26 04:45:34午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][600/781]	Step 17804	lr 0.00184	Loss 0.1216 (0.1518)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:38午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][650/781]	Step 17854	lr 0.00184	Loss 0.1140 (0.1516)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:41午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][700/781]	Step 17904	lr 0.00184	Loss 0.1742 (0.1516)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:45午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][750/781]	Step 17954	lr 0.00184	Loss 0.0877 (0.1519)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [22][781/781]	Step 17985	lr 0.00184	Loss 0.1119 (0.1522)	Prec@(1,5) (94.7%, 100.0%)	
06/26 04:45:47午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 22/24] Final Prec@1 94.6760%
06/26 04:45:48午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][50/391]	Step 17986	Loss 0.1273	Prec@(1,5) (95.9%, 99.9%)
06/26 04:45:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][100/391]	Step 17986	Loss 0.1208	Prec@(1,5) (96.0%, 100.0%)
06/26 04:45:49午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][150/391]	Step 17986	Loss 0.1196	Prec@(1,5) (96.0%, 100.0%)
06/26 04:45:50午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][200/391]	Step 17986	Loss 0.1182	Prec@(1,5) (96.0%, 100.0%)
06/26 04:45:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][250/391]	Step 17986	Loss 0.1200	Prec@(1,5) (95.9%, 100.0%)
06/26 04:45:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][300/391]	Step 17986	Loss 0.1201	Prec@(1,5) (95.9%, 100.0%)
06/26 04:45:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][350/391]	Step 17986	Loss 0.1187	Prec@(1,5) (95.9%, 100.0%)
06/26 04:45:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [22][390/391]	Step 17986	Loss 0.1199	Prec@(1,5) (95.8%, 100.0%)
06/26 04:45:53午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 22/24] Final Prec@1 95.8360%
06/26 04:45:54午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 95.8360%
06/26 04:45:58午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][50/781]	Step 18036	lr 0.00138	Loss 0.2188 (0.1353)	Prec@(1,5) (95.1%, 100.0%)	
06/26 04:46:02午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][100/781]	Step 18086	lr 0.00138	Loss 0.1394 (0.1340)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:46:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][150/781]	Step 18136	lr 0.00138	Loss 0.1093 (0.1321)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:46:09午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][200/781]	Step 18186	lr 0.00138	Loss 0.1209 (0.1281)	Prec@(1,5) (95.6%, 100.0%)	
06/26 04:46:13午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][250/781]	Step 18236	lr 0.00138	Loss 0.1751 (0.1305)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:46:16午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][300/781]	Step 18286	lr 0.00138	Loss 0.1009 (0.1317)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:46:20午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][350/781]	Step 18336	lr 0.00138	Loss 0.2166 (0.1340)	Prec@(1,5) (95.4%, 100.0%)	
06/26 04:46:23午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][400/781]	Step 18386	lr 0.00138	Loss 0.2257 (0.1346)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:27午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][450/781]	Step 18436	lr 0.00138	Loss 0.1027 (0.1361)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:30午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][500/781]	Step 18486	lr 0.00138	Loss 0.2335 (0.1355)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][550/781]	Step 18536	lr 0.00138	Loss 0.2374 (0.1352)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:37午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][600/781]	Step 18586	lr 0.00138	Loss 0.2138 (0.1348)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][650/781]	Step 18636	lr 0.00138	Loss 0.2618 (0.1353)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:44午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][700/781]	Step 18686	lr 0.00138	Loss 0.0926 (0.1357)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:46:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][750/781]	Step 18736	lr 0.00138	Loss 0.1521 (0.1361)	Prec@(1,5) (95.2%, 100.0%)	
06/26 04:46:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [23][781/781]	Step 18767	lr 0.00138	Loss 0.1066 (0.1364)	Prec@(1,5) (95.2%, 100.0%)	
06/26 04:46:50午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 23/24] Final Prec@1 95.2020%
06/26 04:46:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][50/391]	Step 18768	Loss 0.0993	Prec@(1,5) (96.6%, 100.0%)
06/26 04:46:51午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][100/391]	Step 18768	Loss 0.0983	Prec@(1,5) (96.6%, 100.0%)
06/26 04:46:52午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][150/391]	Step 18768	Loss 0.1008	Prec@(1,5) (96.6%, 100.0%)
06/26 04:46:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][200/391]	Step 18768	Loss 0.1002	Prec@(1,5) (96.5%, 100.0%)
06/26 04:46:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][250/391]	Step 18768	Loss 0.1027	Prec@(1,5) (96.5%, 100.0%)
06/26 04:46:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][300/391]	Step 18768	Loss 0.1026	Prec@(1,5) (96.5%, 100.0%)
06/26 04:46:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][350/391]	Step 18768	Loss 0.1041	Prec@(1,5) (96.4%, 100.0%)
06/26 04:46:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [23][390/391]	Step 18768	Loss 0.1044	Prec@(1,5) (96.4%, 100.0%)
06/26 04:46:55午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 23/24] Final Prec@1 96.4240%
06/26 04:46:57午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.4240%
06/26 04:47:01午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][50/781]	Step 18818	lr 0.00109	Loss 0.1538 (0.1396)	Prec@(1,5) (95.1%, 100.0%)	
06/26 04:47:05午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][100/781]	Step 18868	lr 0.00109	Loss 0.1002 (0.1393)	Prec@(1,5) (95.2%, 100.0%)	
06/26 04:47:08午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][150/781]	Step 18918	lr 0.00109	Loss 0.0389 (0.1370)	Prec@(1,5) (95.1%, 100.0%)	
06/26 04:47:12午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][200/781]	Step 18968	lr 0.00109	Loss 0.1216 (0.1357)	Prec@(1,5) (95.2%, 100.0%)	
06/26 04:47:15午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][250/781]	Step 19018	lr 0.00109	Loss 0.1233 (0.1314)	Prec@(1,5) (95.3%, 100.0%)	
06/26 04:47:19午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][300/781]	Step 19068	lr 0.00109	Loss 0.1538 (0.1302)	Prec@(1,5) (95.4%, 100.0%)	
06/26 04:47:22午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][350/781]	Step 19118	lr 0.00109	Loss 0.1264 (0.1284)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:26午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][400/781]	Step 19168	lr 0.00109	Loss 0.0414 (0.1286)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:29午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][450/781]	Step 19218	lr 0.00109	Loss 0.2412 (0.1298)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:33午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][500/781]	Step 19268	lr 0.00109	Loss 0.2029 (0.1295)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:36午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][550/781]	Step 19318	lr 0.00109	Loss 0.0507 (0.1298)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:40午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][600/781]	Step 19368	lr 0.00109	Loss 0.1556 (0.1301)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:43午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][650/781]	Step 19418	lr 0.00109	Loss 0.0861 (0.1303)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:47午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][700/781]	Step 19468	lr 0.00109	Loss 0.1434 (0.1301)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:50午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][750/781]	Step 19518	lr 0.00109	Loss 0.1534 (0.1302)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:52午後 finetuneTeacher_trainer.py:171 [INFO] Train: Epoch: [24][781/781]	Step 19549	lr 0.00109	Loss 0.1756 (0.1310)	Prec@(1,5) (95.5%, 100.0%)	
06/26 04:47:53午後 finetuneTeacher_trainer.py:181 [INFO] Train: [ 24/24] Final Prec@1 95.4580%
06/26 04:47:53午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][50/391]	Step 19550	Loss 0.0965	Prec@(1,5) (97.0%, 100.0%)
06/26 04:47:54午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][100/391]	Step 19550	Loss 0.1043	Prec@(1,5) (96.5%, 100.0%)
06/26 04:47:55午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][150/391]	Step 19550	Loss 0.0983	Prec@(1,5) (96.9%, 100.0%)
06/26 04:47:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][200/391]	Step 19550	Loss 0.1011	Prec@(1,5) (96.6%, 100.0%)
06/26 04:47:56午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][250/391]	Step 19550	Loss 0.1002	Prec@(1,5) (96.6%, 100.0%)
06/26 04:47:57午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][300/391]	Step 19550	Loss 0.0990	Prec@(1,5) (96.6%, 100.0%)
06/26 04:47:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][350/391]	Step 19550	Loss 0.0985	Prec@(1,5) (96.7%, 100.0%)
06/26 04:47:58午後 finetuneTeacher_trainer.py:209 [INFO] Valid: Epoch: [24][390/391]	Step 19550	Loss 0.0996	Prec@(1,5) (96.6%, 100.0%)
06/26 04:47:58午後 finetuneTeacher_trainer.py:216 [INFO] Valid: [ 24/24] Final Prec@1 96.6400%
06/26 04:48:00午後 finetuneTeacher_main.py:54 [INFO] Until now, best Prec@1 = 96.6400%
06/26 04:48:00午後 finetuneTeacher_main.py:56 [INFO] Final best Prec@1 = 96.6400%
