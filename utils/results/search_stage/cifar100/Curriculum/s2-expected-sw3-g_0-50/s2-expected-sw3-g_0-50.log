11/26 10:23:44AM parser.py:28 [INFO] 
11/26 10:23:44AM parser.py:29 [INFO] Parameters:
11/26 10:23:44AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s2-expected-sw3-g_0-50/DAG
11/26 10:23:44AM parser.py:31 [INFO] T=10.0
11/26 10:23:44AM parser.py:31 [INFO] ADVANCED=1
11/26 10:23:44AM parser.py:31 [INFO] ALPHA_LR=0.0003
11/26 10:23:44AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
11/26 10:23:44AM parser.py:31 [INFO] ARCH_CRITERION=expected
11/26 10:23:44AM parser.py:31 [INFO] BATCH_SIZE=128
11/26 10:23:44AM parser.py:31 [INFO] CASCADE=0
11/26 10:23:44AM parser.py:31 [INFO] CHECKPOINT_RESET=False
11/26 10:23:44AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[0, 50]
11/26 10:23:44AM parser.py:31 [INFO] CUTOUT_LENGTH=0
11/26 10:23:44AM parser.py:31 [INFO] DATA_PATH=../data/
11/26 10:23:44AM parser.py:31 [INFO] DATASET=cifar100
11/26 10:23:44AM parser.py:31 [INFO] DEPTH_COEF=0.0
11/26 10:23:44AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3_
11/26 10:23:44AM parser.py:31 [INFO] DISCRETE=1
11/26 10:23:44AM parser.py:31 [INFO] EPOCHS=50
11/26 10:23:44AM parser.py:31 [INFO] EVAL_EPOCHS=100
11/26 10:23:44AM parser.py:31 [INFO] EXP_NAME=s2-expected-sw3-g_0-50
11/26 10:23:44AM parser.py:31 [INFO] FINAL_L=0.0
11/26 10:23:44AM parser.py:31 [INFO] G=0.001
11/26 10:23:44AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
11/26 10:23:44AM parser.py:31 [INFO] GPUS=[0]
11/26 10:23:44AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
11/26 10:23:44AM parser.py:31 [INFO] INIT_CHANNELS=16
11/26 10:23:44AM parser.py:31 [INFO] L=0.0
11/26 10:23:44AM parser.py:31 [INFO] LAYERS=32
11/26 10:23:44AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
11/26 10:23:44AM parser.py:31 [INFO] NAME=Curriculum
11/26 10:23:44AM parser.py:31 [INFO] NONKD=1
11/26 10:23:44AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s2-expected-sw3-g_0-50
11/26 10:23:44AM parser.py:31 [INFO] PCDARTS=0
11/26 10:23:44AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s2-expected-sw3-g_0-50/plots
11/26 10:23:44AM parser.py:31 [INFO] PRINT_FREQ=100
11/26 10:23:44AM parser.py:31 [INFO] RESET=0
11/26 10:23:44AM parser.py:31 [INFO] RESUME_PATH=None
11/26 10:23:44AM parser.py:31 [INFO] SAVE=s2-expected-sw3-g_0-50
11/26 10:23:44AM parser.py:31 [INFO] SEED=2
11/26 10:23:44AM parser.py:31 [INFO] SHARE_STAGE=0
11/26 10:23:44AM parser.py:31 [INFO] SLIDE_WINDOW=3
11/26 10:23:44AM parser.py:31 [INFO] SPEC_CELL=1
11/26 10:23:44AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
11/26 10:23:44AM parser.py:31 [INFO] TEACHER_NAME=none
11/26 10:23:44AM parser.py:31 [INFO] TEACHER_PATH=none
11/26 10:23:44AM parser.py:31 [INFO] TRAIN_PORTION=0.5
11/26 10:23:44AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
11/26 10:23:44AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
11/26 10:23:44AM parser.py:31 [INFO] W_LR=0.025
11/26 10:23:44AM parser.py:31 [INFO] W_LR_MIN=0.001
11/26 10:23:44AM parser.py:31 [INFO] W_MOMENTUM=0.9
11/26 10:23:44AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
11/26 10:23:44AM parser.py:31 [INFO] WORKERS=4
11/26 10:23:44AM parser.py:32 [INFO] 
11/26 10:23:46AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
11/26 10:23:46AM searchEvalStage_curriculum_trainer.py:146 [INFO] --> Curriculum part A finished. Part B begins!
11/26 10:25:27AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][100/195]	Step 100	lr 0.025	Loss 4.1559 (4.4498)	Arch Loss 4.5149 (4.8111)	Arch Hard Loss 4.1615 (4.4542)	Arch Beta Loss 353.4508 (356.8539)	Arch depth Loss -0.0030 (-0.0017)	Prec@(1,5) (3.2%, 12.1%)	
11/26 10:27:00AM searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [0][195/195]	Step 195	lr 0.025	Loss 3.9718 (4.2591)	Arch Loss 4.3894 (4.6130)	Arch Hard Loss 4.0423 (4.2594)	Arch Beta Loss 347.0539 (353.6191)	Arch depth Loss -0.0072 (-0.0036)	Prec@(1,5) (5.1%, 18.0%)	
11/26 10:27:02AM searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  0/149] Final Prec@1 5.1280%
11/26 10:27:17AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/196]	Step 196	Loss 4.0535	Prec@(1,5) (7.3%, 25.2%)
11/26 10:27:32AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][195/196]	Step 196	Loss 4.0625	Prec@(1,5) (7.3%, 24.9%)
11/26 10:27:32AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 7.3560%
11/26 10:27:32AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('avg_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 6), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('avg_pool_3x3', 7)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG2_concat=[4, 6], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('skip_connect', 3)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG3_concat=[2, 4])
11/26 10:27:33AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 7.3560%
11/26 10:29:12午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][100/195]	Step 296	lr 0.025	Loss 3.8799 (3.8812)	Arch Loss 4.1101 (4.2183)	Arch Hard Loss 3.7697 (3.8746)	Arch Beta Loss 340.3132 (343.6536)	Arch depth Loss -0.0079 (-0.0071)	Prec@(1,5) (9.1%, 29.8%)	
11/26 10:30:45午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [1][195/195]	Step 391	lr 0.025	Loss 3.6691 (3.8192)	Arch Loss 4.0365 (4.1551)	Arch Hard Loss 3.7022 (3.8146)	Arch Beta Loss 334.2774 (340.5094)	Arch depth Loss -0.0057 (-0.0071)	Prec@(1,5) (10.2%, 31.9%)	
11/26 10:30:46午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  1/149] Final Prec@1 10.1760%
11/26 10:31:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/196]	Step 392	Loss 3.7344	Prec@(1,5) (11.5%, 35.6%)
11/26 10:31:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][195/196]	Step 392	Loss 3.7495	Prec@(1,5) (11.2%, 35.3%)
11/26 10:31:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 11.2320%
11/26 10:31:16午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 3), ('avg_pool_3x3', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 4])
11/26 10:31:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 11.2320%
11/26 10:32:56午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][100/195]	Step 492	lr 0.02499	Loss 3.6100 (3.6382)	Arch Loss 3.8694 (3.9843)	Arch Hard Loss 3.5413 (3.6532)	Arch Beta Loss 328.0920 (331.1009)	Arch depth Loss -0.0019 (-0.0044)	Prec@(1,5) (12.8%, 37.6%)	
11/26 10:34:29午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [2][195/195]	Step 587	lr 0.02499	Loss 3.5969 (3.5817)	Arch Loss 3.7991 (3.9236)	Arch Hard Loss 3.4765 (3.5953)	Arch Beta Loss 322.5433 (328.2390)	Arch depth Loss -0.0045 (-0.0044)	Prec@(1,5) (14.0%, 39.3%)	
11/26 10:34:30午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  2/149] Final Prec@1 13.9520%
11/26 10:34:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/196]	Step 588	Loss 3.4847	Prec@(1,5) (16.1%, 42.4%)
11/26 10:35:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][195/196]	Step 588	Loss 3.4925	Prec@(1,5) (16.0%, 42.3%)
11/26 10:35:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 15.9880%
11/26 10:35:00午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('avg_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 4])
11/26 10:35:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 15.9880%
11/26 10:36:40午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][100/195]	Step 688	lr 0.02498	Loss 3.2719 (3.3662)	Arch Loss 3.5793 (3.7182)	Arch Hard Loss 3.2626 (3.3987)	Arch Beta Loss 316.7574 (319.5338)	Arch depth Loss -0.0035 (-0.0030)	Prec@(1,5) (18.1%, 45.8%)	
11/26 10:38:13午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [3][195/195]	Step 783	lr 0.02498	Loss 3.3321 (3.3283)	Arch Loss 3.5348 (3.6656)	Arch Hard Loss 3.2232 (3.3487)	Arch Beta Loss 311.6573 (316.8832)	Arch depth Loss -0.0020 (-0.0027)	Prec@(1,5) (18.7%, 47.0%)	
11/26 10:38:14午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  3/149] Final Prec@1 18.7200%
11/26 10:38:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/196]	Step 784	Loss 3.2716	Prec@(1,5) (19.5%, 48.7%)
11/26 10:38:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][195/196]	Step 784	Loss 3.2942	Prec@(1,5) (19.5%, 48.2%)
11/26 10:38:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 19.4520%
11/26 10:38:44午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 4])
11/26 10:38:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 19.4520%
11/26 10:40:25午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][100/195]	Step 884	lr 0.02496	Loss 2.9973 (3.1844)	Arch Loss 3.3959 (3.5409)	Arch Hard Loss 3.0895 (3.2319)	Arch Beta Loss 306.4151 (308.9783)	Arch depth Loss -0.0018 (-0.0020)	Prec@(1,5) (21.1%, 50.4%)	
11/26 10:41:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [4][195/195]	Step 979	lr 0.02496	Loss 2.9259 (3.1379)	Arch Loss 3.3059 (3.4935)	Arch Hard Loss 3.0042 (3.1869)	Arch Beta Loss 301.7167 (306.5776)	Arch depth Loss -0.0030 (-0.0016)	Prec@(1,5) (22.1%, 52.1%)	
11/26 10:41:59午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  4/149] Final Prec@1 22.0600%
11/26 10:42:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/196]	Step 980	Loss 3.1380	Prec@(1,5) (22.0%, 51.8%)
11/26 10:42:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][195/196]	Step 980	Loss 3.1440	Prec@(1,5) (22.4%, 52.1%)
11/26 10:42:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 22.3480%
11/26 10:42:29午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[2, 4])
11/26 10:42:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 22.3480%
11/26 10:44:09午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][100/195]	Step 1080	lr 0.02493	Loss 3.0998 (2.9663)	Arch Loss 3.3161 (3.3617)	Arch Hard Loss 3.0195 (3.0626)	Arch Beta Loss 296.6466 (299.0354)	Arch depth Loss -0.0071 (-0.0049)	Prec@(1,5) (24.6%, 55.9%)	
11/26 10:45:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [5][195/195]	Step 1175	lr 0.02493	Loss 2.9397 (2.9638)	Arch Loss 3.3389 (3.3233)	Arch Hard Loss 3.0468 (3.0265)	Arch Beta Loss 292.0683 (296.7030)	Arch depth Loss -0.0063 (-0.0060)	Prec@(1,5) (25.1%, 56.4%)	
11/26 10:45:43午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  5/149] Final Prec@1 25.1120%
11/26 10:45:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/196]	Step 1176	Loss 2.9981	Prec@(1,5) (24.9%, 55.9%)
11/26 10:46:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][195/196]	Step 1176	Loss 2.9860	Prec@(1,5) (25.4%, 56.3%)
11/26 10:46:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 25.4880%
11/26 10:46:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG3_concat=[2, 6])
11/26 10:46:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 25.4880%
11/26 10:47:53午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][100/195]	Step 1276	lr 0.02491	Loss 2.8351 (2.8277)	Arch Loss 3.2464 (3.2177)	Arch Hard Loss 2.9589 (2.9280)	Arch Beta Loss 287.5000 (289.6858)	Arch depth Loss -0.0125 (-0.0097)	Prec@(1,5) (27.6%, 59.6%)	
11/26 10:49:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [6][195/195]	Step 1371	lr 0.02491	Loss 2.7697 (2.8178)	Arch Loss 3.3113 (3.2077)	Arch Hard Loss 3.0280 (2.9202)	Arch Beta Loss 283.3249 (287.5755)	Arch depth Loss -0.0149 (-0.0116)	Prec@(1,5) (27.9%, 60.0%)	
11/26 10:49:27午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  6/149] Final Prec@1 27.9000%
11/26 10:49:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/196]	Step 1372	Loss 2.8897	Prec@(1,5) (28.2%, 58.2%)
11/26 10:49:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][195/196]	Step 1372	Loss 2.9006	Prec@(1,5) (27.5%, 58.3%)
11/26 10:49:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 27.5600%
11/26 10:49:58午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 6])
11/26 10:49:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 27.5600%
11/26 10:51:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][100/195]	Step 1472	lr 0.02487	Loss 2.8021 (2.7018)	Arch Loss 3.0444 (3.1165)	Arch Hard Loss 2.7656 (2.8354)	Arch Beta Loss 278.8619 (281.0538)	Arch depth Loss -0.0177 (-0.0159)	Prec@(1,5) (30.3%, 62.5%)	
11/26 10:53:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [7][195/195]	Step 1567	lr 0.02487	Loss 2.7760 (2.6830)	Arch Loss 2.9474 (3.0805)	Arch Hard Loss 2.6723 (2.8015)	Arch Beta Loss 275.0421 (279.0197)	Arch depth Loss -0.0206 (-0.0177)	Prec@(1,5) (30.8%, 63.0%)	
11/26 10:53:11午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  7/149] Final Prec@1 30.7640%
11/26 10:53:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/196]	Step 1568	Loss 2.8753	Prec@(1,5) (28.0%, 59.2%)
11/26 10:53:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][195/196]	Step 1568	Loss 2.8706	Prec@(1,5) (27.9%, 59.2%)
11/26 10:53:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 27.8800%
11/26 10:53:42午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 4)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 6])
11/26 10:53:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 27.8800%
11/26 10:55:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][100/195]	Step 1668	lr 0.02483	Loss 2.5044 (2.5795)	Arch Loss 2.9441 (3.0159)	Arch Hard Loss 2.6731 (2.7430)	Arch Beta Loss 271.0293 (272.9931)	Arch depth Loss -0.0238 (-0.0213)	Prec@(1,5) (32.6%, 64.8%)	
11/26 10:56:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [8][195/195]	Step 1763	lr 0.02483	Loss 2.2868 (2.5731)	Arch Loss 2.7589 (2.9991)	Arch Hard Loss 2.4916 (2.7280)	Arch Beta Loss 267.3133 (271.1079)	Arch depth Loss -0.0277 (-0.0239)	Prec@(1,5) (33.1%, 65.3%)	
11/26 10:56:55午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  8/149] Final Prec@1 33.0520%
11/26 10:57:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/196]	Step 1764	Loss 2.7091	Prec@(1,5) (30.8%, 62.7%)
11/26 10:57:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][195/196]	Step 1764	Loss 2.7088	Prec@(1,5) (30.6%, 62.7%)
11/26 10:57:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 30.6280%
11/26 10:57:26午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('max_pool_3x3', 9)]], DAG2_concat=[3, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 6])
11/26 10:57:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 30.6280%
11/26 10:59:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][100/195]	Step 1864	lr 0.02479	Loss 2.4907 (2.4561)	Arch Loss 2.9254 (2.9048)	Arch Hard Loss 2.6619 (2.6394)	Arch Beta Loss 263.5324 (265.3663)	Arch depth Loss -0.0297 (-0.0287)	Prec@(1,5) (35.5%, 68.6%)	
11/26 11:00:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [9][195/195]	Step 1959	lr 0.02479	Loss 2.1031 (2.4636)	Arch Loss 3.3112 (2.8967)	Arch Hard Loss 3.0512 (2.6331)	Arch Beta Loss 259.9990 (263.5915)	Arch depth Loss -0.0307 (-0.0297)	Prec@(1,5) (35.3%, 68.3%)	
11/26 11:00:40午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [  9/149] Final Prec@1 35.2520%
11/26 11:00:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/196]	Step 1960	Loss 2.6049	Prec@(1,5) (33.0%, 64.8%)
11/26 11:01:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][195/196]	Step 1960	Loss 2.6075	Prec@(1,5) (33.0%, 64.9%)
11/26 11:01:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 32.9880%
11/26 11:01:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 4])
11/26 11:01:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 32.9880%
11/26 11:02:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][100/195]	Step 2060	lr 0.02474	Loss 2.4393 (2.3677)	Arch Loss 2.7463 (2.8376)	Arch Hard Loss 2.4900 (2.5795)	Arch Beta Loss 256.2525 (258.0691)	Arch depth Loss -0.0342 (-0.0330)	Prec@(1,5) (37.7%, 70.0%)	
11/26 11:04:23午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [10][195/195]	Step 2155	lr 0.02474	Loss 2.2436 (2.3612)	Arch Loss 2.6384 (2.8147)	Arch Hard Loss 2.3855 (2.5583)	Arch Beta Loss 252.8929 (256.3387)	Arch depth Loss -0.0367 (-0.0342)	Prec@(1,5) (37.7%, 70.5%)	
11/26 11:04:23午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 10/149] Final Prec@1 37.7120%
11/26 11:04:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/196]	Step 2156	Loss 2.5395	Prec@(1,5) (34.0%, 66.8%)
11/26 11:04:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][195/196]	Step 2156	Loss 2.5412	Prec@(1,5) (34.1%, 66.6%)
11/26 11:04:54午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 34.0800%
11/26 11:04:54午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=[2, 4])
11/26 11:04:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 34.0800%
11/26 11:06:34午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][100/195]	Step 2256	lr 0.02468	Loss 2.2395 (2.2433)	Arch Loss 2.9100 (2.7791)	Arch Hard Loss 2.6605 (2.5279)	Arch Beta Loss 249.5248 (251.1543)	Arch depth Loss -0.0395 (-0.0386)	Prec@(1,5) (39.8%, 72.4%)	
11/26 11:08:07午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [11][195/195]	Step 2351	lr 0.02468	Loss 2.2197 (2.2750)	Arch Loss 2.8072 (2.7429)	Arch Hard Loss 2.5609 (2.4934)	Arch Beta Loss 246.2050 (249.5119)	Arch depth Loss -0.0399 (-0.0392)	Prec@(1,5) (39.0%, 72.0%)	
11/26 11:08:08午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 11/149] Final Prec@1 38.9720%
11/26 11:08:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/196]	Step 2352	Loss 2.4675	Prec@(1,5) (36.1%, 68.2%)
11/26 11:08:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][195/196]	Step 2352	Loss 2.4552	Prec@(1,5) (36.5%, 68.5%)
11/26 11:08:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 36.4800%
11/26 11:08:38午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:08:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.4800%
11/26 11:10:18午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][100/195]	Step 2452	lr 0.02462	Loss 1.9857 (2.1493)	Arch Loss 3.0774 (2.6871)	Arch Hard Loss 2.8345 (2.4426)	Arch Beta Loss 242.8819 (244.5023)	Arch depth Loss -0.0420 (-0.0408)	Prec@(1,5) (42.1%, 74.9%)	
11/26 11:11:51午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [12][195/195]	Step 2547	lr 0.02462	Loss 2.0821 (2.1802)	Arch Loss 2.6021 (2.6716)	Arch Hard Loss 2.3621 (2.4286)	Arch Beta Loss 240.0122 (242.9711)	Arch depth Loss -0.0436 (-0.0422)	Prec@(1,5) (41.1%, 74.3%)	
11/26 11:11:52午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 12/149] Final Prec@1 41.0280%
11/26 11:12:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/196]	Step 2548	Loss 2.4925	Prec@(1,5) (35.7%, 68.3%)
11/26 11:12:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][195/196]	Step 2548	Loss 2.4626	Prec@(1,5) (36.1%, 68.8%)
11/26 11:12:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 36.1320%
11/26 11:12:22午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:12:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.4800%
11/26 11:14:02午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][100/195]	Step 2648	lr 0.02456	Loss 1.9621 (2.0824)	Arch Loss 2.6502 (2.6041)	Arch Hard Loss 2.4134 (2.3657)	Arch Beta Loss 236.8136 (238.3459)	Arch depth Loss -0.0465 (-0.0449)	Prec@(1,5) (43.6%, 76.1%)	
11/26 11:15:35午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [13][195/195]	Step 2743	lr 0.02456	Loss 1.8863 (2.0971)	Arch Loss 2.6050 (2.6013)	Arch Hard Loss 2.3710 (2.3644)	Arch Beta Loss 233.9766 (236.9061)	Arch depth Loss -0.0467 (-0.0458)	Prec@(1,5) (43.6%, 75.8%)	
11/26 11:15:35午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 13/149] Final Prec@1 43.6120%
11/26 11:15:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/196]	Step 2744	Loss 2.4606	Prec@(1,5) (36.5%, 68.8%)
11/26 11:16:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][195/196]	Step 2744	Loss 2.4598	Prec@(1,5) (36.9%, 68.8%)
11/26 11:16:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 36.8400%
11/26 11:16:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:16:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.8400%
11/26 11:17:46午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][100/195]	Step 2844	lr 0.02449	Loss 2.1691 (2.0190)	Arch Loss 2.6718 (2.5577)	Arch Hard Loss 2.4406 (2.3252)	Arch Beta Loss 231.1242 (232.5024)	Arch depth Loss -0.0469 (-0.0467)	Prec@(1,5) (44.7%, 78.0%)	
11/26 11:19:19午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [14][195/195]	Step 2939	lr 0.02449	Loss 1.9509 (2.0178)	Arch Loss 2.8471 (2.5453)	Arch Hard Loss 2.6189 (2.3142)	Arch Beta Loss 228.1719 (231.0738)	Arch depth Loss -0.0492 (-0.0474)	Prec@(1,5) (44.9%, 77.7%)	
11/26 11:19:20午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 14/149] Final Prec@1 44.8800%
11/26 11:19:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/196]	Step 2940	Loss 2.3555	Prec@(1,5) (38.6%, 71.2%)
11/26 11:19:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][195/196]	Step 2940	Loss 2.3524	Prec@(1,5) (38.4%, 71.1%)
11/26 11:19:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 38.3600%
11/26 11:19:50午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:19:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 38.3600%
11/26 11:21:30午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][100/195]	Step 3040	lr 0.02441	Loss 1.9075 (1.9405)	Arch Loss 2.6709 (2.5313)	Arch Hard Loss 2.4458 (2.3047)	Arch Beta Loss 225.1613 (226.6168)	Arch depth Loss -0.0513 (-0.0505)	Prec@(1,5) (46.4%, 78.6%)	
11/26 11:23:03午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [15][195/195]	Step 3135	lr 0.02441	Loss 2.2009 (1.9505)	Arch Loss 2.5352 (2.5025)	Arch Hard Loss 2.3127 (2.2772)	Arch Beta Loss 222.5036 (225.2593)	Arch depth Loss -0.0492 (-0.0503)	Prec@(1,5) (46.1%, 78.7%)	
11/26 11:23:03午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 15/149] Final Prec@1 46.0560%
11/26 11:23:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/196]	Step 3136	Loss 2.3050	Prec@(1,5) (39.6%, 72.3%)
11/26 11:23:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][195/196]	Step 3136	Loss 2.3137	Prec@(1,5) (39.8%, 71.9%)
11/26 11:23:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 39.7760%
11/26 11:23:34午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:23:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.7760%
11/26 11:25:14午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][100/195]	Step 3236	lr 0.02433	Loss 2.0121 (1.8525)	Arch Loss 2.4756 (2.4686)	Arch Hard Loss 2.2559 (2.2475)	Arch Beta Loss 219.7559 (221.1325)	Arch depth Loss -0.0488 (-0.0493)	Prec@(1,5) (48.2%, 80.7%)	
11/26 11:26:47午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [16][195/195]	Step 3331	lr 0.02433	Loss 1.9473 (1.8833)	Arch Loss 2.1826 (2.4693)	Arch Hard Loss 1.9656 (2.2495)	Arch Beta Loss 217.0719 (219.7855)	Arch depth Loss -0.0480 (-0.0492)	Prec@(1,5) (47.8%, 80.0%)	
11/26 11:26:48午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 16/149] Final Prec@1 47.7920%
11/26 11:27:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/196]	Step 3332	Loss 2.2118	Prec@(1,5) (41.9%, 73.8%)
11/26 11:27:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][195/196]	Step 3332	Loss 2.2087	Prec@(1,5) (41.8%, 73.7%)
11/26 11:27:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 41.8240%
11/26 11:27:18午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:27:19午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.8240%
11/26 11:28:58午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][100/195]	Step 3432	lr 0.02425	Loss 1.7453 (1.8190)	Arch Loss 2.2263 (2.4211)	Arch Hard Loss 2.0119 (2.2055)	Arch Beta Loss 214.3818 (215.6259)	Arch depth Loss -0.0470 (-0.0474)	Prec@(1,5) (49.3%, 81.2%)	
11/26 11:30:31午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [17][195/195]	Step 3527	lr 0.02425	Loss 2.2178 (1.8287)	Arch Loss 2.2208 (2.4148)	Arch Hard Loss 2.0089 (2.2004)	Arch Beta Loss 211.8374 (214.3899)	Arch depth Loss -0.0465 (-0.0472)	Prec@(1,5) (49.1%, 80.9%)	
11/26 11:30:32午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 17/149] Final Prec@1 49.1200%
11/26 11:30:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/196]	Step 3528	Loss 2.2029	Prec@(1,5) (41.2%, 74.1%)
11/26 11:31:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][195/196]	Step 3528	Loss 2.1993	Prec@(1,5) (41.4%, 74.1%)
11/26 11:31:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 41.3880%
11/26 11:31:02午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
11/26 11:31:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.8240%
11/26 11:32:42午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][100/195]	Step 3628	lr 0.02416	Loss 1.5261 (1.7787)	Arch Loss 2.4297 (2.4062)	Arch Hard Loss 2.2205 (2.1957)	Arch Beta Loss 209.2763 (210.5752)	Arch depth Loss -0.0458 (-0.0464)	Prec@(1,5) (50.3%, 82.6%)	
11/26 11:34:16午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [18][195/195]	Step 3723	lr 0.02416	Loss 1.6064 (1.7758)	Arch Loss 2.2866 (2.3799)	Arch Hard Loss 2.0796 (2.1705)	Arch Beta Loss 206.9388 (209.3665)	Arch depth Loss -0.0432 (-0.0456)	Prec@(1,5) (50.3%, 82.3%)	
11/26 11:34:16午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 18/149] Final Prec@1 50.3040%
11/26 11:34:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/196]	Step 3724	Loss 2.1711	Prec@(1,5) (43.1%, 74.6%)
11/26 11:34:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][195/196]	Step 3724	Loss 2.1367	Prec@(1,5) (43.6%, 75.2%)
11/26 11:34:47午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 43.6280%
11/26 11:34:47午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:34:47午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.6280%
11/26 11:36:27午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][100/195]	Step 3824	lr 0.02406	Loss 1.8199 (1.6845)	Arch Loss 2.2793 (2.3565)	Arch Hard Loss 2.0750 (2.1509)	Arch Beta Loss 204.2959 (205.5983)	Arch depth Loss -0.0428 (-0.0429)	Prec@(1,5) (52.6%, 83.6%)	
11/26 11:38:00午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [19][195/195]	Step 3919	lr 0.02406	Loss 1.9830 (1.7155)	Arch Loss 2.1619 (2.3406)	Arch Hard Loss 1.9599 (2.1362)	Arch Beta Loss 201.9827 (204.4042)	Arch depth Loss -0.0402 (-0.0422)	Prec@(1,5) (51.9%, 83.1%)	
11/26 11:38:00午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 19/149] Final Prec@1 51.9280%
11/26 11:38:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/196]	Step 3920	Loss 2.1671	Prec@(1,5) (43.4%, 75.2%)
11/26 11:38:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][195/196]	Step 3920	Loss 2.1841	Prec@(1,5) (43.1%, 74.9%)
11/26 11:38:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 43.1080%
11/26 11:38:31午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:38:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.6280%
11/26 11:40:10午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][100/195]	Step 4020	lr 0.02396	Loss 1.7419 (1.6255)	Arch Loss 2.2020 (2.3147)	Arch Hard Loss 2.0022 (2.1138)	Arch Beta Loss 199.8032 (200.8299)	Arch depth Loss -0.0358 (-0.0381)	Prec@(1,5) (54.3%, 84.7%)	
11/26 11:41:44午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [20][195/195]	Step 4115	lr 0.02396	Loss 2.0619 (1.6800)	Arch Loss 2.2531 (2.3037)	Arch Hard Loss 2.0556 (2.1040)	Arch Beta Loss 197.5506 (199.7550)	Arch depth Loss -0.0339 (-0.0366)	Prec@(1,5) (52.5%, 83.6%)	
11/26 11:41:44午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 20/149] Final Prec@1 52.5120%
11/26 11:42:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/196]	Step 4116	Loss 2.1416	Prec@(1,5) (43.0%, 75.5%)
11/26 11:42:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][195/196]	Step 4116	Loss 2.1493	Prec@(1,5) (42.9%, 75.2%)
11/26 11:42:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 42.9200%
11/26 11:42:15午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:42:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.6280%
11/26 11:43:54午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][100/195]	Step 4216	lr 0.02386	Loss 1.7231 (1.6012)	Arch Loss 1.9604 (2.2571)	Arch Hard Loss 1.7652 (2.0607)	Arch Beta Loss 195.2358 (196.3453)	Arch depth Loss -0.0291 (-0.0324)	Prec@(1,5) (54.3%, 84.9%)	
11/26 11:45:28午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [21][195/195]	Step 4311	lr 0.02386	Loss 1.6339 (1.6189)	Arch Loss 2.2919 (2.2711)	Arch Hard Loss 2.0988 (2.0758)	Arch Beta Loss 193.0737 (195.2601)	Arch depth Loss -0.0253 (-0.0301)	Prec@(1,5) (53.9%, 84.6%)	
11/26 11:45:28午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 21/149] Final Prec@1 53.9200%
11/26 11:45:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/196]	Step 4312	Loss 2.0854	Prec@(1,5) (44.8%, 76.8%)
11/26 11:45:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][195/196]	Step 4312	Loss 2.0908	Prec@(1,5) (44.8%, 76.5%)
11/26 11:45:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 44.7840%
11/26 11:45:59午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:45:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.7840%
11/26 11:47:38午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][100/195]	Step 4412	lr 0.02375	Loss 1.3638 (1.5432)	Arch Loss 2.3338 (2.2414)	Arch Hard Loss 2.1431 (2.0495)	Arch Beta Loss 190.7573 (191.9106)	Arch depth Loss -0.0233 (-0.0243)	Prec@(1,5) (55.8%, 86.0%)	
11/26 11:49:11午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [22][195/195]	Step 4507	lr 0.02375	Loss 1.7356 (1.5663)	Arch Loss 2.3146 (2.2401)	Arch Hard Loss 2.1258 (2.0493)	Arch Beta Loss 188.8086 (190.8572)	Arch depth Loss -0.0189 (-0.0226)	Prec@(1,5) (55.4%, 85.5%)	
11/26 11:49:12午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 22/149] Final Prec@1 55.4120%
11/26 11:49:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/196]	Step 4508	Loss 2.0625	Prec@(1,5) (45.7%, 76.9%)
11/26 11:49:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][195/196]	Step 4508	Loss 2.0599	Prec@(1,5) (45.7%, 77.0%)
11/26 11:49:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 45.7040%
11/26 11:49:42午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:49:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.7040%
11/26 11:51:22午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][100/195]	Step 4608	lr 0.02363	Loss 1.4758 (1.4760)	Arch Loss 2.0815 (2.2272)	Arch Hard Loss 1.8948 (2.0394)	Arch Beta Loss 186.7198 (187.7915)	Arch depth Loss -0.0147 (-0.0158)	Prec@(1,5) (57.7%, 87.0%)	
11/26 11:52:55午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [23][195/195]	Step 4703	lr 0.02363	Loss 1.5849 (1.5289)	Arch Loss 2.0711 (2.2243)	Arch Hard Loss 1.8864 (2.0375)	Arch Beta Loss 184.6693 (186.7595)	Arch depth Loss -0.0113 (-0.0148)	Prec@(1,5) (56.6%, 86.1%)	
11/26 11:52:55午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 23/149] Final Prec@1 56.5560%
11/26 11:53:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/196]	Step 4704	Loss 2.0830	Prec@(1,5) (45.8%, 76.3%)
11/26 11:53:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][195/196]	Step 4704	Loss 2.0814	Prec@(1,5) (45.4%, 76.5%)
11/26 11:53:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 45.3880%
11/26 11:53:26午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:53:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.7040%
11/26 11:55:06午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][100/195]	Step 4804	lr 0.02352	Loss 1.6667 (1.4715)	Arch Loss 2.1779 (2.1979)	Arch Hard Loss 1.9952 (2.0142)	Arch Beta Loss 182.6683 (183.6642)	Arch depth Loss -0.0071 (-0.0095)	Prec@(1,5) (57.6%, 87.4%)	
11/26 11:56:39午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [24][195/195]	Step 4899	lr 0.02352	Loss 1.5683 (1.4900)	Arch Loss 2.2408 (2.1907)	Arch Hard Loss 2.0600 (2.0080)	Arch Beta Loss 180.8004 (182.7108)	Arch depth Loss -0.0007 (-0.0067)	Prec@(1,5) (57.3%, 87.0%)	
11/26 11:56:40午前 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 24/149] Final Prec@1 57.3000%
11/26 11:56:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/196]	Step 4900	Loss 2.0712	Prec@(1,5) (45.2%, 76.5%)
11/26 11:57:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][195/196]	Step 4900	Loss 2.0707	Prec@(1,5) (45.1%, 76.7%)
11/26 11:57:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 45.1200%
11/26 11:57:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 11:57:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.7040%
11/26 11:58:50午前 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][100/195]	Step 5000	lr 0.02339	Loss 1.5106 (1.4398)	Arch Loss 2.0677 (2.1884)	Arch Hard Loss 1.8889 (2.0087)	Arch Beta Loss 178.7508 (179.6970)	Arch depth Loss 0.0036 (0.0017)	Prec@(1,5) (58.6%, 87.4%)	
11/26 12:00:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [25][195/195]	Step 5095	lr 0.02339	Loss 1.4980 (1.4535)	Arch Loss 2.0621 (2.1816)	Arch Hard Loss 1.8851 (2.0029)	Arch Beta Loss 176.9339 (178.7791)	Arch depth Loss 0.0101 (0.0042)	Prec@(1,5) (58.1%, 87.3%)	
11/26 12:00:24午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 25/149] Final Prec@1 58.1280%
11/26 12:00:40午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/196]	Step 5096	Loss 2.0493	Prec@(1,5) (46.2%, 77.2%)
11/26 12:00:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][195/196]	Step 5096	Loss 2.0685	Prec@(1,5) (46.0%, 76.8%)
11/26 12:00:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 46.0360%
11/26 12:00:54午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 12:00:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.0360%
11/26 12:02:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][100/195]	Step 5196	lr 0.02326	Loss 1.4724 (1.3811)	Arch Loss 2.0429 (2.1736)	Arch Hard Loss 1.8679 (1.9976)	Arch Beta Loss 175.0323 (175.9852)	Arch depth Loss 0.0162 (0.0141)	Prec@(1,5) (60.3%, 88.4%)	
11/26 12:04:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [26][195/195]	Step 5291	lr 0.02326	Loss 1.5468 (1.4053)	Arch Loss 2.0440 (2.1537)	Arch Hard Loss 1.8707 (1.9786)	Arch Beta Loss 173.3231 (175.1066)	Arch depth Loss 0.0245 (0.0174)	Prec@(1,5) (59.4%, 88.2%)	
11/26 12:04:08午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 26/149] Final Prec@1 59.4080%
11/26 12:04:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/196]	Step 5292	Loss 2.0209	Prec@(1,5) (46.7%, 77.9%)
11/26 12:04:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][195/196]	Step 5292	Loss 2.0153	Prec@(1,5) (46.5%, 78.1%)
11/26 12:04:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 46.4240%
11/26 12:04:38午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('skip_connect', 9)]], DAG1_concat=[3, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:04:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.4240%
11/26 12:06:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][100/195]	Step 5392	lr 0.02313	Loss 1.4104 (1.3351)	Arch Loss 1.9028 (2.1849)	Arch Hard Loss 1.7314 (2.0126)	Arch Beta Loss 171.3365 (172.2878)	Arch depth Loss 0.0316 (0.0279)	Prec@(1,5) (61.5%, 89.0%)	
11/26 12:07:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [27][195/195]	Step 5487	lr 0.02313	Loss 1.1642 (1.3791)	Arch Loss 2.0263 (2.1549)	Arch Hard Loss 1.8567 (1.9835)	Arch Beta Loss 169.5980 (171.4105)	Arch depth Loss 0.0391 (0.0314)	Prec@(1,5) (60.4%, 88.5%)	
11/26 12:07:52午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 27/149] Final Prec@1 60.4520%
11/26 12:08:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/196]	Step 5488	Loss 2.0649	Prec@(1,5) (46.6%, 76.6%)
11/26 12:08:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][195/196]	Step 5488	Loss 2.0532	Prec@(1,5) (46.6%, 77.3%)
11/26 12:08:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 46.5800%
11/26 12:08:22午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:08:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.5800%
11/26 12:10:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][100/195]	Step 5588	lr 0.023	Loss 1.4141 (1.3075)	Arch Loss 1.9395 (2.1227)	Arch Hard Loss 1.7717 (1.9540)	Arch Beta Loss 167.7908 (168.7116)	Arch depth Loss 0.0452 (0.0424)	Prec@(1,5) (61.3%, 89.8%)	
11/26 12:11:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [28][195/195]	Step 5683	lr 0.023	Loss 1.2665 (1.3382)	Arch Loss 1.8566 (2.1338)	Arch Hard Loss 1.6906 (1.9660)	Arch Beta Loss 166.0798 (167.8197)	Arch depth Loss 0.0540 (0.0460)	Prec@(1,5) (60.7%, 89.2%)	
11/26 12:11:36午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 28/149] Final Prec@1 60.6440%
11/26 12:11:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/196]	Step 5684	Loss 1.9479	Prec@(1,5) (48.5%, 79.1%)
11/26 12:12:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][195/196]	Step 5684	Loss 1.9444	Prec@(1,5) (48.7%, 78.9%)
11/26 12:12:07午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 48.6760%
11/26 12:12:07午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:12:07午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6760%
11/26 12:13:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][100/195]	Step 5784	lr 0.02285	Loss 1.2583 (1.2683)	Arch Loss 2.0949 (2.1030)	Arch Hard Loss 1.9305 (1.9378)	Arch Beta Loss 164.3817 (165.1804)	Arch depth Loss 0.0613 (0.0568)	Prec@(1,5) (62.7%, 90.6%)	
11/26 12:15:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [29][195/195]	Step 5879	lr 0.02285	Loss 1.3369 (1.3054)	Arch Loss 1.9575 (2.1115)	Arch Hard Loss 1.7948 (1.9471)	Arch Beta Loss 162.7101 (164.3904)	Arch depth Loss 0.0690 (0.0610)	Prec@(1,5) (61.8%, 89.9%)	
11/26 12:15:21午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 29/149] Final Prec@1 61.7800%
11/26 12:15:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/196]	Step 5880	Loss 1.9790	Prec@(1,5) (48.2%, 78.9%)
11/26 12:15:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][195/196]	Step 5880	Loss 1.9770	Prec@(1,5) (48.3%, 78.8%)
11/26 12:15:51午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 48.2960%
11/26 12:15:51午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:15:51午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6760%
11/26 12:17:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][100/195]	Step 5980	lr 0.02271	Loss 1.2021 (1.2454)	Arch Loss 2.0957 (2.1208)	Arch Hard Loss 1.9348 (1.9589)	Arch Beta Loss 160.9346 (161.8512)	Arch depth Loss 0.0788 (0.0741)	Prec@(1,5) (64.1%, 90.3%)	
11/26 12:19:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [30][195/195]	Step 6075	lr 0.02271	Loss 1.4285 (1.2741)	Arch Loss 1.9443 (2.0978)	Arch Hard Loss 1.7849 (1.9368)	Arch Beta Loss 159.4326 (161.0006)	Arch depth Loss 0.0861 (0.0779)	Prec@(1,5) (63.2%, 90.0%)	
11/26 12:19:05午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 30/149] Final Prec@1 63.2320%
11/26 12:19:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/196]	Step 6076	Loss 2.0653	Prec@(1,5) (46.9%, 77.8%)
11/26 12:19:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][195/196]	Step 6076	Loss 2.0605	Prec@(1,5) (46.9%, 77.6%)
11/26 12:19:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 46.8880%
11/26 12:19:36午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:19:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6760%
11/26 12:21:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][100/195]	Step 6176	lr 0.02256	Loss 1.1795 (1.2093)	Arch Loss 1.8393 (2.0804)	Arch Hard Loss 1.6816 (1.9218)	Arch Beta Loss 157.7041 (158.5519)	Arch depth Loss 0.0979 (0.0921)	Prec@(1,5) (64.5%, 90.9%)	
11/26 12:22:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [31][195/195]	Step 6271	lr 0.02256	Loss 1.1136 (1.2520)	Arch Loss 2.0068 (2.0964)	Arch Hard Loss 1.8506 (1.9386)	Arch Beta Loss 156.2421 (157.7943)	Arch depth Loss 0.1060 (0.0970)	Prec@(1,5) (63.7%, 90.1%)	
11/26 12:22:49午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 31/149] Final Prec@1 63.7160%
11/26 12:23:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/196]	Step 6272	Loss 1.9945	Prec@(1,5) (47.8%, 78.4%)
11/26 12:23:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][195/196]	Step 6272	Loss 1.9975	Prec@(1,5) (48.1%, 78.4%)
11/26 12:23:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 48.0640%
11/26 12:23:20午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:23:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.6760%
11/26 12:25:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][100/195]	Step 6372	lr 0.0224	Loss 1.3263 (1.1977)	Arch Loss 2.2270 (2.0898)	Arch Hard Loss 2.0723 (1.9344)	Arch Beta Loss 154.6515 (155.4401)	Arch depth Loss 0.1197 (0.1139)	Prec@(1,5) (64.7%, 91.5%)	
11/26 12:26:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [32][195/195]	Step 6467	lr 0.0224	Loss 1.4610 (1.2167)	Arch Loss 1.7726 (2.0819)	Arch Hard Loss 1.6194 (1.9272)	Arch Beta Loss 153.2463 (154.7138)	Arch depth Loss 0.1284 (0.1190)	Prec@(1,5) (64.7%, 91.0%)	
11/26 12:26:34午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 32/149] Final Prec@1 64.6640%
11/26 12:26:50午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/196]	Step 6468	Loss 1.9316	Prec@(1,5) (49.8%, 79.8%)
11/26 12:27:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][195/196]	Step 6468	Loss 1.9371	Prec@(1,5) (49.7%, 79.6%)
11/26 12:27:05午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 49.6600%
11/26 12:27:05午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:27:05午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.6600%
11/26 12:28:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][100/195]	Step 6568	lr 0.02225	Loss 1.2127 (1.1610)	Arch Loss 1.9834 (2.0698)	Arch Hard Loss 1.8316 (1.9172)	Arch Beta Loss 151.7855 (152.5689)	Arch depth Loss 0.1381 (0.1330)	Prec@(1,5) (65.5%, 91.9%)	
11/26 12:30:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [33][195/195]	Step 6663	lr 0.02225	Loss 1.2674 (1.1854)	Arch Loss 2.1075 (2.0693)	Arch Hard Loss 1.9571 (1.9175)	Arch Beta Loss 150.3320 (151.8124)	Arch depth Loss 0.1490 (0.1380)	Prec@(1,5) (65.1%, 91.3%)	
11/26 12:30:19午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 33/149] Final Prec@1 65.1440%
11/26 12:30:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/196]	Step 6664	Loss 1.9510	Prec@(1,5) (49.0%, 79.3%)
11/26 12:30:50午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][195/196]	Step 6664	Loss 1.9600	Prec@(1,5) (48.8%, 79.2%)
11/26 12:30:50午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 48.7800%
11/26 12:30:50午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 10), ('avg_pool_3x3', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:30:50午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.6600%
11/26 12:32:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][100/195]	Step 6764	lr 0.02208	Loss 1.0984 (1.1435)	Arch Loss 2.2123 (2.0532)	Arch Hard Loss 2.0634 (1.9036)	Arch Beta Loss 148.8960 (149.5786)	Arch depth Loss 0.1559 (0.1521)	Prec@(1,5) (66.7%, 92.0%)	
11/26 12:34:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [34][195/195]	Step 6859	lr 0.02208	Loss 1.1819 (1.1647)	Arch Loss 2.0244 (2.0489)	Arch Hard Loss 1.8767 (1.8999)	Arch Beta Loss 147.6505 (148.9379)	Arch depth Loss 0.1646 (0.1563)	Prec@(1,5) (65.7%, 91.8%)	
11/26 12:34:03午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 34/149] Final Prec@1 65.7520%
11/26 12:34:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/196]	Step 6860	Loss 1.9692	Prec@(1,5) (48.2%, 79.1%)
11/26 12:34:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][195/196]	Step 6860	Loss 1.9581	Prec@(1,5) (48.6%, 79.3%)
11/26 12:34:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 48.5600%
11/26 12:34:34午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:34:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.6600%
11/26 12:36:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][100/195]	Step 6960	lr 0.02192	Loss 1.2209 (1.1117)	Arch Loss 2.1531 (2.0765)	Arch Hard Loss 2.0069 (1.9295)	Arch Beta Loss 146.2196 (146.9432)	Arch depth Loss 0.1777 (0.1714)	Prec@(1,5) (67.2%, 92.2%)	
11/26 12:37:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [35][195/195]	Step 7055	lr 0.02192	Loss 1.1835 (1.1414)	Arch Loss 2.1434 (2.0562)	Arch Hard Loss 1.9983 (1.9099)	Arch Beta Loss 145.0236 (146.2877)	Arch depth Loss 0.1889 (0.1770)	Prec@(1,5) (66.5%, 91.8%)	
11/26 12:37:48午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 35/149] Final Prec@1 66.4440%
11/26 12:38:04午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/196]	Step 7056	Loss 1.9814	Prec@(1,5) (48.5%, 79.2%)
11/26 12:38:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][195/196]	Step 7056	Loss 1.9824	Prec@(1,5) (48.7%, 79.1%)
11/26 12:38:18午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 48.6840%
11/26 12:38:18午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:38:19午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.6600%
11/26 12:39:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][100/195]	Step 7156	lr 0.02175	Loss 1.2459 (1.0912)	Arch Loss 1.6578 (2.0574)	Arch Hard Loss 1.5140 (1.9130)	Arch Beta Loss 143.7553 (144.4352)	Arch depth Loss 0.2008 (0.1948)	Prec@(1,5) (67.9%, 92.6%)	
11/26 12:41:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [36][195/195]	Step 7251	lr 0.02175	Loss 1.1712 (1.1126)	Arch Loss 1.9009 (2.0453)	Arch Hard Loss 1.7584 (1.9015)	Arch Beta Loss 142.5378 (143.8115)	Arch depth Loss 0.2092 (0.1996)	Prec@(1,5) (67.2%, 92.3%)	
11/26 12:41:32午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 36/149] Final Prec@1 67.1760%
11/26 12:41:48午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/196]	Step 7252	Loss 1.9257	Prec@(1,5) (49.7%, 79.9%)
11/26 12:42:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][195/196]	Step 7252	Loss 1.9200	Prec@(1,5) (49.9%, 79.7%)
11/26 12:42:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 49.9280%
11/26 12:42:02午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:42:03午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.9280%
11/26 12:43:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][100/195]	Step 7352	lr 0.02157	Loss 1.0314 (1.0623)	Arch Loss 2.3348 (2.0382)	Arch Hard Loss 2.1935 (1.8963)	Arch Beta Loss 141.2623 (141.8802)	Arch depth Loss 0.2186 (0.2151)	Prec@(1,5) (68.4%, 93.3%)	
11/26 12:45:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [37][195/195]	Step 7447	lr 0.02157	Loss 1.2206 (1.0976)	Arch Loss 1.8054 (2.0403)	Arch Hard Loss 1.6652 (1.8989)	Arch Beta Loss 140.2355 (141.3451)	Arch depth Loss 0.2311 (0.2197)	Prec@(1,5) (67.5%, 92.6%)	
11/26 12:45:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 37/149] Final Prec@1 67.5000%
11/26 12:45:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/196]	Step 7448	Loss 1.9289	Prec@(1,5) (49.7%, 79.9%)
11/26 12:45:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][195/196]	Step 7448	Loss 1.9108	Prec@(1,5) (50.1%, 80.2%)
11/26 12:45:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 50.1080%
11/26 12:45:47午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=[2, 3])
11/26 12:45:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1080%
11/26 12:47:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][100/195]	Step 7548	lr 0.0214	Loss 0.9024 (1.0412)	Arch Loss 1.9454 (2.0159)	Arch Hard Loss 1.8063 (1.8763)	Arch Beta Loss 139.1340 (139.6793)	Arch depth Loss 0.2428 (0.2372)	Prec@(1,5) (68.8%, 93.7%)	
11/26 12:49:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [38][195/195]	Step 7643	lr 0.0214	Loss 1.1228 (1.0707)	Arch Loss 2.1276 (2.0129)	Arch Hard Loss 1.9895 (1.8737)	Arch Beta Loss 138.0693 (139.1421)	Arch depth Loss 0.2517 (0.2423)	Prec@(1,5) (68.2%, 93.1%)	
11/26 12:49:02午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 38/149] Final Prec@1 68.1840%
11/26 12:49:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/196]	Step 7644	Loss 1.9368	Prec@(1,5) (50.4%, 80.0%)
11/26 12:49:32午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][195/196]	Step 7644	Loss 1.9249	Prec@(1,5) (50.1%, 80.1%)
11/26 12:49:32午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 50.1280%
11/26 12:49:32午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 12:49:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1280%
11/26 12:51:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][100/195]	Step 7744	lr 0.02121	Loss 1.0540 (1.0132)	Arch Loss 1.9530 (2.0169)	Arch Hard Loss 1.8161 (1.8794)	Arch Beta Loss 136.9494 (137.4718)	Arch depth Loss 0.2644 (0.2581)	Prec@(1,5) (70.0%, 93.5%)	
11/26 12:52:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [39][195/195]	Step 7839	lr 0.02121	Loss 1.1915 (1.0453)	Arch Loss 1.6701 (2.0228)	Arch Hard Loss 1.5342 (1.8858)	Arch Beta Loss 135.8684 (136.9380)	Arch depth Loss 0.2752 (0.2634)	Prec@(1,5) (69.0%, 93.2%)	
11/26 12:52:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 39/149] Final Prec@1 68.9880%
11/26 12:53:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/196]	Step 7840	Loss 2.0412	Prec@(1,5) (48.4%, 78.4%)
11/26 12:53:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][195/196]	Step 7840	Loss 2.0340	Prec@(1,5) (48.6%, 78.7%)
11/26 12:53:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 48.5800%
11/26 12:53:17午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 12:53:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1280%
11/26 12:54:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][100/195]	Step 7940	lr 0.02103	Loss 1.0716 (0.9916)	Arch Loss 2.0880 (2.0106)	Arch Hard Loss 1.9533 (1.8754)	Arch Beta Loss 134.7181 (135.2190)	Arch depth Loss 0.2860 (0.2822)	Prec@(1,5) (70.4%, 94.2%)	
11/26 12:56:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [40][195/195]	Step 8035	lr 0.02103	Loss 1.0808 (1.0237)	Arch Loss 1.9486 (2.0143)	Arch Hard Loss 1.8150 (1.8796)	Arch Beta Loss 133.6772 (134.7082)	Arch depth Loss 0.2945 (0.2858)	Prec@(1,5) (69.7%, 93.6%)	
11/26 12:56:30午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 40/149] Final Prec@1 69.6880%
11/26 12:56:46午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/196]	Step 8036	Loss 1.9446	Prec@(1,5) (49.9%, 79.9%)
11/26 12:57:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][195/196]	Step 8036	Loss 1.9506	Prec@(1,5) (49.8%, 79.9%)
11/26 12:57:01午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 49.7800%
11/26 12:57:01午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 12:57:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1280%
11/26 12:58:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][100/195]	Step 8136	lr 0.02084	Loss 1.0863 (0.9804)	Arch Loss 2.0952 (2.0076)	Arch Hard Loss 1.9626 (1.8745)	Arch Beta Loss 132.6177 (133.1266)	Arch depth Loss 0.3023 (0.2981)	Prec@(1,5) (71.1%, 94.1%)	
11/26 01:00:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [41][195/195]	Step 8231	lr 0.02084	Loss 0.9487 (1.0038)	Arch Loss 2.0318 (1.9993)	Arch Hard Loss 1.9002 (1.8666)	Arch Beta Loss 131.6096 (132.6217)	Arch depth Loss 0.3150 (0.3030)	Prec@(1,5) (70.4%, 93.8%)	
11/26 01:00:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 41/149] Final Prec@1 70.3920%
11/26 01:00:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/196]	Step 8232	Loss 2.0008	Prec@(1,5) (47.6%, 79.2%)
11/26 01:00:46午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][195/196]	Step 8232	Loss 2.0125	Prec@(1,5) (47.8%, 79.0%)
11/26 01:00:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 47.8120%
11/26 01:00:46午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:00:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1280%
11/26 01:02:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][100/195]	Step 8332	lr 0.02065	Loss 1.0439 (0.9590)	Arch Loss 1.8691 (1.9767)	Arch Hard Loss 1.7385 (1.8456)	Arch Beta Loss 130.6233 (131.0966)	Arch depth Loss 0.3262 (0.3202)	Prec@(1,5) (71.2%, 94.6%)	
11/26 01:04:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [42][195/195]	Step 8427	lr 0.02065	Loss 1.1389 (0.9954)	Arch Loss 2.4070 (2.0033)	Arch Hard Loss 2.2775 (1.8727)	Arch Beta Loss 129.5666 (130.6081)	Arch depth Loss 0.3369 (0.3257)	Prec@(1,5) (70.4%, 94.0%)	
11/26 01:04:04午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 42/149] Final Prec@1 70.3720%
11/26 01:04:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/196]	Step 8428	Loss 1.9159	Prec@(1,5) (50.2%, 80.4%)
11/26 01:04:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][195/196]	Step 8428	Loss 1.9232	Prec@(1,5) (50.1%, 80.3%)
11/26 01:04:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 50.0680%
11/26 01:04:35午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:04:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1280%
11/26 01:06:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][100/195]	Step 8528	lr 0.02045	Loss 1.0408 (0.9397)	Arch Loss 2.0590 (2.0023)	Arch Hard Loss 1.9305 (1.8733)	Arch Beta Loss 128.4990 (129.0299)	Arch depth Loss 0.3488 (0.3434)	Prec@(1,5) (72.1%, 94.8%)	
11/26 01:07:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [43][195/195]	Step 8623	lr 0.02045	Loss 1.0676 (0.9662)	Arch Loss 2.4044 (1.9928)	Arch Hard Loss 2.2767 (1.8642)	Arch Beta Loss 127.6787 (128.5671)	Arch depth Loss 0.3557 (0.3475)	Prec@(1,5) (71.0%, 94.5%)	
11/26 01:07:52午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 43/149] Final Prec@1 71.0440%
11/26 01:08:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/196]	Step 8624	Loss 1.8975	Prec@(1,5) (50.8%, 80.4%)
11/26 01:08:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][195/196]	Step 8624	Loss 1.8874	Prec@(1,5) (50.9%, 80.7%)
11/26 01:08:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 50.8880%
11/26 01:08:23午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:08:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.8880%
11/26 01:10:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][100/195]	Step 8724	lr 0.02026	Loss 0.8970 (0.9231)	Arch Loss 2.4040 (1.9728)	Arch Hard Loss 2.2773 (1.8456)	Arch Beta Loss 126.7413 (127.2115)	Arch depth Loss 0.3619 (0.3584)	Prec@(1,5) (72.6%, 95.1%)	
11/26 01:11:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [44][195/195]	Step 8819	lr 0.02026	Loss 0.8762 (0.9438)	Arch Loss 1.9996 (1.9819)	Arch Hard Loss 1.8737 (1.8551)	Arch Beta Loss 125.8906 (126.7880)	Arch depth Loss 0.3771 (0.3641)	Prec@(1,5) (72.0%, 94.7%)	
11/26 01:11:41午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 44/149] Final Prec@1 71.9600%
11/26 01:11:57午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/196]	Step 8820	Loss 1.8696	Prec@(1,5) (51.5%, 81.0%)
11/26 01:12:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][195/196]	Step 8820	Loss 1.8682	Prec@(1,5) (51.5%, 81.2%)
11/26 01:12:12午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 51.5520%
11/26 01:12:12午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:12:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:13:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][100/195]	Step 8920	lr 0.02005	Loss 0.7590 (0.8733)	Arch Loss 2.0415 (1.9694)	Arch Hard Loss 1.9166 (1.8440)	Arch Beta Loss 124.9375 (125.3754)	Arch depth Loss 0.3847 (0.3814)	Prec@(1,5) (73.9%, 95.4%)	
11/26 01:15:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [45][195/195]	Step 9015	lr 0.02005	Loss 1.1565 (0.9135)	Arch Loss 1.7275 (1.9782)	Arch Hard Loss 1.6035 (1.8533)	Arch Beta Loss 123.9748 (124.9247)	Arch depth Loss 0.3957 (0.3862)	Prec@(1,5) (72.8%, 94.8%)	
11/26 01:15:27午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 45/149] Final Prec@1 72.8120%
11/26 01:15:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/196]	Step 9016	Loss 1.9122	Prec@(1,5) (50.8%, 80.6%)
11/26 01:15:57午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][195/196]	Step 9016	Loss 1.9208	Prec@(1,5) (50.5%, 80.6%)
11/26 01:15:57午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 50.5400%
11/26 01:15:57午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:15:58午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:17:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][100/195]	Step 9116	lr 0.01985	Loss 0.9634 (0.8879)	Arch Loss 2.0750 (2.0108)	Arch Hard Loss 1.9518 (1.8872)	Arch Beta Loss 123.1751 (123.5997)	Arch depth Loss 0.4087 (0.4017)	Prec@(1,5) (73.6%, 95.1%)	
11/26 01:19:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [46][195/195]	Step 9211	lr 0.01985	Loss 1.1543 (0.9127)	Arch Loss 1.9212 (1.9894)	Arch Hard Loss 1.7988 (1.8662)	Arch Beta Loss 122.4428 (123.2135)	Arch depth Loss 0.4184 (0.4078)	Prec@(1,5) (73.0%, 94.8%)	
11/26 01:19:15午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 46/149] Final Prec@1 72.9800%
11/26 01:19:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/196]	Step 9212	Loss 1.8876	Prec@(1,5) (51.7%, 80.7%)
11/26 01:19:46午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][195/196]	Step 9212	Loss 1.8985	Prec@(1,5) (51.2%, 80.6%)
11/26 01:19:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 51.1720%
11/26 01:19:46午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('skip_connect', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 10), ('skip_connect', 9)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:19:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:21:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][100/195]	Step 9312	lr 0.01964	Loss 1.0183 (0.8640)	Arch Loss 1.7119 (1.9770)	Arch Hard Loss 1.5903 (1.8549)	Arch Beta Loss 121.5994 (122.0226)	Arch depth Loss 0.4314 (0.4258)	Prec@(1,5) (74.5%, 95.3%)	
11/26 01:23:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [47][195/195]	Step 9407	lr 0.01964	Loss 1.0183 (0.9006)	Arch Loss 1.9831 (1.9885)	Arch Hard Loss 1.8624 (1.8669)	Arch Beta Loss 120.7185 (121.5923)	Arch depth Loss 0.4399 (0.4309)	Prec@(1,5) (73.2%, 94.8%)	
11/26 01:23:04午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 47/149] Final Prec@1 73.2280%
11/26 01:23:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/196]	Step 9408	Loss 1.8944	Prec@(1,5) (51.2%, 80.6%)
11/26 01:23:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][195/196]	Step 9408	Loss 1.9118	Prec@(1,5) (50.8%, 80.7%)
11/26 01:23:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 50.8040%
11/26 01:23:34午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:23:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:25:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][100/195]	Step 9508	lr 0.01943	Loss 0.7503 (0.8549)	Arch Loss 1.7655 (1.9725)	Arch Hard Loss 1.6456 (1.8521)	Arch Beta Loss 119.9507 (120.3482)	Arch depth Loss 0.4514 (0.4453)	Prec@(1,5) (74.5%, 95.7%)	
11/26 01:26:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [48][195/195]	Step 9603	lr 0.01943	Loss 0.9144 (0.8826)	Arch Loss 1.8199 (1.9834)	Arch Hard Loss 1.7006 (1.8634)	Arch Beta Loss 119.2802 (119.9808)	Arch depth Loss 0.4606 (0.4503)	Prec@(1,5) (73.6%, 95.3%)	
11/26 01:26:52午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 48/149] Final Prec@1 73.5480%
11/26 01:27:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/196]	Step 9604	Loss 1.9060	Prec@(1,5) (50.7%, 80.9%)
11/26 01:27:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][195/196]	Step 9604	Loss 1.9056	Prec@(1,5) (50.8%, 80.7%)
11/26 01:27:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 50.7800%
11/26 01:27:22午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:27:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:29:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][100/195]	Step 9704	lr 0.01922	Loss 0.8571 (0.8578)	Arch Loss 2.0089 (1.9854)	Arch Hard Loss 1.8904 (1.8666)	Arch Beta Loss 118.4914 (118.8870)	Arch depth Loss 0.4692 (0.4642)	Prec@(1,5) (74.2%, 95.6%)	
11/26 01:30:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [49][195/195]	Step 9799	lr 0.01922	Loss 0.8068 (0.8735)	Arch Loss 1.9828 (1.9820)	Arch Hard Loss 1.8650 (1.8634)	Arch Beta Loss 117.8089 (118.5197)	Arch depth Loss 0.4793 (0.4686)	Prec@(1,5) (74.0%, 95.3%)	
11/26 01:30:40午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 49/149] Final Prec@1 73.9320%
11/26 01:30:56午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/196]	Step 9800	Loss 1.9190	Prec@(1,5) (50.6%, 80.5%)
11/26 01:31:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][195/196]	Step 9800	Loss 1.9124	Prec@(1,5) (50.7%, 80.7%)
11/26 01:31:11午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 50.6800%
11/26 01:31:11午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
11/26 01:31:11午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:31:12午後 searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
11/26 01:31:12午後 searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 1., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
11/26 01:31:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][100/351]	Step 9900	lr 0.025	Loss 2.4242 (2.8552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (28.4%, 60.7%)	
11/26 01:32:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][200/351]	Step 10000	lr 0.025	Loss 2.0559 (2.5582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (34.2%, 66.9%)	
11/26 01:33:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][300/351]	Step 10100	lr 0.025	Loss 2.3728 (2.4228)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.7%, 69.6%)	
11/26 01:33:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [50][351/351]	Step 10151	lr 0.025	Loss 2.0634 (2.3742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.7%, 70.6%)	
11/26 01:33:37午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 50/149] Final Prec@1 37.7511%
11/26 01:33:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][39/40]	Step 10152	Loss 2.3783	Prec@(1,5) (37.8%, 70.7%)
11/26 01:33:43午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 37.7400%
11/26 01:33:43午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:34:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][100/351]	Step 10252	lr 0.02499	Loss 1.9281 (1.9729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.3%, 78.4%)	
11/26 01:35:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][200/351]	Step 10352	lr 0.02499	Loss 1.8183 (1.9560)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.5%, 78.9%)	
11/26 01:35:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][300/351]	Step 10452	lr 0.02499	Loss 1.8186 (1.9404)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (46.9%, 79.2%)	
11/26 01:36:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [51][351/351]	Step 10503	lr 0.02499	Loss 1.9720 (1.9340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (47.1%, 79.2%)	
11/26 01:36:06午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 51/149] Final Prec@1 47.0933%
11/26 01:36:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][39/40]	Step 10504	Loss 2.1219	Prec@(1,5) (44.1%, 75.5%)
11/26 01:36:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 44.0800%
11/26 01:36:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:36:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][100/351]	Step 10604	lr 0.02498	Loss 1.7544 (1.8062)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.8%)	
11/26 01:37:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][200/351]	Step 10704	lr 0.02498	Loss 1.9077 (1.8140)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.5%)	
11/26 01:38:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][300/351]	Step 10804	lr 0.02498	Loss 1.7482 (1.8063)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.5%)	
11/26 01:38:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [52][351/351]	Step 10855	lr 0.02498	Loss 1.6399 (1.7985)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.6%)	
11/26 01:38:36午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 52/149] Final Prec@1 50.6156%
11/26 01:38:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][39/40]	Step 10856	Loss 2.0892	Prec@(1,5) (43.7%, 76.7%)
11/26 01:38:42午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 43.7200%
11/26 01:38:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:39:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][100/351]	Step 10956	lr 0.02495	Loss 1.7563 (1.7126)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.2%)	
11/26 01:40:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][200/351]	Step 11056	lr 0.02495	Loss 1.9241 (1.7088)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.2%)	
11/26 01:40:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][300/351]	Step 11156	lr 0.02495	Loss 2.0433 (1.7165)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.4%, 83.0%)	
11/26 01:41:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [53][351/351]	Step 11207	lr 0.02495	Loss 1.5791 (1.7133)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.1%)	
11/26 01:41:05午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 53/149] Final Prec@1 52.4556%
11/26 01:41:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][39/40]	Step 11208	Loss 2.0463	Prec@(1,5) (45.8%, 77.1%)
11/26 01:41:12午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 45.7400%
11/26 01:41:12午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:41:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][100/351]	Step 11308	lr 0.02491	Loss 1.6418 (1.6282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 84.4%)	
11/26 01:42:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][200/351]	Step 11408	lr 0.02491	Loss 1.7477 (1.6440)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.5%, 84.1%)	
11/26 01:43:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][300/351]	Step 11508	lr 0.02491	Loss 1.8919 (1.6510)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.1%, 84.0%)	
11/26 01:43:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [54][351/351]	Step 11559	lr 0.02491	Loss 1.3457 (1.6481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.2%, 84.1%)	
11/26 01:43:35午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 54/149] Final Prec@1 54.2022%
11/26 01:43:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][39/40]	Step 11560	Loss 1.9892	Prec@(1,5) (47.4%, 78.7%)
11/26 01:43:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 47.3800%
11/26 01:43:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:44:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][100/351]	Step 11660	lr 0.02485	Loss 1.5105 (1.5853)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.8%)	
11/26 01:45:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][200/351]	Step 11760	lr 0.02485	Loss 1.6212 (1.5959)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.8%)	
11/26 01:45:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][300/351]	Step 11860	lr 0.02485	Loss 1.2574 (1.5996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.1%, 84.7%)	
11/26 01:46:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [55][351/351]	Step 11911	lr 0.02485	Loss 1.8300 (1.5988)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.1%, 84.8%)	
11/26 01:46:05午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 55/149] Final Prec@1 55.1422%
11/26 01:46:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][39/40]	Step 11912	Loss 1.8737	Prec@(1,5) (49.3%, 79.9%)
11/26 01:46:11午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 49.3600%
11/26 01:46:11午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:46:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][100/351]	Step 12012	lr 0.02479	Loss 1.5438 (1.5371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 85.9%)	
11/26 01:47:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][200/351]	Step 12112	lr 0.02479	Loss 1.4958 (1.5347)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 85.9%)	
11/26 01:48:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][300/351]	Step 12212	lr 0.02479	Loss 1.3700 (1.5354)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 85.8%)	
11/26 01:48:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [56][351/351]	Step 12263	lr 0.02479	Loss 1.7037 (1.5443)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.7%)	
11/26 01:48:34午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 56/149] Final Prec@1 56.5556%
11/26 01:48:40午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][39/40]	Step 12264	Loss 2.0548	Prec@(1,5) (46.8%, 77.3%)
11/26 01:48:40午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 46.8000%
11/26 01:48:40午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:49:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][100/351]	Step 12364	lr 0.02471	Loss 1.4513 (1.4879)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 86.3%)	
11/26 01:50:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][200/351]	Step 12464	lr 0.02471	Loss 1.5741 (1.5007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.1%)	
11/26 01:50:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][300/351]	Step 12564	lr 0.02471	Loss 1.6268 (1.5001)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.8%, 86.3%)	
11/26 01:51:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [57][351/351]	Step 12615	lr 0.02471	Loss 1.6595 (1.5037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.2%)	
11/26 01:51:03午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 57/149] Final Prec@1 57.6778%
11/26 01:51:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][39/40]	Step 12616	Loss 2.0670	Prec@(1,5) (47.0%, 77.8%)
11/26 01:51:09午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 47.0000%
11/26 01:51:09午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5520%
11/26 01:51:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][100/351]	Step 12716	lr 0.02462	Loss 1.4910 (1.4589)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.0%)	
11/26 01:52:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][200/351]	Step 12816	lr 0.02462	Loss 1.4380 (1.4648)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.1%)	
11/26 01:53:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][300/351]	Step 12916	lr 0.02462	Loss 1.5669 (1.4696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 87.0%)	
11/26 01:53:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [58][351/351]	Step 12967	lr 0.02462	Loss 1.4641 (1.4744)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 86.9%)	
11/26 01:53:32午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 58/149] Final Prec@1 58.3756%
11/26 01:53:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][39/40]	Step 12968	Loss 1.7943	Prec@(1,5) (51.6%, 81.8%)
11/26 01:53:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 51.6000%
11/26 01:53:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.6000%
11/26 01:54:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][100/351]	Step 13068	lr 0.02452	Loss 1.2041 (1.4099)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.9%)	
11/26 01:55:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][200/351]	Step 13168	lr 0.02452	Loss 1.2028 (1.4128)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.6%, 87.8%)	
11/26 01:55:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][300/351]	Step 13268	lr 0.02452	Loss 1.4434 (1.4343)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.4%)	
11/26 01:56:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [59][351/351]	Step 13319	lr 0.02452	Loss 1.4350 (1.4370)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.4%)	
11/26 01:56:02午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 59/149] Final Prec@1 59.1022%
11/26 01:56:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][39/40]	Step 13320	Loss 2.0124	Prec@(1,5) (46.6%, 78.2%)
11/26 01:56:09午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 46.6200%
11/26 01:56:09午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.6000%
11/26 01:56:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][100/351]	Step 13420	lr 0.02441	Loss 1.4563 (1.3782)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.1%)	
11/26 01:57:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][200/351]	Step 13520	lr 0.02441	Loss 1.3510 (1.3868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.0%)	
11/26 01:58:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][300/351]	Step 13620	lr 0.02441	Loss 1.5588 (1.4006)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 87.8%)	
11/26 01:58:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [60][351/351]	Step 13671	lr 0.02441	Loss 1.3215 (1.4046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 87.8%)	
11/26 01:58:31午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 60/149] Final Prec@1 60.2267%
11/26 01:58:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][39/40]	Step 13672	Loss 1.8383	Prec@(1,5) (50.7%, 80.9%)
11/26 01:58:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 50.7000%
11/26 01:58:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.6000%
11/26 01:59:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][100/351]	Step 13772	lr 0.02429	Loss 1.6532 (1.3369)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.9%)	
11/26 01:59:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][200/351]	Step 13872	lr 0.02429	Loss 1.4713 (1.3588)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.7%)	
11/26 02:00:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][300/351]	Step 13972	lr 0.02429	Loss 1.5102 (1.3799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.5%)	
11/26 02:01:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [61][351/351]	Step 14023	lr 0.02429	Loss 1.4418 (1.3837)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.4%)	
11/26 02:01:01午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 61/149] Final Prec@1 60.6578%
11/26 02:01:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][39/40]	Step 14024	Loss 1.8237	Prec@(1,5) (52.1%, 81.6%)
11/26 02:01:07午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 52.1000%
11/26 02:01:07午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.1000%
11/26 02:01:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][100/351]	Step 14124	lr 0.02416	Loss 1.3260 (1.3138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 88.8%)	
11/26 02:02:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][200/351]	Step 14224	lr 0.02416	Loss 1.4600 (1.3299)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.9%)	
11/26 02:03:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][300/351]	Step 14324	lr 0.02416	Loss 1.4266 (1.3478)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.5%)	
11/26 02:03:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [62][351/351]	Step 14375	lr 0.02416	Loss 1.5071 (1.3533)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.5%)	
11/26 02:03:30午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 62/149] Final Prec@1 61.3067%
11/26 02:03:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][39/40]	Step 14376	Loss 1.9225	Prec@(1,5) (48.6%, 79.6%)
11/26 02:03:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 48.6000%
11/26 02:03:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.1000%
11/26 02:04:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][100/351]	Step 14476	lr 0.02401	Loss 1.3837 (1.2963)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.2%)	
11/26 02:04:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][200/351]	Step 14576	lr 0.02401	Loss 1.4218 (1.3160)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.0%)	
11/26 02:05:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][300/351]	Step 14676	lr 0.02401	Loss 1.3206 (1.3294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 88.8%)	
11/26 02:05:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [63][351/351]	Step 14727	lr 0.02401	Loss 1.4669 (1.3359)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.7%)	
11/26 02:05:59午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 63/149] Final Prec@1 61.8556%
11/26 02:06:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][39/40]	Step 14728	Loss 1.7492	Prec@(1,5) (52.8%, 82.5%)
11/26 02:06:05午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 52.8000%
11/26 02:06:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.8000%
11/26 02:06:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][100/351]	Step 14828	lr 0.02386	Loss 1.0983 (1.2791)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.7%)	
11/26 02:07:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][200/351]	Step 14928	lr 0.02386	Loss 0.9718 (1.2926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.5%)	
11/26 02:08:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][300/351]	Step 15028	lr 0.02386	Loss 1.2734 (1.3031)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.3%)	
11/26 02:08:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [64][351/351]	Step 15079	lr 0.02386	Loss 1.0913 (1.3080)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.2%)	
11/26 02:08:28午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 64/149] Final Prec@1 62.4733%
11/26 02:08:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][39/40]	Step 15080	Loss 1.8022	Prec@(1,5) (51.2%, 82.2%)
11/26 02:08:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 51.2000%
11/26 02:08:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.8000%
11/26 02:09:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][100/351]	Step 15180	lr 0.02369	Loss 1.3729 (1.2647)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.6%, 89.8%)	
11/26 02:09:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][200/351]	Step 15280	lr 0.02369	Loss 1.1696 (1.2833)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.6%)	
11/26 02:10:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][300/351]	Step 15380	lr 0.02369	Loss 1.5402 (1.2879)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.5%)	
11/26 02:10:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [65][351/351]	Step 15431	lr 0.02369	Loss 1.3255 (1.2908)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.5%)	
11/26 02:10:57午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 65/149] Final Prec@1 62.9422%
11/26 02:11:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][39/40]	Step 15432	Loss 1.7222	Prec@(1,5) (53.7%, 83.3%)
11/26 02:11:03午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 53.7000%
11/26 02:11:04午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7000%
11/26 02:11:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][100/351]	Step 15532	lr 0.02352	Loss 1.2162 (1.2398)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.3%)	
11/26 02:12:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][200/351]	Step 15632	lr 0.02352	Loss 1.2556 (1.2577)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.9%)	
11/26 02:13:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][300/351]	Step 15732	lr 0.02352	Loss 1.2746 (1.2685)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.7%)	
11/26 02:13:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [66][351/351]	Step 15783	lr 0.02352	Loss 1.3668 (1.2729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.6%)	
11/26 02:13:26午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 66/149] Final Prec@1 63.2889%
11/26 02:13:32午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][39/40]	Step 15784	Loss 1.7758	Prec@(1,5) (53.1%, 82.6%)
11/26 02:13:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 53.0400%
11/26 02:13:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7000%
11/26 02:14:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][100/351]	Step 15884	lr 0.02333	Loss 1.2736 (1.2029)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.6%)	
11/26 02:14:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][200/351]	Step 15984	lr 0.02333	Loss 1.3129 (1.2208)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.4%)	
11/26 02:15:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][300/351]	Step 16084	lr 0.02333	Loss 1.5141 (1.2455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
11/26 02:15:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [67][351/351]	Step 16135	lr 0.02333	Loss 1.4531 (1.2525)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.9%)	
11/26 02:15:55午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 67/149] Final Prec@1 63.7244%
11/26 02:16:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][39/40]	Step 16136	Loss 1.7926	Prec@(1,5) (52.4%, 82.6%)
11/26 02:16:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 52.4200%
11/26 02:16:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7000%
11/26 02:16:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][100/351]	Step 16236	lr 0.02313	Loss 1.2643 (1.1742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.0%)	
11/26 02:17:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][200/351]	Step 16336	lr 0.02313	Loss 1.0534 (1.2088)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.6%)	
11/26 02:18:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][300/351]	Step 16436	lr 0.02313	Loss 1.2027 (1.2250)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.4%)	
11/26 02:18:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [68][351/351]	Step 16487	lr 0.02313	Loss 1.3424 (1.2310)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.3%)	
11/26 02:18:24午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 68/149] Final Prec@1 64.2333%
11/26 02:18:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][39/40]	Step 16488	Loss 1.7591	Prec@(1,5) (53.5%, 82.6%)
11/26 02:18:31午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 53.6000%
11/26 02:18:31午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7000%
11/26 02:19:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][100/351]	Step 16588	lr 0.02292	Loss 1.3516 (1.2113)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.2%)	
11/26 02:19:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][200/351]	Step 16688	lr 0.02292	Loss 1.0723 (1.2143)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.3%)	
11/26 02:20:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][300/351]	Step 16788	lr 0.02292	Loss 1.0950 (1.2152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.3%)	
11/26 02:20:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [69][351/351]	Step 16839	lr 0.02292	Loss 1.4463 (1.2188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.3%)	
11/26 02:20:54午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 69/149] Final Prec@1 64.7911%
11/26 02:21:00午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][39/40]	Step 16840	Loss 1.7877	Prec@(1,5) (53.1%, 82.7%)
11/26 02:21:00午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 53.0400%
11/26 02:21:00午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7000%
11/26 02:21:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][100/351]	Step 16940	lr 0.02271	Loss 0.9789 (1.1645)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.2%)	
11/26 02:22:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][200/351]	Step 17040	lr 0.02271	Loss 1.3575 (1.1806)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.0%)	
11/26 02:23:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][300/351]	Step 17140	lr 0.02271	Loss 1.0150 (1.1923)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 90.9%)	
11/26 02:23:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [70][351/351]	Step 17191	lr 0.02271	Loss 1.0731 (1.1970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.9%)	
11/26 02:23:23午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 70/149] Final Prec@1 65.4089%
11/26 02:23:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][39/40]	Step 17192	Loss 1.7001	Prec@(1,5) (54.4%, 83.7%)
11/26 02:23:30午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 54.4200%
11/26 02:23:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.4200%
11/26 02:24:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][100/351]	Step 17292	lr 0.02248	Loss 1.1186 (1.1309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.8%)	
11/26 02:24:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][200/351]	Step 17392	lr 0.02248	Loss 1.2851 (1.1603)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.5%)	
11/26 02:25:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][300/351]	Step 17492	lr 0.02248	Loss 1.2048 (1.1718)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.2%)	
11/26 02:25:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [71][351/351]	Step 17543	lr 0.02248	Loss 0.9565 (1.1767)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.1%)	
11/26 02:25:53午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 71/149] Final Prec@1 65.6533%
11/26 02:25:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][39/40]	Step 17544	Loss 1.7297	Prec@(1,5) (53.4%, 83.3%)
11/26 02:25:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 53.4600%
11/26 02:25:59午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.4200%
11/26 02:26:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][100/351]	Step 17644	lr 0.02225	Loss 1.2297 (1.1190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.9%)	
11/26 02:27:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][200/351]	Step 17744	lr 0.02225	Loss 1.1245 (1.1508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.4%)	
11/26 02:28:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][300/351]	Step 17844	lr 0.02225	Loss 1.1292 (1.1539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.3%)	
11/26 02:28:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [72][351/351]	Step 17895	lr 0.02225	Loss 1.0682 (1.1651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.1%)	
11/26 02:28:22午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 72/149] Final Prec@1 66.1689%
11/26 02:28:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][39/40]	Step 17896	Loss 1.6226	Prec@(1,5) (56.0%, 85.2%)
11/26 02:28:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 56.0800%
11/26 02:28:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.0800%
11/26 02:29:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][100/351]	Step 17996	lr 0.022	Loss 1.1610 (1.1126)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.9%)	
11/26 02:29:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][200/351]	Step 18096	lr 0.022	Loss 0.9802 (1.1266)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.6%)	
11/26 02:30:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][300/351]	Step 18196	lr 0.022	Loss 1.1666 (1.1406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.5%)	
11/26 02:30:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [73][351/351]	Step 18247	lr 0.022	Loss 1.1811 (1.1465)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.5%)	
11/26 02:30:51午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 73/149] Final Prec@1 66.5311%
11/26 02:30:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][39/40]	Step 18248	Loss 1.6912	Prec@(1,5) (55.2%, 83.7%)
11/26 02:30:58午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 55.1800%
11/26 02:30:58午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.0800%
11/26 02:31:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][100/351]	Step 18348	lr 0.02175	Loss 1.3312 (1.0886)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.1%)	
11/26 02:32:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][200/351]	Step 18448	lr 0.02175	Loss 1.1134 (1.1099)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 91.9%)	
11/26 02:33:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][300/351]	Step 18548	lr 0.02175	Loss 1.0753 (1.1261)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.6%)	
11/26 02:33:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [74][351/351]	Step 18599	lr 0.02175	Loss 1.2721 (1.1332)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.5%)	
11/26 02:33:20午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 74/149] Final Prec@1 67.0133%
11/26 02:33:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][39/40]	Step 18600	Loss 1.7889	Prec@(1,5) (53.0%, 82.5%)
11/26 02:33:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 53.0000%
11/26 02:33:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.0800%
11/26 02:34:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][100/351]	Step 18700	lr 0.02149	Loss 0.9231 (1.0890)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.3%)	
11/26 02:34:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][200/351]	Step 18800	lr 0.02149	Loss 1.0649 (1.1042)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.0%)	
11/26 02:35:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][300/351]	Step 18900	lr 0.02149	Loss 1.0109 (1.1191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 91.7%)	
11/26 02:35:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [75][351/351]	Step 18951	lr 0.02149	Loss 1.0707 (1.1260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.7%)	
11/26 02:35:49午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 75/149] Final Prec@1 67.0600%
11/26 02:35:56午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][39/40]	Step 18952	Loss 1.7145	Prec@(1,5) (54.1%, 83.1%)
11/26 02:35:56午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 54.1200%
11/26 02:35:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.0800%
11/26 02:36:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][100/351]	Step 19052	lr 0.02121	Loss 1.2996 (1.0784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.2%)	
11/26 02:37:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][200/351]	Step 19152	lr 0.02121	Loss 1.2710 (1.0864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.2%)	
11/26 02:37:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][300/351]	Step 19252	lr 0.02121	Loss 1.1532 (1.0974)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.1%)	
11/26 02:38:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [76][351/351]	Step 19303	lr 0.02121	Loss 1.3887 (1.1046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.0%)	
11/26 02:38:19午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 76/149] Final Prec@1 67.6400%
11/26 02:38:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][39/40]	Step 19304	Loss 1.7071	Prec@(1,5) (54.0%, 83.3%)
11/26 02:38:25午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 54.0200%
11/26 02:38:25午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.0800%
11/26 02:39:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][100/351]	Step 19404	lr 0.02094	Loss 1.1215 (1.0554)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.7%)	
11/26 02:39:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][200/351]	Step 19504	lr 0.02094	Loss 0.8019 (1.0791)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.5%)	
11/26 02:40:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][300/351]	Step 19604	lr 0.02094	Loss 0.9438 (1.0898)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.3%)	
11/26 02:40:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [77][351/351]	Step 19655	lr 0.02094	Loss 1.0536 (1.0893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.3%)	
11/26 02:40:48午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 77/149] Final Prec@1 67.9778%
11/26 02:40:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][39/40]	Step 19656	Loss 1.6109	Prec@(1,5) (56.9%, 84.6%)
11/26 02:40:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 56.8800%
11/26 02:40:54午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.8800%
11/26 02:41:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][100/351]	Step 19756	lr 0.02065	Loss 0.9904 (1.0515)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.4%)	
11/26 02:42:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][200/351]	Step 19856	lr 0.02065	Loss 0.9552 (1.0533)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.5%)	
11/26 02:42:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][300/351]	Step 19956	lr 0.02065	Loss 0.9371 (1.0641)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.4%)	
11/26 02:43:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [78][351/351]	Step 20007	lr 0.02065	Loss 1.1265 (1.0719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.4%)	
11/26 02:43:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 78/149] Final Prec@1 68.4933%
11/26 02:43:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][39/40]	Step 20008	Loss 1.6600	Prec@(1,5) (56.0%, 84.9%)
11/26 02:43:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 56.0600%
11/26 02:43:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.8800%
11/26 02:44:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][100/351]	Step 20108	lr 0.02035	Loss 1.0933 (1.0236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.0%)	
11/26 02:44:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][200/351]	Step 20208	lr 0.02035	Loss 0.9933 (1.0433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 92.7%)	
11/26 02:45:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][300/351]	Step 20308	lr 0.02035	Loss 0.9862 (1.0570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.6%)	
11/26 02:45:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [79][351/351]	Step 20359	lr 0.02035	Loss 1.1305 (1.0656)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.5%)	
11/26 02:45:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 79/149] Final Prec@1 68.8622%
11/26 02:45:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][39/40]	Step 20360	Loss 1.6616	Prec@(1,5) (55.7%, 84.5%)
11/26 02:45:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 55.7000%
11/26 02:45:53午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.8800%
11/26 02:46:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][100/351]	Step 20460	lr 0.02005	Loss 1.0016 (0.9971)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.3%)	
11/26 02:47:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][200/351]	Step 20560	lr 0.02005	Loss 1.0229 (1.0195)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 92.9%)	
11/26 02:47:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][300/351]	Step 20660	lr 0.02005	Loss 1.2288 (1.0382)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.7%)	
11/26 02:48:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [80][351/351]	Step 20711	lr 0.02005	Loss 0.9183 (1.0441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.6%)	
11/26 02:48:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 80/149] Final Prec@1 69.2756%
11/26 02:48:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][39/40]	Step 20712	Loss 1.6171	Prec@(1,5) (56.7%, 85.3%)
11/26 02:48:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 56.6600%
11/26 02:48:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.8800%
11/26 02:49:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][100/351]	Step 20812	lr 0.01975	Loss 1.0720 (1.0012)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.3%)	
11/26 02:49:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][200/351]	Step 20912	lr 0.01975	Loss 1.2889 (1.0174)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.0%)	
11/26 02:50:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][300/351]	Step 21012	lr 0.01975	Loss 1.1040 (1.0353)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.9%)	
11/26 02:50:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [81][351/351]	Step 21063	lr 0.01975	Loss 1.0542 (1.0393)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 92.8%)	
11/26 02:50:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 81/149] Final Prec@1 69.3778%
11/26 02:50:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][39/40]	Step 21064	Loss 1.6071	Prec@(1,5) (57.3%, 84.6%)
11/26 02:50:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 57.2400%
11/26 02:50:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2400%
11/26 02:51:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][100/351]	Step 21164	lr 0.01943	Loss 1.1177 (0.9760)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.6%)	
11/26 02:52:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][200/351]	Step 21264	lr 0.01943	Loss 1.1253 (1.0053)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.2%)	
11/26 02:52:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][300/351]	Step 21364	lr 0.01943	Loss 0.9566 (1.0272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.9%)	
11/26 02:53:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [82][351/351]	Step 21415	lr 0.01943	Loss 1.0903 (1.0270)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 92.9%)	
11/26 02:53:15午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 82/149] Final Prec@1 69.5822%
11/26 02:53:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][39/40]	Step 21416	Loss 1.7556	Prec@(1,5) (54.3%, 83.2%)
11/26 02:53:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 54.3400%
11/26 02:53:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.2400%
11/26 02:54:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][100/351]	Step 21516	lr 0.01911	Loss 1.0061 (0.9403)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.1%)	
11/26 02:54:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][200/351]	Step 21616	lr 0.01911	Loss 1.0507 (0.9730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.7%)	
11/26 02:55:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][300/351]	Step 21716	lr 0.01911	Loss 1.0567 (0.9958)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.3%)	
11/26 02:55:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [83][351/351]	Step 21767	lr 0.01911	Loss 1.0215 (1.0024)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.2%)	
11/26 02:55:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 83/149] Final Prec@1 70.3667%
11/26 02:55:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][39/40]	Step 21768	Loss 1.5652	Prec@(1,5) (57.9%, 85.9%)
11/26 02:55:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 57.8400%
11/26 02:55:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.8400%
11/26 02:56:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][100/351]	Step 21868	lr 0.01878	Loss 1.1370 (0.9419)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.1%)	
11/26 02:57:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][200/351]	Step 21968	lr 0.01878	Loss 1.1164 (0.9714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.7%)	
11/26 02:57:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][300/351]	Step 22068	lr 0.01878	Loss 0.9704 (0.9827)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.6%)	
11/26 02:58:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [84][351/351]	Step 22119	lr 0.01878	Loss 1.0824 (0.9906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.5%)	
11/26 02:58:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 84/149] Final Prec@1 70.8422%
11/26 02:58:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][39/40]	Step 22120	Loss 1.6110	Prec@(1,5) (57.5%, 85.9%)
11/26 02:58:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 57.4600%
11/26 02:58:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.8400%
11/26 02:59:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][100/351]	Step 22220	lr 0.01845	Loss 0.9945 (0.9310)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.1%)	
11/26 02:59:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][200/351]	Step 22320	lr 0.01845	Loss 0.9349 (0.9483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 93.8%)	
11/26 03:00:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][300/351]	Step 22420	lr 0.01845	Loss 0.9778 (0.9714)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.5%)	
11/26 03:00:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [85][351/351]	Step 22471	lr 0.01845	Loss 1.1006 (0.9788)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.4%)	
11/26 03:00:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 85/149] Final Prec@1 71.1978%
11/26 03:00:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][39/40]	Step 22472	Loss 1.6863	Prec@(1,5) (55.9%, 85.2%)
11/26 03:00:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 55.9200%
11/26 03:00:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.8400%
11/26 03:01:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][100/351]	Step 22572	lr 0.01811	Loss 0.9380 (0.9370)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
11/26 03:02:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][200/351]	Step 22672	lr 0.01811	Loss 1.0208 (0.9507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.8%)	
11/26 03:02:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][300/351]	Step 22772	lr 0.01811	Loss 1.0767 (0.9650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.7%)	
11/26 03:03:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [86][351/351]	Step 22823	lr 0.01811	Loss 1.2180 (0.9666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.6%)	
11/26 03:03:15午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 86/149] Final Prec@1 71.1533%
11/26 03:03:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][39/40]	Step 22824	Loss 1.5446	Prec@(1,5) (58.6%, 86.0%)
11/26 03:03:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 58.6200%
11/26 03:03:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6200%
11/26 03:04:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][100/351]	Step 22924	lr 0.01777	Loss 0.9055 (0.9313)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.2%)	
11/26 03:04:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][200/351]	Step 23024	lr 0.01777	Loss 1.2235 (0.9413)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.1%)	
11/26 03:05:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][300/351]	Step 23124	lr 0.01777	Loss 0.8598 (0.9508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
11/26 03:05:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [87][351/351]	Step 23175	lr 0.01777	Loss 0.9443 (0.9529)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 93.9%)	
11/26 03:05:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 87/149] Final Prec@1 71.7644%
11/26 03:05:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][39/40]	Step 23176	Loss 1.5914	Prec@(1,5) (58.2%, 85.4%)
11/26 03:05:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 58.1800%
11/26 03:05:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.6200%
11/26 03:06:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][100/351]	Step 23276	lr 0.01742	Loss 1.0541 (0.9181)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.4%)	
11/26 03:07:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][200/351]	Step 23376	lr 0.01742	Loss 0.9220 (0.9209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.3%)	
11/26 03:07:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][300/351]	Step 23476	lr 0.01742	Loss 0.9923 (0.9348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.2%)	
11/26 03:08:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [88][351/351]	Step 23527	lr 0.01742	Loss 1.0469 (0.9409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.0%)	
11/26 03:08:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 88/149] Final Prec@1 71.7156%
11/26 03:08:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][39/40]	Step 23528	Loss 1.5471	Prec@(1,5) (58.8%, 86.1%)
11/26 03:08:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 58.7800%
11/26 03:08:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7800%
11/26 03:09:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][100/351]	Step 23628	lr 0.01706	Loss 0.7716 (0.8686)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.9%)	
11/26 03:09:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][200/351]	Step 23728	lr 0.01706	Loss 1.0001 (0.8981)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.3%)	
11/26 03:10:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][300/351]	Step 23828	lr 0.01706	Loss 0.9758 (0.9123)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.2%)	
11/26 03:10:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [89][351/351]	Step 23879	lr 0.01706	Loss 0.9662 (0.9210)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.1%)	
11/26 03:10:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 89/149] Final Prec@1 72.7578%
11/26 03:10:53午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][39/40]	Step 23880	Loss 1.6340	Prec@(1,5) (57.3%, 84.8%)
11/26 03:10:53午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 57.3600%
11/26 03:10:53午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7800%
11/26 03:11:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][100/351]	Step 23980	lr 0.01671	Loss 0.8130 (0.8830)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.6%)	
11/26 03:12:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][200/351]	Step 24080	lr 0.01671	Loss 1.1318 (0.8951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.4%)	
11/26 03:12:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][300/351]	Step 24180	lr 0.01671	Loss 1.0049 (0.9127)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.2%)	
11/26 03:13:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [90][351/351]	Step 24231	lr 0.01671	Loss 0.8702 (0.9184)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.1%)	
11/26 03:13:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 90/149] Final Prec@1 72.5778%
11/26 03:13:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][39/40]	Step 24232	Loss 1.5601	Prec@(1,5) (58.2%, 86.0%)
11/26 03:13:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 58.1600%
11/26 03:13:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7800%
11/26 03:14:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][100/351]	Step 24332	lr 0.01635	Loss 0.9519 (0.8606)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.1%)	
11/26 03:14:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][200/351]	Step 24432	lr 0.01635	Loss 0.9562 (0.8830)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.7%)	
11/26 03:15:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][300/351]	Step 24532	lr 0.01635	Loss 0.7231 (0.8933)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.5%)	
11/26 03:15:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [91][351/351]	Step 24583	lr 0.01635	Loss 0.9561 (0.8998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
11/26 03:15:47午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 91/149] Final Prec@1 72.9622%
11/26 03:15:53午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][39/40]	Step 24584	Loss 1.6807	Prec@(1,5) (56.7%, 85.3%)
11/26 03:15:53午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 56.6600%
11/26 03:15:53午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7800%
11/26 03:16:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][100/351]	Step 24684	lr 0.01598	Loss 0.7917 (0.8379)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.3%)	
11/26 03:17:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][200/351]	Step 24784	lr 0.01598	Loss 0.8624 (0.8447)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.1%)	
11/26 03:17:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][300/351]	Step 24884	lr 0.01598	Loss 0.8471 (0.8692)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.8%)	
11/26 03:18:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [92][351/351]	Step 24935	lr 0.01598	Loss 0.9477 (0.8792)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
11/26 03:18:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 92/149] Final Prec@1 73.5511%
11/26 03:18:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][39/40]	Step 24936	Loss 1.6140	Prec@(1,5) (57.5%, 86.2%)
11/26 03:18:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 57.5000%
11/26 03:18:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.7800%
11/26 03:19:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][100/351]	Step 25036	lr 0.01562	Loss 0.9303 (0.8224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.2%)	
11/26 03:19:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][200/351]	Step 25136	lr 0.01562	Loss 0.7488 (0.8482)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 94.9%)	
11/26 03:20:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][300/351]	Step 25236	lr 0.01562	Loss 0.9854 (0.8688)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
11/26 03:20:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [93][351/351]	Step 25287	lr 0.01562	Loss 0.7085 (0.8761)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.7%)	
11/26 03:20:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 93/149] Final Prec@1 73.7156%
11/26 03:20:53午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][39/40]	Step 25288	Loss 1.4869	Prec@(1,5) (59.1%, 87.4%)
11/26 03:20:53午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 59.1200%
11/26 03:20:54午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1200%
11/26 03:21:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][100/351]	Step 25388	lr 0.01525	Loss 0.8590 (0.8246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.4%)	
11/26 03:22:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][200/351]	Step 25488	lr 0.01525	Loss 1.0243 (0.8420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.3%)	
11/26 03:22:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][300/351]	Step 25588	lr 0.01525	Loss 1.0425 (0.8552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.1%)	
11/26 03:23:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [94][351/351]	Step 25639	lr 0.01525	Loss 0.9400 (0.8577)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 95.0%)	
11/26 03:23:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 94/149] Final Prec@1 73.9067%
11/26 03:23:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][39/40]	Step 25640	Loss 1.6636	Prec@(1,5) (56.9%, 84.5%)
11/26 03:23:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 56.9000%
11/26 03:23:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1200%
11/26 03:24:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][100/351]	Step 25740	lr 0.01488	Loss 0.7356 (0.8051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.4%)	
11/26 03:24:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][200/351]	Step 25840	lr 0.01488	Loss 0.7940 (0.8229)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.3%)	
11/26 03:25:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][300/351]	Step 25940	lr 0.01488	Loss 0.6754 (0.8367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.1%)	
11/26 03:25:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [95][351/351]	Step 25991	lr 0.01488	Loss 0.9279 (0.8422)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.7%, 95.0%)	
11/26 03:25:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 95/149] Final Prec@1 74.7089%
11/26 03:25:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][39/40]	Step 25992	Loss 1.5701	Prec@(1,5) (58.1%, 85.6%)
11/26 03:25:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 58.1200%
11/26 03:25:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1200%
11/26 03:26:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][100/351]	Step 26092	lr 0.0145	Loss 0.8237 (0.7809)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.6%)	
11/26 03:27:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][200/351]	Step 26192	lr 0.0145	Loss 0.7917 (0.8024)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.5%)	
11/26 03:27:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][300/351]	Step 26292	lr 0.0145	Loss 0.7731 (0.8226)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.3%)	
11/26 03:28:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [96][351/351]	Step 26343	lr 0.0145	Loss 0.8850 (0.8309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.2%)	
11/26 03:28:15午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 96/149] Final Prec@1 74.9311%
11/26 03:28:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][39/40]	Step 26344	Loss 1.5838	Prec@(1,5) (58.6%, 85.8%)
11/26 03:28:21午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 58.5800%
11/26 03:28:21午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1200%
11/26 03:29:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][100/351]	Step 26444	lr 0.01413	Loss 0.9111 (0.7730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.7%)	
11/26 03:29:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][200/351]	Step 26544	lr 0.01413	Loss 0.7864 (0.7953)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.7%)	
11/26 03:30:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][300/351]	Step 26644	lr 0.01413	Loss 0.6374 (0.8085)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.5%)	
11/26 03:30:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [97][351/351]	Step 26695	lr 0.01413	Loss 0.8022 (0.8200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.3%)	
11/26 03:30:44午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 97/149] Final Prec@1 75.0711%
11/26 03:30:50午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][39/40]	Step 26696	Loss 1.5519	Prec@(1,5) (59.1%, 86.7%)
11/26 03:30:50午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 59.1200%
11/26 03:30:50午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1200%
11/26 03:31:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][100/351]	Step 26796	lr 0.01375	Loss 0.7066 (0.7534)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.0%)	
11/26 03:32:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][200/351]	Step 26896	lr 0.01375	Loss 0.7248 (0.7762)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.7%)	
11/26 03:32:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][300/351]	Step 26996	lr 0.01375	Loss 0.8506 (0.7954)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.5%)	
11/26 03:33:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [98][351/351]	Step 27047	lr 0.01375	Loss 0.7862 (0.7990)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.5%)	
11/26 03:33:13午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 98/149] Final Prec@1 75.8733%
11/26 03:33:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][39/40]	Step 27048	Loss 1.5004	Prec@(1,5) (59.7%, 86.7%)
11/26 03:33:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 59.6600%
11/26 03:33:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6600%
11/26 03:34:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][100/351]	Step 27148	lr 0.01338	Loss 0.7119 (0.7700)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.2%)	
11/26 03:34:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][200/351]	Step 27248	lr 0.01338	Loss 0.9458 (0.7753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.9%)	
11/26 03:35:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][300/351]	Step 27348	lr 0.01338	Loss 0.7266 (0.7871)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.7%)	
11/26 03:35:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [99][351/351]	Step 27399	lr 0.01338	Loss 0.7037 (0.7911)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.6%)	
11/26 03:35:43午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [ 99/149] Final Prec@1 75.9444%
11/26 03:35:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][39/40]	Step 27400	Loss 1.5218	Prec@(1,5) (59.7%, 86.6%)
11/26 03:35:49午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 59.6800%
11/26 03:35:50午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6800%
11/26 03:36:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][100/351]	Step 27500	lr 0.013	Loss 0.8218 (0.7429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.1%)	
11/26 03:37:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][200/351]	Step 27600	lr 0.013	Loss 0.5459 (0.7647)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 95.9%)	
11/26 03:37:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][300/351]	Step 27700	lr 0.013	Loss 0.8973 (0.7748)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
11/26 03:38:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [100][351/351]	Step 27751	lr 0.013	Loss 0.8231 (0.7775)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
11/26 03:38:13午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [100/149] Final Prec@1 76.3578%
11/26 03:38:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][39/40]	Step 27752	Loss 1.5927	Prec@(1,5) (58.4%, 85.6%)
11/26 03:38:19午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 58.3200%
11/26 03:38:19午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6800%
11/26 03:39:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][100/351]	Step 27852	lr 0.01262	Loss 0.6276 (0.7162)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.4%)	
11/26 03:39:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][200/351]	Step 27952	lr 0.01262	Loss 0.7301 (0.7429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
11/26 03:40:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][300/351]	Step 28052	lr 0.01262	Loss 0.7063 (0.7545)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.1%)	
11/26 03:40:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [101][351/351]	Step 28103	lr 0.01262	Loss 0.6386 (0.7590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.1%)	
11/26 03:40:42午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [101/149] Final Prec@1 76.9156%
11/26 03:40:48午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][39/40]	Step 28104	Loss 1.5827	Prec@(1,5) (58.6%, 86.2%)
11/26 03:40:48午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 58.5600%
11/26 03:40:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.6800%
11/26 03:41:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][100/351]	Step 28204	lr 0.01225	Loss 0.7031 (0.7084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.5%)	
11/26 03:42:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][200/351]	Step 28304	lr 0.01225	Loss 0.6715 (0.7223)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.3%)	
11/26 03:42:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][300/351]	Step 28404	lr 0.01225	Loss 0.8971 (0.7353)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
11/26 03:43:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [102][351/351]	Step 28455	lr 0.01225	Loss 0.6208 (0.7433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.2%)	
11/26 03:43:11午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [102/149] Final Prec@1 77.3822%
11/26 03:43:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][39/40]	Step 28456	Loss 1.5108	Prec@(1,5) (60.6%, 87.0%)
11/26 03:43:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 60.6200%
11/26 03:43:18午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:43:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][100/351]	Step 28556	lr 0.01187	Loss 0.6518 (0.6982)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.5%)	
11/26 03:44:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][200/351]	Step 28656	lr 0.01187	Loss 0.7027 (0.7215)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.2%)	
11/26 03:45:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][300/351]	Step 28756	lr 0.01187	Loss 0.7308 (0.7314)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
11/26 03:45:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [103][351/351]	Step 28807	lr 0.01187	Loss 0.8110 (0.7387)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.1%)	
11/26 03:45:40午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [103/149] Final Prec@1 77.4533%
11/26 03:45:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][39/40]	Step 28808	Loss 1.5607	Prec@(1,5) (59.5%, 86.7%)
11/26 03:45:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 59.5200%
11/26 03:45:47午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:46:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][100/351]	Step 28908	lr 0.0115	Loss 0.7634 (0.6836)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.9%)	
11/26 03:47:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][200/351]	Step 29008	lr 0.0115	Loss 0.5200 (0.7064)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.5%)	
11/26 03:47:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][300/351]	Step 29108	lr 0.0115	Loss 0.6109 (0.7188)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.4%)	
11/26 03:48:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [104][351/351]	Step 29159	lr 0.0115	Loss 0.7378 (0.7220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.4%)	
11/26 03:48:09午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [104/149] Final Prec@1 78.0422%
11/26 03:48:16午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][39/40]	Step 29160	Loss 1.5602	Prec@(1,5) (59.7%, 86.2%)
11/26 03:48:16午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 59.6600%
11/26 03:48:16午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:48:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][100/351]	Step 29260	lr 0.01112	Loss 0.6943 (0.6849)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
11/26 03:49:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][200/351]	Step 29360	lr 0.01112	Loss 0.7045 (0.6997)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.5%)	
11/26 03:50:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][300/351]	Step 29460	lr 0.01112	Loss 0.7183 (0.7020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.5%)	
11/26 03:50:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [105][351/351]	Step 29511	lr 0.01112	Loss 0.8996 (0.7077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.4%)	
11/26 03:50:39午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [105/149] Final Prec@1 78.4044%
11/26 03:50:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][39/40]	Step 29512	Loss 1.5413	Prec@(1,5) (59.6%, 87.1%)
11/26 03:50:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 59.6000%
11/26 03:50:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:51:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][100/351]	Step 29612	lr 0.01075	Loss 0.7774 (0.6429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 96.9%)	
11/26 03:52:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][200/351]	Step 29712	lr 0.01075	Loss 0.6866 (0.6741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 96.7%)	
11/26 03:52:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][300/351]	Step 29812	lr 0.01075	Loss 0.4655 (0.6795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.7%)	
11/26 03:53:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [106][351/351]	Step 29863	lr 0.01075	Loss 0.7403 (0.6864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.6%)	
11/26 03:53:09午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [106/149] Final Prec@1 79.1178%
11/26 03:53:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][39/40]	Step 29864	Loss 1.5400	Prec@(1,5) (60.6%, 86.5%)
11/26 03:53:15午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 60.6200%
11/26 03:53:15午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:53:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][100/351]	Step 29964	lr 0.01038	Loss 0.5982 (0.6271)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.2%)	
11/26 03:54:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][200/351]	Step 30064	lr 0.01038	Loss 0.7847 (0.6488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.1%)	
11/26 03:55:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][300/351]	Step 30164	lr 0.01038	Loss 0.6652 (0.6663)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.5%, 97.0%)	
11/26 03:55:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [107][351/351]	Step 30215	lr 0.01038	Loss 0.8051 (0.6749)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
11/26 03:55:38午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [107/149] Final Prec@1 79.3667%
11/26 03:55:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][39/40]	Step 30216	Loss 1.6007	Prec@(1,5) (59.6%, 86.7%)
11/26 03:55:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 59.6000%
11/26 03:55:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:56:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][100/351]	Step 30316	lr 0.01002	Loss 0.5614 (0.6281)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.2%)	
11/26 03:57:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][200/351]	Step 30416	lr 0.01002	Loss 0.6269 (0.6495)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
11/26 03:57:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][300/351]	Step 30516	lr 0.01002	Loss 0.5084 (0.6586)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/26 03:58:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [108][351/351]	Step 30567	lr 0.01002	Loss 0.8313 (0.6647)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
11/26 03:58:08午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [108/149] Final Prec@1 79.6733%
11/26 03:58:14午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][39/40]	Step 30568	Loss 1.5390	Prec@(1,5) (60.2%, 87.9%)
11/26 03:58:14午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 60.1800%
11/26 03:58:14午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6200%
11/26 03:58:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][100/351]	Step 30668	lr 0.00965	Loss 0.5873 (0.6190)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.4%)	
11/26 03:59:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][200/351]	Step 30768	lr 0.00965	Loss 0.7600 (0.6380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.2%)	
11/26 04:00:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][300/351]	Step 30868	lr 0.00965	Loss 0.6606 (0.6462)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
11/26 04:00:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [109][351/351]	Step 30919	lr 0.00965	Loss 0.5917 (0.6509)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
11/26 04:00:37午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [109/149] Final Prec@1 79.9044%
11/26 04:00:44午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][39/40]	Step 30920	Loss 1.5035	Prec@(1,5) (60.7%, 87.7%)
11/26 04:00:44午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 60.6600%
11/26 04:00:44午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6600%
11/26 04:01:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][100/351]	Step 31020	lr 0.00929	Loss 0.5713 (0.5889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.7%)	
11/26 04:02:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][200/351]	Step 31120	lr 0.00929	Loss 0.6901 (0.6091)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/26 04:02:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][300/351]	Step 31220	lr 0.00929	Loss 0.6618 (0.6224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.3%)	
11/26 04:03:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [110][351/351]	Step 31271	lr 0.00929	Loss 0.7426 (0.6362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.1%)	
11/26 04:03:07午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [110/149] Final Prec@1 80.3933%
11/26 04:03:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][39/40]	Step 31272	Loss 1.5259	Prec@(1,5) (59.8%, 86.8%)
11/26 04:03:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 59.7800%
11/26 04:03:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6600%
11/26 04:03:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][100/351]	Step 31372	lr 0.00894	Loss 0.5182 (0.5979)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
11/26 04:04:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][200/351]	Step 31472	lr 0.00894	Loss 0.7152 (0.6012)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.4%)	
11/26 04:05:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][300/351]	Step 31572	lr 0.00894	Loss 0.8520 (0.6106)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.3%)	
11/26 04:05:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [111][351/351]	Step 31623	lr 0.00894	Loss 0.6410 (0.6177)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.2%)	
11/26 04:05:36午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [111/149] Final Prec@1 81.2156%
11/26 04:05:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][39/40]	Step 31624	Loss 1.5086	Prec@(1,5) (61.1%, 87.0%)
11/26 04:05:42午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 61.1000%
11/26 04:05:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1000%
11/26 04:06:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][100/351]	Step 31724	lr 0.00858	Loss 0.4856 (0.5720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
11/26 04:07:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][200/351]	Step 31824	lr 0.00858	Loss 0.5395 (0.5803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.7%)	
11/26 04:07:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][300/351]	Step 31924	lr 0.00858	Loss 0.7810 (0.6008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
11/26 04:08:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [112][351/351]	Step 31975	lr 0.00858	Loss 0.7318 (0.6060)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.4%)	
11/26 04:08:05午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [112/149] Final Prec@1 81.2911%
11/26 04:08:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][39/40]	Step 31976	Loss 1.5162	Prec@(1,5) (61.2%, 87.5%)
11/26 04:08:11午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 61.2000%
11/26 04:08:12午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.2000%
11/26 04:08:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][100/351]	Step 32076	lr 0.00823	Loss 0.5466 (0.5650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.9%)	
11/26 04:09:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][200/351]	Step 32176	lr 0.00823	Loss 0.5663 (0.5697)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
11/26 04:10:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][300/351]	Step 32276	lr 0.00823	Loss 0.6906 (0.5817)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.6%)	
11/26 04:10:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [113][351/351]	Step 32327	lr 0.00823	Loss 0.7352 (0.5880)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.5%)	
11/26 04:10:34午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [113/149] Final Prec@1 81.8667%
11/26 04:10:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][39/40]	Step 32328	Loss 1.4634	Prec@(1,5) (61.6%, 88.3%)
11/26 04:10:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 61.6400%
11/26 04:10:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/26 04:11:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][100/351]	Step 32428	lr 0.00789	Loss 0.6212 (0.5413)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.9%)	
11/26 04:12:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][200/351]	Step 32528	lr 0.00789	Loss 0.5711 (0.5579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.8%)	
11/26 04:12:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][300/351]	Step 32628	lr 0.00789	Loss 0.5796 (0.5706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
11/26 04:13:03午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [114][351/351]	Step 32679	lr 0.00789	Loss 0.6005 (0.5766)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.7%)	
11/26 04:13:03午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [114/149] Final Prec@1 82.3156%
11/26 04:13:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][39/40]	Step 32680	Loss 1.5251	Prec@(1,5) (61.2%, 87.5%)
11/26 04:13:10午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 61.1600%
11/26 04:13:10午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.6400%
11/26 04:13:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][100/351]	Step 32780	lr 0.00755	Loss 0.6417 (0.5252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.0%)	
11/26 04:14:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][200/351]	Step 32880	lr 0.00755	Loss 0.4952 (0.5376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 97.9%)	
11/26 04:15:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][300/351]	Step 32980	lr 0.00755	Loss 0.4687 (0.5492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.8%)	
11/26 04:15:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [115][351/351]	Step 33031	lr 0.00755	Loss 0.5983 (0.5551)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.8%)	
11/26 04:15:32午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [115/149] Final Prec@1 83.0111%
11/26 04:15:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][39/40]	Step 33032	Loss 1.4652	Prec@(1,5) (61.8%, 88.0%)
11/26 04:15:39午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 61.8000%
11/26 04:15:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.8000%
11/26 04:16:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][100/351]	Step 33132	lr 0.00722	Loss 0.6132 (0.5202)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.1%)	
11/26 04:17:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][200/351]	Step 33232	lr 0.00722	Loss 0.5514 (0.5389)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/26 04:17:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][300/351]	Step 33332	lr 0.00722	Loss 0.5741 (0.5448)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
11/26 04:18:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [116][351/351]	Step 33383	lr 0.00722	Loss 0.6225 (0.5496)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
11/26 04:18:02午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [116/149] Final Prec@1 83.1689%
11/26 04:18:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][39/40]	Step 33384	Loss 1.5263	Prec@(1,5) (61.5%, 87.8%)
11/26 04:18:08午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 61.4600%
11/26 04:18:09午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.8000%
11/26 04:18:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][100/351]	Step 33484	lr 0.00689	Loss 0.5131 (0.5035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.2%)	
11/26 04:19:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][200/351]	Step 33584	lr 0.00689	Loss 0.5619 (0.5087)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
11/26 04:20:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][300/351]	Step 33684	lr 0.00689	Loss 0.6628 (0.5183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.2%, 98.1%)	
11/26 04:20:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [117][351/351]	Step 33735	lr 0.00689	Loss 0.5245 (0.5236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.0%)	
11/26 04:20:31午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [117/149] Final Prec@1 83.9867%
11/26 04:20:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][39/40]	Step 33736	Loss 1.4741	Prec@(1,5) (61.7%, 88.2%)
11/26 04:20:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 61.7200%
11/26 04:20:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.8000%
11/26 04:21:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][100/351]	Step 33836	lr 0.00657	Loss 0.3679 (0.4776)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.4%)	
11/26 04:21:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][200/351]	Step 33936	lr 0.00657	Loss 0.5116 (0.4912)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.3%)	
11/26 04:22:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][300/351]	Step 34036	lr 0.00657	Loss 0.4218 (0.5034)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.2%)	
11/26 04:23:00午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [118][351/351]	Step 34087	lr 0.00657	Loss 0.5572 (0.5116)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.2%)	
11/26 04:23:00午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [118/149] Final Prec@1 84.3000%
11/26 04:23:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][39/40]	Step 34088	Loss 1.4866	Prec@(1,5) (61.4%, 87.9%)
11/26 04:23:07午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 61.3600%
11/26 04:23:07午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.8000%
11/26 04:23:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][100/351]	Step 34188	lr 0.00625	Loss 0.4097 (0.4777)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.4%)	
11/26 04:24:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][200/351]	Step 34288	lr 0.00625	Loss 0.5329 (0.4873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
11/26 04:25:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][300/351]	Step 34388	lr 0.00625	Loss 0.4846 (0.4981)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.6%, 98.3%)	
11/26 04:25:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [119][351/351]	Step 34439	lr 0.00625	Loss 0.6370 (0.5058)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.2%)	
11/26 04:25:30午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [119/149] Final Prec@1 84.3644%
11/26 04:25:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][39/40]	Step 34440	Loss 1.5021	Prec@(1,5) (62.0%, 87.9%)
11/26 04:25:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 61.9800%
11/26 04:25:37午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.9800%
11/26 04:26:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][100/351]	Step 34540	lr 0.00595	Loss 0.4919 (0.4529)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.5%)	
11/26 04:26:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][200/351]	Step 34640	lr 0.00595	Loss 0.4640 (0.4732)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.4%)	
11/26 04:27:38午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][300/351]	Step 34740	lr 0.00595	Loss 0.5048 (0.4861)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.3%)	
11/26 04:27:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [120][351/351]	Step 34791	lr 0.00595	Loss 0.5722 (0.4910)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
11/26 04:27:59午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [120/149] Final Prec@1 85.0022%
11/26 04:28:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][39/40]	Step 34792	Loss 1.4886	Prec@(1,5) (62.8%, 87.9%)
11/26 04:28:06午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 62.8000%
11/26 04:28:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.8000%
11/26 04:28:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][100/351]	Step 34892	lr 0.00565	Loss 0.4483 (0.4521)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.6%)	
11/26 04:29:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][200/351]	Step 34992	lr 0.00565	Loss 0.4780 (0.4631)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
11/26 04:30:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][300/351]	Step 35092	lr 0.00565	Loss 0.5753 (0.4751)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.4%)	
11/26 04:30:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [121][351/351]	Step 35143	lr 0.00565	Loss 0.4864 (0.4788)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
11/26 04:30:29午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [121/149] Final Prec@1 85.4978%
11/26 04:30:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][39/40]	Step 35144	Loss 1.4484	Prec@(1,5) (63.4%, 88.5%)
11/26 04:30:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 63.4800%
11/26 04:30:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:31:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][100/351]	Step 35244	lr 0.00535	Loss 0.4433 (0.4358)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.6%)	
11/26 04:31:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][200/351]	Step 35344	lr 0.00535	Loss 0.5272 (0.4512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.5%)	
11/26 04:32:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][300/351]	Step 35444	lr 0.00535	Loss 0.3339 (0.4578)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.5%)	
11/26 04:32:58午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [122][351/351]	Step 35495	lr 0.00535	Loss 0.4381 (0.4611)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.5%)	
11/26 04:32:58午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [122/149] Final Prec@1 85.9867%
11/26 04:33:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][39/40]	Step 35496	Loss 1.4734	Prec@(1,5) (61.9%, 88.2%)
11/26 04:33:05午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 61.9000%
11/26 04:33:05午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:33:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][100/351]	Step 35596	lr 0.00506	Loss 0.3948 (0.4246)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.8%)	
11/26 04:34:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][200/351]	Step 35696	lr 0.00506	Loss 0.3861 (0.4371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.7%)	
11/26 04:35:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][300/351]	Step 35796	lr 0.00506	Loss 0.5691 (0.4442)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.6%)	
11/26 04:35:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [123][351/351]	Step 35847	lr 0.00506	Loss 0.6848 (0.4509)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.6%)	
11/26 04:35:27午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [123/149] Final Prec@1 86.2311%
11/26 04:35:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][39/40]	Step 35848	Loss 1.4749	Prec@(1,5) (63.1%, 87.8%)
11/26 04:35:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 63.1200%
11/26 04:35:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:36:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][100/351]	Step 35948	lr 0.00479	Loss 0.5111 (0.4183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.8%)	
11/26 04:36:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][200/351]	Step 36048	lr 0.00479	Loss 0.3548 (0.4238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
11/26 04:37:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][300/351]	Step 36148	lr 0.00479	Loss 0.3842 (0.4346)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.7%)	
11/26 04:37:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [124][351/351]	Step 36199	lr 0.00479	Loss 0.5999 (0.4364)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.7%)	
11/26 04:37:57午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [124/149] Final Prec@1 86.5489%
11/26 04:38:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][39/40]	Step 36200	Loss 1.4801	Prec@(1,5) (62.7%, 88.3%)
11/26 04:38:03午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 62.6600%
11/26 04:38:03午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:38:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][100/351]	Step 36300	lr 0.00451	Loss 0.4493 (0.3906)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.0%)	
11/26 04:39:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][200/351]	Step 36400	lr 0.00451	Loss 0.4399 (0.4036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 98.9%)	
11/26 04:40:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][300/351]	Step 36500	lr 0.00451	Loss 0.4586 (0.4136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
11/26 04:40:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [125][351/351]	Step 36551	lr 0.00451	Loss 0.5476 (0.4198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 98.7%)	
11/26 04:40:26午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [125/149] Final Prec@1 87.2511%
11/26 04:40:32午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][39/40]	Step 36552	Loss 1.4923	Prec@(1,5) (62.8%, 88.5%)
11/26 04:40:32午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 62.8000%
11/26 04:40:32午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:41:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][100/351]	Step 36652	lr 0.00425	Loss 0.6438 (0.3956)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 98.9%)	
11/26 04:41:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][200/351]	Step 36752	lr 0.00425	Loss 0.5138 (0.4038)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
11/26 04:42:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][300/351]	Step 36852	lr 0.00425	Loss 0.4145 (0.4015)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 98.8%)	
11/26 04:42:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [126][351/351]	Step 36903	lr 0.00425	Loss 0.4003 (0.4046)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.8%)	
11/26 04:42:55午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [126/149] Final Prec@1 87.7867%
11/26 04:43:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][39/40]	Step 36904	Loss 1.4757	Prec@(1,5) (62.9%, 88.6%)
11/26 04:43:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 62.9000%
11/26 04:43:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:43:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][100/351]	Step 37004	lr 0.004	Loss 0.3447 (0.3794)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.0%)	
11/26 04:44:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][200/351]	Step 37104	lr 0.004	Loss 0.4337 (0.3856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.0%)	
11/26 04:45:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][300/351]	Step 37204	lr 0.004	Loss 0.2852 (0.3926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.1%, 99.0%)	
11/26 04:45:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [127][351/351]	Step 37255	lr 0.004	Loss 0.4396 (0.3974)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.0%)	
11/26 04:45:25午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [127/149] Final Prec@1 87.9444%
11/26 04:45:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][39/40]	Step 37256	Loss 1.4810	Prec@(1,5) (63.0%, 88.8%)
11/26 04:45:31午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 62.9600%
11/26 04:45:31午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:46:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][100/351]	Step 37356	lr 0.00375	Loss 0.4510 (0.3696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.1%)	
11/26 04:46:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][200/351]	Step 37456	lr 0.00375	Loss 0.2869 (0.3803)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.1%)	
11/26 04:47:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][300/351]	Step 37556	lr 0.00375	Loss 0.3777 (0.3842)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.0%)	
11/26 04:47:54午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [128][351/351]	Step 37607	lr 0.00375	Loss 0.3528 (0.3858)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.0%)	
11/26 04:47:54午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [128/149] Final Prec@1 88.4511%
11/26 04:48:00午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][39/40]	Step 37608	Loss 1.4602	Prec@(1,5) (63.1%, 88.7%)
11/26 04:48:00午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 63.1200%
11/26 04:48:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.4800%
11/26 04:48:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][100/351]	Step 37708	lr 0.00352	Loss 0.4071 (0.3564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.1%)	
11/26 04:49:22午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][200/351]	Step 37808	lr 0.00352	Loss 0.2699 (0.3654)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.1%)	
11/26 04:50:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][300/351]	Step 37908	lr 0.00352	Loss 0.3588 (0.3741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.1%)	
11/26 04:50:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [129][351/351]	Step 37959	lr 0.00352	Loss 0.4428 (0.3745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.1%)	
11/26 04:50:23午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [129/149] Final Prec@1 88.8667%
11/26 04:50:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][39/40]	Step 37960	Loss 1.4697	Prec@(1,5) (63.9%, 88.6%)
11/26 04:50:30午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 63.8600%
11/26 04:50:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.8600%
11/26 04:51:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][100/351]	Step 38060	lr 0.00329	Loss 0.3268 (0.3523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.2%)	
11/26 04:51:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][200/351]	Step 38160	lr 0.00329	Loss 0.3636 (0.3574)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
11/26 04:52:32午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][300/351]	Step 38260	lr 0.00329	Loss 0.4357 (0.3623)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.1%, 99.2%)	
11/26 04:52:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [130][351/351]	Step 38311	lr 0.00329	Loss 0.3527 (0.3643)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.1%)	
11/26 04:52:53午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [130/149] Final Prec@1 88.9556%
11/26 04:52:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][39/40]	Step 38312	Loss 1.4339	Prec@(1,5) (63.5%, 88.6%)
11/26 04:52:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 63.5400%
11/26 04:52:59午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.8600%
11/26 04:53:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][100/351]	Step 38412	lr 0.00308	Loss 0.4058 (0.3413)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.2%)	
11/26 04:54:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][200/351]	Step 38512	lr 0.00308	Loss 0.4535 (0.3450)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
11/26 04:55:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][300/351]	Step 38612	lr 0.00308	Loss 0.3962 (0.3537)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.2%)	
11/26 04:55:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [131][351/351]	Step 38663	lr 0.00308	Loss 0.3014 (0.3557)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.2%)	
11/26 04:55:22午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [131/149] Final Prec@1 89.3578%
11/26 04:55:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][39/40]	Step 38664	Loss 1.4405	Prec@(1,5) (64.6%, 88.3%)
11/26 04:55:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 64.5800%
11/26 04:55:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 04:56:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][100/351]	Step 38764	lr 0.00287	Loss 0.2801 (0.3299)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.3%)	
11/26 04:56:50午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][200/351]	Step 38864	lr 0.00287	Loss 0.3936 (0.3349)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.1%, 99.3%)	
11/26 04:57:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][300/351]	Step 38964	lr 0.00287	Loss 0.4341 (0.3426)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.2%)	
11/26 04:57:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [132][351/351]	Step 39015	lr 0.00287	Loss 0.3210 (0.3448)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
11/26 04:57:51午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [132/149] Final Prec@1 89.6600%
11/26 04:57:57午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][39/40]	Step 39016	Loss 1.4578	Prec@(1,5) (63.9%, 89.0%)
11/26 04:57:57午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 63.9200%
11/26 04:57:57午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 04:58:39午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][100/351]	Step 39116	lr 0.00267	Loss 0.3078 (0.3129)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
11/26 04:59:19午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][200/351]	Step 39216	lr 0.00267	Loss 0.3553 (0.3238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.3%)	
11/26 04:59:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][300/351]	Step 39316	lr 0.00267	Loss 0.3153 (0.3285)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.3%)	
11/26 05:00:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [133][351/351]	Step 39367	lr 0.00267	Loss 0.2361 (0.3329)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.3%)	
11/26 05:00:20午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [133/149] Final Prec@1 90.2289%
11/26 05:00:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][39/40]	Step 39368	Loss 1.4573	Prec@(1,5) (64.2%, 88.7%)
11/26 05:00:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 64.2400%
11/26 05:00:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:01:08午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][100/351]	Step 39468	lr 0.00248	Loss 0.2994 (0.3063)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
11/26 05:01:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][200/351]	Step 39568	lr 0.00248	Loss 0.3053 (0.3164)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.3%)	
11/26 05:02:28午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][300/351]	Step 39668	lr 0.00248	Loss 0.3232 (0.3198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.3%)	
11/26 05:02:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [134][351/351]	Step 39719	lr 0.00248	Loss 0.3310 (0.3224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.3%)	
11/26 05:02:49午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [134/149] Final Prec@1 90.4578%
11/26 05:02:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][39/40]	Step 39720	Loss 1.4605	Prec@(1,5) (63.9%, 88.8%)
11/26 05:02:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 63.9000%
11/26 05:02:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:03:37午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][100/351]	Step 39820	lr 0.00231	Loss 0.2139 (0.2991)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
11/26 05:04:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][200/351]	Step 39920	lr 0.00231	Loss 0.3833 (0.3105)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
11/26 05:04:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][300/351]	Step 40020	lr 0.00231	Loss 0.2895 (0.3162)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
11/26 05:05:18午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [135][351/351]	Step 40071	lr 0.00231	Loss 0.2804 (0.3179)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
11/26 05:05:18午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [135/149] Final Prec@1 90.6378%
11/26 05:05:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][39/40]	Step 40072	Loss 1.4849	Prec@(1,5) (63.6%, 88.7%)
11/26 05:05:25午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 63.6200%
11/26 05:05:25午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:06:07午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][100/351]	Step 40172	lr 0.00214	Loss 0.2485 (0.3025)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.4%)	
11/26 05:06:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][200/351]	Step 40272	lr 0.00214	Loss 0.3610 (0.3050)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
11/26 05:07:27午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][300/351]	Step 40372	lr 0.00214	Loss 0.3232 (0.3085)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
11/26 05:07:48午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [136][351/351]	Step 40423	lr 0.00214	Loss 0.3333 (0.3115)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
11/26 05:07:48午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [136/149] Final Prec@1 91.0244%
11/26 05:07:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][39/40]	Step 40424	Loss 1.4707	Prec@(1,5) (64.1%, 88.5%)
11/26 05:07:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 64.1600%
11/26 05:07:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:08:36午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][100/351]	Step 40524	lr 0.00199	Loss 0.2949 (0.2872)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.4%)	
11/26 05:09:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][200/351]	Step 40624	lr 0.00199	Loss 0.3183 (0.2972)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.4%)	
11/26 05:09:57午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][300/351]	Step 40724	lr 0.00199	Loss 0.2362 (0.3007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.4%)	
11/26 05:10:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [137][351/351]	Step 40775	lr 0.00199	Loss 0.3326 (0.3008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.4%)	
11/26 05:10:18午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [137/149] Final Prec@1 91.2933%
11/26 05:10:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][39/40]	Step 40776	Loss 1.4543	Prec@(1,5) (64.1%, 88.7%)
11/26 05:10:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 64.0800%
11/26 05:10:24午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:11:06午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][100/351]	Step 40876	lr 0.00184	Loss 0.2527 (0.2774)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.4%)	
11/26 05:11:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][200/351]	Step 40976	lr 0.00184	Loss 0.2834 (0.2862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.4%)	
11/26 05:12:26午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][300/351]	Step 41076	lr 0.00184	Loss 0.4397 (0.2938)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
11/26 05:12:47午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [138][351/351]	Step 41127	lr 0.00184	Loss 0.4114 (0.2936)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
11/26 05:12:47午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [138/149] Final Prec@1 91.5911%
11/26 05:12:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][39/40]	Step 41128	Loss 1.4530	Prec@(1,5) (64.6%, 88.8%)
11/26 05:12:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 64.5800%
11/26 05:12:54午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:13:35午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][100/351]	Step 41228	lr 0.00171	Loss 0.2966 (0.2800)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
11/26 05:14:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][200/351]	Step 41328	lr 0.00171	Loss 0.2757 (0.2871)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
11/26 05:14:56午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][300/351]	Step 41428	lr 0.00171	Loss 0.3673 (0.2889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
11/26 05:15:17午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [139][351/351]	Step 41479	lr 0.00171	Loss 0.2949 (0.2905)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
11/26 05:15:17午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [139/149] Final Prec@1 91.7244%
11/26 05:15:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][39/40]	Step 41480	Loss 1.4411	Prec@(1,5) (64.0%, 89.1%)
11/26 05:15:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 64.0000%
11/26 05:15:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.5800%
11/26 05:16:05午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][100/351]	Step 41580	lr 0.00159	Loss 0.2514 (0.2720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/26 05:16:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][200/351]	Step 41680	lr 0.00159	Loss 0.3804 (0.2747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
11/26 05:17:25午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][300/351]	Step 41780	lr 0.00159	Loss 0.2112 (0.2791)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.5%)	
11/26 05:17:46午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [140][351/351]	Step 41831	lr 0.00159	Loss 0.3081 (0.2819)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.5%)	
11/26 05:17:46午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [140/149] Final Prec@1 92.1356%
11/26 05:17:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][39/40]	Step 41832	Loss 1.4313	Prec@(1,5) (64.9%, 89.5%)
11/26 05:17:53午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 64.9000%
11/26 05:17:53午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:18:34午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][100/351]	Step 41932	lr 0.00148	Loss 0.2681 (0.2606)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/26 05:19:15午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][200/351]	Step 42032	lr 0.00148	Loss 0.3030 (0.2683)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
11/26 05:19:55午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][300/351]	Step 42132	lr 0.00148	Loss 0.2633 (0.2725)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
11/26 05:20:16午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [141][351/351]	Step 42183	lr 0.00148	Loss 0.3191 (0.2738)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
11/26 05:20:16午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [141/149] Final Prec@1 92.2800%
11/26 05:20:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][39/40]	Step 42184	Loss 1.4848	Prec@(1,5) (64.2%, 89.0%)
11/26 05:20:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 64.2400%
11/26 05:20:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:21:04午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][100/351]	Step 42284	lr 0.00138	Loss 0.2042 (0.2752)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
11/26 05:21:44午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][200/351]	Step 42384	lr 0.00138	Loss 0.3495 (0.2724)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
11/26 05:22:24午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][300/351]	Step 42484	lr 0.00138	Loss 0.2748 (0.2723)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.5%)	
11/26 05:22:45午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [142][351/351]	Step 42535	lr 0.00138	Loss 0.2691 (0.2745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
11/26 05:22:45午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [142/149] Final Prec@1 92.2511%
11/26 05:22:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][39/40]	Step 42536	Loss 1.4317	Prec@(1,5) (64.8%, 88.9%)
11/26 05:22:51午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 64.8000%
11/26 05:22:51午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:23:33午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][100/351]	Step 42636	lr 0.00129	Loss 0.1788 (0.2612)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
11/26 05:24:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][200/351]	Step 42736	lr 0.00129	Loss 0.2306 (0.2623)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
11/26 05:24:53午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][300/351]	Step 42836	lr 0.00129	Loss 0.1923 (0.2681)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/26 05:25:14午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [143][351/351]	Step 42887	lr 0.00129	Loss 0.2479 (0.2691)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/26 05:25:14午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [143/149] Final Prec@1 92.5867%
11/26 05:25:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][39/40]	Step 42888	Loss 1.4590	Prec@(1,5) (63.7%, 89.0%)
11/26 05:25:21午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 63.6400%
11/26 05:25:21午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:26:02午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][100/351]	Step 42988	lr 0.00121	Loss 0.3334 (0.2561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
11/26 05:26:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][200/351]	Step 43088	lr 0.00121	Loss 0.2097 (0.2625)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
11/26 05:27:23午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][300/351]	Step 43188	lr 0.00121	Loss 0.2500 (0.2644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
11/26 05:27:43午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [144][351/351]	Step 43239	lr 0.00121	Loss 0.2536 (0.2632)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/26 05:27:43午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [144/149] Final Prec@1 92.7156%
11/26 05:27:50午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][39/40]	Step 43240	Loss 1.4389	Prec@(1,5) (64.6%, 89.2%)
11/26 05:27:50午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 64.6400%
11/26 05:27:50午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:28:31午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][100/351]	Step 43340	lr 0.00115	Loss 0.2479 (0.2600)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.7%)	
11/26 05:29:12午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][200/351]	Step 43440	lr 0.00115	Loss 0.2551 (0.2615)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
11/26 05:29:52午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][300/351]	Step 43540	lr 0.00115	Loss 0.2857 (0.2593)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
11/26 05:30:13午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [145][351/351]	Step 43591	lr 0.00115	Loss 0.2739 (0.2604)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
11/26 05:30:13午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [145/149] Final Prec@1 92.7444%
11/26 05:30:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][39/40]	Step 43592	Loss 1.4389	Prec@(1,5) (64.5%, 89.4%)
11/26 05:30:19午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 64.5600%
11/26 05:30:19午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:31:01午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][100/351]	Step 43692	lr 0.00109	Loss 0.2513 (0.2492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
11/26 05:31:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][200/351]	Step 43792	lr 0.00109	Loss 0.2170 (0.2518)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
11/26 05:32:21午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][300/351]	Step 43892	lr 0.00109	Loss 0.2510 (0.2566)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.6%)	
11/26 05:32:42午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [146][351/351]	Step 43943	lr 0.00109	Loss 0.2929 (0.2581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
11/26 05:32:42午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [146/149] Final Prec@1 92.9667%
11/26 05:32:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][39/40]	Step 43944	Loss 1.4271	Prec@(1,5) (64.7%, 89.5%)
11/26 05:32:49午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 64.6600%
11/26 05:32:49午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:33:30午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][100/351]	Step 44044	lr 0.00105	Loss 0.3011 (0.2494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
11/26 05:34:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][200/351]	Step 44144	lr 0.00105	Loss 0.2240 (0.2499)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
11/26 05:34:51午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][300/351]	Step 44244	lr 0.00105	Loss 0.2699 (0.2528)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
11/26 05:35:11午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [147][351/351]	Step 44295	lr 0.00105	Loss 0.2228 (0.2533)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
11/26 05:35:12午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [147/149] Final Prec@1 93.0644%
11/26 05:35:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][39/40]	Step 44296	Loss 1.4612	Prec@(1,5) (64.1%, 89.1%)
11/26 05:35:18午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 64.1400%
11/26 05:35:18午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:35:59午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][100/351]	Step 44396	lr 0.00102	Loss 0.2827 (0.2429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
11/26 05:36:40午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][200/351]	Step 44496	lr 0.00102	Loss 0.2065 (0.2482)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.6%)	
11/26 05:37:20午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][300/351]	Step 44596	lr 0.00102	Loss 0.2367 (0.2499)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
11/26 05:37:41午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [148][351/351]	Step 44647	lr 0.00102	Loss 0.2442 (0.2511)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
11/26 05:37:41午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [148/149] Final Prec@1 93.2089%
11/26 05:37:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][39/40]	Step 44648	Loss 1.4400	Prec@(1,5) (64.5%, 89.3%)
11/26 05:37:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 64.4800%
11/26 05:37:47午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:38:29午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][100/351]	Step 44748	lr 0.00101	Loss 0.3317 (0.2405)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
11/26 05:39:09午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][200/351]	Step 44848	lr 0.00101	Loss 0.2898 (0.2445)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
11/26 05:39:49午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][300/351]	Step 44948	lr 0.00101	Loss 0.2242 (0.2479)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
11/26 05:40:10午後 searchEvalStage_curriculum_trainer.py:208 [INFO] Train: Epoch: [149][351/351]	Step 44999	lr 0.00101	Loss 0.2081 (0.2489)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
11/26 05:40:10午後 searchEvalStage_curriculum_trainer.py:222 [INFO] Train: [149/149] Final Prec@1 93.2689%
11/26 05:40:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][39/40]	Step 45000	Loss 1.4494	Prec@(1,5) (64.6%, 89.4%)
11/26 05:40:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 64.5200%
11/26 05:40:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9000%
11/26 05:40:17午後 searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 64.9000%
11/26 05:40:17午後 searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[2, 3], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
